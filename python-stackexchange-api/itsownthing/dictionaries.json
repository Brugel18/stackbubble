{'Body': '<p>I know the term <strong>order</strong> of a B-tree. Recently I heard a new term  <strong>B tree with minimum degree of 2.</strong><br>\nWe know the degree is related with a node but what is degree of a tree.<br>\nIs degree imposes any kind of a restriction on height of a B-tree?  </p>\n', 'ViewCount': '1586', 'Title': 'B-Tree Is degree and order both are the same thing related to a B-Tree', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-21T10:30:15.287', 'LastEditDate': '2014-02-21T10:30:15.287', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '3075', 'Tags': '<terminology><data-structures><search-trees><dictionaries>', 'CreationDate': '2012-11-21T05:17:52.773', 'FavoriteCount': '1', 'Id': '6799''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Bloom filter use a hash function to test membership for S by checking if an item is present of not at the specified position. To mitigate the effect of hash collision, multiple functions are used, yielding probabilistic bound if using universal hash.\nWe can use 10 bits per elements to have 'reasonable' error rate.</p>\n\n<p>If we could build directly a perfect hashing function for the set  S + $\\infty$, where last the element is one not present in S, we could use only 1 bit per element and have perfect recovery.</p>\n\n<p>What are the fundamental reasons why this reasonning is wrong ?</p>\n", 'ViewCount': '182', 'Title': 'Bloom filter and perfect hashing', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T11:35:07.190', 'LastEditDate': '2014-04-29T11:35:07.190', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4469', 'Tags': '<data-structures><hash><probabilistic-algorithms><bloom-filters><dictionaries>', 'CreationDate': '2013-06-03T15:20:55.557', 'Id': '12444''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '254', 'Title': 'Why do Bloom filters work?', 'LastEditDate': '2014-04-29T11:35:41.260', 'AnswerCount': '3', 'Score': '4', 'OwnerDisplayName': 'user220201', 'PostTypeId': '1', 'OwnerUserId': '8842', 'Body': "<p>Let's say I am using Bloom filters to create a function to check if a word exists in a document or not.  If I pick a hash function to fill out a bit bucket for all words in my document. Then if for a given number of words, wouldn't the whole bit bucket be all 1s? If so then checking for any word will return true? What am I missing here? </p>\n", 'Tags': '<data-structures><probabilistic-algorithms><bloom-filters><dictionaries>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T11:35:41.260', 'CommentCount': '0', 'AcceptedAnswerId': '12838', 'CreationDate': '2013-06-22T13:12:57.470', 'Id': '12834''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I know that standard Bloom Filters only have operations like inserting elements and checking if an element belongs to filter, but are also some modification of Bloom filters which enable a delete operation--for example: counting Bloom filters. I heard also about another method, which uses a second filter. If I want to remove an element I have to 'insert' it into this second filter. I can't find how this proposed structure operates, any article about it, or even the name of the originator. Maybe someone can share with me with a link to any interesting articles about this method? I found a lot of articles about counting Bloom filters and other methods, but I can't find any description of this one.</p>\n", 'ViewCount': '101', 'Title': 'Deleting in Bloom Filters', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T11:35:49.423', 'LastEditDate': '2014-04-29T11:35:49.423', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12038', 'Tags': '<reference-request><data-structures><probabilistic-algorithms><bloom-filters><dictionaries>', 'CreationDate': '2013-12-25T22:52:19.973', 'Id': '19292''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u"<p>I am looking for implementation of the set data type. That is, we have to</p>\n\n<ul>\n<li>maintain a dynamic subset $S$ (of size $n$) from the universe $U = \\{0, 1, 2, 3, \\dots , u \u2013 1\\}$ of size $u$ with</li>\n<li>operations <code>insert(x)</code> (add an element <code>x</code> to $S$) and <code>find(x)</code> (checks whether element <code>x</code> is a member of $S$).</li>\n</ul>\n\n<p>I don't care about other operations. For orientation, in applications I'm working with we have $u \\approx 10^{10}$.</p>\n\n<p>I know of implementations that provide both operations in time $O(1)$, so I worry mostly about the size of data structure. I expect <em>billions</em> of entries but want to avoid swapping as much as possible.</p>\n\n<p>I am willing to sacrifice runtime if necessary. Amortised runtime of $O(\\log n)$ is what I can admit; expected runtimes or runtimes in $\\omega(\\log n)$ are not admissable.</p>\n\n<p>One idea I have is that if $S$ can be represented as a union of ranges <code>[xmin, xmax]</code>, then we will be able to save on storage size with the price of some performance decrease. Also, some other data patterns are possible, like <code>[0, 2, 4, 6]</code>.</p>\n\n<p>Could you please point me to data structures which can do something like that?</p>\n", 'ViewCount': '155', 'Title': 'Looking for a set implementation with small memory footprint', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-03T09:34:06.393', 'LastEditDate': '2014-01-31T08:03:57.357', 'AnswerCount': '2', 'CommentCount': '11', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '11850', 'Tags': '<data-structures><efficiency><space-complexity><sets><dictionaries>', 'CreationDate': '2014-01-29T16:42:55.737', 'Id': '20070''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '76', 'Title': 'Why should leaf nodes in a red-black tree be black?', 'LastEditDate': '2014-03-27T15:03:50.240', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16188', 'FavoriteCount': '1', 'Body': u'<p>From the property of Red-Black Trees we know that: </p>\n\n<ul>\n<li>All leaves (NIL) are black. (All leaves are same color as the root.)(Comren et al "Introduction to Algorithms")</li>\n</ul>\n\n<p><img src="http://i.stack.imgur.com/hz7wf.png" alt="An example of a red\u2013black tree. From Wikipedia"></p>\n\n<p>But what is the reason that we should enforce them as Black, even though they\'re NILL\'s? </p>\n', 'Tags': '<terminology><data-structures><search-trees><dictionaries>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-29T05:15:31.620', 'CommentCount': '1', 'AcceptedAnswerId': '23123', 'CreationDate': '2014-03-27T10:13:14.353', 'Id': '23119''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '871', 'Title': 'Is there an anti-Bloom filter?', 'LastEditDate': '2014-04-29T11:35:57.480', 'AnswerCount': '4', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '5323', 'FavoriteCount': '4', 'Body': '<p>A <a href="https://en.wikipedia.org/wiki/Bloom_filter" rel="nofollow">Bloom filter</a> makes it possible to efficiently keep track of whether various values have already been encountered during processing.  When there are many data items then a Bloom filter can result in a significant memory saving over a hash table.  The main feature of a Bloom filter, which it shares with a hash table, is that it always says "not new" if an item is not new, but there is a non-zero probability that an item will be flagged as "not new" even when it is new.</p>\n\n<blockquote>\n  <p>Is there an "anti-Bloom filter", which has the opposite behaviour?</p>\n</blockquote>\n\n<p>In other words: is there an efficient data structure which says "new" if an item is new, but which might also say "new" for some items which are not new?</p>\n\n<p>Keeping all the previously seen items (for instance, in a sorted linked list) satisfies the first requirement but may use a lot of memory.  I am hoping it is also unnecessary, given the relaxed second requirement.</p>\n\n<hr>\n\n<p>For those who prefer a more formal treatment, write $b(x) = 1$ if the Bloom filter thinks $x$ is new, $b(x) = 0$ otherwise, and write $n(x) = 1$ if $x$ really is new and $n(x) = 0$ otherwise.</p>\n\n<p>Then $Pr[b(x) = 0 | n(x) = 0] = 1$; $Pr[b(x) = 0 | n(x) = 1] = \\alpha$; $Pr[b(x) = 1 | n(x) = 0] = 0$; $Pr[b(x) = 1 | n(x) = 1] = 1 - \\alpha$, for some $0 &lt; \\alpha &lt; 1$.</p>\n\n<p>I am asking: does an efficient data structure exist, implementing a function $b\'$ with some $0 &lt; \\beta &lt; 1$, such that $Pr[b\'(x) = 0 | n(x) = 0] = \\beta$; $Pr[b\'(x) = 0 | n(x) = 1] = 0$; $Pr[b\'(x) = 1 | n(x) = 0] = 1 - \\beta$; $Pr[b\'(x) = 1 | n(x) = 1] = 1$?</p>\n\n<hr>\n\n<p><strong>Edit:</strong> It seems this question has been asked before on StackExchange, as <a href="http://stackoverflow.com/questions/635728">http://stackoverflow.com/questions/635728</a> and <a href="http://cstheory.stackexchange.com/questions/6596">http://cstheory.stackexchange.com/questions/6596</a> with a range of answers from "can\'t be done" through "can be done, at some cost" to "it is trivial to do, by reversing the values of $b$".  It is not yet clear to me what the "right" answer is.  What <em>is</em> clear is that an LRU caching scheme of some sort (such as the one suggested by Ilmari Karonen) works rather well, is easy to implement, and resulted in a 50% reduction in the time taken to run my code.</p>\n', 'Tags': '<reference-request><data-structures><hash><bloom-filters><dictionaries>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T11:35:57.480', 'CommentCount': '3', 'AcceptedAnswerId': '24122', 'CreationDate': '2014-04-25T21:08:54.120', 'Id': '24118''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I've been playing around with a simple probabilistic data structure which is very similar to a Bloom filter. Where a Bloom filter would use $k$ independent hash functions to choose $k$ of the $m$ bits to set, this structure uses $m$ hash functions, and sets each bit with probability $p$.</p>\n\n<p>This structure doesn't produce as low a false-positive rate as Bloom filters, but it seems to be extremely fast to compute, particularly if $m$ is some multiple of the machine word size and $p = 2^{-b}$ for some integer $b$: The hash functions can be computed in parallel by AND-ing $b$ independent $m$-bit hashes, and no dependent indexing or variable bitshifts are required.</p>\n\n<p>I'm certain someone's come up with this idea before me, and done a lot more advanced analysis and comparison of it than I'm qualified to do. Is there a particular name for this type of structure?</p>\n", 'ViewCount': '33', 'Title': 'Bloom filter variant', 'LastEditorUserId': '8410', 'LastActivityDate': '2014-04-29T17:07:58.197', 'LastEditDate': '2014-04-29T13:27:12.427', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24230', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8410', 'Tags': '<reference-request><data-structures><probabilistic-algorithms><bloom-filters><dictionaries>', 'CreationDate': '2014-04-29T10:55:19.287', 'Id': '24217''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '58', 'Title': 'Tree data structure for fast merges', 'LastEditDate': '2014-04-30T18:06:55.563', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17191', 'Body': '<p>I need trees that have the following properties:</p>\n\n<ol>\n<li><p>Each node in the tree has two values associated with it - a key and an associated opaque data element.</p></li>\n<li><p>An internal node in the tree has unbounded number of children. The tree reflects a real world hierarchy that is in flux over time - hence the maximum number of children of a given node are not known ahead of time.</p></li>\n<li><p>There is an ordering defined on sibling nodes that is a function of the keys stored in the nodes. </p></li>\n</ol>\n\n<p>Allow the following operations to be $O(\\lg n)$.</p>\n\n<h2>Update operations</h2>\n\n<ul>\n<li><p><code>merge(tree_1, tree_2)</code> - Destructively consumes <code>tree_1</code> and <code>tree_2</code> to create a new tree which contains keys from both input trees. I realize now that this operation is underdefined, I will put more thought into the semantics of the merge.</p></li>\n<li><p><code>insert(tree, parent_key, child_key, value)</code> - inserts the given key-value pair into the given subtree rooted at the node pointed to by the parent key. </p></li>\n<li><p><code>delete(tree, key)</code> - Delete subtree rooted at node with given key.</p></li>\n<li><p><code>update(tree, key, value)</code> - Destructively updates the existing data associated with the given key-value pair.</p></li>\n</ul>\n\n<h2>Query operations</h2>\n\n<ul>\n<li><p><code>find(tree, key)</code> - returns the value associated with the given key in the given tree. </p></li>\n<li><p><code>get_tree(tree, key)</code> - Return a subtree that is rooted at node with given key. The returned tree must a reference and share identity with corresponding nodes in the incoming tree. Modifying any nodes via the returned tree will hence result in changes to the initial tree. </p></li>\n<li><p><code>children(tree, key)</code> - Returns sequence of (key, data) of child nodes of node corresponding to key. </p></li>\n</ul>\n\n<p>Things I looked at before I asked this question - Binary trees, AVL trees, Red Black trees, 2-3 trees and they were not suitable because of fixed degree of internal nodes.</p>\n', 'ClosedDate': '2014-04-30T17:45:07.280', 'Tags': '<data-structures><trees><dictionaries>', 'LastEditorUserId': '17191', 'LastActivityDate': '2014-04-30T18:06:55.563', 'CommentCount': '6', 'AcceptedAnswerId': '24241', 'CreationDate': '2014-04-29T21:23:05.400', 'Id': '24235''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}