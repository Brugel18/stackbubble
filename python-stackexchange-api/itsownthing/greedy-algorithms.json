2070:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '761', 'Title': 'How to use a greedy algorithm to find the non-decreasing sequence closest to the given one?', 'LastEditDate': '2012-10-11T21:23:25.513', 'AnswerCount': '3', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '1718', 'FavoriteCount': '1', 'Body': "<p>You are given n integers $a_1, \\ldots, a_n$ all between $0$ and $l$. Under each integer $a_i$ you should write an integer $b_i$ between $0$ and $l$ with the requirement that the $b_i$'s form a non-decreasing sequence. Define the deviation of such a sequence to be $\\max(|a_1-b_1|, \\ldots, |a_n-b_n|)$. Design an algorithm that finds the $b_i$'s with the minimum deviation in runtime $O(n\\sqrt[4]{l})$.</p>\n\n<p>I honestly have no clue whatsoever how to even begin to solve this question. It looks like a dynamic programming question to me, but the professor said that this should be solved using a greedy algorithm. It would be much appreciated if someone can point me in the right direction by giving a small hint.</p>\n", 'Tags': '<algorithms><optimization><greedy-algorithms><subsequences>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-10-11T21:23:25.513', 'CommentCount': '6', 'AcceptedAnswerId': '2242', 'CreationDate': '2012-06-01T15:43:28.810', 'Id': '2188'},2071:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '27', 'Title': 'How to use greedy algorithm to solve this?', 'LastEditDate': '2012-06-09T07:28:40.890', 'AnswerCount': '0', 'Score': '1', 'OwnerDisplayName': 'Aden Dong', 'PostTypeId': '1', 'OwnerUserId': '1718', 'Body': u'<blockquote>\n  <p><strong>Possible Duplicate:</strong><br>\n  <a href="http://cs.stackexchange.com/questions/2188/how-to-use-greedy-algorithm-to-solve-this">How to use greedy algorithm to solve this?</a>  </p>\n</blockquote>\n\n\n\n<p>You are given $n$ integers $a_1, \\ldots, a_n$ all between $0$ and $l$. Under each integer $a_i$ you should write an integer $b_i$ between $0$ and $l$ with the requirement that the $b_i$\'s form a non-decreasing sequence (i.e. $b_i \\le b_{i+1}$ for all $i$). Define the deviation of such a sequence to be $\\max(|a_1\u2212b_1|,\\ldots,|a_n\u2212b_n|)$. Design an algorithm that finds the $b_i$\'s with the minimum deviation in runtime $O(n\\sqrt[4]{l})$.</p>\n\n<p>There were also two hints, one is to first find an algorithm in $O(nl)$ time, the other is that the runtime of the optimal algorithm is actually must less than $\\Theta(n\\sqrt[4]{l})$.</p>\n\n<p>I was able to find a solution that runs in $O(n^2)$ (without using any of the hints), but I have no idea how to find an algorithm that runs in $O(n\\sqrt[4]{l})$. Can anyone offer some insight into this? Maybe give a rough sketch of your algorithm? Thanks!</p>\n', 'ClosedDate': '2012-06-09T08:32:15.807', 'Tags': '<algorithms><optimization><greedy-algorithms>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-09T07:28:40.890', 'CommentCount': '0', 'CreationDate': '2012-06-06T04:06:54.050', 'Id': '2296'},2072:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I was trying to write some simple code for a "flow layout" manager and what I came up with initially was something like the following (semi-pseudocode):</p>\n\n<pre><code>int rowHeight = 0;\nRECT rect = parent.getClientRect();\nPOINT pos = rect.position;  // Start at top-left corner, row by row\n\nforeach (Window child in parent.children)\n{\n    // POINT is a tuple of: (x, y)\n    // SIZE is a tuple of: (width, height)\n    // RECT is a tuple of: (left, top, right, bottom)\n    RECT proposed1 = RECT(rect.left + pos.x, rect.top + pos.y, rect.right, rect.bottom),\n         proposed2 = RECT(rect.left, rect.top + pos.y + rowHeight, rect.right, rect.bottom);\n    SIZE size1 = child.getPreferredSize(proposed1),\n         size2 = child.getPreferredSize(proposed2);\n    if (size1.width &lt;= proposed1.width)\n    {\n        child.put(proposed1);  // same row\n        pos.x += size1.width;\n        rowHeight = max(rowHeight, size1.height);\n    }\n    else\n    {\n        child.put(proposed2);  // new row\n        pos.x = rect.left;\n        pos.y += rowHeight;\n        rowHeight = size2.height;\n    }\n}\n</code></pre>\n\n<p>In other words, the algorithm is very simple:<br>\nThe layout manager asks every component, "is the remaining portion of the row enough for you?" and, if the component says "no, my width is too long", it places the component on the next row instead.</p>\n\n<p>There are two major problems with this approach:</p>\n\n<ul>\n<li><p>This algorithm results in very long, thin components, because it is essentially greedy with the width of each component -- if a component wants the whole row, it will use the whole row (ugly), even if it could use a smaller width (but larger height).</p></li>\n<li><p>It only works if you already <em>know</em> what the parent\'s size is -- but you might not! Instead, you might simply have a restriction, "the parent\'s size must be between these two dimensions", but the rest might be open-ended.</p></li>\n</ul>\n\n<p>I am, however, at a loss of how to come up with a better algorithm -- how do I figure out what would be a good size to to \'propose\' to the component?   And even when I figure that out, what should I try to optimize, exactly? (The area, the width, the aspect ratio, the number of components on the screen, or something else?)</p>\n\n<p>Any ideas on how I should approach this problem?</p>\n', 'ViewCount': '280', 'Title': '"Flow layouts" inside a GUI -- how do I come up with a good algorithm?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-10T11:26:48.527', 'LastEditDate': '2012-06-10T11:26:48.527', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '836', 'Tags': '<algorithms><computational-geometry><greedy-algorithms><user-interface>', 'CreationDate': '2012-06-09T23:51:40.070', 'FavoriteCount': '0', 'Id': '2306'},2073:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given a <a href="https://en.wikipedia.org/wiki/Cactus_graph" rel="nofollow">cactus</a>, we want to weight its edges in such a way that</p>\n\n<ol>\n<li>For each vertex, the sum of the weights of edges incident to the vertex is no more than 1.</li>\n<li>The sum of all edge weights is maximized.</li>\n</ol>\n\n<p>Clearly the answer is no more than $\\frac{n}{2}$ for $n$ vertices ($\\sum d_i = 2D$ where $d_i$ is the sum for one vertex and $D$ is the sum over every edge). This bound is achievable for cycle graphs by weighting each edge 1/2.</p>\n\n<p>I found a greedy algorithm for trees. Just assign 1 to edges incident to leaves and remove them and their neighbors from the graph in repeated passes. This prunes the cactus down to a bunch of interconnected cycles. At this point I assumed the remaining cycles were not interconnected and weighted each edge 1/2. This got 9/10 test cases but is, of course, incomplete.</p>\n\n<p>So, how might we solve this problem for cacti in general? I would prefer hints to full solutions, but either is fine.</p>\n\n<p><sub>\nThis question involves a problem from <a href="https://genesys.interviewstreet.com" rel="nofollow">an InterviewStreet CompanySprint</a>. I already competed but I\'d like some thoughts on a problem (solutions aren\'t released, and I\'ve been banging my head against the wall over this problem).\n</sub></p>\n', 'ViewCount': '265', 'Title': 'Balanced weighting of edges in cactus graph', 'LastEditorUserId': '39', 'LastActivityDate': '2012-07-04T21:47:55.087', 'LastEditDate': '2012-07-04T21:47:55.087', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2038', 'Tags': '<algorithms><graph-theory><greedy-algorithms>', 'CreationDate': '2012-07-03T16:09:43.020', 'FavoriteCount': '1', 'Id': '2598'},2074:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '209', 'Title': 'Greedy choice and matroids (greedoids)', 'LastEditDate': '2012-07-20T14:19:38.057', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2220', 'FavoriteCount': '3', 'Body': '<p>As I was going through the material about the greedy approach, I came to know that a knowledge on matroids (greedoids) will help me approaching the problem properly. After reading about matroids I have roughly understood what matroids are. But how do you use the concept of a matroid for solving a given optimisation problem? </p>\n\n<p>Take, for example, the <a href="https://en.wikipedia.org/wiki/Activity_selection_problem" rel="nofollow">activity selection problem</a>. What are the steps to use matroid theory for solving the problem?</p>\n', 'Tags': '<algorithms><graph-theory><greedy-algorithms>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-20T14:23:46.633', 'CommentCount': '2', 'AcceptedAnswerId': '2841', 'CreationDate': '2012-07-20T09:34:21.970', 'Id': '2840'},2075:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I was watching the <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/" rel="nofollow">video lecture from MIT on Prim\'s algorithm for minimum spanning trees</a>.\nWhy do we need to do the swap step for proving the theorem that if we choose a set of vertices  in minimum spanning tree of $G(V,E)$and let us call that $A$ such  $A\\subset B$,  the edge with the least weight connecting $A$ to $V-A$ will always be in the minimum spanning tree ?  The professor has done the swap step at point 59:07 seconds in the video.</p>\n', 'ViewCount': '179', 'Title': "Why do the swap step in Prim's algorithm for minimum spanning trees?", 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-20T06:52:26.807', 'LastEditDate': '2012-09-19T21:19:36.247', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '4624', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2223', 'Tags': '<algorithms><graph-theory><algorithm-analysis><greedy-algorithms><spanning-trees>', 'CreationDate': '2012-09-19T13:11:11.090', 'Id': '4614'},2076:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given a set of coins with different denominations $c1, ... , cn$ and a value v you want to find the least number of coins needed to represent the value v.</p>\n\n<p>E.g. for the coinset 1,5,10,20 this gives 2 coins for the sum 6 and 6 coins for the sum 19. </p>\n\n<p>My main question is: when can a greedy strategy be used to solve this problem?</p>\n\n<hr>\n\n<p>Bonus points: Is this statement plain incorrect? (From: <a href="http://stackoverflow.com/questions/6025076/how-to-tell-if-greedy-algorithm-suffices-for-the-minimum-coin-change-problem/6031625#6031625">How to tell if greedy algorithm suffices for the minimum coin change problem?</a>)</p>\n\n<blockquote>\n  <p>However, this paper has a proof that if the greedy algorithm works for the first largest denom + second largest denom values, then it works for them all, and it suggests just using the greedy algorithm vs the optimal DP algorithm to check it.\n  <a href="http://www.cs.cornell.edu/~kozen/papers/change.pdf">http://www.cs.cornell.edu/~kozen/papers/change.pdf</a></p>\n</blockquote>\n\n<p>Ps. note that the answers in that thread are incredibly crummy- that is why I asked the question anew.</p>\n', 'ViewCount': '3360', 'Title': 'When can a greedy algorithm solve the coin change problem?', 'LastActivityDate': '2012-11-12T03:16:46.283', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '6625', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '2826', 'Tags': '<algorithms><combinatorics><greedy-algorithms>', 'CreationDate': '2012-11-08T08:59:30.133', 'FavoriteCount': '0', 'Id': '6552'},2077:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Could anyone point me to simple tutorial on greedy algorithm  for Minimum Spanning tree - Kruskal's and Prims' Method</p>\n\n<p>I am looking for a tutorial which </p>\n\n<ul>\n<li>does not include all the mathematical notation  </li>\n<li>explains algorithm along with the analysis of the running time.</li>\n</ul>\n", 'ViewCount': '614', 'Title': 'Greedy algorithms tutorial', 'LastEditorUserId': '3004', 'LastActivityDate': '2012-11-13T07:33:33.163', 'LastEditDate': '2012-11-12T18:32:49.273', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6635', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '3004', 'Tags': '<algorithm-analysis><greedy-algorithms>', 'CreationDate': '2012-11-12T15:02:47.490', 'Id': '6634'},2078:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a complex query $Q$ used to search a dataset $S$ to find $H_\\text{exact} = \\{s \\in S \\mid \\text{where $Q(s)$ is True}\\}$. Each query takes on average time $t$ so the overall time in the linear search is $t\\cdot |S|$. I can break a query down into simpler sub-queries q_i and find $H_\\text{approx} = \\{s\\in S \\mid \\forall q_j(s) \\text {is True}\\}$  and where $H_\\text{exact}\\subseteq H_\\text{approx}$. Each subquery $q_i$ is much faster to compute, so overall it is faster to find $H_\\text{approx}$ and then use $Q$ to find $H_\\text{exact}$.</p>\n\n<p>Each $Q$ has many $q_i$. The overlap between different $Q$ is high. I\'m looking for a way to determine a decision-tree-like set of fixed questions $q_j$ which minimize the average time to find a H_exact, based on a large sample of search queries.</p>\n\n<p>To make this more concrete, suppose the data set contains the 7 billion people in the world, and the complex queries are things like "the woman who lives in the red house on the corner of 5th and Lexington in a city starting with B."</p>\n\n<p>The obvious solution is to check every person in world and see who matches the query. There may be more than one such person. This method takes a long time. </p>\n\n<p>I could pre-compute this query exactly, in which case it would be very fast .. but only for this question. However, I know that other queries are for the woman who lives on the blue house on the same corner, the man who lives on the same corner, the same question but in a city starting with C, or something totally different, like \'the king of Sweden.\'</p>\n\n<p>Instead, I can break the complex question down into a set of easier but more general sets. For example, all of the above questions have a gender-role based query, so I can precompute the set of all people in the world who consider themselves a \'woman.\' This sub-query takes essentially no time, so the overall search time decreases by roughly 1/2. (Assuming that by other knowledge we know that a Swedish "king" cannot be a "woman." Hatshepsut was an Egyptian woman who was king.)</p>\n\n<p>However, there are sometimes queries which aren\'t gender-based, like "the person who lives on 8th street in a red house in a city starting with A." I can see that the subquery "lives in a red house" is common, and pre-compute a list of all those people who live in a red house.</p>\n\n<p>This gives me a decision tree. In the usual case, each branch of the decision tree contains different questions, and the methods to select the optimal terms for the decision tree are well known. However, I\'m building on an existing system which requires that all branches must ask the same questions.</p>\n\n<p>Here\'s an example of a possible final decision set: question 1 is \'is the person a woman?\', question 2 is \'does the person live in a red house?\', question 3 is \'does the person live in a city starting with A or does the person live in a city starting with B?\', and question 4 is \'does the person live on a numbered street?\'.</p>\n\n<p>When a query $Q$ comes in, I see if its $q_i$ match any of the pre-computed questions $q_j$ I\'ve determined. If so, then I get the intersection of those answers, and ask the question $Q$ on that intersection subset. Eg, if the question is "people who live in a red house on an island" then find that "person lives in a red house" is already precomputed, so it\'s only matter of finding the subset of those who also live on an island.</p>\n\n<p>I can get a cost model by looking at a set of many $Q$ and check to see the size of the corresponding $H_\\text{approx}$. I want to minimize the average size of $H_\\text{approx}$.</p>\n\n<p>The question is, how do I optimize the selection of possible $q_j$ to make this fixed decision tree? I tried a GA but it was slow to converge. Probably because my feature space has a few million possible $q_j$. I\'ve come up with a greedy method, but I\'m not happy with the result. It too is very slow, and I think I\'m optimizing the wrong thing.</p>\n\n<p>What existing research should I be looking at for ideas?</p>\n', 'ViewCount': '98', 'Title': 'Fixed-length decision-tree-like feature selection to minimize average search performance', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-19T09:26:37.540', 'LastEditDate': '2012-11-19T09:26:37.540', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4650', 'Tags': '<algorithms><optimization><machine-learning><greedy-algorithms>', 'CreationDate': '2012-11-19T09:17:01.957', 'Id': '6763'},2079:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p><strong>Facts:</strong> n points in the plane, each has one of k colors, all k colors are represented.</p>\n\n<p><strong>Problem:</strong> You wish to select k points, one of each color, such that the perimeter of the convex hull is as small as possible.</p>\n\n<p><strong>Greedy algorithm:</strong> For each point p, for each color c not equal to p, select the point of color c closest to p. In the end, choose the point set that has a convex hull with the smallest diameter (diameter is the distance between the two points furthest apart.)</p>\n\n<p>Why is the approximation ratio $\\pi/2$?</p>\n\n<p>This was an exercise on my graduate level algorithms exam. We were only given a few lines to answer so it should be simple enough, but I do not know where to start.</p>\n', 'ViewCount': '61', 'Title': 'Show that approximation ratio for a convex hull algorithm is $\\pi/2$', 'LastEditorUserId': '2826', 'LastActivityDate': '2012-12-11T20:16:15.093', 'LastEditDate': '2012-12-11T20:05:41.483', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2826', 'Tags': '<algorithms><approximation><greedy-algorithms>', 'CreationDate': '2012-12-11T19:59:06.100', 'Id': '7333'},20710:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am trying to figure out a greedy algorithm that finds the optimum (minimum) dominating set for any tree in linear time.</p>\n\n<p>So a greedy algorithm to find a dominating set for a general graph is not optimum. It's an approximation of the optimum dominating set. But since this is a tree I am assuming that a greedy algorithm can give the optimum.</p>\n\n<p>What i have so far is:</p>\n\n<p>Select a vertex with the maximum number of adjacent vertices that are not dominated (that is, it's neighbors are either not dominated by one it its neighbors or they are not a dominated vertex themselves). We add this vertex to the dominated set.</p>\n\n<p>We repeat this proceudue until all vertices are either in the dominated set or are neighbors of one of the dominated vertices.</p>\n\n<p>But I am not sure this will give an optimum solution.</p>\n", 'ViewCount': '418', 'Title': 'Greedy Optimum Dominating Set For A Tree', 'LastActivityDate': '2012-12-23T08:11:29.983', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '512', 'Tags': '<graph-theory><greedy-algorithms>', 'CreationDate': '2012-12-17T19:13:27.847', 'Id': '7470'},20711:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<blockquote>\n  <p>Given a set of n jobs with [start time, end time, cost] find a subset so that no 2 jobs overlap and the cost is maximum.</p>\n</blockquote>\n\n<p>Now I'm not sure if a greedy algorithm will do the trick. That is, sort by cost and always take the next job that doesn't intersect and with max cost between the two.</p>\n\n<p>Is this equivalent to a knapsack problem? How could I approach it?</p>\n", 'ViewCount': '407', 'Title': 'Find non-overlapping scheduled jobs with maximum cost', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-16T17:54:04.300', 'LastEditDate': '2013-11-09T15:21:08.183', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7705', 'Tags': '<algorithms><scheduling><greedy-algorithms><knapsack-problems>', 'CreationDate': '2013-04-12T15:24:23.293', 'Id': '11265'},20712:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>How to solve fractional knapsack in linear time? I found this on <a href="https://www.google.com.sg/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CC0QFjAA&amp;url=http://algo2.iti.kit.edu/sanders/courses/algdat03/sol12.pdf&amp;ei=UJt8UZ_tGMHVrQfk1ICQDg&amp;usg=AFQjCNFKeWMLX_Gr2Pu-wS4zzjCT-ESCkg&amp;bvm=bv.45645796,d.bmk&amp;cad=rja" rel="nofollow">Google</a> but don\'t really understand it. </p>\n\n<ol>\n<li>Choose element $r$ at random from $R$ (set of profit/weight ratios)</li>\n<li>Determine\n<ul>\n<li>$R_1 = \\{ p_i / w_i | p_i / w_i &gt; r, for 1 \\leq i \\leq n \\}, W_1 = \\sum_{i \\in R_1} w_i$</li>\n<li>$R_2 = \\{ p_i / w_i | p_i / w_i = r, for 1 \\leq i \\leq n \\}, W_2 = \\sum_{i \\in R_3} w_i$</li>\n<li>$R_3 = \\{ p_i / w_i | p_i / w_i &lt; r, for 1 \\leq i \\leq n \\}, W_3 = \\sum_{i \\in R_3} w_i$</li>\n</ul></li>\n<li>if $W_1 &gt; W$\n<ul>\n<li>recurse $R_1$ and return computed solution</li>\n</ul></li>\n<li>else\n<ul>\n<li>while (there\'s space in knapsack and $R_2$ is not empty)\n<ul>\n<li>add items from $R_2$</li>\n</ul></li>\n<li>if (knapsack gets full)\n<ul>\n<li>return items in $R_1$ and items just added from $R_2$</li>\n</ul></li>\n<li>else \n<ul>\n<li>reduce knapsack capacity by $W_1 + W_2$</li>\n<li>recurse on $R_3$ and return items in $R_1 \\cup R_2$</li>\n<li>add items returned from recursive call </li>\n</ul></li>\n</ul></li>\n</ol>\n\n<p>I don\'t get how it works, what $R$ and $W$ are supposed to represent ... can someone explain? Or maybe if you have another algorithm to propose? </p>\n', 'ViewCount': '605', 'Title': 'Fractional Knapsack in linear time', 'LastEditorUserId': '683', 'LastActivityDate': '2013-04-28T04:43:06.850', 'LastEditDate': '2013-04-28T04:43:06.850', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '3099', 'Tags': '<algorithms><algorithm-analysis><greedy-algorithms>', 'CreationDate': '2013-04-28T04:03:32.447', 'Id': '11620'},20713:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am trying to solve a problem of finding incompatible jobs set using greedy algorithm. However, I am not sure if greedy algorithm can solve this problem or I need to perform another approach.</p>\n\n<p>I have a set of jobs with start and finish time and I want to find the smallest subset of this jobs such that all the jobs are incompatible with at least one job of this subset.</p>\n\n<p>Suppose</p>\n\n<pre><code>job  start   end\n1    1       3\n2    2       11\n3    4       6\n4    7       8\n</code></pre>\n\n<p>My required job set J is {2} since  all the jobs are incompatible with at least one job of the job set J. I tried to use greedy algorithm like sorting jobs by start time, end time ( adding one  and removing all the ones incompatible and so on) But it is not optimal. As you can see in this example. If I add job 1 and then remove all the job incompatible with it, I will remove job 2, Then I will have to add 3 and 4 in the jobset J.</p>\n\n<p>Am I going the right way?</p>\n', 'ViewCount': '200', 'Title': 'Issues with using greedy algorithm (Interval scheduling variant)', 'LastEditorUserId': '8153', 'LastActivityDate': '2013-05-14T22:45:50.280', 'LastEditDate': '2013-05-14T14:31:20.733', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8153', 'Tags': '<algorithms><combinatorics><dynamic-programming><scheduling><greedy-algorithms>', 'CreationDate': '2013-05-14T04:16:16.893', 'Id': '12001'},20714:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am trying to solve a problem of finding compatible jobs set using greedy algorithm. However, I am not sure if greedy algorithm can solve this problem or I need to perform another approach.</p>\n\n<p>I have a set of jobs with start and finish time and I want to find the smallest subset of this jobs such that all the jobs are incompatible with at least one job of this subset. And all the jobs in this subset are compatible</p>\n\n<p>Suppose</p>\n\n<pre><code>job  start   end\n1    1       3\n2    2       11\n3    4       6\n4    12       14\n</code></pre>\n\n<p>My required job set J is {2,4} since  all the jobs are incompatible with at least one job of the job set J. And all the jobs in the job set J are compatible. I tried using earliest deadline first and schedule but it doesn't work. Any suggestions?</p>\n\n<p>Am I going the right way?</p>\n", 'ViewCount': '171', 'Title': 'Solving a variant of interval scheduling problem', 'LastActivityDate': '2013-05-14T12:34:59.047', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8110', 'Tags': '<algorithms><algorithm-analysis><greedy-algorithms>', 'CreationDate': '2013-05-14T12:34:59.047', 'Id': '12018'},20715:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>There is  a greedy algorithm for finding minimum vertex cover of a tree which uses DFS traversal.</p>\n\n<ol>\n<li>For each leaf of the tree, select its parent (i.e. its parent is in minimum vertex cover).</li>\n<li>For each internal node:<br>\nif any of its children is not selected, then select this node.</li>\n</ol>\n\n<p>How do I prove that this greedy strategy gives an optimal answer? That there is no vertex cover smaller in size than the one that the above algorithm produces?</p>\n', 'ViewCount': '1379', 'Title': 'Correctness-Proof of a greedy-algorithm for minimum vertex cover of a tree', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-05-21T18:43:17.647', 'LastEditDate': '2013-05-21T16:09:33.600', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4980', 'Tags': '<algorithms><trees><greedy-algorithms>', 'CreationDate': '2013-05-21T03:52:48.837', 'Id': '12177'},20716:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u"<p>I've developed the following backtrack algorithm, and I'm trying to find out it time complexity.</p>\n\n<p>A set of $K$ integers defines a set of modular distances between all pairs of them. In this\nalgorithm, I considered the inverse problem of reconstructing all integer sets which realize a given distance multiset. i.e. :</p>\n\n<p><br>\nInputs: $D=\\{p_i\u2212p_j \\mod N, i\u2260j \\},K $\n<br>\nOutput : $P=\\{p_1,p_2,...,p_K\\},\\qquad p_i \\in \\{0,1,2,...,N-1\\},\\qquad p_i &gt; p_j $ for $i&gt;j$\n<br></p>\n\n<p>Simply saying, the algorithm puts $K$ blanks to be filled. Initially, puts 1 in the first blank. For the second blank it looks for the first integer that if we add to P, it doesn't produce any difference exceeding the existent differences in $D$. Then, it does so, for next blanks. While filling a blank if it checked all possible integers and found no suitable integer for that blank, it turns back to the previous blank and looks for next suitable integer for it. If all blanks are filled, it has finished his job, otherwise it means that there weren't any possible $P$'s for this $D$.</p>\n\n<p>Here's my analysis so far.\nSince the algorithm checks at most all members of $\\{2,...,N\\}$ for each blank (upper bound) there is $N-1$ search for each blank. If each visited blank was filled in visiting time, the complexity would be $O((K-1)(N-1))$ since we have $K-1$ blank (assuming first one is filled with 1). But the algorithm is more complex since for some blanks it goes backward and some blanks may be visited more that once. I'm looking for the worst case complexity i.e. the case that all blanks are visited and no solution is found.</p>\n", 'ViewCount': '1179', 'Title': 'Time complexity of a backtrack algorithm', 'LastEditorUserId': '9098', 'LastActivityDate': '2013-07-13T23:34:21.333', 'LastEditDate': '2013-07-12T07:56:41.700', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9098', 'Tags': '<algorithms><algorithm-analysis><combinatorics><search-algorithms><greedy-algorithms>', 'CreationDate': '2013-07-09T18:22:51.307', 'FavoriteCount': '2', 'Id': '13181'},20717:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>A typical way of proving the greedy choice property of the fractional knapsack problem is as follows:</p>\n\n<hr>\n\n<p>From Slide 5 of <a href="http://www.cs.kzoo.edu/cs215/lectures/f4-knapsack.pdf" rel="nofollow">this link</a>:</p>\n\n<p>Given: A set of items $I = \\{I_1,I_2..I_n\\}$ with weights $\\{w_1,w_2 ... w_n\\}$ and values $\\{v_1,v_2 ...v_n\\}$. Let $P$ be the problem of selecting items from $I$, with the weight limit $K$ such that the resulting value is maximum.</p>\n\n<p>Let $O = \\{o_1,o_2 ... o_j\\} \\subseteq I$ be the <strong>optimum</strong> solution of problem $P$. </p>\n\n<p>Let\xa0$G = \\{g_1,g_2 ... g_k\\} \\subseteq I$ be\xa0the\xa0greedy\xa0solution,\xa0where\xa0the\xa0 items\xa0are\xa0ordered\xa0according\xa0to the\xa0greedy\xa0choices.\xa0</p>\n\n<p>We\xa0need to\xa0show\xa0that\xa0there\xa0exists\xa0some\xa0optimal\xa0solution\xa0$O\'$\xa0that\xa0includes\xa0the\xa0choice $g_1$\n.</p>\n\n<p>CASE\xa01:\xa0$g_1$\xa0is\xa0non-\xadfractional.</p>\n\n<ol>\n<li>If\xa0$g_1$\xa0is\xa0included\xa0in $O$,\xa0then\xa0we\xa0are\xa0done.</li>\n<li>If\xa0$g_1$\xa0is\xa0not\xa0included\xa0in\xa0$O$,\xa0then\xa0we\xa0arbitrarily\xa0remove\xa0$w_{g_1}$\xa0worth\xa0of\xa0stuff from\xa0$O$\xa0and\xa0replace\xa0it\xa0with\xa0$g_1$\xa0to\xa0produce\xa0$O\'$.</li>\n<li>$O\'$ is\xa0a\xa0solution, and\xa0it\xa0is at\xa0least\xa0as\xa0good as\xa0$O$.</li>\n</ol>\n\n<hr>\n\n<p>In the above proof, step $3$ for CASE 1 merely shows that weight criteria is satisfied. How does it show that $O\'$ is also an optimal solution(i.e. in terms of value achieved), more so when we are "arbitrarily removing $w_{g_1}$ worth of stuff" without paying attention to corresponding change in value ?</p>\n\n<p><strong>UPDATE</strong>: I found the answer in terms of change in value <a href="http://oucsace.cs.ohiou.edu/~razvan/courses/cs4040/lecture15.pdf" rel="nofollow">here</a>. I am not sure if this should go into the answer part. Mods, please suggest.</p>\n', 'ViewCount': '1236', 'Title': 'Proving greedy choice property of fractional knapsack', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-05T20:37:19.433', 'LastEditDate': '2013-08-05T20:37:19.433', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'OwnerDisplayName': 'curryage', 'PostTypeId': '1', 'OwnerUserId': '8660', 'Tags': '<algorithms><algorithm-analysis><correctness-proof><greedy-algorithms>', 'CreationDate': '2013-07-03T00:09:45.020', 'Id': '13575'},20718:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Given a list of pairs $(a_1,b_1),\\ldots,(a_n,b_n)$, where all $a_i \\geq 0$ and all $b_i &gt; 0$, my general problem is when we can use linear subset scan (described below) to solve the optimization problem of finding the optimal combination of pairs,</p>\n\n<p>$$I^* = \\hbox{argmax}_I F(\\sum_{i \\in I} a_i) / G(\\sum_{i \\in I} b_i)$$</p>\n\n<p>where $F,G$ are given increasing positive functions for positive inputs.</p>\n\n<p>I have found a class of functions where there is a fast solution, namely $F(x) = x + A$ and $G(x) = (x + B)^\\beta$ where $A,B \\geq 0$ and $0 \\leq \\beta \\leq 1$.  In this case, the optimal solution can be found by sorting all pairs $(a_i,b_i)$ in decreasing order according to $a_i/b_i$, and then trying the first $k$ pairs in sorted order for all $k$ and choosing the best solution, and this gives the optimal solution.  (This is an example of linear subset scan optimization.)  </p>\n\n<p>Now I want to know, if there a general class of functions $F,G$, ideally defined by abstract properties, where this linear subset scan approach works, where pairs are sorted either according to $a_i/b_i$ or perhaps sorted according to $H(a_i,b_i)$ where $H$ depends on $F,G$?  This could be a question where someone has a new insight and proof, or simply someone has seen something like this in the literature.  At any rate, I feel like the class of $F,G$ I stated where I have a proof is perhaps not the most general possible, and I'm missing some key abstract property that makes the linear subset scan work.   </p>\n", 'ViewCount': '98', 'Title': 'Generalizing the linear subset scan algorithm to a wider class of objective functions, maybe by finding a paper', 'LastActivityDate': '2014-04-06T23:59:48.870', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<algorithms><optimization><greedy-algorithms>', 'CreationDate': '2013-08-08T23:01:49.873', 'Id': '13680'},20719:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have been studying about <a href="http://en.wikipedia.org/wiki/Activity_selection_problem" rel="nofollow">activity-selection-problem</a> and the solution of greedy choice I came across is to select the activity that finishes in the earliest among the present activities.</p>\n\n<p>But surely there are other greedy choices to solve the problem. The one I have been able to figure out is to select the activity that starts last.</p>\n\n<p>My question is: are there any other greedy choices that can lead to solve activity selection problem? Any formal proof is also appreciated.</p>\n', 'ViewCount': '118', 'Title': 'Other greedy choices to solve activity selection problem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-16T07:59:27.903', 'LastEditDate': '2013-09-16T07:59:27.903', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6699', 'Tags': '<algorithms><optimization><greedy-algorithms>', 'CreationDate': '2013-09-15T03:55:05.647', 'Id': '14316'},20720:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>This is an exercise in the book Introduction to Algorithm, 3rd Edition.</p>\n\n<p>The original question is:</p>\n\n<p>Show how to implement GREEDY-SET-COVER in such a way that it runs in time $O(\\sum_{S\\in\\mathcal{F}}|S|)$.</p>\n\n<p>The GREEDY-SET-COVER in the text book is as follows:</p>\n\n<p><img src="http://i.stack.imgur.com/v55Gn.png" alt="greedy-set-cover-in-text-book"></p>\n\n<p>Definition for $(X,\\mathcal{F})$ is given as:</p>\n\n<p><img src="http://i.stack.imgur.com/3aVbz.png" alt="enter image description here"></p>\n', 'ViewCount': '397', 'ClosedDate': '2013-10-30T10:05:07.743', 'Title': 'How to implement GREEDY-SET-COVER in a way that it runs in linear time', 'LastActivityDate': '2013-10-16T18:49:41.563', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '4662', 'Tags': '<algorithms><algorithm-analysis><time-complexity><greedy-algorithms>', 'CreationDate': '2013-10-16T17:15:40.530', 'Id': '16142'},20721:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>How to minimize the sum of difference of element in sub-sequence of array of length k from given sequence of length n ?</p>\n\n<p>for example : for n=10\n1\n2\n3\n4\n10\n20\n30\n40\n100\n200</p>\n\n<p>the sub-sequence of length will with minimized sum of difference will be\n1 2 3 4\nas  |1-2| + |1-3| + |1-4| + |2-3| + |2-4| + |3-4| = 10 i.e minimum in any sequence.</p>\n', 'ViewCount': '181', 'Title': 'How to minimize the sum of difference of element in sub-sequence of array of length k from given sequence of length n', 'LastActivityDate': '2013-10-20T19:17:17.783', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '10851', 'Tags': '<algorithms><dynamic-programming><linear-programming><greedy-algorithms><constraint-programming>', 'CreationDate': '2013-10-19T08:38:14.163', 'Id': '16224'},20722:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Consider the following problem:</p>\n\n<p>There are $n$ points in the plane.\nStarting from one of them I want to visit each of them once (except the starting node which has to be visited twice) but in a way that minimizes the cost of the total path.</p>\n\n<p>The weight of each edge changes depending on the path followed.\nFor example imagine $n=3$: $A$, $B$, $C$ and we start at $A$. \nThe weight of the edge $xy$ is $Sd_{xy}$, where $d_{xy}$ is the distance between the points $x$ and $y$ and $S$ is a given constant)\nIf I pick the edge $A\\to B$, the weight of the edge $B\\to A$ is now\n$(S-s_B)d_{AB}$ because $B$ changes $S$ by a constant amount $s_B$. \nSimilarly if I pick the edge $A\\to C$, the weight of the edge $B\\to C$ is now\n$(S-s_C)d_{AC}$ because visiting $C$ changes $S$ by a constant amount $s_C$. </p>\n\n<p>Developing the $n=3$ case, imagine S=11, $d_{AB}=5,d_{AC}=3,d_{BC}=4$ and $s_{A}=2,s_{B}=5,s_{C}=4$.\nThen there are 4 possible paths:</p>\n\n<p>A->B->C->A with cost $11*5+(11-5)*4+(11-5-4)*3$</p>\n\n<p>(we stop once we reach A because 11-5-4-2=0)</p>\n\n<p>A->B->A->C with cost $11*5+(11-5)*5+(11-4-2)*3$</p>\n\n<p>A->C->B->A with cost $11*3+(11-4)*4+(11-4-5)*5$</p>\n\n<p>A->C->A->B with cost $11*3+(11-4)*3+(11-4-2)*5$</p>\n\n<p>For $n=4$ there will be 3*3!=18 possible paths and so on.</p>\n\n<p>I know that $s_A+s_B+s_C=S$. This generalizes for $n$ points.\n What is an efficient algorithm for finding the minimum cost path?</p>\n', 'ViewCount': '186', 'Title': 'minimum cost path', 'LastEditorUserId': '10946', 'LastActivityDate': '2013-10-25T20:37:02.393', 'LastEditDate': '2013-10-25T20:37:02.393', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10946', 'Tags': '<dynamic-programming><greedy-algorithms>', 'CreationDate': '2013-10-24T01:54:35.210', 'FavoriteCount': '1', 'Id': '16391'},20723:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Here is a variation of a job-scheduling Problem.\nLet $J = \\{j_1,...j_n\\}$ be a set of Jobs for $1 \\leq i \\leq n$. Given Job length $|j_i|\\in \\mathbb{N}$, deadline $f_i \\in \\mathbb{N}$, profit $p_i \\ge 0$ and starting-time $s_i  \\in \\mathbb{N}$. I am looking for a greedy approximation factor given that the Job length may only be distinguished by factor k. </p>\n\n<p>$$max_i|j_i| \\leq k \\cdot min_i|j_i|$$</p>\n\n<p>The Greedy algorithm of this Problem is fairly stupid. Greedy takes a job with the biggest profit.  I created an example (3-Job-Scheduling):</p>\n\n<p>Let $J = \\{j_1,j_2,j_3\\}$ with $|j_1| = 2, j_2 = j_3 = 1$ and </p>\n\n<p>$s_1 = 0; s_2 = 0; s_3 = 1$,</p>\n\n<p>$f_1 = 2;f_2 = 1; f_3 = 2$</p>\n\n<p>$p_1 = w; p_2 = p_3 = (w-1)$</p>\n\n<p>What I want to show is that Greedy gives us w while 2(w-1) is the optimal solution. </p>\n\n<p>My question: Is this valid for n-Job-Scheduling (the general case). Is this the worst-case? </p>\n\n<p>I can't think of anything worse. So I figured since the problem is a k-Matroid (is this a common term?) there will be a an approximation factor $\\frac{1}{k-\\epsilon}$ for  any $\\epsilon &gt; 0.$ I know this is not exactly a proof yet, but am I on the right way?</p>\n\n<p>Thanks for your help!</p>\n", 'ViewCount': '118', 'Title': 'Single machine job scheduling (Greedy heuristic)', 'LastActivityDate': '2013-11-08T13:06:23.300', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10940', 'Tags': '<approximation><scheduling><greedy-algorithms><check-my-proof>', 'CreationDate': '2013-11-08T13:06:23.300', 'Id': '16821'},20724:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u"<p>Below is a homework problem where we have been asked to alter a greedy algorithm to return n element instance of a set problem. The original algorithm is also below. I was thinking that I could alter line 3 so that it would run until the size of C was equal to n, and change the logic in line 4 so that it would pick and remove vertices until the size of n. A vertex would be removed when the size of C doesn't equal to n but the cover is complete. I can't really think of any other way to do it. The real problem is that I'm not entirely sure how to make the algorithm run in exponential time like they are asking. </p>\n\n<blockquote>\n  <p>GREEDY-SET-COVER can return a number of different solutions, depending on\n  how we break ties in line 4. Give a procedure BAD-SET-COVER-INSTANCE.n/\n  that returns an n-element instance of the set-covering problem for which, depending\n  on how we break ties in line 4, GREEDY-SET-COVER can return a number of\n  different solutions that is exponential in n.</p>\n  \n  <p>$X$ \u2014 some finite set<br>\n  $F$ \u2014 a family of subsets of $X$<br>\n  $C$ \u2014 cover being constructed    </p>\n  \n  <p>GREEDY-SET-COVER($n$)<br>\n  1    let $U = X$<br>\n  2    let $C = \\varnothing$<br>\n  3    while $U \\ne \\varnothing$<br>\n  3a            select an $S \\in F$ that maximizes $\\left|S \\cap U\\right|$<br>\n  3b            set $U = U \\setminus S$<br>\n  3c            set $C = C \\cup \\{S\\}$<br>\n  4    return $C$   </p>\n</blockquote>\n\n<p>Could it be said that since the number of subsets a set has is $2^n$ and that in the worst case this algorithm will end up finding all of those subsets before settling on an n-instance set to return?</p>\n", 'ViewCount': '112', 'Title': 'Finding an instance of an n-element set cover', 'LastEditorUserId': '39', 'LastActivityDate': '2013-11-28T21:30:30.133', 'LastEditDate': '2013-11-28T21:30:30.133', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11580', 'Tags': '<algorithms><algorithm-analysis><greedy-algorithms><set-cover><approximation-algorithms>', 'CreationDate': '2013-11-23T23:48:31.680', 'Id': '18287'},20725:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'ve got 30 elements which has to be  grouped/sorted into 10 ordered 3-tuple. \nThere are several rules and constraints about grouping/sorting.\nFor example: Element $A$ must not be in the same tuple same unit $B$. \nElement $C$ must not be right in front of element $A$, etc.</p>\n\n<p>I am searching for an approximated algorithm:</p>\n\n<ol>\n<li>We don\'t need to achieve the exact optimum </li>\n<li>It is OK for some rules not to be satisfied, if it helps to fulfill more rules.</li>\n</ol>\n\n<p>Do you know of any algorithm/proceeding that solve this problem or a similar one?\nI fear to solve it in an optimal way, you have to try out every possible solution-> $2 ^ {30}$</p>\n\n<p><strong>EDIT</strong>: Sorry for the bad explanation. I am trying to make it a bit clearer:\nI got 30 elements for example: $\\{1,2,3,\\ldots,30\\}$.\nI need to group them into 3-tuples so that i get something like: $(1,2,3)$, $(4,5,6)$,$\\ldots$,$(28,29,30)$.</p>\n\n<p>There are several constraints. For example: </p>\n\n<ul>\n<li>1 cannot precede 2 in an ordered tuple, so, for instance  $(1,2,3)$ is not a valid tuple.</li>\n<li>5 must be together with 4. </li>\n</ul>\n\n<p>Those constraints can be broken and its possible that there is no solution where all rules can be fulfilled. <br />An solution is considered as good if the amount of rules broken is "low".</p>\n\n<p>Hope that makes it clearer and thanks for the help so far.</p>\n', 'ViewCount': '81', 'Title': 'Algorithm for sorting with constraints', 'LastEditorUserId': '157', 'LastActivityDate': '2013-12-16T01:48:30.027', 'LastEditDate': '2013-12-16T00:37:15.273', 'AnswerCount': '2', 'CommentCount': '5', 'AcceptedAnswerId': '18345', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '11601', 'Tags': '<algorithms><sorting><randomized-algorithms><greedy-algorithms>', 'CreationDate': '2013-11-25T00:14:58.160', 'Id': '18312'},20726:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Is there any example that anybody could come up  with that shows Prim's algorithm does not always give the correct result when it comes knowing the minimal spanning tree.</p>\n", 'ViewCount': '137', 'Title': "Minimal Spanning tree and Prim's Algorithm", 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-05T17:28:24.357', 'LastEditDate': '2014-01-05T17:28:24.357', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '19309', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '7269', 'Tags': '<algorithms><greedy-algorithms><spanning-trees>', 'CreationDate': '2013-12-26T17:49:25.153', 'Id': '19306'},20727:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>what is the reason for the correctness proof of Prim's Algorithm for the undirected case cannot carry over to the directed case?</p>\n\n<p>Is it because of after any number of steps, $S$ might not be in a sub tree of an MST since it depends upon the direction of the edge of the directed graph, unlike the undirected one?</p>\n", 'ViewCount': '111', 'ClosedDate': '2014-01-05T17:29:58.513', 'Title': "Proof of Correctness of Prim's algorithm", 'LastEditorUserId': '7269', 'LastActivityDate': '2013-12-31T16:22:53.543', 'LastEditDate': '2013-12-31T13:52:39.337', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '7269', 'Tags': '<graph-theory><correctness-proof><greedy-algorithms><spanning-trees>', 'CreationDate': '2013-12-31T12:55:44.063', 'Id': '19405'},20728:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>The GSAT (Greedy Satisfiability) algorithm can be used to find a solution to a search problem encoded in CNF. I\'m aware that since GSAT is greedy, it is incomplete (which means there would be cases where a solution might exist, but GSAT cannot find it). From the following link, I learned that this can happen when flipping variables greedily traps us in a cycle such as I \u2192 I\' \u2192 I\'\' \u2192 I. </p>\n\n<p><a href="http://www.dis.uniroma1.it/~liberato/ar/incomplete/incomplete.html" rel="nofollow">http://www.dis.uniroma1.it/~liberato/ar/incomplete/incomplete.html</a></p>\n\n<p>I\'ve been trying quite hard to come up with an actual instance that can show this, but have not been able to (and could not find examples elsewhere). Any help would be much appreciated. Thanks :)</p>\n\n<p>P.S. I\'m not talking about "hard" k-SAT problems in which the ratio of variables to clauses approaches 4.3. I\'m just looking for a simple example, possibly involving the least number of variables and/or clauses required.</p>\n', 'ViewCount': '76', 'Title': 'GSAT incompleteness example', 'LastActivityDate': '2014-02-27T05:59:46.950', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15094', 'Tags': '<algorithms><satisfiability><greedy-algorithms><3-sat>', 'CreationDate': '2014-02-27T05:07:36.670', 'Id': '22079'},20729:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>There is a shop which consists of N items and there are M buyers. Each buyer wants to buy a specific set of items. However, the cost of all transactions is same irrespective of the number of items sold. So, the shopkeeper needs to maximize the number of buyers. The buyers will buy only if all the items are being sold. Items are unique. All items need not be sold.</p>\n\n<p>So, basically, we have a bipartite graph. We need to find a set of edges which maximize the number of nodes on Buyer vertex set such that each node on item set has only one edge. Any suggestions?</p>\n', 'ViewCount': '28', 'Title': 'How to maximize the number of buyers in a shop?', 'LastActivityDate': '2014-03-08T15:42:28.667', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15420', 'Tags': '<graph-theory><greedy-algorithms><bipartite-matching>', 'CreationDate': '2014-03-08T15:42:28.667', 'Id': '22399'},20730:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>We have a 0-1 knapsack in which the increasing order of items by weight is the same as the decreasing order of items by value. Design a greedy algorithm and prove that the greedy choice guarantees an optimal solution.</p>\n\n<p>Given the two orders I imagined that we could just choose the first k elements from either sequence and use them to fill knapsack until it was full. This would be similar to choosing the items with the greatest ratio of value to weight. But I don't think that is an optimal solution. </p>\n\n<p>So what I need help with is whether or not this solution is optimal. And how would I prove the correctness of a greedy algorithm. </p>\n", 'ViewCount': '63', 'Title': 'Correctness proof of greedy algorithm for 0-1 knapsack problem', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-26T16:45:47.887', 'LastEditDate': '2014-03-26T08:38:55.053', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '23060', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15512', 'Tags': '<algorithms><algorithm-analysis><correctness-proof><greedy-algorithms><knapsack-problems>', 'CreationDate': '2014-03-26T03:23:03.477', 'Id': '23058'},20731:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have two <code>True or False</code> questions in my practice test that are related but I am unsure about:</p>\n\n<pre><code>1. If an optimization problem can be solved using a greedy algorithm, \nthere must be a solution for this optimization problem using dynamic programming as well.\n\n2. If an optimization problem can be solved using dynamic programming, \nthere must be a solution for this problem using a greedy algorithm as well.\n</code></pre>\n\n<p>I think the answers are <code>1. True</code> and <code>2. False</code> is this correct?</p>\n', 'ViewCount': '96', 'ClosedDate': '2014-04-14T17:37:38.693', 'Title': 'Dynamic programming VS Greedy Algroithms', 'LastActivityDate': '2014-04-07T02:28:55.033', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '23495', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16514', 'Tags': '<algorithms><dynamic-programming><greedy-algorithms>', 'CreationDate': '2014-04-07T01:29:57.837', 'Id': '23493'},20732:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>So here is the challenge problem statement: <a href="https://icpcarchive.ecs.baylor.edu/index.php?option=com_onlinejudge&amp;Itemid=8&amp;page=show_problem&amp;problem=1512" rel="nofollow">https://icpcarchive.ecs.baylor.edu/index.php?option=com_onlinejudge&amp;Itemid=8&amp;page=show_problem&amp;problem=1512</a> </p>\n\n<p>Basically, given a 0/1 matrix, you need to permute the columns so that the first column is fixed and after the permutation of columns, then for each row the 1\'s in the row occur contiguously (without counting wrap-around). I thought about this problem and came up with a conjecture that would make it easy to solve, but I\'m not sure if it\'s true.</p>\n\n<p>Conjecture: After the first $k$ columns have been chosen, let $S$ be the set of rows that end with a $1$ in the $k$th column, such that there exists an unchosen column that has a $1$ in that row. Then the $k+1$th column can be chosen to be the column that has (i) 1\'s for all positions in $S$, and (ii) which has a minimum total number of $1$\'s.</p>\n\n<p>Is this true? If so an optimal solution could be constructed very quickly. I know that the $k+1$th column has to satisfy condition (i), which reduces the possibilities, but I\'m really hoping we can ensure condition (ii) also holds so that the choice of $k+1$th column is essentially unique.</p>\n', 'ViewCount': '26', 'Title': 'Conjecture about a matrix column swapping challenge problem', 'LastEditorUserId': '9584', 'LastActivityDate': '2014-04-21T18:53:34.960', 'LastEditDate': '2014-04-21T18:53:34.960', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<algorithms><correctness-proof><greedy-algorithms><permutations>', 'CreationDate': '2014-04-21T17:15:13.210', 'Id': '23997'}