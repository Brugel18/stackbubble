{'Body': '<p>A recent exam question went as follows:</p>\n\n<blockquote>\n  <ol>\n  <li>$A$ is an infinite recursively enumerable set. Prove that $A$ has an infinite recursive subset.</li>\n  <li>Let $C$ be an infinite recursive subset of $A$. Must $C$ have a subset that is <em>not</em> recursively enumerable?</li>\n  </ol>\n</blockquote>\n\n<p>I answered 1. already. Regarding 2., I answered affirmatively and argued as follows. </p>\n\n<p>Suppose that all the subsets of $C$ were recursively enumerable. Since $C$ is infinite, the power set of $C$ is uncountable, so by assumption there would be uncountably many recursively enumerable sets. But the recursively enumerable sets are in one-to-one correspondence with the Turing machines that recognize them, and Turing machines are enumerable. Contradiction. So $C$ must have a subset that is not recursively enumerable.</p>\n\n<p>Is this correct?</p>\n', 'ViewCount': '625', 'Title': 'subsets of infinite recursive sets', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-14T15:08:27.217', 'LastEditDate': '2012-05-14T15:08:27.217', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '1435', 'Tags': '<computability><check-my-proof>', 'CreationDate': '2012-05-11T03:35:27.040', 'FavoriteCount': '1', 'Id': '1790'}{'Body': '<p>I need to prove that $\\mathsf{NP}$ is a subset of the union of $\\mathsf{DTIME}(2^{n^c})$ for all $c &gt; 1$.</p>\n\n<p>Let $L$ be a language/decision problem in $\\mathsf{NP}$. Then $L$ can be decided given a polynomial-size certificate in polynomial time with a turing machine $M$. So then we enumerate all possible certificates of polynomial size. There are $2^l$ possible certificates for a certificate of length $l$. For a certificate of length up to $n^c$, there are $\\sum_{l=0}^{n^c} 2^l = 2^{n^c + 1} - 1$ many certificates. Each certificate can be decided in polynomial time, so we get that each problem in $\\mathsf{NP}$ can be done in $\\mathsf{DTIME}(2^{n^c}n^c)$. What am I doing wrong?</p>\n', 'ViewCount': '164', 'Title': 'Proving NP is a subset of the union of exponential DTIME', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-29T15:20:18.607', 'LastEditDate': '2012-05-29T07:52:22.427', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1682', 'Tags': '<complexity-theory><check-my-proof>', 'CreationDate': '2012-05-29T06:08:59.757', 'FavoriteCount': '1', 'Id': '2151'}{'Body': "<p>$L=\\{&lt;\\!M,x\\!&gt;\\, \\mid M's \\text{ transition function can only move right and   } M\\text{ halts on } x \\}$. I need to show that $L$ is recursive/decidable.</p>\n\n<p>I thought of checking the encoding of $M$ first and determine whether its transition function moves only right (Can I do that?). If so then try to simulate $M$ on $x$ for $|Q|+1$ steps, if it stops then $&lt;\\!M,x\\!&gt;\\, \\in L$ otherwise it is not.</p>\n\n<p>Is this correct?</p>\n", 'ViewCount': '237', 'Title': 'Show that the halting problem is decidable for one-pass Turing machines', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-18T09:58:30.713', 'LastEditDate': '2012-06-03T15:42:33.780', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '2213', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1589', 'Tags': '<formal-languages><computability><turing-machines><check-my-proof>', 'CreationDate': '2012-06-03T14:32:39.493', 'Id': '2212'}{'Body': '<p>I have to proof that if $L_1 \\subset L_2$ and $L_1$ is not regular then $L_2$ it not regular. This is my proof. Is it valid? </p>\n\n<p>Since $L_1$ is not regular, there does not exists a finite automata $M_1$ such that $L_1$ is the language of $M_1$. Pick $x\\in L_1$. So $x \\in L_2$ and suppose that $L_2$ is regular. Then there exists a finite automata $M_2$ such that $L_2$ is the language of $M_2$. Since $x \\in L_2$ and $L_2$ is regular, there exists a state $s\\in S$ such that from the initial state in $M_2$ there is a path $x$ to this final state $s$. Since this holds for all $x \\in L_1$, we can construct a finite automata which language is $L_1$, so $L_1$ is regular, so we reached a contradiction, so $L_2$ is not regular.</p>\n\n<p>Can this be done easier?</p>\n', 'ViewCount': '463', 'Title': 'Are supersets of non-regular languages also non-regular?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-29T12:06:06.380', 'LastEditDate': '2012-06-28T16:53:23.070', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1998', 'Tags': '<formal-languages><regular-languages><automata><finite-automata><check-my-proof>', 'CreationDate': '2012-06-28T16:24:12.253', 'Id': '2528'}{'ViewCount': '361', 'Title': 'Is Karp Reduction identical to Levin Reduction', 'LastEditDate': '2012-07-17T16:29:13.687', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2121', 'FavoriteCount': '2', 'Body': "<h3>Definition: Karp Reduction</h3>\n\n<p>A language $A$ is Karp reducible to a language $B$ if there is a polynomial-time computable function $f:\\{0,1\\}^*\\rightarrow\\{0,1\\}^*$ such that for every $x$, $x\\in A$ if and only if $f(x)\\in B$.</p>\n\n<h3>Definition: Levin Reduction</h3>\n\n<p>A search problem $V_A$ is Levin reducible to a search problem $V_B$ if there is polynomial time function $f$ that Karp reduces $L(V_A)$ to $L(V_B)$ and there are polynomial-time computable functions $g$ and $h$ such that</p>\n\n<ol>\n<li><p>$\\langle x, y \\rangle \\in V_A \\implies \\langle f(x), g(x,y) \\rangle \\in V_B$,</p></li>\n<li><p>$\\langle f(x), z \\rangle \\in V_B \\implies \\langle x, h(x,z) \\rangle \\in V_A$</p></li>\n</ol>\n\n<p>Are these reductions equivalent?</p>\n\n<hr>\n\n<p>I think the two definitions are equivalent. For any two $\\mathsf{NP}$ languages $A$ and $B$, if $A$ is Karp reducible to $B$, then $A$ is Levin reducible to $B$. </p>\n\n<p>Here is my proof:</p>\n\n<p>Let $x$ and $\\overline{x}$ be arbitrary instances of $A$ while $x'$ be that of $B$. \nSuppose $V_A$ and $V_B$ are verifiers of $A$ and $B$. \nLet $y$ and $\\overline{y}$ be arbitrary certificates of $x$ and $\\overline{x}$ according to $V_A$. \nLet $z$ be that of $x'$ according to $V_B$. </p>\n\n<p>Construct new verifiers $V'_A$ and $V'_B$ with new certificates $y'$ and $z'$:</p>\n\n<p>$V'_A(x,y'):$</p>\n\n<ol>\n<li>$y'=\\langle 0,\\overline{x},\\overline{y}\\rangle$: If $f(x)\\ne f(\\overline{x})$, reject. \nOtherwise output $V_A(\\overline{x},\\overline{y})$.</li>\n<li>$y'=\\langle 1,z\\rangle$: Output $V_B(f(x),z)$.</li>\n</ol>\n\n<p>$V'_B(x',z'):$</p>\n\n<ol>\n<li><p>$z'=\\langle 0,z\\rangle$: Output $V_B(x',z)$.</p></li>\n<li><p>$z'=\\langle 1,x,y\\rangle$: If $x'\\ne f(x)$, reject. \nOtherwise output $V_A(x,y)$.</p></li>\n</ol>\n\n<p>The polynomial-time computable functions $g$ and $h$ are defined as below:</p>\n\n<p>$g(x,y')$</p>\n\n<ol>\n<li><p>$y'=\\langle 0,\\overline{x},\\overline{y}\\rangle$: Output $\\langle 1,\\overline{x},\\overline{y}\\rangle$.</p></li>\n<li><p>$y'=\\langle 1,z\\rangle$: Output $\\langle 0,z\\rangle$.</p></li>\n</ol>\n\n<p>$h(x',z')$</p>\n\n<ol>\n<li><p>$z'=\\langle 0,z\\rangle$: Output $\\langle 1,z\\rangle$.</p></li>\n<li><p>$z'=\\langle 1,x,y\\rangle$: Output $\\langle 0,x,y\\rangle$.</p></li>\n</ol>\n\n<p>Let $Y_x$ be the set of all certificates of $x$ according to $V_A$ and $Z_{x'}$ be the set of all certificates of $x'$ according to $V_B$. \nThen the set of all certificates of $x$ according to $V'_A$ is $0\\overline{x}Y_\\overline{x}+1Z_{f(x)}$ such that $f(x)=f(\\overline{x})$, \nand the set of all certificates of $x'$ according to $V'_B$ is $0Z_{x'}+1\\overline{x}Y_\\overline{x}$ such that $x'=f(\\overline{x})$. </p>\n\n<p>(This is derived from the accepting language of $V'_A$ and $V'_B$.) </p>\n\n<p>Now let $x'=f(x)$, the rest part is easy to check.</p>\n", 'Tags': '<complexity-theory><reductions><check-my-proof>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-17T16:29:13.687', 'CommentCount': '1', 'AcceptedAnswerId': '2702', 'CreationDate': '2012-07-11T06:25:12.317', 'Id': '2689'}{'Body': '<p>I am currently working my way through <a href="http://aofa.cs.princeton.edu/home/" rel="nofollow">An Introduction to Analysis of Algorithms</a> to stay sharp with recurrences as well as learn generating function techniques. However my analyses and the books analyses for the first few sample problems on ordinary generating functions differ. I\'ve checked and rechecked [my work as well as errata on the webpage], but cannot see how the authors made certain leaps. For example:</p>\n\n<p>Given the recurrence $a_{n} = a_{n-1} + 1$ for $n \\geq 1$ with $a_0 = 0$ and letting $A(z) = \\sum_{n \\geq 0} a_n z^n$ I have the following steps:\n$$ \\begin{align*}\n\\sum_{n \\geq 1} a_n z^n &amp;= \\sum_{n \\geq 1} a_{n-1} z^n + \\sum_{n \\geq 1} z^n \\\\\nA(z) - a_0&amp;= zA(z) + \\frac{z}{1-z} \\\\\nA(z)(1 - z) &amp;= \\frac{z}{1-z} + a_0\\\\\nA(z) &amp;=\\frac{z}{(1-z)^2} + \\frac{a_0}{1-z}\n\\end{align*}$$</p>\n\n<p>Since $a_0 = 0$ we just end up with $$A(z) = \\frac{z}{(1-z)^2} \\\\ a_n = n$$.</p>\n\n<p>However, the authors\' derivation is the following:\n$$ \\begin{align*}\n\\sum_{n \\geq 1} a_n z^n &amp;= \\sum_{n \\geq 1} a_{n-1} z^n + \\frac{1}{1-z} \\\\\nA(z) - 1 &amp;= zA(z) + \\frac{1}{1-z} \\\\\nA(z) &amp;= \\frac{z}{(1-z)^2} \\\\\na_n &amp;= n\\\\\n\\end{align*}$$\nAm I crazy, how did they get $A(z) - 1$ in the 2nd step? They do the exact same thing in the next example for $a_n = 2a_{n-1} + 1$. Is this just a typo? I would expect them to subtract $a_0z^0 = a_0$. Where did that $-1$ come from?</p>\n', 'ViewCount': '100', 'Title': 'Error in Generating Function Solution', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-30T22:19:21.597', 'LastEditDate': '2012-08-29T00:18:51.577', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '3376', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '19', 'Tags': '<recurrence-relation><mathematical-analysis><check-my-proof>', 'CreationDate': '2012-08-28T20:47:04.473', 'Id': '3355'}{'Body': "<p>I'm trying to prove the following lemma:</p>\n\n<p>$c$ is a positive real number and $f, g$ are functions from natural numbers to non-negative real numbers. I'm trying to prove rigorously that:</p>\n\n<p>$\\Omega(cf(n))$ = $\\Omega(f(n))$.</p>\n\n<p>I know that it is obvious but I'm trying to construct a proof that is as complete as possible. My current approach is like this:</p>\n\n<p>This lemma is equivalent to saying that: $f(n) \\in \\Omega(cf(n))$ iff $cf(n) \\in \\Omega(f(n))$.</p>\n\n<p>We can also restate that as:</p>\n\n<ol>\n<li>If $t(n) \\in \\Omega(cf(n))$ then $t(n) \\in \\Omega(f(n))$.</li>\n<li>If $t(n) \\in \\Omega(f(n))$ then $t(n) \\in \\Omega(cf(n))$.</li>\n</ol>\n\n<p>For 1.,</p>\n\n<p>$(*)$ $\\exists d_1, d_2 \\gt 0, \\forall n \\gt n_0, n_1, \\forall n \\in N$:</p>\n\n<p>$t(n) \\ge d_1cf(n)$ and $t(n) \\ge d_2f(n)$</p>\n\n<p>Now let's fix $d_1, d_2$ and $n_0, n_1$ to be any constants that fulfils $(*)$, such that:\n$n'=max\\{n_0, n_1\\}$ and $d_1c \\ge d_2$, using this we can say that:</p>\n\n<p>$t(n) \\ge d_1cf(n) \\ge d_2f(n)$ and hence the 1. is satisfied because $t(n) \\in \\Omega(cf(n)), \\Omega(f(n))$. The proof of 2. is mutatis mutandis.</p>\n\n<p>Do I have a mistake in my proof, is there a better/more elegant way to prove this lemma? Shortly how can I improve this?</p>\n", 'ViewCount': '141', 'Title': 'Proving $\\Omega(cf) = \\Omega(f)$', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-03T11:34:57.393', 'LastEditDate': '2012-10-02T17:45:39.213', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2956', 'Tags': '<asymptotics><proof-techniques><check-my-proof>', 'CreationDate': '2012-10-02T12:45:11.833', 'Id': '4840'}{'Body': '<p>Here is my proof, but I am not sure whether it is correct.</p>\n\n<p>We know:</p>\n\n<p>$\\qquad \\begin{array}{l}\n \\forall {c_1},\\exists {n_1},0 \\le f\\left( n \\right) \\le {c_1}g\\left( n \\right),\\forall n \\ge {n_1} \\\\ \n \\forall {c_1},\\exists {n_2},0 \\le g\\left( n \\right) \\le {c_1}h\\left( n \\right),\\forall n \\ge {n_2} \\\\ \n \\end{array}$</p>\n\n<p>Hope to prove:</p>\n\n<p>$\\qquad \\begin{array}{l}\n \\forall c,\\exists {n_0},0 \\le f\\left( n \\right) \\le ch\\left( n \\right),\\forall n \\ge {n_0} \\\\ \n  \\Rightarrow 0 \\le f\\left( n \\right) \\le {c_1}g\\left( n \\right) \\le {c_1}\\left( {{c_1}h\\left( n \\right)} \\right),\\forall n \\ge \\max \\left\\{ {{n_1},{n_2}} \\right\\} \\\\ \n \\end{array}$</p>\n\n<p>Let $c = {c_1}^2$. Then,</p>\n\n<p>$\\qquad 0 \\le f\\left( n \\right) \\le {c^2}h\\left( n \\right),\\forall n \\ge {n_0} = \\max \\left\\{ {{n_1},{n_2}} \\right\\}$</p>\n\n<p>Is there any mistake?</p>\n', 'ViewCount': '240', 'Title': 'How to prove transitivity in small-o of asymptotic analysis?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-28T11:12:16.707', 'LastEditDate': '2012-10-28T11:12:16.707', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '240', 'Tags': '<asymptotics><check-my-proof>', 'CreationDate': '2012-10-21T03:41:43.880', 'Id': '6207'}{'Body': "<p>Let's start with the comparison sorting lower bound proof, which I'll summarize as follows:</p>\n\n<ol>\n<li>For $n$ distinct numbers, there are $n!$ possible orderings.</li>\n<li>There is only one correct sorted sequence of the $n$ numbers.</li>\n<li>We are given that comparison ($&lt;$) is the only operation we have that can narrow down the $n!$ possible orderings, and each comparison has only two possible outcomes.</li>\n<li>So $\\log_2(n!)$ comparisons are required.</li>\n</ol>\n\n<p>Now consider the following generalization of the argument above:</p>\n\n<ol>\n<li>Define a space of possibilities and its size (in the case of sorting, $n!$ orderings)</li>\n<li>Define the goal state and its size (in this case, only one correctly sorted answer)</li>\n<li>Define the amount of information that is gained at each step of the computation (in this case, one bit since there are only two possible outcomes per comparison)</li>\n<li>Calculate the information difference between the space of possibilities (step 1) and the goal space (step 2) and divide by the information gain per step (step 3) to yield the lower bound on the number of steps (in this case, $(\\log_2(n!)$ - $\\log_2(1))$ / 1 = $\\log_2(n!)$).</li>\n</ol>\n\n<p>Please answer all the following questions. I'm less concerned with the correctness of the particulars of step 4 than I am with the correctness of steps 1 - 3.</p>\n\n<ol>\n<li>Are there any problems with the generalized argument?</li>\n<li>If the problems can be fixed, what are the fixes?</li>\n<li>If the problems can't be fixed, please point out the fatal ones and provide directions to sources which describe these lower-bounds proofs and their pitfalls.</li>\n</ol>\n", 'ViewCount': '274', 'Title': 'Generalizing the Comparison Sorting Lower Bound Proof', 'LastEditorUserId': '19', 'LastActivityDate': '2012-12-23T05:23:41.497', 'LastEditDate': '2012-11-08T16:36:29.557', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1295', 'Tags': '<proof-techniques><sorting><information-theory><check-my-proof><lower-bounds>', 'CreationDate': '2012-11-08T15:48:38.323', 'FavoriteCount': '1', 'Id': '6562'}{'Body': '<p>As this thread title gives away I need to prove $x^y$ to be a primitive recursive function. </p>\n\n<p>So mathematically speaking, I think the following are the recursion equations, well aware that I am assigning to $0^0$ the value $1$, which shouldn\'t be, since it is an "indeterminate" form.</p>\n\n<p>\\begin{cases}\n  x^0=1 \\\\\n  x^{n+1} = x^n\\cdot x\n\\end{cases}</p>\n\n<p>More formally I would write:\n\\begin{cases}\n  h(0) = 1 \\\\\n  h(x,y+1) = g(y,h(x,x),x)\n\\end{cases}</p>\n\n<p>as $g(x_1, x_2, x_3) = h\\left(u^3_2(x_1, x_2, x_3),u^3_3(x_1, x_2, x_3)\\right)$ and provided $h(x,y) = x \\cdot y$ is primitive recursive.</p>\n\n<p>Is my proof acceptable? Am I correct, am I missing something or am I doing anything wrong?</p>\n', 'ViewCount': '524', 'Title': 'Show $x^y$ is a primitive recursive function', 'LastActivityDate': '2013-02-02T21:20:18.577', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2778', 'Tags': '<computability><recursion><check-my-proof>', 'CreationDate': '2013-01-16T12:35:30.310', 'Id': '8967'}{'Body': "<p>Let $\\varphi(x)=2x$ if $x$ is a perfect square, $\\varphi(x) = 2x+1$ otherwise. Show $\\varphi$ is primitive recursive.</p>\n\n<p>In proving $\\varphi$ to be a p.r. function I think it could come in handy the following theorem:</p>\n\n<p>Let $\\mathcal C$ be a PRC class. Let the functions $g$, $h$ and the predicate $P$ belong to $\\mathcal C$, let</p>\n\n<p>\\begin{equation}\n f(x_1,\\ldots, x_n) =\n \\begin{cases}\n  g(x_1, \\ldots, x_n) \\;\\;\\;\\;\\;\\text{ if } P(x_1, \\ldots, x_n)\\\\\n  h(x_1,\\ldots,x_n) \\;\\;\\;\\;\\;\\text{ otherwise}\n \\end{cases}\n\\end{equation}\nThen $f$ belongs to $\\mathcal C$ because $$f(x_1, \\ldots, x_n) = g(x_1, \\ldots, x_n) \\cdot  P(x_1, \\ldots, x_n) + g(x_1, \\ldots, x_n) \\cdot \\alpha(P(x_1, \\ldots, x_n))$$ where </p>\n\n<p>\\begin{equation}\n \\alpha(x) =\n \\begin{cases}\n  1 \\;\\;\\;\\;\\;\\text{ if } x = 0\\\\\n  0 \\;\\;\\;\\;\\;\\text{ if } x \\neq 0\n \\end{cases}\n\\end{equation}</p>\n\n<p>and $\\alpha(x)$ is p.r.</p>\n\n<p>So similarly I would say that $\\varphi(x)$ is p.r. as</p>\n\n<p>\\begin{equation}\n \\varphi(x) =\n \\begin{cases}\n  2x \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{ if } x = t \\cdot t \\\\\n  2x+1 \\;\\;\\;\\;\\;\\text{ otherwise}\n \\end{cases}\n\\end{equation}\nhence $$\\varphi(x) = 2x \\cdot  P(x_1, \\ldots, x_n) + (2x+1) \\cdot \\alpha(P(x_1, \\ldots, x_n))$$ and $P$ is a primitive recursive predicate as $x \\cdot y$ is p.r. and also $x = y$.</p>\n\n<p>Does everything hold? Is there anything wrong? If so, since I am tackling this kind of exercise for the fist time, will you please tell me what's the proper way to solve this?</p>\n", 'ViewCount': '103', 'Title': 'Prove $\\varphi(x)$ to be primitive recursive', 'LastActivityDate': '2013-02-17T04:22:42.263', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2778', 'Tags': '<computability><recursion><check-my-proof>', 'CreationDate': '2013-01-17T18:30:40.390', 'Id': '8999'}{'Body': '<p>I need to show that $H_1(x)$ defined as follows is partially computable.</p>\n\n<p>\\begin{equation}\nH_1(x)=\n\\begin{cases}\n1 \\;\\;\\;\\;\\;\\text{ if } \\Phi(x,x) \\downarrow \\\\\n\\uparrow \\;\\;\\;\\;\\; \\text{ otherwise}\n\\end{cases}\n\\end{equation}</p>\n\n<p>The thing is my textbook, that is  "Computability, Complexity, and Languages" by Davis, Sigal and Weyuker, lacks of examples and walkthroughs so, personally, I find hard solving even the easiest exercises. </p>\n\n<p>I think I can prove $H_1(x)$ partially computable, if I can find a program $\\mathcal P$ that executes it.</p>\n\n<p>First of all for the Universality Theorem:</p>\n\n<p>$$\\Phi(x,x) = \\psi^{(1)}_{\\mathcal P}(x) \\text{ and } \\# (\\mathcal P)=x$$</p>\n\n<p>so I can write a program that computes $\\psi^{(1)}_{\\mathcal P}(x)$:</p>\n\n<p>\\begin{array} \\\\\n\\;\\;\\;\\;\\;\\;\\;\\;\\;Y \\gets 0 \\\\\n\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{IF } X \\neq 0 \\text{ GOTO } A \\\\\n[E] \\;\\;\\;\\text{ GOTO } E \\\\\n[A]\\;\\;\\;\\; Y \\gets Y+1 \n\\end{array}</p>\n\n<p>I don\'t know if I am on the right track. I would greately appreciate every comment, suggestion, nudge in the right direction, because I really feel kind of lost.</p>\n\n<p><strong>Attempt #2</strong>: First of all I am so very sorry for not providing you enough details. Basically:\n$$\\Phi^{(n)}(x_1, \\ldots, x_n, x_{n+1}) = \\psi^{(n+1)}_{\\mathcal P}(x_1, \\ldots, x_n, x_{n+1})$$</p>\n\n<p>in plain English $\\psi^{(n)}_{\\mathcal P}(x_1, \\ldots, x_n)$ is the value of the output at the terminal snapshot; $\\Phi^{(n)}(x_1, \\ldots, x_n, y)$, where $\\#(\\mathcal P) = y$  is the universal program $\\mathcal U_n$, which works as an interpreter, it keeps track of the current snapshot by <em>decoding</em> the number of program being interpreted, decides what to do next and do it. So $f(x) = \\Phi^{(1)}(x,y)=\\psi^{(2)}_{\\mathcal U_1}(x,y)$. So my answer would be:</p>\n\n<p>\\begin{array} \\\\\n\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{IF } \\Phi(x,x) \\text{ GOTO } C \\\\\n[A] \\;\\;\\;\\text{ GOTO } A \\\\\n[C]\\;\\;\\;\\; Y \\gets 1 \n\\end{array}</p>\n\n<p>or</p>\n\n<p>\\begin{array} \\\\\n\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{IF STP}^{(2)}(x,x,y,k)  \\text{ GOTO } C \\\\\n[A] \\;\\;\\;\\text{ GOTO } A \\\\\n[C]\\;\\;\\;\\; Y \\gets 1 \n\\end{array}</p>\n\n<p>where $STP^{(n)}(x_1, \\ldots, x_n, y, t)$ is a primitive recursive predicate that happens to be true if the program with number $y$ on input $(x_1, \\ldots, x_n)$ eventually stops after $t$ steps.</p>\n', 'ViewCount': '135', 'Title': 'Show $H_1(x)$ is partially computable', 'LastEditorUserId': '2778', 'LastActivityDate': '2013-07-23T17:14:46.530', 'LastEditDate': '2013-07-23T17:14:46.530', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2778', 'Tags': '<computability><check-my-proof>', 'CreationDate': '2013-01-20T19:07:16.897', 'Id': '9060'}{'ViewCount': '139', 'Title': u'Number of Hamiltonian cycles on a Sierpi\u0144ski graph', 'LastEditDate': '2013-03-06T07:09:17.007', 'AnswerCount': '1', 'Score': '10', 'OwnerDisplayName': 'flonk', 'PostTypeId': '1', 'OwnerUserId': '7165', 'Body': '<p>I am new to this forum and just a physicist who does this to keep his brain in shape, so please show grace if I do not use the most elegant language. Also please leave a comment, if you think other tags would be more appropriate.</p>\n\n<p>I am trying to solve <a href="http://projecteuler.net/problem=312">this problem</a> for which I need to compute the number of Hamiltonian cycles $C(n)$ in the $n$th order Sierpinski-graph $S_n$. (Please also see the above link for the definition and pictures of Sierpinski-graphs)</p>\n\n<p>I have found $C(n)$, but I must have messed up something, because my solution does not match the given value $C(5) = 71328803586048$. My argumentation consists of very basic thoughts, and I cannot find the mistake. Any help is greatly appreciated. Even if it seems lengthy, the thoughts become trivial if you <a href="http://projecteuler.net/problem=312">look at the graphs</a> while following.</p>\n\n<p><strong>(a)</strong> In a given graph $S_n$ call the outer corners $A,B,C$. Then I define the following quantities: </p>\n\n<p>$N(n) := $ the number of Hamiltonian paths from $A$ to $C$.</p>\n\n<p>$\\bar{N}(n) := $ the number of paths from $A$ to $C$ which visit each node once except $B$.</p>\n\n<p>I will also call such paths $N$- or $\\bar{N}$-type paths in the following. </p>\n\n<p><strong>(b)</strong> It is easy to see that $N(n)=\\bar{N}(n)$. </p>\n\n<p>The reason is the following: Consider a $N$-type path. Starting at $A$ this path is of the form $(A,...,X_1,B,X_2,...,C)$. By replacing the segment $(X_1,B,X_2)$ by $(X_1,X_2)$ we obtain a $\\bar{N}$-type path. This operation uniquely maps all $N$-type paths to $\\bar{N}$-type paths.</p>\n\n<p><strong>(c)</strong> We derive the recursion $N(n+1)=2N(n)^3$.</p>\n\n<p>Consider an $N$-type path from $A$ to $B$ and denote the subtriangles at the outer corners $A,B,C$ by $T_A,T_B,T_C$, respectively. It is clear that the $N$-type path will visit each subtriangle exactly once starting from $T_A$ over $T_B$ to $T_C$. Now consider the node $Z$ at which the subtriangles $T_A$ and $T_C$ touch. There are two possibilities, when this point is visited by the path, either <strong>(i)</strong> before leaving $T_A$ or <strong>(ii)</strong> after entering $T_C$. In these cases the three subpaths inside $T_A,T_B,T_C$ are of the types <strong>(i)</strong> $N,N,\\bar{N}$ or <strong>(ii)</strong> $\\bar{N},N,N$, respectively. With this in mind we can count </p>\n\n<p>$N(n+1)=N(n)N(n)\\bar{N}(n)+\\bar{N}(n)N(n)N(n)$ and with <strong>(b)</strong> we arrive at the upper recursion.</p>\n\n<p><strong>(d)</strong> We solve the recursion <strong>(c)</strong> with $N(1)=1$ and obtain $N(n)=2^{3^0+3^1+...+3^{n-2}}$.</p>\n\n<p><strong>(e)</strong> Consider a Hamiltonian cycle in the graph $S_n$. As each of three subtriangles is connected to the others via two nodes only, it is clear that the cycle will enter each subtriangle exactly once via one connecting node, then "fill" it, an finally leave it via the other connecting node. Hence the Hamiltonian cycle in $S_n$ consists of three $N$-type subpaths in the subtriangles which all have the structure of $S_{n-1}$. We can conclude for the number of Hamiltonian cycles</p>\n\n<p>$C(n) = N(n-1)^3$.</p>\n\n<p>However it follows for $n=5$</p>\n\n<p>$C(5) = N(4)^3 = 8192^3=549755813888 \\neq 71328803586048$</p>\n\n<p>where the latter should be obtained according to the problem page (link above).</p>\n\n<p>Thanks again for any help or comments.</p>\n', 'Tags': '<graph-theory><combinatorics><check-my-proof>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-24T03:14:30.723', 'CommentCount': '0', 'AcceptedAnswerId': '10306', 'CreationDate': '2013-03-05T10:07:51.497', 'Id': '10305'}{'ViewCount': '1328', 'Title': 'Flaw in my NP = CoNP Proof?', 'LastEditDate': '2013-03-13T14:36:43.313', 'AnswerCount': '3', 'Score': '6', 'OwnerDisplayName': 'simpleton', 'PostTypeId': '1', 'OwnerUserId': '7253', 'FavoriteCount': '1', 'Body': '<p>I have this very simple "proof" for NP = CoNP and I think I did something wrongly somewhere, but I cannot find what is wrong. Can someone help me out?</p>\n\n<p>Let A be some problem in NP, and let M be the decider for A. Let B be the complement, i.e. B is in CoNP. Since M is a decider, you can use it to decide B as well (just flip the answer). Doesn\'t that mean that we solve both NP and CoNP problems with the same M?</p>\n\n<p>To put it more concretely.</p>\n\n<p>Let A be some NP-complete problem, and let M be decider for A. Consider any problem B in CoNP. We consider its complement not-B, which is in NP, and then get a polynomial reduction to A. Then we run our decider M and flip our answer. We thus obtain a decider for B. This implies B is in NP as well. </p>\n\n<p>May I know what is wrong with my reasoning?</p>\n', 'Tags': '<complexity-theory><p-vs-np><check-my-proof><np>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-13T14:36:43.313', 'CommentCount': '2', 'CreationDate': '2013-03-12T09:52:11.097', 'Id': '10485'}{'Body': "<p>Given $n$ arrays of size $k$ each, we want to show that at least $\\Omega(nk \\log k)$ comparisons are needed to sort all arrays (indepentent of each other). </p>\n\n<p>My proof is a simple modification of the decision tree argument used to obtain the lower bound for comparison-based sorting of one array. More specifically, I argue that there are in total $k!^n$ possible permutations for the entries in all given arrays, and that a binary tree with that number of leaves is of height $h \\in \\Omega(nk \\log k)$. Is that argument correct? </p>\n\n<p>Furthermore, I was told that merely observing that one needs $\\Omega(k \\log k)$ comparisons for each of the arrays and we need to sort $n$ times in total (for $n$ arrays) is <em>not</em> a sufficient argument. Why is that? My answer would be that this is just <em>one</em> possible approach to this problem, and not a general argument excluding each and every other potential comparison-based algorithm for solving the given task with less than $\\Omega(nk \\log k)$ comparisons. \nHowever, this is not particularly concise and I would consider a rather technical argument (which I don't see) as more appropriate. What would that be?</p>\n", 'ViewCount': '132', 'Title': 'Lower bound for sorting n arrays of size k each', 'LastEditorUserId': '7486', 'LastActivityDate': '2013-03-29T13:24:00.140', 'LastEditDate': '2013-03-29T13:24:00.140', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '10893', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<algorithms><sorting><arrays><lower-bounds><check-my-proof>', 'CreationDate': '2013-03-29T12:07:19.733', 'Id': '10890'}{'Body': "<p>This was given as a homework problem but I have already submitted the assignment.  I'd like to resolve it at this point for my own satisfaction.</p>\n\n<p>Given that $L_1$ is a linear language and $L_2$ is a regular language, show that $L=L_1L_2$ is a linear language.</p>\n\n<p>Recall that a linear grammar $G=(\\Sigma, V, P, \\sigma)$ has productions $A\\to yBz$ for some $y,z \\in \\Sigma^*$ and $A,B \\in V$.</p>\n\n<p>I use the theorem that every regular language can be represented by a right linear grammar.</p>\n\n<p>Then I use the theorem that every right linear grammar is the reverse of a left linear grammar (being a little careful about what I mean by reverse)... $L(rev(G))=rev(L(G))$...</p>\n\n<p>Next each left linear grammar is the reverse of a regular language, but the reverse of a regular language is regular, so left linear grammars also represent regular languages.</p>\n\n<p>So our productions in $L_2$ are of the form $x \\to Ca \\mid a$ for some $C \\in V_{L_2}$ and $a \\in \\Sigma_{L_2}$.</p>\n\n<p>Now on to the show...</p>\n\n<p>What we are looking for is $L = L_1.L_2$, $L$ is linear (to show).</p>\n\n<p>So this has the form $S \\to yBzCa \\mid yBzaa$</p>\n\n<p>So far so good, the second production is linear and within our expectations for set inclusion.</p>\n\n<p>I'm having a devil of a time reducing $yBzCa$ however ...</p>\n\n<p>If I introduce $V\\to BzC$ that linearizes $S$ but $V$ is not linear ... </p>\n\n<p>If I give $T\\to z$ to get $V\\to BTC$ I'm not much better off </p>\n\n<p>If I use $V_1\\to Bz$ (ok linear!) but then $V\\to V_1C$ (not linear)</p>\n\n<p>What is the piece of the puzzle I'm missing?</p>\n\n<p>I have a suspicion that my woes are because I failed to have a production that is $B\\implies^*a$ for some terminal $a \\in \\Sigma_{L_1}$ but I haven't observed that in the definitions thus far... and further unless B only goes to a terminal I'm in the same mess (if $B\\to t$ where $t \\in \\Sigma_{L_2} \\bigcup {\\epsilon} $ then I think I'm finished but how do I justify it?</p>\n", 'ViewCount': '99', 'Title': 'How can I show a linear languages are closed against concatenating with regular ones?', 'LastEditorUserId': '6551', 'LastActivityDate': '2013-04-04T10:55:25.213', 'LastEditDate': '2013-04-03T18:51:26.803', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10988', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6551', 'Tags': '<formal-languages><context-free><closure-properties><check-my-proof>', 'CreationDate': '2013-04-03T02:16:07.357', 'Id': '10985'}{'Body': '<p>My question refers to the draft of <a href="http://www.liafa.jussieu.fr/~jep/PDF/MPRI/MPRI.pdf" rel="nofollow">Mathematical Foundations of Automata Theory</a>, IV.2.1 (pages 89ff in the pdf). I will repeat everything necessary nevertheless:</p>\n\n<p>Let $M,N$ be monoids and $\\varphi: M \\rightarrow N $ a monoid morphism. We say that a subset $L$ of $M$ is recognizable by $\\varphi$ if there is a subset $P$ of $N$ such that $L = \\varphi^{-1}(P)$. As is known, the rational languages are precisely the recognizable subsets of $\\Sigma^\\ast$.</p>\n\n<p>Furthermore, we define an equivalence relation $R_\\varphi$ by $u R_\\varphi v :\\Leftrightarrow \\varphi(u)=\\varphi(v)$. \nThis relation is a congruence relation, that is $\\forall s,t,u,v \\in M:s R_\\varphi t \\Rightarrow usv~R_\\varphi~utv$.</p>\n\n<p>We say that a congruence relation $R$ <em>saturates</em> $L$ if for all $u \\in L$, $uRv$ implies $v \\in L$.\nThen in the above document, the following proposition (IV.2.2, page 90) is stated:</p>\n\n<p>Let $\\varphi : M \\rightarrow N$ be a monoid morphism and let\n$L$ be a subset of $M$. The following conditions are equivalent:</p>\n\n<p>(1) $L$ is recognised by $\\varphi$</p>\n\n<p>(2) $L$ is saturated by $R_\\varphi$</p>\n\n<p>(3) $\\varphi^{-1}(\\varphi(L))=L$</p>\n\n<p>Proof. (1) implies (2). If $L$ is recognised by $\\varphi$, then $L=\\varphi^{-1}(P)$ for some subset $P$ of $N$. Thus if $x \\in L$ and $x R_\\varphi y$, one has $\\varphi(x) \\in P$ and since $\\varphi(x)=\\varphi(y), y \\in \\varphi^{-1}(P)=L$.</p>\n\n<p>(2) implies (3). If $x \\in \\varphi^{-1}(\\varphi(L))$, there is $y \\in L$ such that $\\varphi(x) = \\varphi(y)$, that is $x R_\\varphi y$. Thus, $x \\in L$, and $\\varphi^{-1}(\\varphi(L)) \\subseteq L$ follows. "$\\supseteq$" is trivial.</p>\n\n<p>(3) implies (1). Let $P:=\\varphi(L)$, then $\\varphi^{-1}(P)=L$. </p>\n\n<p>I want to weaken the assumptions made in the proposition. Namely, assume tgat the  $N$ in the above definitions is a proper groupoid (in fact, I need to deal with loops), that is, associativity and identity are lost. Further, $\\varphi$ need not be a morphism (the relation $R_\\varphi$, defined in the same way as above, a priori need not be a congruence anymore) and we restate (1) accordingly (as formally, the notion of a "recognable subset" is not defined for groupoids).\nThen my questions are</p>\n\n<blockquote>\n  <p>(1) Is $R_\\varphi$ still a congruence if we demand $\\varphi$ \n  to be a morphism of groupoids (loops)?</p>\n  \n  <p>(2) Does the proposition still hold? Does it if we assume that $R_\\varphi$ is  <em>not</em> a congruence?</p>\n  \n  <p>(3) What other sources (preferably monographs) are there that you recommend as comprehensive introductions to algebraic automata theory, esp. concerned with the role of monoids, semigroups (and maybe more general structures as groupoids) and their connection with automata and languages?</p>\n</blockquote>\n\n<p>Personally, I think they are both true, as for (2), neither the morphism properties, nor associativity nor congruences seem to be used in the proof. And for (1), I don\'t see where one would need associativity to prove it. \nBut it may well be that I overlooked something (which is why I ask...).</p>\n', 'ViewCount': '77', 'Title': 'Quasigroups, congruences and recognizable subsets', 'LastActivityDate': '2013-06-08T16:55:03.373', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '12536', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<formal-languages><reference-request><check-my-proof>', 'CreationDate': '2013-06-07T19:09:01.057', 'Id': '12515'}{'Body': "<p>Pardon me if i'm missing something which is very obvious here but i cant seem to figure it out. </p>\n\n<p>$E=\\{ \\langle M, w \\rangle \\mid \\text{ Turing Machine encoded by $M$ accepts input $w$ after at most $ 2^{|w|}$ steps}\\}$</p>\n\n<p>We have to prove $E\\notin P$</p>\n\n<p>The book (Papadimitrou, Elements of the ToC) assumes $E\\in P$ and it constructs another language (a diagonal one) </p>\n\n<p>$E_1=\\{\\langle M\\rangle \\mid \\text{ Turing Machine encoded by $M$ accepts input $M$ after at most $  2^{|M|}$ steps}\\}$</p>\n\n<p>and takes its complement language $E_1'$ and it follows that with the assumption $E\\in P$ , it is true that $E_1' \\in P$</p>\n\n<p>The question it then asks is the following: Say the polynomially bounded turing machine to decide $E_1'$ is $M^*$ then what happens when $M^*$ is presented with $M^*$ as an input?\nNow I understand it cant give an yes because that results in a contradiction. My doubt is where is the contradiction if the answer is no?</p>\n", 'ViewCount': '108', 'Title': 'Proving that a language is not in P using diagonalization', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-06-29T07:03:24.240', 'LastEditDate': '2013-06-29T07:03:24.240', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12955', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '8912', 'Tags': '<complexity-theory><polynomial-time><check-my-proof>', 'CreationDate': '2013-06-28T15:45:59.360', 'Id': '12953'}{'Body': '<p>Let $B = \\{z \\mid (\\exists x)\\; P(x,z)\\}$ and $P$ be a computable predicate. Show $B$ is a recursive enumerable set.</p>\n\n<p><strong>My attempt</strong></p>\n\n<p>As $P$ is a computable predicate then there is a program that computes it, therefore $B= \\{z \\mid (\\exists x)(\\exists t)\\;\\text{STP}^{(1)}(x,z,t)\\} \\Rightarrow B= \\{z \\mid \\Phi(x)\\downarrow\\} = W_z$ and so $B$ is a recursive enumerable set.</p>\n\n<p><strong>Further info</strong></p>\n\n<p>$\\text{STP}^{(n)} (x_1, \\ldots, x_n, y,t)$ is a predicate that is true if the program number $y$ halts after $t$ or fewer steps on inputs $x_1, \\ldots, x_n$.</p>\n\n<p><em>Note: please note this is the first time I ever try to solve this kind of exercises, so even if I got everything wrong and nothing makes sense, every nudge in the right direction is really welcome.</em></p>\n', 'ViewCount': '71', 'Title': 'Show $B= \\{z \\mid (\\exists x)\\; P(x,z)\\}$ is a recursive enumerable set', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-05T14:07:40.023', 'LastEditDate': '2013-09-05T14:07:40.023', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2778', 'Tags': '<computability><check-my-proof><enumeration>', 'CreationDate': '2013-09-04T14:21:03.683', 'Id': '14129'}{'Body': "<p>Here is a variation of a job-scheduling Problem.\nLet $J = \\{j_1,...j_n\\}$ be a set of Jobs for $1 \\leq i \\leq n$. Given Job length $|j_i|\\in \\mathbb{N}$, deadline $f_i \\in \\mathbb{N}$, profit $p_i \\ge 0$ and starting-time $s_i  \\in \\mathbb{N}$. I am looking for a greedy approximation factor given that the Job length may only be distinguished by factor k. </p>\n\n<p>$$max_i|j_i| \\leq k \\cdot min_i|j_i|$$</p>\n\n<p>The Greedy algorithm of this Problem is fairly stupid. Greedy takes a job with the biggest profit.  I created an example (3-Job-Scheduling):</p>\n\n<p>Let $J = \\{j_1,j_2,j_3\\}$ with $|j_1| = 2, j_2 = j_3 = 1$ and </p>\n\n<p>$s_1 = 0; s_2 = 0; s_3 = 1$,</p>\n\n<p>$f_1 = 2;f_2 = 1; f_3 = 2$</p>\n\n<p>$p_1 = w; p_2 = p_3 = (w-1)$</p>\n\n<p>What I want to show is that Greedy gives us w while 2(w-1) is the optimal solution. </p>\n\n<p>My question: Is this valid for n-Job-Scheduling (the general case). Is this the worst-case? </p>\n\n<p>I can't think of anything worse. So I figured since the problem is a k-Matroid (is this a common term?) there will be a an approximation factor $\\frac{1}{k-\\epsilon}$ for  any $\\epsilon &gt; 0.$ I know this is not exactly a proof yet, but am I on the right way?</p>\n\n<p>Thanks for your help!</p>\n", 'ViewCount': '118', 'Title': 'Single machine job scheduling (Greedy heuristic)', 'LastActivityDate': '2013-11-08T13:06:23.300', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10940', 'Tags': '<approximation><scheduling><greedy-algorithms><check-my-proof>', 'CreationDate': '2013-11-08T13:06:23.300', 'Id': '16821'}