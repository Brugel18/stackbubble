{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Having extracted the data-flow in some rather large programs as directed, acyclic graphs, I'd now like to optimize the order of evaluation to minimze the maximum amount of memory used.</p>\n\n<p>That is, given a graph {1 -> 3, 2 -> 3, 4 -> 5, 3 -> 5}, I'm looking for an algorithm that will decide the order of graph reduction to minimize the number of 'in-progress' nodes, in this particular case to decide that it should be reduced in the order 1-2-3-4-5; avoiding the alternative ordering, in this case 4-1-2-3-5, which would leave the output from node 4 hanging until 3 is also complete.</p>\n\n<p>Naturally, if there are two nodes using the output from a third, then it only counts once; data is not copied unnecessarily, though it does hang around until both of those nodes are reduced.</p>\n\n<p>I would also quite like to know what this problem is called, if it has a name. It looks similar to the graph bandwidth problem, only not quite; the problem statement may be defined in terms of path/treewidth, but I can't quite tell, and am unsure if I should prioritize learning that branch of graph theory right now.</p>\n", 'ViewCount': '126', 'Title': 'Optimizing order of graph reduction to minimize memory usage', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-10T03:23:26.373', 'LastEditDate': '2012-05-10T03:23:26.373', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1425', 'Tags': '<algorithms><graphs><optimization><software-engineering><program-optimization>', 'CreationDate': '2012-05-09T12:07:24.633', 'FavoriteCount': '1', 'Id': '1752'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>On <a href="https://en.wikipedia.org/wiki/Levenshtein_distance#Computing_Levenshtein_distance">Wikipedia</a>, an implementation for the bottom-up dynamic programming scheme for the edit distance is given. It does not follow the definition completely; inner cells are computed thus:</p>\n\n<pre><code>if s[i] = t[j] then  \n  d[i, j] := d[i-1, j-1]       // no operation required\nelse\n  d[i, j] := minimum\n             (\n               d[i-1, j] + 1,  // a deletion\n               d[i, j-1] + 1,  // an insertion\n               d[i-1, j-1] + 1 // a substitution\n             )\n}\n</code></pre>\n\n<p>As you can see, the algorithm <em>always</em> chooses the value from the upper-left neighbour if there is a match, saving some memory accesses, ALU operations and comparisons. </p>\n\n<p>However, deletion (or insertion) may result in a <em>smaller</em> value, thus the algorithm is locally incorrect, i.e. it breaks with the optimality criterion. But maybe the mistake does not change the end result -- it might be cancelled out.</p>\n\n<p>Is this micro-optimisation valid, and why (not)?</p>\n', 'ViewCount': '306', 'Title': 'Micro-optimisation for edit distance computation: is it valid?', 'LastActivityDate': '2012-08-02T07:32:35.867', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2997', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<algorithms><dynamic-programming><string-metrics><correctness-proof><program-optimization>', 'CreationDate': '2012-08-01T15:41:33.670', 'Id': '2985'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In Chapter 9 of the Dragon Book, the authors describe the dataflow framework for global analysis (described also in <a href="http://dragonbook.stanford.edu/lecture-notes/Stanford-CS243/l3-handout.pdf">these slides</a>).  In this framework, an analysis is defined by a set of transfer functions, along with a <a href="http://en.wikipedia.org/wiki/Semilattice">meet semilattice</a>.</p>\n\n<p>At each step of the iteration, the algorithm works by maintaining two values for each basic block: an IN set representing information known to be true on input to the basic block, and an OUT set representing information known to be true on output from the basic block.  The algorithm works as follows:</p>\n\n<ol>\n<li>Compute the meet of the OUT sets for all predecessors of the current basic block, and set that value as the IN set to the current basic block.</li>\n<li>Compute $f(IN)$ for the current basic block, where $f$ is a transfer function representing the effects of the basic block.  Then set OUT for this block equal to this value.</li>\n</ol>\n\n<p>I am confused about why this algorithm works by taking the meet of all the input blocks before applying the transfer function.  In some cases (non-distributive analyses), this causes a loss of precision.  Wouldn\'t it make more sense to apply the transfer function to each of the OUT values of the predecessors of the given block, then to meet all of those values together?  Or is this not sound?</p>\n\n<p>Thanks!</p>\n', 'ViewCount': '84', 'Title': 'Dataflow framework for global analysis: Why meet, then apply?', 'LastActivityDate': '2012-08-12T05:26:27.267', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3133', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2131', 'Tags': '<compilers><program-optimization>', 'CreationDate': '2012-08-08T17:40:34.587', 'Id': '3095'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is it possible to design a compiler which optimizes a loop in which arrays are accessed in alternate fashion? For example like this:</p>\n\n<pre><code>// int[] a,b\nint sum = 0;\nfor(int i = 0; i &lt; n; i++)\n{\n  sum += a[i] + b[i];\n}\n</code></pre>\n\n<p>With the usual sequential array storage, <code>a[i]</code> and <code>b[i]</code> may be far away from each other in memory. Therefore, I think a good compiler optimization would detect that <code>a[i]</code> and <code>b[i]</code> are always accesses at the "same" time, and store the arrays interleaved, that is <code>a[0] b[0] a[1] b[1] ...</code> so that one memory access may retrieve both <code>a[i]</code> and <code>b[i]</code>.</p>\n', 'ViewCount': '101', 'Title': 'Are compilers able to detect alternating accesses to arrays and interleave them in memory?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-05T19:48:04.607', 'LastEditDate': '2012-09-05T19:48:04.607', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '3434', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><arrays><program-optimization><memory-management>', 'CreationDate': '2012-09-05T13:27:15.477', 'Id': '3433'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>We collect most of the information about possible compiler optimizations during forward pass. Is it possible to utilize the information collected in forward pass in a backward pass so as to perform better optimizations ?</p>\n\n<p>Note: I have been going through the patent <a href="http://www.google.com/patents/US7765534" rel="nofollow">Compiler with cache utilization optimizations</a> by Roch G. Archambault et al. (2004) and was wondering what kind of information might have been utilized in their backward pass.</p>\n', 'ViewCount': '71', 'Title': 'Benefit of Backward Pass at compile time', 'LastEditorUserId': '2741', 'LastActivityDate': '2012-09-06T23:36:56.983', 'LastEditDate': '2012-09-06T23:36:56.983', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3452', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><program-optimization>', 'CreationDate': '2012-09-06T13:29:18.803', 'Id': '3449'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>How exactly <a href="http://en.wikipedia.org/wiki/Loop_dependence_analysis" rel="nofollow">Loop Dependence Analysis</a> helps in <a href="http://en.wikipedia.org/wiki/Vectorization_%28parallel_computing%29" rel="nofollow">vectorization</a> ? Are there any standard rules of safety criterias for parallizing such loops ?</p>\n', 'ViewCount': '71', 'Title': 'Using Loop Dependence analysis for vectorization', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-08T09:27:02.593', 'LastEditDate': '2012-09-07T07:27:34.463', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '3465', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><parallel-computing><program-optimization>', 'CreationDate': '2012-09-07T00:25:42.440', 'Id': '3454'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '889', 'Title': "Using Amdahl's law how do you determine execution time after an improvement?", 'LastEditDate': '2012-10-22T21:23:53.303', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1480', 'FavoriteCount': '1', 'Body': "<p>Speeding up a new floating-point unit by 2 slows down data cache accesses by a factor of 2/3 (or a 1.5 slowdown for data caches).  If old FP unit took 20% of program's execution time and data cache accesses took 10% of program's execution time, what is the overall speed up? </p>\n\n<p>I solved this problem using amdahl's law: </p>\n\n<p>FeFP = floating point enhanced fraction = .2</p>\n\n<p>FeDC = data cache access enhanced fraction = .1</p>\n\n<p>SeFP = floating point enhanced speedup = 2</p>\n\n<p>SeDC = data cache access enhanced speedup = 2/3</p>\n\n<p>Speedup overall = 1 / (   (1 - FeFP - FeDC)   +   FeFP/SeFP   +    FeDC * SeDC    )</p>\n\n<p>= 1 /  (   (   1 - .2 - .1  ) + .2/2 + (.1) * (2/3)   )\n = 1.154. </p>\n\n<p>I hope I did this correctly, but I'm confused about the next part asking what percentage of execution time is spent on floating point operations after implementing the new FP unit? </p>\n\n<p>I know that T[improved ] = T[affected] / improvement factor   + T[unaffected]</p>\n\n<p>But I'm unclear how to use it in the context of this problem.  Would appreciate all / any advice. </p>\n", 'Tags': '<computer-architecture><program-optimization>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-22T21:23:53.303', 'CommentCount': '1', 'AcceptedAnswerId': '6204', 'CreationDate': '2012-10-20T22:07:45.577', 'Id': '6200'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '163', 'Title': 'Fastest Algo to separate the 0s and 1s', 'LastEditDate': '2013-03-18T12:23:35.627', 'AnswerCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2042', 'Body': '<p>Suppose, I have an array of length 100.\nI have 0s at some positions and 1s at some other positions.\nWhat is the <strong><em>fastest method</em></strong> by which I can separate the <strong>0s</strong> and <strong>1s</strong>, so that we get all the 0s at the beginning and all the 1s at the remaining positions / vice-versa?</p>\n', 'ClosedDate': '2013-03-20T13:18:10.800', 'Tags': '<program-optimization>', 'LastEditorUserId': '2042', 'LastActivityDate': '2013-03-19T19:20:56.090', 'CommentCount': '9', 'AcceptedAnswerId': '10623', 'CreationDate': '2013-03-18T10:49:18.463', 'Id': '10598'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In Andrew W. Appel\'s book, <em>Modern Compiler Implementation in ML</em>, he says under chapter 17 that <em>Computability theory shows that it will always be possible to invent new optimizing transformations</em> and proceeds to prove that a <em>fully optimizing compiler</em> will solve the halting problem: A program <em>Q</em> that produces no output and never halts can easily be replaced by its optimal representation, <em>Opt(Q)</em>, being "L: goto L". So a fully optimizing compiler can solve the halting problem.</p>\n\n<p>So my question is this: <strong>Does a fully optimizing compiler exist for terminating programs?</strong> My only thoughts are the following: Even though a program is guaranteed to terminate, it can still be arbitrarily complex, and for any concrete optimizing compiler, C, one could perhaps construct a program that takes C as input and somehow produces a worse program as some kind of corner case.</p>\n\n<p>Also, <strong>What are the implications of restricting ourselves to terminating programs?</strong></p>\n', 'ViewCount': '185', 'Title': 'Do fully optimizing compilers for terminating programs exist?', 'LastEditorUserId': '9213', 'LastActivityDate': '2013-07-18T16:25:27.483', 'LastEditDate': '2013-07-18T16:25:27.483', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '13315', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '9213', 'Tags': '<computability><compilers><program-optimization>', 'CreationDate': '2013-07-17T12:14:57.423', 'Id': '13313'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Now I am confused about symbolic execution (SE) and reachability analysis (RA). As I know, SE uses symbols to execute some code to reach each branch with branch conditions. And RA can be used to find the reachability of each branch, right? When RA is used, we can extract the branch condition for each branch. If so, what's the difference between them? Can they be swift? Are they all static analysis?</p>\n", 'ViewCount': '54', 'Title': 'Difference between symbolic execution and reachability analysis', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-30T10:30:32.577', 'LastEditDate': '2013-07-30T10:30:32.577', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13497', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9406', 'Tags': '<algorithm-analysis><compilers><program-optimization>', 'CreationDate': '2013-07-29T16:10:30.270', 'Id': '13492'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I need help to understand Chaitin\'s elegant program proof. An elegant program is the shortest program that produces a given output.</p>\n\n<p>Here is the proof:</p>\n\n<blockquote>\n  <p>Construct a program $B$ that takes as input a number $N$ and enumerates all possible programs $P_k$ longer than $N$. $B$ runs the elegance tester $\\mathrm{ET}$ on each enumerated program $P_k$ in turn until it finds some $P_k$ which $\\mathrm{ET}$ claims is elegant. $B$ then runs that $P_k$, thus producing the same output as that $P_k$.</p>\n  \n  <p><strong>Lemma:</strong> B must produce some output.</p>\n  \n  <p><strong>Proof:</strong> There are an infinite number of elegant programs, as noted earlier. So if $\\mathrm{ET}$ works as assumed, $B$ must eventually find one of those elegant programs whereupon it will produce that program\'s output.\n  Now run $B$ with $N$ set to $|B| + 1$ (See note 1). (This is the "threshold size" mentioned in the theorem.) $B$ now will produce the same output as some program $P_k$ which $\\mathrm{ET}$ claimed was elegant. But $P_k$ is longer than $B$, so $P_k$ cannot be elegant because $B$, which is shorter, produced the same output. Therefore, $\\mathrm{ET}$ was wrong when it claimed $P_k$ was elegant. QED.</p>\n</blockquote>\n\n<p>My question is: The proof begins with a program $B$ that is a program "that takes as input a number $N$ and enumerates all possible programs $P_k$ longer than $N$" But because of the halting problem such a program is not possible, so the proof starts dead? There is something I\'m not understanding here.</p>\n', 'ViewCount': '91', 'Title': "Chaitin's elegant programs", 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-13T10:15:58.190', 'LastEditDate': '2013-08-13T08:44:01.653', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9631', 'Tags': '<computability><program-optimization>', 'CreationDate': '2013-08-13T07:22:40.833', 'Id': '13728'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am looking for advice in the following optimization problem. I have a website (system) that receives database updates later returned in queries made to the same system. In order to speed up the system the obvious solution is to cache data in different places. I have identified the most likely places where caching may be useful, but caching in every case is clearly not practical. I have begun to decompose the times it takes to place data in different caches. I will end up with.</p>\n\n<pre><code>Cu = uth computation time\nSu = storage required to store result of uth computation\nSCn = storage cost using nth storage resource\nWn = storage cache write time for nth storage resource\nRn = storage cache read time for nth storage resource\n</code></pre>\n\n<p>I understand that there are multiple caches inside today's microprocessors, but I want to ignore those for now. I actually have several options for storage. I can buy plenty of SSD, Spinning drives and/or RAM. But given the amount of possible caching I want to buy what makes most sense.</p>\n\n<p>I am trying to come up with a cost function, storage seems to be pretty straight forward since there will be an allocated space that will cost X dollars. I am struggling a bit more with timing. Clearly I could minimize the time it takes to query and update. But that does not seem correct. I need responsiveness, we need servers to be responsive with every request not to be able to process every single update and query at once in a couple of days, instead of three. I am constructing a $$ to seconds function. This function would imply, we are willing to pay $X for a computer that responds in Y seconds.</p>\n\n<p>I will also need an optimization algorithm, there are a lot out there and I am not sure which could be a good fit for this problem.</p>\n\n<p>I am having a lot of difficulty finding research similar to this description. And I do know I will need to redo this optimization a number of times, so I will end up writing code so I don't have to do this every time.</p>\n", 'ViewCount': '63', 'Title': 'How to compute an optimally cost-effective cache strategy?', 'LastActivityDate': '2013-09-03T18:39:54.083', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9964', 'Tags': '<optimization><program-optimization>', 'CreationDate': '2013-09-03T18:39:54.083', 'Id': '14109'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The following is Figure 1 in Gene M. Amdahl\'s "Validity of the single processor approach to achieving large scale computing capabilities" (1967) (<a href="http://www-inst.eecs.berkeley.edu/~n252/paper/Amdahl.pdf" rel="nofollow">PDF</a>):</p>\n\n<p><img src="http://i.stack.imgur.com/KkY3p.png" alt="Figure 1 from Amdahl\'s &quot;Validity of the single processor approach&quot;"></p>\n\n<p>The text describes this as representing the performance (presumably vertical) as a function of the fraction of instructions that can be executed in parallel for three machines. Machine A has 32 arithmetic execution units, machine B has 3-deep pipelined execution units working on 8-element vectors, machine C has 3-deep pipelined execution units with 8-wide scalar execution (if I understood the descriptions correctly). With a note that "The probable region of operation is centered around a point corresponding to 25% data management overhead and 10% of the problem operations forced to be sequential."</p>\n\n<p>How did Amdahl derive this graph and how is the graph meant to be interpreted?</p>\n', 'ViewCount': '41', 'Title': u'Amdahl \u201cvalidity of the single processor approach\u201d', 'LastEditorUserId': '4577', 'LastActivityDate': '2014-02-12T20:21:39.273', 'LastEditDate': '2014-02-09T02:09:36.137', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14488', 'Tags': '<program-optimization>', 'CreationDate': '2014-02-07T21:48:45.900', 'Id': '21434'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have the memory reference string for a multithreaded application and want to run this through a simulator which implements/approximates Belady\'s OPT page replacement algorithm.</p>\n\n<p>But what is the best way to do this?</p>\n\n<p>There is no problem with a single threaded approach - just look for the page in memory with longest reuse distance and get rid of it. But with multithreaded this becomes much more complex - we know what the reuse distances for each thread is, but we don\'t know the "combined" reuse distance.</p>\n\n<p>Practically, it\'s easy to get into the position where a page for one thread has a very long reuse distance and so gets chucked out when memory space is needed, only for it to be quickly faulted back in by another thread.</p>\n\n<p>I cannot find any scientific literature on this - but cannot believe it hasn\'t been studied before: does anyone know of any papers that consider this issue?</p>\n', 'ViewCount': '25', 'Title': "Implementing/approximating Belady's OPT for multithreaded environments (papers?)", 'LastActivityDate': '2014-03-16T22:39:32.250', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6712', 'Tags': '<memory-management><paging><program-optimization><threads>', 'CreationDate': '2014-03-16T22:39:32.250', 'Id': '22687'}}