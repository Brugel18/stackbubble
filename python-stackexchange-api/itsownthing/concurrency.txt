{'Body': '<p><a href="http://en.wikipedia.org/wiki/Reflection_%28computer_programming%29" rel="nofollow">Reflection</a> is a common mechanism for accessing and changing the structure of a program at run-time, found in many dynamic programming languages such as Smalltalk, Ruby and Python, and in impoverished form in Java and (hence) Scala. Functional languages such as LISP and Scheme also support a good reflect framework. </p>\n\n<p>Modern languages support concurrency, either by adding threads on top of the existing language constructs, or by designing from the ground up with concurrency in mind.</p>\n\n<p>My question is: </p>\n\n<blockquote>\n  <p>What models of reflection for the concurrency aspects in concurrent languages (multi-threaded, actor-based, active-object-based) exist? </p>\n</blockquote>\n', 'ViewCount': '164', 'Title': 'Reflection on Concurrency', 'LastEditorUserId': '31', 'LastActivityDate': '2012-03-16T23:43:47.517', 'LastEditDate': '2012-03-12T19:34:39.557', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '31', 'Tags': '<programming-languages><semantics><concurrency><reflection>', 'CreationDate': '2012-03-12T16:55:45.647', 'FavoriteCount': '1', 'Id': '246'}{'Body': '<p>I am reading about atomicity and came across the following scenario</p>\n\n<pre><code>int x = y = z = 0;\n\nThread 1        Thread 2\n---------       --------\nx = y + z       y = 1\n                z = 2\n</code></pre>\n\n<p>Which gives the following sets of output</p>\n\n<p>$$\\begin{array}{ccc}1&amp;2&amp;3\\\\\r\nT1 : x = y + z&amp;T2 : y = 1&amp;T2 : y = 1\\\\T2 : y = 1&amp;T2 : z = 2&amp;T1 : x = y + z\\\\T2 : z = 2&amp;T1 : x = y + z&amp;T2 : z = 2\\end{array}$$</p>\n\n<p>Translating the $x=y+z$ expression to machine code gives</p>\n\n<pre><code>load r1; y\nload r2; z\nadd r3; r1; r2\nstore r3; \n</code></pre>\n\n<p>However according to some notes I read going down the path of</p>\n\n<pre><code>T1 : load r1, y\nT2 : y = 1\n     z = 2\nT1 : load r2, z\n     add r3, r1, r         \n     store r3, x\n</code></pre>\n\n<p>I cannot seem to understand how the author came to result that $x=2$. </p>\n\n<p>To me, based on the previous machine instructions the result should be 3, which I guess leads me to realize I am supposed to hit <em>eureka</em> (or a simple misread) and realize where the atomicity occurs. Could you explain the atomicity in this fairly simple statement that leads to the correct result?</p>\n', 'ViewCount': '47', 'Title': 'Which instruction yields atomicity in this expression that makes the result 2?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-13T17:16:55.433', 'LastEditDate': '2012-03-13T17:10:32.273', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '324', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '151', 'Tags': '<operating-systems><programming-languages><concurrency>', 'CreationDate': '2012-03-13T17:05:33.810', 'Id': '323'}{'Body': u'<p>We\'re in a shared memory concurrency model where all reads and writes to integer variables are atomic.  </p>\n\n<ul>\n<li><code>do:</code> $S_1$ <code>in parallel with:</code> $S_2$&#160;\xa0 means to execute $S_1$ and $S_2$ in separate threads, concurrently.</li>\n<li><code>atomically(</code>$E$<code>)</code> \xa0 means to evaluate $E$ atomically, i.e. all other threads are stopped during the execution of $E$.</li>\n</ul>\n\n<p>Consider the following program:</p>\n\n<pre><code>x = 0; y = 4\ndo:                 # thread T1\n    while x != y:\n        x = x + 1; y = y - 1\nin parallel with:   # thread T2\n    while not atomically (x == y): pass\n    x = 0; y = 2\n</code></pre>\n\n<p>Does the program always terminate? When it does terminate, what are the possible values for <code>x</code> and <code>y</code>?</p>\n\n<p><sub> Acknowledgement: this is a light rephrasing of exercise 2.19 in <a href="http://www.cs.arizona.edu/~greg/mpdbook/" rel="nofollow"><em>Foundations of Multithreaded, Parallel, and Distributed Programming</em></a> by Gregory R. Andrews. </sub>  </p>\n', 'ViewCount': '150', 'Title': 'termination of two concurrent threads with shared variables', 'LastEditorUserId': '39', 'LastActivityDate': '2012-03-26T16:55:14.447', 'LastEditDate': '2012-03-26T16:55:14.447', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '448', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '39', 'Tags': '<concurrency><shared-memory><imperative-programming>', 'CreationDate': '2012-03-16T23:58:16.950', 'Id': '443'}{'Body': '<p>A drink dispenser requires the user to insert a coin ($\\bar c$), then press one of three buttons: $\\bar d_{\\text{tea}}$ requests a cup of tea $e_{\\text{tea}}$, ditto for coffee, and $\\bar r$ requests a refund (i.e. the machine gives back the coin: $\\bar b$). This dispenser can be modeled by the following <a href="http://en.wikipedia.org/wiki/Calculus_of_communicating_systems" rel="nofollow">CCS</a> process:</p>\n\n<p>$$ M \\stackrel{\\mathrm{def}}= c.(d_{\\text{tea}}.\\bar e_{\\text{tea}}.M + d_{\\text{coffee}}.\\bar e_{\\text{coffee}}.M + r.\\bar b.M)$$</p>\n\n<p>A civil war raises the price of coffee to two coins, while the price of tea remains one coin. We want a modified machine that delivers coffee only after two coins, and acquiesces to a refund after either one or two coins. How can we model the modified machine with a CCS process?</p>\n', 'ViewCount': '151', 'Title': 'CCS process for a drink dispenser with two different prices', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-17T17:42:36.120', 'LastEditDate': '2013-09-17T17:42:36.120', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '446', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '39', 'Tags': '<logic><concurrency><modelling><process-algebras><ccs>', 'CreationDate': '2012-03-17T00:49:38.620', 'Id': '444'}{'Body': '<p>To my knowledge, there are three major process algebras that have inspired a vast range of research into formal models of concurrency. These are:</p>\n\n<ul>\n<li>CCS and $\\pi$-calculus both by Robin Milner</li>\n<li>CSP by Tony Hoare and</li>\n<li>ACP by Jan Bergstra and Jan Willem Klop</li>\n</ul>\n\n<p>All three seem to have to this day a quite active following and vast amounts of research has been done on them.</p>\n\n<blockquote>\n  <p>What are the key similarities and differences of these approaches? \n  Why has research in process algebra diverged instead of converged, in the sense that there is no one universal model to unify the field? </p>\n</blockquote>\n', 'ViewCount': '334', 'Title': 'Similarities and differences in major process algebras', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-27T21:07:13.243', 'LastEditDate': '2012-03-26T05:23:03.690', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '31', 'Tags': '<logic><concurrency><process-algebras>', 'CreationDate': '2012-03-17T13:58:59.003', 'FavoriteCount': '2', 'Id': '465'}{'Body': "<p>After reading several sources I'm still confused about user- and kernel-level threads. </p>\n\n<p>In particular:</p>\n\n<blockquote>\n  <p>Threads can exist at both the user level and the kernel level</p>\n</blockquote>\n\n<p>What is the difference between the user level and kernel level? </p>\n", 'ViewCount': '13017', 'Title': 'What is the difference between user-level threads and kernel-level threads?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:11:48.700', 'LastEditDate': '2012-04-22T16:11:48.700', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1066', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '935', 'Tags': '<operating-systems><terminology><concurrency><kernel>', 'CreationDate': '2012-04-05T21:26:34.357', 'Id': '1065'}{'Body': '<p>In other words, what advantages does <a href="http://en.wikipedia.org/wiki/Thread_%28computer_science%29#M%3aN_.28Hybrid_threading.29" rel="nofollow">Hybrid threading</a> have over 1:1 (kernel only) and N:1 (user only) threading?</p>\n\n<p><sub>This is a follow-up to <a href="http://cs.stackexchange.com/questions/1065/what-is-the-difference-between-user-level-threads-and-kernel-level-threads">What is the difference between user-level threads and kernel-level threads?</a></sub></p>\n', 'ViewCount': '343', 'Title': 'What is the purpose of M:N (Hybrid) threading?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-04-06T13:46:58.783', 'LastEditDate': '2012-04-06T11:30:13.317', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '1075', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '935', 'Tags': '<operating-systems><concurrency><kernel>', 'CreationDate': '2012-04-06T10:44:19.613', 'Id': '1074'}{'Body': "<p>I'm applying the Compare-and-Swap technique to a SQL database to create custom row-level locking in my dataset, allowing for safe READ UNCOMMITTED isolation at the database level.</p>\n\n<p>The Resource table includes a LockOwner <code>GUID</code> and a IsLocked <code>BIT</code> field.  To acquire a lock, a dirty-read query gets the ID, LockOwner, and LockStatus.  If <code>Unlocked</code>, attempt to <code>UPDATE</code> the Resource by (ID, LockOwner) with a newly generated LockOwner and LockStatus of <code>Locked</code>.  Abort and start again if no rows are updated - meaning someone else got there first.  Otherwise, the Lock is held in the READ UNCOMMITTED transaction.  The transaction is needed to allow rollback on client failure/abandon, but the dirty reads avoid locks.</p>\n\n<p><strong>This seems to me to work great for resources that are independent of each other.  But what must I add to account for a new kind of lock, ResourceGroup?</strong></p>\n\n<p>ResourceGroup to Resource is a one-to-many relationship.  Resources can be locked individually, but if the ResourceGroup needs to be locked, then all of the Resources must also be locked.  </p>\n\n<p>Locking a ResourceGroup is a far less frequent need than locking a Resource, so the scheme should be optimized for Resource queries, avoiding requiring joins to ResourceGroup if possible.</p>\n\n<p>I am imagining a scenario where locking a ResourceGroup involves marking the member rows with some flag, but I'm not sure what scheme doesn't interfere with the original Resource-only scheme.  Part of the problem comes from the UPDATE of a Resource while it is locked (and therefore already UPDATED in another transaction).  I believe that even if the fields are different within the record, the UPDATE will place an UPDATE LOCK on the row, so any lock on ResourceGroup would introduce blocking that we are trying to avoid.  Even if we could do this, how would the ResourceGroup lock acquisition mechanism know when all of the Resources (which may have had locks in process as we began locking their peers) have been released?</p>\n\n<p>There may be differences in this locking granularity by RDBMS, I'm on MS SQL 2005+.</p>\n", 'ViewCount': '134', 'Title': 'Compare-and-Swap in an RDBMS for custom locks and lock escalation', 'LastEditorUserId': '39', 'LastActivityDate': '2012-05-22T14:50:44.323', 'LastEditDate': '2012-05-21T22:19:04.747', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '762', 'Tags': '<concurrency><database-theory>', 'CreationDate': '2012-05-21T13:22:33.523', 'Id': '1974'}{'Body': '<p>I think that in <a href="http://en.wikipedia.org/wiki/Peterson%27s_algorithm" rel="nofollow">Peterson\'s algorithm</a> for <a href="http://en.wikipedia.org/wiki/Mutual_exclusion" rel="nofollow">mutual exclusion</a>, if the process first to enter the critical section were to die or be cancelled, the other process would loop forever, waiting to enter the critical section.</p>\n\n<p>In the picture, if process 1 is stopped, the rest of the processes behind process 1 will execute up to where of process 1 is but then loop.</p>\n\n<p><img src="http://i.stack.imgur.com/Tz6vK.jpg" alt="enter image description here"></p>\n\n<p>What happens if the process that reaches the critical section first dies before leaving it?</p>\n', 'ViewCount': '376', 'Title': "Does Peterson's 2-process mutual exclusion algorithm account for dying processes?", 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-20T16:44:21.693', 'LastEditDate': '2013-01-20T15:41:17.353', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '6', 'OwnerDisplayName': 'ganadara', 'PostTypeId': '1', 'OwnerUserId': '1778', 'Tags': '<programming-languages><concurrency><mutual-exclusion>', 'CreationDate': '2012-03-15T02:17:23.163', 'Id': '2237'}{'Body': u'<p>I\'ve been reading a bit of the literature lately, and have found some rather interesting data-structures.</p>\n\n<p>I have researched various different methods of getting update times down to $\\mathcal{O}(1)$ worst-case update time [1-7].</p>\n\n<p>Recently I begun looking into lock-free data-structures, to support efficient concurrent access.</p>\n\n<p><strong>Have any of these worst-case $\\mathcal{O}(1)$ update-time techniques been used in the implementation of lock-free data structures?</strong></p>\n\n<p>I ask because; to me, they seem like the obvious practical extension of this "theoretical enhancement".</p>\n\n<hr>\n\n<ol>\n<li><p><a href="http://www.sciencedirect.com/science/article/pii/0020019083900996">Tarjan, Robert Endre. \u201cUpdating a Balanced Search Tree in O(1) Rotations.\u201d Information Processing Letters 16, no. 5 (1983): 253 \u2013 257.</a></p></li>\n<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.4630">Driscoll, J R, N Sarnak, D D Sleator, and R E Tarjan. \u201cMaking Data Structures Persistent.\u201d In Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, 109\u2013121. STOC  \u201986. New York, NY, USA: ACM, 1986.</a></p></li>\n<li><p><a href="http://dx.doi.org/10.1007/BF00299635">Levcopoulos, C., and Mark H. Overmars. \u201cA Balanced Search Tree with O(1) Worst Case Update Time.\u201d Acta Inf. 26, no. 3 (November 1988): 269\u2013277.</a></p></li>\n<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.9433">Fleischer, Rudolf. A Simple Balanced Search Tree With O(1) Worst-Case Update Time</a></p></li>\n<li><p><a href="http://dx.doi.org/10.1016/0020-0190%2894%2900115-4">Dietz, Paul F, and Rajeev Raman. \u201cA Constant Update Time Finger Search Tree.\u201d Information Processing Letters 52, no. 3 (1994): 147 \u2013 154.</a></p></li>\n<li><p><a href="http://dl.acm.org/citation.cfm?id=998223.998229">Lagogiannis, George, Christos Makris, Yannis Panagis, Spyros Sioutas, and Kostas Tsichlas. \u201cNew Dynamic Balanced Search Trees with Worst-case Constant Update Time.\u201d J. Autom. Lang. Comb. 8, no. 4 (July 2003): 607\u2013632.</a></p></li>\n<li><p><a href="http://www.cs.au.dk/~gerth/papers/stoc02.pdf">Brodal, Gerth St\xf8lting, George Lagogiannis, Christos Makris, Athanasios Tsakalidis, and Kostas Tsichlas. \u201cOptimal Finger Search Trees in the Pointer Machine.\u201d J. Comput. Syst. Sci. 67, no. 2 (September 2003): 381\u2013418.</a></p></li>\n</ol>\n', 'ViewCount': '506', 'Title': 'Lock-free, constant update-time concurrent tree data-structures?', 'LastEditorUserId': '1120', 'LastActivityDate': '2013-05-14T16:27:44.497', 'LastEditDate': '2012-07-18T05:21:06.267', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '1120', 'Tags': '<reference-request><data-structures><time-complexity><concurrency><search-trees>', 'CreationDate': '2012-07-10T20:04:39.177', 'FavoriteCount': '5', 'Id': '2680'}{'Body': '<p>Is there an algorithm to perform batch processing in the increase-key operation? Let us say, a binary heap (min-heap) is used. In the normal increase-key function, if we perform increase key on one node, then we have to traverse paths from the node towards the children to re balance the heap. If we want to increase the keys of five nodes in the heap, we need to call the increase-key function five times. Is it possible to call only one increase-key function and perform increase-key on five nodes simultaneously?</p>\n', 'ViewCount': '217', 'Title': 'Batch processing in increase-key function using binary heap', 'LastEditorUserId': '472', 'LastActivityDate': '2012-08-15T11:00:10.347', 'LastEditDate': '2012-08-14T12:08:17.190', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2460', 'Tags': '<algorithms><data-structures><parallel-computing><concurrency><priority-queues>', 'CreationDate': '2012-08-14T00:39:37.677', 'FavoriteCount': '1', 'Id': '3163'}{'Body': '<p>I have a problem that is almost equal to the standard one of the dining philosophers, but has a quirk: while a philosopher thinks, he still holds the fork on his left.</p>\n\n<p>If after the period of thinking (which isn\'t infinite), I release the fork on the left and then apply the normal solution (that is, acquire forks in the order of their <a href="http://en.wikipedia.org/wiki/Dining_philosophers_problem#Resource_hierarchy_solution" rel="nofollow">priority</a>), then would this solution be correct for this problem?</p>\n', 'ViewCount': '161', 'Title': 'Variation of the dining philosophers: is the standard solution still valid?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-21T12:37:20.157', 'LastEditDate': '2013-01-20T15:40:12.097', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'OwnerDisplayName': 'Lorenzo Pistone', 'PostTypeId': '1', 'Tags': '<operating-systems><concurrency><synchronization>', 'CreationDate': '2012-06-10T08:11:40.520', 'Id': '3562'}{'Body': '<p>So we have the following table of processes , where A, B and $\\Gamma$ are the resources.</p>\n\n<p>Here is a pic that i drew with the processes and the resources.</p>\n\n<p><img src="http://i.stack.imgur.com/MzpAz.jpg" alt="Table"></p>\n\n<p>So the exact question is this: Using banker\'s algorithm, calculate the minimum values of $x$ and $y$ in order the system is Deadlock free.</p>\n\n<p>I have done pretty much <em>huge</em> paper work and found that $x,y$ should be the numbers 2 and 3. But in order to find this I run the algorithm on paper several times ; for $[x,y] = [0,0],[0,1],[1,0],[1,1],[1,2]$ etc. until I found that for pair $[x=2, y=3]$ the system is deadlock free!</p>\n\n<p>So, I think that I am missing the point. All this took me like 1 hour or so. Is there a simple method with less paperwork? </p>\n\n<p>Thanks a lot in advance!</p>\n', 'ViewCount': '680', 'Title': "Banker's Algorithm and deadlocks", 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-27T17:17:21.627', 'LastEditDate': '2012-09-17T17:54:25.173', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2865', 'Tags': '<algorithms><reference-request><concurrency>', 'CreationDate': '2012-09-17T16:34:15.583', 'Id': '4593'}{'ViewCount': '355', 'Title': 'What is a linearization point?', 'LastEditDate': '2012-12-03T20:59:49.560', 'AnswerCount': '1', 'Score': '3', 'OwnerDisplayName': 'nfaughnan', 'PostTypeId': '1', 'OwnerUserId': '4866', 'Body': '<p>With respect concurrent programming, what is a linearization point? </p>\n\n<p>They seem to occur at a compare-and-swap instruction apparently. The best definition I could find is <a href="http://en.wikipedia.org/wiki/Atomicity_%28programming%29#Linearization_points" rel="nofollow">here</a>. </p>\n\n<blockquote>\n  <p>All function calls have a linearization point at some instant between their invocation and their response.</p>\n</blockquote>\n\n<p>Okay that\'s fine, they occur somewhere within a function call, but what are they?</p>\n\n<blockquote>\n  <p>All functions appear to occur instantly at their linearization point, behaving as specified by the sequential definition.</p>\n</blockquote>\n\n<p>Occur instantly at their LP\'s??? I don\'t understand this.</p>\n\n<p>I also read through <a href="http://www.eecs.qmul.ac.uk/~ohearn/Workshops/Concurrency09/slides/vafeiadis.pdf" rel="nofollow">this</a> which attempts to prove LP\'s. I am having trouble finding any solid definitions. Could anyone help?</p>\n', 'Tags': '<semantics><concurrency><synchronization>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-03T20:59:49.560', 'CommentCount': '0', 'AcceptedAnswerId': '7133', 'CreationDate': '2012-12-03T19:04:17.580', 'Id': '7132'}{'Body': '<p>I want to implement mutual exclusion for $n$ processes. Critical section code:</p>\n\n<pre><code>int turn = 0;        /* shared control variable */\n\nPi:                  /* i is 0 or 1 */\nwhile (turn != i)\n   ;                 /* busy wait */\nCSi;\nturn = 1 - i;\n</code></pre>\n\n<p>This solution from <a href="http://phoenix.goucher.edu/~kelliher/cs42/sep27.html" rel="nofollow">this page</a> but it is only made for two processes.</p>\n\n<p>I tried to adapt it for $n$ processes like this:</p>\n\n<pre><code>turn = 0 // shared control variable \n\ni = turn;\n\nwhile (turn != i);\n\n// CS\n\nturn = (turn + 1) % n;\n</code></pre>\n\n<p>Does this work?</p>\n', 'ViewCount': '96', 'Title': 'Mutual exclusion for n processes', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-21T13:01:15.777', 'LastEditDate': '2013-01-20T15:39:39.273', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6488', 'Tags': '<concurrency><mutual-exclusion>', 'CreationDate': '2013-01-20T14:20:33.747', 'Id': '9056'}{'Body': '<p>I am reading on concurrent processes and algorithms which find infinite processes by searching the process graph recursively. </p>\n\n<p>Most of the material I have found is not for beginners. I am looking for references / algorithms that can help me understand:</p>\n\n<ol>\n<li>What are process graphs?</li>\n<li>How to search for infinite processes in these graphs?</li>\n</ol>\n\n<p>Thanks in advance</p>\n', 'ViewCount': '57', 'Title': 'Process graphs and finding infinite processes', 'LastActivityDate': '2013-02-20T09:10:02.277', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9962', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6854', 'Tags': '<reference-request><concurrency><process-algebras>', 'CreationDate': '2013-02-13T01:34:04.573', 'Id': '9727'}{'Body': "<p>I apologies if my title is vague, I'm trying to apply CTL/LTL model-checking on some system written in java, however, I still don't understand how to reach a result using either of the approaches mentioned. Do I model my LTS/write specification and use a tool like SPIN to validate that or? I'm mainly looking for a point at a direction that will help me in making a start.</p>\n\n<p>Again sorry but I made this thread after so much frustration searching for an explanation to my problem.</p>\n\n<p>Thank you</p>\n", 'ViewCount': '59', 'Title': 'applying CTL/LTL model-checking on some system', 'LastActivityDate': '2013-02-25T21:50:44.457', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10104', 'Score': '0', 'OwnerDisplayName': 'Meldar', 'PostTypeId': '1', 'OwnerUserId': '7069', 'Tags': '<model-checking><concurrency><program-verification>', 'CreationDate': '2013-02-21T13:21:01.257', 'Id': '10103'}{'Body': "<p>How can someone synchronize two or more threads using serialization? According to my professor's slides and code assignments you can use serialization to solve the synchronization problem. (He doesn't explain what serialization is).</p>\n\n<p>I tried to do my research but serialization means that you put data in a specific order. I would understand that it means the same thing in this case (Running threads in a specific order). But what I most confused about is the syntax of the question. My question is:</p>\n\n<p>Does serialization mean synchronization? How would one synchronize threads using serialization?</p>\n", 'ViewCount': '72', 'Title': 'Synchronization using serialization', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-26T07:32:34.700', 'LastEditDate': '2013-03-25T10:31:34.590', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10770', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7405', 'Tags': '<concurrency><synchronization>', 'CreationDate': '2013-03-25T03:10:28.627', 'Id': '10761'}{'Body': "<p>I've a couple of questions that I need answers for. What I am looking for here is the outline of the answers. Not necessarily the exact complete answer. I can do that. \nThe question is that common operating systems provide support for concurrency through processes and threads. </p>\n\n<p>There are differences between processes and threads and that well documented and easily understood. The issue here is What support does the hardware need to provide for processes and threads? \nThe initial guess that came to my mind was that it is related to process communication and synchronization. However, these concepts are parts from another question which gets me to think that they are not the right answer. I am aware of the hyper-threading which is a hardware approach for concurrency. Is it ?!</p>\n\n<p>The other question is that Operating systems and programming languages offer various means for communication and synchronization between processes and threads. What are the most\ncommon ones? What support does the hardware need to provide and, in particular, what instructions does a processor need to offer for communication and synchronization?</p>\n\n<p>I know it is a long question but again, I don't seem to figure out the outline for the specific hardware support for (concurrent process and threads, as well as communication and synchronization).</p>\n\n<p>Your help is highly appropriated     </p>\n", 'ViewCount': '114', 'Title': 'concurrency and hardware', 'LastActivityDate': '2013-04-27T22:01:58.327', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7936', 'Tags': '<operating-systems><concurrency>', 'CreationDate': '2013-04-27T20:33:59.857', 'Id': '11610'}{'ViewCount': '84', 'Title': 'Formalisms in concurrent and/or distributed programming?', 'LastEditDate': '2013-04-30T05:30:14.553', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '7974', 'FavoriteCount': '1', 'Body': '<p>My background came from imperative languages, primarily C, C++, and Python. I picked up Scala, Erlang, and a bit of Haskell a few years later and have since become very interested in functional programming and the formalisms behind it.</p>\n\n<p>I am also interested in concurrent and distributed programming and have been looking into formalisms behind that, especially those that have seen at least a tiny bit of the "light of day" (e.g. real world use, or at least an implementation somewhere). So far I know of Communicating Sequential Processes, the Actor model, Algebra of Communicating Processes, and the Calculus of Communicating Systems. Among these I know the Actor model has realized itself in languages like Erlang, Scala, and Haskell.</p>\n\n<p>I am wondering if there are foundations I should learn and practice before tackling these fields, if there is a "classic" one that I should study first, and if there are any other popular ones that I may have missed?</p>\n', 'Tags': '<distributed-systems><concurrency>', 'LastEditorUserId': '7974', 'LastActivityDate': '2013-05-02T05:29:38.057', 'CommentCount': '0', 'AcceptedAnswerId': '11669', 'CreationDate': '2013-04-30T05:18:44.353', 'Id': '11666'}{'ViewCount': '760', 'Title': "What does 'true concurrency' mean?", 'LastEditDate': '2013-05-12T10:15:57.010', 'AnswerCount': '1', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '147', 'FavoriteCount': '2', 'Body': "<p>I often hear phrases like 'true concurrency semantics' and 'true concurrency equivalences' without any references. What does those terms mean and why are they important?</p>\n\n<p>What are some examples of true concurrency equivalences and what is the need for them? E.g. in which cases they are more applicable than more standard equivalences (bisimulation, trace equivalence, etc)?</p>\n", 'Tags': '<terminology><reference-request><concurrency>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-20T09:27:25.823', 'CommentCount': '0', 'AcceptedAnswerId': '11896', 'CreationDate': '2013-05-08T14:07:16.857', 'Id': '11893'}{'Body': '<p>There are definitions of Absolute, Strong and Weak Fairness available across the internet, but I cannot find a definition of "K-Fairness" property for critical section algorithms (also algorithms that satisfy a 1-fairness or 3-fairness property). Does this actually exist or is this something that was made up to describe a phenomenon that I am not recognizing?</p>\n', 'ViewCount': '78', 'Title': u'Definition of \u201cK-fairness\u201d with respect to concurrency?', 'LastActivityDate': '2013-05-14T10:40:43.013', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12014', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8159', 'Tags': '<concurrency>', 'CreationDate': '2013-05-14T07:33:02.987', 'Id': '12007'}{'Body': '<p>I am reading an article called <a href="http://www.sciencedirect.com/science?_ob=MiamiImageURL&amp;_cid=271538&amp;_user=32321&amp;_pii=0304397581901109&amp;_check=y&amp;_origin=article&amp;_zone=toolbar&amp;_coverDate=31-Dec-1981&amp;view=c&amp;originContentFamily=serial&amp;wchp=dGLzVlV-zSkWb&amp;md5=2073f527aa2be434886953d7aaa0f7d3&amp;pid=1-s2.0-0304397581901109-main.pdf" rel="nofollow">The temporal semantics of concurrent programs</a>\n.</p>\n\n<p>On page $9$, there is a small section (numbered as $2$) called "clean behavior".</p>\n\n<p>I think that there is a problem with this part, what does Pnueli meant by "Let $\\lambda_i$ be the leagality condition for <strong>the</strong> statement departing from $m^i$" ?</p>\n\n<p>I have marked the word "the" in bold since, as I see it, there can be more than one edge departing from $m^i$, an example can be seen on page $11$, at the beginning of part $5$.</p>\n\n<p>Did I missunderstood something , or is there actually a mistake in the article by not addressing the fact that there can be more than one statement that can be exectuded after $m^i$, and that this expression for clean behavior need to be corrected accordingly ?</p>\n', 'ViewCount': '41', 'Title': "Is there a mistake in the expression for clean behavior in Pnueli's article from 81'?", 'LastActivityDate': '2013-06-24T06:44:33.670', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '3090', 'Tags': '<concurrency><linear-temporal-logic>', 'CreationDate': '2013-05-24T22:43:47.727', 'Id': '12258'}{'Body': "<p>I'm trying to understand Little's law and can't seem to get past this scenario:</p>\n\n<p>Let's say people arrive at the register at 12 per hour. It takes 10 minutes (1/6 of an hour) to service each one of them. The law says that the long-term average number of customers is 12 * 1/6 = 2. After the first hour, my assumption is that there will be 6 customers not serviced. Then after the second hour, there will be 6 more. Why is the long-term average <code>2</code> and not the <code>storeCapacity</code>?</p>\n\n<p>Is my usage of the law wrong because I'm not talking about a stable system?</p>\n", 'ViewCount': '83', 'Title': "Using Little's law to find the average N of customers", 'LastActivityDate': '2013-05-28T03:10:06.337', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'OwnerDisplayName': 'alex', 'PostTypeId': '1', 'Tags': '<concurrency>', 'CreationDate': '2013-05-26T17:16:29.687', 'FavoriteCount': '1', 'Id': '12316'}{'Body': '<p>I am trying to understand the algorithms by Peterson and Dekker which are very similar and display a lot of symmetries.</p>\n\n<p>I tried to formulate the algorithms in informal language like follows:</p>\n\n<pre><code>Peterson\'s: "I want to enter."                 flag[0]=true;\n            "You can enter next."              turn=1;\n            "If you want to enter and          while(flag[1]==true&amp;&amp;turn==1){\n            it\'s your turn I\'ll wait."         }\n            Else: Enter CS!                    // CS\n            "I don\'t want to enter any more."  flag[0]=false;\n\nDekker\'s:   "I want to enter."                 flag[0]=true;\n            "If you want to enter              while(flag[1]==true){\n             and if it\'s your turn               if(turn!=0){\n             I don\'t want to enter any more."      flag[0]=false;\n            "If it\'s your turn                     while(turn!=0){\n             I\'ll wait."                           }\n            "I want to enter."                     flag[0]=true;\n                                                 }\n                                               }\n            Enter CS!                          // CS\n            "You can enter next."              turn=1;\n            "I don\'t want to enter any more."  flag[0]=false;\n</code></pre>\n\n<p>The difference seems to be the point where <code>"You can enter next."</code> occurs and the fact that <code>"if it\'s your turn I don\'t want to enter any more."</code> occurs in Dekker\'s.</p>\n\n<p>In Peterson\'s algorithm, the two processes seem to be dominant. A process seems to force his way in into the critical section unless it\'s the other one\'s turn.</p>\n\n<p>Conversely, in Dekker\'s algorithm, the two processes seem to be submissive and polite. If both processes want to enter the critical section, and it\'s the other one\'s turn, the process decides to no longer want to enter. (Is this needed for starvation-freedom? Why?)</p>\n\n<p>How exactly do these algorithms differ? I imagine that when both processes try to enter the critical section, in Peterson\'s, the process says "I enter", while in Dekker\'s the process says "You may enter". Can someone clear up the way the processes behave in each algorithm? Is my way of putting it in informal terms correct?</p>\n', 'ViewCount': '2071', 'Title': u'Understanding Peterson\u2019s and Dekker\u2019s algorithms', 'LastActivityDate': '2013-12-01T18:19:12.083', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '8623', 'Tags': '<algorithms><concurrency>', 'CreationDate': '2013-06-11T14:47:31.950', 'FavoriteCount': '3', 'Id': '12621'}{'Body': '<p>When two threads try to access the same resources at exactly the same time how does the computer decide which one gets the resource, or is it just decided at random?</p>\n', 'ViewCount': '89', 'Title': 'How does a race condition work?', 'LastEditorUserId': '31', 'LastActivityDate': '2013-06-26T16:36:03.890', 'LastEditDate': '2013-06-25T06:15:30.397', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8854', 'Tags': '<terminology><concurrency>', 'CreationDate': '2013-06-25T04:52:31.793', 'Id': '12885'}{'Body': "<p>If Turing Machines are the automata equivalent of the $\\lambda$ calculus, what is the automaton equivalent of the $\\pi$ calculus? I suppose it would be some class of automata that resembled a Turing Machine, but with support for communication channels or signals of some type, but I'm not sure, and would appreciate some direction.</p>\n", 'ViewCount': '153', 'Title': u'Automaton equivalent of the \u03c0 calculus?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-27T21:21:29.893', 'LastEditDate': '2013-09-17T17:40:08.220', 'AnswerCount': '2', 'CommentCount': '11', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '5291', 'Tags': '<automata><concurrency><machine-models><pi-calculus>', 'CreationDate': '2013-07-05T02:12:24.763', 'FavoriteCount': '3', 'Id': '13091'}{'ViewCount': '117', 'Title': 'What is the impact of synchronisation overhead on parallel speedup?', 'LastEditDate': '2013-08-06T09:11:51.160', 'AnswerCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8767', 'FavoriteCount': '0', 'Body': '<p>When implementing a parallel version of an algorithm, what is the impact of synchronization delays on speedup efficiency? Does this depend on the platform used?</p>\n\n<p>Is coarse-grained parallelism better than fine-grained parallelism in certain situations?</p>\n', 'ClosedDate': '2013-08-11T12:10:46.710', 'Tags': '<efficiency><parallel-computing><concurrency><synchronization>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-06T09:11:51.160', 'CommentCount': '5', 'CreationDate': '2013-08-05T12:48:59.380', 'Id': '13611'}{'Body': "<p>Given a program consisting of variables and instructions which modify these variables, and a synchronization primitive (a monitor, mutex, java's synchronized or C#'s lock), is it possible to prove that such a program is thread safe? </p>\n\n<p>Is there even a formal model for describing things like thread safety or racing conditions? </p>\n", 'ViewCount': '110', 'Title': 'Is it possible to prove thread safety?', 'LastActivityDate': '2013-09-17T14:26:49.070', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '14365', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10169', 'Tags': '<proof-techniques><correctness-proof><concurrency><threads>', 'CreationDate': '2013-09-16T15:57:39.443', 'FavoriteCount': '2', 'Id': '14356'}{'Body': '<p>I am looking for visual tools for the design, and optionally verifications, of concurrent systems.</p>\n\n<p>PS:\nThere is no tag for visual-programming, I must have 150 reputation to create one, so please create one if you can.</p>\n', 'ViewCount': '18', 'Title': 'What are some visual tools for the design of concurrent systems?', 'LastActivityDate': '2013-09-22T01:11:25.990', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4817', 'Tags': '<programming-languages><concurrency>', 'CreationDate': '2013-09-22T01:11:25.990', 'FavoriteCount': '1', 'Id': '14506'}{'ViewCount': '238', 'Title': 'Maximum degree of concurrency in task dependency graphs', 'LastEditDate': '2013-11-09T15:10:52.437', 'AnswerCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11256', 'FavoriteCount': '1', 'Body': "<p>I've been researching ways of modeling and executing tasks which are dependent on each other (but in an acyclic way) and came up with task graphs. But the question that's bugging me is how can I find out the maximum degree of concurrency in a given task graph.</p>\n\n<p>In my case, I'm talking of a relatively small graph, around 100 nodes, but nodes, representing tasks, are long running tasks. So the occuracy, more then complexity of such an algorithm would matter.</p>\n\n<p>Assuming I came up of such a degree, the second problem, is how should I distrubute tasks? I've read about topological sort, and transforming the result in a list of sets, with each set being run in parallel. But again, I suspect if this is the best approach.</p>\n", 'Tags': '<optimization><distributed-systems><concurrency>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-07T15:51:08.327', 'CommentCount': '1', 'AcceptedAnswerId': '16829', 'CreationDate': '2013-11-08T13:56:22.220', 'Id': '16823'}{'Body': '<p>I was reading about synchronization problems for cooperating processes and i learned that only hardware solutions like <code>test_and_wait()</code> and <code>compare_and_set()</code> are performed atomically at the hardware level and in all other software solutions like <strong>mutex</strong>, <strong>semaphore</strong> the code needs to be executed atomically and hence these have to be executed in the critical section themselves.</p>\n\n<p>Does this mean that these software solutions have limited use when compared to the hardware solutions, though it seems that the former are used extensively?</p>\n', 'ViewCount': '298', 'Title': 'Solutions to synchronization problem need to be executed in critical section', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-13T18:15:55.573', 'LastEditDate': '2013-11-12T17:51:29.193', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '17991', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10120', 'Tags': '<operating-systems><concurrency><synchronization><mutual-exclusion>', 'CreationDate': '2013-11-12T06:03:16.840', 'Id': '17945'}{'Body': '<p>All the article I can find seems to talk about multitasking and context switch as its a two different thing. It seems that multitasking and context switch are the same thing.</p>\n', 'ViewCount': '68', 'Title': 'Is it possible to do multitasking without context switch with just one cpu?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-03T08:41:44.767', 'LastEditDate': '2013-12-03T08:41:44.767', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11764', 'Tags': '<terminology><computer-architecture><operating-systems><concurrency>', 'CreationDate': '2013-12-02T19:44:56.067', 'Id': '18546'}{'Body': '<p>I was a little confused between these three terms Multitasking, Multithreading and Multiprogramming</p>\n\n<p>Although every one means executing different lines of codes, and for every one we need something like Task State Segment or context to store data for that particular thread/task. </p>\n\n<p>I am missing something, can anyone give me the basic difference between them and how they are actually executed in a processor</p>\n\n<p><strong>Edit:</strong> Actually I was a guy from Electronics background and I was poor at OS related issues. The main thing I understood between multiprogramming and multithreading is that in multiprogramming we execute two separate programs where as in multithreading the scheduler produces two different threads which can be executed independently. I think these are a form of multitasking implementation. Am I correct. I was really confused</p>\n', 'ViewCount': '787', 'Title': 'Difference between multitasking, multithreading and multiprogramming', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-07T13:02:37.500', 'LastEditDate': '2014-01-07T13:02:37.500', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '18739', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11539', 'Tags': '<terminology><operating-systems><concurrency>', 'CreationDate': '2013-12-08T03:22:35.070', 'Id': '18728'}{'Body': '<p>In a database system, say there are $N$ transactions each having $m_1,m_2,\\dots,m_N$ operations. How many  concurrent schedules are possible?</p>\n\n<p>$(m_1+m_2+....+m_n)!$ is the number of possible interleavings.<br>\nIs this number equal to number of concurrent schedules? Serial schedules have to be discarded from the total number?</p>\n', 'ViewCount': '88', 'Title': 'Number of concurrent schedules in database', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-13T16:51:50.990', 'LastEditDate': '2014-01-13T19:36:57.920', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '12377', 'Tags': '<concurrency><databases>', 'CreationDate': '2013-12-26T03:35:16.750', 'Id': '19295'}{'Body': '<p>As big-step operational semantics is about evaluating an expression to a final value, can we state that for defining a concurrent language one needs small-step semantics, as concurrent programs need not result in a value?</p>\n', 'ViewCount': '19', 'Title': 'defining the operational semantics of a concurrent language', 'LastActivityDate': '2013-12-28T21:01:38.003', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12426', 'Tags': '<concurrency><operational-semantics>', 'CreationDate': '2013-12-28T21:01:38.003', 'Id': '19349'}{'Body': '<p>At 15:30 in <a href="http://www.infoq.com/presentations/clojure-core-async" rel="nofollow">this talk</a>  (p13 of <a href="http://qconsf.com/system/files/presentation-slides/Clojure.pdf" rel="nofollow">this presentation here</a>) Rich Hickey mentions the formalisms available for reasoning about Communicating Sequential Processes. He then goes on to mention that these haven\'t yet been applied to Clojure\'s core.async. </p>\n\n<p>The only reference I know of for CSP is <a href="http://www.usingcsp.com/cspbook.pdf" rel="nofollow">Hoare\'s book</a>. I can see some examples of <a href="http://en.wikipedia.org/wiki/Communicating_sequential_processes#Algebraic_operators" rel="nofollow">formalisms to describe CSP here</a>. </p>\n\n<p>Suppose I wanted to do the most basic of CSP as per Rob Pike\'s presentation in Go (slide 43 <a href="http://talks.golang.org/2012/concurrency.slide#43" rel="nofollow">of this</a>). </p>\n\n<pre><code>var (\n    Web = fakeSearch("web")\n    Image = fakeSearch("image")\n    Video = fakeSearch("video")\n)\n\ntype Search func(query string) Result\n\nfunc fakeSearch(kind string) Search {\n        return func(query string) Result {\n              //time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)\n              return Result(fmt.Sprintf("%s result for %q\\n", kind, query))\n        }\n}\n</code></pre>\n\n<p><strong>How would I express this as an Algebraic statement? What benefit would it give me?</strong></p>\n\n<p>Taking a stab at it - I get</p>\n\n<p><code>(Web &rarr; P) &Pi; (Search &rarr; Q)  &Pi; (Video &rarr; R)</code></p>\n\n<p>Which tells me that the Search process can choose to interact with Web or Video depending on which environment the Search Process chooses to communicate with. </p>\n\n<p><strong>Assumptions</strong></p>\n\n<p>I\'m told that you can\'t do this in pure CSP because of the timer. For an answer I\'m happy to  assume we\'ll ignore the timer part of this. </p>\n', 'ViewCount': '45', 'Title': "How to express Rob Pike's classic Go Code presentation in Hoare's CSP Algebra?", 'LastActivityDate': '2013-12-30T13:02:34.043', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19375', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1709', 'Tags': '<concurrency><process-algebras><threads>', 'CreationDate': '2013-12-30T06:41:12.887', 'Id': '19372'}{'Body': '<p>When we look at the <a href="http://en.wikipedia.org/wiki/Actor_model" rel="nofollow">Actor Model</a> and <a href="http://en.wikipedia.org/wiki/Communicating_sequential_processes" rel="nofollow">Communicating Sequential Processes</a> we see that they are both trying to do <a href="http://en.wikipedia.org/wiki/Concurrency_%28computer_science%29" rel="nofollow">concurrency</a> based on <a href="http://en.wikipedia.org/wiki/Message_passing" rel="nofollow">message passing</a>, yet <a href="http://en.wikipedia.org/wiki/Actor_model#Contrast_with_other_models_of_message-passing_concurrency" rel="nofollow">they are distinct</a>. </p>\n\n<p>(We see implementations of the <a href="http://en.wikipedia.org/wiki/JCSP#Overview" rel="nofollow">CSP Model</a> in <a href="http://golang.org/" rel="nofollow">go-lang</a>\'s <a href="https://gobyexample.com/goroutines" rel="nofollow">goroutines</a> (and <a href="http://en.wikipedia.org/wiki/Clojure" rel="nofollow">Clojure\'s</a> <a href="https://github.com/clojure/core.async" rel="nofollow">core.async</a>) and the Actor Model in <a href="http://en.wikipedia.org/wiki/Scala_%28programming_language%29" rel="nofollow">Scala\'s</a> <a href="http://en.wikipedia.org/wiki/Akka_%28toolkit%29" rel="nofollow">Akka</a> toolkit)</p>\n\n<p>I\'m trying to get a simple list of the differences between the Actor Model and CSP. So far I have:</p>\n\n<ul>\n<li>actors message passing is asynchronous, CSP message passing is synchronous</li>\n<li>actors are <a href="http://en.wikipedia.org/wiki/Actor_model#Composing_Actor_Systems" rel="nofollow">composable</a>, CSP is not (necessarily)</li>\n<li>actors <a href="http://en.wikipedia.org/wiki/Actor_model#Unbounded_nondeterminism_controversy" rel="nofollow">always</a> have <a href="http://en.wikipedia.org/wiki/Unbounded_nondeterminism" rel="nofollow">unbounded non-determinism</a>, CSP may have <a href="http://en.wikipedia.org/wiki/Actor_model#Contrast_with_other_models_of_message-passing_concurrency" rel="nofollow">bounded or unbounded non-determinism</a></li>\n<li>actors have <a href="http://en.wikipedia.org/wiki/Actor_model#Actor_creation_plus_addresses_in_messages_means_variable_topology" rel="nofollow">variable topology</a> whereas CSP has fixed topology</li>\n<li>actors have the <a href="http://en.wikipedia.org/wiki/Locality_of_reference" rel="nofollow">principle of locality</a>, CSP does not have locality</li>\n<li>actors are designed around their behaviour, CSP doesn\'t not necessarily have this</li>\n</ul>\n\n<p>Is this correct? Is there anything I\'m missing?</p>\n\n<p><strong>Assumptions</strong></p>\n\n<ul>\n<li>When I say \'actor model\' - I mean the theoretical basis behind the implementation in Scala\'s Akka framework</li>\n</ul>\n', 'ViewCount': '140', 'Title': 'Differences between the Actor Model and Communicating Sequential Processes (CSP)', 'LastEditorUserId': '1709', 'LastActivityDate': '2014-01-07T22:10:41.857', 'LastEditDate': '2014-01-07T22:10:41.857', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '19560', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1709', 'Tags': '<concurrency><message-passing><actor-model>', 'CreationDate': '2014-01-05T04:25:23.293', 'Id': '19506'}{'Body': '<p>I am undertaking a module in Concurrent Programming where some of the new content this year covers linearizability, the Java Memory Model, and sequential consistency. Our class slides are companion slides to <strong>The Art Of Multiprocessor Programming.</strong></p>\n\n<p>I have been doing OK with linearizability but have become confused at this point below:\n<img src="http://i.stack.imgur.com/aoiED.png" alt="The art of multiprocessor programming slides"></p>\n\n<p>I understand that removing pending invocations gives a complete subhistory, however I cannot understand from this example how a subset G can be equivalent to set S which is larger than it - how is G  obtained from S here?</p>\n\n<p>As far as I am aware there is not enough information to determine if there are pending invocations from the diagram on the right and I am not sure why a --> b is removed in the subset that is G - at first I thought it\'s because they are overlapping but A and B both have linearization points for viewing them \'as sequential objects\'.</p>\n\n<p>I may be over looking something simple and have just misunderstood the slides.</p>\n', 'ViewCount': '92', 'Title': 'How can an extended linearizable history G be equivalent to sequential history S?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-19T02:27:23.217', 'LastEditDate': '2014-01-22T21:31:34.553', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '19903', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '12785', 'Tags': '<concurrency>', 'CreationDate': '2014-01-22T20:21:25.907', 'Id': '19901'}{'Body': "<p>Firstly, I am revising for my Concurrent Programming exam and have come across the following question from a previous exam paper. I have attempted to answer it, and will try and convey this effort; I'm very stuck with this question and not sure how to further progress.</p>\n\n<h3>Question</h3>\n\n<p>This question is from a 2011 Past Paper from my University created by the Examining Body that year.\nExaminers: Professor E K Burke\nDr P Sage\nand the internal examiners</p>\n\n<blockquote>\n  <p>A car park has 100 parking spaces. Because of building work max cars must be accommodated in an overflow area which is accessed via the main car park. Entrance to the main and overflow areas is controlled by two automatic barriers as follows.</p>\n  \n  <ul>\n  <li><p>When the car park is empty both barriers are closed.</p></li>\n  <li><p>Normally, the main barrier is raised as a car approaches and is lowered immediately the car has entered.</p></li>\n  <li>An exception occurs immediately after the main car park is full i.e. when it has 100-max cars in it. As the next car approaches the overflow barrier is raised first, then the main barrier is raised. Once the car has entered the main car park the overflow barrier remains raised and the main barrier is lowered. The normal main barrier action described above then resumes.</li>\n  </ul>\n  \n  <p>Consider the following program which is intended to control the two barriers. </p>\n  \n  <p>All instructions, o1, o2, o3, m1, m2, m3 and m4, are atomic. You may assume that $0 &lt; \\max \\leq 100$.</p>\n\n<pre><code>int #cars=0;\n\nprocess Main {\nwhile (true)\n {\n m1: &lt;#cars++&gt;;\n m2: &lt;openMainBarrier&gt;;\n m3: &lt;closeMainBarrier&gt;;\n m4: &lt;if (#cars==100)\n     break&gt;;\n }\n}\n\nprocess Overflow {\nint max; \no1: &lt;input(max)&gt;;\n while (true) \n {\n   o2: &lt;if (#cars==100-max+1)  break&gt;; \n   o3: &lt;openOverflowBarrier&gt;; \n }\n}\n</code></pre>\n  \n  <ol>\n  <li><p>The program terminates only if both processes terminate. Explain why the program may not terminate.</p></li>\n  <li><p>Explain why, even if the program does terminate, it may not operate as specified.</p></li>\n  <li><p>By introducing the use of semaphores, ensure that program does terminate and operates as specified. You must only use atomic instructions. You may introduce new additional non-semaphore variables but you must not alter the scope of #cars and max.</p></li>\n  </ol>\n</blockquote>\n\n<h3>My attempt</h3>\n\n<p>Most semaphore exercises I have looked at so far often have the main process in a <code>while(true){...}</code> infinite loop, thus, termination has never been an issue before - it is normally not addressed in these short exercises.</p>\n\n<p>It is because of this I am having difficulty trying to produce an answer for 2) and 3). The question does not even appear to address cars leaving the car park, which leads me to understand this isn't an infinite ongoing cycle type process, but will terminate when both car parks reach maximum capacity?</p>\n\n<p>In this instance, the only thing I can think of is that the process will not terminate in the event the main carpark or overflow carpark does not reach capacity, however I feel this answer is not 'clever' enough and I'm worried I may be missing something. </p>\n\n<p>I have attempted 3) as follows but I am worried this is incorrect as I'm not sure if I am supposed to handle cars leaving the car park, or if I am supposed to ignore that in order to force it to terminate.</p>\n\n<pre><code>OverflowCarPark{\nint max;\n&lt;input (max)&gt;\nwhile(true){\n down(maxFull)\n if(#cars &lt;= 100 + max){\n    down(openMainBarrier)\n    up(openOverflowBarrier)\n }\n  else { break; }\n}\n\nMainCarPark{\n&lt;cars++;&gt;\nwhile(true){\n if(#cars &lt;= 100){\n    up(openMainBarrier)\n  } else if (#cars &gt; 100 + max) { break; \n  } else { \n    up(maxFull);\n    down(openOverflowBarrier);\n }\n}\n</code></pre>\n\n<p>What is the recommended approach to dealing with termination here? </p>\n", 'ViewCount': '38', 'Title': 'Finding issues in concurrent implementation of carpark overflow control', 'LastEditorUserId': '12785', 'LastActivityDate': '2014-01-26T09:17:05.963', 'LastEditDate': '2014-01-26T02:40:05.850', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12785', 'Tags': '<algorithms><concurrency><synchronization><mutual-exclusion>', 'CreationDate': '2014-01-26T00:47:28.777', 'Id': '19977'}{'ViewCount': '273', 'Title': 'Difference between Parallel and Concurrent programming?', 'LastEditDate': '2014-01-26T17:29:35.977', 'AnswerCount': '3', 'Score': '6', 'OwnerDisplayName': 'nish1013', 'PostTypeId': '1', 'OwnerUserId': '13158', 'FavoriteCount': '1', 'Body': '<p>When looking at concurrent programming, two terms are commonly used i.e. concurrent and parallel.</p>\n\n<p>And some programming languages specifically claim support for parallel programming, such as <a href="http://www.ateji.com/px/whitepapers/Ateji%20PX%20for%20Java%20v1.0.pdf" rel="nofollow">Java</a>.</p>\n\n<p>Does this means parallel and concurrent programming are actually different?</p>\n', 'Tags': '<terminology><parallel-computing><concurrency>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-26T17:31:11.030', 'CommentCount': '6', 'CreationDate': '2014-01-24T12:20:40.377', 'Id': '19987'}{'Body': '<p><img src="http://i.stack.imgur.com/bamMN.png" alt="enter image description here"></p>\n\n<p>Here is a resource allocation graph asked in my Operating Systems Theory midterm. The question is, "Is there a deadlock here? Explain your answer in detail"</p>\n\n<p>Ra and Rb are resource sets and every dot inside of them are resources. Circles are processes. An arrow from process to a resource set means that process is requesting a resource from that set. An arrow from resource set to process means that process owns a resource from that resource set.</p>\n\n<p>I want to have your opinions on this, because the lecturer\'s answer is conflicting with mine. Lecturer says there is a deadlock here. But my answer was, since Py and Pz are not requesting a resource, they will simply continue their execution and terminate, releasing their resources. Then Px and Pw can obtain their requested resources and keep executing. It is obvious there is a cycle in this graph as Px-Pw but this doesn\'t conclude us to a deadlock. Thus I can\'t see a way to make "there is a deadlock here"conclusion. </p>\n\n<p>So is there a deadlock here?</p>\n', 'ViewCount': '179', 'Title': 'Deadlock and cycle in a resource allocation graph', 'LastEditorUserId': '39', 'LastActivityDate': '2014-02-01T13:56:33.677', 'LastEditDate': '2014-02-01T13:56:33.363', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '20137', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11579', 'Tags': '<operating-systems><concurrency><resource-allocation><deadlocks>', 'CreationDate': '2014-01-30T20:46:42.123', 'Id': '20131'}{'Body': '<p>While reading the research paper <a href="http://dl.acm.org/citation.cfm?id=2108244" rel="nofollow">Polylogarithmic Concurrent Data Structures from Monotone Circuits [@JACM\'2012]</a> by James Aspnes, Hagit Attiya, and Keren Censor-Hillel, I am not sure about some points and need some verification and explanation.  </p>\n\n<p>In the first three sections of the paper, the authors presents constructions of useful concurrent data structures, including <strong>max register</strong> and <strong>counters</strong> with bounded values, with step complexity that is <em>polylogarithmic</em> in the number of values the object can take or the number of operations applied to it. Specifically (and extremely in brief),  </p>\n\n<blockquote>\n  <p>The max register is an object $r$ supporting both <code>WriteMax(r,t)</code> and <code>ReadMax(r)</code> operations. It is recursively constructed from a tree of increasingly large max registers. The implementation is wait-free and linearizable.    </p>\n  \n  <p>The counter, supporting an <code>CounterIncrement()</code> operation and a <code>ReadCounter()</code> operation, is structured as a binary tree of max registers. The implementation is also wait-free and linearizable. </p>\n</blockquote>\n\n<p>My problems are as follows:</p>\n\n<blockquote>\n  <p>(1) <strong>On the max register:</strong> What is the space complexity, i.e., the number of base objects of multi-writer multi-reader (MWMR, for short) registers, of the recursive implementation?  </p>\n</blockquote>\n\n<p>[[<strong>In my opinion:</strong>]] It is $2m - 1$ for there is exactly one MWMR register for each node in the tree. In particular, the tree can be thought of as the logic structure of an underlying array of $2m-1$ MWMR registers.</p>\n\n<blockquote>\n  <p>(2) <strong>Also on the max register:</strong> Is it possible to implement a max register with only a single MWMR register? Are there any related work? </p>\n</blockquote>\n\n<p>[[<strong>(EDIT) In my opinion:</strong>]] I have found a <a href="http://www.cs.bgu.ac.il/~satcc112/wiki.files/Jayanti-Time-and-Space-Lower-Bounds.pdf" rel="nofollow">related paper: Time and Space Lower Bounds for Non-blocking Implementations [@PODC\'1996]</a>, in which Jayanti et al. show that </p>\n\n<blockquote>\n  <p>Operations must take $\\Omega(n)$ <strong>space</strong> and $\\Omega(n)$ steps in the worst case, for many common data structures, including (unbounded) max registers and (unbounded) counters, where $n$ is the number of concurrent processes.</p>\n</blockquote>\n\n<p>However, I have not realized similar conclusions concerning about value-bounded data structures. </p>\n\n<blockquote>\n  <p>(3) <strong>On both the max register and the counter:</strong> Are there any related work on the max&amp;min register supporting both <code>ReadMax(r)</code> and <code>ReadMin(r)</code>? Similarly, are there any related work on the inc&amp;dec counter supporting both <code>CounterIncrement()</code> and <code>CounterDecrement()</code>?</p>\n</blockquote>\n', 'ViewCount': '22', 'Title': 'Polylogarithmic value-bounded concurrent data structures such as max register, counter, and monotone circuit', 'LastEditorUserId': '4911', 'LastActivityDate': '2014-02-13T05:53:17.450', 'LastEditDate': '2014-02-13T05:53:17.450', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><data-structures><distributed-systems><concurrency>', 'CreationDate': '2014-02-12T08:03:37.973', 'Id': '21561'}{'Body': "<p>I know that this is a known theorem but I can't find its proof. The theorem is: </p>\n\n<blockquote>\n  <p>The write-contention of any $n$-process wait-free consensus algorithm (implemented from any read-modify-write operations) is $n$.</p>\n</blockquote>\n\n<p>Can someone link me to a proof or an explanation?</p>\n", 'ViewCount': '38', 'Title': 'Proof of contention of the wait-free consensus algorithm', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-12T13:30:08.410', 'LastEditDate': '2014-02-12T13:30:08.410', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14602', 'Tags': '<algorithms><reference-request><proof-techniques><concurrency>', 'CreationDate': '2014-02-12T10:02:18.260', 'Id': '21566'}{'Body': '<p><a href="http://courses.cs.vt.edu/~cs5204/fall07-kafura/Papers/TransactionalMemory/Linearizability.pdf" rel="nofollow">Linearizability</a> is a well-known correctness condition for concurrent objects.  It provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response. To prove linearizability of an implementation, it is necessary and sufficient to show that all its possible executions are linearizable with respect to some sequential specification. For this purpose, two common methods have been developed, as summarized in the paper <a href="http://dl.acm.org/citation.cfm?id=1993687" rel="nofollow">"Linearizable Implementations Do Not Suffice for Randomized Distributed Computation [@STOC\'2011]"</a>. </p>\n\n<p>However, what are typical methods for showing that some implementation is <em>not</em> linearizable? Logically, it is necessary to identify an execution which is not linearizable. But, how to achieve it? Are there some typical examples of demonstrating the non-linearizablity of an implementation in the literature?</p>\n', 'ViewCount': '30', 'Title': 'What are methods for showing that concurrent objects are not linearizable?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-18T13:05:12.033', 'LastEditDate': '2014-02-18T13:05:12.033', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><proof-techniques><concurrency>', 'CreationDate': '2014-02-18T12:24:11.333', 'Id': '21760'}{'Body': '<p><strong>Background:</strong> </p>\n\n<p>In section 4.2 of the paper <a href="http://dl.acm.org/citation.cfm?id=1993687" rel="nofollow">Linearizable Implementations Do Not Suffice for Randomized Distributed Computation@STOC\'2011</a>, the authors mentioned two typical proof strategies for linearizability of implementations. In the following, Let $O$ be the implemented object and let $H$ be a history over $O$.</p>\n\n<p>In one proof strategy, for each operation $op$ on $O$ a unique "linearization point" $pt(op)$ is assigned, which is a shared memory operation that occurs during the execution of operation $op$. A sequential history $S$ is formed by ordering the operations on $O$ in $H$ so that $op_1$ precedes $op_2$ in $S$ if and only if $pt (op_1) \\prec_{H} pt (op_2)$. The construction of $S$ guarantees agreement with the "happens before" order of operations on $O$ in $H$, and so the proof obligation for linearizability is only to show that $S$ is valid for $O$.</p>\n\n<p>In the second general proof strategy, the operations in a history $H$ are first ordered somehow into a valid sequence $S$, and the proof obligation is to show that $S$ is consistent with the "happens before"\norder of $H$. </p>\n\n<p>For instance, the practical constructions of sets and lists such as the "FineList", "OptimisticList", and "LazyList" described by Herlihy and Shavit in their book "The Art of Multiprocessor Programming" fall into the first category while the classic construction of atomic snapshot object and the implementation of atomic multi-writer register from atomic single-writer ones are in the second category.</p>\n\n<p><strong>My problems here are as follows:</strong></p>\n\n<blockquote>\n  <ol>\n  <li>Are there some implementations in the literature whose linearizability can be proved by <em>both</em> of the above-mentioned proof strategies? Such examples may be useful to help people understand and compare these two proof strategies better.</li>\n  <li>Are there any other proof strategies for linearizability used in the literature? It need not be general and can be specific to its particular problem.  </li>\n  </ol>\n</blockquote>\n', 'ViewCount': '22', 'Title': 'Proof strategies for linearizability of implementations', 'LastEditorUserId': '4911', 'LastActivityDate': '2014-02-21T02:06:02.073', 'LastEditDate': '2014-02-21T02:06:02.073', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><concurrency>', 'CreationDate': '2014-02-20T14:37:32.927', 'Id': '21847'}{'Body': '<p>In section 6.3 of the paper <a href="https://smartech.gatech.edu/bitstream/handle/1853/6781/GIT-CC-93-55.pdf" rel="nofollow">Causal memory: definitions, implementations, and programming</a>, the authors define "data-race free" as follows:</p>\n\n<blockquote>\n  <p>Program $\\Pi$ is data-race free if, for all histories $H$ of $\\Pi$ and all causality orders $\\leadsto$ of $H$, if $H$ has a serialization that respects $\\leadsto$ (note that this implies that $H$ is sequentially consistent), then $H$ is data-race free with respect to $\\leadsto$.</p>\n</blockquote>\n\n<p>The one-sentence definition is too complicated for me to follow. It involves various notions and their relations. Specifically, a program is a set of its histories. Given a history, there may be more than one causality order for it, because there may be multiple writes of a value to a variable and thus more than one writes-into order. Let $H$ be a history with causality order $\\leadsto$. We have to consider whether it is sequentially consistent and data-race free with respect to $\\leadsto$.</p>\n\n<p>The following image enumerates all the possible classes of executions <em>which I can think of</em> produced by any program. The red crosses in the image indicate non-existence. For instance, the "path" $\\Pi - H_1 - \\leadsto_{12} - S_{12} - DRF_{12}$ means that $S_{12}$ is a serialization (thus sequentially consistent) of history $H_1$ that respects $\\leadsto_{12}$ but is not data-race free with respect to $\\leadsto_{12}$.</p>\n\n<p><img src="http://i.stack.imgur.com/cW61x.png" alt="data-race free"></p>\n\n<p><strong>EDIT: Here are some explanations of this image.</strong> For any program, there are five possible <em>classes of executions</em>. $H_0$ indicates the class of executions which have no causality orders at all (i.e., it causality orders are cyclic). The executions like $H_1$ have more than one causality orders, such as $\\leadsto_{11}, \\leadsto_{12},$ and $\\leadsto_{13}$. However, $H_1$ (as a representative of its class) is not sequentially consistent respecting $\\leadsto_{11}$ (denoted by the red cross over $S_{11}$); $H_1$ is sequentially consistent respecting $\\leadsto_{12}$ but is not data-race free with respect to $\\leadsto_{12}$ (denoted by the red cross over $DRF_{12}$); and $H_1$ is sequentially consistent respecting $\\leadsto_{13}$ and is data-race free with respect to $\\leadsto_{13}$. The cases for $H_2$, $H_3$, and $H_4$ are similar.</p>\n\n<p>Here comes my first problem:</p>\n\n<blockquote>\n  <p>(1). What are the classes of executions excluded by "data-race free"? (and does the image miss some classes of executions?)</p>\n  \n  <p><em>In my opinion,</em> only the executions like $H_1$ are excluded. The reason is that the "path" $\\Pi - H_1 - \\leadsto_{12} - S_{12} - DRF_{12}$ violates the definition of "data-race free".</p>\n</blockquote>\n\n<hr>\n\n<p>Immediately following the definition of data-race free, the authors show that data-race free programs produce only sequential consistent executions when run on causal memory:</p>\n\n<blockquote>\n  <p><strong>Theorem 5.</strong> If $\\Pi$ is data-race free, then all histories of $\\Pi$ with causal memory are sequentially consistent.</p>\n</blockquote>\n\n<p>In the first paragraph of its proof, it says that "Let $H$ be a finite (infinite) causal history and let $\\leadsto$ be a causality order that proves that $H$ is causal. We will prove that $H$ is data-race free with respect to $\\leadsto$ and has a serialization that respects $\\leadsto$". </p>\n\n<p>Here come my other two problems:</p>\n\n<blockquote>\n  <p>(2). Back to the image above, does the theorem mean that when run on causal memory data-race free programs produce only the executions like $H_3$ which are <em>both sequentially consistent and data-race free</em> with respect to <strong>each</strong> of its causality orders?</p>\n  \n  <p>(3). If so, is it right to conclude that the executions produced by data-race free programs when run on causal memory actually satisfy some stronger consistency model (though not formally defined) than sequentially consistent model?</p>\n</blockquote>\n\n<p>Besides the answers to my problems, any personal (or even subjective) comments worthy of note on the definition "data-race free" are appreciated.</p>\n', 'ViewCount': '59', 'Title': '"Data-race free" programs', 'LastEditorUserId': '4911', 'LastActivityDate': '2014-03-02T06:05:59.563', 'LastEditDate': '2014-03-02T06:05:59.563', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<terminology><parallel-computing><concurrency>', 'CreationDate': '2014-03-01T14:43:42.677', 'Id': '22158'}{'Body': '<p>In section 17.4.5 <a href="http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5" rel="nofollow">"Happens-before Order" of Java Language Specification</a>, a trace is examined for the notion of happens-before consistency. </p>\n\n<p>The trace is shown in the figure in which $A$ and $B$ are shared variables with initially $A = B = 0$. </p>\n\n<p><img src="http://i.stack.imgur.com/NXND7.png" alt="trace"></p>\n\n<p>An execution order of the trace is as follows. </p>\n\n<p><img src="http://i.stack.imgur.com/JvbFI.png" alt="executionorder"></p>\n\n<p>In this execution, the reads see writes that occur later in the execution order. The document says that it is happens-before consistent. I am quite confused about this. In my opinion, this execution order does not even satisfy program order. Why is it happens-before consistent?  </p>\n', 'ViewCount': '17', 'Title': 'Why is this execution happens-before consistent?', 'LastActivityDate': '2014-03-03T14:20:30.233', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<programming-languages><parallel-computing><concurrency>', 'CreationDate': '2014-03-03T14:20:30.233', 'Id': '22220'}{'ViewCount': '32', 'Title': 'If a thread containing main terminates, can another thread do anything?', 'LastEditDate': '2014-03-29T20:42:43.353', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11711', 'FavoriteCount': '1', 'Body': '<p>I\'m studying threads in C and I have this theoretical question in mind that is driving me crazy.\nAssume the following code:</p>\n\n<pre><code>1) void main() {\n2)     createThread(...); // create a new thread that does "something"\n3) }\n</code></pre>\n\n<p>After line 2 is executed, two paths of execution are created. However I believe that immediately after line 2 is executed then it doesn\'t even matter what the new thread does, which was created at line 2, because the original thread that executed line 2 will end the entire program at its next instruction. Am I wrong? is there any chance the original thread gets suspended somehow and the new thread get its chance to do something (assume the code as is, no sync between threads or join operations are performed)</p>\n', 'Tags': '<parallel-computing><concurrency><threads>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-29T20:42:43.353', 'CommentCount': '1', 'AcceptedAnswerId': '23136', 'CreationDate': '2014-03-27T15:08:12.743', 'Id': '23129'}{'Body': '<p>I am currently reading <a href="https://www.kernel.org/doc/ols/2002/ols2002-pages-479-495.pdf">Fuss, Futexes and Furwocks: Fast Userland Locking in Linux</a> and came across this quote:</p>\n\n<blockquote>\n  <p>In a fair locking scheme the lock is granted in the order it was\n  requested. This can have negative impact on throughput due to the\n  increased number of context switches. At the same time it can lead to\n  the so called convoy problem. Since the locks are granted in the order\n  of arrival, they all proceed at the speed of the slowest process,\n  slowing down all waiting processes. A common solution to the convoy\n  problem has been to mark the lock available upon release, wake all\n  waiting processes and have them recontend for the lock. This is\n  referred to as random fairness. However, this also leads to the\n  thundering herd problem. Despite this, it can work well on\n  uni-processor systems if the first task to wake releases the lock\n  before being preempted or scheduled, allowing the second herd member\n  to obtain the lock, etc...</p>\n</blockquote>\n\n<p>I have a few questions about this quote.</p>\n\n<p>First, does a fair locking scheme result in an increased number of context switches because different tasks put processes into the wait queue at different times and thus by serving processes in the order they were received, we\'d be context switching between multiple tasks?</p>\n\n<p>Second, how does granting locks in the order of arrival cause processes to proceed at the speed of the slowest process? Wouldn\'t this only be the case if the slowest process is granted the lock before the other processes? Similarly, how does having processes contending randomly for the lock solve the convoy problem?</p>\n\n<p>Finally, I don\'t understand how random fairness is any better on uni-processor systems in comparison to multiprocessor systems. For example, in both cases, all of the waiting processors are woken up, one gets the lock, and the others have to go to sleep again, right? So how does this work well on uni-processor systems?</p>\n', 'ViewCount': '81', 'Title': 'Question about threads and locks', 'LastActivityDate': '2014-04-14T21:09:55.147', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '23798', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '16760', 'Tags': '<concurrency><threads>', 'CreationDate': '2014-04-14T15:12:48.010', 'FavoriteCount': '1', 'Id': '23785'}{'Body': "<p>Consider the following program:</p>\n\n<pre><code>const int n = 50;\nint tally;\n\nvoid total() {\n  int count;\n  for (count = 1; count &lt;= n; count++){\n    tally++;\n  }\n}\n\nvoid main() {\n  tally = 0;\n  parbegin (total (), total ());\n  write (tally);\n}\n</code></pre>\n\n<blockquote>\n  <ol>\n  <li><p>Determine the proper lower bound and upper bound on the final value of the\n  shared variable tally output by this concurrent program.Assume processes can execute\n  at any relative speed and that a value can only be incremented after it has\n  been loaded into a register by a separate machine instruction.</p></li>\n  <li><p>Suppose that an arbitrary number of these processes are permitted to execute in\n  parallel under the assumptions of part (a).What effect will this modification have\n  on the range of final values of tally?</p></li>\n  </ol>\n</blockquote>\n\n<p>My problem is that I don't understand the question what does this mean ?</p>\n\n<blockquote>\n  <p>... and that a value can only be incremented after it has been loaded into a register by a separate machine instruction.</p>\n</blockquote>\n\n<p>I feel that when two processes execute simultaneously due to this assumption some value of tally will be lost but I don't know how it can happen because I don't know what this assumption means so I can't find lower bound!it is obvious that if 2 or n process execute one after the other tally will be 100 hence 100 = (number of process *50) is upper bound!</p>\n", 'ViewCount': '72', 'Title': "What does it mean that a value can only be incremented after it's been loaded into a register?", 'LastEditorUserId': '98', 'LastActivityDate': '2014-05-03T08:40:59.377', 'LastEditDate': '2014-04-30T17:24:13.493', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '17217', 'Tags': '<terminology><concurrency><semantics>', 'CreationDate': '2014-04-30T14:01:31.777', 'FavoriteCount': '0', 'Id': '24255'}