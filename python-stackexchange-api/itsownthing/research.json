{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I know that since ~2004, Moore's law stopped working for CPU clock speed.\nI'm looking for a graph showing this, but am unable to find it: most charts out there show the transistor count or the capacity per year.</p>\n\n<p>Where can I find some data showing the CPU frequency of computers (anything is fine, personal computers, servers, laptops, ...) from the last few decades to today?<br>\nRaw data that I can plot myself would be fine as well (hum, probably even better).</p>\n", 'ViewCount': '1715', 'Title': 'CPU frequency per year', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:21:22.313', 'LastEditDate': '2012-04-22T16:21:22.313', 'AnswerCount': '4', 'CommentCount': '5', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '489', 'Tags': '<computer-architecture><empirical-research><data-sets>', 'CreationDate': '2012-03-21T10:27:51.997', 'FavoriteCount': '2', 'Id': '594'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '2545', 'Title': 'How are statistics being applied in computer science to evaluate accuracy in research claims?', 'LastEditDate': '2014-02-08T00:50:08.267', 'AnswerCount': '4', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '983', 'FavoriteCount': '3', 'Body': '<p>I have noticed in my short academic life that many published papers in our area sometimes do not have much rigor regarding statistics. This is not just an assumption; I have heard professors say the same. </p>\n\n<p>For example, in CS disciplines I see papers being published claiming that methodology X has been observed to be effective and this is proved by ANOVA and ANCOVA, however I see no references for other researchers evaluating that the necessary constraints have been observed. It somewhat feels like as soon as some \'complex function and name\' appears, then that shows the researcher is using some highly credible method and approach that \'he must know what is he doing and it is fine if he does not describe the constraints\', say, for that given distribution or approach, so that the community can evaluate it. </p>\n\n<p>Sometimes, there are excuses for justifying the hypothesis with such a small sample size. </p>\n\n<p>My question here is thusly posed as a student of CS disciplines as an aspirant to learn more about statistics: How do computer scientists approaches statistics? </p>\n\n<p>This question might seems like I am asking what I have already explained, but that is my <em>opinion</em>. I might be wrong, or I might be focusing on a group of practitioners whereas other groups of CS researchers might be doing something else that follows better practices with respect to statistics rigor. </p>\n\n<p>So specifically, what I want is "Our area is or is not into statistics because of the given facts (papers example, books, or another discussion article about this are fine)". @Patrick answer is closer to this. </p>\n', 'Tags': '<software-engineering><empirical-research><statistics>', 'LastEditorUserId': '472', 'LastActivityDate': '2014-02-08T17:39:10.957', 'CommentCount': '4', 'AcceptedAnswerId': '1101', 'CreationDate': '2012-04-07T01:53:58.053', 'Id': '1100'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was interested on evaluating a catalogue that students would be using to observe how is it being used probabilistically. </p>\n\n<p>The catalogue works by choosing cells in a temporal sequence, so for example:</p>\n\n<ul>\n<li>Student A has: ($t_1$,$Cell_3$),($t_2$,$Cell_4$)</li>\n<li>Student B has: $(t_1,Cell_5),(t_2,Cell_3),(t_3,Cell_7)$. </li>\n</ul>\n\n<p>Assume that the cells of the table are states of a <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Model</a>, so the transition between states would map in the real world to a student going from a given cell to another.</p>\n\n<p>Assuming that the catalogue is nothing more than guidance, it is expected to have a certain kind of phenomenon to occur on a given artifact. Consider this artifact to be unique, say, for example a program. </p>\n\n<p>What happens to this program is a finite list of observations, thus, for a given cell we have a finite list of observations for following the suggestion mentioned on that cell. On a HMM this would be then the probability associated to a state to generate a given observation in this artifact. </p>\n\n<p>Finally, consider the catalogue to be structured in a way that initially it is expected that the probability to start in a given cell is equal. The catalogue does not suggest any starting point. </p>\n\n<ul>\n<li><p><strong>Question 1</strong>: Is the mapping between the catalogue and the HMM appropriate?</p></li>\n<li><p><strong>Question 2</strong>: Assuming question 1 holds true. Consider now that we train the HMM using as entries $(t_1,Cell_1), (t_2,Cell_3) , ... (t_n,Cell_n)$ for the students. Would the trained HMM, once asked to generate the transition between states that it is most likely yields as result what is the most used way by the people who used the catalogue for a given experiment $\\epsilon$? </p></li>\n</ul>\n', 'ViewCount': '74', 'Title': 'Is it viable to use an HMM to evaluate how well a catalogue is used?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-19T02:04:32.233', 'LastEditDate': '2012-04-22T16:09:37.950', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '1132', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<probability-theory><empirical-research><modelling><hidden-markov-models>', 'CreationDate': '2012-04-07T23:04:00.013', 'Id': '1122'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am wondering if there are any experiments that show the existence or the non-existence of a correlation between usage of a dynamic language (such as Python, Ruby, or even languages that run on the Java platform such as Groovy, Clojure) over a static language (such as C/C++), and the difference in the productivity.</p>\n', 'ViewCount': '298', 'Title': 'Is there evidence that using dynamic languages has an impact on productivity?', 'LastEditorUserId': '5', 'LastActivityDate': '2014-01-21T16:55:55.333', 'LastEditDate': '2012-05-26T15:14:02.587', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '5', 'Tags': '<programming-languages><empirical-research><software-engineering>', 'CreationDate': '2012-04-09T00:54:11.487', 'FavoriteCount': '4', 'Id': '1150'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>This question might seems vague but heres the context:</p>\n\n<p>When we are focusing on HCI we would most likely be interested on knowing first how the user usually deals with a certain object. We then try to see how our system could take away one of the tasks he would do himself and try to do it itself. </p>\n\n<ul>\n<li><p>The object of my interest here is a simple paper catalogue. How would you measure its usability (paper one). </p></li>\n<li><p>Then, how would you map it to a system interface? How would you measure the usability now on the system?</p></li>\n<li><p>How would you compare the two usabilities measures?</p></li>\n</ul>\n\n<p>This question narrows down this approach which is suggested on Stones book - User Interface and Evaluation. </p>\n\n<p>What the catalogue is about is not the point, that why I left it without a description: To avoid suggestions trying to measure what the catalogue is about. My focus here is on the particular mapping of this kind of object on the real world as a simple paper and when it is mapped to a system interface. Assume the catalogue to consist of rows and tables, where each matching row and table gives you a suggestion and you must first reason about each row and each column to see if it suits you (Perhaps you would suggest another template for the catalogue?).</p>\n', 'ViewCount': '50', 'Title': 'How can I measure the usability of a catalogue?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:07:59.883', 'LastEditDate': '2012-04-22T16:07:59.883', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '1173', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<empirical-research><modelling><hci>', 'CreationDate': '2012-04-09T06:58:17.557', 'Id': '1154'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm starting my mater's thesis in computer science. I'm interested in computational Origami (algorithms mainly); I've read a little about the subject and I'm worried because I lack some of the knowledge that I think is necessary to do research in that area. But still I'd like to start and want to ask: which is better an approach: learn the necessary background as I go and wheneve a necessity pops up or learn it first and then start. I have 4 to 5 months to finish my thesis.</p>\n", 'ViewCount': '217', 'Title': 'Acquiring the necessary background for research', 'LastActivityDate': '2013-01-28T01:11:33.087', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '9073', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2499', 'Tags': '<research>', 'CreationDate': '2013-01-21T13:50:33.913', 'FavoriteCount': '2', 'Id': '9072'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '147', 'Title': "Where can I find a short and 'easy' peer reviewed paper on something from computability, decidability or complexity?", 'LastEditDate': '2013-01-26T20:49:07.570', 'AnswerCount': '5', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6572', 'FavoriteCount': '2', 'Body': "<p>It's a homework assignment, we were asked to read, understand, and present to our colleagues a short paper/article (suggested 4-6 pages) for our Computability, Decidability or Complexity class.</p>\n\n<p>The articles I was able to find in the past couple days using google scholar a way over what we were taught, plus, 50-100+ pages is way over the scope of my assignment. In class, we were provided with an introduction to the three topics, complexity classes, relations between them, and (mostly informal) proofs for the most representative problems from each class by modelling them using all kinds of Turing Machines.</p>\n\n<p>Any possible solutions? It's the first time in my life I'm touching anything related to research, I can barely understand even the scope of most papers I find.. I guess any advice would be welcome.</p>\n", 'Tags': '<complexity-theory><computability><turing-machines><research>', 'LastEditorUserId': '6572', 'LastActivityDate': '2013-01-30T15:17:09.530', 'CommentCount': '0', 'AcceptedAnswerId': '9179', 'CreationDate': '2013-01-26T20:36:18.643', 'Id': '9178'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What are some research papers which are really fundamental and led to the birth of a new field of study or a novel idea in Computer-Science?</p>\n', 'ViewCount': '133', 'ClosedDate': '2013-02-18T11:35:08.297', 'Title': 'Research papers in Computer Science', 'LastActivityDate': '2013-02-20T04:24:20.527', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2822', 'Tags': '<reference-request><research>', 'CreationDate': '2013-02-18T04:42:13.227', 'Id': '9883'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am running some experiments with a maze, and trying different variations of A*. Based on my experiments, I have been able to form some opinion (that at least in those cases, graph checking is better than IDA). </p>\n\n<p>I am looking for online articles that have done similar experiments, comparing variations of A* with respect to expanded nodes, but have not come across anything concrete.</p>\n', 'ViewCount': '81', 'Title': 'Comparing variations of A*', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:52:54.573', 'LastEditDate': '2013-04-08T14:52:54.573', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '11136', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6966', 'Tags': '<algorithms><reference-request><artificial-intelligence><search-algorithms><empirical-research>', 'CreationDate': '2013-04-05T22:21:35.823', 'Id': '11067'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I have developed two existing data structures and I want to see their performances over a certain algorithm. In this case I use Dijkstra's algorithm with binary and Fibonacci heaps. Just to ask, if I have 100 to 1000 number of vertices in the tested sparse digraphs, how many times should I execute my program for a single n vertices? How do I know that the empirical differences in performance that I've obtained between data structures are not due to chance?</p>\n", 'ViewCount': '69', 'Title': 'performance between the data structures', 'LastEditorUserId': '4736', 'LastActivityDate': '2013-04-29T09:50:43.620', 'LastEditDate': '2013-04-29T09:50:43.620', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7956', 'Tags': '<data-structures><priority-queues><performance><empirical-research>', 'CreationDate': '2013-04-29T04:33:05.927', 'Id': '11651'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is there a common code metric for "code redundancy" or "code cloning"?</p>\n\n<p>I think I read somewhere a definition, where the LOC (lines of code) of\nthe redundant code was measured.</p>\n\n<p>I also searched for references, but didn\'t find a paper that seemed like an good or trustworthy reference.</p>\n', 'ViewCount': '44', 'Title': 'Code metric for code redundancy or code cloning', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-05-09T01:46:25.000', 'LastEditDate': '2013-05-09T01:46:25.000', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><empirical-research>', 'CreationDate': '2013-05-08T00:29:13.067', 'FavoriteCount': '2', 'Id': '11872'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For my thesis, I have created a development approach (consisting of schemes, an application template and prototype code) that should make it easier to develop and adapt applications for a specific platform.</p>\n\n<p>I have conducted interviews with developers of that platform to evaluate my approach. There where 5 interviewees and the feedback that I got from them is sufficient for my scope, I would say.</p>\n\n<p>However, in my thesis I would like to justify my decision that 5 evaluators are enough. Is there any scientific research or paper that suggests a certain number of evaluators for such a rather theoretical approach?</p>\n\n<p>I know <a href="http://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/" rel="nofollow">Nielsen\'s work about heuristic usability evaluation</a> which says that with 5 participants, you discover around 75% of all problems in <em>software usability / UI testing</em>.</p>\n\n<p>But as I said, my approach is no specific software product that has to be evaluated, but only the model itself, which is why I\'m looking for research in that area.</p>\n', 'ViewCount': '58', 'Title': 'Ideal number of participants for evaluation of development approach / software architecture', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T10:27:33.920', 'LastEditDate': '2013-09-02T10:25:45.363', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '8450', 'Tags': '<reference-request><software-engineering><empirical-research>', 'CreationDate': '2013-05-30T18:52:54.170', 'Id': '12378'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm looking for empirical papers which investigate if a user can benefit from Q&amp;A sites like Stack Overflow. I welcome any papers related to this topic, e.g: </p>\n\n<ul>\n<li>an experiment, investigating if a specific task can be executed faster,</li>\n<li>an analysis, investigating if a user understands the solutions on Q&amp;A sites or if he just does copy&amp;paste without thinking about it,</li>\n<li>a comparative analysis of the code quality of users with access to Q&amp;A sites in contrast to users without internet access (but just offline documentation of APIs).</li>\n</ul>\n", 'ViewCount': '112', 'Title': 'Empirical studies about benefits of Q&A sites for programming', 'LastEditorUserId': '1636', 'LastActivityDate': '2014-01-24T14:29:31.617', 'LastEditDate': '2013-07-04T01:32:24.893', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8988', 'Tags': '<reference-request><software-engineering><empirical-research><social-networks>', 'CreationDate': '2013-07-03T11:36:45.447', 'Id': '13056'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am doing bachelors in Electronics &amp; Communication Engg.. But most of my work happened to be in Web development.. I am thinking to do my bachelor thesis which very closely overlaps with my recent work.</p>\n\n<p>Are there any specific areas in CS, EE (may be Computer Networking in broad terms) that I can take up? </p>\n', 'ViewCount': '47', 'Title': 'What areas in EE overlap closely with CS', 'LastEditorUserId': '8079', 'LastActivityDate': '2013-10-02T17:03:51.437', 'LastEditDate': '2013-10-02T15:19:10.950', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8079', 'Tags': '<computer-networks><research>', 'CreationDate': '2013-10-02T14:36:18.053', 'Id': '14753'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am considering strategies to compare the performance of routers with buffers vs. their lower latency counterparts in a simple network setting (N clients communicating with each other randomly through a router). I know that buffered routers should ideally perform better when there are traffic bursts.</p>\n\n<p>My question is regarding my concern which is that I do not know what is a good strategy to pick scenarios and how could I convey that these models are relevant to common real world situations. So the question would be:</p>\n\n<ol>\n<li>How to pick scenarios that are similar to real world situations?</li>\n<li>How to convince that these scenarios are indeed relevant to real\nworld situations.</li>\n</ol>\n\n<p>My main concern is measuring the benefit of buffers vs. an improvement in RRT (lower latency) with varying levels of congestion. Also showing possible disadvantages where the amounts of congestion are overwhelming (buffer bloat) and possibly other patterns.</p>\n', 'ViewCount': '29', 'ClosedDate': '2014-04-01T22:04:17.640', 'Title': 'Buffering packets vs. low latency routing', 'LastEditorUserId': '14875', 'LastActivityDate': '2014-02-21T10:18:53.960', 'LastEditDate': '2014-02-21T10:18:53.960', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14875', 'Tags': '<computer-networks><empirical-research><routing>', 'CreationDate': '2014-02-20T09:28:32.287', 'Id': '21840'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Phase space learning <a href="http://cseweb.ucsd.edu/users/gary/pubs/nips94.pdf" rel="nofollow">Paper1</a> and <a href="http://gliamac.mit.edu/people/seung/papers/continuous.pdf" rel="nofollow">Paper2</a> in neural network represents the input  in higher dimension in auto associative learning. So, the network functions as an auto-associative memory where dynamical attractors are fixed points, each corresponding to one of the patterns that we want to store in the network. If the network has 3 input nodes, the the number of outputs will also be 3. Thus, for a time instant, $t$ Input is a vector. </p>\n\n<p>The Authors mention that a trajectory is traced out. In my case, for every time instant I have a feature vector of dimension 3 i.e there are three features. In my opinion, for every time step, t a learning algorithm is used to update the weights. Also. the Authors mention delay embedding for time series reconstruction which is an essential point in any phase space representation. Based on these, the following concepts are unclear and I will be thankful for an intuitive explanation. </p>\n\n<p>Q1. How come a feature vector is delay embedded and a trajectory is formed since we have only one example at every time instant? </p>\n\n<p>Q2. I will appreciate ideas in how to apply phase space learning with particle Swarm optimization and the objective function is the mean square error between the actual output of the network and the target. In my application, I only have the final target vector not a target vector for every time step. </p>\n', 'ViewCount': '14', 'Title': 'Supervised learning based on phase space representation', 'LastEditorUserId': '10583', 'LastActivityDate': '2014-03-11T03:06:09.200', 'LastEditDate': '2014-03-11T03:06:09.200', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10583', 'Tags': '<machine-learning><neural-networks><pattern-recognition><research>', 'CreationDate': '2014-03-11T02:56:38.210', 'Id': '22489'}},