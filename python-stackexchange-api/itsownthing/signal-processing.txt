{'Body': u'<p>I\'m reading <a href="http://bero.freqvibez.net/public/segs/icassp03_senseg.pdf" rel="nofollow">\u201cSpeech segmentation without speech recognition\u201d by Dong Wang, Lie Lu and Hong-Jiang Zhang</a>.\nThe algorithm I\'m looking at is a V/C/P (Vowel/Consonant/Pause) classification algorithm on a digital speech signal. It is described as such:</p>\n\n<ol>\n<li><p>Audio data is segmented into 20ms-long non-overlapping frames, \nwhere features, including ZCR, Energy and Pitch, are extracted.  </p></li>\n<li><p>Energy and pitch curve is smoothed. </p></li>\n<li><p>The  <code>Mean_En</code> and  <code>Std_En</code> of energy curve are calculated to \ncoarsely estimate the background noise energy level, as: </p>\n\n<pre><code>NoiseLevel = Mean_En - 0.75 Std_En. \n</code></pre>\n\n<p>Similarly the threshold of ZCR (<code>ZCR_dyna</code>) is defined as: </p>\n\n<pre><code>ZCR_dyna = Mean_ZCR + 0.5 Std_ZCR\n</code></pre></li>\n<li><p>Frames are classified as V/C/P coarsely by using the following \nrules, where FrameType is used to denote the type of each frame. </p>\n\n<pre><code>If ZCR &gt; ZCR_dyna then FrameType = Consonant \nElse if Energy &lt; NoiseLevel, then  FrameType = Pause \nElse FrameType = Vowel   \n</code></pre></li>\n<li><p>Update the <code>NoiseLevel</code> as the weighted average energy of the \nframes at each vowel boundary and the background segments. </p></li>\n<li><p>Re-classify the frames using algorithm in step 4 with the updated \n<code>NoiseLevel</code>. Pauses are merged by removing isolated short \nconsonants. Vowel will be split at its energy valley if its duration is \ntoo long  </p></li>\n</ol>\n\n<p>I do not understand step #5. Like I don\'t know how to interpret the wording - is there another way to describe what they are doing? I get that we want to update the <code>NoiseLevel</code> variable and re-run step #4 for every frame, I just don\'t understand how exactly. </p>\n', 'ViewCount': '49', 'Title': 'Help understanding an audio processing algorithm', 'LastEditorUserId': '39', 'LastActivityDate': '2013-02-05T20:16:13.140', 'LastEditDate': '2013-02-05T20:16:13.140', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6720', 'Tags': '<algorithms><machine-learning><natural-lang-processing><signal-processing>', 'CreationDate': '2013-02-05T16:56:55.613', 'Id': '9513'}{'Body': '<p>Assume I have producer and consumer in a monitor.</p>\n\n<ol>\n<li><p>The code of the consumer signals the producer and then does something else.\nI know in a Hoare-style monitor, after signaling, the thread that is signaled wakes up and is is now schedule.\nWhat about the other instructions in the consumer after the signal? When will the consumer continue?</p></li>\n<li><p>What if the consumer sends the signal before the producer does the wait?   Will the producer be stuck forever?</p></li>\n<li><p>If there is a context switch will the mutex of the monitor be released?</p></li>\n</ol>\n', 'ViewCount': '135', 'Title': 'Hoare\'s monitor - what happens after a "signal"', 'LastEditorUserId': '7459', 'LastActivityDate': '2013-11-22T15:17:37.353', 'LastEditDate': '2013-07-24T13:53:35.177', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8546', 'Tags': '<operating-systems><signal-processing>', 'CreationDate': '2013-07-24T10:47:58.260', 'Id': '13416'}{'Body': "<p>I'm looking for an actual definition of a stream processing unit (SPU), preferably sourced. The context is not specifically graphics cards.</p>\n\n<p>I can find many, many articles explaining what they contain, or what they do in specific cases, but I need a definition for an informal class presentation. I have a general sense of what they are, but can't find much literature to back that up. However, even an informal definition would help.</p>\n\n<p>Would really appreciate any input.</p>\n", 'ViewCount': '31', 'Title': 'Stream processor definition', 'LastActivityDate': '2013-10-26T19:26:32.913', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10991', 'Tags': '<parallel-computing><graphics><signal-processing>', 'CreationDate': '2013-10-26T19:26:32.913', 'FavoriteCount': '1', 'Id': '16452'}{'ViewCount': '109', 'Title': 'Which algorithms are usable for heatmaps and what are their pros and cons', 'LastEditDate': '2013-11-28T08:26:17.133', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11126', 'FavoriteCount': '1', 'Body': '<p>This is a <a href="http://stackoverflow.com/questions/19765076/which-algorithms-are-usable-for-heatmaps-and-what-are-their-pros-and-cons">cross post from Stack Overflow,</a> and <a href="http://dsp.stackexchange.com/questions/11463/which-algorithms-are-usable-for-heatmaps-and-what-are-their-pros-and-cons">DSP at Stackexchange</a> since I cannot really decide which part of Stackexchange is most fitting. If this is the wrong place please tell me and I\'ll remove the question.</p>\n\n<p>I have a matrix with numerical data. The matrix contains values from 0 to an arbitrary integer value.</p>\n\n<p>Each element of the matrix is equivalent to a coordinate on a map.</p>\n\n<p>I want to display that data as a heatmap overlayed the original map.</p>\n\n<p>The three approaches I have found so far are </p>\n\n<ol>\n<li><p>Linear interpolation. I guess the interpolation is don from the original datapoint to some set distance away from it in each direction. </p></li>\n<li><p>Average of surrounding cells. Each empty cell gets the average value of the eight adjacent cells. </p></li>\n<li><p>Gaussian blur as suggested on the SO thread.</p></li>\n<li><p>Box blur with 1..n passes.</p></li>\n</ol>\n\n<p>Are there any more methods? What are the pros and cons of the different approaches? What is a good source, online or print, for a discussion on heatmaps or similar problems?</p>\n', 'Tags': '<algorithms><image-processing><matrices><signal-processing>', 'LastEditorUserId': '11126', 'LastActivityDate': '2013-11-28T08:26:17.133', 'CommentCount': '6', 'AcceptedAnswerId': '18422', 'CreationDate': '2013-11-04T09:51:03.010', 'Id': '16699'}{'Body': '<p>I thought the Gibbs phenomenom is the result of Fourier analysis estimation (but was it Fourier Series estimation or can it also be Fourier Transform estimation?)</p>\n\n<p><img src="http://i.stack.imgur.com/A1Vt2.png" alt="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Gibbs_phenomenon_50.svg/285px-Gibbs_phenomenon_50.svg.png"></p>\n\n<p>JPEG uses the Discrete cosines Transform. A DCT is similar to a Fourier transform in the sense that it produces a kind of spatial frequency spectrum.</p>\n\n<p><img src="http://i.stack.imgur.com/H2AuR.jpg" alt="JPEG example JPG RIP 001.jpg  Lowest quality"> </p>\n\n<p>But what are the differences between the Gibbs phenomenom artefacts from Fourier and the artefacts from the Discrete Cosine?</p>\n', 'ViewCount': '32', 'Title': 'What are all the differences between the Gibbs phenomenon artefects and JPEG artefacts?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-31T02:14:05.370', 'LastEditDate': '2014-03-28T12:46:38.770', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '16228', 'Tags': '<image-processing><data-compression><graphics><signal-processing>', 'CreationDate': '2014-03-28T08:56:20.763', 'Id': '23169'}