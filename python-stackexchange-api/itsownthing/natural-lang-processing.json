{'ViewCount': '177', 'Title': 'Identifying events related to dates in a paragraph', 'LastEditDate': '2012-03-17T16:51:17.110', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '191', 'FavoriteCount': '1', 'Body': '<p>Is there an <s><em>algorithmic</em></s> approach to identify that dates given in a paragraph correlate to particular events (phrases) in the paragraph?</p>\n\n<p>Example, consider the following paragraph:</p>\n\n<blockquote>\n  <p>In June 1970, the great leader took the oath. But it was only after May 1972, post the death of the Minister of State, that he took over the reins of the country. While he enjoyed popular support until Mid-1980, his influence began to fall thereafter.</p>\n</blockquote>\n\n<p>Is there an algorithm (deterministic or stochastic)# that can generate a 2-tuple (date, event), where the <em>event</em> is implied, by the paragraph, to have occured on the <em>date</em>? In the above case:</p>\n\n<ul>\n<li>(June 1970, great leader took oath)</li>\n<li><p>(May 1972, took over the reins)   </p>\n\n<p>or better yet</p></li>\n<li>(May 1972, <em>the great leader</em> took over the reins)</li>\n<li>(1980, fall in influence)  </li>\n</ul>\n\n<hr>\n\n<p>#Later addition</p>\n', 'Tags': '<algorithms><data-mining><natural-lang-processing>', 'LastEditorUserId': '191', 'LastActivityDate': '2012-03-17T18:56:43.870', 'CommentCount': '6', 'AcceptedAnswerId': '474', 'CreationDate': '2012-03-11T17:29:14.580', 'Id': '221''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>It seems as though modern speech recognition (e.g., through Android, iOS phones) make use of grammar or sentence structure. (e.g., it might have a tough time distinguishing between "grammar" and "grandma" but can distinguish between "I\'m going to see grandma" and "I\'m reading a book on english grammar". (yes, I just tried it with my Android phone with vLingo app)</p>\n\n<p>That is much improved (with Speaker Independent SR (i.e., no training)) over what I experienced with Dragon Dictate even using Speaker Dependent SR (with 30m of training).</p>\n\n<p>So, I\'m wondering whether my guess is right: When did the commercially available SR software start using grammar and sentence structure to "guess" the right speech?</p>\n', 'ViewCount': '98', 'Title': 'When did commercial Speech Recognition first begin using grammar (sentence structure) for prediction?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-06T23:23:33.617', 'LastEditDate': '2012-04-06T23:23:33.617', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '972', 'Tags': '<natural-lang-processing><history>', 'CreationDate': '2012-04-06T15:51:14.253', 'Id': '1079''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '753', 'Title': 'Finding interesting anagrams', 'LastEditDate': '2012-06-07T22:08:29.743', 'AnswerCount': '4', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '1786', 'FavoriteCount': '0', 'Body': "<p>Say that $a_1a_2\\ldots a_n$ and $b_1b_2\\ldots b_n$ are two strings of the same length.  An <strong>anagramming</strong> of two strings is a bijective mapping $p:[1\\ldots n]\\to[1\\ldots n]$ such that $a_i = b_{p(i)}$ for each $i$.</p>\n\n<p>There might be more than one anagramming for the same pair of strings.  For example, If $a=$<code>abcab</code> and $b=$<code>cabab</code> we have $p_1[1,2,3,4,5]\\to[4,5,1,2,3]$ and $p_2[1,2,3,4,5] \\to [2,5,1,4,3]$, among others.</p>\n\n<p>We'll say that the <strong>weight</strong> $w(p)$ of an anagramming $p$ is the number of values of $i\\in[1\\ldots n-1]$ for which $p(i)+1\\ne p(i+1)$. That is, it is the number of points at which $p$ does <em>not</em> increase by exactly 1.For example, $w(p_1) = 1$ and $w(p_2) = 4$.</p>\n\n<p>Suppose there exists an anagramming for two strings $a$ and $b$. Then at least one  anagamming must have least weight. Let's say this this one is <strong>lightest</strong>. (There might be multiple lightest anagrammings; I don't care because I am interested only in the weights.)</p>\n\n<h2>Question</h2>\n\n<p>I want an algorithm which, given two strings for which an anagramming exists, efficiently <strong>yields the exact weight of the lightest anagramming</strong> of the two strings. It is all right if the algorithm yields a lightest anagramming, but it need not.</p>\n\n<p>It is a fairly simple matter to generate all anagrammings and weigh them, but there may be many, so I would prefer a method that finds light anagrammings directly.</p>\n\n<hr>\n\n<h2>Motivation</h2>\n\n<p>The reason this problem is of interest is as follows.  It is very easy to make the computer search the dictionary and find anagrams, pairs of words that contain exactly the same letters.  But many of the anagrams produced are uninteresting.  For instance, the longest examples to be found in Webster's Second International Dictionary are:</p>\n\n<blockquote>\n  <p>cholecystoduodenostomy<br>\n  duodenocholecystostomy</p>\n</blockquote>\n\n<p>The problem should be clear: these are uninteresting because they admit a very light anagramming that simply exchanges the <code>cholecysto</code>, <code>duedeno</code>, and <code>stomy</code> sections, for a weight of 2. On the other hand, this much shorter example is much more surprising and interesting:</p>\n\n<blockquote>\n  <p>coastline<br>\n  sectional</p>\n</blockquote>\n\n<p>Here the lightest anagramming has weight 8.</p>\n\n<p>I have a program that uses this method to locate interesting anagrams, namely those for which all anagrammings are of high weight. But it does this by generating and weighing all possible anagrammings, which is slow.</p>\n", 'Tags': '<algorithms><strings><search-algorithms><natural-lang-processing>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-11-21T14:18:17.910', 'CommentCount': '2', 'AcceptedAnswerId': '2265', 'CreationDate': '2012-06-07T18:31:28.390', 'Id': '2259''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have a very specific question about semantic clustering.</p>\n\n<p>I have a list of words/phrases. I want to run an intelligent semantic clustering algorithm on this list. Please let me know what the available options are. Definitely I am looking for NLP based algorithms.</p>\n\n<p>Simple, open-source, easy-to-use solutions will be highly appreciated. The semantic part is extremely important here.</p>\n', 'ViewCount': '523', 'Title': 'Semantic clustering', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-27T18:49:17.373', 'LastEditDate': '2012-07-27T14:31:08.407', 'AnswerCount': '1', 'CommentCount': '10', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2288', 'Tags': '<algorithms><strings><string-metrics><natural-lang-processing><ontologies>', 'CreationDate': '2012-07-27T10:56:33.110', 'FavoriteCount': '1', 'Id': '2922''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Is there a relatively simple way of telling if two pieces of text are semantically similar?</p>\n\n<p>Some assumptions that are valid:</p>\n\n<ul>\n<li>It is all english</li>\n<li>I have a list of all the <em>important</em> nouns</li>\n</ul>\n\n<p>Are there any strategies that I should pursue? Looking for something that is relatively computationally cheap, though something that could be scaled to improve accuracy at the expense of computational power would be a bonus.</p>\n\n<p><strong>Note:</strong></p>\n\n<p>Assume that there are not enough posts for some type of probabilistic analysis, but some type of NN might be feasible (I think, just don't know enough about it).</p>\n", 'ViewCount': '144', 'Title': 'Semantic similarity in text', 'LastEditorUserId': '472', 'LastActivityDate': '2012-08-01T01:56:11.157', 'LastEditDate': '2012-07-31T09:09:35.170', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '863', 'Tags': '<algorithms><natural-lang-processing><ontologies>', 'CreationDate': '2012-07-30T23:28:34.217', 'FavoriteCount': '2', 'Id': '2955''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '325', 'Title': 'Compression of domain names', 'LastEditDate': '2012-08-08T06:51:13.347', 'AnswerCount': '1', 'Score': '11', 'OwnerDisplayName': 'eggyal', 'PostTypeId': '1', 'OwnerUserId': '2380', 'FavoriteCount': '1', 'Body': '<p>I am curious as to how one might <em>very compactly</em> compress the domain of an arbitrary <a href="http://en.wikipedia.org/wiki/Internationalized_domain_name">IDN</a> hostname (as defined by <a href="http://tools.ietf.org/html/rfc5890">RFC5890</a>) and suspect this could become an interesting challenge. A Unicode host or domain name (U-label) consists of a string of Unicode characters, typically constrained to one language depending on the top-level domain (e.g. Greek letters under <code>.gr</code>), which is encoded into an ASCII string beginning with <code>xn--</code> (the corresponding A-label).</p>\n\n<p>One can build data models not only from the formal requirements that</p>\n\n<ul>\n<li><p>each non-Unicode label be a string matching <code>^[a-z\\d]([a-z\\d\\-]{0,61}[a-z\\d])?$</code>;</p></li>\n<li><p>each A-label be a string matching <code>^xn--[a-z\\d]([a-z\\d\\-]{0,57}[a-z\\d])?$</code>; and</p></li>\n<li><p>the total length of the entire domain (A-labels and non-IDN labels concatenated with \'.\' delimiters) not exceed 255 characters</p></li>\n</ul>\n\n<p>but also from various heuristics, including:</p>\n\n<ul>\n<li><p>lower-order U-labels are often lexically, syntactically and semantically valid phrases in some natural language including proper nouns and numerals (unpunctuated except hyphen, stripped of whitespace and folded per <a href="http://tools.ietf.org/html/rfc3491">Nameprep</a>), with a preference for shorter phrases; and</p></li>\n<li><p>higher-order labels are drawn from a dictionary of SLDs and TLDs and provide context for predicting which natural language is used in the lower-order labels.</p></li>\n</ul>\n\n<p>I fear that achieving good compression of such short strings will be difficult without considering these specific features of the data and, furthermore, that existing libraries will produce unnecessary overhead in order to accomodate their more general use cases.</p>\n\n<p>Reading Matt Mahoney\'s online book <a href="http://mattmahoney.net/dc/dce.html">Data Compression Explained</a>, it is clear that a number of existing techniques could be employed to take advantage of the above (and/or other) modelling assumptions which ought to result in far superior compression versus less specific tools.</p>\n\n<p>By way of context, this question is an offshoot from a <a href="http://stackoverflow.com/questions/7792624/producing-compact-ciphertext-of-short-strings">previous one on SO</a>.</p>\n\n<hr>\n\n<p><strong>Initial thoughts</strong></p>\n\n<p>It strikes me that this problem is an excellent candidate for offline training and I envisage a compressed data format along the following lines:</p>\n\n<ul>\n<li><p>A Huffman coding of the "<a href="http://publicsuffix.org/">public suffix</a>", with probabilities drawn from some published source of domain registration or traffic volumes;</p></li>\n<li><p>A Huffman coding of which (natural language) model is used for the remaining U-labels, with probabilities drawn from some published source of domain registration or traffic volumes given context of the domain suffix;</p></li>\n<li><p>Apply some dictionary-based transforms from the specified natural language model; and</p></li>\n<li><p>An arithmetic coding of each character in the U-labels, with probabilities drawn from contextually adaptive natural language models derived from offline training (and perhaps online too, although I suspect the data may well be too short to provide any meaningful insight?).</p></li>\n</ul>\n', 'Tags': '<algorithms><strings><natural-lang-processing><data-compression>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-31T13:51:19.050', 'CommentCount': '5', 'CreationDate': '2011-10-18T02:19:42.587', 'Id': '3056''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I want the conditional probability for each topic (being the word that we give as input). For example, the text being</p>\n\n<blockquote>\n  <p>have seen and reviewed your requirements you posted here.  If you can\n  give me the fix criteria/category of your data mining then I can do\n  this job. If you want me to define and allot criteria and categorize\n  it in then charges will be extra for per categorization included.</p>\n  \n  <p>I have seen and reviewed your requirements you posted here.  If you can give me the fix criteria/category of your data mining then\n  I can do this job. If you want me to define and allot criteria and\n  categorize it in then charges will be extra for per categorization\n  included.</p>\n</blockquote>\n\n<hr>\n\n<p>Assume that I give a word called <strong>research</strong> as an input, I want to know</p>\n\n<pre><code>What is the likelihood/probability that the text relates to research?\n</code></pre>\n\n<p>What algorithms we should create to get the above?</p>\n', 'ViewCount': '267', 'Title': 'Algorithm to find the probability of a given text to be about a large topic', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-17T19:56:03.353', 'LastEditDate': '2013-03-11T07:20:01.300', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '3120', 'Tags': '<machine-learning><natural-lang-processing>', 'CreationDate': '2012-10-09T07:14:33.467', 'FavoriteCount': '1', 'Id': '4970''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '207', 'Title': 'Has someone seen this structure before?', 'LastEditDate': '2012-12-07T11:19:19.687', 'AnswerCount': '0', 'Score': '3', 'OwnerDisplayName': u'Enrique P\xe9rez Arnaud', 'PostTypeId': '1', 'OwnerUserId': '4898', 'FavoriteCount': '1', 'Body': '<p>I am working <a href="https://github.com/enriquepablo/terms/blob/master/terms/core/tests/shegets.test" rel="nofollow">1</a> with a certain structure,\nand I wonder if someone has seen it before.\nI am no mathematician, so all I can say is that\nI will do my best to describe this structure.\nIt is actually very simple.\nI am sure I have seen it (and its interpretation) somewhere, years ago,\nperhaps in some old first year university textbook on the philosophy of language,\nbut haven\'t been able to find it.</p>\n\n<p>The structure is a first order theory, with predicates similar to those\nof a formal set theory (of the ZFC type).\nThe main difference with set theory is that it doesn\'t incorporate\nthe axioms Fraenkel called "constructive"\n(e.g. in the introduction to Paul Bernays\' "Axiomatic set theory" [2]),\nand limits itself to the basic axioms of equality and extensionality\nand definition of subset.</p>\n\n<p>Appart from this, the theory only defines a tuple operator and a few primitive atoms (see <a href="https://github.com/enriquepablo/terms/blob/master/terms/core/tests/shegets.test" rel="nofollow">1</a>, the "words" section). This, and a few relations among these atoms (given by the quasy-set-theoretic predicates outlined above),\nresult in a very simple and limited structure,\nconsistent and complete - as its full expansion is just a handful of sentences.</p>\n\n<p>This structure is used by extending it with new ad hoc atoms, relations among the atoms, and rules (implications),\nto model natural language "texts".\nThe interesting thing here is to model assertive, factual natural sentences\nas tuples, instead of as actual formal sentences.\nAs an example, we might have</p>\n\n<p>(john loves sue) belongs_to fact.</p>\n\n<p>Here, \'john\', \'loves\', \'sue\', and \'fact\' would be atomic terms,\nindividuals; \'(john loves sue)\' would be an operation, valued as an individual;\n\'()\' would be the tuple operator; and \'belongs_to\' would be a predicate symbol.</p>\n\n<p>This allows us to reason about (sufficient enough) sentences of the natural language\nwithout any restriction,\nand use first order variables indistinctly for "facts", "verbs", "nouns", or "names".</p>\n\n<p>I oppose this to the idea of representing natural sentences\nas formal sentences, using predicate symbols to represent all verbs,\nand running to limitations with classes, quantification of predicates, and Russell\'s paradox.</p>\n\n<p>"Copular" sentences (formed with copular verbs, such as "to be")\nare excluded from the above, and are represented as formal sentences;\ni.e., the formal predicates are interpreted as the copular verbs.\nSo "a person is a thing", or "john is a person", might be expressed as:</p>\n\n<p>person subset_of thing.</p>\n\n<p>john belongs_to person.</p>\n\n<p>And that\'s it, more or less.</p>\n\n<p>Does this make any sense?\nMy memory may have failed me and I may have implemented some deranged half baked scheme;\nOn the other hand, I do think that my work with it is allowing me to express some "ontologies" that,\nin my (limited) experience, cannot be easily expressed with other systems.</p>\n\n<hr>\n\n<ol>\n<li><p><a href="https://github.com/enriquepablo/terms#the-terms-knowledge-store" rel="nofollow">Terms knowledge store</a></p></li>\n<li><p><a href="http://books.google.es/books/about/Axiomatic_set_theory.html?id=aHi4AAAAIAAJ" rel="nofollow">Axiomatic Set Theory</a> by Paul Bernays (1958)</p></li>\n</ol>\n\n<hr>\n\n<p>Edit in response to the comment:</p>\n\n<p>You are making Triple Knowledge Base. You may find this interesting: ILP &amp; Triple Knowledge Bases\nAnton</p>\n\n<hr>\n\n<p>@Anton:\nWhat I see as a technological advantage is the separation\nbetween copular verbs and other verbs. Consider this:</p>\n\n<pre><code>john isa man.\n(john loves sue) isa fact.\n</code></pre>\n\n<p>It allows you to take advantage of the obvious\nand hard earned correspondence between "to be" and set theory,\nand at the same time allows you to use other verbs without problems -\nwithout running into fundamental antinomies.</p>\n\n<p>In your references, I see the the possibility of saying:</p>\n\n<pre><code>john isa man.\njohn loves sue.\n</code></pre>\n\n<p>Inmediately after this, you need unrestricted comprehension;\nyou need variables ranging over verbs and predicates. Google for "OWL Full semweb" if you want proof of that need.</p>\n\n<p>That is what Gottlob Frege was doing that\nBertrand Russell showed was wrong.</p>\n\n<p>With the first expression, you don\'t need\nunrestricted comprehension to keep talking.\nIt\'s amazing, see [3] for an example.</p>\n\n<p>3.- <a href="https://github.com/enriquepablo/terms/blob/master/terms/core/tests/shegets.test" rel="nofollow">https://github.com/enriquepablo/terms/blob/master/terms/core/tests/shegets.test</a></p>\n', 'Tags': '<logic><natural-lang-processing>', 'LastEditorUserId': '4898', 'LastActivityDate': '2012-12-07T11:19:19.687', 'CommentCount': '6', 'CreationDate': '2012-11-27T21:50:01.753', 'Id': '7207''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm thinking about the optimal algorithm for the following problem:</p>\n\n<p>Input data:</p>\n\n<ul>\n<li>a <strong>text</strong>, say it's an article about 5-50 pages.</li>\n<li>a set of <strong>ngrams</strong> (ngram strings, n>2), of arbitrary length, could be more than 20k n-grams.</li>\n</ul>\n\n<p>The algorithm should output the following:</p>\n\n<ul>\n<li>a dictionary of all ngrams that were found in the text with the corresponding quantities, it should also take into account that ngrams could partially intersect or consist of each other (like <em>'probability density', 'probability density function', 'probability density distribution'</em>)</li>\n</ul>\n\n<p>So <strong>the question is</strong> what would be the most time-efficient algorithm to compute this?</p>\n\n<p>Both all words in a text and all words in ngrams are reduced to the canonical forms.</p>\n", 'ViewCount': '169', 'Title': 'Optimal algorithm for finding all ngrams from a pre-defined set in a text', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-27T01:11:03.780', 'LastEditDate': '2013-01-16T21:10:34.413', 'AnswerCount': '4', 'CommentCount': '0', 'AcceptedAnswerId': '8976', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2066', 'Tags': '<algorithms><time-complexity><strings><natural-lang-processing>', 'CreationDate': '2013-01-16T16:38:56.730', 'Id': '8972''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m interested in finding a solution for the following problem:</p>\n\n<ul>\n<li>problem space: any language that has more than 1 article</li>\n<li>let\'s take German language as example. So the articles in German are "der", "die", "das". - every word has an article as prefix and you must use the article. for example you can\'t say just "Auto"(car), you must say "das Auto".</li>\n<li>If you are not a native German speaker, you have bad luck, because you have to memorize the article too, when learning a new word, since there are only 3-4 rules to know which word takes which article. And those rules are perhaps about max. 10% percent of the vocabulary. (for example if a word ends with "-ung", it takes "die")</li>\n</ul>\n\n<p><hr/>\nSo here comes the funny part: as a non-native-German-speaker, i wanted to analyze the language from an IT-point of view and asked some friends of mine random words with the following properties: <br/></p>\n\n<ul>\n<li>first I reduced the input set from "any German word" to "a German word", for which no known article rule exists".</li>\n<li>then I extended the input set with "made up words", which do not exist.</li>\n</ul>\n\n<p>Every candidate had the same answer for German words, which should be not surprise. But when I asked them per word "why do you think/feel that the article of the word is "der/die/das"?" they couldnt give an answer. They just know it, without knowing why.</p>\n\n<p>Here comes the real hammer: every candidate had the same answer for any made-up non-German word. I say anything, make any meaningful voice, and they all give the same answer (ie. article).</p>\n\n<p>I\'m pretty sure that I\'m not the first human being in the world who made thoughts about this topic. And I\'m interested in any scientific papers/research about that topic.\nBy the way, what I definitely do NOT need is, any method (like neural networks) which outputs a pure mathematical function. I thought about following possibilities:</p>\n\n<ul>\n<li><p>focusing on feelings of subjects psychologically (I think it can be managed with colors somehow etc.)</p></li>\n<li><p>analyzing the words statistically according to their syllable structure</p></li>\n</ul>\n\n<p>Where can I begin? What are your suggestions? Are there any Machine Learning research about that topic?</p>\n', 'ViewCount': '69', 'Title': 'Analyzing rules of articles in languages', 'LastEditorUserId': '41', 'LastActivityDate': '2013-04-21T10:08:14.350', 'LastEditDate': '2013-01-21T09:10:31.840', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5222', 'Tags': '<machine-learning><natural-lang-processing>', 'CreationDate': '2013-01-20T01:43:55.890', 'Id': '9047''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u'<p>I\'m reading <a href="http://bero.freqvibez.net/public/segs/icassp03_senseg.pdf" rel="nofollow">\u201cSpeech segmentation without speech recognition\u201d by Dong Wang, Lie Lu and Hong-Jiang Zhang</a>.\nThe algorithm I\'m looking at is a V/C/P (Vowel/Consonant/Pause) classification algorithm on a digital speech signal. It is described as such:</p>\n\n<ol>\n<li><p>Audio data is segmented into 20ms-long non-overlapping frames, \nwhere features, including ZCR, Energy and Pitch, are extracted.  </p></li>\n<li><p>Energy and pitch curve is smoothed. </p></li>\n<li><p>The  <code>Mean_En</code> and  <code>Std_En</code> of energy curve are calculated to \ncoarsely estimate the background noise energy level, as: </p>\n\n<pre><code>NoiseLevel = Mean_En - 0.75 Std_En. \n</code></pre>\n\n<p>Similarly the threshold of ZCR (<code>ZCR_dyna</code>) is defined as: </p>\n\n<pre><code>ZCR_dyna = Mean_ZCR + 0.5 Std_ZCR\n</code></pre></li>\n<li><p>Frames are classified as V/C/P coarsely by using the following \nrules, where FrameType is used to denote the type of each frame. </p>\n\n<pre><code>If ZCR &gt; ZCR_dyna then FrameType = Consonant \nElse if Energy &lt; NoiseLevel, then  FrameType = Pause \nElse FrameType = Vowel   \n</code></pre></li>\n<li><p>Update the <code>NoiseLevel</code> as the weighted average energy of the \nframes at each vowel boundary and the background segments. </p></li>\n<li><p>Re-classify the frames using algorithm in step 4 with the updated \n<code>NoiseLevel</code>. Pauses are merged by removing isolated short \nconsonants. Vowel will be split at its energy valley if its duration is \ntoo long  </p></li>\n</ol>\n\n<p>I do not understand step #5. Like I don\'t know how to interpret the wording - is there another way to describe what they are doing? I get that we want to update the <code>NoiseLevel</code> variable and re-run step #4 for every frame, I just don\'t understand how exactly. </p>\n', 'ViewCount': '49', 'Title': 'Help understanding an audio processing algorithm', 'LastEditorUserId': '39', 'LastActivityDate': '2013-02-05T20:16:13.140', 'LastEditDate': '2013-02-05T20:16:13.140', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6720', 'Tags': '<algorithms><machine-learning><natural-lang-processing><signal-processing>', 'CreationDate': '2013-02-05T16:56:55.613', 'Id': '9513''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '1496', 'Title': 'Are programming languages becoming more like natural languages?', 'LastEditDate': '2013-02-08T00:55:20.197', 'AnswerCount': '9', 'Score': '17', 'OwnerDisplayName': 'user881920', 'PostTypeId': '1', 'OwnerUserId': '6766', 'FavoriteCount': '10', 'Body': "<p>Can we study programming languages in the context of linguistics? Do programming languages evolve naturally in similar ways to natural languages? </p>\n\n<p>Although full rationality, and mathematical consistency is essential to programming languages, there still is the need (especially modern languages) to make them readable and comfortable to humans. </p>\n\n<p>Are programming languages evolving to become more linguistic and thus more natural? For example machine code, punch cards and assembly languages have given way to more readable languages like Ruby and Python etc. </p>\n\n<p>When I say computer languages are becoming more natural, I don't mean they contain more 'words we have in english', I mean they seem to becoming more like a natural language, in terms of their complexity of grammer and ability to express meaning (for example, being able to eloquently describe a query from a database in both rational and human understandable ways).</p>\n\n<p>What do you all think? Are programming languages becoming more like natural languages, and thus becoming applicable to the laws of Linguistics?</p>\n\n<p>Or perhaps languages live on a spectrum, where on one side you have the extreme rational languages and the other the more creative. Maybe, programming and natural languages are identical and both just lie on this language spectrum (their only difference, perhaps being the 'thing' they are trying to give their meaning to).  </p>\n\n<p>Is there a connection between the (Babel Tower effect) separation of human languages and of computer langages? Do they become more diverse for the same reasons (i.e. to solve different problems within ever-evolving computer-systems/culture-systems etc.)?</p>\n", 'Tags': '<programming-languages><natural-lang-processing>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-02T14:07:21.780', 'CommentCount': '6', 'CreationDate': '2013-02-07T23:27:48.050', 'Id': '9581''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>What is the role of AI in Natural language processing ? </p>\n\n<p>For example Siri. Is Ai used to make siri get better at understanding the users voice ?</p>\n', 'ViewCount': '1232', 'ClosedDate': '2014-01-09T21:52:00.313', 'Title': 'How is Natural language processing related to Artificial Intelligence', 'LastActivityDate': '2013-12-30T13:58:11.833', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '9932', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6944', 'Tags': '<artificial-intelligence><natural-lang-processing>', 'CreationDate': '2013-02-19T02:57:21.190', 'FavoriteCount': '1', 'Id': '9920''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>There is a sentence with N words.</p>\n\n<p>The words are randomly shuffled.</p>\n\n<p>I have a heuristic algorithm that tries to restore the original order.</p>\n\n<p>I want to evaluate my algorithm on a dataset of several hundred long sentences from the internet. </p>\n\n<p>The main goal of the algorithm is that humans looking at the restored sentence will be able to easily know what the original sentence was. So I can evaluate my algorithm by asking humans to grade the quality of the restored order. However, this is very expensive.</p>\n\n<p>Another option is to count the number of words that are in their correct position in each sentence, and divide by the total number of words in all sentences. However, this is not a good measurement of the quality, because, for example, if the only mistake of my algorithm is that it put the last word first, the resulting sentence will get a score of 0, although it is quite similar to the gold standard, and a human will easily notice this.</p>\n\n<p>A third option is to find the minimum number of word moves that need to be done on the algorithm output in order to achieve the gold standard. However, this seems like a non-trivial task in itself.</p>\n\n<p>Can you suggest a measurement that will be both meaningful and easy to implement?</p>\n', 'ViewCount': '66', 'Title': 'Evaluation metric for an ordering algorithm', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-21T01:35:12.557', 'LastEditDate': '2013-03-19T10:25:00.073', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '10674', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<natural-lang-processing><string-metrics>', 'CreationDate': '2013-03-19T08:17:04.963', 'Id': '10613''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p><a href="http://www.cs.utexas.edu/~ml/nldata/geoquery.html" rel="nofollow">GeoQuery</a> is a dataset used for benchmarking semantic parsers. It contains 880 queries about USA geography. The queries are in Prolog format, for example:</p>\n\n<blockquote>\n  <p>answer(A,longest(A,(river(A),traverse(A,B),const(B,countryid(usa)))))</p>\n</blockquote>\n\n<p>(this represents a question for the longest river that passes through the us).</p>\n\n<p>I have read <a href="http://www.citeulike.org/user/erelsegal-halevi/tag/geoquery" rel="nofollow">several papers about the GeoQuery</a>, but they don\'t seem to give a formal definition of the grammar underlying the dataset. The email address in the dataset page seem to be dysfunctional. So, my question (addressed primarily to researchers who have worked with the GeoQuery dataset before) is twofold:</p>\n\n<ul>\n<li>Is there a formal definition of the GeoQuery language?</li>\n<li>Is this language context-free?</li>\n</ul>\n\n<p>EDIT:</p>\n\n<p>It seems that, if the number of variables (A, B, C...) is unlimited, then GeoQuery is not context-free, because a CFG cannot make sure that two variables in different places are identical (this is similar to the {ww} language, which is not context-free).</p>\n\n<p>But what if we limit ourselves to A, B and C?</p>\n', 'ViewCount': '51', 'Title': 'The grammar of the GeoQuery language', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-04-16T10:02:47.367', 'LastEditDate': '2013-04-16T10:02:47.367', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<formal-languages><context-free><semantics><natural-lang-processing>', 'CreationDate': '2013-04-15T13:22:36.020', 'Id': '11331''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I wonder about cases in which knowing several languages can lead a researcher to  interesting results in natural language processing.</p>\n\n<p>For example, knowledge of foreign languages can without doubt contribute to better machine translation, it's the most obvious example.</p>\n\n<p>In what other fields of NLP can a researcher benefit from knowing several languages?</p>\n", 'ViewCount': '58', 'Title': 'Advantages of knowing foreign languages for natural language processing', 'LastEditorUserId': '683', 'LastActivityDate': '2013-08-20T17:28:02.883', 'LastEditDate': '2013-08-20T17:28:02.883', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<natural-lang-processing>', 'CreationDate': '2013-08-20T06:45:45.870', 'Id': '13833''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I am building a classifier for short texts in a chat system. My features are words and pairs of words.</p>\n\n<p>Naturally, the sentences contain spelling mistakes. If a particular wrong spelling of a certain word hasn't appeared in the training corpus, the classifier has no chance to identify it.</p>\n\n<p>I consider taking an existing spelling corrector, and integrate it with my current classifier, but I am not sure how to do it.</p>\n\n<p>Do you know of a paper that integrates an automatic spelling correction tool with a short text classifier? </p>\n", 'ViewCount': '76', 'Title': 'short text categorization with spelling correction', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-08-22T14:34:49.877', 'LastEditDate': '2013-08-22T11:42:58.863', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><machine-learning><natural-lang-processing><classification>', 'CreationDate': '2013-08-22T11:20:26.190', 'Id': '13864''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Suppose I have $n$ independent observations $x_1,\\dots,x_n$ from some unknown distribution over a known alphabet $\\Sigma$, and I want to estimate the entropy of the distribution.  I can count the frequency $f_s$ of each symbol $s \\in \\Sigma$ among the observations; how should I use them to estimate the Shannon entropy of the source?</p>\n\n<hr>\n\n<p>The obvious approach is to estimate the probability of each symbol $s$ as $\\Pr[X=s]=f_s/n$, and then calculate the entropy using the standard formula for Shannon entropy.  This leads to the following estimate of the entropy $H(X)$:</p>\n\n<p>$$\\text{estimate}(H(X)) = - \\sum_{s \\in \\Sigma} {f_s \\over n} \\lg (f_s/n).$$</p>\n\n<p>However, this feels like it might not produce the best estimate.  Consider, by analogy, the problem of estimating the probability of symbol $s$ based upon its frequency $f_s$.  The naive estimate $f_s/n$ is likely an underestimate of its probability.  For instance, if I make 100 observations of birds in my back yard and none of them were a hummingbird, should my best estimate of the probability of seeing a hummingbird on my next observation be exactly 0?  No, instead, it\'s probably more realistic to estimate the probability is something small but not zero.  (A zero estimate means that a hummingbird is absolutely impossible, which seems unlikely.)</p>\n\n<p>For the problem of estimating the probability of symbol $s$, there are a number of standard techniques for addressing this problem.  <a href="https://en.wikipedia.org/wiki/Laplace_smoothing" rel="nofollow">Additive smoothing</a> (aka Laplace smoothing) is one standard technique, where we estimate the probability of symbol $s$ as $\\Pr[X=s] = (f_s + 1)/(n+|\\Sigma|)$.  Others have proposed Bayesian smoothing or other methods.  These methods are widely used in natural language processing and document analysis, where just because a word never appears in your document set doesn\'t mean that the word has probability zero.  In natural language processing, this also goes by the name <a href="https://en.wikipedia.org/wiki/N-gram#Smoothing_techniques" rel="nofollow">smoothing</a>.</p>\n\n<p>So, taking these considerations into account, how should I estimate the entropy, based upon observed frequency counts?  Should I apply additive smoothing to get an estimate of each of the probabilities $\\Pr[X=s]$, then use the standard formula for Shannon entropy with those probabilities?  Or is there a better method that should be used for this specific problem?</p>\n', 'ViewCount': '108', 'Title': 'Estimate entropy, based upon observed frequency counts', 'LastActivityDate': '2013-10-13T18:18:02.167', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<information-theory><statistics><natural-lang-processing><entropy><information-retrieval>', 'CreationDate': '2013-10-11T21:26:30.400', 'Id': '15010''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I try to understand the details regarding using <a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Model</a> in Tagging Problem.</p>\n\n<p>The best concise description that I found is the <a href="http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf" rel="nofollow">Course notes by Michal Collins</a>.</p>\n\n<p>The goal is to find a function $f(x)=arg max_{y \\in Y} p(y|x)$, where $y$ is the tag set for sentence $x$. </p>\n\n<p><strong>Question 1</strong>. It\'s suggested to use a generative model and to estimate joint probability $p(x,y)$ from the trainig examples, however what the the reason to use generative model and increase the number of computation why not directly to estimate $p(y|x)$, I think it\'s possible to estimate the conditional probability straightforward from the training data.</p>\n\n<p><strong>Addendum</strong>. Do you know the reason why at all we should try to use a generative model in this case (POS tagging). As I  understand if we can estimate $p(x,y)$ that exactly with  the same success we can estimate $p(y|x)$  and directly find the answer to the question, what is the best tagging - $\\hat{y}$ without weak assumption of generative model. There is the reason to use generative model, and I don\'t see it yet. Can you explain me what the reason?</p>\n\n<p><strong>Question 2.</strong> Assume we decided to use a generative model and made estimation to $p(x,y)$ why we decide to decompose it as follows $p(x,y)=p(y)p(x|y)$ and not  $p(x,y)=p(x)p(y|x)$? </p>\n\n<p><strong>Addendum</strong>. I do understand that it\'s very logical to use the decomposition $p(y)p(x|y)$ just because by doing it we approach $p(y|x)$, so mathematically it seems very reasonable, however according to the task I don\'t see what the problem to decompose it like $p(x,y)=p(x)p(y|x)$, there should be sore reason why we can not decompose it so and I don\'t understand why.</p>\n\n<p>I appreciate your help.</p>\n', 'ViewCount': '74', 'Title': 'Hidden Markov Model in Tagging Problem', 'LastEditorUserId': '8473', 'LastActivityDate': '2013-11-07T13:51:13.720', 'LastEditDate': '2013-11-07T13:51:13.720', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '16779', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<machine-learning><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2013-11-06T20:02:49.927', 'Id': '16777''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I would like to  <strong>determine interests or hobbies that people have given their Twitter timeline data</strong>. Their timeline is their historical collection of tweets.</p>\n\n<p>The result I am trying to achieve is to automatically label a user with a collection of interests such as:</p>\n\n<ul>\n<li>Finance </li>\n<li>Photography</li>\n<li>Android Development</li>\n</ul>\n\n<p><strong>I have tried using a topic model, LDA, using an individuals tweets as the corpus but I am not so sure about the applicability of the results</strong>. LDA gives a collection of terms associated with the topics it found. This requires some manual interpretation to distinguish what the interest is.</p>\n\n<p>For example you might get some results from LDA like the following:</p>\n\n<ul>\n<li>[Twitter, Java, time, work, day]</li>\n<li>[code, IPhone, mobile, look, job]</li>\n<li>[football, fantasy, team, pick, score]</li>\n</ul>\n\n<p>I can generally pick out the topics people are interested in here but its just the key word or topic identifier I am interested in not the other contextual terms like team, pick or score in the last example. Ideally I would like to transform these term-based results into something like the following interests:</p>\n\n<ul>\n<li>[Twitter, Java]</li>\n<li>[IPhone, Mobile Development]</li>\n<li>[Fantasy Football]</li>\n</ul>\n\n<p><strong>I have considered how to do this using a supervised approach</strong>. Given your categories of interest and using a bag-of-words model with a naive Bayes classifier the task would be to determine which category the topic terms belong to.</p>\n\n<p>This requires labelled data for each category of interest which could be quite time consuming to create. <strong>Is there a possible unsupervised learning approach that could work?</strong></p>\n\n<p>I may have gone down the wrong path using topic models, if so, what existing textual research areas could help.</p>\n\n<p><strong>Not looking for a complete solution to the problem, just any suggestions, references or links would be appreciated</strong>.</p>\n', 'ViewCount': '106', 'Title': 'Determining interests from Twitter text using Latent Dirichlet Allocation', 'LastEditorUserId': '11558', 'LastActivityDate': '2013-12-23T15:32:40.587', 'LastEditDate': '2013-11-23T14:44:34.963', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11558', 'Tags': '<natural-lang-processing>', 'CreationDate': '2013-11-22T17:22:59.967', 'Id': '18261''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am studying the following paper for understanding next-word prediction using n-gram &amp; trie: - <a href="http://nlp.cs.berkeley.edu/pubs/Pauls-Klein_2011_LM_paper.pdf" rel="nofollow">http://nlp.cs.berkeley.edu/pubs/Pauls-Klein_2011_LM_paper.pdf</a> Before this, I did some brief study on what are n-grams. And, I know trie data structure. The issue is - the algorithm in paper is not so intuitive to understand. Anyone can provide some better/intuitive explanation of this algorithm, or some similar Language Model Implementation. I am new to this site, so if this question structure is inappropriate to this site, please guide. Thanks in advance.</p>\n', 'ViewCount': '128', 'Title': 'Next Word Prediction using n-gram & Tries', 'LastActivityDate': '2013-11-26T04:08:32.257', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11628', 'Tags': '<algorithms><machine-learning><artificial-intelligence><natural-lang-processing>', 'CreationDate': '2013-11-26T04:08:32.257', 'Id': '18351''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u"<p>I was looking into how a <strong>next-word prediction engine</strong> like swift key or XT9 can be implemented.</p>\n\n<p>Here's what I did.</p>\n\n<ul>\n<li>I read about <strong>n-grams</strong> here - en.wikipedia.org/wiki/N-gram and aicat.inf.ed.ac.uk/entry.php?id=663</li>\n<li>I read about <strong>Language Models/Markov Model/n-grams/training/Smoothing/Back-Offs</strong> - en.wikipedia.org/wiki/Language_model &amp; www.stanford.edu/class/cs124/lec/languagemodeling.pptx\u200e &amp; www.statmt.org/book/slides/07-language-models.pdf.</li>\n<li>I read about the T9 engine design for next-word prediction based on Tries - courses.cs.washington.edu/courses/cse303/09wi/homework/T9files/T9_Tries.pdf</li>\n<li>I came across <strong>SRILM</strong>, a popular toolkit for building &amp; applying Language Models here - www.speech.sri.com/projects/srilm/ (the toolkit) &amp; www.speech.sri.com/cgi-bin/run-distill?papers/icslp2002-srilm.ps.gz (the documentation)</li>\n<li>I came across the blog where <strong>Google</strong>'s Peter Norvig made an announcement to <strong>share it's huge training corpus of one trillion words</strong> to the entire world - googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you</li>\n<li>I came across an <strong>n-gram viewer</strong> based on google books' corpus - books.google.com/ngrams/</li>\n<li>I came across Microsoft's N-gram services - web-ngram.research.microsoft.com/</li>\n<li>I came across <strong>an algorithm for N-Gram Language Models which is as fast as but smaller (in memory footprint) than SRILM's model</strong> (not based on tries, uses encoding) - nlp.cs.berkeley.edu/pubs/Pauls-Klein_2011_LM_paper.pdf (I need to do more work here.)</li>\n<li>I had a look at some <strong>open-source engines</strong> available like <strong>AnySoftKeyboard</strong> - github.com/AnySoftKeyboard. That's is a huge amount of code with no documentation!</li>\n</ul>\n\n<p>Some discussions on <strong>stackoverflow</strong>:</p>\n\n<ul>\n<li>Implementing T9 prediction engine - Implementing T9 text prediction</li>\n<li>A discussion on implementation of autocomplete using tries vs. ternary search trees vs. succint trees - stackoverflow.com/questions/10970416/tries-versus-ternary-search-trees-for-autocomplete</li>\n</ul>\n\n<p>The <strong>major players</strong> in this area:</p>\n\n<ul>\n<li><strong>Swift Key</strong> - en.wikipedia.org/wiki/SwiftKey &amp; www.swiftkey.net/en/</li>\n<li><strong>XT9 by Nuance</strong> - en.wikipedia.org/wiki/XT9 &amp; www.nuance.com/for-business/by-product/xt9/index.htm</li>\n</ul>\n\n<p>Can anybody guide me how to proceed further.</p>\n\n<p>I am relatively new to this site. So please guide me if my question is inappropriate for this site.</p>\n", 'ViewCount': '207', 'Title': 'Next-Word Prediction, Language Models, N-grams', 'LastEditorUserId': '11628', 'LastActivityDate': '2013-11-26T08:15:40.323', 'LastEditDate': '2013-11-26T08:15:40.323', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11628', 'Tags': '<artificial-intelligence><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2013-11-26T05:36:16.227', 'FavoriteCount': '1', 'Id': '18354''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Next-word prediction or phrase-prediction engines used in modern keyboards of mobiles and tablets, like swift key &amp; XT9, which predict the next word the user is going to type based on some pre-defined or dynamic corpus, based on n-grams (maximum frequency of last typed 2-3 words plus the current word) based language models (Markov Model).</p>\n\n<p>What I think is that these engines/algos are a part of AI/NLP.\nBut what I am not sure about is what specific branch of AI/NLP they belong to.</p>\n\n<p>Is it machine learning ?\nIs it data science ?\nIs it big data ?\nIs it Computing Intelligence ?\nIs it decision-making ?\nIs it data-mining ?\nOr statistical pattern recognition/ predictive analytics/ Supervised learning/ Unsupervised learning ?\nOr all/many of these or something else ?</p>\n', 'ViewCount': '55', 'ClosedDate': '2013-12-03T17:35:15.933', 'Title': 'Next-Word Prediction Engines - which branch of AI do they belong', 'LastEditorUserId': '11628', 'LastActivityDate': '2013-11-26T16:09:39.763', 'LastEditDate': '2013-11-26T16:09:39.763', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11628', 'Tags': '<machine-learning><artificial-intelligence><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2013-11-26T15:39:28.363', 'Id': '18387''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>The first chapter of the book "Graphs and their uses" by Oystein Ore says that interval graphs can be used to resolve authorship disputes, but I couldn\'t find any details.  How does this work?  What is the algorithm?</p>\n\n<p><strong>From the text (Chapter 1.7):</strong></p>\n\n<blockquote>\n  <p>Interval graphs have also been used to investigate the likely authorship of disputed pieces of writing, such as certain works of Plato. Various features of an authors prose style are studied for their appearance in several literary works. By drawing a graph in which the vertices correspond to these literary features and the edges correspond to pairs of them which occur together in the same work, we obtain a situation very similar to our archaeological example. As before, we can then investigate whether the resulting graph can be represented as an interval graph, and we can thereby attempt to arrange the works in chronological order. By doing this, it has sometimes been possible to relate the style of the disputed piece of writing to that of the author in question, and thereby to determine the likely authorship.</p>\n</blockquote>\n', 'ViewCount': '64', 'Title': 'Using interval graphs to find authorship disputes', 'LastEditorUserId': '472', 'LastActivityDate': '2014-01-13T13:14:32.097', 'LastEditDate': '2014-01-13T12:58:54.237', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '947', 'Tags': '<graph-theory><graphs><natural-lang-processing>', 'CreationDate': '2014-01-13T01:54:11.963', 'Id': '19680''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm a researcher working with a language that has gone through phonological changes through time.  I would like to tag parts of a word (i.e. prefix, stem, suffix) and then apply those phonological changes and then see what is left or different about the stuff that I tagged.</p>\n\n<p>I'm currently using Python with some regex stuff to apply the changes so if I can do this using its NPL toolkit that would be perfect.  I've start to mess around with it but I haven't found anything that will work just yet.  I'm also not sure if this toolkit would be the best for this.</p>\n\n<p>For example, I apply the following transformation to tag <code>re</code>, <code>peat</code> and <code>ed</code> in <code>repeated</code>:\n$$\n\\begin{align}\n  \\mathtt{repeated}\n  &amp; \\xrightarrow{\\mathtt{rep} \\mapsto \\mathtt{rp}} \\mathtt{rpeated} \\\\\n  &amp; \\xrightarrow{\\mathtt{ea} \\mapsto \\mathtt{e}} \\mathtt{rpeted} \\\\\n  &amp; \\xrightarrow{\\mathtt{d}\\$ \\mapsto \\epsilon} \\mathtt{rpete} \\\\\n\\end{align}\n$$</p>\n\n<p>I would like to be able to find out what is left of the stuff I tagged.  So I'd like to see that <code>r</code> is all that is left of the prefix, <code>pe</code> is all that is left of the stem, etc.  Any help or direction is greatly appreciated!</p>\n", 'ViewCount': '25', 'Title': 'Trying to tag parts of a word and keep track of any changes that happen to those parts', 'LastEditorUserId': '39', 'LastActivityDate': '2014-01-29T15:41:39.147', 'LastEditDate': '2014-01-29T15:41:34.770', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12849', 'Tags': '<algorithms><strings><natural-lang-processing><computational-linguistics>', 'CreationDate': '2014-01-14T19:56:01.060', 'Id': '19725''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>There is a famous <a href="http://en.wikipedia.org/wiki/Part-of-speech_tagging" rel="nofollow">part-of-speech tagging problem</a> in Natural Language Processing. The popular solution is to use <a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Models</a>.</p>\n\n<p>So that, given the sentence $x_1 \\dots x_n$ we want to find the sequence of POS tags $y_1 \\dots y_n$ such that $y_1 \\dots y_n = \\arg\\max_{y_1 \\dots y_n}p(Y,X)$.</p>\n\n<p>By Bayes Theorem, $P(X,Y)=P(Y)P(X \\mid Y)$.</p>\n\n<p>Solving POS by HMM implies the assumptions: $p(y_i \\mid y_{i-1})$ and $p(x_i \\mid y_i)$.</p>\n\n<p>The question is there are any particular reason why we prefere to solve it by generative model with a lot of assumption and not directly by estimating $P(Y \\mid X)$, given the training corpus it\'s still possible to estimate $p(y_i \\mid x_i)$.</p>\n\n<p>The second question, even when we convinced that the generative model is preferred why to calculate is as $P(Y,X)=P(Y)P(X \\mid Y)$ and not $P(X,Y)=P(X)P(Y \\mid X)$. In case we have an appropriate generative story I can use $P(X,Y)=P(X)P(Y \\mid X)$ as well, is it mentioned somewhere that assumed generative story is preferred.</p>\n', 'ViewCount': '35', 'Title': 'Solving the part-of-speech tagging problem with HMM', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-01T16:41:25.817', 'LastEditDate': '2014-02-01T15:46:40.370', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '20190', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<machine-learning><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2014-02-01T13:49:50.607', 'Id': '20185''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>What aspects of linguistics are necessary or good to know for natural language processing? What references do you recommend for studying those aspects? Thanks!</p>\n', 'ViewCount': '141', 'ClosedDate': '2014-02-07T07:53:41.993', 'Title': 'What aspects of linguistics are necessary or good for natural language processing?', 'LastActivityDate': '2014-02-07T04:16:59.973', 'AnswerCount': '4', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<natural-lang-processing>', 'CreationDate': '2014-02-05T22:52:56.443', 'Id': '21334''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>In NLP, do you distinguish tokens that you don't observe in a training sample and still expect that they may occur in a test sample, between </p>\n\n<ul>\n<li>those you know what they are, and</li>\n<li>those you don't what they are, and how many of them</li>\n</ul>\n\n<p>If yes, how do you treat them differently to estimate the probabilities in N-grams? Thanks!</p>\n", 'ViewCount': '22', 'Title': "In NLP, tokens not seen in training sample, but you know or don't know what they are", 'LastEditorUserId': '336', 'LastActivityDate': '2014-02-27T21:21:09.767', 'LastEditDate': '2014-02-27T21:21:09.767', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<natural-lang-processing>', 'CreationDate': '2014-02-27T14:21:32.563', 'Id': '22092''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m writing a small program that implements a trigram HMM model and apply it by using Viterbi Algorithm. It\'s very standardized. However, I have never written anything like this before, and I get confused of what I should use as the <code>START (*)</code> and <code>STOP</code> symbols.</p>\n\n<p>I tried to search for the answer online but apparently people who know the answer don\'t need to ask online, and people who don\'t know the answer don\'t need to know. </p>\n\n<p>I primarily use Scala as my choice of implementation language. Scala has a program called ScalaNLP, but it\'s nowhere being mature, and it does not have HMM implementation as far as I can tell. So I decide to include a statistic package of Scala and write one by myself.</p>\n\n<p>I recently watched Michael Collins\' NLP class on Coursera and I thought he explained HMM model very well and I could possibly try to implement that by myself.</p>\n\n<p>The "apply-part" of program itself on the outmost surface (structure) should look like the Viterbi Algorithm described in Collins\' video. I do need to explain. HMM has two parts: training and applying. Training part is implemented to get emission variable: $e - e(x^i|y^i)$ and the parameter $q(v|w, u)$. The applying part is to take in a sentence: x1x2...xn and add two start symbols <code>**</code> to the beginning of the sentence and a <code>STOP</code> symbol at the end.</p>\n\n<p>I don\'t know if I am truly capable of doing such, but these great professors never mentioned any real implementation because people will just go and use a library created by someone else.</p>\n', 'ViewCount': '34', 'Title': 'NLP: in practice, what should I choose as Start and End symbol?', 'LastEditorUserId': '39', 'LastActivityDate': '2014-03-14T22:01:44.063', 'LastEditDate': '2014-03-14T22:01:43.830', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14597', 'Tags': '<natural-lang-processing>', 'CreationDate': '2014-03-11T20:24:28.070', 'Id': '22512''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I would like to know whether there is a method to find similar questions for a given question, just like this stackexchange.com does.</p>\n\n<p>Is there any paper or tools?\nI tried keywords such as "deduplication" and "linking" but it was not successful.</p>\n', 'ViewCount': '18', 'Title': 'Is there a paper/implementation/tool on automatically finding/suggesting similar questions for a given question?', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-03-17T11:56:15.640', 'LastEditDate': '2014-03-17T11:56:15.640', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15765', 'Tags': '<reference-request><natural-lang-processing>', 'CreationDate': '2014-03-17T08:27:58.670', 'FavoriteCount': '1', 'Id': '22696''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am curious as to what steps one would reasonably need to take to perform an extraction-based text summarizer.</p>\n\n<p>I\'ve taken a look at some papers I\'ve found on Google such as <a href="https://wwws.cs.umn.edu/tech_reports_upload/tr2000/00-034.ps" rel="nofollow">this one</a>, which explains that UPGMA is the best clustering algorithm (out of the tested set). I\'ve also found <a href="http://acl.ldc.upenn.edu/I/I05/I05-2004.pdf" rel="nofollow">this one</a> to be interesting, regarding single and multi-document summarization.</p>\n\n<p>I\'m unclear as to whether I\'d need to combine these techniques for summarization or whether it would suffice to use a tool like Gensim to model a corpus of documents and just extract the sentences with the highest vector values.</p>\n', 'ViewCount': '23', 'Title': 'Document clustering for summarization', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-11T06:35:58.613', 'LastEditDate': '2014-04-11T06:35:58.613', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '16190', 'Tags': '<machine-learning><data-mining><natural-lang-processing><cluster>', 'CreationDate': '2014-04-10T22:42:44.780', 'Id': '23661''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In the coursera NLP course, Dan Jurofsky says you might want to extract relations from text to serve as input to other algorithms. What are examples of ways that researchers have used or might use relations extracted from text as the input for later "downstream" algorithms?</p>\n', 'ViewCount': '14', 'ClosedDate': '2014-04-23T16:50:11.117', 'Title': 'What are ways that you might analyze relations extracted from text', 'LastActivityDate': '2014-04-15T13:47:35.443', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2605', 'Tags': '<natural-lang-processing>', 'CreationDate': '2014-04-15T13:47:35.443', 'Id': '23812''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am learning about NLP, with an eye to starting some practical NLP projects. I see that many of the algorithms for relation extraction and named entity recognition require you to identify linguistic features like "word comes before a period" or "word is the last word in a verb phrase." This seems like it takes a lot of manual work. You have to look at instances in the text and parse out features. </p>\n\n<p>I also know that in distant supervised relation extraction they generate tons of features from tons of examples -- so it seems like there are ways to extract features automatically. Are there any ways of doing this? For instance, are there ways to grep for known names and then automatically detect the features around those names? Can anyone explain what (if any) methods exist for doing this?</p>\n', 'ViewCount': '8', 'Title': 'Are there any methods that NLP practitioners use to automatically learn linguistic features from text?', 'LastActivityDate': '2014-05-03T00:07:38.253', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2605', 'Tags': '<natural-lang-processing>', 'CreationDate': '2014-05-03T00:07:38.253', 'Id': '24331''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am looking for any good Lex Ranking tool like Sumy in python. I would like to experiment with my data with multiple lex ranking  algorithms. So could anyone please suggest me a good tool in Python for Lex Ranking?</p>\n\n<p>Thank you</p>\n', 'ViewCount': '3', 'Title': 'Any good python Lex Ranking tool apart from sumy?', 'LastActivityDate': '2014-05-04T01:56:24.440', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17307', 'Tags': '<natural-lang-processing><ranking>', 'CreationDate': '2014-05-04T01:56:24.440', 'Id': '24375''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}