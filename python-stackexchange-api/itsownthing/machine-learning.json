{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '639', 'Title': "Are there improvements on Dana Angluin's algorithm for learning regular sets", 'LastEditDate': '2012-04-03T03:49:58.997', 'AnswerCount': '1', 'Score': '21', 'PostTypeId': '1', 'OwnerUserId': '55', 'FavoriteCount': '6', 'Body': '<p>In her 1987 seminal paper Dana Angluin presents a polynomial time algorithm for learning a DFA from membership queries and theory queries (counterexamples to a proposed DFA).</p>\n\n<p>She shows that if you are trying to learn a minimal DFA with $n$ states, and your largest countexample is of length $m$, then you need to make $O(mn^2)$ membership-queries and at most $n - 1$ theory-queries.</p>\n\n<p>Have there been significant improvements on the number of queries needed to learn a regular set?</p>\n\n<hr>\n\n<h3>References and Related Questions</h3>\n\n<ul>\n<li><p>Dana Angluin (1987) "Learning Regular Sets from Queries and Counterexamples", Infortmation and Computation 75: 87-106</p></li>\n<li><p><a href="http://cstheory.stackexchange.com/q/10958/1037">Lower bounds for learning in the membership query and counterexample model</a></p></li>\n</ul>\n', 'Tags': '<algorithms><learning-theory><machine-learning>', 'LastEditorUserId': '55', 'LastActivityDate': '2013-06-16T02:15:47.507', 'CommentCount': '4', 'AcceptedAnswerId': '1021', 'CreationDate': '2012-03-08T01:12:58.203', 'Id': '118'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '1098', 'Title': 'How to determine likely connections in a social network?', 'LastEditDate': '2012-04-22T16:33:09.770', 'AnswerCount': '4', 'Score': '20', 'PostTypeId': '1', 'OwnerUserId': '151', 'FavoriteCount': '2', 'Body': '<p>I am curious in determining an approach to tackling a "suggested friends" algorithm.</p>\n\n<p><a href="http://facebook.com">Facebook</a> has a feature in which it will recommended individuals to you which it thinks you may be acquainted with. These users normally (excluding the edge cases in <a href="http://www.facebook.com/help/?faq=154758887925123#How-do-I-suggest-a-friend-to-someone?">which a user specifically recommends a friend</a>) have a highly similar network to oneself. That is, the number of friends in common are high. I assume Twitter follows a similar path for their "Who To Follow" mechanism.</p>\n\n<p><a href="http://stackoverflow.com/a/6851193/321505">Stephen Doyle (Igy)</a>, a Facebook employee suggested that the related newsfeed that uses <a href="http://www.quora.com/How-does-Facebook-calculate-weight-for-edges-in-the-EdgeRank-formula">EdgeRank formula</a> which seems to indicate that more is to valued than friends such as appearance is similar posts. Another user suggested the Google Rank system. </p>\n\n<p>Facebook states their News Feed Optimization as $\\sum u_{e}w_{e}d_{e}$ where</p>\n\n<p>$u_{e}$ = affinity score between viewing user and edge creator<br>\n$w_{e}$ = weight for this edge (create, comment, like, tag, etc)<br>\n$d_{e}$ = time decay factor based on how long ago the edge was created   </p>\n\n<p>Summing these items is supposed to give an object\'s rank which I assume as Igy hinted, means something in a similar format is used for suggested friends.</p>\n\n<p>So I\'m guessing that this is the way in which connections for all types are done in general via a rank system?</p>\n', 'Tags': '<algorithms><machine-learning><modelling><social-networks>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:33:09.770', 'CommentCount': '2', 'AcceptedAnswerId': '314', 'CreationDate': '2012-03-12T23:24:54.360', 'Id': '261'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Fully connected (at least layer to layer with more than 2 hidden layers) backprop networks are universal learners. Unfortunately, they are often slow to learn and tend to over-fit or have awkward generalizations. </p>\n\n<p>From fooling around with these networks, I have observed that pruning some of the edges (so that their weight is zero and impossible to change) tends to make the networks learn faster and generalize better. Is there a reason for this? Is it only because of a decrease in the dimensionality of the weights search space, or is there a more subtle reason?</p>\n\n<p>Also, is the better generalization an artifact of the 'natural' problems I am looking at?</p>\n", 'ViewCount': '302', 'Title': 'Why do neural networks seem to perform better with restrictions placed on their topology?', 'LastEditorUserId': '31', 'LastActivityDate': '2012-03-18T04:38:07.220', 'LastEditDate': '2012-03-17T08:36:17.587', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '22', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<machine-learning><network-topology><neural-networks>', 'CreationDate': '2012-03-17T07:00:56.503', 'FavoriteCount': '3', 'Id': '455'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>The Eagles are a rock supergroup from the 70s and 80s, responsible for such classics as <em>Hotel California</em>. They have two quite distinctive sounds, one where guitarist Joe Walsh is present (for example, in <em>Life in the Fast Lane</em>) and one where he is absent. The latter songs have a markedly more sombre/boring feel.</p>\n\n<p>I'm curious to understand the degree to which an (unsupervised) learning algorithm would be able to detect the difference between the two sounds. One could imagine that it would be easy to tell the difference between speed metal and classical music, but what about sounds by the same band.</p>\n\n<blockquote>\n  <p>How would I set up such an experiment? Assume that I already have the relevant audio files in some standard format.</p>\n</blockquote>\n\n<p>Note that this should also apply to other rock groups, such as AC/DC who had a change of lead singer in 1980, and possibly even to other genres, possibly even more modern music.</p>\n", 'ViewCount': '315', 'Title': 'Clustering of Songs (The Joe Walsh Problem)', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:24:15.210', 'LastEditDate': '2012-04-22T16:24:15.210', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '19', 'PostTypeId': '1', 'OwnerUserId': '31', 'Tags': '<machine-learning><modelling>', 'CreationDate': '2012-03-19T11:33:08.247', 'FavoriteCount': '1', 'Id': '494'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '2298', 'Title': 'Why has research on genetic algorithms slowed?', 'LastEditDate': '2012-04-06T23:24:25.237', 'AnswerCount': '5', 'Score': '28', 'PostTypeId': '1', 'OwnerUserId': '258', 'FavoriteCount': '6', 'Body': '<p>While discussing some intro level topics today, including the use of genetic algorithms; I was told that research has really slowed in this field. The reason given was that most people are focusing on machine learning and data mining. <br>\n<strong>Update:</strong> Is this accurate? And if so, what advantages does ML/DM have when compared with GA?</p>\n', 'Tags': '<machine-learning><data-mining><evolutionary-computing><history>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-06T23:24:25.237', 'CommentCount': '2', 'AcceptedAnswerId': '565', 'CreationDate': '2012-03-21T01:17:25.527', 'Id': '561'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '704', 'Title': 'What combination of data structures efficiently stores discrete Bayesian networks?', 'LastEditDate': '2012-04-30T21:39:20.727', 'AnswerCount': '1', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '373', 'FavoriteCount': '1', 'Body': "<p>I understand the theory behind Bayesian networks, and am wondering what it takes to build one in practice. Let's say for this example, that I have a Bayesian (directed) network of 100 discrete random variables; each variable can take one of up to 10 values.</p>\n\n<p>Do I store all the nodes in a DAG, and for each node store its Conditional Probability Table (CPT)? Are there other data structures I should make use of to ensure efficient computation of values when some CPTs change (apart from those used by a DAG)?</p>\n", 'Tags': '<data-structures><machine-learning>', 'LastEditorUserId': '41', 'LastActivityDate': '2014-02-06T21:19:05.753', 'CommentCount': '3', 'AcceptedAnswerId': '587', 'CreationDate': '2012-03-21T05:11:40.937', 'Id': '580'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have designed a classifier M which recognizes gestures and classifies it under any category always. A gesture is classified based on the hamming distance between the sample time series y and the training time series x. The result of the classifier are probabilistic values. There are 3 classes/categories with labels A,B,C which classifies hand gestures where there are 100 samples for each class which are to be classified (single feature and data length=100). The data are different time series (x coordinate vs time). The training set is used to assign probabilities indicating which gesture has occured how many times. So,out of 10 training samples if gesture A appeared 6 times then probability that a gesture falls under category A is  </p>\n\n<blockquote>\n  <p>P(A)=0.6\n   similarly \n  P(B)=0.3</p>\n</blockquote>\n\n<p>and</p>\n\n<blockquote>\n  <p>P(C)=0.1</p>\n</blockquote>\n\n<p>Now, I am trying to compare the performance of this classifier with Bayes classifier, K-NN, Principal component analysis (PCA) and Neural Network. </p>\n\n<ol>\n<li>On what basis,parameter and method should I do it if I consider ROC or cross validate since the features for my classifier are the probabilistic values for the ROC plot hence what shall be the features for k-nn,bayes classification and PCA?</li>\n<li>Is there a code for it which will be useful.</li>\n<li>What should be the value of k is there are 3 classes of gestures?</li>\n</ol>\n\n<p>Please help. I am in a fix. </p>\n', 'ViewCount': '137', 'Title': 'Issue in comparing classifiers for pattern recognition', 'LastActivityDate': '2012-03-29T23:11:53.287', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '883', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<machine-learning><pattern-recognition>', 'CreationDate': '2012-03-29T20:22:01.553', 'FavoriteCount': '0', 'Id': '878'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am trying to compare the performance of a classification result with Bayes classifier, K-NN, Piece wise component analysis (PCA). I have doubts regarding the following (please excuse my lack of programming skills since I am a biologist and not a programmer thus finding the Matlab documentation hard to follow).</p>\n\n<p>In the Matlab code </p>\n\n<pre><code>    Class = knnclassify(Sample, Training, Group, k)\n    Group =  [1;2;3]   //where 1,2,3 represents Class A,B,C respectively.\n</code></pre>\n\n<p>What goes in the sample because my data is a 100 row 1 column for each of the classes? So Group 1 contains data like $[0.9;0.1;......n]$ where $n=100$. Would the sample be a vector containing random mixtures of the data points from the three classes? Same question for the <code>Training</code> matrix.</p>\n', 'ViewCount': '110', 'Title': 'Pattern classification: what goes into the sample?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:13:55.830', 'LastEditDate': '2012-04-22T16:13:55.830', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<machine-learning><modelling><pattern-recognition>', 'CreationDate': '2012-04-02T06:06:42.343', 'Id': '983'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The main idea of <a href="https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm">k-Nearest-Neighbour</a> takes into account the $k$ nearest points and decides the classification of the data by majority vote. If so, then it should not have problems in higher dimensional data because methods like <a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search#Locality_sensitive_hashing">locality sensitive hashing</a> can efficiently find nearest neighbours.</p>\n\n<p>In addition, feature selection with Bayesian networks can reduce the dimension of data and make learning easier.</p>\n\n<p>However, this <a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=2038&amp;context=compsci&amp;sei-redir=1&amp;referer=http%3A%2F%2Fscholar.google.com.hk%2Fscholar_url%3Fhl%3Den%26q%3Dhttp%3A%2F%2Frepository.cmu.edu%2Fcgi%2Fviewcontent.cgi%253Farticle%253D2038%2526context%253Dcompsci%26sa%3DX%26scisig%3DAAGBfm2_yYj4fmPTEDqBmHIZN-g3FWN7BA%26oi%3Dscholarr%26ei%3DzeB7T6qOIOmwiQeHj8GKCQ%26ved%3D0CBsQgAMoADAA#search=%22http%3A%2F%2Frepository.cmu.edu%2Fcgi%2Fviewcontent.cgi%3Farticle%3D2038%26context%3Dcompsci%22">review paper</a> by John Lafferty in statistical learning points out that non-parametric learning in high dimensional feature spaces is still a challenge and unsolved. </p>\n\n<p>What is going wrong?</p>\n', 'ViewCount': '139', 'Title': 'Non-Parametric Methods Like K-Nearest-Neighbours in High Dimensional Feature Space', 'LastEditorUserId': '848', 'LastActivityDate': '2012-04-04T20:29:21.947', 'LastEditDate': '2012-04-04T05:52:06.770', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '1046', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2012-04-04T01:58:12.193', 'Id': '1018'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m currently reading about machine learning and wondered how to apply it to playing <a href="http://en.wikipedia.org/wiki/Connect_Four">Connect Four</a>.</p>\n\n<p>My current attempt is a simple multiclass classificator using a sigmoid function model and the one-vs-all method.</p>\n\n<p>In my opinion, the input features have to be the state (disc of player 1, disc of player 2, empty) of the 7x6=42 grid fields. </p>\n\n<p>The output would be the number of the row to put the disc into. Because that is a discrete number between 1 and 7, I guess this can be treated as a multiclass classification problem.</p>\n\n<p>But how do I generate training examples usable in supervised learning? </p>\n\n<p>The main goal is to win the game but the outcome obviously isn\'t known when doing every but the last turn.\nIf I just let two players who decide randomly what to do play against each other thousands of times, will it be sufficient to simply take all turns made by the winner of each game round as training examples? Or do I have to do this in a completly different way?</p>\n\n<p><strong>Edit: As suggested in the comments I read a little about reinforcement learning.</strong>\nFrom what I know understand, Q-Learning should do the trick, i.e. I have to approximate a function Q of the current state and the action to take to be the maximum cumulative reward beginning in that state. Then each step would be to choose the action which results in the maximum value of Q. However, this game has way too many states in order to do this e.g. as a lookup table. So, what is an effective way to model this Q-Function?</p>\n', 'ViewCount': '718', 'Title': 'Machine learning algorithm to play Connect Four', 'LastEditorUserId': '994', 'LastActivityDate': '2012-06-13T08:41:59.500', 'LastEditDate': '2012-04-08T19:08:11.937', 'AnswerCount': '2', 'CommentCount': '9', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '994', 'Tags': '<machine-learning><board-games>', 'CreationDate': '2012-04-07T20:06:32.017', 'FavoriteCount': '1', 'Id': '1117'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I once had a veteran in my course that created an algorithm that would suggest cooking recipes. At first, all sort of crazy recipes would come out. Then, she would train the cooking algorithm with real recipes and eventually it would suggest very good ones. </p>\n\n<p>I believe she used something related to Bayes Theorem or Clustering, but she is long gone and so is the algorithm. I have searched the internet but looking for cooking recipes will yield any sort of results but not the one I am looking for. So, my question is:</p>\n\n<blockquote>\n  <p>What techniques can be used to devise an algorithm that (randomly) suggests feasible recipes (without using a database of fixed recipes)?</p>\n</blockquote>\n\n<p>Why would I bother looking for a cooking algorithm? Well, it was a very good example of a real world application of the underlying concepts, and such algorithm could be useful in different settings that are closer to the real world.</p>\n', 'ViewCount': '769', 'Title': 'How to devise an algorithm that suggests feasible cooking recipes?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-03T16:52:16.993', 'LastEditDate': '2012-04-22T16:09:20.370', 'AnswerCount': '4', 'CommentCount': '24', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<machine-learning><artificial-intelligence><modelling><recommendation-systems>', 'CreationDate': '2012-04-08T00:17:14.350', 'FavoriteCount': '1', 'Id': '1124'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm trying to figure out a way I could represent a Facebook user as a vector. I decided to go with stacking the different attributes/parameters of the user into one big vector (i.e. age is a vector of size 100, where 100 is the maximum age you can have, if you are lets say 50, the first 50 values of the vector would be 1 just like a thermometer).</p>\n\n<p>Now I want to represent the Facebook interests as a vector too, and I just can't figure out a way. They are a collection of words and the space that represents all the words is huge, I can't go for a model like a bag of words or something similar. How should I proceed? I'm still new to this, any reference would be highly appreciated.</p>\n", 'ViewCount': '101', 'Title': 'How to represent the interests of a Facebook user', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-22T16:01:26.117', 'LastEditDate': '2012-04-22T16:01:26.117', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1395', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1173', 'Tags': '<machine-learning><modelling><social-networks><knowledge-representation>', 'CreationDate': '2012-04-20T16:24:33.100', 'Id': '1394'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>My goal is to solve the following problem, which I have described by its input and output:</p>\n\n<p><strong>Input:</strong></p>\n\n<p>A directed acyclic graph $G$ with $m$ nodes, $n$ sources, and $1$ sink ($m > n \\geq 1$).</p>\n\n<p><strong>Output:</strong></p>\n\n<p>The <a href="https://en.wikipedia.org/wiki/Vc_dimension">VC-dimension</a> (or an approximation of it) for the neural network with topology $G$.</p>\n\n<p><strong>More specifics</strong>: </p>\n\n<ul>\n<li>Each node in $G$ is a sigmoid neuron. The topology is fixed, but the weights on the edges can be varied by the learning algorithm.</li>\n<li>The learning algorithm is fixed (say backward-propagation).</li>\n<li>The $n$ source nodes are the input neurons and can only take strings from $\\{-1,1\\}^n$ as input.</li>\n<li>The sink node is the output unit. It outputs a real value from $[-1,1]$ that we round up to $1$ or down to $-1$ if it is more than a certain fixed threshold $\\delta$ away from $0$. </li>\n</ul>\n\n<p>The naive approach is simply to try to break more and more points, by attempting to train the network on them. However, this sort of simulation approach is not efficient.</p>\n\n<hr>\n\n<h3>Question</h3>\n\n<p>Is there an efficient way (i.e. in $\\mathsf{P}$ when changed to the decision-problem: is VC-dimension less than input parameter $k$?) to compute this function? If not, are there hardness results?</p>\n\n<p>Is there a works-well-in-practice way to compute or approximate this function? If it is an approximation, are there any guarantees on its accuracy?</p>\n\n<h3>Notes</h3>\n\n<p>I asked a <a href="http://stats.stackexchange.com/q/25952/4872">similar question</a> on stats.SE but it generated no interest.</p>\n', 'ViewCount': '204', 'Title': 'Efficiently computing or approximating the VC-dimension of a neural network', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-10T02:12:14.187', 'LastEditDate': '2012-04-25T16:58:07.127', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<algorithms><complexity-theory><machine-learning><neural-networks><vc-dimension>', 'CreationDate': '2012-04-25T15:21:46.690', 'FavoriteCount': '1', 'Id': '1504'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '550', 'Title': 'Line separates two sets of points', 'LastEditDate': '2012-05-10T13:54:35.603', 'AnswerCount': '3', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '1170', 'FavoriteCount': '0', 'Body': '<p>If there is a way to identify if two sets of points can be separated by a line?</p>\n\n<blockquote>\n  <p>We have two sets of points $A$ and $B$ if there is a line that separates $A$ and $B$ such that all points of $A$ and only $A$ on the one side of the line, and all points of $B$ and only $B$ on the other side.</p>\n</blockquote>\n\n<p>The most naive algorithm I came up with is building convex polygon for $A$ and $B$ and test them for intersection. It looks time the time complexity for this should be $O(n\\log h)$ as for constructing a convex polygon. Actually I am not expecting any improvements in time complexity, I am not sure it can be improved at all. But al least there should be a more beautiful way to determine if there is such a line.</p>\n', 'Tags': '<algorithms><machine-learning><computational-geometry>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-10T13:54:35.603', 'CommentCount': '0', 'AcceptedAnswerId': '1687', 'CreationDate': '2012-05-05T15:18:04.503', 'Id': '1672'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '182', 'Title': 'How do I classify my emulator input optimization problem, and with which algorithm should I approach it?', 'LastEditDate': '2012-05-10T05:41:50.040', 'AnswerCount': '2', 'Score': '9', 'OwnerDisplayName': 'GManNickG', 'PostTypeId': '1', 'OwnerUserId': '1436', 'FavoriteCount': '1', 'Body': '<p>Due to the nature of the question, I have to include lots of background information (because my question is: how do I narrow this down?) That said, it can be summarized (to the best of my knowledge) as:</p>\n\n<p><strong>What methods exist to find local optimums on extremely large combinatorial search spaces?</strong></p>\n\n<h2>Background</h2>\n\n<p>In the tool-assisted superplay community we look to provide specially-crafted (not generated in real-time) input to a video game console or emulator in order to minimize some cost (usually time-to-completion). The way this is currently done is by playing the game frame-by-frame and specifying the input for each frame, often redoing parts of the run many times (for example, the <a href="http://tasvideos.org/2020M.html">recently published</a> run for <em>The Legend of Zelda: Ocarina of Time</em> has a total of 198,590 retries).</p>\n\n<p><strong>Making these runs obtain their goal usually comes down to two main factors: route-planning and traversal.</strong> The former is much more "creative" than the latter.</p>\n\n<p>Route-planning is determining which way the player should navigate overall to complete the game, and is often the most important part of the run. This is analogous to choosing which sorting method to use, for example. The best bubble sort in the world simply isn\'t going to outperform a quick-sort on 1 million elements.</p>\n\n<p>In the desire for perfection, however, traversal (how the route is carried out) is also a huge factor. Continuing the analogy, this is how the sorting algorithm is implemented. Some routes can\'t even be performed without very specific frames of input. This is the most tedious process of tool-assisting and is what makes the production of a completed run takes months or even years. It\'s not a <em>difficult</em> process (to a human) because it comes down to trying different variations of the same idea until one is deemed best, but humans can only try so many variations in their attention-span. The application of machines to this task seems proper here.</p>\n\n<p><strong>My goal now is to try to automate the traversal process in general for the Nintendo 64 system</strong>. The search space for this problem is <em>far</em> too large to attack with a brute-force approach. An n-frame segment of an N64 run has 2<sup>30n</sup> possible inputs, meaning a mere 30 frames of input (a second at 30FPS) has 2<sup>900</sup> possible inputs; it would be impossible to test these potential solutions, let alone those for a full two-hour run.</p>\n\n<p>However, I\'m not interested in attempting (or rather, am not going to even try to attempt) total global optimization of a full run. Rather, <strong>I would like to, given an initial input, approximate the <em>local</em> optimum for a particular <em>segment</em> of a run (or the nearest <em>n</em> local optimums, for a sort of semi-global optimization)</strong>. That is, given a route and an initial traversal of that route: search the neighbors of that traversal to minimize cost, but don\'t degenerate into trying all the cases that could solve the problem.</p>\n\n<p>My program should therefore take a starting state, an input stream, an evaluation function, and output the local optimum by minimizing the result of the evaluation.</p>\n\n<h2>Current State</h2>\n\n<p>Currently I have all the framework taken care of. This includes evaluating an input stream via manipulation of the emulator, setup and teardown, configuration, etc. And as a placeholder of sorts, the optimizer is a very basic genetic algorithm. It simply evaluates a population of input streams, stores/replaces the winner, and generates a new population by mutating the winner stream. This process continues until some arbitrary criteria is met, like time or generation number.</p>\n\n<p><strong>Note that the slowest part of this program will be, by far, the evaluation of an input stream</strong>. This is because this involves emulating the game for <em>n</em> frames. (If I had the time I\'d write my own emulator that provided hooks into this kind of stuff, but for now I\'m left with synthesizing messages and modifying memory for an existing emulator from another process.) On my main computer, which is fairly modern, evaluating 200 frames takes roughly 14 seconds. As such, I\'d prefer an algorithm (given the choice) that minimizes the number of function evaluations.</p>\n\n<p>I\'ve created a system in the framework that manages emulators concurrently. As such <strong>I can evaluate a number of streams at once</strong> with a linear performance scale, but practically speaking the number of running emulators can only be 8 to 32 (and 32 is really pushing it) before system performance deteriorates. This means (given the choice), an algorithm which can do processing while an evaluation is taking place would be highly beneficial, because the optimizer can do some heavy-lifting while it waits on an evaluation.</p>\n\n<p>As a test, my evaluation function (for the game <em>Banjo Kazooie</em>) was to sum, per frame, the distance from the player to a goal point. This meant the optimal solution was to get as close to that point as quickly as possible. Limiting mutation to the analog stick only, it took a day to get an <em>okay</em> solution. (This was before I implemented concurrency.)</p>\n\n<p>After adding concurrency, I enabled mutation of A button presses and did the same evaluation function at an area that required jumping. With 24 emulators running it took roughly 1 hour to reach the goal from an initially blank input stream, but would probably need to run for days to get to anything close to optimal.</p>\n\n<h2>Problem</h2>\n\n<p><strong>The issue I\'m facing is that I don\'t know enough about the mathematical optimization field to know how to properly model my optimization problem</strong>! I can roughly follow the conceptual idea of many algorithms as described on Wikipedia, for example, but I don\'t know how to categorize my problem or select the state-of-the-art algorithm for that category.</p>\n\n<p><strong>From what I can tell, I have a combinatorial problem with an extremely large neighborhood</strong>. On top of that, <strong>the evaluation function is extremely discontinuous, has no gradient, and has many plateaus</strong>. Also, there aren\'t many constraints, though I\'ll gladly add the ability to express them if it helps solve the problem; I would like to allow specifying that the Start button should not be used, for example, but this is not the general case.</p>\n\n<h2>Question</h2>\n\n<p><strong>So my question is: how do I model this? What kind of optimization problem am I trying to solve? Which algorithm am I suppose to use?</strong> I\'m not afraid of reading research papers so let me know what I should read!</p>\n\n<p>Intuitively, a genetic algorithm couldn\'t be the best, because it doesn\'t really seem to learn. For example, if pressing Start seems to <em>always</em> make the evaluation worse (because it pauses the game), there should be some sort of designer or brain that learns: "pressing Start at any point is useless." But even this goal isn\'t as trivial as it sounds, because sometimes pressing start <em>is</em> optimal, such as in so-called "pause backward-long-jumps" in <em>Super Mario 64</em>! Here the brain would have to learn a much more complex pattern: "pressing Start is useless except when the player is in this very specific state <em>and will continue with some combination of button presses</em>." </p>\n\n<p>It seems like I should (or the machine could learn to) represent input in some other fashion more suited to modification. Per-frame input seems too granular, because what\'s really needed are "actions", which may span several frames...yet many discoveries are made on a frame-by-frame basis, so I can\'t totally rule it out (the aforementioned pause backward-long-jump requires frame-level precision). It also seems like the fact that input is processed serially should be something that can be capitalized on, but I\'m not sure how.</p>\n\n<p><strong>Currently I\'m reading about (Reactive) Tabu Search, Very Large-scale Neighborhood Search, Teaching-learning-based Optimization, and Ant Colony Optimization.</strong></p>\n\n<p>Is this problem simply too hard to tackle with anything other than random genetic algorithms? Or is it actually a trivial problem that was solved long ago? Thanks for reading and thanks in advance for any responses.</p>\n', 'Tags': '<reference-request><machine-learning><combinatorics><optimization><search-problem>', 'LastEditorUserId': '1436', 'LastActivityDate': '2014-01-19T16:02:17.470', 'CommentCount': '2', 'AcceptedAnswerId': '2947', 'CreationDate': '2012-05-09T06:34:52.220', 'Id': '1774'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am learning the <a href="http://en.wikipedia.org/wiki/A%2a_search_algorithm" rel="nofollow">A* search algorithm</a> on an 8-puzzle problem.</p>\n\n<p>I don\'t have questions about A*, but I have some for the heuristic score -  Nilsson\'s sequence score.</p>\n\n<p><a href="http://www.heyes-jones.com/astar.html" rel="nofollow">Justin Heyes-Jones web pages - A* Algorithm</a> explains A* very clearly. It has a picture for Nilsson\'s sequence scores.</p>\n\n<p><img src="http://i.stack.imgur.com/Wbl63.jpg" alt="Nilsson\'s sequence scores"></p>\n\n<p>It explains:</p>\n\n<p><strong>Nilsson\'s sequence score</strong></p>\n\n<blockquote>\n  <p>A tile in the center scores 1 (since it should be empty)</p>\n  \n  <p>For each tile not in the center, if the tile clockwise to it is not the one that should be clockwise to it then score 2. </p>\n  \n  <p>Multiply this sequence by three and finally add the total distance you need to move each tile back to its correct position. </p>\n</blockquote>\n\n<p>I can\'t understand the steps above for calculating the scores.</p>\n\n<p>For example, for the start state, what h = 17?</p>\n\n<blockquote>\n  <p>0 A C </p>\n  \n  <p>H B D </p>\n  \n  <p>G F E</p>\n</blockquote>\n\n<p>So, by following the description, </p>\n\n<p><code>B</code> is in the center, so we have 1</p>\n\n<p>Then <code>for each title not in the center, if the **tile** clockwise to **it** is not the one that should be clockwise to it then score 2.</code> I am not sure what this statement means. </p>\n\n<p>What does the double starred <code>title</code> refer to? </p>\n\n<p>What does the double starred <code>it</code> refer to?</p>\n\n<p>Does the double starred <code>it</code> refer to the center title (B in this example)? Or does it refer to each title not in the center?</p>\n\n<p>Is the next step that we start from <code>A</code>? So <code>C</code> should not be clockwise to <code>A</code>, then we have 2. And then <code>B</code> should be clockwise to <code>A</code>, then we ignore, and so on and so forth?</p>\n', 'ViewCount': '1466', 'Title': "Nilsson's sequence score for 8-puzzle problem in A* algorithm", 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-18T22:19:54.293', 'LastEditDate': '2012-05-18T07:52:23.553', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'OwnerDisplayName': 'Jackson Tale', 'PostTypeId': '1', 'Tags': '<algorithms><machine-learning><search-algorithms><heuristics>', 'CreationDate': '2012-05-14T15:41:04.650', 'Id': '1904'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>So I\'m reading <em>"Introduction to Machine Learning"</em> 2nd edition, by Bishop, et. all.  On page 27 they discuss the Vapnik-Chervonenkis Dimension which is,</p>\n\n<blockquote>\n  <p><em>"The maximum number of points that can be shattered by H [the hypothesis class] is called the Vapnik-Chervonenkis (VC) Dimension of H, is denoted VC(H) and measures the capacity of H."</em></p>\n</blockquote>\n\n<p>Whereas "shatters" indicates a hypothesis $h \\in H$ for a set of N data points such that it separates the positive examples from the negative.  In such an example it is said that "H shatters N points".</p>\n\n<p>So far I think I understand this.  However, the authors lose me with the following:</p>\n\n<blockquote>\n  <p><em>"For example, four points on a line cannot be shattered by rectangles."</em></p>\n</blockquote>\n\n<p>There must be some concept here I\'m not fully understanding, because I cannot understand why this is the case.  Can anyone explain this to me?  </p>\n', 'ViewCount': '159', 'Title': 'Vapnik-Chervonenkis Dimension: why cannot four points on a line be shattered by rectangles?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-05-19T19:46:25.100', 'LastEditDate': '2012-05-19T08:23:32.217', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1932', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '603', 'Tags': '<machine-learning><vc-dimension>', 'CreationDate': '2012-05-18T20:22:02.690', 'Id': '1917'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '253', 'Title': 'Machine Learning algorithms based on "structural risk minimization"?', 'LastEditDate': '2012-05-23T15:42:06.250', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1603', 'FavoriteCount': '1', 'Body': '<p>Which machine learning algorithms (besides SVM\'s) use the principle of <a href="https://en.wikipedia.org/wiki/Structural_risk_minimization" rel="nofollow">structural risk minimization</a>?</p>\n', 'Tags': '<reference-request><machine-learning>', 'LastEditorUserId': '137', 'LastActivityDate': '2012-05-23T15:42:06.250', 'CommentCount': '5', 'AcceptedAnswerId': '2007', 'CreationDate': '2012-05-22T20:03:45.760', 'Id': '2006'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I was trying to come up with a system that would evaluate bylaws for an organization as to determine their underlying logic.</p>\n\n<p>I think a first-order predicate system would work for representing the rules, which could be translated from the text via part-of-speech tagging and other NLP techniques.  </p>\n\n<p>Is there a systematic way to interpret the first-order logic rules as a whole, or some type of ML architecture that would work as a second layer to find similarities between the elements.</p>\n\n<p>For example,</p>\n\n<blockquote>\n  <p>List of fun activities:</p>\n  \n  <ul>\n  <li>golf</li>\n  <li>coffee break</li>\n  <li>pizza</li>\n  </ul>\n  \n  <p>Bylaws:</p>\n  \n  <ol>\n  <li><p>On Friday, we play golf</p></li>\n  <li><p>On Friday or Saturday, we take a quick coffee break, and if it's Saturday, we get pizza</p></li>\n  </ol>\n</blockquote>\n\n<p>Conclusion: our group has fun on weekends</p>\n\n<p>It sounds far fetched, but I'm curious if it's possible.  I also realize that perhaps more first-order logic would be a better fit for driving the conclusions of the second layer.  </p>\n", 'ViewCount': '80', 'Title': 'Methods to evaluate a system of written rules', 'LastActivityDate': '2012-08-13T22:49:33.717', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '3160', 'Score': '10', 'OwnerDisplayName': 'jonsca', 'PostTypeId': '1', 'OwnerUserId': '88', 'Tags': '<machine-learning><algorithms><pattern-recognition><logic>', 'CreationDate': '2012-02-16T07:32:59.457', 'Id': '2382'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '911', 'Title': 'Must Neural Networks always converge?', 'LastEditDate': '2012-06-20T19:04:21.237', 'AnswerCount': '2', 'Score': '9', 'OwnerDisplayName': 'user1631', 'PostTypeId': '1', 'FavoriteCount': '1', 'Body': '<h2>Introduction</h2>\n\n<p><strong>Step One</strong></p>\n\n<p>I wrote a standard backpropegating neural network, and to test it, I decided to have it map XOR.</p>\n\n<p>It is a 2-2-1 network (with tanh activation function)</p>\n\n<pre><code>X1  M1\n        O1\nX2  M2\n\nB1  B2\n</code></pre>\n\n<p>For testing purposes, I manually set up the top middle neuron (M1) to be an AND gate and the lower neuron (M2) to be an OR gate (both output 1 if true and -1 if false).</p>\n\n<p>Now, I also manually set up the connection M1-O1 to be -.5, M2-O1 to be 1, and \nB2 to be -.75</p>\n\n<p>So if M1 = 1 and M2 = 1, the sum is (-0.5 +1 -0.75 = -.25) tanh(0.25) = -0.24</p>\n\n<p>if M1 = -1 and M2 = 1, the sum is ((-0.5)*(-1) +1 -0.75 = .75) tanh(0.75) = 0.63</p>\n\n<p>if M1 = -1 and M2 = -1, the sum is ((-0.5)*(-1) -1 -0.75 = -1.25) tanh(1.25) = -0.8</p>\n\n<p>This is a relatively good result for a "first iteration".</p>\n\n<p><strong>Step Two</strong></p>\n\n<p>I then proceeded to modify these weights a bit, and then train them using error propagation algorithm (based on gradient descent). In this stage, I leave the weights between the input and middle neurons intact, and just modify the weights between the middle (and bias) and output. </p>\n\n<p>For testing, I set the weights to be and .5 .4 .3 (respectively for M1, M2 and bias)</p>\n\n<p>Here, however, I start having issues.</p>\n\n<hr>\n\n<h2>My Question</h2>\n\n<p>I set my learning rate to .2 and let the program iterate through training data (A B A^B) for 10000 iterations or more.</p>\n\n<p><em>Most</em> of the time, the weights converge to a good result. However, at times, those weights converge to (say) 1.5, 5.7, and .9 which results in a +1 output (even) to an input of {1, 1} (when the result should be a -1).</p>\n\n<p>Is it possible for a relatively simple ANN which has a solution to not converge at all or is there a bug in my implementation?</p>\n', 'Tags': '<machine-learning><neural-networks>', 'LastEditorUserId': '1590', 'LastActivityDate': '2012-06-21T00:03:44.897', 'CommentCount': '0', 'AcceptedAnswerId': '2413', 'CreationDate': '2012-06-19T02:17:19.860', 'Id': '2406'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Apologies for another Markov Chain question but this one is best given its own question to avoid confusion. I am using a Markov Chain to get the 10 best search results from the union of 3 different search engines. The top 10 results are taken from each engine to form a set of 30 results.</p>\n\n<p>The chain starts at State x, a uniform distribution of set S = {1,2,3,...30}. If the current state is page P, select page Q uniformly from the union of the results from each search engine. If the rank of Q &lt; rank of P in 2 of the 3 engines that rank both P and Q, move to Q. Else, remain at P. </p>\n\n<p>This results in a number of pairwise comparisons being carried out. result2 is compared with result1 and a count is made of each time result2 ranks better than 1. The results are sorted by the results of the pairwise comparisons, with the lowest score ranked first. e.g.</p>\n\n<pre>\nEngine Rankings:                       Pairwise Comparison:\n         eng1   eng2   eng3                    result1  result2  result3  result4  result5\nresult1   1      2      2              result1    0        1        0        0        1\nresult2   4      3      1              result2    2        0        1        2        2\nresult3   2      4      5              result3    3        2        0        1        2\nresult4   5      5      3              result4    3        1        2        0        1\nresult5   3      1      4              result5    2        1        1        2        0\n\n</pre>\n\n<p>The problem with this example is, if we add the total of each row in the pairwise comparison, we get {2,7,8,7,7}, leaving 3 different results with the same score. I'm wondering if there is a method to further sort these results in order to refine the results so that I'm not left with a number of results that have the same score? I've seen Keminization but I can't see how this would apply? Can someone please give me some guidance?</p>\n", 'ViewCount': '107', 'Title': 'Improve Markov Chain results', 'LastActivityDate': '2012-06-23T06:01:57.383', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1916', 'Tags': '<algorithms><machine-learning><markov-chains>', 'CreationDate': '2012-06-22T19:37:01.610', 'Id': '2457'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Sometimes it is necessary to dig into Artificial Intelligence or specifically Machine Learning problems to make a research. Common googling (in my own experience) usually doesn't help much due to a lot of irrelevant or paid material among the results. Google Scholar in contrast is limited to scientific publications only, sometimes it is too narrow.</p>\n\n<p>I wonder if there is a kind of dedicated search engine over AI- and ML-related sites?</p>\n", 'ViewCount': '252', 'Title': 'Is there a search engine over Artificial Intelligence and Machine Learning -related sites?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-25T14:23:32.677', 'LastEditDate': '2012-07-05T07:14:50.053', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2068', 'Tags': '<reference-request><machine-learning><artificial-intelligence>', 'CreationDate': '2012-07-04T14:53:42.673', 'FavoriteCount': '2', 'Id': '2612'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Consider one specific useful function of our human brain: abstraction of object. Take the example of two pictures: if we are told the pictures are similar, we actually make conclusion about the aspects in which they are close to each other.</p>\n\n<p>I'm considering whether machine can have the ability described. More accurately, is it possible to find and select a set of feature representations of two samples (e.g. image, sound) such that under those representations, the samples are similar with respect to a metric, say weighted euclidean norm?</p>\n", 'ViewCount': '99', 'Title': 'Finding Feature Representation Such That Two Samples Are Similar in Feature Space', 'LastActivityDate': '2012-07-16T17:17:41.727', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '2768', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2012-07-15T12:01:45.340', 'FavoriteCount': '2', 'Id': '2749'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '11606', 'Title': 'What exactly is the difference between supervised and unsupervised learning?', 'LastEditDate': '2012-07-25T12:55:29.187', 'AnswerCount': '3', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '2266', 'FavoriteCount': '1', 'Body': "<p>Right now I am trying to understand Clustering-methods.</p>\n\n<p>What I understood by now:</p>\n\n<ol>\n<li><p>In supervised learning the categories, data is assigned to are known before computation.\nSo they are being used in order to 'learn' the parameters that are really significant for those Clusters.</p></li>\n<li><p>In unsupervised learning Datasets are assigned to segments, without the clusters being known.</p></li>\n</ol>\n\n<p>Does that mean that if I don't even know which parameters are crucial for a segmentation I should prefer supervised learning?</p>\n", 'Tags': '<machine-learning>', 'LastEditorUserId': '31', 'LastActivityDate': '2013-12-18T11:22:14.007', 'CommentCount': '2', 'AcceptedAnswerId': '2908', 'CreationDate': '2012-07-25T12:22:35.027', 'Id': '2907'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>A Naive Bayes predictor makes its predictions using this formula:</p>\n\n<p>$$P(Y=y|X=x) = \\alpha P(Y=y)\\prod_i P(X_i=x_i|Y=y)$$</p>\n\n<p>where $\\alpha$ is a normalizing factor. This requires estimating the parameters $P(X_i=x_i|Y=y)$ from the data. If we do this with $k$-smoothing, then we get the estimate</p>\n\n<p>$$\\hat{P}(X_i=x_i|Y=y) = \\frac{\\#\\{X_i=x_i,Y=y\\} + k}{\\#\\{Y=y\\}+n_ik}$$</p>\n\n<p>where there are $n_i$ possible values for $X_i$. I'm fine with this. However, for the prior, we have</p>\n\n<p>$$\\hat{P}(Y=y) = \\frac{\\#\\{Y=y\\}}{N}$$</p>\n\n<p>where there are $N$ examples in the data set. Why don't we also smooth the prior? Or rather, <em>do</em> we smooth the prior? If so, what smoothing parameter do we choose? It seems slightly silly to also choose $k$, since we're doing a different calculation. Is there a consensus? Or does it not matter too much?</p>\n", 'ViewCount': '1530', 'Title': 'Smoothing in Naive Bayes model', 'LastEditorUserId': '88', 'LastActivityDate': '2012-08-08T02:02:36.983', 'LastEditDate': '2012-08-08T02:02:36.983', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2341', 'Tags': '<machine-learning><probability-theory><statistics>', 'CreationDate': '2012-08-02T15:47:28.573', 'FavoriteCount': '1', 'Id': '3005'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm not even sure if this is the right StackExchange to post this, but it seems like sentiment analysis would go here.</p>\n\n<p>What would be the best approach to determine if two people on Twitter are actually friends?</p>\n\n<p>I think that the first criteria would be that they are following each other. This would eliminate all of the celebrities, companies, etc. that a person follows.</p>\n\n<p>The second criteria could be physical proximity to one another. If two people tweet from the same general areas, then there's probably a higher chance that they actually know each other.</p>\n\n<p>After that, I'm not sure what criteria I should look for. Would sentiment analysis of their tweets to each other be a viable option? With that friendly sentiment could indicate that they actually know each other.</p>\n", 'ViewCount': '133', 'Title': 'Analyzing Twitter Relationships', 'LastEditorUserId': '41', 'LastActivityDate': '2012-10-25T01:49:05.057', 'LastEditDate': '2012-08-06T03:48:54.740', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2214', 'Tags': '<algorithms><machine-learning><computer-networks><social-networks>', 'CreationDate': '2012-08-05T17:56:11.877', 'Id': '3050'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In Tom Mitchell\'s book <a href="http://rads.stackoverflow.com/amzn/click/0070428077" rel="nofollow">"Machine Learning"</a>, Chap.1, a checkers game is used to illustrate how machine learning can be applied solve problems.</p>\n\n<p>An experience propagation rule is described for iterative learning of a hypothesis. Suppose a game has been played and watched by the program, the state of the endgame is labeled 100 for winning and -100 for losing. For each of the states on the path toward the endgame, we label it as $\\hat{V}(Successor)$, where $\\hat{V}(state)$ is the current model output on some state. Then the model is trained by adding the new label, and iteratively, the model converges to a good checkers program.</p>\n\n<p>Why does this experience propagation rule work? It is mentioned in the book that it works quite well for most chess games.</p>\n', 'ViewCount': '69', 'Title': "Why does the experience propagation rule for checkers work in Tom Mitchell's book?", 'LastEditorUserId': '88', 'LastActivityDate': '2012-12-21T15:15:56.883', 'LastEditDate': '2012-08-23T07:31:50.323', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7537', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<machine-learning>', 'CreationDate': '2012-08-23T01:54:31.707', 'Id': '3296'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In computer vision, scales are important when we carry out a scene analysis. Choosing different scales affect the result of the analysis. For example, if a face is relatively small in the scene, then the details including nose, eyes will be omitted. On the other hand, details on larger faces become relatively more salient.</p>\n\n<p>I know both Gaussian Blur with different sigmas and Down Sampling on the image can generate different scales. Which is more reasonable on a cognitive sense?</p>\n', 'ViewCount': '95', 'Title': 'Which Is a Better Way of Obtaining Scales, Gaussian Blur or Down Sampling?', 'LastActivityDate': '2012-08-24T18:29:39.153', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3319', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<machine-learning><computer-vision><image-processing>', 'CreationDate': '2012-08-24T08:40:02.273', 'Id': '3310'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Just thinking of Counter Strike as a canonical example, if you have a coordinate representation of the map and for every player you have a complete history of everything you might need for every moment of time, say every 10 miliseconds or something and you just recorded where the players went around the map, and what they did. So maybe, for example, at each time <code>t</code> you had <code>v(t)</code> a vector function whose components are (<code>location(t)</code>, <code>velocity(t)</code>, <code>rotationVector(t)</code>, <code>rotationVelocity(t)</code>, <code>isFiring(t)</code>, <code>ammoCount(t)</code>, <code>health(t)</code>, <code>isEnemyVisible(t)</code>, <code>isTeamMateVisible(t)</code>) or whatever other measurements you think would be useful for the state space.</p>\n\n<p>If you collected a bunch of data like this what sort of hypotheses or models would you consider testing? Would it be possible to construct a probabilistic model to classify histories and possibly predict outcomes of player-enemy encounters? Could you train AI bots on this data?</p>\n', 'ViewCount': '112', 'Title': 'What could you learn from studying player movement and behaviour on online FPS games?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-25T17:56:03.673', 'LastEditDate': '2012-09-24T05:47:40.930', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2631', 'Tags': '<machine-learning><computer-games>', 'CreationDate': '2012-08-24T18:19:44.083', 'Id': '3318'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am new to the reinforcement learning. In the textbook there is a question which confuses me. It says: To think about three substantially different reward schemes for a given policy on the grid world, and for each scheme I should give rewards and discount.</p>\n\n<p>I can think of one, but it needs three substantially different reward schemes. What could others look like?</p>\n\n<p><a href="http://www.flickr.com/photos/80454490@N00/7819773356/in/photostream" rel="nofollow">Picture</a>:</p>\n\n<p><img src="http://i.stack.imgur.com/6iKcO.jpg" alt="enter image description here"></p>\n', 'ViewCount': '105', 'Title': 'How many rewards schemes are there in reinforcement learning?', 'LastEditorUserId': '6998', 'LastActivityDate': '2013-11-18T20:25:59.393', 'LastEditDate': '2013-11-18T20:25:59.393', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '-1', 'OwnerDisplayName': 'user824624', 'PostTypeId': '1', 'Tags': '<machine-learning>', 'CreationDate': '2012-08-15T04:38:07.537', 'Id': '3334'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '466', 'Title': 'What are the mathematical prerequisites for adaptive machine learning algorithms?', 'LastEditDate': '2012-09-28T09:36:27.647', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2798', 'FavoriteCount': '2', 'Body': '<p>I am a PhD student in Computer Science who switched his PhD a little bit towards ML algorithms combined with something else... I am an expert in that something else, say image processing, but not an expert in Machine Learning. What should I read/learn to get the ML mathematics right? Especially for adaptive learning algorithms.</p>\n', 'Tags': '<reference-request><machine-learning><education><learning-theory>', 'LastEditorUserId': '157', 'LastActivityDate': '2012-10-26T23:17:51.163', 'CommentCount': '2', 'AcceptedAnswerId': '6324', 'CreationDate': '2012-09-12T07:31:52.607', 'Id': '3510'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m looking for good resources regarding <strong>Support Vector Machines</strong>, or suggestions where to start learning SVM.</p>\n\n<p>Already used references: </p>\n\n<ul>\n<li><p><a href="http://dde.binghamton.edu/kodovsky/svm/index.php?content=Material" rel="nofollow">Stanford ML course by Andrew Ng</a> is great place to star  </p></li>\n<li><p>A Tutorial on Support Vector Machines for Pattern Recognition, Burges, 1998<br>\n<a href="http://svms.org/tutorials/" rel="nofollow">SVM tutorials</a>   </p></li>\n<li><p>Neural Networks and Learning Machines, Third Edition  Learning with Kernels - SVM, A. Smola  </p></li>\n</ul>\n', 'ViewCount': '289', 'Title': 'Machine Learning - Support Vector Machines', 'LastEditorUserId': '867', 'LastActivityDate': '2014-04-27T23:29:08.580', 'LastEditDate': '2012-12-10T17:14:27.817', 'AnswerCount': '4', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2592', 'Tags': '<reference-request><machine-learning><data-mining>', 'CreationDate': '2012-09-26T20:12:16.970', 'FavoriteCount': '2', 'Id': '4750'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '375', 'Title': 'Using Funk SVD with SGD?', 'LastEditDate': '2012-09-30T18:00:23.330', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '106', 'FavoriteCount': '2', 'Body': '<p>I work on a recommender system framework which is implemented with a variant on Funk SVD (See his explanation of his algorithm <a href="http://sifter.org/~simon/journal/20061211.html" rel="nofollow" title="here">here</a>). </p>\n\n<p>However the framework that we are trying to integrate doesn\'t support Funk SVD, only SGD (<a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="nofollow">Stochastic Gradient Descent</a>). </p>\n\n<p>Since shouldn\'t these be compatible? In other words, I should be able to create the U and V matrices with SGD and then treat them like they were made via the Funk SVD process?</p>\n\n<p>Are there any disadvantages of using this versus the algorithm detailed by Funk?</p>\n', 'Tags': '<algorithms><machine-learning><matrices>', 'LastEditorUserId': '106', 'LastActivityDate': '2012-09-30T18:00:23.330', 'CommentCount': '5', 'AcceptedAnswerId': '4809', 'CreationDate': '2012-09-30T02:09:47.340', 'Id': '4806'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I want the conditional probability for each topic (being the word that we give as input). For example, the text being</p>\n\n<blockquote>\n  <p>have seen and reviewed your requirements you posted here.  If you can\n  give me the fix criteria/category of your data mining then I can do\n  this job. If you want me to define and allot criteria and categorize\n  it in then charges will be extra for per categorization included.</p>\n  \n  <p>I have seen and reviewed your requirements you posted here.  If you can give me the fix criteria/category of your data mining then\n  I can do this job. If you want me to define and allot criteria and\n  categorize it in then charges will be extra for per categorization\n  included.</p>\n</blockquote>\n\n<hr>\n\n<p>Assume that I give a word called <strong>research</strong> as an input, I want to know</p>\n\n<pre><code>What is the likelihood/probability that the text relates to research?\n</code></pre>\n\n<p>What algorithms we should create to get the above?</p>\n', 'ViewCount': '267', 'Title': 'Algorithm to find the probability of a given text to be about a large topic', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-17T19:56:03.353', 'LastEditDate': '2013-03-11T07:20:01.300', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '3120', 'Tags': '<machine-learning><natural-lang-processing>', 'CreationDate': '2012-10-09T07:14:33.467', 'FavoriteCount': '1', 'Id': '4970'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '157', 'Title': 'How can lazy learning systems simultaneously solve multiple problems?', 'LastEditDate': '2012-10-14T09:43:01.483', 'AnswerCount': '3', 'Score': '5', 'OwnerDisplayName': 'Shedeki', 'PostTypeId': '1', 'OwnerUserId': '8080', 'FavoriteCount': '1', 'Body': u'<p>On the english Wikipedia <a href="http://en.wikipedia.org/wiki/Lazy_learning" rel="nofollow">it says about lazy learning systems</a>:</p>\n\n<blockquote>\n  <p>Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems [\u2026]</p>\n</blockquote>\n\n<p>What does this mean? I can only guess what "approximated locally" is supposed to say but even then I have no idea how one is supposed to follow from the other.</p>\n', 'Tags': '<terminology><machine-learning>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-07T15:33:57.370', 'CommentCount': '0', 'AcceptedAnswerId': '11856', 'CreationDate': '2012-09-10T21:52:18.973', 'Id': '6058'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have rank-deficient matrix $M \\in \\mathbb{R}^{n\\times m}$ with $\\text{rank}(M) = k$ and I want to find a <a href="http://en.wikipedia.org/wiki/Rank_factorization" rel="nofollow">rank factorization</a> $M = PQ$ with $P \\in \\mathbb{R}^{n \\times k}$ and $Q \\in \\mathbb{R}^{k \\times m}$. </p>\n\n<p>A popular approach is to compute the singular value decomposition (SVD) $M = UDV^*$ and keep the columns of $U$ and rows of $V$ corresponding to the non-zero singular values. This is a great approach, especially since it behaves nicely under noise. However, SVD seems to compute more than I need for just rank factorization (and the noise tolerance is cool, but not necessary). </p>\n\n<p><strong>What are the other approaches I can use?</strong> In particular, I am interested in algorithms that have <em>one</em> (or more) of the following properties:</p>\n\n<ol>\n<li>Outperform SVD asymptotically.</li>\n<li>Outperform SVD in practice, or on special inputs (for a reasonably interesting class of special inputs).</li>\n<li>Performance under small perturbation of $M$ is well understood.</li>\n</ol>\n\n<p>I am fine with giving $k$ to the algorithm ahead of time. Note that SVD does not require this (unless we are doing a perturbation analysis, but even then we usually give a bound on perturbation size and determine $k$ at run-time based on that).</p>\n', 'ViewCount': '202', 'Title': 'Alternatives to SVD for rank factorization', 'LastEditorUserId': '55', 'LastActivityDate': '2013-01-06T21:42:05.483', 'LastEditDate': '2013-01-06T21:42:05.483', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<algorithms><machine-learning><numerical-analysis><linear-algebra>', 'CreationDate': '2012-11-05T20:45:27.737', 'Id': '6497'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p><a href="http://www.scotthyoung.com/blog/mit-challenge/#1" rel="nofollow">http://www.scotthyoung.com/blog/mit-challenge/#1</a></p>\n\n<p>This guy\'s work is mind blowing. He learned the 4 year MIT CS curriculum in 1 year, at home through opencourseware. I want to get into artificial neural networks and machine learning, and I thought doing some of the courses he did would help. Problem is, I have no idea which ones, and in what order! Some of the ones I think I should do are the single and multivariable calc, logic 1 and 2, artificial intelligence, mathematics for cs, etc.</p>\n\n<p>Which ones should I do, and what order?</p>\n\n<p>Thank you all!</p>\n', 'ViewCount': '109', 'ClosedDate': '2012-11-19T14:53:52.027', 'Title': 'What courses to learn for artificial neural networks and machine learning?', 'LastActivityDate': '2012-11-19T06:10:23.297', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4647', 'Tags': '<logic><machine-learning><artificial-intelligence>', 'CreationDate': '2012-11-19T05:28:14.343', 'Id': '6754'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a complex query $Q$ used to search a dataset $S$ to find $H_\\text{exact} = \\{s \\in S \\mid \\text{where $Q(s)$ is True}\\}$. Each query takes on average time $t$ so the overall time in the linear search is $t\\cdot |S|$. I can break a query down into simpler sub-queries q_i and find $H_\\text{approx} = \\{s\\in S \\mid \\forall q_j(s) \\text {is True}\\}$  and where $H_\\text{exact}\\subseteq H_\\text{approx}$. Each subquery $q_i$ is much faster to compute, so overall it is faster to find $H_\\text{approx}$ and then use $Q$ to find $H_\\text{exact}$.</p>\n\n<p>Each $Q$ has many $q_i$. The overlap between different $Q$ is high. I\'m looking for a way to determine a decision-tree-like set of fixed questions $q_j$ which minimize the average time to find a H_exact, based on a large sample of search queries.</p>\n\n<p>To make this more concrete, suppose the data set contains the 7 billion people in the world, and the complex queries are things like "the woman who lives in the red house on the corner of 5th and Lexington in a city starting with B."</p>\n\n<p>The obvious solution is to check every person in world and see who matches the query. There may be more than one such person. This method takes a long time. </p>\n\n<p>I could pre-compute this query exactly, in which case it would be very fast .. but only for this question. However, I know that other queries are for the woman who lives on the blue house on the same corner, the man who lives on the same corner, the same question but in a city starting with C, or something totally different, like \'the king of Sweden.\'</p>\n\n<p>Instead, I can break the complex question down into a set of easier but more general sets. For example, all of the above questions have a gender-role based query, so I can precompute the set of all people in the world who consider themselves a \'woman.\' This sub-query takes essentially no time, so the overall search time decreases by roughly 1/2. (Assuming that by other knowledge we know that a Swedish "king" cannot be a "woman." Hatshepsut was an Egyptian woman who was king.)</p>\n\n<p>However, there are sometimes queries which aren\'t gender-based, like "the person who lives on 8th street in a red house in a city starting with A." I can see that the subquery "lives in a red house" is common, and pre-compute a list of all those people who live in a red house.</p>\n\n<p>This gives me a decision tree. In the usual case, each branch of the decision tree contains different questions, and the methods to select the optimal terms for the decision tree are well known. However, I\'m building on an existing system which requires that all branches must ask the same questions.</p>\n\n<p>Here\'s an example of a possible final decision set: question 1 is \'is the person a woman?\', question 2 is \'does the person live in a red house?\', question 3 is \'does the person live in a city starting with A or does the person live in a city starting with B?\', and question 4 is \'does the person live on a numbered street?\'.</p>\n\n<p>When a query $Q$ comes in, I see if its $q_i$ match any of the pre-computed questions $q_j$ I\'ve determined. If so, then I get the intersection of those answers, and ask the question $Q$ on that intersection subset. Eg, if the question is "people who live in a red house on an island" then find that "person lives in a red house" is already precomputed, so it\'s only matter of finding the subset of those who also live on an island.</p>\n\n<p>I can get a cost model by looking at a set of many $Q$ and check to see the size of the corresponding $H_\\text{approx}$. I want to minimize the average size of $H_\\text{approx}$.</p>\n\n<p>The question is, how do I optimize the selection of possible $q_j$ to make this fixed decision tree? I tried a GA but it was slow to converge. Probably because my feature space has a few million possible $q_j$. I\'ve come up with a greedy method, but I\'m not happy with the result. It too is very slow, and I think I\'m optimizing the wrong thing.</p>\n\n<p>What existing research should I be looking at for ideas?</p>\n', 'ViewCount': '98', 'Title': 'Fixed-length decision-tree-like feature selection to minimize average search performance', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-19T09:26:37.540', 'LastEditDate': '2012-11-19T09:26:37.540', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4650', 'Tags': '<algorithms><optimization><machine-learning><greedy-algorithms>', 'CreationDate': '2012-11-19T09:17:01.957', 'Id': '6763'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Having a unsupervised algorithm done on a dataset (e.g. K-means), how can I determine which cluster is normal and which is anomalous (for 30 clusters, for example)? </p>\n\n<p>If the dataset contains normal traffic much more than anomalies (99%), then the radius of clusters associate to normal traffic is bigger. Is this true? Why? </p>\n\n<p>If so, then we set the clusters with greater radius to normal according to a threshold. The smaller the threshold, the more the detection rate and the more the false alarm rate. Is this true?</p>\n\n<p>Could a labeled dataset help determine the normal clusters? For example, finding the closest point to the centroid of a given cluster and checking whether it is labeled anomaly or not?</p>\n\n<p>[1] uses Cluto software and its mountain visualization graph that I can't understand why its 3D, having feature space of dimension 41.</p>\n\n<p>Reference: \n[1] Jose F. Nieves, Data Clustering for Anomaly Detection in Network Intrusion Detection</p>\n", 'ViewCount': '116', 'Title': 'Unsupervised anomaly detection: assigning the clusters to normal and anomaly', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-08-28T05:17:58.957', 'LastEditDate': '2013-06-18T15:43:13.387', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'OwnerDisplayName': 'Yasser MZadeh', 'PostTypeId': '1', 'OwnerUserId': '4654', 'Tags': '<machine-learning><pattern-recognition>', 'CreationDate': '2012-11-19T06:43:36.200', 'Id': '6766'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>There are N players and M objects, each of the objects has a value. Each player has a strategy in choosing an object. Each round a player will choose an object, many players can choose the same object. However the value of each object is divided evenly among every player that has chosen it. There will be 9000 rounds(choices) per game. Our goal is to maximize the values that we accumulate at the end of the game.</p>\n\n<p>Question: how can I build a probability distribution function for each playing assuming that their decisions are random variables?</p>\n\n<p>Current Approach: My current approach is to count the frequency of a player choosing a specific object and dividing by the total number of rounds, that would give a probability a player is likely to choose that specific object.</p>\n\n<p>Problem: With each player playing aggressively trying to be unpredictable as possible(noise), with my current approach the probability distribution functions are not accurate(9000 rounds doesn't seem to be enough data). Is there a better way to build these distribution functions?</p>\n\n<p>Note: I've read somewhere that (Bayes model and HMM) are more superior than frequency counts, but I am not sure how to adapt it to this situation.</p>\n", 'ViewCount': '114', 'Title': 'Building probability distribution functions from observation', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-20T09:28:55.593', 'LastEditDate': '2012-11-20T09:28:55.593', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4365', 'Tags': '<machine-learning><probability-theory><modelling>', 'CreationDate': '2012-11-20T00:58:46.293', 'Id': '6775'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>I am wondering why some methods transform the underlying graphical model (Bayesian Network for example) to a junction tree\xb9? What are the advantages?  Also what are the limitations?  </p>\n\n<p>I believe it\'s for computational purposes. If that\'s the case under what circumstances it is not recommended to transform the underlying DAG to joint-trees? </p>\n\n<p><em>Edit</em>: speaking about graphical models in general (whether they are probabilistic or not), is there some guidelines when to transform them i.e. decompose them? </p>\n\n<hr>\n\n<p><sup>1</sup> Junction trees are also known as <a href="http://en.wikipedia.org/wiki/Tree_decomposition" rel="nofollow">tree decomposition</a>.</p>\n', 'ViewCount': '99', 'Title': 'Why use joint trees in Graphical Models?', 'LastEditorUserId': '4598', 'LastActivityDate': '2012-12-17T21:12:13.027', 'LastEditDate': '2012-12-17T21:12:13.027', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<machine-learning>', 'CreationDate': '2012-11-27T04:56:54.067', 'Id': '6940'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>So, I was trying to learn machine learning, and, after watching a couple of Andrew Ng's lectures decided to try and write a simple piece of code to determine what someone's salary would be based on the number of years they worked at a company by this simple linear function:</p>\n\n<p>salary = w1 * numberOfYears + w0</p>\n\n<p>I then used the least square method to calculate the error between the predicted results and the actual results and tried to minimize the error of the gradient of that function:</p>\n\n<p>Error = (1/2) [ sum of (predicted - actual)^2 for all samples (x, y) ]</p>\n\n<p>The predicted value is the one calculated by the linear equation above, and actual = y.  w1 and w0 are weights to the function that are set to some initial values (0 and 0 for example) and are changed to decrease the error throughout the process of gradient descent.</p>\n\n<p>Steps to the algorithm:</p>\n\n<p>1)  Choose some (random) initial values for the model parameters (w).<br />\n2)  Calculate the gradient G of the error function with respect to each model parameter.<br />\n3)  Change the model parameters so that we move a short distance in the direction of the greatest rate of decrease of the error, i.e., in the direction of -G.<br />\n4)  Repeat steps 2 and 3 until G gets close to zero.</p>\n\n<p>In my implementation I have this code:</p>\n\n<pre><code>for(int i = 0; i &lt; numSamples; i++) {\n    double error = prediction(data.X[i]) - data.Y[i];\n    while(nearsZero(error)) {\n        for(int j = 0; j &lt; w.length; j++) {\n            w[j] -=  0.1 * error * data.X[i][j];\n        }\n        error = data.Y[i] - prediction(data.X[i]);\n    }\n}\n</code></pre>\n\n<p>If I run this with only one sample (meaning ignore the outermost loop), then the weights continuously subtract a value that is continuously nearing infinity (or -infinity).  If I change the w[j] -= ... to a w[j] += ... then the function works for the first value and sets initial w that will solve it for one sample (but that isn't what I was supposed to do as far as I can tell).  Also, when I add multiple samples the numbers just do the same thing on the second sample that they were doing on the first sample when I had -=.</p>\n\n<p>I feel like gradient descent doesn't make sense here because it was demoed on graphs like z=y^2+x^2, which looks like a big bowl with one central min that it will find eventually.</p>\n\n<p>On the graph in my problem the graph looks like a parabola that extends to infinity in both directions and has infinite min values along a line.</p>\n\n<p>I'm not sure what it is that I am doing wrong, but I would assume that it's something to do with my understanding of the problem.  If anyone knows how to get this working I would appreciate it.</p>\n\n<p><strong>EDIT:</strong> Updated data.X[i] in the while loop to data.X[i][j].  Each data point i should have some value Y[i] and an array of X values at X[i].</p>\n", 'ViewCount': '386', 'Title': 'Machine Learning: how to correctly calculate gradient descent for simple linear problem', 'LastEditorUserId': '4737', 'LastActivityDate': '2012-11-28T16:36:50.723', 'LastEditDate': '2012-11-28T16:36:50.723', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4737', 'Tags': '<machine-learning><linear-algebra>', 'CreationDate': '2012-11-27T22:31:50.273', 'Id': '6972'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Is machine learning a branch of (AI) Artificial Intelligence, or its own field?</p>\n', 'ViewCount': '87', 'ClosedDate': '2012-12-07T21:06:19.347', 'Title': 'Machine Learning and Artificial Intelligence', 'LastActivityDate': '2012-12-07T02:41:01.213', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7221', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4908', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2012-12-07T01:12:58.533', 'Id': '7220'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I was reading Wiki on <a href="http://en.wikipedia.org/wiki/Feature_vector" rel="nofollow">feature vectors</a>, and as far as I can see, it suggests creating new features from already existing features:</p>\n\n<blockquote>\n  <p>Higher-level features can be obtained from already available features\n  and added to the feature vector, for example for the study of diseases\n  the feature \'Age\' is useful and is defined as Age = \'Year of birth\' -\n  \'Year of death\'. This process is referred to as feature construction.</p>\n</blockquote>\n\n<p>But assuming that you already have included <code>\'Year of birth\'</code> and <code>\'Year of Death\'</code> as features, will adding <code>\'Age\'</code> (that is, <code>\'Year of birth\' - \'Year of death\'</code>) as a feature in the feature vector improve it in any way? I\'m thinking not, as the variables are linearly dependent.</p>\n\n<p>If it depends on the machine learning algorithm used, I am mostly interested in SVMs.</p>\n', 'ViewCount': '134', 'Title': 'Do linearly dependent features in feature vectors improve the feature vector?', 'LastActivityDate': '2012-12-08T05:42:59.170', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7246', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2826', 'Tags': '<machine-learning>', 'CreationDate': '2012-12-07T17:02:50.883', 'Id': '7232'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Suppose through $\\ell_1$ minimization I obtained two sparse probability distributions $P, Q$ which may contain many zero terms. Then I would like to compute the KL-Divergence of them $D(P || Q) = \\sum_i {p_i\\log(\\frac{p_i}{q_i})}$.  However, since the probability distribution is sparse, it might occur that $p_i \\not= 0$ and $q_i = 0$. In that case, KL-Divergence is not well defined.  One solution is to incorporate Dirichlet Prior. However, I am afraid by doing so the sparsity of the probability distributions is violated.  Is there any other way to compute the KL-Divergence of the two probability distributions?</p>\n', 'ViewCount': '91', 'Title': '$\\ell_1$ Minimization of Probability Distribution and KL-Divergence', 'LastEditorUserId': '19', 'LastActivityDate': '2012-12-14T15:07:19.970', 'LastEditDate': '2012-12-14T15:07:19.970', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7394', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<machine-learning><information-theory>', 'CreationDate': '2012-12-14T00:14:24.593', 'Id': '7392'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am interested in the stateless k-armed bandit problem, where an agent repeatedly chooses one of k independent arms, each with a different distribution of rewards, and tries to maximize its total reward.</p>\n\n<p>I read many papers about this subject, but I am still confused, as there are two types of solutions:</p>\n\n<p>A. It has been proven that the optimal solution to this problem is an index policy: For each arm, calculate a quality index, based on the rewards received from that arm so far. The index roughly estimates an upper confidence bound on the expected reward from that arm. Now choose the arm with the highest index.</p>\n\n<p>B. On the other hand, this problem can also be presented as a Markov decision process, which can be solved by Q-learning. The general formula for Q-learning is:</p>\n\n<p>$Q_{t+1}(s,a) := (1-z_t) Q_t(s,a) + z_t (R_t + g * max_{a'}(Q_t(s',a'))$</p>\n\n<p>Where: t is the time, s is the state we were at, a is the action we did, s' is the state we got into, $z_t$ is the rate of learning at time t, R_t is the reward we received at time t, and g is a constant discount rate.</p>\n\n<p>In this case, there is only a single non-terminal state. Each arm-pull is an episode: it starts with the initial state, and always goes to the final state. Therefore, the Q value of the final state is always 0, and we only need to calculate Q values for actions of the single initial state:</p>\n\n<p>$Q_{t+1}(a) := (1-z_t) Q_t(a) + z_t R_t$</p>\n\n<p>It is guaranteed that the process will converge to an optimal policy, if each action is selected eventually, and if the learning rate $z_t$ decreases in an appropriate rate (speficically, $\\sum_{t=1}^\\infty z_t^2 &lt; \\infty$ and $\\sum_{t=1}^\\infty z_t = \\infty$).</p>\n\n<p>Now, my question is: what is the relation between two methods for solving the k-armed bandit problem?</p>\n\n<ol>\n<li><p>Is it possible to prove, that the Q values converge to one of the indices given in the literature?</p></li>\n<li><p>Why use an index method, if it is possible to use the much simpler Q-learning method?</p></li>\n</ol>\n", 'ViewCount': '97', 'Title': 'k-armed bandit - index policies vs. Q-learning', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-02-25T16:30:25.537', 'LastEditDate': '2012-12-27T15:10:45.260', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7615', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<machine-learning>', 'CreationDate': '2012-12-26T09:19:39.360', 'Id': '7602'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>As I know, there are several upper bounds on the generalization error of hypothesis set with respect to sample complexity. For hypothesis space $V$, if the learning algorithm output the set of hypotheses that are consistent with the training data, i.e., $\\sum\\limits_{1 \\leq i \\leq n}{\\frac{I[h(x_i) \\not= y_i]}{n}} = 0$, the VC theory gives the bound on generalization error. If we consider the "margin" or confidence of classification, PAC Bayes theory gives tighter bounds on generalization error with margin incorporated.</p>\n\n<p>My question is: what other properties or structure of the set of all possible hypotheses output by the learning algorithm matter for the bound on generalization errors? Name a few.</p>\n', 'ViewCount': '92', 'Title': 'What Properties Matter For the Bound on Generalization Error of Hypothesis Set?', 'LastEditorUserId': '683', 'LastActivityDate': '2012-12-31T23:43:33.697', 'LastEditDate': '2012-12-30T12:11:58.107', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2012-12-30T08:01:28.323', 'Id': '7651'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m interested in finding a solution for the following problem:</p>\n\n<ul>\n<li>problem space: any language that has more than 1 article</li>\n<li>let\'s take German language as example. So the articles in German are "der", "die", "das". - every word has an article as prefix and you must use the article. for example you can\'t say just "Auto"(car), you must say "das Auto".</li>\n<li>If you are not a native German speaker, you have bad luck, because you have to memorize the article too, when learning a new word, since there are only 3-4 rules to know which word takes which article. And those rules are perhaps about max. 10% percent of the vocabulary. (for example if a word ends with "-ung", it takes "die")</li>\n</ul>\n\n<p><hr/>\nSo here comes the funny part: as a non-native-German-speaker, i wanted to analyze the language from an IT-point of view and asked some friends of mine random words with the following properties: <br/></p>\n\n<ul>\n<li>first I reduced the input set from "any German word" to "a German word", for which no known article rule exists".</li>\n<li>then I extended the input set with "made up words", which do not exist.</li>\n</ul>\n\n<p>Every candidate had the same answer for German words, which should be not surprise. But when I asked them per word "why do you think/feel that the article of the word is "der/die/das"?" they couldnt give an answer. They just know it, without knowing why.</p>\n\n<p>Here comes the real hammer: every candidate had the same answer for any made-up non-German word. I say anything, make any meaningful voice, and they all give the same answer (ie. article).</p>\n\n<p>I\'m pretty sure that I\'m not the first human being in the world who made thoughts about this topic. And I\'m interested in any scientific papers/research about that topic.\nBy the way, what I definitely do NOT need is, any method (like neural networks) which outputs a pure mathematical function. I thought about following possibilities:</p>\n\n<ul>\n<li><p>focusing on feelings of subjects psychologically (I think it can be managed with colors somehow etc.)</p></li>\n<li><p>analyzing the words statistically according to their syllable structure</p></li>\n</ul>\n\n<p>Where can I begin? What are your suggestions? Are there any Machine Learning research about that topic?</p>\n', 'ViewCount': '69', 'Title': 'Analyzing rules of articles in languages', 'LastEditorUserId': '41', 'LastActivityDate': '2013-04-21T10:08:14.350', 'LastEditDate': '2013-01-21T09:10:31.840', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5222', 'Tags': '<machine-learning><natural-lang-processing>', 'CreationDate': '2013-01-20T01:43:55.890', 'Id': '9047'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have a multilayer perceptron. It has an input layer with two neurons, a hidden layer with an arbitrary number of neurons, and an output layer with two neurons.</p>\n\n<p>Given that <code>randomboolean</code> and <code>targetboolean</code> are random boolean values, and the network operates as such:</p>\n\n<pre><code>input(randomboolean); //Set the input neurons to reflect the random boolean\npropagateforwards(); //Perform standard forward propagation\noutputboolean = output(); //To get the networks output\nideal(targetboolean); //Performs connection updating via back-prop\n</code></pre>\n\n<p>Is it possible to get the network to map the <code>randomboolean</code> value to the <code>targetboolean</code> value in such a way as the the <code>outputboolean</code> value will correctly match the <code>targetboolean</code> while running in an 'on-line' (where prediction occurs along with continued learning) mode after some arbitrary number of training cycles. </p>\n\n<p>I hear that the network needs to be recurrent to process this as it may be temporal behaviour, however the MLP is a universal computing platform and I assume it should be able to approximate the temporal behaviour needed for this task.</p>\n", 'ViewCount': '144', 'Title': 'About the behaviour of multi-layer perceptrons', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-30T16:06:02.490', 'LastEditDate': '2013-01-25T11:18:32.820', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '9152', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '814', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-01-24T19:14:58.373', 'Id': '9137'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have seen a few years back a nice and simple algorithm that, given a (finite) set of words in some alphabet, builds a context-free grammar for a language including these words and in some sense "natural" (e.g., the grammar doesn\'t produce all words in the alphabet). The algorithm is very simple,  it has something like 3--4 rules for grammar transformation attempted on each new word. Any help in finding it would be appreciated.</p>\n', 'ViewCount': '181', 'Title': 'Construct a context-free grammar for a given set of words', 'LastEditorUserId': '6591', 'LastActivityDate': '2013-12-10T07:31:05.390', 'LastEditDate': '2013-01-28T15:39:42.217', 'AnswerCount': '2', 'CommentCount': '9', 'AcceptedAnswerId': '9268', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6591', 'Tags': '<algorithms><formal-languages><reference-request><formal-grammars><machine-learning>', 'CreationDate': '2013-01-28T10:01:35.720', 'Id': '9246'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm looking for an OCR technique (PCA or SVM or anything else) in a peculiar setting. I want to detect the motion of the finger so that if someone writes something in front of the camera in the air, I want to recognize the characters online (meaning as soon as they are written).</p>\n", 'ViewCount': '166', 'Title': 'Handwritten character recognition as characters are being traced', 'LastEditorUserId': '39', 'LastActivityDate': '2013-05-02T09:11:28.823', 'LastEditDate': '2013-01-30T21:31:31.013', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6621', 'Tags': '<machine-learning><computer-vision><pattern-recognition><ocr>', 'CreationDate': '2013-01-30T09:16:29.270', 'FavoriteCount': '1', 'Id': '9302'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I need a pool of photos (if possible with description) for my project. I mainly have to perform term extraction for semantic searching. Is there something available out there that is made available for such kinds of thing?</p>\n\n<p>I'm going to mine the description of these photos, maybe build ontologies and then perform search on them. The result of the mining might give useful terms about the pictures.</p>\n", 'ViewCount': '50', 'Title': 'Pool of photos for term extraction', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-03T15:11:37.810', 'LastEditDate': '2013-02-02T13:45:11.110', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6669', 'Tags': '<machine-learning><data-mining><data-sets><ontologies>', 'CreationDate': '2013-02-01T19:25:53.240', 'Id': '9404'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>I\'m reading <a href="http://bero.freqvibez.net/public/segs/icassp03_senseg.pdf" rel="nofollow">\u201cSpeech segmentation without speech recognition\u201d by Dong Wang, Lie Lu and Hong-Jiang Zhang</a>.\nThe algorithm I\'m looking at is a V/C/P (Vowel/Consonant/Pause) classification algorithm on a digital speech signal. It is described as such:</p>\n\n<ol>\n<li><p>Audio data is segmented into 20ms-long non-overlapping frames, \nwhere features, including ZCR, Energy and Pitch, are extracted.  </p></li>\n<li><p>Energy and pitch curve is smoothed. </p></li>\n<li><p>The  <code>Mean_En</code> and  <code>Std_En</code> of energy curve are calculated to \ncoarsely estimate the background noise energy level, as: </p>\n\n<pre><code>NoiseLevel = Mean_En - 0.75 Std_En. \n</code></pre>\n\n<p>Similarly the threshold of ZCR (<code>ZCR_dyna</code>) is defined as: </p>\n\n<pre><code>ZCR_dyna = Mean_ZCR + 0.5 Std_ZCR\n</code></pre></li>\n<li><p>Frames are classified as V/C/P coarsely by using the following \nrules, where FrameType is used to denote the type of each frame. </p>\n\n<pre><code>If ZCR &gt; ZCR_dyna then FrameType = Consonant \nElse if Energy &lt; NoiseLevel, then  FrameType = Pause \nElse FrameType = Vowel   \n</code></pre></li>\n<li><p>Update the <code>NoiseLevel</code> as the weighted average energy of the \nframes at each vowel boundary and the background segments. </p></li>\n<li><p>Re-classify the frames using algorithm in step 4 with the updated \n<code>NoiseLevel</code>. Pauses are merged by removing isolated short \nconsonants. Vowel will be split at its energy valley if its duration is \ntoo long  </p></li>\n</ol>\n\n<p>I do not understand step #5. Like I don\'t know how to interpret the wording - is there another way to describe what they are doing? I get that we want to update the <code>NoiseLevel</code> variable and re-run step #4 for every frame, I just don\'t understand how exactly. </p>\n', 'ViewCount': '49', 'Title': 'Help understanding an audio processing algorithm', 'LastEditorUserId': '39', 'LastActivityDate': '2013-02-05T20:16:13.140', 'LastEditDate': '2013-02-05T20:16:13.140', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6720', 'Tags': '<algorithms><machine-learning><natural-lang-processing><signal-processing>', 'CreationDate': '2013-02-05T16:56:55.613', 'Id': '9513'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have eye-tracking data on two subjects -- a teacher, and a student. It's in the form (x, y, time), so there is a series of these for each subject. What the teacher looks at influences what the student looks at. What method would I use to predict what the student is looking at, using only teacher data? Lets say I can train some learning algorithm using a gold standard set of student and teacher data.</p>\n\n<p>I was thinking hidden markov model would be appropriate, given the definition in Wikipedia, but I am not sure how to put this into practice over my dataset.</p>\n\n<p>More detail: I have data about how a teacher and student each look at a map and some readings. I have 40 of these datasets, which look like [(366,234,0), (386,234,5), ...] which means the teacher looked at point (366,234) at time 0 and then 5 seconds later moved up to look at coordinate (386, 234). I can to learn a model to understand the relationship between how a teacher looks at content, to predict how a student will look at the same content. So maybe the student looks at the content in the same order as the teacher but slower. Or perhaps the student doesn't look around as much but the teacher scans more of the content. I have both sets of data and want to see how accurate of a model I can get -- would I be able to predict the student's looking behavior within 50px of the teacher's looking behavior?</p>\n", 'ViewCount': '136', 'Title': 'What learning algorithm is appropriate for predicting one time-series from another?', 'LastEditorUserId': '6902', 'LastActivityDate': '2013-08-27T12:55:24.293', 'LastEditDate': '2013-02-16T20:23:19.980', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6902', 'Tags': '<machine-learning>', 'CreationDate': '2013-02-16T07:17:56.070', 'Id': '9828'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>For an academic question, I plan to design a medical diagnosis system. Given a description of symptoms, produce a list of probable diseases (with closeness matching). I'm having some trouble finding papers for getting started. Which algorithms and data structure should I consider?</p>\n", 'ViewCount': '175', 'Title': 'Data structure and algorithms for a medical diagnosis software', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-25T07:12:28.043', 'LastEditDate': '2013-02-25T07:12:28.043', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7014', 'Tags': '<algorithms><machine-learning>', 'CreationDate': '2013-02-24T20:05:02.043', 'Id': '10063'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Could anyone explain to me the differences &amp; similarities between machine learning and system identifications? Are these just two names of the same thing? In <a href="http://www.ipam.ucla.edu/programs/si2013/" rel="nofollow">this page</a>, they say: </p>\n\n<blockquote>\n  <p>Machine learning and system identification communities are faced with similar problems where one needs to construct a model from limited or noisy observations. </p>\n</blockquote>\n\n<p>I\'ve also read the early chapters of the famous book Pattern Recognition and Machine Learning by Christopher M. Bishop. So far, my conclusion is that the problem that system identification is trying to solve is a subset of what machine learning is trying to solve.</p>\n', 'ViewCount': '171', 'Title': 'Machine Learning vs System Identification?', 'LastActivityDate': '2013-04-28T09:10:03.820', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '5387', 'Tags': '<machine-learning>', 'CreationDate': '2013-02-27T03:09:27.107', 'FavoriteCount': '1', 'Id': '10134'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '60', 'Title': 'What is the Meaning of the Notation', 'LastEditDate': '2013-03-05T16:22:52.133', 'AnswerCount': '1', 'Score': '2', 'OwnerDisplayName': 'Anjali Vijaya', 'PostTypeId': '1', 'OwnerUserId': '6522', 'Body': '<p>What is meant by saying an algorithm runs in time $Poly(|S|,n,\\frac{1}{\\epsilon})$.</p>\n\n<p>Can somebody explain with an example.</p>\n', 'ClosedDate': '2013-03-05T17:49:02.400', 'Tags': '<complexity-theory><machine-learning>', 'LastEditorUserId': '41', 'LastActivityDate': '2013-03-05T16:22:52.133', 'CommentCount': '3', 'AcceptedAnswerId': '10293', 'CreationDate': '2013-03-05T09:00:17.110', 'Id': '10292'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m very new to neural networks, and have been trying to figure some things out.  So, let\'s say you come across a neural network which has 100 inputs, a hidden layer with 200 nodes, and 32 outputs. Let\'s also say that you, the "discoverer" of this particular instance of a neural network, are able to read the weights of the individual neurons. What could you figure out about it\'s function?</p>\n\n<p>1) Are you able to determine what the algorithm or logic is contained within the neural network?  Other than feeding in all possible inputs and studying the outputs it produces.</p>\n\n<p>2) If you were given information about the connection of the neural network (maybe the network isn\'t fully connected), would solving question one above be easier?</p>\n', 'ViewCount': '181', 'Title': 'What can be learned from the weights in a neural network?', 'LastActivityDate': '2013-03-19T00:03:49.407', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7157', 'Tags': '<machine-learning><neural-networks>', 'CreationDate': '2013-03-05T16:44:38.130', 'FavoriteCount': '1', 'Id': '10295'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am learning the SVM classification and encounter a problem. I am not sure if this dilemma has a terminology for it.</p>\n\n<p>Assume we would like to classify patient by SVM given the samples of healthy people ( of both gender) and people with liver cancer ( of both gender). If we label healthy people sample as class 1 and the people with cancer as class 2, we can train a binary SVM and obtain a classifier 1 to predict any new patient. Now, image another scenario. Assume that we first divide all samples by gender before SVM classification. For each gender, we still label healthy patients vs cancerous patients into 2 classes and train a binary SVM to obtain classifier 2 and classifier 3 for female and male samples respectively. The question is if there is a new female patient, which classifier, 1 or 2, should be used to obtain more accurate prediction ? Here is the dilemma for the arguments I have</p>\n\n<p>(1) When the number of samples is large, the prediction should be more accurate. Based on this argument, the classifier 1 seems a good choice.</p>\n\n<p>(2) However, if we divide samples into female and male groups first, the classifier 2 seems a better choice since the new patient (unknown test sample) is female.</p>\n\n<p>Does this kind of dilemma have a terminology or does anyone know any further information or how to solve problem like this ? I am not even sure if this is a legit question and sorry for the naive question in advance. Thanks</p>\n', 'ViewCount': '99', 'Title': 'Which classifier is more accurate for a SVM classification?', 'LastActivityDate': '2013-09-23T18:41:15.917', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '7161', 'Tags': '<machine-learning>', 'CreationDate': '2013-03-05T23:00:44.853', 'FavoriteCount': '1', 'Id': '10304'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '95', 'Title': 'Using the appropriate machine learning algorithm', 'LastEditDate': '2013-03-09T01:35:50.600', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7196', 'FavoriteCount': '1', 'Body': '<p>I am not sure if this is the right forum to ask this.</p>\n\n<p>I have some data of the houses, like their size(in square meters), if they use aircondition, how many residents live in, I have their electricity consumption as well.\nI want to train any Machine Learning Algorithm to the dataset above, in order to create a model that estimates the houses consumption.</p>\n\n<p>I tried many different algorithms (using weka), but I did not have good results.\nI was said that SVMs could solve this problem, with the right preprocessing. However, i did not have good results either. </p>\n\n<p>Can anyone help me, in the way i should approach this problem?</p>\n\n<p>Thanks in advance</p>\n', 'ClosedDate': '2013-04-24T06:46:56.037', 'Tags': '<algorithms><machine-learning><artificial-intelligence>', 'LastEditorUserId': '7196', 'LastActivityDate': '2013-03-09T21:40:15.973', 'CommentCount': '1', 'CreationDate': '2013-03-08T20:41:55.537', 'Id': '10392'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have on a few occasions trained neural networks (back propagation networks) with some rather complicated data sets (backgammon positions and OCR). When doing this, it seems that a lot of the work involves trying out different configurations of the networks, in order to find the optimal configuration for learning. Often there is a compromise between small nets that are faster to use/learn, and bigger nets, that are able to represent more knowledge.</p>\n\n<p>Then I wonder if it could be possible to make some networks that are both fast and big. I\'m thinking that at network where every neuron ain\'t fully connected ought to be faster to calculate than nets with full connection on all layers. It could be the training that detected that certain inputs are not needed by certain neurons, and therefore remove those connections. In the same way the training could also involve adding new neurons if some neurons seems to be "overloaded".</p>\n\n<p>Is this something that have been tried out with any success ? Does any classes of networks exists with this kind of behavior ?</p>\n', 'ViewCount': '110', 'Title': 'Adapting neural network', 'LastActivityDate': '2013-04-04T00:39:42.330', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10986', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7516', 'Tags': '<machine-learning><neural-networks><learning-theory>', 'CreationDate': '2013-03-31T15:39:51.687', 'FavoriteCount': '2', 'Id': '10937'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>When clustering a set of data points, what exactly are the differences between <a href="http://en.wikipedia.org/wiki/Fuzzy_clustering#Fuzzy_c-means_clustering" rel="nofollow">Fuzzy C-Means</a> (aka Soft K-Means) and <a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" rel="nofollow">Expectation Maximization</a>?</p>\n\n<p>In slide 30 and 32 of <a href="http://eniac.cs.qc.cuny.edu/andrew/gcml-11/lecture10c.pptx" rel="nofollow">this lecture</a> I found, it says that Soft K-Means is a special case of EM in Soft K-Means only the means are re-estimated and not the covariance matrix, why\'s that and what are the advantages / disadvantages? How does covariance matrix affect the outcomes of EM?</p>\n\n<p>Another question about these two algorithms: When they converge, all the data points will be hard-assigned to a particular cluster if the probability of it being in the said cluster is highest, right?</p>\n', 'ViewCount': '444', 'Title': 'Differences between Fuzzy C-Means and EM', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-29T14:41:12.010', 'LastEditDate': '2013-08-29T14:41:12.010', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14017', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7329', 'Tags': '<algorithms><terminology><algorithm-analysis><machine-learning><statistics>', 'CreationDate': '2013-04-04T17:14:03.000', 'Id': '11022'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm looking for something i would call rating functions.\nI'm searching for some literature about this concept.\nI'm not really sure about the terminology, but what I mean should be pretty obvious.</p>\n\n<p>A type of function that returns a rating of some input.</p>\n\n<p>Lets have a function that gets some input and returns a number between 0 and 1 as a rating, where 0 is bad and 1 is great. Everything between is well between bad and great depending.</p>\n\n<p>Lets assume inputs are just numbers</p>\n\n<p>$f\\colon \\mathbb{N} \\longrightarrow [0,1]$</p>\n\n<p>I would like if I have several rating functions be able to compose them.\nFor example if I have the rating functions $r_1$, $r_2$ I would like to compose both to a new rating function that returns a new rating in dependency to $r_1$ and $r_2$</p>\n\n<p>Now I'm looking for literature, but was unable to find any.\nCan somebody hint me into the correct direction?\nThe correct name for the concept I'm looking for would be great.</p>\n\n<h2>Edit</h2>\n\n<p>I want to implement various Rating Functions and want to combine them</p>\n\n<p>One functions could be</p>\n\n<pre><code>alwaysPerfect = (x) -&gt; 1\nalwaysBad = (x) -&gt; 0\nisOdd = (x) -&gt; x%2\ndistanceToOne = (x) -&gt;\n  x = 2 if x is 0\n  1/abs(x)\n</code></pre>\n\n<p>Anyone could implement this functions, but the contract for this functions would be to always return a value between 0 and 1</p>\n\n<p>I need to evaluate some data with various evaluation conditions. Writing these evaluation seperate small functions and combine them seems to be more clearer than writing one big function that does all the evalauting</p>\n", 'ViewCount': '49', 'Title': 'Looking for Rating Functions', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-11T09:01:17.707', 'LastEditDate': '2013-04-11T23:03:24.010', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7684', 'Tags': '<machine-learning><mathematical-analysis><data-mining>', 'CreationDate': '2013-04-11T16:02:37.263', 'Id': '11233'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have the dataset which you can find <a href="https://dl.dropboxusercontent.com/u/8546316/Dataset.csv" rel="nofollow">here</a>, containing many different characteristics of different houses, including their types of heating, or the number of adults and children living in the house. In total there are about 500 records. I want to use an algorithm, that can be trained using the dataset above, in order to be able to predict the electricity consumption of a house that is not in the set.</p>\n\n<p>I have tried every possible machine learning algorithm (using weka) (linear regression, SVM etc) . However I had about 350 mean absolute error, which is not good. I tried to make my data to take values from 0 to 1, or to delete some characteristics. I did not managed to find some good results.</p>\n\n<p>I also tried to use R tool, and I did not have good results either...</p>\n\n<p>I would be very grateful, if someone could give me some advice, or if you could examine a little the dataset and run some algorithms on it. What type of preprocessing should I use, and what type of algorithm?</p>\n\n<p>I have posted a <a href="http://cs.stackexchange.com/questions/10392/using-the-appropriate-machine-learning-algorithm">similar question</a> last month, but I did not get any useful answers.</p>\n', 'ViewCount': '132', 'Title': 'Predicting energy consumption of households', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-24T06:43:43.053', 'LastEditDate': '2013-04-24T06:43:43.053', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7196', 'Tags': '<algorithms><machine-learning><statistics>', 'CreationDate': '2013-04-23T22:37:26.683', 'Id': '11527'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>I\u2019m trying to make a Liquid State Machine in python and I already read many articles about it, but still there are many points I don\u2019t understand.</p>\n\n<p>The readout function is a Feed-forward Neural Network, but how is it taught to read out the states? In the echo state network I had a train period when I feed a train signal through backward weights and by saving each step\u2019s state, the output weights were calculated. </p>\n\n<p>Is it the same way in the Liquid State Machine, or is its \u201cinner weight matrix\u201d trained instead (the connections between the inner nodes / neurons)? Or does it have an entirely different method?</p>\n', 'ViewCount': '53', 'Title': "How is the Liquid State Machine's readout function trained?", 'LastActivityDate': '2013-04-28T19:28:45.633', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7950', 'Tags': '<machine-learning>', 'CreationDate': '2013-04-28T19:28:45.633', 'Id': '11637'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>I\u2019m trying to make a Liquid State Machine in python and I already read many articles about it, but still there are many points I don\u2019t understand.</p>\n\n<p>(I had trouble putting \'LSM\'s in context to see what it actually is, but looking at <a href="http://pybrain.org/pages/features" rel="nofollow">PyBrain\'s feature</a> list and the description of <a href="http://aureservoir.sourceforge.net/" rel="nofollow">aureservoir</a> I could classify LSM like this: \'Machine Learning\' > Networks > Recurrent Networks (RNN) > Reservoir Computing > Liquid State Machine (LSM).)</p>\n\n<p>However I don\'t understand how do I give the input to the liquid? </p>\n\n<p>Should I give it to <em>all</em> the neurons, or just to a selected (how?) <em>few</em>, or only to <em>one</em>?**</p>\n', 'ViewCount': '64', 'Title': 'Which nodes do I give the input to in a Liquid State Machine?', 'LastActivityDate': '2013-04-28T20:12:38.730', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7950', 'Tags': '<machine-learning>', 'CreationDate': '2013-04-28T20:12:38.730', 'Id': '11641'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>I\u2019m trying to make an Echo State Network (ESN) in Python and althought I already read many articles about it, still there are many points I don\u2019t understand.</p>\n\n<p>(I had trouble putting \'ESN\' in context to see what it actually is, but looking at <a href="http://pybrain.org/pages/features" rel="nofollow">PyBrain\'s feature</a> list and the description of <a href="http://aureservoir.sourceforge.net/" rel="nofollow">aureservoir</a> I could classify ESN like this: \'Machine Learning\' > Networks > Recurrent Networks (RNN) > Reservoir Computing > Echo State Network (ESN).)</p>\n\n<p>I\'ve attempted to write a very basic ESN in Python and I\'m not sure if I got ESN right, thus I\'m asking this question.</p>\n\n<p>What I did was to fed a teach signal to it through a feedback weight matrix. From this, the output weight matrix could be calculated.</p>\n\n<p>Once the output weights are ready, I try to run the echo state network again. But should I still provide signal through the feedback matrix?</p>\n\n<p>How do the network run after it was taught? Without the teacher, does it need the previous output instead, as if the previous output were the teacher signal?</p>\n\n<p>The network is similar to <a href="http://pybrain.org/pages/features" rel="nofollow">this image</a> and first W<sub>back</sub> is fed from the teacher signal and then an \'y\' is created replaying the network\'s states with the teacher signal but through the now known W<sub>out</sub>. But should I use this \'frozen\' \'y\' in the subsequent time steps, or do I send the actual output back to the units through W<sub>back</sub> each time?</p>\n', 'ViewCount': '77', 'Title': "Once taught, should I feed back the network's actual output into itself in an Echo State Network?", 'LastEditorUserId': '7950', 'LastActivityDate': '2013-05-01T08:13:36.377', 'LastEditDate': '2013-05-01T08:13:36.377', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7950', 'Tags': '<machine-learning>', 'CreationDate': '2013-04-28T20:32:37.640', 'Id': '11642'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Suppose one has a couple of <em>.wav</em> files with English spoken words, multiple ones for each word, and for each such set there exists a transcription of their right output, the pronunciation as <em>ascii text</em>.</p>\n\n<p>As far as I know, machine learning neural networks use arrays of floats as input and output, and also internally.</p>\n\n<p>What do one do in machine learning in order to convert such \'real world\' data formats/data sets into another data structure that is meaningful and suitable for the machine learning neural networks? </p>\n\n<p>Furthermore, what classifies a particular data structure as \'suitable\', except the fact that it can be expressed as arrays of integers (what fits every digital data)?</p>\n\n<p>(I suppose it could be more sophisticated than stripping the headers and feeding the uncompressed binary data in as integers, or is it?)</p>\n\n<hr>\n\n<p><strong>edit</strong>: in an other SE site\'s <a href="http://stats.stackexchange.com/questions/7224/detecting-a-given-face-in-a-database-of-facial-images">question</a> (regarding how to filter out an image of Justin Bieber), an answer asserts that one <em>"has some method of feature generation to transform the raw images into features that are useful for machine learning purposes"</em>, but it doesn\'t explain how this is done, or how does one begin to create a method for such a feature conversion.</p>\n', 'ViewCount': '128', 'Title': 'How is sound input and output data converted to use with machine learning networks?', 'LastEditorUserId': '31', 'LastActivityDate': '2013-06-01T17:30:47.413', 'LastEditDate': '2013-05-02T07:28:37.360', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7770', 'Tags': '<data-structures><machine-learning><data-sets>', 'CreationDate': '2013-05-02T06:31:28.187', 'Id': '11720'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I was told by my adviser (future one) to look into <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" rel="nofollow">libsvm</a> library or any other and try to get familiar with it.. to work on a programming project (on Machine Learning) (will start in a month).</p>\n\n<p>my background: Programming knowledge in Python, C.. doing Java now.</p>\n\n<p>So, where should I probably start? and How long it takes me to get into ML, SVM etc.. and be productive? Would I probably fit for this project? --considering my programming background (I so far have been much into Web development, wanted to take a change and have fun)</p>\n', 'ViewCount': '156', 'ClosedDate': '2013-05-12T15:53:20.787', 'Title': 'Can we understand SVM without knowledge of Machine Learning', 'LastActivityDate': '2013-05-07T22:02:28.073', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '11855', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8079', 'Tags': '<reference-request><machine-learning><data-mining>', 'CreationDate': '2013-05-07T14:16:44.423', 'Id': '11854'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am investigating PAC learning (computational learning theory) as a beginner with no previous knowledge of machine learning / AI. I am investigating the model mainly from a historical point of view.</p>\n\n<p>For this, the most important things are of course the results based on the model. There are enough papers out there that document these results. But I also want to write something about what was going on before PAC learning, as to sketch the historical context up to where Valiant came with the notion of the PAC model.</p>\n\n<p>No papers/surveys I've found so far document this, and as someone with no real knowledge of machine learning, it is hard to find this out. I am therefore asking this soft question here, because I believe there are enough experts that can help me with this. References are highly appreciated.</p>\n\n<p>When I can research and study what was going on before PAC, I might get a better appreciation as to why the academic world is so enthusiastic about the PAC model, which is also something interest to document in my historical work! </p>\n", 'ViewCount': '137', 'Title': 'What was going on before PAC learning', 'LastActivityDate': '2013-05-14T10:35:43.113', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '11949', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '17', 'Tags': '<machine-learning>', 'CreationDate': '2013-05-10T16:36:02.393', 'FavoriteCount': '1', 'Id': '11937'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have seen a lot of explanations of what Bayesian networks are, but I simply cannot wrap my head around their use in code. So here is my three part question. </p>\n\n<ol>\n<li>Am I right in my definition of bayes nets? Bayesian networks are a way to (visually) portray how variables/events are linked and how they will affect each other. Probabilities can be added to each node to give you a greater sense of what will happen. In conjunction with an acting AI, bayes nets are used to predict the AI's actions and inform what it should be doing, ie giving minimax a better prediction.</li>\n<li>Can you give a pseudo code representation of a bayes net? </li>\n<li><p>Let's get a little more specific. I have a creature simulator, the creature has a home where he sleeps and, there are patches of grass where he eats. There are other creatures out there that he wants to avoid because they will fight him. So his action -> reaction set is: </p>\n\n<p>{hungry->find food -> eat food<br>\ntiered -> go to shelter -> sleep<br>\nin danger -> avoid other creature<br>\nunder attack -> run to shelter}</p>\n\n<p>I am trying to express this as an mdp so that it will learn what actions are best when; and what are the best spots(most prosperous &amp; least dangerous) on the map.\nHow, if at all, am I supposed to use a bayes net? If the situation requires probabilities feel free to add your own, pseudo code also appreciated.</p></li>\n</ol>\n", 'ViewCount': '141', 'Title': 'What is the purpose of Bayesian networks?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-26T11:19:18.883', 'LastEditDate': '2013-08-26T11:19:18.883', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8147', 'Tags': '<terminology><machine-learning><artificial-intelligence><probability-theory>', 'CreationDate': '2013-05-13T15:29:28.663', 'Id': '11992'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Is it proper to view conditional probabilities, such as the forms:</p>\n\n<p>P(a|c)</p>\n\n<p>P(a|c,d)</p>\n\n<p>P(a, b|c, d)</p>\n\n<p>...and so forth, as being tensors?</p>\n\n<p>If so, does anyone know of a decent introductory text (online tutorial, workshop paper, book, etc) which develops tensors in that sense for computer scientists/machine learning practitioners?</p>\n\n<p>I have found a number of papers, but those written at an introductory level are written for physicists, and those written for computer scientists are rather advanced.  </p>\n', 'ViewCount': '69', 'Title': 'Conditional Probabilities as Tensors?', 'LastActivityDate': '2013-05-17T23:18:12.193', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1940', 'Tags': '<machine-learning><probability-theory><statistics>', 'CreationDate': '2013-05-17T23:18:12.193', 'Id': '12100'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have recently been asked in an interview to devise an algorithm that divides a set of points in a coordinate system so that half of the points lie on one side of the line, and the rest on the other side.</p>\n\n<p>The points are unevenly placed and the line must not pass through any of the points.</p>\n\n<p>Can any one give any approach to solve the problem? Analysis of the algorithm is appreciated.</p>\n\n<p>Hints: Count the points, use medians.</p>\n\n<p>The number of points is assumed to be even.</p>\n', 'ViewCount': '168', 'Title': 'Algorithm to find a line that divides the number of points equally', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-19T14:54:52.617', 'LastEditDate': '2013-05-19T14:54:52.617', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '12114', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6699', 'Tags': '<algorithms><machine-learning><computational-geometry><classification>', 'CreationDate': '2013-05-18T13:51:24.557', 'Id': '12111'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am trying to estimate the graph in very high dimensional data, I mean with million nodes. Up to now all the papers that I have found, they are limited to few thousands.</p>\n\n<p>All of them like graphical lasso, non parnormal, they use the estimated covariance matrix and then use the gaussian likelihood function which they optimize to find the precision matrix, which actually encodes the graph structure</p>\n\n<p>In my case, I have million nodes. So if I try to estimate the covariance matrix at the beginning, that is a dense matrix of 1 million x 1 million. I will run out of memory with that</p>\n\n<p>I wanted to know if any methods have been devised that actually deal with this issue. Or this problem is unsolved?</p>\n', 'ViewCount': '58', 'Title': 'Graph estimation in high dimensional data', 'LastActivityDate': '2013-05-20T02:17:06.667', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6999', 'Tags': '<graph-theory><machine-learning>', 'CreationDate': '2013-05-20T02:17:06.667', 'Id': '12146'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given a PDA $P=(Q,\\sum,\\delta,q_0,F)$ construct formally a TM that accepts $L(P)$.</p>\n\n<p>My idea is to construct a Turing machine with 2 tapes, one for the input and the other for the stack. Also to add $q_a$ for accept and $q_r$ for reject and to send to $q_a$ if the TM stops on states in $F$ and send to $q_r$ otherwise.</p>\n\n<p>But I am having a trouble to define new the transition function for the TM: $\\delta_M$.</p>\n', 'ViewCount': '114', 'Title': 'construct a TM from a PDA', 'LastActivityDate': '2013-05-25T05:27:49.823', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '12264', 'Score': '0', 'OwnerDisplayName': 'David', 'PostTypeId': '1', 'OwnerUserId': '15890', 'Tags': '<machine-learning><turing-machines><machine-models>', 'CreationDate': '2013-05-24T12:13:01.970', 'Id': '12263'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I would like to build an online web-based machine learning system, where users can continuously add classified samples, and have the model updated online. I would like to use a perceptron or a similar online-learning algorithm. </p>\n\n<p>But, users may make mistakes and insert irrelevant examples. In that case, I would like to have the option to delete a specific example, without re-training the perceptron on the entire set of examples (which may be very large).</p>\n\n<p>Is this possible?</p>\n', 'ViewCount': '143', 'Title': 'Can a perceptron forget?', 'LastActivityDate': '2013-05-31T03:11:27.920', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '12389', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<machine-learning><online-algorithms>', 'CreationDate': '2013-05-27T11:12:29.320', 'FavoriteCount': '2', 'Id': '12306'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am making a survey of Artificial Intelligence Techniques applied to educational fields. Actually I would like to find papers related to machine learning techniques applied to automatic scoring of exams and automatically increasing the difficulty of the questions in an exam, but I have not found any.</p>\n\n<p>Does anybody has some references about that specific topic?</p>\n\n<p>Thanks</p>\n', 'ViewCount': '28', 'Title': 'machine learning applied to automatic assesment?', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-07T15:11:07.660', 'LastEditDate': '2013-06-07T15:11:07.660', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6430', 'Tags': '<reference-request><machine-learning>', 'CreationDate': '2013-06-07T13:51:05.323', 'Id': '12509'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I cannot undertand how exactly the Stacked Generalisation works.</p>\n\n<p>I have tried to read <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.1533" rel="nofollow">the original paper</a> and also the <a href="http://users.rowan.edu/~polikar/RESEARCH/index_files/Ensemble.html" rel="nofollow">survey by Robi Polikar</a>. I understand that a meta-classifier is created and it is used to choose which classifier to use for each instance, but I can\'t understand how is it trained and how it really works.</p>\n\n<p>Please help me giving a good reference about the topic.</p>\n', 'ViewCount': '29', 'Title': 'Simple explanation for Stacked Generalisation ensemble method', 'LastActivityDate': '2013-06-22T18:09:21.123', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '851', 'Tags': '<reference-request><machine-learning>', 'CreationDate': '2013-06-22T18:09:21.123', 'Id': '12831'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '130', 'Title': 'distance between histograms', 'LastEditDate': '2013-06-25T19:10:37.723', 'AnswerCount': '2', 'Score': '1', 'OwnerDisplayName': 'Hani Gotc', 'PostTypeId': '1', 'OwnerUserId': '9033', 'Body': '<p>I have 2 histograms that represent the height of characters in 2 images. \nexample: </p>\n\n<ul>\n<li>1 <strong>**</strong></li>\n<li>2 <strong><em>*</em>***</strong></li>\n<li>3 <strong><em>*</em>**<em>*</em></strong></li>\n<li>.</li>\n<li>.</li>\n<li>.</li>\n<li>100 <strong><em>*</em>**<em>*</em>**</strong></li>\n</ul>\n\n<p>For these 2 histograms I compute the peaks. And To <strong>check</strong> if these 2 images are <strong>similar</strong> I compute the interseciton between the indices of the 2 images.\nExample:\nFor image 1 the indices of the peaks are 1, 10 and 13\nfor image 2 the indices of the peals are 1,10, 14.\nImage1 Inter Image1 = 2 So these images are similar.</p>\n\n<p>But I feel that the intersection is not enough. I think that i should also use the size of the buckets of the histograms peaks.</p>\n\n<p>Is there  a way to use to both of them to measure the similarity in <strong>1 function</strong> So that I can have a stable similarity function?</p>\n', 'Tags': '<machine-learning><probability-theory><statistics>', 'LastEditorUserId': '19', 'LastActivityDate': '2013-06-25T19:10:37.723', 'CommentCount': '1', 'AcceptedAnswerId': '12898', 'CreationDate': '2013-06-18T11:00:45.170', 'Id': '12846'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am a CS undergraduate (but I don\'t know much about AI though, did not take any courses on it, and definitely nothing about NN until recently) who is about to do a school project in AI, so I pick a topics regarding grammar induction (of context-free language and perhaps some subset of context-sensitive language) using reinforcement learning on a neural network. I started to study previous successful approach first to see if they can be tweaked, and now I am trying to understand the approach using supervised learning with Long Short Term Memory.\nI am reading <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.4170" rel="nofollow">"Learning to Forget: Continual Prediction with LSTM"</a>. I am also reading the paper on peephole too, but it seems even more complicated and I\'m just trying something simpler first. I think I get correctly how the memory cell and the network topology work. What I do not get right now is the training algorithm. So I have some questions to ask:</p>\n\n<ul>\n<li><p>How exactly does different input get distinguished? Apparently the network is not reset after each input, and there is no special symbol to delimit different input. Does the network just receive a continuous stream of strings without any clues on where the input end and the next one begin?</p></li>\n<li><p>What is the time lag between the input and the corresponding target output? Certainly some amount of time lag are required, and thus the network can never be trained to get a target output from an input that it have not have enough time to process. If it was not Reber grammar that was used, but something more complicated that could potentially required a lot more information to be stored and retrieved, the amount of time need to access the information might varied depending on the input, something that probably cannot be predicted while we decide on the time lag to do training.</p></li>\n<li><p>Is there a more intuitive explanation of the training algorithm? I find it difficult to figure out what is going on behind all the complicated formulas, and I would need to understand it because I need to tweak it into a reinforced learning algorithm later.</p></li>\n<li><p>Also, the paper did not mention anything regarding noisy <strong>training</strong> data. I have read somewhere else that the network can handle very well noisy testing data. Do you know if LSTM can handle situation where the training data have some chances of being corrupted/ridden with superfluous information?</p></li>\n</ul>\n', 'ViewCount': '184', 'Title': 'Intuitive description for training of LSTM (with forget gate/peephole)?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-26T10:53:14.773', 'LastEditDate': '2013-06-26T10:53:14.773', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8835', 'Tags': '<formal-languages><machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-06-24T17:04:54.560', 'Id': '12871'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m interested to see if I can use machine learning/network analysis methods to automatically detect automatically generated (spam) webpages.  I\'m particularly interested in webpages that look structurally like a non-spam website, but on closer inspection are total rubbish.</p>\n\n<p>If I want to test a method, I\'d need some way of accessing (or generating) these webpages.</p>\n\n<blockquote>\n  <p><strong>Question</strong>: Where can I access automatically generated (spam) webpages?</p>\n</blockquote>\n\n<p>Here\'s a sample of the kind of webpage I\'m thinking about:</p>\n\n<p><img src="http://i.stack.imgur.com/yNQpF.png" alt="Sample spam">\n<a href="https://zvelo.com/blog/entry/spam-web-page-detection-a-new-approach" rel="nofollow">Image source</a></p>\n', 'ViewCount': '35', 'Title': 'Accessing automatically generated (spam) webpages?', 'LastActivityDate': '2013-06-27T14:37:12.610', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2254', 'Tags': '<machine-learning>', 'CreationDate': '2013-06-27T14:37:12.610', 'FavoriteCount': '1', 'Id': '12928'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '114', 'Title': 'A text-classifier that explains its decisions', 'LastEditDate': '2013-12-15T15:11:45.857', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1342', 'FavoriteCount': '1', 'Body': '<p>I am building a text categorizer for short sentences. In addition to telling the  user "the category of the text you entered is C", I want to be able to explain why I made this decision, in a short and understandable way. For example, I don\'t want to tell the user "I put your sentence into a complex 3-layered neural network and that\'s the answer that scored the best"; I want explanations such as "Your sentence contains the words U, V and W, that are characteristic of this category, because of sentences such as X, Y and Z that appeared in the training data".</p>\n\n<p>My question is: what classification algorithms are best suited for such application?</p>\n\n<p>k-nearest-neighbours seems like a good candidate, because I can tell the user "Your sentence has category C because it is similar to sentences X, Y and Z that have the same category. But its performance on text categorization problems is known to be poor. I am looking for a classifie that balances performance with explanation ability.</p>\n\n<p>EDIT: After spending a lot of time looking for such a classifier, I started to build a machine-learning library called <a href="https://github.com/erelsgl/limdu" rel="nofollow">limdu</a>, that allows the classifiers to explain their decisions. It is still under development, but, it has already helped me explain to myself and my colleagues why our classifiers fail so often...</p>\n', 'Tags': '<machine-learning><classification>', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-12-15T15:11:45.857', 'CommentCount': '2', 'AcceptedAnswerId': '12966', 'CreationDate': '2013-06-28T12:45:51.443', 'Id': '12950'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '64', 'Title': 'Pairwise comparisons with confidence', 'LastEditDate': '2013-07-03T11:53:51.223', 'AnswerCount': '2', 'Score': '1', 'OwnerDisplayName': 'Bob Davidson', 'PostTypeId': '1', 'OwnerUserId': '8989', 'Body': "<p>There is a lot of information available on the subject of Pairwise Comparisons but I haven't found any guidance on how to optimize pair measurements that have confidence values attached to them.</p>\n\n<p>Imagine that an AI black box has been trained on many pairs of objects in order to predict the distance between the objects in novel pairs. All objects are colinear. The black box also provides a confidence level for each distance. Here is a simple example of outputs based on a set of 5 objects ($a$ to $e$):</p>\n\n<pre><code>Pair, Distance, Confidence\n\na-b,  5,        0.4\na-c,  9,        0.7\na-d,  -3,       0.9\na-e,  2,        0.6\nb-c,  6,        0.8\nb-d,  -10,      0.7\nb-e,  -2,       1.0\nc-d,  -6,       0.5\nc-e,  -2,       0.6\nd-e,  7,        0.9\n</code></pre>\n\n<p>So, the distance between $a$ and $b$ is predicted to be 5 units ($b$ is to the right of $a$) and the black box's confidence in that measurement is 0.4 (0.0 = no confidence and 1.0 = perfect confidence). The distance between $a$ and $d$ is -3 units ($d$ is to the left of $a$) and the confidence is 0.9.</p>\n\n<p>I would like to understand the process for deriving the solution, which is the optimization of the four distances between these objects given the predicted distances and their associated confidence levels.</p>\n", 'Tags': '<machine-learning><artificial-intelligence><computational-geometry>', 'LastEditorUserId': '8989', 'LastActivityDate': '2013-07-03T17:15:20.740', 'CommentCount': '4', 'AcceptedAnswerId': '13048', 'CreationDate': '2013-07-01T00:00:55.800', 'Id': '13015'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a large data set consisting of ca. 40 categorical data items and a few interval data items (real numbers, less than 5 such items). Most categories should have a lot of values that repeat themselves over and over, and very few that appear very rarely. Some categories are also overcategories of others (like country and city). The outcome of each data is either 1 if the event occurred, or 0 if it did not occur.</p>\n\n<p>The idea is to calibrate a machine learning model or a statistical model that can predict for every given data row the probability that the outcome is 1. The data set I will use will have at least 1 million rows.</p>\n\n<p>Which machine learning approaches and statistical models will perform well on such a task? My initial thoughts are logarithmic regression and support vector machines (with extensions like random forest).</p>\n\n<p>How do I deal with the interval data items? The easiest approach is obviously to convert different ranges into categories, which I think will not be a problem.</p>\n\n<p>What libraries and tools can I use when my data set has a size of 10 GB? I am interested in tools/libraries that include machine learning algorithms but also statistical tools to help me find attributes with significant influence on the outcome. I can code in Java and C++ at the moment. I looked into <a href="http://root.cern.ch/drupal/" rel="nofollow">Root</a>, a data analysis tool from CERN for large data sets, and its machine learning module <a href="https://twiki.cern.ch/twiki/bin/view/TMVA/WebHome" rel="nofollow">TMVA</a>, but it can only handle real numbers and integers as input as far as I know.</p>\n', 'ViewCount': '74', 'Title': 'Event Prediction through Machine Learning', 'LastEditorUserId': '8457', 'LastActivityDate': '2013-07-03T12:33:47.257', 'LastEditDate': '2013-07-03T12:33:38.647', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8977', 'Tags': '<machine-learning><data-mining>', 'CreationDate': '2013-07-02T14:31:57.473', 'Id': '13037'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Can somebody refer me to peer-reviewed papers studying the advantages or disadvantages of writing code in a functional style? Are there papers which discuss the applications of Lambda Calculus in fields such as Machine Learning, Language Design, etc.?</p>\n', 'ViewCount': '202', 'Title': 'Are there peer-reviewed papers studying the pros and cons of functional programming?', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-07-10T19:02:23.393', 'LastEditDate': '2013-07-04T05:35:51.533', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '8998', 'Tags': '<reference-request><programming-languages><machine-learning><lambda-calculus><functional-programming>', 'CreationDate': '2013-07-03T23:37:07.887', 'FavoriteCount': '7', 'Id': '13076'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Anyone knows where I can find information about Time-based Inductive Machine(TIM). Good explanation of the method or the source code of the original implementation could help.</p>\n', 'ViewCount': '26', 'Title': 'Time-based Inductive Machine', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-07T17:47:28.977', 'LastEditDate': '2013-07-07T17:47:28.977', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9067', 'Tags': '<terminology><reference-request><machine-learning>', 'CreationDate': '2013-07-07T13:47:47.017', 'Id': '13130'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Can someone please point me towards a rigorous derivation of the energy function of a discrete Hopfield network. What I want, is the derivation must start out with the structure of the network and prove that the critical points of the dynamical system can be obtained by minimization of some function (possibly by constructing the Lyapunov function of the dynamical system). I cannot seem to find such a rigorous proof. Thankyou! </p>\n', 'ViewCount': '135', 'Title': 'Derivation of the energy function of a hopfield network', 'LastActivityDate': '2013-07-09T15:40:53.530', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8912', 'Tags': '<reference-request><machine-learning><neural-networks>', 'CreationDate': '2013-07-07T14:17:15.630', 'Id': '13132'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Is it common to have a different feature set for samples in the train set and in the test set?</p>\n\n<p>My use case is text categorization: when training, I use the words as the features. But when testing, I want to add hypernyms.</p>\n\n<p>For example, if the training set contained the sentence "I eat a fruit", and there is a test sentence "I eat an apple", then I want to have the word "fruit" as a feature of the test sentence, in addition to its words, so that it will be classified positive. However, I don\'t want to add those hypernyms in the training set - if the training set contained only "I eat an apple", I don\'t want the sentence "I eat a fruit" to be classified positive.</p>\n\n<p>So, I thought of having a small feature set for training, and a larger feature set for testing. </p>\n\n<p>Is this common? If so, I would be happy to have some references.</p>\n', 'ViewCount': '64', 'Title': 'Different feature sets for training and testing?', 'LastActivityDate': '2013-07-09T13:39:21.047', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><machine-learning>', 'CreationDate': '2013-07-09T07:37:30.840', 'Id': '13169'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>A question about Laplace\'s approximation:</p>\n\n<p>In Laplace\'s method, we need to find the mode of a function and take second order Taylor\'s expansion. The first order term will vanish (since the gradient is zero at local optimum), and the second order term will be used to give a covariance of the gaussian. I am wondering if I am doing MCMC and the "point" I found is not local optimum (a.k.a gradient is not zero), will that influence my covariance matrix? Will the matrix be non-positive-definite something like that ?</p>\n', 'ViewCount': '30', 'Title': "Laplace's Approximation for graphical models", 'LastActivityDate': '2013-07-19T12:57:47.637', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9257', 'Tags': '<machine-learning><matrices><linear-algebra>', 'CreationDate': '2013-07-19T12:57:47.637', 'Id': '13349'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I got a very hard automatically clustering problem with some training data (500 samples, each with roughly 5-50 classes and 10000-20000 data points in total). What I need to do is to cluster an input into multiple classes (the number of classes is unknown). </p>\n\n<p>So far I had some several clustering algorithms, each gives me an output. I noticed that none of them works sufficient robust over the entire training set, but some works better than others on data with a small number classes, some works better on data with a large number of classes. Meanwhile, some gives me very good cluster results on part of a sample, while performs bad on the other half. Visually speaking, I feel that human should be able to generate a better clustering output by combining all initial outputs of using existing methods. However, it seems that it is hard to translate my human selection logic into codes. Because I know that a good cluster result in my data should be of a shape like a long eclipse, if I see a class in one of my output is very dislike this shape, I know there is something wrong, and if I look up the results of this area in other outputs, I can easily pick those close to my expectations. The actual case is even more complicated, my human decision on choose which class in which output for which region in my data sample uses both relative information among different outputs and prior knowledge on the distribution of tested data points. Please help me, I even donot know where to start. </p>\n\n<p>Any comments and hints are welcome. </p>\n\n<p>Thank you.</p>\n\n<hr>\n\n<p>Thank you for your comments. I see what you said, but it turns out that my ultimate goal is different from what you suggested. I am not interested in finding which clustering output is better than others, but trying to generate a new output based on existing clustering output. </p>\n\n<p>At the first glance, these two goals look compatible: if I can choose one best clustering output for a given set of data points, then I shall be able to repeat this process and apply it iterative to cover the entire dataset, and in this way we can generate a new output, whose solution is composed of different clustering outputs at different regions. However, in my problem this is really not a feasible approach, because I really donot know how to separate an entire dataset into reasonable subsets. </p>\n\n<p>If we know how to do this job properly, the clustering problem can be largely simplified. We can first separate the entire set into nonoverlapping subset, then use an appropriate clustering method for each individual subset, and finally collect all subset clustering outputs as a new output. Meanwhile, it seems that this way of sequential process might be harmful if we make mistakes in the early stage of dividing subsets. </p>\n', 'ViewCount': '52', 'Title': 'How to train a clustering system based on multiple initial clustering results', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-25T19:23:51.500', 'LastEditDate': '2013-07-28T11:29:29.213', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9331', 'Tags': '<machine-learning><pattern-recognition>', 'CreationDate': '2013-07-25T01:05:34.993', 'Id': '13424'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I understand that fuzzy clustering using FCM produces a membership matrix for the set of data points we feed to it. What characteristics will an anomalous cluster produced during this method have? (Considering I only have unlabelled data)</p>\n', 'ViewCount': '91', 'Title': 'Anomaly/outlier detection using fuzzy clustering', 'LastActivityDate': '2013-08-26T11:14:17.737', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9396', 'Tags': '<machine-learning><data-mining>', 'CreationDate': '2013-07-29T01:05:01.850', 'Id': '13481'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p><strong>Updated based on comments:</strong></p>\n\n<p>In what ways can we distinguish a human being doing certain activities online and a bot programmed to do similar activities, say checking email, downloading some music files, shopping on ebay, searching on Google etc., or maybe trying to deface/hack a website, brute force a log-in password etc. </p>\n\n<p>To limit the scope of the question and make it more clear, let us restrict our observations <em>only</em> to network-oriented behavior, some examples being- the amount of time spent doing XYZ thing online, the amount/type of data downloaded (say) from a file sharing website, the number of friends/followers on Social media websites, etc. </p>\n\n<p>I guess it should possible to obtain some 'patterns' which will distinguish human behavior and programmed behavior. </p>\n\n<p>The Turing test is not what I am looking for. </p>\n\n<p>What techniques can be useful here? Machine learning? Game theory? </p>\n\n<p>References to relevant academic/research articles will also be good. </p>\n", 'ViewCount': '171', 'Title': 'In what ways can we distinguish between a human and bot behavior?', 'LastEditorUserId': '4190', 'LastActivityDate': '2013-08-06T08:32:41.143', 'LastEditDate': '2013-08-06T08:32:41.143', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4190', 'Tags': '<machine-learning><artificial-intelligence><game-theory><computer-vs-human>', 'CreationDate': '2013-08-03T05:32:35.383', 'Id': '13580'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have implemented a neural network (using CUDA) with 2 layers. (2 Neurons per layer). I'm trying to make it learn 2 simple quadratic polynomial functions using <strong>backpropagation</strong>.</p>\n\n<p>But instead of converging, it is diverging (the output is becoming infinity)</p>\n\n<p>Here are some more details about what I've tried:</p>\n\n<ul>\n<li>I had set the initial weights to 0, but since it was diverging I have\nrandomized the initial weights (Range: -0.5 to 0.5)</li>\n<li>I read that a neural network might diverge if the learning rate is\ntoo high so I reduced the learning rate to 0.000001</li>\n<li>The two functions I am trying to get it to add are: 3 * i + 7 * j+9\nand j*j + i*i + 24 (I am giving the layer i and j as input)</li>\n<li>I had implemented it as a single layer previously and that could\napproximate the polynomial functions better than it is doing now</li>\n<li>I am thinking of implementing momentum in this network but I'm not\nsure it would help it learn</li>\n<li>I am using a linear (as in no) activation function</li>\n<li>There is oscillation in the beginning but the output starts diverging\nthe moment any of weights become greater than 1</li>\n</ul>\n\n<p>I have checked and rechecked my code but there doesn't seem to be any kind of issue with it.</p>\n\n<p>So here's my question: what is going wrong here?</p>\n\n<p>Any pointer will be appreciated.</p>\n", 'ViewCount': '140', 'Title': 'Neural network diverging instead of converging', 'LastActivityDate': '2013-08-03T18:49:20.880', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9479', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-08-03T13:20:13.500', 'Id': '13587'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am building a classifier for short texts in a chat system. My features are words and pairs of words.</p>\n\n<p>Naturally, the sentences contain spelling mistakes. If a particular wrong spelling of a certain word hasn't appeared in the training corpus, the classifier has no chance to identify it.</p>\n\n<p>I consider taking an existing spelling corrector, and integrate it with my current classifier, but I am not sure how to do it.</p>\n\n<p>Do you know of a paper that integrates an automatic spelling correction tool with a short text classifier? </p>\n", 'ViewCount': '76', 'Title': 'short text categorization with spelling correction', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-08-22T14:34:49.877', 'LastEditDate': '2013-08-22T11:42:58.863', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><machine-learning><natural-lang-processing><classification>', 'CreationDate': '2013-08-22T11:20:26.190', 'Id': '13864'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have started reading about Decision Support Systems which according to wikipedia is "a computer-based information system that supports business or organizational decision-making activities".</p>\n\n<p>I have seen papers suggesting intelligent decision support systems, does that means a DSS necessarily utilizes Machine Learning ? How is a DSS different from Machine Learning or vice versa.</p>\n', 'ViewCount': '141', 'Title': 'What is the difference between Decision Support System and Machine Learning?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-26T00:52:29.473', 'LastEditDate': '2013-08-26T07:15:13.633', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<terminology><machine-learning>', 'CreationDate': '2013-08-22T17:23:38.067', 'FavoriteCount': '1', 'Id': '13871'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Why are neural networks initial weights initialized as random numbers?\nI had read somewhere that this is done to "break the symmetry" and this makes the neural network learn faster.\nHow does breaking the symmetry make it learn faster?</p>\n\n<p>Would\'nt initializing the weights to 0 be a better idea? That way the weights would be able to find their values (whether positive or negative)  faster?</p>\n\n<p>Is there some other underlying philosophy behind randomizing the weights apart from hoping that they would be near their optimum values when initialized?</p>\n', 'ViewCount': '119', 'Title': 'Why are weights of Neural Networks initialized with random numbers?', 'LastActivityDate': '2013-08-23T04:01:53.217', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13883', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '9479', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-08-23T02:49:56.567', 'Id': '13882'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '1789', 'Title': 'Which machine learning algorithms can be used for time series forecasts?', 'LastEditDate': '2013-08-26T13:02:49.107', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '9836', 'FavoriteCount': '3', 'Body': '<p>Currently I am playing around with time series forecasts (specifically for Forex). I have seen some scientific papers about echo state networks which are applied to Forex forecast. Are there other good machine learning algorithms for this purpose?</p>\n\n<p>It would also be interesting to extract "profitable" patterns from the time series.</p>\n', 'Tags': '<reference-request><machine-learning><artificial-intelligence>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-11T18:11:56.823', 'CommentCount': '1', 'AcceptedAnswerId': '14000', 'CreationDate': '2013-08-26T09:06:00.243', 'Id': '13937'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am not experienced in machine learning but I have been looking at the Python toolklit <code>scikit-learn</code>. I have thousands of mammograms and I have written an algorithm to find the outline of the images. I have some cases where the outline of the mammogram is not correct. I would like to be able to take these thousands of outlines of mammograms that are arrays (of different lengths) of the x and y coordinates of the edge and to classify them. This would allow me to find the outliers and also possibly allow me to categorise the images. Does a clustering algorithm exists that would allow me to do this? </p>\n\n<p>Edit 1:</p>\n\n<p>Expected outline<img src="http://i.stack.imgur.com/IKcP2.png" alt="enter image description here"></p>\n\n<p>Unwanted outline<img src="http://i.stack.imgur.com/lU3UT.png" alt="enter image description here"></p>\n', 'ViewCount': '57', 'Title': 'Classification of 2d arrays of outlines', 'LastEditorUserId': '9884', 'LastActivityDate': '2013-09-04T08:37:13.340', 'LastEditDate': '2013-09-04T08:37:13.340', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '14033', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9884', 'Tags': '<machine-learning><data-mining>', 'CreationDate': '2013-08-29T12:31:12.340', 'Id': '14019'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am looking for algorithms to classify words in a paragraph of text. I am particularly interested in a classification to determine if a certain word is noun, verb, etc., but also looking for any kind of word-classification algorithms. I am given a smaller input (e.g. 200 words) so there is no many options for machine learning but I would really appreciate algorithms involving machine learning.</p>\n', 'ViewCount': '90', 'Title': 'Word classification algorithms', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T09:52:19.747', 'LastEditDate': '2013-09-02T09:52:19.747', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8870', 'Tags': '<machine-learning><classification><computational-linguistics>', 'CreationDate': '2013-08-30T12:42:27.970', 'Id': '14037'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p><a href="https://en.wikipedia.org/wiki/Multi-label_classification" rel="nofollow">Multi-label classification</a> is a machine-learning problem where each sample can have zero or more labels from a closed set of possible labels. This task has applications in several fields. For example, in dialog systems, each sentence that the human says may have several intents, and the classifier should detect all of them. For example, the sentence "I want a cake and a drink" contains the two intents "WANTCAKE" and "WANTDRINK".</p>\n\n<p>Theoretically, I expect a classifier to classify multi-label samples, even if the training data contained only single-label samples. For example, consider the following training set (where each word is considered a feature):</p>\n\n<ul>\n<li>"I want a cake" -> WANTCAKE</li>\n<li>"I want a drink" -> WANTDRINK</li>\n<li>"I want a solution" -> WANTSOLUTION</li>\n</ul>\n\n<p>I would expect a classifier to realize, that the words "I want a" are not relevant for classification, and the words cake/drink/solution are indicative of the classes WANTCAKE/WANTDRINK/WANTSOLUTION respectively, and classify the sentence "I want a cake and a drink" correctly as {WANTCAKE,WANTDRINK}.</p>\n\n<p>This seems trivial to humans. Therefore. I was very surprised to find out, that many state-of-the-art multi-label classifiers fail miserably on this simple task!</p>\n\n<p>For example, consider a multi-label classifier in the "Binary Relevance" method. In this method, there is a single binary classifier for each label. For example, there is a binary classifier for the "WANTCAKE" label, trained with I want a cake" as a positive sample, and the other two sentences as negative samples. When this classifier sees the sentence "I want a cake and a drink and a solution", it sees a <em>single</em> feature "cake" that is a positive signal of WANTCAKE, and <em>two</em> features, "drink" and "solution", that are negative signals of WANTCAKE, because they appeared in the training set with sentences that did not have the WANTCAKE label. Therefore, this classifier returns \'negative\'. The same happens for the other two binary classifiers, and thus the multi-label classifier returns an empty set!</p>\n\n<p>I also tried other approaches to multi-label classification, such as RF-PCT (Random Forest Prediction Clustering Trees), with a slightly larger example (7 labels instead of 3) and got similar results. </p>\n\n<p>I sent this problem to machine learning experts, and they told me that I need more training data. They said that a classifier cannot tag multi-label instances, if the training data contains only single-label instances. In practice, they are right - adding more training data usually improves the accuracy of the classifier. </p>\n\n<p>But I am still bothered with the theoretical issue - how can it be, that there is no state-of-the-art classifier that can solve this trivial, 3-instance problem?</p>\n\n<p>I am looking for a classifier that provably solves such problems. I.e., a classifier for which there is a proof, that if it is given correct single-label samples, it can correctly solve multi-label cases.</p>\n\n<p>Is there such a classifier?</p>\n', 'ViewCount': '89', 'Title': 'Theory of multi-label classification', 'LastActivityDate': '2013-09-08T00:07:55.913', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '14205', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<machine-learning><correctness-proof><classification>', 'CreationDate': '2013-09-03T17:41:10.823', 'Id': '14107'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m thinking of an application for diabetics, that, given previous values of blood glucose and insulin dosage, predicts the glucose level for the next few hours.</p>\n\n<p>I know a few things about neural networks and perceptrons, but not much. And there are probably whole other worlds of other machine learning methods. So I\'d like to ask about what way should I try to go.</p>\n\n<p>My problem is below:</p>\n\n<hr>\n\n<p>The app would probably have a (very) simplified model over what is the reality (what food, how much of it, did some sport lately?, what kind of insulin, etc.) - and there are also some "expert knowledge" rules that I know but that wouldn\'t get programmed into it (eg. if you have too low glucose level, your body compensates and makes it into a too high glucose level). I want to try how far can I get just with the glucose measurements (when and how much) and insulin dosage (when and how much).</p>\n\n<p>I guess the main question it would be nice if the program solved is <strong>"Given my glucose history, what glucose will I have in a few hours if I take X units of insulin?"</strong> (That could indirectly solve question "How many units of insulin should I take if I want to have a good glucose level in a few hours?" but that\'s more complicated matter.)</p>\n\n<p>The food is an important part of the question, but I think it\'s closely linked to the insulin - the two balance out: if you eat food, you take insulin. You don\'t take insulin without eating (it\'s more complicated than that, but I\'m trying to make it simple), so I guess it could work without putting in the data about food.</p>\n\n<p>Now the data (at least timewise) isn\'t uniformly distributed. Ideally it should be (regular measurements at the morning, noon, evening, etc.) but more often than not the measurements get skipped. So the training dataset would have to deal with having "holes" in it. I guess that\'s ruling out some methods.</p>\n\n<p>What do you recommend to try? (Again, this is not anything medically professional and "to be used in real life" - it\'s just a proof of concept for me and a toy project to try to do some machine learning.)</p>\n', 'ViewCount': '72', 'Title': 'What machine learning method for diabetes prediction SW?', 'LastActivityDate': '2013-09-07T21:06:16.847', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9122', 'Tags': '<algorithms><machine-learning><classification>', 'CreationDate': '2013-09-07T21:06:16.847', 'Id': '14201'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The <a href="http://rjlipton.wordpress.com/2009/06/04/the-junta-problem/">junta problem</a> is the following: we have a boolean function $f:\\{0,1\\}^n \\to \\{0,1\\}$ that actually happens to depend on only $k$ of its input variables.  Given the value of $f(x)$ for many random values of $x$, we want to identify the $k$ input variables that $f$ actually depends upon.  In other words, secretly $f(x_1,\\dots,x_n) = g(x_{i_1},\\dots,x_{i_k})$ for some indices $i_1,\\dots,i_k$; given many pairs $(x,f(x))$ where each $x$ is random, we want to find the $i_1,\\dots,i_k$.</p>\n\n<p>I am interested in a variant of the junta problem, where we are allowed membership queries.  In particular, at any point, we can choose a value $x$ and receive the value of $f(x)$.  The goal remains the same: We want to learn the junta, i.e., learn the indices $i_1,\\dots,i_k$.</p>\n\n<p>How many membership queries are needed, and what is the running time to learn the junta?</p>\n\n<p>There is a simple, straightforward algorithm that uses something like $O(n)$ membership queries (first find $x,y$ such that $f(x)\\ne f(y)$, then move from $x$ to $y$ by changing one bit of the input at a time, to identify $x\',y\'$ such that $f(x\')\\ne f(y\')$ and $x\',y\'$ differ in a single bit position).  But can it be done with many fewer membership queries?  For instance, can we learn the junta with, say, $O(\\lg n)$ membership queries?</p>\n', 'ViewCount': '94', 'Title': 'Learning juntas, with membership queries', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-12T15:23:10.917', 'LastEditDate': '2013-09-09T10:27:33.200', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<algorithms><machine-learning><learning-theory>', 'CreationDate': '2013-09-08T03:20:12.577', 'Id': '14206'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Several popular machine learning algorithms such as Logistic regression or Neural networks require its inputs to be numeric.</p>\n\n<p>What I\'m interested in is how you make these algorithms work on non-numeric inputs (such as short strings).</p>\n\n<p>As an example, let\'s say we\'re building an email classification system (spam/not spam), where one of the input features is the sender address.</p>\n\n<p>To be able to use a learning algorithm, we need to represent the sender address as a number. One way is to simply number the senders 1..n. Our training set might then look like this:</p>\n\n<p><img src="http://i.stack.imgur.com/SxSxf.png" alt="inputs for machine learning"></p>\n\n<p>This won\'t work, however, because algorithms such as Logistic regression or Neural networks learn patterns in the input data, while in our example, the output looks totally random to the algorithm. Indeed, once in a university class, we tried to train a Neural network on a dataset that looked like this and the network was unable to learn anything (the learning curve was flat).</p>\n\n<p>Would you use Logistic regression or Neural networks in this example at all? If yes, in which way? If not, what would be a good way to classify emails based on sender address?</p>\n\n<p>A perfect answer would discuss the email classification example as well as handling short strings in ML in general.</p>\n', 'ViewCount': '144', 'Title': 'String inputs in Machine Learning', 'LastEditorUserId': '10260', 'LastActivityDate': '2013-09-21T07:27:59.863', 'LastEditDate': '2013-09-21T07:27:59.863', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10260', 'Tags': '<machine-learning><data-mining>', 'CreationDate': '2013-09-21T05:26:20.390', 'FavoriteCount': '1', 'Id': '14488'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am using neural networks to predict a time series.\nThe question I\'m facing now is how do I encode date/time/serial no. of each input set as an input to the neural network?</p>\n\n<p>Should I use 1 of C encoding (used for encoding categories) as described <a href="ftp://ftp.sas.com/pub/neural/FAQ2.html#A_cat" rel="nofollow">here</a>?</p>\n\n<p>Or Should I just feed it the time (in milliseconds since 1-1-1970)?</p>\n\n<p>Or is feeding it the time unnecessary as long as I feed it the rest of the data chronologically?</p>\n', 'ViewCount': '201', 'Title': 'How to encode date as input in neural network?', 'LastActivityDate': '2013-09-30T15:01:48.540', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '14702', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9479', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-09-27T03:58:02.437', 'FavoriteCount': '1', 'Id': '14634'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given a hypothesis $h:X\\rightarrow Y$ ($h$ is returned by an Empirical Risk Minimization (ERM) strategy with realizable case i.e. $h$ is consistent with the sample examples) over $X=[0,1]\\subseteq R$ where $Y=\\{0,1\\}$ and $D$ is the uniform distribution over $X$. How can I prove that for the accuracy parameter $0\\leq\\epsilon\\leq 1$ we might get $err_D(h)&gt;\\epsilon$? where $err_D(h)$ is the true error of $h$ in the distribution $D$.  </p>\n\n<p><strong>This is a homework</strong> and all I can do is using probabilities (as its shown in the course slides and other sources) to give some bounds on the error (i.e. $P(err_D(h)&gt; \\epsilon)\\leq k(1-\\epsilon)^m$) where $k$ is the number of <em>bad</em> hypotheses $|H_B|$ s.t. ($\\bar{h}\\in H_B | err_D(\\bar{h})&gt;\\epsilon)$ and $m$ is the sample size.  </p>\n\n<p>MY question is: is there any other way (beside using probabilities) to prove this? It just seems odd to me when the question asks for a prove and the answer is about probability bound. I am new to the field of learning theory and this might seems like a silly question but I am really trying to understand the intuition behind using probabilities. </p>\n', 'ViewCount': '62', 'Title': 'proving the error bound for a hypothesis', 'LastEditorUserId': '4598', 'LastActivityDate': '2013-09-30T05:07:42.513', 'LastEditDate': '2013-09-29T08:21:38.313', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '14693', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<machine-learning><learning-theory>', 'CreationDate': '2013-09-29T06:56:04.283', 'Id': '14670'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I know Gentle Boost, an adaption of the AdaBoost algorithm, can be used for <em>binary</em> classification. However, I need to do $n$-ary classification. How do I modify or extend the GentleBoost algorithm so it can be used for $n$-ary classification?</p>\n', 'ViewCount': '93', 'Title': 'N-ary (NOT binary) Gentle Boost algorithm?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-10-01T19:06:03.560', 'LastEditDate': '2013-10-01T18:47:15.770', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<algorithms><machine-learning><classification>', 'CreationDate': '2013-09-30T19:54:09.537', 'Id': '14714'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have in mind a particular 3D object.  Given an image taken by a camera, I want to check whether that image contains an instance of my object.</p>\n\n<p>For instance, let's say that the object is a bathroom sink.  There are many kinds of bathroom sinks, but they tend to share some common elements (e.g., shape, size, color, function).  There can also be significant variation in lighting and pose.  Given an image, I want to know whether the image contains a bathroom sink.</p>\n\n<p>How do I do that?  What technique/algorithm would be appropriate?  Is there research on this topic?</p>\n\n<p>Of course, it is easy to use Google Images to obtain many example images that are known to contain a bathroom sink (or whatever the object I'm looking for might be), which could be used for training some sort of machine learning algorithm.  This suggests to me that maybe some combination of computer vision plus machine learning might be a promising approach, but I'm not sure exactly what the specifics might look like.</p>\n", 'ViewCount': '100', 'Title': 'Object recognition - given an image, does it contain a particular 3D object of interest?', 'LastActivityDate': '2013-10-29T18:12:04.513', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '14719', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<machine-learning><image-processing><computer-vision><pattern-recognition>', 'CreationDate': '2013-09-30T23:58:18.703', 'Id': '14717'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I recently did work in the area of machine learning for one of my jobs and was able to build a classifier which evaluated to an F score of 85%. I also have access to correctly and incorrectly classified instances. My boss would like to make sure my classifier is good and and test it for statistical significance. I'm not quite sure what he means by this. I have taken a course in statistics quite some time ago where I did hypothesis testing and stuff with confidence intervals. Do you think that's what he means or does he want me to compare it with other algorithms? I don't want to say what kind of data set I am working with but it's comparable to something such as predicting spam or ham for email messages. </p>\n\n<p>Any help or guidance on this question would be greatly appreciated. I am pretty new to the area of computer science research. But am I right in saying that statistics are used quite a lot to evaluate these types of things?</p>\n\n<p>Thank you!</p>\n", 'ViewCount': '29', 'Title': 'Finding Statistical Signifigance for a Classifier', 'LastActivityDate': '2013-10-07T00:11:48.270', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14870', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4336', 'Tags': '<machine-learning><statistics><classification>', 'CreationDate': '2013-10-06T23:28:43.117', 'Id': '14866'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am reading a paper on <a href="http://talukdar.net/papers/adsorption_ecml09.pdf" rel="nofollow">Semi Supervised Learning</a> and I am confused about a term. The paper talks about graphs that are invariant to permutations of the vertices. Can somebody explain or perhaps give an example? Is it same a regular graphs?</p>\n', 'ViewCount': '43', 'Title': 'Graphs invariant to permutations of vertices', 'LastActivityDate': '2013-10-08T11:42:31.550', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1972', 'Tags': '<graph-theory><graphs><machine-learning>', 'CreationDate': '2013-10-08T11:42:31.550', 'Id': '14906'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm learning about Support Vector Machines(SVM).\nI understood that their objective is to maximize the margin between the decision line and the closest point to it.\nFor simplicity, let's assume we have a linear SVM and linearly separable data X.\nWe would like to find the maximum distance D and vector W, such that</p>\n\n<p>$\\dfrac{W^T \\cdot X_i+W_0}{\\|W\\|}\\geq D$ for all $X_i$ in the first class</p>\n\n<p>$\\dfrac{W^T \\cdot X_i+W_0}{\\|W\\|}\\leq-D$ for all $X_i$ in the second class.</p>\n\n<p>Why is the problem equivalent to maximizing $\\frac{1}{\\|W\\|}$, given the following constraints are satisfied:</p>\n\n<p>$W^T\\cdot X_i+W_0\\geq1$ for all $X_i$ in the first class</p>\n\n<p>$W^T\\cdot X_i+W_0\\leq-1$ for all $X_i$ in the second class.</p>\n\n<p>I'm more interested in a formal proof than in the intuition.</p>\n", 'ViewCount': '74', 'Title': 'SVM optimization objective: why are we maximizing $\\frac{1}{\\|w\\|}$?', 'LastEditorUserId': '683', 'LastActivityDate': '2013-10-11T23:47:04.260', 'LastEditDate': '2013-10-11T23:47:04.260', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '15013', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10665', 'Tags': '<machine-learning>', 'CreationDate': '2013-10-11T22:35:14.853', 'Id': '15012'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>My aim is to prove a VC-dimension $d$ for different problems. All the problems I have do not have a target function (or concept) explicitly stated. This unlike most of the examples I came through. For example in the interval problem, the target function $h^*$ is: if point $x\\in [a,b]$ then $x=+$ and $-$ otherwise. I do not know where $[a,b]$ resides in $R$ but at least I know its an interval. Therefore, three points of $(+,-,+)$ cannot be shattered by any concept.   </p>\n\n<p>I am given an infinite input space $X$ and $H$ is the class of all finite languages over $X$ and asked to prove the VC-dimension for this problem. I have no clue what the target function looks like.  </p>\n\n<p>Assume I got two points $x_1,x_2\\in X$, there are $2^2$ possibilities $(-,-),(-,+),(+,-),(+,+)$. I am stucking here since I don't know what is <em>shattered</em> (i.e. realisable) and what is <em>not</em> without knowing the target function $h^*$. Should I assume such function exists and then workout based on its behaviour? am I missing something? </p>\n", 'ViewCount': '84', 'Title': 'How to find the shattered set size for unknown hypothesis target', 'LastActivityDate': '2013-10-12T22:09:56.733', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<machine-learning><vc-dimension>', 'CreationDate': '2013-10-12T22:09:56.733', 'Id': '15025'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm currently studying Decision Trees and the definition of a decision tree in our course is somewhat obscure for me. Nowhere in other online definitions of decision trees do I find something about relevant subtrees and relevant leafs...</p>\n\n<p>The course is based on the book Machine Learning from Tom Mitchell, so I'll have a look in that book for more information.</p>\n\n<p>I wanted to know if someone can explain to me in English a relevant subtree and a relevant leaf...</p>\n\n<p>If the question is too vague or abstract, I'll first read the chapter in Tom Mitchell's book and then come back to this forum.</p>\n", 'ViewCount': '23', 'Title': 'Relevant subtree and relevant leaf in Machine Learning Decision Trees', 'LastActivityDate': '2013-10-13T14:08:46.683', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10575', 'Tags': '<machine-learning><decision-problem>', 'CreationDate': '2013-10-13T14:08:46.683', 'Id': '16038'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I've been learning about neural networks and SVMs.  The tutorials I've read have emphasized how important kernelization is, for SVMs.  Without a kernel function, SVMs are just a linear classifier.  With kernelization, SVMs can also incorporate non-linear features, which makes them a more powerful classifier.</p>\n\n<p>It looks to me like one could also apply kernelization to neural networks, but none of the tutorials on neural networks I've seen have mentioned this.  Do people commonly use the kernel trick with neural networks?  I presume someone must have experimented with it to see if it makes a big difference.  Does kernelization help neural networks as much as it helps SVMs?  Why or why not?</p>\n\n<p>(I can imagine several ways to incorporate the kernel trick into neural networks.  One way would be to use a suitable kernel function to preprocess the input, a vector in $\\mathbb{R}^n$, into a higher-dimensional input, a vector in $\\mathbb{R}^{m}$ for $m\\ge n$.  For multiple-layer neural nets, another alternative would be to apply a kernel function at each level of the neural network.)</p>\n", 'ViewCount': '123', 'Title': 'Kernelization trick, for neural networks', 'LastActivityDate': '2013-11-02T04:10:50.153', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-10-19T07:01:58.443', 'FavoriteCount': '1', 'Id': '16220'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am a microbiologist and I am currently self-studying machine learning from some open lecture videos. I am finding it pretty difficult to understand proofs that are somewhat "obvious", my poor mathematical knowledge is to blame for that. Can you please recommend a text-book that deals with the mathematical proofs of the theorems? Or approaches machine learning from the mathematical side?</p>\n', 'ViewCount': '74', 'Title': 'Recommendations for machine learning book?', 'LastActivityDate': '2013-11-01T05:37:35.780', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10977', 'Tags': '<machine-learning><proof-techniques>', 'CreationDate': '2013-10-25T20:29:04.257', 'Id': '16430'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>What is the difference between a Neural Network, a Deep Learning System and a Deep Belief System?</p>\n\n<p>As I recall your basic neural network is a 3 layers kinda thing,\nand I have had Deep Belief Systems described as being neural networks stacked on top of each other.</p>\n\n<p>I've not personally heard of a Deep Learning Systems, but i strongly suspect it is a synonym for Deep Belief System. In fact I believe that Deep Belief System is the less common term. Can anyone confirm this?</p>\n", 'ViewCount': '414', 'Title': 'What is the difference between a Neural Network, a Deep Learning System and a Deep Belief System?', 'LastEditorUserId': '11043', 'LastActivityDate': '2013-10-31T03:35:06.613', 'LastEditDate': '2013-10-31T02:47:39.893', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '11043', 'Tags': '<machine-learning><neural-networks><boltzmann-machine>', 'CreationDate': '2013-10-29T14:04:58.587', 'FavoriteCount': '1', 'Id': '16545'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>How to find hyperparameters (in Gaussian Process) by log marginal likelihood.<br>\nSuppose we have mean function as $m=ax^2 +bx + c$.<br>\nso we have $hyperparameters = \\{a,b,c,sigma_y,sigma_n,l\\}$;<br>\nHow we calculate all these parameters by log marginal likelihood and by partial derivatives?</p>\n', 'ViewCount': '35', 'Title': 'Gaussian Process doubt for machine learning', 'LastEditorUserId': '9612', 'LastActivityDate': '2013-10-30T09:17:56.493', 'LastEditDate': '2013-10-30T09:17:56.493', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11062', 'Tags': '<machine-learning>', 'CreationDate': '2013-10-30T07:19:19.773', 'FavoriteCount': '1', 'Id': '16568'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Let's say we have a sport, where many competitions are organized throughout the year. In these events, a set of people compete, although not every person competes in every event.</p>\n\n<p>I would like to categorize these people, and the events, in such a way that people in category $A$ performed well in the events of category $A$ etc. This also means that people in category $A$ usually perform well at the same events. There would then be a one-to-one correspondence between event categories and people categories.</p>\n\n<p>It would also be OK for me if every event and every person is not uniquely put into one category, but is given a weight $w_A$ representing how much it fits into category $A$</p>\n\n<p>The data I have are the results from all the events.</p>\n\n<p>What do you think would be a good algorithm to categorize both events and people at the same time (since they are related)? I have been reading up on different machine learning algorithms, but would love some input on what to focus on.</p>\n", 'ViewCount': '40', 'Title': 'Categorizing sport events and competitors', 'LastActivityDate': '2013-11-05T17:56:41.147', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11208', 'Tags': '<algorithms><machine-learning>', 'CreationDate': '2013-11-05T17:56:41.147', 'Id': '16747'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Assume I have a complex structure (say a bayesian network) defined over a set of variables $V=\\{X_1,X_2,..,X_n\\}$  and has the domain $D=\\{D_{X_1}\\times D_{X_2}\\times ...\\times\\ D_{X_n}\\}$. </p>\n\n<p>I am trying to implement a learner $h:D\\rightarrow \\{0,1\\}$ that takes $D$ as its input space and poses some queries to  an oracle with noise level $0\\leq\\mu&lt;0.5$. So for any example $x\\in D$, the probability of classifying it correctly is $1-\\mu$. </p>\n\n<p>I am stuck here since things are not clear enough to me. Given any response $y$ for a query $x$, $y$ will have some noise with probability $\\mu$. How should I proceed to implement such learner? How to know whether $y$ is the correct label of point $x$? </p>\n', 'ViewCount': '28', 'Title': 'Intuitively understanding the learning problem with noise', 'LastActivityDate': '2013-11-06T04:51:32.357', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<machine-learning>', 'CreationDate': '2013-11-06T04:51:32.357', 'Id': '16762'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m not sure if this is the correct stack exchange or correct tags, but my question is as follows: </p>\n\n<p>I am working on a sort-of ratings system for players in a particular game. After allowing the ratings to develop for many games, I have set up a "database" (not sure if this is the correct term) for matches: a point in the database would consist of the score difference between the players (i.e if it\'s >0 player 1 won) and the rating discrepancy between the two players before this match.</p>\n\n<p>The idea is to use this database in order to predict the score difference of a match that has not yet occurred: I measure the rating discrepancy between the 2 players, and lookup in my database for the score differences in games of a "similar" rating discrepancy, and based on these games I am able to predict, say, a rough probability of each score difference occurring in this match that has not yet happened.</p>\n\n<p>I actually have two questions: </p>\n\n<p>1) what is a good approach to using the database to predict the probability of each score difference, i.e what qualifies as a "similar" rating discrepancy, how do I deal with extreme cases where the rating discrepancy is very large and I have few data examples of such matches (should I relax my definition of "similar"?), etc. A bit of googling shows that maybe I am looking for something relating to data clusters.</p>\n\n<p>2)how would I go about implementing an algorithm as above? are there good standard implementations of such classification algorithms? I am writing in C# if it makes a difference. </p>\n', 'ViewCount': '47', 'Title': 'Analysis and classification based on data points', 'LastActivityDate': '2013-11-06T20:13:58.630', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8247', 'Tags': '<data-structures><machine-learning><data-mining><cluster>', 'CreationDate': '2013-11-06T17:36:07.680', 'Id': '16775'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I try to understand the details regarding using <a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Model</a> in Tagging Problem.</p>\n\n<p>The best concise description that I found is the <a href="http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf" rel="nofollow">Course notes by Michal Collins</a>.</p>\n\n<p>The goal is to find a function $f(x)=arg max_{y \\in Y} p(y|x)$, where $y$ is the tag set for sentence $x$. </p>\n\n<p><strong>Question 1</strong>. It\'s suggested to use a generative model and to estimate joint probability $p(x,y)$ from the trainig examples, however what the the reason to use generative model and increase the number of computation why not directly to estimate $p(y|x)$, I think it\'s possible to estimate the conditional probability straightforward from the training data.</p>\n\n<p><strong>Addendum</strong>. Do you know the reason why at all we should try to use a generative model in this case (POS tagging). As I  understand if we can estimate $p(x,y)$ that exactly with  the same success we can estimate $p(y|x)$  and directly find the answer to the question, what is the best tagging - $\\hat{y}$ without weak assumption of generative model. There is the reason to use generative model, and I don\'t see it yet. Can you explain me what the reason?</p>\n\n<p><strong>Question 2.</strong> Assume we decided to use a generative model and made estimation to $p(x,y)$ why we decide to decompose it as follows $p(x,y)=p(y)p(x|y)$ and not  $p(x,y)=p(x)p(y|x)$? </p>\n\n<p><strong>Addendum</strong>. I do understand that it\'s very logical to use the decomposition $p(y)p(x|y)$ just because by doing it we approach $p(y|x)$, so mathematically it seems very reasonable, however according to the task I don\'t see what the problem to decompose it like $p(x,y)=p(x)p(y|x)$, there should be sore reason why we can not decompose it so and I don\'t understand why.</p>\n\n<p>I appreciate your help.</p>\n', 'ViewCount': '74', 'Title': 'Hidden Markov Model in Tagging Problem', 'LastEditorUserId': '8473', 'LastActivityDate': '2013-11-07T13:51:13.720', 'LastEditDate': '2013-11-07T13:51:13.720', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '16779', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<machine-learning><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2013-11-06T20:02:49.927', 'Id': '16777'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a question about preparing the dataset of positive samples for a cascaded classifier that will be used for object detection.</p>\n\n<p>As positive samples, I have been given 3 sets of images:</p>\n\n<ol>\n<li>a set of <strong>colored</strong> images in full size (about 1200x600) with a <strong>white background</strong> and with the object displayed at a different angles in each image</li>\n<li>another set with the same images in grayscale and with a <strong>white background</strong>, scaled down to the detection window size (60x60)</li>\n<li>another set with the same images in grayscale and with a <strong>black background</strong>, scaled down to the detection window size (60x60)</li>\n</ol>\n\n<p>My question is that in Set 1, should the background really be white? Should it not instead be an <strong>environment</strong> that the object is likely to be found in in the testing dataset? Or should I have a fourth set where the images are in their natural environments? How does environment figure into the training samples?</p>\n', 'ViewCount': '36', 'Title': 'Environment requirement in training image dataset for classifier', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-27T12:25:13.433', 'LastEditDate': '2013-11-12T16:52:26.290', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<machine-learning><image-processing><computer-vision><data-sets><classification>', 'CreationDate': '2013-11-12T09:44:33.823', 'Id': '17949'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>My aim is to classify types of cars (Sedans,SUV,Hatchbacks) and earlier I was using corner features for classification but it didn\'t work out very well so now I am trying Gabor features.<br/></p>\n\n<p><a href="http://www.mathworks.in/matlabcentral/fileexchange/38844-gabor-image-features" rel="nofollow">code from here</a><br/></p>\n\n<p>Now the features are extracted and suppose when I give an image as input then for 5 scales and 8 orientations I get 2 [1x40] matrices.</p>\n\n<p><strong>1. 40 columns of squared Energy.</strong></p>\n\n<p><strong>2. 40 colums of mean Amplitude.</strong></p>\n\n<p>Problem is I want to use these two matrices for classification and I have about 230 images of 3 classes (SUV,sedan,hatchback).</p>\n\n<p>I do not know how to create a [N x 230] matrix which can be taken as vInputs by the neural netowrk in matlab.(where N be the total features of one image).</p>\n\n<p>My question:</p>\n\n<ol>\n<li><p>How to create a one dimensional image vector from the 2 [1x40] matrices for one image.(should I append the mean Amplitude to square energy matrix to get a [1x80] matrix or something else?)</p></li>\n<li><p>Should I be using these gabor features for my purpose of classification in first place? if not then what?</p></li>\n</ol>\n\n<p>Thanks in advance</p>\n', 'ViewCount': '53', 'Title': 'Making feature vector from Gabor filters for classification', 'LastActivityDate': '2013-11-16T13:58:45.183', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18073', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11370', 'Tags': '<machine-learning><neural-networks><image-processing><classification>', 'CreationDate': '2013-11-14T06:23:16.160', 'Id': '18009'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Im designing a program to play Connect 6, a variation of connect 4. I have narrowed down my options to the following:</p>\n\n<p>1) Minimax with Alpha-Beta Proning </p>\n\n<p>2) A Neural Net </p>\n\n<p>3) Machine Learning</p>\n\n<p>My program has one second to make a move, so I can only branch out 2 moves ahead with Minimax. Which solution would best perform under 1 second?</p>\n\n<p>I looked around the web, but couldn't find anything relevant.</p>\n\n<p>Also, are there any other additional resources you suggest I have a look at?</p>\n", 'ViewCount': '333', 'Title': 'Algorithms for Connect 4?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-15T23:35:49.010', 'LastEditDate': '2013-11-15T14:46:39.167', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '3', 'OwnerDisplayName': 'asd', 'PostTypeId': '1', 'Tags': '<algorithms><machine-learning><artificial-intelligence><board-games>', 'CreationDate': '2013-11-11T16:49:58.777', 'FavoriteCount': '1', 'Id': '18012'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>What makes neuromorphic architectures more efficient (less heat and power consumption) than von Neumann architecture for complex tasks? Except inspiration from biological systems, what are some formal results on this?\nAny reference to books or articles is appreciated as well. </p>\n', 'ViewCount': '89', 'Title': 'What makes neuromorphic computing architecture more efficient than von Neumann', 'LastActivityDate': '2013-11-16T21:11:49.633', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11368', 'Tags': '<complexity-theory><machine-learning><parallel-computing>', 'CreationDate': '2013-11-16T21:11:49.633', 'FavoriteCount': '2', 'Id': '18081'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am implementing a learner to learn a DAG model $G=\\langle V,E\\rangle$ where $V$ and $E$ represent both variables and dependencies respectively ( similar to Bayesian networks). Each variable $v\\in V$ is associated with possible values (domain) $D_v$ and a function $\\theta_v$.</p>\n\n<p>I assume the learner knows the number of variables $n$ (i.e. vertices) and their possible values (domain). The goal is to find $E$ (dependencies) and $\\theta_v$ for every variable $v$. I also assume there is a target function $c$ exist (the realizable case).</p>\n\n<p>The hypothesis class is defined as the set of consistent hypotheses i.e. $H=\\{h|\\ h(x)=c(x)\\} \\forall x\\in S$ where $S$ is set of examples seen so far. </p>\n\n<p>I am trying to find a way to represent my hypotheses class. Initially, before receiving any example, it contains:</p>\n\n<ol>\n<li>all possible DAGs over $V$.</li>\n<li>all different combinations of $E$ as long as its acyclic.</li>\n<li>For every Graph $G$ generated from (1) and (2),all different function values over $G$. </li>\n</ol>\n\n<p>Beside my naive representation, I do not know how to compute (1) precisely. To put my question in another way, how to represent the hypotheses class over Bayesian networks? </p>\n', 'ViewCount': '63', 'Title': 'How to represent/implement the hypotheses class for a DAG learner', 'LastEditorUserId': '4598', 'LastActivityDate': '2014-01-03T20:51:01.397', 'LastEditDate': '2013-11-21T20:46:51.080', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<graphs><machine-learning>', 'CreationDate': '2013-11-21T20:08:17.023', 'FavoriteCount': '1', 'Id': '18239'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '63', 'Title': 'How to determine the size of training data using VC dimension?', 'LastEditDate': '2013-11-25T21:24:28.870', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '11576', 'FavoriteCount': '0', 'Body': u'<p>I want to determine the size of training data ($m$) when I know the parameters $VC(H)$, $\u03b4$ and $e$. As I know the $VC$ bound satisfy this equation:</p>\n\n<p>$$ \\mathrm{error}_{\\mathrm{true}}(h) \\le \\mathrm{error}_{\\mathrm{train}}(h) + \\sqrt\\frac{VC(H) \\times \\ln\\left(\\frac{2m}{VC(H)} + 1\\right) + \\ln(4\u03b4)}m\n$$</p>\n\n<p>but how can I determine the size of training data ($m$) if I know the others?</p>\n', 'Tags': '<machine-learning><learning-theory><vc-dimension>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-11-26T13:09:12.277', 'CommentCount': '0', 'AcceptedAnswerId': '18383', 'CreationDate': '2013-11-23T14:40:08.877', 'Id': '18276'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The question emerged while reading Ch. 3 of Rasmussen &amp; Williams <a href="http://www.gaussianprocess.org/gpml/" rel="nofollow">http://www.gaussianprocess.org/gpml/</a>. In the end of this chapter, the authors gave results for the problem of handwritten digits classification (16x16 greyscale pictures); features are 256 pixel intensities + bias. I was surprised that in such a high-dimensional problem, \'metric\' methods, like Gaussian processes with squared exponential kernel, or SVM with the same kernel, behave quite nice.</p>\n\n<p>Also, I heard sometimes that SVM is good for [essentially bag-of-word] text classification. Why aren\'t they suffering from the curse of dimensionality?</p>\n', 'ViewCount': '29', 'Title': 'Why are kernel methods with RBFs effective for handwritten digits (letters) classification?', 'LastActivityDate': '2013-11-24T12:00:02.520', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '11591', 'Tags': '<machine-learning><kernel><ocr>', 'CreationDate': '2013-11-24T12:00:02.520', 'FavoriteCount': '1', 'Id': '18298'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am studying the following paper for understanding next-word prediction using n-gram &amp; trie: - <a href="http://nlp.cs.berkeley.edu/pubs/Pauls-Klein_2011_LM_paper.pdf" rel="nofollow">http://nlp.cs.berkeley.edu/pubs/Pauls-Klein_2011_LM_paper.pdf</a> Before this, I did some brief study on what are n-grams. And, I know trie data structure. The issue is - the algorithm in paper is not so intuitive to understand. Anyone can provide some better/intuitive explanation of this algorithm, or some similar Language Model Implementation. I am new to this site, so if this question structure is inappropriate to this site, please guide. Thanks in advance.</p>\n', 'ViewCount': '128', 'Title': 'Next Word Prediction using n-gram & Tries', 'LastActivityDate': '2013-11-26T04:08:32.257', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11628', 'Tags': '<algorithms><machine-learning><artificial-intelligence><natural-lang-processing>', 'CreationDate': '2013-11-26T04:08:32.257', 'Id': '18351'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Next-word prediction or phrase-prediction engines used in modern keyboards of mobiles and tablets, like swift key &amp; XT9, which predict the next word the user is going to type based on some pre-defined or dynamic corpus, based on n-grams (maximum frequency of last typed 2-3 words plus the current word) based language models (Markov Model).</p>\n\n<p>What I think is that these engines/algos are a part of AI/NLP.\nBut what I am not sure about is what specific branch of AI/NLP they belong to.</p>\n\n<p>Is it machine learning ?\nIs it data science ?\nIs it big data ?\nIs it Computing Intelligence ?\nIs it decision-making ?\nIs it data-mining ?\nOr statistical pattern recognition/ predictive analytics/ Supervised learning/ Unsupervised learning ?\nOr all/many of these or something else ?</p>\n', 'ViewCount': '55', 'ClosedDate': '2013-12-03T17:35:15.933', 'Title': 'Next-Word Prediction Engines - which branch of AI do they belong', 'LastEditorUserId': '11628', 'LastActivityDate': '2013-11-26T16:09:39.763', 'LastEditDate': '2013-11-26T16:09:39.763', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11628', 'Tags': '<machine-learning><artificial-intelligence><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2013-11-26T15:39:28.363', 'Id': '18387'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm having this binary classification model for my Master's thesis. In my tests I get pretty good results (~85%-90% success rate). Though, I would like to have a comparison of other classification problems so I could know if I'm above or below the average success rates.</p>\n\n<p>I know I should do the comparison within my field and I am working on that as well. But it will be nice to have other examples of classification success rates from other fields, for example: medical patients (sick or healthy?), elections of two candidates and etc.</p>\n\n<p>Thanks in advanced,</p>\n\n<p>Cheers!</p>\n", 'ViewCount': '40', 'Title': 'What considered as good results in machine learning binary classification', 'LastActivityDate': '2013-12-02T08:31:10.300', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11754', 'Tags': '<machine-learning><classification>', 'CreationDate': '2013-12-02T08:31:10.300', 'Id': '18528'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a multi-label classification problem, in which each input sample has a set of zero or more output labels.</p>\n\n<p>I have a multi-class classifier which, for every input sample, returns a certain score for each of the output labels.</p>\n\n<p>One way to use this multi-class classifier for multi-label classification is to calculate a <strong>threshold score</strong>, and select for the output all labels that get a score above the threshold.</p>\n\n<p>My question is: <strong>what is the most efficient way to calculate the threshold score?</strong></p>\n\n<p>Currently we use the following scheme:</p>\n\n<ul>\n<li>Train the multi-class classifier on 90% of the training set.</li>\n<li>Run the base multi-class classifier on the remaining 10% of the training set (which we call "development set"). Keep all the scores in a large array.</li>\n<li>Create a set of all scores that are returned by the base multi-class classifier for any input and any label. Call the set $S$.</li>\n<li>For every score $s \\in S$, and for every input sample in the development set, calculate the positive labels returned when the threshold is $s$. Compare to the gold-standard. Calculate the precision, recall and $F1$.</li>\n<li>Select the score $s_max$ that yielded the maximum $F1$.</li>\n</ul>\n\n<p>This is not efficient because there are many different scores and the method is linear in the number of different scores.</p>\n\n<p>We plotted the $F1$ against the scores and noticed that this is a concave function - it has a single maximum. So, we thought of using binary search to find the maximum point. But, we are not sure that the function will always be concave.</p>\n\n<p>What advice do you have for making this process more efficient?</p>\n', 'ViewCount': '39', 'Title': 'Calculating the classification threshold efficiently', 'LastActivityDate': '2013-12-04T10:16:54.473', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<time-complexity><machine-learning><efficiency>', 'CreationDate': '2013-12-04T10:16:54.473', 'Id': '18602'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm not sure if this is the kind of question that belongs here! Sorry if I got it wrong.</p>\n\n<p>I'm trying to find out what subjects I should be studying to understand what a computer can and cannot do in terms of its relationship between its hardware and its software.</p>\n\n<p>Examples Questions I want to understand the answers to:</p>\n\n<ul>\n<li><p>Can this raspberry pi run this graphic intensive javascript website?</p></li>\n<li><p>Is this hardware powerful enough to provide a smooth user experience?</p></li>\n<li><p>Can an average household computer simulate dozens of AI learning entities in a video game?</p></li>\n<li><p>How fast will a computer have to be in order to house a single human-like AI</p></li>\n</ul>\n\n<p>Sorry if these questions are vague. I'm not looking for answers to these specific questions per se, but I want to know what I should be studying to get a stronger understanding of these kind of problems.</p>\n\n<p>Thanks!</p>\n", 'ViewCount': '60', 'ClosedDate': '2013-12-26T09:39:49.053', 'Title': 'What subjects should I study to understand the limitations of hardware with specific software?', 'LastActivityDate': '2013-12-15T19:02:28.623', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '-1', 'OwnerDisplayName': 'sunwoo yang', 'PostTypeId': '1', 'Tags': '<machine-learning>', 'CreationDate': '2013-12-12T17:09:20.883', 'Id': '18928'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Neural networks can have multiple inputs.\nBut some times two or more of these inputs can often be related to a single entity.</p>\n\n<p>E.g : Height and weight of a person to predict the probability of disease or price and Volume of a stock to predict it's value.</p>\n\n<p>How can we make a neural network understand that two inputs are related to the same entity?\nIs there any efficient (or inefficient) way of '<em>tagging</em>' them together?</p>\n", 'ViewCount': '82', 'Title': 'How to make a Neural network understand that multiple inputs are related to the same entity?', 'LastEditorUserId': '9479', 'LastActivityDate': '2013-12-19T07:01:09.173', 'LastEditDate': '2013-12-19T03:40:55.333', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9479', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2013-12-18T08:25:48.263', 'Id': '19090'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a question regarding optimal mistake bound for learning algorithm</p>\n\n<p>There is a famous fact that $VC(C) \\leq Opt(C)$, </p>\n\n<p>where $C$ - set of learning concepts,</p>\n\n<p><a href="http://en.wikipedia.org/wiki/VC_dimension" rel="nofollow">VC(C)</a> - VC dimension of C,</p>\n\n<p>$Opt(C)$ - the smallest mistake bound (of the best learning algorithm) on the hardest learning concept $c \\in C$ .</p>\n\n<p>I don\'t understand why $VC(C) \\leq Opt(C)$, in my opinion the notion of best algorithm $A$ is so vague that you cannot for sure say that $VC(C)$ is not more than $Opt(C)$</p>\n\n<p>For example,  $VC(line\\ on\\ the\\ plane)$=3 , it means that $Opt(C) \\geq 3$ in words it means for the hardest concept $c \\in C$ (represented as a line on the plane) the number of mistakes of the best learning algorithm is more than 3.</p>\n\n<p>Why the above fact is so strong?</p>\n', 'ViewCount': '77', 'Title': 'VC dimension and optimal mistake bound', 'LastActivityDate': '2013-12-19T19:49:50.850', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<machine-learning><vc-dimension>', 'CreationDate': '2013-12-19T07:37:09.793', 'Id': '19113'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm using machine-learning algorithms to solve binary classification problem (i.e. classification can be 'good' or 'bad'). I'm using <code>SVM</code> based algorithms, <code>LibLinear</code> in particular. When I get a classification result, sometimes, the probability estimations over the result are pretty low. For example, I get a classification 'good' with probability of 52% - those kind of results I rather throw away or maybe classify them as 'unknown'.</p>\n\n<p><strong>EDITED - by D.W.'s suggestion</strong></p>\n\n<p>Just to be more clear about it, my output is not only the classification 'good' or 'bad', I also get the confidence level (in %). For example, If I'm the weather guy, I'm reporting that tomorrow it will be raining, and I'm 52% positive at my forecast. In this case, I'm sure you won't take your umbrella when you leave home tomorrow, right? So in those cases where my model does not have a high confidence level I throw away this prediction and don't count it in my estimations.</p>\n\n<p>Unfortunately, I can't find articles regarding thresholding the probability estimations... </p>\n\n<p>Does anyone have an idea what is a normal threshold that I can set over the probability estimations? or at least can refer me to a few articles about it?</p>\n", 'ViewCount': '69', 'Title': 'What would be a decent threshold for classification problem?', 'LastEditorUserId': '11754', 'LastActivityDate': '2014-04-20T10:08:52.793', 'LastEditDate': '2013-12-21T08:24:16.580', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11754', 'Tags': '<machine-learning><probabilistic-algorithms><statistics><classification>', 'CreationDate': '2013-12-20T07:53:10.210', 'Id': '19146'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I found this problem in a book. It supposedly minimizes the number of Support vectors rather than maximizing the margin:</p>\n\n<p>$min_{\\alpha,b} \\frac{1}{2}\\sum_{i=1}^{m}\\alpha_{i}^{2}$<br>\n$s.t.\\quad y_{i}(\\sum_{j=1}^m\\alpha_{j}y_{j}(x_{i}\\cdot x_{j})+b)\\ge1 \\quad \\forall i\\in \\{1,...m\\}$</p>\n\n<p>(for simplicity, I've omitted the slack variables - let's assume the problem is linearly sperable.)</p>\n\n<p>I don't understand how this was derived. we get $w=\\sum_{i=1}^{m}\\alpha_{i}y_{i}x_{i}$ from the regular lagrangian for the SVM problem, in which $w$ is squared - thus, when we derive by $w$ and equate to 0, we get the formula for $w$. But here, $w$ is already replaced with the same expression. It makes sense - we still want to express the seperator as some combination of the input vectors. But how do you get this mathematically for this different problem?</p>\n\n<p>Also, I understand that using l<sub>1</sub> norm for $\\alpha_{i}$ should make the number of support vectors even lower. how come?</p>\n", 'ViewCount': '29', 'Title': 'Minimum number of support vectors', 'LastEditorUserId': '12266', 'LastActivityDate': '2013-12-20T18:07:08.923', 'LastEditDate': '2013-12-20T18:07:08.923', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12266', 'Tags': '<machine-learning>', 'CreationDate': '2013-12-20T15:13:30.063', 'Id': '19158'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '67', 'Title': 'Naive Bayes Intuition', 'LastEditDate': '2013-12-22T08:13:28.823', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8473', 'FavoriteCount': '1', 'Body': "<p>I have some difficulties in understanding the intuition behind Naive Bayes Classification.</p>\n\n<p>In general, I do understand every argument of the definition, however I don't understand why it's correct and why any other argument is incorrect.</p>\n\n<p>Start from the beginning:</p>\n\n<p><strong>Goal:</strong> $v_{MAP} = argmax_{v_i} p(v_i|a_1...a_n)$</p>\n\n<p>the goal is simply to find the maximum aposteriori of the value of the target function given the set of features Note,  here we don't mention the hypothesis, because we are not interested in hypothesis.</p>\n\n<p>After developing the formula with Bayes formula, we get</p>\n\n<p>$argmax_{v_i} p(v_i)p(a_1...a_n|v_i)$</p>\n\n<p>Now, the trick goes $p(a_1...a_n|v_i)=\\prod_{j} p(a_j|v_i)$</p>\n\n<p>The question is why in the very begging, having the formula of</p>\n\n<p>$v_{MAP} = argmax_{v_i} p(v_i|a_1...a_n)$</p>\n\n<p>I cannot apply the trick $p(v_i|a_1...a_n)=\\prod_{j} p(v_i|a_j)$</p>\n\n<p>It's just a reverse direction, in addition we don't have to calculate the prior probability of $p(v_i)$, so for me it looks like the better way to go.</p>\n\n<p>What's wrong with my reasoning.</p>\n", 'Tags': '<machine-learning><probability-theory>', 'LastEditorUserId': '8473', 'LastActivityDate': '2013-12-22T19:48:04.187', 'CommentCount': '1', 'AcceptedAnswerId': '19185', 'CreationDate': '2013-12-21T11:32:10.787', 'Id': '19175'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>This is more of a conceptual question.</p>\n\n<p>I have learned about Neural Nets, and I have some clue as to how Support Vector Machines work. I read somewhere however that given the appropriate kernel (is that right?), the SVM is identical to the Neural Net. Could someone who understands this please enlighten me as to how that's possible?</p>\n", 'ViewCount': '25', 'Title': 'Support Vector Machines as Neural Nets?', 'LastActivityDate': '2013-12-28T06:36:46.847', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12414', 'Tags': '<machine-learning><neural-networks><kernel>', 'CreationDate': '2013-12-28T06:36:46.847', 'FavoriteCount': '1', 'Id': '19337'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>I\'m studying support vector machines and came across <a href="http://www.tristanfletcher.co.uk/SVM%20Explained.pdf" rel="nofollow">this paper</a>. The following equation doesn\'t make sense to me, especially the part with the 0 \u2200i. Any help understanding the basics of SVMs?</p>\n\n<p>yi * (xi * w + b) - 1 >= 0 \u2200i</p>\n\n<ul>\n<li>xi - one input </li>\n<li>yi - the classification (+1 or -1) </li>\n<li>w and b - variables to find in order to "train up" the SVM (?)</li>\n</ul>\n\n<p>Please forgive my ignorance on SVMs, a lot is still unclear to me and I\'m trying to learn these bit by bit. Thanks!</p>\n', 'ViewCount': '43', 'Title': 'SVM math question', 'LastEditorUserId': '12414', 'LastActivityDate': '2013-12-28T20:45:51.473', 'LastEditDate': '2013-12-28T20:27:11.807', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '19347', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12414', 'Tags': '<machine-learning>', 'CreationDate': '2013-12-28T19:14:35.150', 'Id': '19344'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>This is a machine learning question. Given this series of categorical data, what program will derive the underlying algorithm and predict what comes next in the series?</p>\n\n<p>Here is the series:</p>\n\n<p>B, BA, BB, BAA, BAB, BBA, BBB, BAAA, BAAB, BABA, ...</p>\n\n<p>Anyone with knowledge of computer science may quickly realize that this series is simply counting in binary with "A" substituted for "0" and "B" substituted for "1". This is true, but...</p>\n\n<p>the program that predicts what comes next must do so <strong>only by manipulating the symbols given</strong> in the series. It must not use hard-coded knowledge of binary counting.</p>\n\n<p>I realize many patter recognition algorithms are available but I haven\'t seen how any can solve this deceptively hard problem.</p>\n\n<p>-Edit-</p>\n\n<p>Based on the votes that this problem is insolvable, I\'ve done some refactoring and posed the question another way, with more constraints, here:\n<a href="http://cs.stackexchange.com/questions/19663/what-program-will-derive-the-underlying-algorithm-in-these-question-answer-pairs">What program will derive the underlying algorithm in these question-answer pairs</a></p>\n', 'ViewCount': '74', 'Title': 'Machine Learning: What program will derive the underlying algorithm in this series?', 'LastEditorUserId': '12742', 'LastActivityDate': '2014-01-12T04:13:24.513', 'LastEditDate': '2014-01-12T04:13:24.513', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '12742', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2014-01-10T22:41:51.880', 'Id': '19638'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given this set of question-answer pairs, what program will derive the underlying algorithm and provide the correct answer for any question of the same format.</p>\n\n<p><strong>Question-Answer Pairs (training set):</strong></p>\n\n<pre><code>B:BA\nBA:BB\nBB:BAA\nBAA:BAB\nBAB:BBA\nBBA:BBB\nBBB:BAAA\nBAAA:BAAB\nBAAB:BABA\n</code></pre>\n\n<p>Those familiar with binary may notice that the training set is binary numbers with A and B substituted for 0 and 1. The answer to each question is the next binary number (using A and B). </p>\n\n<p>After processing the training set, the program should be able to answer questions such as the following using the algorithm it derived:</p>\n\n<pre><code>BABA:?\nBABB:?\nBBBBAAA:?\nBAABBAAABBABA:?\n</code></pre>\n\n<p><strong>Constraints:</strong></p>\n\n<ul>\n<li>The program must derive the counting algorithm <strong>only by manipulating the data given</strong> in the training set. It must not use hard coded knowledge of binary counting.</li>\n<li>Many algorithms may produce the correct answers. Therefore, <strong>the simplest algorithm is preferred</strong>. </li>\n<li>The program should assume that <strong>each answer is a transformation of the question</strong>.</li>\n<li>All questions will be in the binary format seen above, but they may be of arbitrary size.</li>\n</ul>\n\n<p>Can any existing machine learning programs/algorithms solve this? If so, how?\nIf you believe this is unsolvable, please explain why.</p>\n\n<hr>\n\n<p><em>This update contains background to the question, explanation of the problem space, a new constraint, a proposed solution, and further questions.</em></p>\n\n<p>This problem is relevant to general machine learning where the machine must learn by observation and feedback the algorithms that govern the world around it.</p>\n\n<p>Based on <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity" rel="nofollow">Kolmogorov complexity</a>, there is at least one program that can produce the correct mappings:</p>\n\n<pre><code>if B, then BA\nif BA, then BB\n(etc. for all pairs in training set)\n</code></pre>\n\n<p>This will work for every pair in the training set and nothing else. This will be the shortest program if the training set is completely random. The good news is that this is an upper bound. For any training set that is not random, there will be a smaller program that will work. Also, the number of programs smaller than upper bound is finite. </p>\n\n<p>A unfortunate result of Kolmogorov complexity is that it cannot be calculated. This is due to the <a href="http://en.wikipedia.org/wiki/Halting_problem" rel="nofollow">halting problem</a>. We can\'t know if any program will stop until it does.</p>\n\n<p>If the question is "Write pi," then the program that produces the correct answer would never halt because pi has infinite digits. An answer infinitely long is never desirable so I think the best way to deal with this is to put an <strong>arbitrary limit on the length of the answer</strong>.</p>\n\n<p>With that additional constraint, here is an (inefficient) program that will generate a correct solution program shorter than the upper bound if one exists. (sorry of this is confusing, but these steps outline a program that generates programs that implement an algorithm to map questions to answers in a training set):</p>\n\n<ol>\n<li>Create the "upper bound" program. One that maps each input in the training set directly to its output.</li>\n<li>Generate every possible program that is shorter than the upper bound and list them from shortest to longest.</li>\n<li>Starting with the shortest program, run the first step of every program. </li>\n<li>Stop when a correct program is found.</li>\n<li>Eliminate programs that stop without a correct answer or produce an answer longer than the arbitrary limit.</li>\n<li>Repeat steps 3-5 running the second step, third step, etc. of the programs.</li>\n</ol>\n\n<p>This program has the following benefits:</p>\n\n<ul>\n<li>It limits the number of programs to those smaller than the "upper bound" program.</li>\n<li>It avoids the halting problem by\n<ul>\n<li>incorporating an arbitrary limit to the length of the answer and </li>\n<li>executing step x in all programs before moving on to step x+1 so that the solution will be found before looping infinity.</li>\n</ul></li>\n</ul>\n\n<p>The main disadvantage is that it is terribly slow. It takes millions of years to crack a 128 bit password and I think this program could have comparable performance.</p>\n\n<p><strong>Now, the questions:</strong></p>\n\n<ul>\n<li><p>Do you see any significant flaws in this solution?</p></li>\n<li><p>Can this program\'s performance be improved in any significant way\nwithout introducing onerous constraints?</p></li>\n</ul>\n', 'ViewCount': '95', 'Title': 'What program will derive the underlying algorithm in these question-answer pairs (updated)?', 'LastEditorUserId': '12742', 'LastActivityDate': '2014-01-14T22:27:00.303', 'LastEditDate': '2014-01-14T22:27:00.303', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '19682', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12742', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2014-01-12T04:09:23.450', 'Id': '19663'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given two sets $A,B$ of strings over alphabet $\\Sigma$, can we compute the smallest deterministic finite-state automaton (DFA) $M$ such that $A \\subseteq L(M)$ and $L(M) \\subseteq \\Sigma^*\\setminus B$?</p>\n\n<p>In other words, $A$ represents a set of positive examples.  Every string in $A$ needs to be accepted by the DFA.  $B$ represents a set of negative examples.  No string in $B$ should be accepted by the DFA.</p>\n\n<p>Is there a way to solve this, perhaps using <a href="https://en.wikipedia.org/wiki/DFA_minimization">DFA minimization</a> techniques?  I could imagine creating a DFA-like automaton that has three kinds of states: accept states, reject states, and "don\'t-care" states (any input that ends in a "don\'t-care" state can be either accepted or rejected).  But can we then find a way to minimize this to an ordinary DFA?</p>\n\n<p>You could think of this as the problem of learning a DFA, given positive and negative examples.</p>\n\n<p>This is inspired by  <a href="http://cs.stackexchange.com/q/19686/755">Is regex golf NP-Complete?</a>, which asks a similar questions for regexps instead of DFAs.</p>\n', 'ViewCount': '158', 'Title': 'Smallest DFA that accepts given strings and rejects other given strings', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-15T08:31:57.547', 'LastEditDate': '2014-01-13T12:59:49.750', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '19693', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<regular-languages><automata><finite-automata><machine-learning>', 'CreationDate': '2014-01-13T09:37:38.647', 'Id': '19687'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have developed an algorithm which recommends geographical locations to users based on popular trends and their own interests. The dataset is created by my organization. So the user selects a few categories and based on his interest and rating by other people he is presented with recommended places for him. </p>\n\n<p>How do you evaluate or use metrics for such system given that ground truth doesn't makes sense in this case ? </p>\n\n<p><strong>EDIT:</strong> \nI meant that how to evaluate the accuracy or quality of results in such case especially for published work.</p>\n\n<p><strong>EDIT 2</strong> (as per the request for details in the comments)</p>\n\n<p>Details of the system</p>\n\n<ol>\n<li><p>The user indicates his preferences from a predefined set of tags (cultural, mountains etc)</p></li>\n<li><p>Users can also rate different places on a scale of 1-5. </p></li>\n<li><p>Users profile (geographical location, places already visited etc are already stored in his profile)</p></li>\n<li><p>Based on user's choice and other heuristics(rating etc), a set of places is recommended by the system.</p></li>\n</ol>\n", 'ViewCount': '62', 'Title': 'How to evaluate recommendation engine without ground truth?', 'LastEditorUserId': '2741', 'LastActivityDate': '2014-01-15T16:04:53.503', 'LastEditDate': '2014-01-15T08:46:39.027', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<machine-learning><recommendation-systems>', 'CreationDate': '2014-01-13T17:51:43.163', 'Id': '19699'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am new to statistical learning. I have a structure $X$ where I showed its hypothesis class $H$ has VC dimension $d$. All I know now is that I can bound the number of examples by $m\\geq \\frac{1}{\\epsilon}ln \\frac{d}{\\delta}$ and with probability at least $1-\\delta$ I will get a hypothesis with error at most $\\epsilon$. </p>\n\n<p>My question concerns what is usually the next step(s),with regard to the big picture of learning a structure $X$, after showing its VCD? </p>\n\n<p>I thought about studying other complexity measures for $X$ but wish to hear others suggestions. </p>\n', 'ViewCount': '90', 'Title': 'What is usually the next step after showing the VC dimension?', 'LastActivityDate': '2014-01-23T00:00:54.697', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<machine-learning><learning-theory><vc-dimension>', 'CreationDate': '2014-01-22T04:40:35.833', 'FavoriteCount': '1', 'Id': '19887'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '21', 'Title': 'How do I apply patch sized features to larger images?', 'LastEditDate': '2014-01-24T17:23:21.613', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13101', 'FavoriteCount': '0', 'Body': "<p>I've been trying to teach myself some machine learning, and I wanted to ask what seems a simple question, but I've not been able to find any resources that explain the next step.</p>\n\n<p>Let's say I am doing semi-supervised learning, and have a few hundred sparsely distributed feature extractors, trained on random 32x32 regions (the unsupervised part of the process). </p>\n\n<p>I now want to take the larger images in my training set, and do some supervised learning based on the feature extractors I now have. In this case, multi-label classification.</p>\n\n<p>The bit I'm not clear on is what I do with the full sized image from my training set:</p>\n\n<ul>\n<li>Take random samples from it? -- seems like it would be pot luck if it picks an area needed to identify appropriate labels</li>\n<li>Take overlapping tiles with a sliding window? -- seems like I'd end up with absurd dimensionality, since for each tile, I get a whole vector of features</li>\n<li>Take adjacent tiles? -- dimensionality still nonsensical, and probably translation sensitive as well</li>\n</ul>\n\n<p>It's a hypothetical example, but let's say my inputs are 800x600 photographs, i.e. the input is about 100-1000 times bigger than the samples I used in the unsupervised learning stage.</p>\n", 'Tags': '<machine-learning><image-processing><pattern-recognition>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-25T12:26:53.737', 'CommentCount': '0', 'AcceptedAnswerId': '19962', 'CreationDate': '2014-01-24T15:46:33.130', 'Id': '19944'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>There is a new <a href="http://quant.stackexchange.com/">Quantitative Finance SE site</a>. However, I am interested in asking the "CS crowd": </p>\n\n<blockquote>\n  <p>What are some interesting key references or surveys on applying algorithms to stock trading analysis?</p>\n</blockquote>\n\n<p>There are many such references, however, I am particularly interested in those that would appeal to those with a CS background. Further, I am especially interested in those that find surprising applications of TCS or mathematics theory.</p>\n', 'ViewCount': '41', 'Title': 'Applications of algorithms to stock trading analysis', 'LastEditorUserId': '472', 'LastActivityDate': '2014-01-31T23:16:57.623', 'LastEditDate': '2014-01-31T23:16:57.623', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<reference-request><machine-learning><optimization><statistics>', 'CreationDate': '2014-01-31T22:55:00.353', 'Id': '20173'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>There is a famous <a href="http://en.wikipedia.org/wiki/Part-of-speech_tagging" rel="nofollow">part-of-speech tagging problem</a> in Natural Language Processing. The popular solution is to use <a href="http://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Models</a>.</p>\n\n<p>So that, given the sentence $x_1 \\dots x_n$ we want to find the sequence of POS tags $y_1 \\dots y_n$ such that $y_1 \\dots y_n = \\arg\\max_{y_1 \\dots y_n}p(Y,X)$.</p>\n\n<p>By Bayes Theorem, $P(X,Y)=P(Y)P(X \\mid Y)$.</p>\n\n<p>Solving POS by HMM implies the assumptions: $p(y_i \\mid y_{i-1})$ and $p(x_i \\mid y_i)$.</p>\n\n<p>The question is there are any particular reason why we prefere to solve it by generative model with a lot of assumption and not directly by estimating $P(Y \\mid X)$, given the training corpus it\'s still possible to estimate $p(y_i \\mid x_i)$.</p>\n\n<p>The second question, even when we convinced that the generative model is preferred why to calculate is as $P(Y,X)=P(Y)P(X \\mid Y)$ and not $P(X,Y)=P(X)P(Y \\mid X)$. In case we have an appropriate generative story I can use $P(X,Y)=P(X)P(Y \\mid X)$ as well, is it mentioned somewhere that assumed generative story is preferred.</p>\n', 'ViewCount': '35', 'Title': 'Solving the part-of-speech tagging problem with HMM', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-01T16:41:25.817', 'LastEditDate': '2014-02-01T15:46:40.370', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '20190', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<machine-learning><natural-lang-processing><hidden-markov-models>', 'CreationDate': '2014-02-01T13:49:50.607', 'Id': '20185'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>In case of binary classification problem, what are the $y_i$ 's in the training data set $\\{(x_1, y_1), (x_2, y_2), \\dots (x_n, y_n)\\}$?</p>\n\n<p>I guess they are from $\\{1,-1\\}$. Now I see a method for finding a scoring function $f(x) = w^Tx + b$ by minimizing the squared error between the $f(x_i)$'s and $y_i$'s over $w$ and $b$. Now is it correct to minimize the error between $f(x_i)$'s and $y_i$? The latter is a sign while the former is a value? They seem incomparable to me. </p>\n", 'ViewCount': '43', 'Title': 'What values do $y_i$ in training data for binary classification problems attain?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-04T15:07:53.207', 'LastEditDate': '2014-02-02T13:53:00.000', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13091', 'Tags': '<terminology><machine-learning><classification>', 'CreationDate': '2014-02-02T13:01:37.330', 'Id': '20214'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I need to link facts to actions through rules. If a person bought soup 10 times and he is coming at midday every day, then the system should link the fact that the person bought soup so many times, using the rule "person, consecutively buying soup 5 or more times within a month is going to buy soup with 90% confidence", to the conclusion that with 90% confidence today at midday, the same person will show up, ordering soup.</p>\n\n<p>Above is an example of an expert system, however based on the research I\'ve just done, it seems like expert systems have lost their popularity, which they had in 90s-00s. The only "popular" applications are business decision making and some medical systems. I am wondering if I should use expert systems or should I look into more "advanced" alternatives? What are the obvious disadvantages to using an expert system, besides the setup cost of conducting the research?</p>\n', 'ViewCount': '61', 'Title': 'Are expert systems outdated, what are better alternatives to them, if any?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-07T12:02:57.150', 'LastEditDate': '2014-02-07T07:58:10.620', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '21420', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14453', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2014-02-06T21:16:04.027', 'Id': '21403'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Deep Learning, now one of the most popular fields in Artificial Neural Network, has shown great promise in terms of its accuracies on data sets. How does it compare to Spiking Neural Network. Recently Qualcomm unveils its zeroth processor on SNN, so I was thinking if there are any difference if deep learning is used instead. </p>\n', 'ViewCount': '71', 'Title': 'What are the key differences between Spiking Neural Network and Deep Learning', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-25T19:49:57.550', 'LastEditDate': '2014-02-10T08:40:54.117', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14541', 'Tags': '<machine-learning><neural-networks>', 'CreationDate': '2014-02-10T07:43:27.300', 'Id': '21487'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am currently learning about the <a href="http://en.wikipedia.org/wiki/Q-learning" rel="nofollow">Q-learning</a> algorithm, so I therefore assume that it has some use or purpose. However I currently cannot see how it is in any way useful. In terms of complexity class, it appears to perform equal to or worse than brute force, which as far as I am aware, is the lowest you ever need to go to compute something computable.</p>\n\n<p>What, if anything, have I missed?</p>\n', 'ViewCount': '74', 'Title': 'Is Q-Learning ever better than Brute Force?', 'LastEditorUserId': '472', 'LastActivityDate': '2014-02-16T20:49:42.927', 'LastEditDate': '2014-02-16T20:49:42.927', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14568', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2014-02-11T11:20:32.407', 'Id': '21528'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Let $C\\subseteq 2^X$ be a concept class over $X$ and let $\\bar{C}:=\\{X\\setminus c\\mid c\\in C\\}$ be the complement. Show that $VCdim(C)=VCdim(\\bar{C})$.</p>\n\n<p>Proof:</p>\n\n<p>Let $d:=VC_{dim}(C)$, then there exists $S\\subseteq X$, $|S|=d$, s.t. $S$ is shattered by $C$.</p>\n\n<p>Let $d':=VC_{dim}(\\bar{C})$, then there exists $S'\\subseteq X$, $|S'|=d'$, s.t. $S'$ is shattered by $C$.</p>\n\n<p>Show that $d\\leq d'$ and $d' \\leq d$. I know that a set $S$ is shattered by $C$ iff $\\Pi_C(S):=\\{c\\cap S\\mid c\\in C\\}=2^S$, but I have no clue how to show the two sides. Can someone help me with that?</p>\n", 'ViewCount': '55', 'Title': 'VC dimension of complement', 'LastActivityDate': '2014-02-12T17:27:50.553', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '21572', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14600', 'Tags': '<machine-learning><vc-dimension>', 'CreationDate': '2014-02-12T08:52:04.493', 'Id': '21563'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm currently trying to find an efficient algorithm to solve a discrete optimization problem that arises when constructing decision trees. The problem is as follows:</p>\n\n<p>Say we are given $N$ ordered data points on the real line: $x_1,\\ldots,x_N \\in \\mathbb{R}$ such that $x_1 &lt; x_2 &lt; \\ldots &lt; x_N$. </p>\n\n<p>Each of the points $x_i$ has a label $y_i \\in \\{0,1\\}$. We are asked to predict this label using a <em>decision stump classifier</em>, $h(x;t) = \\mathbb{1}[x&gt;t]$. The decision stump classifier predicts $\\hat{y}_i = 1$ if $x_i &gt; t$. Thus, the accuracy of this classifier depends on the threshold parameter $t$. </p>\n\n<p>I am looking for an efficient algorithm to determine the value of $t$ that maximizes the number of correctly classified points. That is, solve the problem:</p>\n\n<p>$$\\max_{t\\in\\mathbb{R}} A(t)=\\sum_{i=1}^N \\mathbb{1}[y_i=0]\\mathbb{1}[x_i\\leq t] + \\mathbb{1}[y_i=1]\\mathbb{1}[x_i&gt;t]$$\nSome insights:</p>\n\n<ul>\n<li><p>Since there are $N$ data points, we only need to consider $N+1$ values of $t$. These are values that lie in the $N+1$ intervals $(-\\infty,x_1), [x_1,x_2),\\ldots, [x_{N-1},x_N), [x_N,\\infty]$.</p></li>\n<li><p>When $t &lt; \\min_{i}x_i$, the decision stump predicts $\\hat{y}_i=1$ for all $i=1,\\ldots,N$. Here $A(t) = \\sum_{i=1}^N{\\mathbb{1}[y_i=1]}=N^+$.</p></li>\n<li><p>When $t \\geq \\max_{i}x_i$, the decision stump predicts $\\hat{y}_i=0$ for all $i=1,\\ldots,N$. Here $A(t) = \\sum_{i=1}^N{\\mathbb{1}[y_i=0]}=N^-$.</p></li>\n<li><p>The number of correctly classified points $A(t)$ can be decomposed as $B(t)+C(t)$, where\n$$B(t) = \\sum_{i=1}^N{\\mathbb{1}[y_i=0]\\mathbb{1}[x_i\\leq t]}$$\nis the number of correctly classified points with negative labels and\n$$C(t) = \\sum_{i=1}^N{\\mathbb{1}[y_i=1]\\mathbb{1}[x_i&gt;t]}$$\nand the number of correctly classified points with positive labels. Note that $B(t)$ is monotonically increasing in $t$ while $C(t)$ is monotonically decreasing in $t$.</p></li>\n</ul>\n", 'ViewCount': '80', 'Title': 'Determining the optimal threshold value for a one-dimensional decision stump classifier', 'LastEditorUserId': '2046', 'LastActivityDate': '2014-02-16T20:30:00.237', 'LastEditDate': '2014-02-14T17:52:01.077', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2046', 'Tags': '<algorithms><machine-learning><discrete-mathematics>', 'CreationDate': '2014-02-14T02:54:49.967', 'Id': '21623'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>For the past several months I've been interested in some Machine Learning and I can't help but notice that nomatter what kind of learning algorithm I'm using - at its core lies a simple polynomial or logistic regression. Today I went back to the most basic definition that I could find:</p>\n\n<blockquote>\n  <p>Machine learning, a branch of artificial intelligence, concerns the\n  construction and study of systems that can learn from data.</p>\n</blockquote>\n\n<p>The fact that we're creating mathematical hypotheses based on data ALWAYS means that you're doing some kind of statistical regression ?</p>\n\n<p>If I'm wrong, can you please provide an example where this doesn't hold true.</p>\n", 'ViewCount': '48', 'ClosedDate': '2014-02-24T16:00:56.080', 'Title': 'Is machine learning all about statistical regressions at its core?', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-02-24T13:14:09.477', 'LastEditDate': '2014-02-24T13:14:09.477', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14979', 'Tags': '<machine-learning>', 'CreationDate': '2014-02-24T08:29:43.557', 'Id': '21962'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m studying the online learning model and the Halving algorithm.</p>\n\n<p>We\'ve seen the threshold problem:</p>\n\n<p>The domain is $X=\\left\\{ 1,2,...,N-1\\right\\} $, the label set is  $Y=\\{-1,1\\}$ and the hypotheses class is $H=\\left\\{ h_{\\theta}(x)=sign(x-\\theta):\\theta\\in\\left\\{ \\frac{1}{2},1+\\frac{1}{2},...,(N-1)+\\frac{1}{2}\\right\\} \\right\\} $</p>\n\n<p>I\'ll denote the number of mistakes the learner $A$ does on the environment $E$ by $M(A,E) = \\left|\\left\\{ i:\\hat{y_{i}}=A_{\\mbox{pred}}(x_{i})\\neq y_{i}\\right\\} \\right|$ where $E=\\left\\{ (x_{i},y_{i})\\right\\} _{i=1}^{n}$</p>\n\n<p>For any environment $E$, the mistake bound for Halving  is  $M$(Halving,$E$)$\\leq\\left\\lfloor \\log N\\right\\rfloor $</p>\n\n<p>Now I must prove that this bound is "tight", i.e., for any learning algorithm $A$ there exists a realizable environment $E$ such that $M(A,E)\\geq \\left\\lfloor \\log N\\right\\rfloor$ </p>\n\n<p>My try - I came to the conclusion that finding the correct $h^{*} \\in H$ is pretty similar in this case to finding a value in a sorted array.\nSince we\'ll need at least $\\left\\lfloor \\log N\\right\\rfloor $ comparisons, an algorithm $A$ which can find $h^{*}$ and make less than $\\left\\lfloor \\log N\\right\\rfloor$  mistakes "<em>can find a value in a sorted array in less than $\\left\\lfloor \\log N\\right\\rfloor$ comparisons for any given array, which is a contradiction.</em>" </p>\n\n<p>The sentence in quotes is my intuition, but I\'m having trouble proving it formally.</p>\n\n<p>Is this the right way to go? </p>\n\n<p>Many thanks.</p>\n', 'ViewCount': '33', 'Title': 'Proving $\\log (N)$ mistake bound is "tight" for a learner when learning thresholds', 'LastEditorUserId': '14934', 'LastActivityDate': '2014-02-24T21:23:26.033', 'LastEditDate': '2014-02-24T21:22:56.360', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14934', 'Tags': '<machine-learning>', 'CreationDate': '2014-02-24T16:33:44.587', 'Id': '21969'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>It is a well-known fact that "Correlation doesn\'t equal causation", but machine learning seems to be almost entirely based on correlation. I\'m working on a system to estimate the performance of students on questions based on their past performances. Unlike other tasks, like Google search, this doesn\'t seem like the kind of system that can be easily gamed - so causation isn\'t really relevant in that regard.</p>\n\n<p>Clearly if we want to do experiments to optimise the system, we will have to care about the correlation/causation distinction. But from the point of view of just building a system to pick questions that are likely to be of the appropriate difficulty level - does this distinction have any importance?</p>\n', 'ViewCount': '26', 'Title': 'Machine learning - importance of correlation vs. causation', 'LastActivityDate': '2014-02-24T18:17:40.953', 'AnswerCount': '4', 'CommentCount': '1', 'AcceptedAnswerId': '21987', 'Score': '9', 'OwnerDisplayName': 'Casebash', 'PostTypeId': '1', 'OwnerUserId': '644', 'Tags': '<machine-learning><statistics>', 'CreationDate': '2014-02-18T04:51:45.277', 'Id': '21986'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>In most implementations of genetic algorithms, the focus is on crossover and mutation. But somehow, most of them leave out diploid (dominant/recessive) nature of genes. As far as my (limited) understanding goes dominant/recessive nature of genes is a very important factor in deciding the actual characteristics of an organism.</p>\n\n<p>So my question is why is the diploid nature of genes left out of genetic algorithms in most implementation?</p>\n\n<p>Is it because:</p>\n\n<ul>\n<li>it doesn't provide much benefit </li>\n<li>it adds unnecessary complexity to an otherwise simple algorithm</li>\n<li>it's difficult to implement</li>\n</ul>\n\n<p>Or something else entirely? </p>\n", 'ViewCount': '40', 'Title': 'Why are diploid (dominant/recessive) genes not used widely in genetic algorithms?', 'LastActivityDate': '2014-02-24T18:17:57.267', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '11', 'OwnerDisplayName': 'Shayan RC', 'PostTypeId': '1', 'OwnerUserId': '9479', 'Tags': '<machine-learning><genetic-algorithms>', 'CreationDate': '2014-02-18T13:17:26.417', 'Id': '21991'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am having an AI exam in two weeks, and I am still figuring out certain concepts and ideas, related to Bayesian Nets, Hidden Markov Chains, Conditional Random Fields and Neural Nets (yes it is all going to be tested and yes we have a text (AI - A Modern Approach), but no, we did not cover everything in class).</p>\n\n<p>I "know" a few things about the mathematical descriptions of all of those, but I know pretty much nothing about their usage or practical applications.</p>\n\n<p>Here are my questions (and I apologize for my naivety):</p>\n\n<ol>\n<li>What kind of machine learning algorithm classes do they belong to? Since they all need training, does it mean that they are all supervised learning algorithms?</li>\n<li>They all have an underlying structure that allows a graph to represent them, where directed edges denote dependencies between states. The probability of being in a state is computed as a conditional probability from ancestors of the state. Does that sound about right?</li>\n<li>In what kind of situation do you want to use which of the algorithms? Is it possible to some it up, or does it require subtle differentiation and expert-level knowledge?</li>\n<li>Why do Neural Nets get special treatment? I heard of many classes teaching Neural Nets, but I have heard of no such thing for the other guys.</li>\n</ol>\n', 'ViewCount': '52', 'Title': 'How are Bayesian Nets, Hidden Markov Chains, Conditional Random Fields and Neural Nets related?', 'LastActivityDate': '2014-02-28T16:11:53.907', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15080', 'Tags': '<machine-learning><artificial-intelligence><neural-networks><probabilistic-algorithms><markov-chains>', 'CreationDate': '2014-02-26T20:00:12.453', 'Id': '22062'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm classifying different electrical devices based on features extracted from their electricity consumption into a household-specific model built from around 10 devices. Now I want to detect whether a classified testing instance is coming from a device which has not been present in the training set, i.e. I want to discriminate known from unknown devices.</p>\n\n<p>I'm working with Weka and use the Classifier.distributionForInstance() method to give me the (classifier-specific) probability distribution for those 10 possible classes for each instance.</p>\n\n<p>Now, the problem is that some classifiers (SMO, NaiveBayes, J48 and other trees) most of the time classify a not known device with a high probability of almost 1 to a class, whereas RandomForest (preferably with high amount of trees) and IBk (kNN) perform rather well in giving back lower probabilities of classification/more uncertain results.</p>\n\n<p>The questions I have: \nCan you think of alternative approaches or any other algorithms/methods? \nWhy is it, that the first stated algorithms strongly decide for one class. I would have expected them to return unclearer results. </p>\n\n<p>thx, regards</p>\n", 'ViewCount': '38', 'Title': 'ML Algorithms to discriminate "known" from "unknown" instances', 'LastActivityDate': '2014-02-28T20:34:48.113', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15101', 'Tags': '<machine-learning>', 'CreationDate': '2014-02-27T13:39:15.343', 'Id': '22091'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>To calculate the error in back propagation you would use,\n(target_output - actual_output) * actual_output * (1 - actual_output)</p>\n\n<p>So what does, actual_output * (1 - actual_output) solve?</p>\n\n<p>Wouldn't, [target_output - actual_output] be the amount it's incorrect by?</p>\n", 'ViewCount': '45', 'ClosedDate': '2014-03-27T07:55:51.317', 'Title': 'In back propagation why is this necessary, o (1 - o)', 'LastEditorUserId': '9479', 'LastActivityDate': '2014-03-17T16:29:15.307', 'LastEditDate': '2014-03-12T10:21:12.580', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'OwnerDisplayName': 'user15206', 'PostTypeId': '1', 'Tags': '<machine-learning><artificial-intelligence><neural-networks>', 'CreationDate': '2014-03-02T21:39:20.853', 'Id': '22207'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am new to machine learning, so forgive me if I am doing something absolutely absurd.</p>\n\n<p>I have a classification task (~100 classes) and have about 2 million training data points in a 2000-dimensional space. Coordinates of data points are integers (discrete). All points have non-zero coordinates only for &lt; 10 dimensions. That is, each point can be uniquely defined in &lt; 10 dimensional sub-space.</p>\n\n<p>If I use a Gaussian Mixture Model (GMM) for each class, I will end up with ~100 GMMs in a 2000-dimensional space. I feel that given the fact that each point is uniquely definable in less than 10 dimensional space, there can possibly be a better way of doing it.</p>\n\n<p>What am I missing here?</p>\n', 'ViewCount': '40', 'Title': 'Classification algorithm for high dimensional data which is uniquely definable in a very small sub-space', 'LastEditorUserId': '472', 'LastActivityDate': '2014-03-04T09:09:49.450', 'LastEditDate': '2014-03-04T09:09:49.450', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15225', 'Tags': '<machine-learning><classification>', 'CreationDate': '2014-03-03T12:47:29.817', 'FavoriteCount': '1', 'Id': '22217'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm having trouble thinking about the following. If we have two machines 1 and 2 that evenly split a set of data points, does $k$-means separately, then averages the result, does this agree with just $k$-means on one machine?</p>\n\n<p>To be more specific, consider the following routine:</p>\n\n<blockquote>\n  <ol>\n  <li>Split an input dataset evenly between 1 and 2.</li>\n  <li>Initialize $k$ centroids that are the same on both 1 and 2.</li>\n  <li>Use $k$-means algorithm to find updated centroids.</li>\n  <li>Find a new set of $k$ centroids by averaging the corresponding centroid from 1 and 2. </li>\n  <li>Loop over 2. </li>\n  </ol>\n</blockquote>\n\n<p>Will this agree with just running $k$-means? I think that it is the averaging part that might work, but then I'm not sure if this routine finishes running. </p>\n", 'ViewCount': '34', 'Title': 'parallelizing $k$-means', 'LastActivityDate': '2014-03-05T07:58:00.607', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15297', 'Tags': '<algorithms><machine-learning><parallel-computing>', 'CreationDate': '2014-03-05T06:16:31.567', 'Id': '22292'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>If my goal were to compress say 10,000 images and I could include a dictionary or some sort of common database that the compressed data for each image would reference, could I use a large dictionary shared by the entire catalog and therefore get much smaller file sizes?  Could this be expanded to work with images in general, i.e. to replace something like JPEG?</p>\n\n<p>Are there existing compression systems that operate like this, where there is a large common set of bits transmitted and loaded before decompression, that has been built by analyzing many images?</p>\n\n<p>For example, is there an existing computer science/machine learning research effort using sparse autoencoding over a large set of images and this concept of distributing a network derived from that encoding with the decompressor?</p>\n\n<p>Note: I have deleted quite a bit of context from this question because it was claimed that this made the question too "opinionated".  I also had to edit the title after someone else modified the title in such a way as to change the meaning of the question.  If you are looking for clarification about my question, please ask.</p>\n', 'ViewCount': '165', 'Title': 'Does there exist a data compression algorithm that uses a large dataset distributed with the encoder/decoder?', 'LastEditorUserId': '15323', 'LastActivityDate': '2014-04-06T22:59:48.903', 'LastEditDate': '2014-03-07T02:16:22.923', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15323', 'Tags': '<machine-learning><neural-networks><data-compression><computer-vision>', 'CreationDate': '2014-03-05T21:00:31.943', 'Id': '22317'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a data set with two classes: one class has at most 2000 members while the size of the second class is unlimited, though it is typically in the hundreds of thousands.  I have read that it is problematic to use a decision tree to naively classify this data.  My question is, how how I modify the data or the classification scheme to classify such data, using a decision tree at some point?</p>\n', 'ViewCount': '26', 'Title': 'Decision Tree with Unbalanced Data', 'LastActivityDate': '2014-03-29T00:54:58.383', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15425', 'Tags': '<machine-learning><data-mining><classification>', 'CreationDate': '2014-03-08T17:40:23.287', 'Id': '22406'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>We're accessing an API of a web system for obtaining product information. We require some additional information, which is not available through the API. This information is publically available for each product visually - through the source code for each item on its item page. We've written an algorithm which parses this information from the web page for each item, but that will be highly ineffective in the long run, since the algorithm will simply stop working if and when they decide to change the source code ( for example - redesign of the front end ).</p>\n\n<p>I feel like there should be a supservised learning approach to this problem, however I'm unaware if there exist such solutions.</p>\n\n<p>What are some good aproaches to this kind of problems ?</p>\n\n<p>Regards.</p>\n", 'ViewCount': '36', 'Title': 'web content "mining" using supervised learning tequniques', 'LastActivityDate': '2014-04-28T04:35:02.273', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14979', 'Tags': '<machine-learning><data-mining>', 'CreationDate': '2014-03-09T17:22:29.470', 'Id': '22434'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Phase space learning <a href="http://cseweb.ucsd.edu/users/gary/pubs/nips94.pdf" rel="nofollow">Paper1</a> and <a href="http://gliamac.mit.edu/people/seung/papers/continuous.pdf" rel="nofollow">Paper2</a> in neural network represents the input  in higher dimension in auto associative learning. So, the network functions as an auto-associative memory where dynamical attractors are fixed points, each corresponding to one of the patterns that we want to store in the network. If the network has 3 input nodes, the the number of outputs will also be 3. Thus, for a time instant, $t$ Input is a vector. </p>\n\n<p>The Authors mention that a trajectory is traced out. In my case, for every time instant I have a feature vector of dimension 3 i.e there are three features. In my opinion, for every time step, t a learning algorithm is used to update the weights. Also. the Authors mention delay embedding for time series reconstruction which is an essential point in any phase space representation. Based on these, the following concepts are unclear and I will be thankful for an intuitive explanation. </p>\n\n<p>Q1. How come a feature vector is delay embedded and a trajectory is formed since we have only one example at every time instant? </p>\n\n<p>Q2. I will appreciate ideas in how to apply phase space learning with particle Swarm optimization and the objective function is the mean square error between the actual output of the network and the target. In my application, I only have the final target vector not a target vector for every time step. </p>\n', 'ViewCount': '14', 'Title': 'Supervised learning based on phase space representation', 'LastEditorUserId': '10583', 'LastActivityDate': '2014-03-11T03:06:09.200', 'LastEditDate': '2014-03-11T03:06:09.200', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10583', 'Tags': '<machine-learning><neural-networks><pattern-recognition><research>', 'CreationDate': '2014-03-11T02:56:38.210', 'Id': '22489'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Consider the following soft margin loss function: $\\max(0, 1-yf(x))$.  I have the problem of needing to compute the conditional probability $p(y|x)$ corresponding to this function and am having trouble making the connection between conditional probability and this function.  I have come across a few papers (e.g. <a href="http://www.unc.edu/~yfliu/papers/lum.pdf" rel="nofollow">http://www.unc.edu/~yfliu/papers/lum.pdf</a>) that say that "soft classifiers explicitly calculate the class conditional probabilities", but I do not understand how as the output of a classifier is not a probability.  Can someone please explain what I am missing?</p>\n', 'ViewCount': '73', 'Title': 'Soft Margin Loss and Conditional Probabilities', 'LastEditorUserId': '683', 'LastActivityDate': '2014-03-31T12:54:01.220', 'LastEditDate': '2014-03-11T11:50:27.197', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15425', 'Tags': '<machine-learning><probability-theory><classification>', 'CreationDate': '2014-03-11T08:42:06.473', 'Id': '22494'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Yue et al [1] and Chong &amp; Wong [2] apply a cognitive map for goal-oriented decision making.  The basic premise is that we need to find out the initial states that will give us the desired goal vector. In Paper1 an Immune algorithm is used to generate random populations of input states of the network and in Paper2 Genetic Algorithm is used. The objective function Eg(3) in Paper1 and Eq(7) in Paper2 is the same in both the papers. The following issues are based on Paper2. </p>\n\n<p>Background : The model of the cognitive map is mathematically expressed by Eq(1). There are 2 applications of FCM: </p>\n\n<ol>\n<li><p>Learning where the weights are unknown and they are optimized using learning algorithms most commonly used in neural network. This is referred to as forward chaining. Here, we test if the FCM converges with the given stimulus or not and we want the FCM to converge to the desired state. The FCM evolves using Eq(1). </p></li>\n<li><p>Finding the initial state vectors that will make the FCM converge to the desired goal- Known as backward chaining. Here the initial state vector is unknown but the target goal is known. I do not understand are the following and will be extremely helpful if somebody can explain what is going on while using the example Fuzzy cognitive Map (FCM) in Figure2</p></li>\n</ol>\n\n<p>I am mostly concerned with application two, ginding the initial state vectors which will produce the desired goal. I have two questions:</p>\n\n<ol>\n<li><p>In Paper2 Table 1 lists the initial setting. The weight vector, W only has a diagonal element of 1 but the picture in Fig 2 has a different weight matrix E. During the calculation of the next state when the FCM evolves using Eq(1), which weight matrix is used (either W in Table 1 or in the Fig 2) What is the use of the weight matrix given in Figure2? Is the weight matrix unknown also?</p></li>\n<li><p>Is the weight matrix updated in this Application 2? If the chromosomes represent the states and not the weights, then how come the weight matrix is different as shown in Figure 2?\nCan somebody please explain which weight goes into the objective function and if the weights are also unknown or if they are fixed? If fixed, then which ones are they?</p></li>\n</ol>\n\n<hr>\n\n<ol>\n<li><a href="http://dl.acm.org/citation.cfm?id=1353927" rel="nofollow">Goal-Oriented Decision Support Based on Fuzzy Cognitive Map</a> by H. Yue et al. (2007) [<a href="http://www.wseas.us/e-library/conferences/2007beijing/papers/554-092.pdf" rel="nofollow">Download</a>]</li>\n<li><a href="http://dx.doi.org/10.1109/CEC.2007.4424805" rel="nofollow">On the Fuzzy Cognitive Map Attractor Distance</a> by A. Chong and K. W. Wong (2007) [<a href="http://researchrepository.murdoch.edu.au/976/1/Published_Version.pdf" rel="nofollow">Download</a>]</li>\n</ol>\n', 'ViewCount': '27', 'Title': 'Difficulty in understanding a graphical model in training', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-13T09:43:47.547', 'LastEditDate': '2014-03-13T09:43:47.547', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10583', 'Tags': '<machine-learning><graphical-models>', 'CreationDate': '2014-03-13T00:34:39.677', 'FavoriteCount': '1', 'Id': '22568'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>As we all know, Matrix Factorization is an effective method to do rating prediction jobs in recommender systems. Thanks to the work of Yahuda Koren. My question is why MF can do this job? What's the physical meaning behind it?</p>\n", 'ViewCount': '53', 'Title': 'Physical Meaning Behind Matrix Factorization', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-14T22:24:45.737', 'LastEditDate': '2014-03-14T09:37:20.077', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15674', 'Tags': '<machine-learning><data-mining><recommendation-systems>', 'CreationDate': '2014-03-14T04:51:40.857', 'FavoriteCount': '1', 'Id': '22609'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Which kind of machine learning concept / model is used in <a href="http://www.20q.net" rel="nofollow">20 Questions</a>?<br>\nIs this kind of thing best solved by a neural network?<br>\nWhere I can read something about it?</p>\n', 'ViewCount': '44', 'Title': 'What kind of model is used by 20 Questions?', 'LastActivityDate': '2014-03-20T22:24:41.397', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '22885', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15915', 'Tags': '<machine-learning><neural-networks><data-mining>', 'CreationDate': '2014-03-20T16:48:31.383', 'FavoriteCount': '2', 'Id': '22872'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Currently I'm trying to classify spam emails with kNN classification. Dataset is represented in the bag-of-words notation and it contains approx. 10000 observations with approx. 900 features. Matlab is the tool I use to process the data.</p>\n\n<p>Within the last days I played with several machine learning approaches: SVM, Bayes and kNN. In my point of view, kNN's performance beats SVM and Bayes when it comes to minimize the false positive rate. Checking with 10-fold Cross-Validation I obtain a false positive rate of 0.0025 using k=9 and Manhattan-Distance. Hamming distance performs in the same region.</p>\n\n<p>To further improve my FPR I tried to preprocess my data with PCA, but that blow away my FPR as a value of 0.08 is not acceptable.</p>\n\n<p>Do you have any idea how to tune the dataset to get a better FPR?</p>\n\n<p>PS: Yes, this is a task I have to do in order to pass a machine learning course.</p>\n", 'ViewCount': '60', 'Title': 'kNN: how to improve Spam classification?', 'LastActivityDate': '2014-04-26T17:41:22.150', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15994', 'Tags': '<machine-learning><classification>', 'CreationDate': '2014-03-22T11:18:18.067', 'FavoriteCount': '1', 'Id': '22934'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I want to learn maths for artificial intelligence. I heard that main areas of mathematics for AI are Multivariable Calculus, Linear Algebra, Probability and Statistics and Discrete Mathematics. But what level of these subjects do I need? For example the easy level is like Calculus of Gilbert Strang and 18.01 Calculus from MIT Open Course Ware. The hard level is Apostol's or Spivak's Calculus. Do I need easy level of maths or hard level to be good at artificial intelligence and its areas (machine learning, pattern recognition).</p>\n", 'ViewCount': '41', 'ClosedDate': '2014-03-24T10:42:23.590', 'Title': 'What level of maths do I need for artificial intelligence?', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-03-24T10:38:00.990', 'LastEditDate': '2014-03-24T10:38:00.990', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16051', 'Tags': '<machine-learning><artificial-intelligence><pattern-recognition><mathematical-foundations>', 'CreationDate': '2014-03-24T05:50:54.990', 'Id': '22988'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I know I can use a Bayes classifier to determine if something is one of N classes, but can I also determine if something is NOT in any of the predefined classes?  Or will a Bayes classifier only find the closest class?</p>\n', 'ViewCount': '31', 'Title': 'Can you use a Bayes classifier to determine if something is NOT in a defined class?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-29T20:47:42.620', 'LastEditDate': '2014-03-29T20:47:42.620', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23147', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16195', 'Tags': '<machine-learning><bayesian-statistics>', 'CreationDate': '2014-03-27T13:30:26.863', 'Id': '23125'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I've been researching on AdaBoost and GentleBoost classifiers, but can't seem to find a clear answer to the question:</p>\n\n<ul>\n<li>What is Adaboost better at classifying in computer vision?</li>\n<li>What is GentleBoost better at classifying?</li>\n</ul>\n\n<p>I've been told that AdaBoost is good for things with soft edges, like facial recognition, while GentleBoost is good for things with harder and more symmetrical features and edges, like vehicles. Is this true? Is there any proof for this or any evidence to back up this claim?</p>\n", 'ViewCount': '26', 'Title': 'Advantages of adaboost over gentleboost in applications, or vice versa?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-01T13:37:38.917', 'LastEditDate': '2014-04-01T13:37:38.917', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<algorithms><reference-request><machine-learning><classification><computer-vision>', 'CreationDate': '2014-04-01T10:34:09.543', 'FavoriteCount': '1', 'Id': '23316'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am doing a project in order to recognize an apple. (I am using Emgucv with Visual Studio 2010 C#, if that's relevant). My project is a classification (is or is not an apple). I have 2000 images of apples but I need images for the second class. </p>\n\n<p>I have read about classification using ANN but they have multiple classes but I need to recognize if image contain an apple or not. So what kind of images do I need for the second classes? I want to use background of apples like second class. Is that a good idea?</p>\n\n<p>I only want that ANN recognize if a image contain a pen or not so I have 2 classes(pen and non-pen) My question is What kind of image can I use to the second class? For example My first class are images of pen and second class are images of non pen (pencil, apples, grapes, tables); is that correct?</p>\n", 'ViewCount': '54', 'ClosedDate': '2014-04-29T23:35:57.197', 'Title': 'What are good counter-examples when training an apple classifier?', 'LastEditorUserId': '39', 'LastActivityDate': '2014-04-05T11:35:16.640', 'LastEditDate': '2014-04-05T11:35:16.640', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16399', 'Tags': '<machine-learning><neural-networks><data-sets>', 'CreationDate': '2014-04-02T23:33:24.867', 'Id': '23374'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm working on a problem where I have a matrix of values which I know will be in groups of similarly-valued elements.  I am trying to find these groups of similarly-valued elements.</p>\n\n<p>I'm going to define an error function for an element as distance from the mean value of its cluster. </p>\n\n<p>given k, I want to find the clustering that maximizes the number of elements below an error threshold.  If this isn't possible, I'd like to at least cluster the elements in any way I could and then examine this error.</p>\n\n<p>I've been examining the standard clustering algorithms (k-means, EM) and I can't seem to map this problem to the problems formulated in these algorithms.</p>\n\n<p>Any ideas?</p>\n", 'ViewCount': '20', 'Title': 'Clustering a matrix into similar groups', 'LastActivityDate': '2014-04-06T07:59:13.663', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16460', 'Tags': '<machine-learning><cluster>', 'CreationDate': '2014-04-04T21:40:04.940', 'Id': '23436'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am doing an project about recognizing one kind of leaf. Well I am using Emgucv with visual stduio 2010 c#. I have read about using 3 differente features extraction but I do not know when I can use haar, lbp or hog. I want to use my program in a embedded system so the thing is what type of feature exctraction is better in emebedded system? and why?</p>\n', 'ViewCount': '44', 'Title': 'Haar cascade vs Lbp cascade vs Hog Cascade in object detection', 'LastEditorUserId': '16454', 'LastActivityDate': '2014-04-05T18:08:03.270', 'LastEditDate': '2014-04-05T18:08:03.270', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16454', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2014-04-05T17:49:03.517', 'Id': '23459'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m trying to understand the material in "A Dual Coordinate Descent Method for Large-scale Linear SVM" by Hsieh et. al. (<a href="http://ntu.csie.org/~cjlin/papers/cddual.pdf" rel="nofollow">link to paper</a>) There is an equation for the Dual form of an unconstrained optimisation problem,</p>\n\n<p>$$\nf(\\mathbf{\\alpha})=\\dfrac{1}{2}\\mathbf{\\alpha}^T\\bar{Q}\\alpha-e^T\\alpha\n$$</p>\n\n<p>I don\'t understand what the $\\mathbf{e}^T$ means, it\'s not explained in the surronding text, so I assume it\'s just some common notation. Later in the paper $\\mathbf{e}_i$ is defined as $\\mathbf{e}_i=[0,\\ldots,1,0,\\ldots,0]^T$, so maybe it\'s some sort of selector term? Not sure if this second mention is even related.</p>\n\n<p>Please may someone explain to be what the $\\mathbf{e}^T$ bit is doing in this formula? Thank you for your time.</p>\n', 'ViewCount': '93', 'Title': 'Unknown notation "$e^T$" in a machine learning paper', 'LastEditorUserId': '472', 'LastActivityDate': '2014-04-08T12:08:07.270', 'LastEditDate': '2014-04-08T12:08:07.270', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '23517', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '16012', 'Tags': '<terminology><machine-learning><optimization>', 'CreationDate': '2014-04-07T14:04:03.300', 'Id': '23515'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>i\'m a little bit lost ... can you help me ?</p>\n\n<p>So I have this table of date (each row give a point with its group)</p>\n\n<p><img src="http://i.stack.imgur.com/h3wef.png" alt="data table"></p>\n\n<p><img src="http://i.stack.imgur.com/RnEgL.jpg" alt="enter image description here"></p>\n\n<p>So i took a random weight let\'s say : [1, -2]\nH = 1 if n =&lt; 0\n    0 otherwise</p>\n\n<p>a= H([1,-2][6,3]) = H(0) = 1 but the target output is 0 ... so we have to update the weight:\nw -> w - p = [5 , -5] .\nNext : </p>\n\n<p>a= H([5,-5][3,3]= H(0)=1 the problem is : there the target output is 1 so we don\'t have to update the weight , but that\'s strange because the [5 -5] vector doesn\'t draw a linear separation between the 2 groups ...</p>\n\n<p>Thanks for your help ? :) </p>\n', 'ViewCount': '55', 'ClosedDate': '2014-04-14T17:40:03.533', 'Title': "Perceptron learning rule doesn't work", 'LastActivityDate': '2014-04-08T12:53:53.387', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16532', 'Tags': '<algorithms><machine-learning><neural-networks>', 'CreationDate': '2014-04-07T14:53:01.470', 'Id': '23518'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>My research is in the area of Document Image Analysis. To be specific, the topic of my thesis is to automatically recognize and index characters in a set of hand-drawn objects, e.g. given a volume of comics --> how to localize, recognize then index the characters in it (e.g. return "Lucky Luke" position in some random volume).</p>\n\n<p>First thing first, before I can work on the indexing part, I must have some reliable system to recognize the interested characters. After some months working on it, I find the recognition is extremely hard, because the drawings are some time very "abstract".</p>\n\n<p>For normal face recognition, there are a lot of researches on it, thus we have Haar-like features, biometrics features, etc. For normal photograph objects, we may use e.g. SIFT/SURF, or other strong features for the purpose of object recognition.</p>\n\n<p>But in cartoons or comics, we may extract so few or zero feature(s) following the traditional approaches. Human visual interpretation system is amazingly effective in recognize such abstract objects (e.g. only with 4 lines and 2 curves, we still recognize the familiar character).</p>\n\n<p>So I think the solution must be somewhere in the understanding how human can interpret such a set of line strokes as a meaningful object. Once we understand it we can try to "teach" the computer the same way.</p>\n\n<p>Thus are there some good approaches in the terms of recognition of abstract objects such as drawn comic objects? (I searched for some but they\'re not so relevant). Thanks.</p>\n', 'ViewCount': '81', 'Title': 'Method to recognize abstract objects such as hand-drawn objects?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T05:03:02.323', 'LastEditDate': '2014-04-10T22:29:54.210', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'OwnerDisplayName': 'Jim Raynor', 'PostTypeId': '1', 'OwnerUserId': '16662', 'Tags': '<machine-learning><image-processing><pattern-recognition>', 'CreationDate': '2014-04-09T21:53:22.637', 'Id': '23657'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am curious as to what steps one would reasonably need to take to perform an extraction-based text summarizer.</p>\n\n<p>I\'ve taken a look at some papers I\'ve found on Google such as <a href="https://wwws.cs.umn.edu/tech_reports_upload/tr2000/00-034.ps" rel="nofollow">this one</a>, which explains that UPGMA is the best clustering algorithm (out of the tested set). I\'ve also found <a href="http://acl.ldc.upenn.edu/I/I05/I05-2004.pdf" rel="nofollow">this one</a> to be interesting, regarding single and multi-document summarization.</p>\n\n<p>I\'m unclear as to whether I\'d need to combine these techniques for summarization or whether it would suffice to use a tool like Gensim to model a corpus of documents and just extract the sentences with the highest vector values.</p>\n', 'ViewCount': '23', 'Title': 'Document clustering for summarization', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-11T06:35:58.613', 'LastEditDate': '2014-04-11T06:35:58.613', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '16190', 'Tags': '<machine-learning><data-mining><natural-lang-processing><cluster>', 'CreationDate': '2014-04-10T22:42:44.780', 'Id': '23661'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '102', 'Title': 'EM algorithm for two Gaussian models', 'LastEditDate': '2014-04-11T15:34:11.077', 'AnswerCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '16682', 'FavoriteCount': '1', 'Body': '<p>This is about basic machine learning which I do not understand clearly.</p>\n\n<p>I have 2 Gaussian models $G_1$ and $G_2$ and given a list of data as below.</p>\n\n<p>(1, 3, 4, 5, 7, 8, 9, 13, 14, 15, 16, 18, 23)</p>\n\n<p>I do not know which numbers were generated by which $G_i$ model, but I want to do Expectation Maximization for clustering.</p>\n\n<p>So, what are the hidden variables? and how to perform Expectation and Maximization steps?</p>\n\n<p>Could you show some calculation or short Python code of the likelihood metric? (Perhaps 2 iteration)</p>\n\n<p>I got the basics of EM algorithm from here, but I cannot apply to this question. <a href="http://www.nature.com/nbt/journal/v26/n8/full/nbt1406.html" rel="nofollow">http://www.nature.com/nbt/journal/v26/n8/full/nbt1406.html</a></p>\n', 'Tags': '<algorithms><machine-learning>', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-04-18T00:00:26.993', 'CommentCount': '0', 'AcceptedAnswerId': '23681', 'CreationDate': '2014-04-11T13:50:46.657', 'Id': '23673'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have heard of machine learning systems that can learn from trials of data what effect it should have, but I was wondering is it possible to make a learning appliance that builds on past data? Instead of only receiving new entries, once the database is big enough to begin going over it and doing pseudo consideration, drawing conclusions about the data and adding yet more entries to its database purely from looking at its past results? I suppose such a thing would probably eat up memory quickly unless it had a threshold of entries it was allowed to create. (In theory it would take a long time to get it to a state where it can become sentient in that way, through many trial sets before it begins thinking on its own.)</p>\n\n<p>An application of such a thing would go beyond just determining what the best way to optimize code is, or how to beat a player in a game, but a machine that can actually build its own personality.</p>\n', 'ViewCount': '55', 'Title': 'Can a self-learning appliance be developed?', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-22T08:58:56.877', 'LastEditDate': '2014-04-22T04:23:14.357', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16973', 'Tags': '<algorithms><machine-learning>', 'CreationDate': '2014-04-22T02:36:04.760', 'Id': '24016'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>To add onto the question, how are elliptical differential equations applicable in this context?</p>\n\n<p>I was listening to a talk about Bayesian networks and someone asked if they were using differential elliptical equations in the context of linear relaxation.</p>\n', 'ViewCount': '21', 'ClosedDate': '2014-04-26T12:17:39.360', 'Title': 'What is linear relaxation in the context of bayesian networks?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-23T06:00:46.480', 'LastEditDate': '2014-04-23T06:00:46.480', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17012', 'Tags': '<machine-learning><probability-theory><linear-programming>', 'CreationDate': '2014-04-23T03:43:13.713', 'Id': '24039'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Let $X$ be an $m\\times n$ ($m$: number of records, and $n$: number of attributes) dataset.  When the number of attributes $n$ is large and the dataset $X$ is noisy, classification gets more complicated and the classification accuracy decreases. One way to over come this problem is to use linear transformation, i.e., perform classification on $Y=XR$, where $R$ is an $n\\times p$ matrix, and $p\\leq n$. I was wondering how linear transformation simplifies classification? and why classification accuracy increases if we do classification on the transformed data $Y$ when $X$ is noisy?</p>\n', 'ViewCount': '57', 'Title': 'Why linear transformation can improve classification accuracy when the dimensionality of data is high?', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-28T22:51:22.710', 'LastEditDate': '2014-04-27T05:08:49.667', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '17110', 'Tags': '<machine-learning><data-mining><linear-algebra><matrices><classification>', 'CreationDate': '2014-04-27T01:46:05.837', 'FavoriteCount': '1', 'Id': '24147'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In Sutton and Barto\'s reinforcement learning book, in multi-armed bandit problem a phrase has been used. "finding an optimal action" using greedy/$\\epsilon$-greedy algorithm. When it is said that an algorithm "finds the optimal action " ? </p>\n', 'ViewCount': '25', 'Title': 'What does "finding an optimal action" for a bandit mean?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-05-01T05:10:18.083', 'LastEditDate': '2014-05-01T02:44:31.973', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '13091', 'Tags': '<algorithms><terminology><machine-learning><optimization><artificial-intelligence>', 'CreationDate': '2014-05-01T01:17:32.423', 'Id': '24282'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>In Sutton and Barto's reinforcement learning book, in multi-armed bandit problem, consider to algorithms : </p>\n\n<p>1) greedy \n2) $\\epsilon$-greedy</p>\n\n<p>now, consider two cases: </p>\n\n<p>1) reward for each action has variance 1\n2) reward for each action has variance 10</p>\n\n<p>$\\epsilon$ greedy will perform better in each of the cases over greedy. I want to know for which case the performance is better (is it with less variance or with more variance).</p>\n", 'ViewCount': '11', 'ClosedDate': '2014-05-03T02:02:13.477', 'Title': 'Comparison of greedy/$\\epsilon$ greedy for multi-armed bandit problem', 'LastActivityDate': '2014-05-01T05:07:54.510', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '13091', 'Tags': '<machine-learning><artificial-intelligence>', 'CreationDate': '2014-05-01T05:07:54.510', 'Id': '24285'}