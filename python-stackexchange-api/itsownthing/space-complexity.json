1670:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have the following algorithmic problem:</p>\n\n<blockquote>\n  <p>Determine the space Turing complexity of recognizing DNA strings that are Watson-Crick palindromes. </p>\n</blockquote>\n\n<p>Watson-Crick palindromes are strings whose reversed complement is the original string. The <em>complement</em> is defined letter-wise, inspired by DNA: A is the complement of T and C is the complement of G. A simple example for a WC-palindrome is ACGT.</p>\n\n<p>I've come up with two ways of solving this.</p>\n\n<p><strong>One requires $\\mathcal{O}(n)$ space.</strong></p>\n\n<ul>\n<li>Once the machine is done reading the input. The input tape must be copied to the work tape in reverse order. </li>\n<li>The machine will then read the input and work tapes from the left and compare each entry to verify the cell in the work tape is the compliment of the cell in the input. This requires $\\mathcal{O}(n)$ space. </li>\n</ul>\n\n<p><strong>The other requires $\\mathcal{O}(\\log n)$ space.</strong></p>\n\n<ul>\n<li>While reading the input. Count the number of entries on the input tape.</li>\n<li>When the input tape is done reading\n<ul>\n<li>copy the complement of the letter onto the work tape</li>\n<li>copy the letter L to the end of the work tape</li>\n</ul></li>\n<li>(Loop point)If the counter = 0, clear the worktape and write yes, then halt</li>\n<li>If the input tape reads L\n<ul>\n<li>Move the input head to the left by the number of times indicated by the counter  (requires a second counter)</li>\n</ul></li>\n<li>If the input tape reads R \n<ul>\n<li>Move the input head to the right by the number of times indicated by the counter (requires a second counter)</li>\n</ul></li>\n<li>If the cell that holds the value on the worktape matches the current cell on the input tape\n<ul>\n<li>decrement the counter by two</li>\n<li>Move one to the left or right depending if R or L is on the worktape respectively</li>\n<li>copy the Complement of L or R to the worktape in place of the current L or R</li>\n<li>continue the loop</li>\n</ul></li>\n<li>If values dont match, clear the worktape and write no, then halt</li>\n</ul>\n\n<p>This comes out to about $2\\log n+2$ space for storing both counters, the current complement, and the value L or R.</p>\n\n<p><strong>My issue</strong></p>\n\n<p>The first one requires both linear time and space. The second one requires $\\frac{n^2}{2}$ time and $\\log n$ space. I was given the problem from the quote and came up with these two approaches, but I don't know which one to go with. I just need to give the space complexity of the problem. </p>\n\n<p><strong>The reason I'm confused</strong></p>\n\n<p>I would tend to say the second one is the best option since it's better in terms of time, but that answer only comes from me getting lucky and coming up with an algorithm. It seems like if I want to give the space complexity of something, it wouldn't require luck in coming up with the right algorithm. Am I missing something? Should I even be coming up with a solution to the problem to answer the space complexity?</p>\n", 'ViewCount': '406', 'Title': 'The space complexity of recognising Watson-Crick palindromes', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-28T07:35:10.873', 'LastEditDate': '2012-04-11T20:15:46.800', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '1224', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '596', 'Tags': '<algorithms><algorithm-analysis><turing-machines><space-complexity>', 'CreationDate': '2012-04-11T15:21:09.507', 'Id': '1223'},1671:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>We know that $st\\text{-}non\\text{-}connectivity$ is in <a href="http://en.wikipedia.org/wiki/NL_%28complexity%29" rel="nofollow">$\\mathsf{NL}$</a> by <a href="https://en.wikipedia.org/wiki/Immerman%E2%80%93Szelepcs%C3%A9nyi_theorem" rel="nofollow">Immerman\u2013Szelepcs\xe9nyi theorem</a> theorem and since $st\\text{-}connectivity$ is $\\mathsf{NL\\text{-}hard}$ therefore $st\\text{-}non\\text{-}connectivity$ is many-one log-space reducible to $st\\text{-}connectivity$. But is there a direct/combinatorial reduction that doesn\'t go through the configuration graph of the Turing machines in $\\mathsf{NL}$?</p>\n\n<blockquote>\n  <p><a href="http://en.wikipedia.org/wiki/St-connectivity" rel="nofollow">$\\mathsf{stConnectivity}$</a> (a.k.a. $stPATH$):</p>\n  \n  <p>Given directed graph $G$ and vertices $s$ and $t$,</p>\n  \n  <p>Is there a directed path from vertex $s$ to vertex $t$? </p>\n</blockquote>\n\n<hr>\n\n<h3>Clarifications:</h3>\n\n<p>You can assume a graph is given by its adjacency matrix (however this is not essential since standard representations of graphs are log-space convertible to each other.)</p>\n\n<p>It is possible to unpack the proof of $\\mathsf{NL\\text{-}hard}$ness of $st\\text{-}connectivity$ and move it into the proof so the proof does not use it that theorem as a lemma. However this is still the same construction essentially. What I am looking for is <em>not</em> this, I want a conceptually direct reduction. Let me give an analogy with the $\\mathsf{NP}$ case. We can reduce various $\\mathsf{NP\\text{-}complete}$ problems to each other by using the fact that they are in $\\mathsf{NP}$ therefore reduce to $SAT$ and $SAT$ reduces to the other problem. And we can unpack and combine these two reductions to get a direct reduction. However it is often possible to give a conceptually much simpler reduction that doesn\'t go through this intermediate step (you can remove mentioning it, but it is still there conceptually). For example, to reduce $HamPath$ or $VertexCover$ or $3\\text{-}Coloring$ to $SAT$ we don\'t say $HamPath$ is in $\\mathsf{NP}$ and therefore reduces to $SA$ since $SAT$ is $\\mathsf{NP\\text{-}hard}$. We can give a simple intuitive formula that is satisfiable iff the graph has a Hamiltonian path. \nAnother example, we have reductions from other problems in $\\mathsf{NL}$ to $st\\text{-}Connectivity$ which do not rely on $\\mathsf{NL\\text{-}complete}$ness of $st\\text{-}Connectivity$, e.g. $Cycle$, $StronglyConnected$, etc, they involve modification on the input graph (and do not refer to any Turing machines that is solving them). </p>\n\n<p>I still don\'t see any reason why this cannot be done for this one.\nI am looking for a reduction of this kind.</p>\n\n<p>It might be the case that this is not possible and any reduction would conceptually go through the $\\mathsf{NL\\text{-}hard}$ness result. However I don\'t see why that should be the case, why the situation would be different from the $\\mathsf{NP}$ case.\nObviously to give a negative answer to my question we would need to be more formal about when does a proof <em>conceptually</em> include another proof (which is proof theory question that AFAIK not settle in a satisfactory way). However note that for a positive answer one does not need such a formal definition and I am hoping that is the case. (I will think about how to formalize what I am asking in a faithful way when I find more free time. Essentially I want a reduction that would work even if we didn\'t know that the problem is complete for $\\mathsf{NL}$.)</p>\n\n<p>Using the proof of Immerman\u2013Szelepcs\xe9nyi theorem is fine, using $\\mathsf{NL\\text{-}complete}$ness of $stPATH$ and configuration graph of an $\\mathsf{NL}$ machine is what I want to avoid.</p>\n', 'ViewCount': '257', 'Title': 'Direct reduction from $st\\text{-}non\\text{-}connectivity$ to $st\\text{-}connectivity$', 'LastEditorUserId': '41', 'LastActivityDate': '2012-10-11T06:25:20.147', 'LastEditDate': '2012-10-09T18:13:36.133', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<complexity-theory><reductions><space-complexity>', 'CreationDate': '2012-04-25T20:28:48.090', 'FavoriteCount': '1', 'Id': '1509'},1672:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>What is the expected space used by the skip list after inserting $n$ elements?</p>\n\n<p>I expect that in the worst case the space consumption may grow inde\ufb01nitely.</p>\n\n<p><a href="http://en.wikipedia.org/wiki/Skip_list" rel="nofollow">Wikipedia</a> says space $O(n)$.</p>\n\n<p>How can this be proven one way or another?</p>\n', 'ViewCount': '146', 'Title': 'Expected space consumption of skip lists', 'LastEditorUserId': '472', 'LastActivityDate': '2012-05-07T20:55:22.670', 'LastEditDate': '2012-05-07T08:47:42.743', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1402', 'Tags': '<data-structures><space-complexity>', 'CreationDate': '2012-05-07T08:45:05.963', 'FavoriteCount': '1', 'Id': '1713'},1673:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>We know that the $polyL$-hierarchy doesn't have complete problems, as it would conflict with the space hierarchy theorem. But: Are there complete problems for each level of this hierarchy?</p>\n\n<p>To be precise: Does the class $DSPACE(\\log(n)^k)$ have complete problems under $L$-reductions for each $k &gt; 0$?</p>\n", 'ViewCount': '162', 'Title': 'Complete Problems for $DSPACE(\\log(n)^k)$', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-27T12:41:04.607', 'LastEditDate': '2012-05-26T12:54:24.433', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '2106', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '641', 'Tags': '<complexity-theory><reductions><space-complexity>', 'CreationDate': '2012-05-26T09:28:27.063', 'Id': '2088'},1674:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have the following question from <a href="http://www.cs.princeton.edu/theory/complexity/" rel="nofollow">Computational Complexity - A modern Approach</a> by Sanjeev Arora and Boaz Barak:</p>\n\n<blockquote>\n  <p><em>[Q 4.1]</em><br>\n  Prove the existence of a universal TM for space bounded computation (analogously to the deterministic universal TM of Theorem 1.9). </p>\n</blockquote>\n\n<p>That is, prove that there exists a Turing Machine $SU$ such that for every string $\\alpha$ and input $x$, if the TM $M_\\alpha$ -- the TM represented by $\\alpha$ -- halts on $x$ before using $t$ cells of its work tape, then $SU(\\alpha, t, x) = M_\\alpha(x)$ and moreover, $SU$ uses at most $C\\cdot t$ cells of its work tape, where $C$ is a constant depending only on $M_\\alpha$.</p>\n\n<p>After checking theorem 1.9 and the universal TM with time bound, I see that the construct $SU(\\alpha, t, x)$ means that the Turing machine SU stops after $t$ steps. However if this is the case, then it means that we can create a Turing Machine equivalent to $M_\\alpha$ such that the new Turing Machine stops in $t$ steps where $t$ is the "space" used in the original.</p>\n\n<p>However, this seems a dubious interchange of space and time. If on the other hand, $t$ actually meant that the second machine stops within $t$ space, too, then the second part does not make sense any more because it says $SU$ uses $Ct$ cells, which is not $t$.</p>\n\n<p>So my question is how do I interpret this? Is the first interpretation really possible?</p>\n', 'ViewCount': '324', 'Title': 'Space bounded Turing Machine - clarification on Computational Complexity (book: Arora-Barak ) question 4.1', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-27T18:37:19.410', 'LastEditDate': '2012-05-27T18:23:04.883', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '2113', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1209', 'Tags': '<complexity-theory><terminology><turing-machines><space-complexity>', 'CreationDate': '2012-05-27T17:36:53.217', 'Id': '2110'},1675:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm looking for some standard terminology, metrics and/or applications of the consideration of density and sequentiality of algorithms.</p>\n\n<p>When we measure algorithms we tend to give the big-Oh notation such as $O(n)$ and usually we are measuring time complexity. Somewhat less frequently, though still often, we'll also measure the space complexity of an algorithm.</p>\n\n<p>Given current computing systems however the density of memory and the sequence in which it is accessed plays a major role in the practical performance of the algorithm. Indeed there are scenarios where a time complexity algortihm of $O(\\log n)$ with disperse random memory access can be slower than a $O(n)$ algorithm with dense sequential memory access. I've not seen these aspects covered in formal theory before; surely it must exist and I'm just ignorant here.</p>\n\n<p>What are the standard metrics, terms, and approaches to this space density and access sequentiality?</p>\n", 'ViewCount': '82', 'Title': 'Complexity of space density and sequentiality', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-10T11:44:37.957', 'LastEditDate': '2012-06-10T11:33:14.040', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '2318', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1642', 'Tags': '<complexity-theory><reference-request><terminology><space-complexity>', 'CreationDate': '2012-06-10T09:29:46.877', 'Id': '2317'},1676:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Here is a well-known problem.</p>\n\n<p>Given an array $A[1\\dots n]$ of positive integers, output the smallest positive integer not in the array.</p>\n\n<p>The problem can be solved in $O(n)$ space and time: read the array, keep track in $O(n)$ space whether $1,2,\\dots,n+1$ occured, scan for smallest element.</p>\n\n<p>I noticed you can trade space for time. If you have $O(\\frac{n}{k})$ memory only, you can do it in $k$ rounds and get time $O(k n)$. In a special case, there is obviously constant-space quadratic-time algorithm.</p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Is this the optimal tradeoff, i.e. does $\\operatorname{time} \\cdot \\operatorname{space} = \\Omega(n^2)$?\n  In general, how does one prove such type of bounds?</p>\n</blockquote>\n\n<p>Assume RAM model, with bounded arithmetic and random access to arrays in O(1).</p>\n\n<p>Inspiration for this problem: time-space tradeoff for palindromes in one-tape model (see for example, <a href="http://www.cs.uiuc.edu/class/fa05/cs475/Lectures/new/lec24.pdf" rel="nofollow">here</a>).</p>\n', 'ViewCount': '291', 'Title': 'Time-space tradeoff for missing element problem', 'LastEditorUserId': '72', 'LastActivityDate': '2012-06-29T22:18:45.900', 'LastEditDate': '2012-06-29T22:18:45.900', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '667', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-06-23T15:32:31.797', 'FavoriteCount': '1', 'Id': '2464'},1677:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'ve been studying the <a href="http://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" rel="nofollow">Spearman\'s rank correlation coefficient</a></p>\n\n<p>$\\qquad \\displaystyle \\rho = \\frac{\\sum_i(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_i (x_i-\\bar{x})^2 \\sum_i(y_i-\\bar{y})^2}}$.</p>\n\n<p>for two lists $x_1, \\dots, x_n$ and $y_1, \\dots, y_n$. What\'s the <em>complexity</em> of the algorithm?</p>\n\n<p>Since the algorithm should just compute $n$ subtractions, is it possible to be $O(n)$ ?</p>\n', 'ViewCount': '204', 'Title': "What's the complexity of Spearman's rank correlation coefficient computation?", 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-05T14:00:32.050', 'LastEditDate': '2012-07-04T10:24:10.760', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2064', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-07-04T07:45:52.857', 'Id': '2604'},1678:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '175', 'Title': 'Bound on space for selection algorithm?', 'LastEditDate': '2012-07-24T08:41:54.167', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '67', 'FavoriteCount': '2', 'Body': '<p>There is a well known worst case $O(n)$ <a href="http://en.wikipedia.org/wiki/Selection_algorithm" rel="nofollow">selection algorithm</a> to find the $k$\'th largest element in an array of integers.  It uses a <a href="http://en.wikipedia.org/wiki/Selection_algorithm#Properties_of_pivot" rel="nofollow">median-of-medians</a> approach to find a good enough pivot, partitions the input array in place and then recursively continues in it\'s search for the $k$\'th largest element.</p>\n\n<p>What if we weren\'t allowed to touch the input array, how much extra space would be needed in order to find the $k$\'th largest element in $O(n)$ time?  Could we find the $k$\'th largest element in $O(1)$ extra space and still keep the runtime $O(n)$?  For example, finding the maximum or minimum element takes $O(n)$ time and $O(1)$ space.  </p>\n\n<p>Intuitively, I cannot imagine that we could do better than $O(n)$ space but is there a proof of this?</p>\n\n<p>Can someone point to a reference or come up with an argument why the $\\lfloor n/2 \\rfloor$\'th element would require $O(n)$ space to be found in $O(n)$ time?</p>\n', 'Tags': '<algorithms><algorithm-analysis><space-complexity><lower-bounds>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-26T18:36:48.300', 'CommentCount': '1', 'AcceptedAnswerId': '2896', 'CreationDate': '2012-07-24T03:19:59.790', 'Id': '2893'},1679:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The problem, coming from an interview question, is:</p>\n\n<blockquote>\n  <p>You have a stream of incoming numbers in range 0 to 60000 and you have\n  a function which will take a number from that range and return the\n  count of occurrence of that number till that moment. Give a suitable\n  Data structure/algorithm to implement this system.</p>\n</blockquote>\n\n<p>The stream is infinite, so if fixed size data structures re used, i.e. primitive types in Java or C, they will overflow. So there is the need to use data structures that have a size that grows over time. As pointed by the interviewer, the memory occupied by those data structures will diverge.</p>\n\n<p>The model of computation is a Turing machine with three tapes:</p>\n\n<ul>\n<li>infinite read-only one-way input tape;</li>\n<li>constant space bounded read-write two way work tape;</li>\n<li>infinite write-only one-way output tape.</li>\n</ul>\n\n<p>The main reason to choose the model above is that in the real world there is virtually no limit to the quantity of input that can be acquired using a keyboard or a network connection. Also, there is virtually no limit to the quantity of information that can be displayed on amonitor over time. But memory is limited and expensive.</p>\n\n<p>I modeled the problem as the problem to recognize the language L of all couples (number,number of occurrences so far).</p>\n\n<p>As a corollary of the Theorem 3.13 in Hopcroft-Ullman I know that every language recognized by a constant space bounded machine is regular.</p>\n\n<p>But, in any given moment, the language L is a finite language, because the number of couples to be recognized is finite: 60001. So I can\'t use the pumping lemma for regular languages to prove that such language is not regular.</p>\n\n<p>Is there a way I can complete my proof?</p>\n\n<p>The original question is <a href="http://stackoverflow.com/questions/11708957/find-the-count-of-a-particular-number-in-an-infinite-stream-of-numbers-at-a-part">here</a>.</p>\n', 'ViewCount': '198', 'Title': 'Counting with constant space bounded TMs', 'LastEditorUserId': '851', 'LastActivityDate': '2012-07-30T11:41:01.430', 'LastEditDate': '2012-07-30T11:41:01.430', 'AnswerCount': '2', 'CommentCount': '9', 'AcceptedAnswerId': '2951', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '851', 'Tags': '<regular-languages><turing-machines><finite-automata><space-complexity><streaming-algorithm>', 'CreationDate': '2012-07-29T16:44:46.170', 'Id': '2948'},16710:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '494', 'Title': 'Minimum space needed to sort a stream of integers', 'LastEditDate': '2012-10-22T19:53:01.833', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4315', 'FavoriteCount': '1', 'Body': '<p>This question has gotten a lot of attention on SO:<br>\n<a href="http://stackoverflow.com/questions/12748246/sorting-1-million-8-digit-numbers-in-1mb-of-ram">Sorting 1 million 8-digit numbers in 1MB of RAM</a></p>\n\n<p>The problem is to sort a stream of 1 million 8-digit numbers (integers in the range $[0,\\: 99\\mathord{,}999\\mathord{,}999]$) using only 1 MB of memory ($2^{20}$ bytes = $2^{23}$ bits) and no external storage. The program must read values from an input stream and write the sorted result to an output stream.</p>\n\n<p>Obviously the entire input can\'t fit into memory, but clearly the result can be represented in under 1 MB since $2^{23} \\geq \\log_2 \\binom{10^8}{10^6} \\approx 8079302$ (it\'s a tight fit).</p>\n\n<p>So, what is the minimum amount of space needed to sort n integers with duplicates in this streaming manner, and is there an algorithm to accomplish the specified task?</p>\n', 'Tags': '<algorithms><sorting><space-complexity><data-compression><streaming-algorithm>', 'LastEditorUserId': '4315', 'LastActivityDate': '2012-10-23T10:13:54.180', 'CommentCount': '5', 'AcceptedAnswerId': '6246', 'CreationDate': '2012-10-22T18:13:46.890', 'Id': '6236'},16711:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I've got two log-space programs $F$ and $G$.</p>\n\n<ul>\n<li>Program $F$ will get input in array $A[1..n]$ and will create the output array $B[1..n]$.</li>\n<li>Program $G$ will get as input $B$ as created by $F$ and create from it the output array $C[1..n]$.</li>\n</ul>\n\n<p>I have to write a proof that there exist a log-space program $H$, which will get input Array $A$ and create from it corresponding array $C$. But I can't find the correct way to write it. How is this done?</p>\n\n<hr>\n\n<p>A log-space program is a program which uses $O(\\log n)$ bits of memory. Here are some conditions you have to keep:</p>\n\n<ol>\n<li><p>You have to use only variables which have simple integer type (for example <code>int</code> in C++, <code>longint</code> in Pascal).</p></li>\n<li><p>Allowed range of integer is defined: if $n$ is the size of the input we can save into variables only values which are polymonial sized based on $n$.</p>\n\n<p>For example: we can have variables which can takes on values in $[-n...n]$, $[-3n^5...3n^5]$ or also values $[-4...7]$, but we can't have variables which will take on values in $[ 0...2^n]$.\nNo other types of variables are allowed, neither are arrays and iterators.</p></li>\n<li><p>Exceptions from the rules about are input and output. Input will be available in special variables (mostly arrays) which your program can only read from, and the output can only be written to other special variables. So you can't read from output, and you can't increase values of input variables etc.</p></li>\n<li><p>Your programs can't use recursion.</p></li>\n</ol>\n\n<p>Example of log-space program written in Pascal (so everyone can understand it) which will find the largest number in the array of integer</p>\n\n<pre><code>    var n: integer;  //input variable the number of elements in A\n    A: array [1..n] of integer; //input variable - the array of integers\n    m: integer;      // output variable, the position of maximum\n    i, j: integer;   //working variables\n    begin\n      j := 1;\n      for i := 2 to n do\n        if A[i] &gt; A[j] then j := i;\n      m := j;\n    end;\n</code></pre>\n\n<p>The only two variables here are <code>j</code> and <code>i</code> and they evidently take values in $[1...n]$. Therefore all conditions are fulfilled and it really is a log-space program.</p>\n", 'ViewCount': '121', 'Title': 'Simulate the concatenation of two log-space programs in log-space', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-21T06:29:00.577', 'LastEditDate': '2012-11-09T07:49:44.290', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'OwnerDisplayName': 'user12392', 'PostTypeId': '1', 'Tags': '<algorithms><complexity-theory><simulation><space-complexity>', 'CreationDate': '2012-11-06T21:30:33.060', 'Id': '6571'},16712:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am following <strong>"Introduction to the theory of computation" by Sipser</strong>.</p>\n\n<p>My question is about relationship of different classes which is present in <strong>Chapter 8.2. The Class PSPACE</strong>.</p>\n\n<p>$P \\subseteq NP \\subseteq PSPACE = NPSPACE \\subseteq EXPTIME$</p>\n\n<p>I am trying to understand why the the following part is true $NPSPACE \\subseteq EXPTIME$.</p>\n\n<p>The explanation from the textbook is following: </p>\n\n<p><em>"For $f(x)\\geq n$, a TM that  uses $f(x)$ space can have at most $f(n)2^{O(f(n))}$ different configurations, by a simple generalization of the proof of the Lemma 5.8 on page 194. A TM computation that halts may not repeat a configuration. Therefore a TM that uses space $f(n)$ must run in time $f(n)2^{O(f(n))}$, so $NPSPACE \\subseteq EXPTIME$"</em></p>\n\n<p>I am trying to understand why it\'s true, why TM that uses $f(n)$ space must run in time $f(n)2^{O(f(n))}$. Let\'s try to reverseengeneer the formula: $n$ is the length of the input, 2 is the size of alphabet, $f(n)$ is the space that TM use on the second tape (operational tape) and $f(n) \\geq n$, but how to explain what $O(f(n))$ means. Apparently, $2^{O(f(n))}$ expreses a configuration, so $O(f(n))$ must express union of transition function and alphabet, but actually it seems like I get it wrong. The most intriguing question why, in the end,  $f(n)2^{O(f(n))}$ expressed in the terms of time, the transition from space to time is very vague for me.</p>\n\n<p>I will very appreciate if someone could explain me this relationship.</p>\n', 'ViewCount': '153', 'Title': 'Proving that NPSPACE $\\subseteq$ EXPTIME', 'LastActivityDate': '2012-11-13T19:29:32.513', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6651', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1170', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-11-13T18:43:57.293', 'Id': '6649'},16713:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I would like to ask you some clarification on the following question:\nknow that ${\\sf NP}$ is a subset of ${\\sf IP}$ \nand also ${\\sf coNP}$ it is a subset of ${\\sf IP}$.\nSo ${\\sf IP}$ is a biggest class, but how much it is big?</p>\n\n<p>May i say that ${\\sf PSPACE}$ is a subset of ${\\sf IP}$? or that they may intersect?</p>\n\n<p>Can you give me a easy clarification about it?</p>\n', 'ViewCount': '160', 'Title': 'Relation between interactive proof systems (IP), NP, coNP, PSPACE', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-16T21:07:21.567', 'LastEditDate': '2012-11-16T21:07:21.567', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4488', 'Tags': '<complexity-theory><time-complexity><space-complexity><complexity-classes><interactive-proof-systems>', 'CreationDate': '2012-11-15T13:47:04.607', 'Id': '6679'},16714:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '151', 'Title': 'Showing that Independent set of size $k$ can be decided using logarithmic space', 'LastEditDate': '2012-11-27T08:05:39.133', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2329', 'FavoriteCount': '1', 'Body': "<p>An independent set $I$ is a subset of the nodes of a graph $G$ where: no 2 nodes in $I$ are adjacent in $G$. For natural number $k$, the problem $k-\\text{IND}$ asks if there is an independent set of size $k$.</p>\n\n<p>I'd really love your help with showing that $k-\\text{IND} \\in {\\sf L}$, i.e., can be decided using deterministic logarithmic space.</p>\n", 'Tags': '<complexity-theory><graphs><space-complexity>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-27T18:19:38.020', 'CommentCount': '3', 'AcceptedAnswerId': '6946', 'CreationDate': '2012-11-26T21:58:10.790', 'Id': '6933'},16715:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I don't know exactly how to solve the exercise below.</p>\n\n<blockquote>\n  <p>Show that the multiplication lies in $\\text{FL}$.</p>\n  \n  <p>Hint: A useful approach to a solution is to split the exercise into two parts and to explain that each function lies in $\\text{FL}$. The standard multiplication scheme can be used as an intermediate step. Example:</p>\n  \n  <p>$\\begin{align}\n1001 \\cdot{} 1100 &amp; = \\\\\n 1001000\\\\\n + \\ \\ \\ 100100\\\\\n + \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\\\\n + \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\\\\n\\end{align}$</p>\n  \n  <p>Other useful approaches are certainly also accepted.</p>\n</blockquote>\n\n<p>Useful definitions from our lecture notes:</p>\n\n<hr>\n\n<p>Let $f : \\Sigma^* \\to \\Sigma^*$ be a function, let $t : \\mathbb N \\to \\mathbb N$ be a time bound and let $s : \\mathbb N \\to \\mathbb N$ be a memory space bound.</p>\n\n<p>$\\bullet$ It is $f \\in \\text{FDTIME}(t),$ if there exists a DTM $M$ with an output tape, calculating $f$ and for which $T_M \\in O(t)$ holds.</p>\n\n<p>$\\bullet$ It is $A \\in \\text{FDSPACE}(s),$ if there exists an offline DTM $M$, calculating $f$ and for which $S_M \\in O(s)$ holds. The fields being written on the output band are not considered for the amount of memory space.</p>\n\n<p>$\\text{FP}=\\bigcup_{k \\in \\mathbb N} \\text{FDTIME}(n^k), \\text{FL}=\\text{FDSPACE}(\\log n)$</p>\n\n<hr>\n\n<p>I think the hint wants me to find two functions (one for the multiplication and one for the addition), but I don't see how to find two functions that do the calculation of the example in the appropriate way. Can somebody help me, please?</p>\n", 'ViewCount': '175', 'Title': 'Show that the multiplication lies in FL', 'LastActivityDate': '2013-03-02T08:46:26.067', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-11-29T17:57:19.647', 'Id': '7022'},16716:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The following exercise is difficult for me:</p>\n\n<blockquote>\n  <p>Show that for each $k \\in \\mathbb{N}$ the question of existence of a $k$-clique within a graph lies in $\\text{L}$.</p>\n  \n  <p>Hint: A $k$-clique denotes $k$ verteces within a graph that are all connected with each other.</p>\n  \n  <p>Annotation: if the question also considers $k$ as parameter, then the problem is $\\text{NP}$-complete.</p>\n</blockquote>\n\n<p>So $\\text{L}$ is "the complexity class containing decision problems which can be solved by a deterministic Turing machine using a logarithmic amount of memory space". Now I\'m wondering if this exercise isn\'t a catchy question, since I\'ve found <a href="http://www.cs.berkeley.edu/~virgi/combclique-ipl-g.pdf" rel="nofollow">this paper</a> and it says "We give an algorithm for $k$-clique that runs in (...) $O(n^{\\varepsilon})$ space, for all $\\varepsilon &gt; 0$, on graphs with $n$ nodes"?</p>\n\n<p>Furthermore, I also don\'t understand the annotation, because how should it be possible to not consider $k$ for the $k$-clique problem?</p>\n', 'ViewCount': '109', 'Title': 'Show that k-clique lies in L', 'LastActivityDate': '2012-11-30T11:43:05.207', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-11-30T10:19:40.617', 'Id': '7039'},16717:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In famous Structure and Interretation of Computer Programs, there is an exercise (<a href="http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-11.html#%_thm_1.14" rel="nofollow">1.14</a>), that asks for the time complexity of the following algorithm - in Scheme - for counting change (the problem statement suggests drawing the tree for <code>(cc 11 5)</code> - which looks <a href="http://telegraphics.com.au/~toby/sicp/ex1-14.svg" rel="nofollow">like this</a>):</p>\n\n<pre><code> ; count change\n (define (count-change amount)\n   (define (cc amount kinds-of-coins)\n     (cond ((= amount 0) 1)\n           ((or (&lt; amount 0) (= kinds-of-coins 0)) 0)\n           (else (+ (cc (- amount\n                           (first-denomination kinds-of-coins))\n                        kinds-of-coins)\n                    (cc amount\n                        (- kinds-of-coins 1))))))\n   (define (first-denomination kinds-of-coins)\n     (cond ((= kinds-of-coins 1) 1)\n           ((= kinds-of-coins 2) 5)\n           ((= kinds-of-coins 3) 10)\n           ((= kinds-of-coins 4) 25)\n           ((= kinds-of-coins 5) 50)))\n   (cc amount 5))\n</code></pre>\n\n<p>Now... there are sites with solutions to the SICP problems, but I couldn\'t find any easy to understand proof for the <em>time</em> complexity of the algorithm - there is a mention somewhere that it\'s polynomial <code>O(n^5)</code></p>\n', 'ViewCount': '120', 'Title': 'Time complexity for count-change procedure in SICP', 'LastActivityDate': '2012-12-02T18:19:47.847', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7106', 'Score': '0', 'OwnerDisplayName': 'NeuronQ', 'PostTypeId': '1', 'OwnerUserId': '4844', 'Tags': '<algorithms><time-complexity><space-complexity>', 'CreationDate': '2012-11-22T20:09:19.883', 'Id': '7105'},16718:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Suppose\n$$A = \\left\\{\\langle G, d, s, t\\rangle \\;\\Bigg|\\;\n\\begin{array}{l}\n  \\text{\\(G\\) undirected}, \\\\\n  \\text{\\(s\\) and \\(t\\) are nodes in \\(G\\)}, \\\\\n  \\text{there is a path of length \\(d\\) from \\(s\\) to \\(t\\) and no path of shorter length}\n\\end{array}\\right\\}$$\nI can easily see that this language is in NL, but I am having trouble proving that this is NL-complete.</p>\n', 'ViewCount': '236', 'Title': 'Prove the following problem is NL-complete', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-03T21:04:47.773', 'LastEditDate': '2012-12-03T21:04:47.773', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1718', 'Tags': '<complexity-theory><graphs><space-complexity>', 'CreationDate': '2012-12-03T01:40:51.520', 'Id': '7115'},16719:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Show that for $l(n) = \\log \\log n$, it holds that $\\text{DSPACE}(o(l)) = \\text{DSPACE}(O(1))$.</p>\n\n<p>It's well known fact in Space Complexity, but how to show it explicitly?</p>\n", 'ViewCount': '285', 'Title': 'Space complexity below $\\log\\log$', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-13T15:09:01.203', 'LastEditDate': '2012-12-13T15:09:01.203', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7378', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><regular-languages><space-complexity><lower-bounds>', 'CreationDate': '2012-12-13T10:57:13.230', 'Id': '7372'},16720:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm trying to decide which of the following statements are true:</p>\n\n<ol>\n<li><p>$\\mathsf{NSpace}(\\log \\log n) = \\mathsf{coNSpace}(\\log \\log n )$</p></li>\n<li><p>$\\mathsf{NSpace}(\\lg^2n) = \\mathsf{coNSpace}(\\lg^2n)$</p></li>\n<li><p>$\\mathsf{NSpace}(\\sqrt n) = \\mathsf{coNSpace}(\\sqrt n)$</p></li>\n</ol>\n\n<p>I thought immediately that (1) is correct since $\\lg \\lg n &lt; \\lg n$, and since $\\mathsf{NL} = \\mathsf{coNL}$, I thought that the statement yields from it. I thought that since we don't know if $\\mathsf{P} = \\mathsf{PSPACE}$, we can't say anything about a class which is bigger than $\\lg n$ and a subset of $P$.</p>\n\n<p>But it is exactly the opposite. (1) is not necessarily true while (2) and (3) are necessarily true. Why is that?</p>\n\n<p>The question is from a past midterm that I'm solving now.</p>\n", 'ViewCount': '124', 'Title': 'Equality of NSpace and coNSpace classes', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-14T09:30:50.753', 'LastEditDate': '2012-12-13T21:48:53.410', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7386', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-13T19:16:21.123', 'Id': '7385'},16721:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Let $M_U$ be an universal Turing machine which fulfills the following condition:</p>\n\n<blockquote>\n  <p>If $M$ running $x$ takes $f(x)$ space, then $M_U$ running on $\\langle \\langle M\\rangle,x\\rangle$ takes $(f(|x|))^3+2\\cdot|x|+|\\langle M\\rangle|$ space.</p>\n</blockquote>\n\n<p>Why can we conclude from the above that ${\\sf Space}(n^2) \\neq {\\sf Space}(n^7)$?</p>\n', 'ViewCount': '61', 'Title': 'Concluding $SPACE(n^2) \\neq SPACE(n^7)$ from universal turing machine running time', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-15T11:24:06.970', 'LastEditDate': '2012-12-15T11:24:06.970', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7407', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-15T09:49:28.640', 'Id': '7405'},16722:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I try to solve exercise "on the power of double - logarithmic space" from the great textbook <a href="http://books.google.com/books?id=EuguvA-w5OEC&amp;pg=PA176&amp;lpg=PA176&amp;redir_esc=y#v=onepage&amp;q&amp;f=false" rel="nofollow">Computational Complexity by Oded Goldreich. </a>\nThe goal is to show that the given set $S=\\left \\{ w_k \\mid k \\in \\mathbb{N} \\right \\}$, where $w_k$ - concatenation of all $k$-bit long strings separated by *\'s is not regular and yet it is decidable in double-logarithmic space. The exercise contains guidelines, and I would like to shed the light on few sentences from guidelines in order to solve the exercise.</p>\n\n<p>In the guidelines it\'s mentioned that </p>\n\n<blockquote>\n  <p>we can take advantage of of the *\'s (in $w_i$) , the $i$th iteration\n  can be implemented in space $O(\\log i)$</p>\n</blockquote>\n\n<p>The $i$th iteration is verifying whether $x = w_i$, which is really can be decided in $O(\\log i)$ space, where $\\log i$ can be used to note the position in $i$ long string, but the position in $x$ can be included in $O(\\log i)$ or not?</p>\n\n<blockquote>\n  <p>Furthermore, on input $x \\notin S$, we halt and reject after at most\n  $\\log |x|$ iterations.</p>\n</blockquote>\n\n<p>It means only $\\log |x|$ $w$\'s from the set S will be compared to $x$. Why it is actually so?</p>\n\n<blockquote>\n  <p>Actually, it is slightly simpler to handle the related set\n  $\\left \\{w_1**w_2**..**w_k \\right \\}$</p>\n</blockquote>\n\n<p>Why it is actually so, and I would call it set, it is rather concatenated string.</p>\n', 'ViewCount': '91', 'Title': 'Power of Double - Logarithmic Space', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-19T18:01:29.307', 'LastEditDate': '2012-12-19T17:33:42.143', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7515', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-19T17:21:23.247', 'Id': '7511'},16723:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>In [1] <em>strongly-polynomial</em> is defined as either:</p>\n\n<ul>\n<li>The algorithm runs in strongly polynomial time if the algorithm is a polynmomial space algorithm and performs a number of elementary arithmetic operations which is bounded by a polynomial in the number of input numbers.</li>\n<li>A polynomial algorithm is a polynomial space algorithm (in our standard Turing machine model) and polynomial time algorithm in the arithmetic model (see this question for a clarification).</li>\n</ul>\n\n<p>Why do they restrict to polynomial TM space as opposed to polynomial TM time? (this came up <a href="http://cs.stackexchange.com/a/7542/5106">here</a>)</p>\n\n<p>It seems strange for an algorithm that takes a number of TM steps unboundable by a polynomial to still be considered strongly-polynomial (provided it takes polynomial space and a number of arithmetic operations polynomial in the number of numbers in the input). Can it be shown that such an algorithm does not exist? Perhaps based on this argument: the number of arithmetic operations would not be polynomial, since under the arithmetic model every operation is an arithmetic operation (?).</p>\n\n<p>[1] Gr\xf6tschel, Martin; L\xe1szl\xf3 Lov\xe1sz, Alexander Schrijver (1988). "Complexity, Oracles, and Numerical Computation". Geometric Algorithms and Combinatorial Optimization. Springer. ISBN 0-387-13624-X.</p>\n', 'ViewCount': '203', 'Title': 'Are there strongly-polynomial algorithms that take more than polynomial time?', 'LastActivityDate': '2012-12-22T11:18:34.597', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '5106', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-12-22T02:53:58.370', 'Id': '7543'},16724:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I had an interview today, and the interviewer has told me about a theorem (of someone called Hill- or Hell-something) which states that for a non-deterministic algorithm there exists a deterministic algorithm of some time complexity and a space complexity of no more than the original space complexity times log(n).</p>\n\n<p>I am looking for that theorem (couldn't find it on Google). Thanks!</p>\n", 'ViewCount': '183', 'Title': 'Logarithmic space difference between deterministic and non-deterministic algorithms', 'LastActivityDate': '2012-12-23T08:37:29.267', 'AnswerCount': '0', 'CommentCount': '10', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5165', 'Tags': '<algorithms><space-complexity><nondeterminism>', 'CreationDate': '2012-12-23T08:37:29.267', 'Id': '7559'},16725:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Prove that the problem of determining if graph is bipartite is computationally equivalent under log-space reductions to $s$-$t$ undirected connectivity. </p>\n\n<p>Problem of $s$-$t$ undirected connectivity is the following given an undirected graph $G = (V, E)$ and two designated vertices, $s$ and $t$, determine whether there is a path from $s$ to $t$ in $G$.</p>\n\n<p>I assume the idea is to consider mapping from graph $G$ to bipartite graph $G'$, there should be a correspondence between edges of $G$ and edges of bipartite graph $G'$, and between edges of $G$ and the edges that violates the bipartite property of graph $G'$. The problem is I cannot come up with such correspondence.</p>\n\n<p>I would appreciate any idea. </p>\n", 'ViewCount': '88', 'Title': 'Bipartite Problem is Log-Space Reducible To $s$-$t$ Undirected Connectivity', 'LastActivityDate': '2012-12-23T20:54:55.873', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-23T19:35:07.883', 'FavoriteCount': '0', 'Id': '7568'},16726:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Consider the following problem:</p>\n\n<p>Let $k$ be a constant. We are given a $k$-ary array $A_{d_1\\times\\ldots\\times d_k}$ of $0$ and $1$\'s. Let $N = \\prod_{i=1}^k d_i$. </p>\n\n<p>We want to create a data structure by preprocessing $A$ to perform the following type of query operations:</p>\n\n<ol>\n<li>Given the coordinates of a $k$-ary box $D$, is there a $1$ in the box?  </li>\n<li>Given the coordinates of a $k$-ary box $D$, return the position of a $1$ in the box (if there is one). </li>\n</ol>\n\n<p>The operations must be performed in constant time $O(1)$. The time complexity is measured on a RAM machine. The preprocessing time and space for the data structure are not important for us. </p>\n\n<p>The question is how much space (in bit complexity) do we need to store a datastructure allowing the above operations?</p>\n\n<p>The trivial lower-bound is $N$ bits since the array can be reconstructed for these queries (so the data structure should have at least the same amount of information in it).</p>\n\n<p>The trivial upper-bound is to store the answer to all of the queries. That would need $\\prod_{i=1}^k {d_i \\choose 2} = \\Theta(N^2)$ bits. However we suspect that this can be done much more efficiently.</p>\n\n<p>For example, consider the special case where $k=1$. In this case we can use a <a href="http://link.springer.com/chapter/10.1007/978-3-540-74450-4_41" rel="nofollow">succinct RMQ data structure</a> to solve the first problem, and the data structure takes $2N+o(N)$ bits to store.</p>\n\n<blockquote>\n  <p>What is an efficient data-structure for this task?<br>\n  How low can the space complexity (the number of bits) go to support these operations (or just the first operation)?</p>\n</blockquote>\n\n<p><strong>Update (1/15):</strong>\nIn the special case $k=1$, using $N +o(N)$ bits is sufficient (actually better, $\\log {N\\choose t}+O(t)$, where $t$ is the number of $1$\'s in $A$) by reducing the problem to a predecessor problem and using the reduction from predecessor problem to fully indexable dictionary (FID). See "<a href="http://arxiv.org/abs/0902.2648" rel="nofollow">More Haste, Less Waste: Lowering the Redundancy in Fully Indexable Dictionaries</a>" by Grossi, Orlandi, Raman and Rao (2009).</p>\n\n<p><strong>Update (6/27):</strong>\nAgain by reduce the problem to RMQ. We use a $k$-dimensional RMQ by <a href="https://www.siam.org/proceedings//soda/2010/SODA10_014_yuanh.pdf" rel="nofollow">Yuan and Atallah</a> to get a $O(n\\log n)$ upper bound on the amount of space required when $k$ is fixed. </p>\n', 'ViewCount': '316', 'Title': 'Bit complexity of O(1) time range query in a $k$-ary array', 'LastEditorUserId': '220', 'LastActivityDate': '2013-06-27T23:36:27.377', 'LastEditDate': '2013-06-27T23:36:27.377', 'AnswerCount': '1', 'CommentCount': '9', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<reference-request><data-structures><space-complexity>', 'CreationDate': '2013-01-10T20:52:45.990', 'FavoriteCount': '3', 'Id': '7876'},16727:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The question is: What is the smallest complexity class in which the following problem is contained: Given a graph with $n$ nodes, Is there independent set of size of at least $n-10$? </p>\n\n<p>I have a little difficulty to understand the meaning of being in ${\\sf L}$ and examine problems in a correct way for deciding if they are in ${\\sf NL}$ or ${\\sf L}$ </p>\n\n<p>First I know that for being in ${\\sf NL}$ I need to provide a verifier for a Turing machine which uses only $O(\\log n)$ space on its working tape- So I wonder- I can give as a verifier this set of nodes to be independent set as requested, but how does the checking work? Can it go to all the lists of the pointers to the neighbors of each node , and for every node to check whether all the other nodes in the set given as independent set is not on that list- Is this considered of not using any space and I only need to count the nodes in the list that fulfill the requirement and therefore use only $O(\\log n)$ space? Is this correct? Is there a way to prove that the problem is in ${\\sf L}$?</p>\n', 'ViewCount': '94', 'Title': 'NL- definition and a problem', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-01-21T22:41:27.887', 'LastEditDate': '2013-01-21T20:28:19.350', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2126', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-01-21T18:27:59.220', 'Id': '9075'},16728:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>It's known that for $f(n) \\geq \\log n$,  $\\mathsf{NSPACE}(f(n)) = \\mathsf{coNSPACE}(f(n))$.</p>\n\n<p>What if $f(n)&lt;\\log n$? Are they also equal?</p>\n", 'ViewCount': '93', 'Title': 'Does $\\mathsf{NSPACE}( f (n)) = \\mathsf{coNSPACE}( f (n))$ hold for $ f(n) < \\log (n) $?', 'LastEditorUserId': '683', 'LastActivityDate': '2013-02-11T00:25:29.670', 'LastEditDate': '2013-02-10T22:58:08.963', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9629', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '4409', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-02-09T21:48:58.417', 'Id': '9625'},16729:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Let Undir-Reachability be the following problem:\ngiven an undirected graph G and two specified vertices s and t in G, is there a path from s to t in G?</p>\n\n<p>I need to prove that the 2-Colourability is in L, by knowing that Undir-Reachability belongs to the complexity class L.</p>\n\n<p>I don't know how to start.</p>\n", 'ViewCount': '55', 'Title': 'Prove that 2-Colourability is in L from Undir-Reachability is in L', 'LastActivityDate': '2013-02-21T23:20:30.173', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10024', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6978', 'Tags': '<complexity-theory><graph-theory><space-complexity><colorings>', 'CreationDate': '2013-02-21T18:32:59.790', 'Id': '10016'},16730:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I need to prove that the following problem $0$-$1$ $\\mathsf{ Ineq}$ is $\\mathsf{NL}$-complete.</p>\n\n<p>Given a finite set of variables $V$, a finite set of inequalities of the form $x \\le y$ (where $x, y \\in V$) and a finite set of equalities of the form $x=a$ (where $x \\in V$ and $a \\in \\{0,1\\}$), is there an assignment of values from $\\{0, 1\\}$ to the variables satisfying all the inequalities and all the equalities?</p>\n\n<p>How can I start to resolve the proof?</p>\n', 'ViewCount': '64', 'Title': 'Prove that $0$-$1$ $\\mathsf{ Ineq}$ is $\\mathsf{NL}$-complete', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-02-22T10:06:31.597', 'LastEditDate': '2013-02-22T10:06:31.597', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '10023', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6978', 'Tags': '<complexity-theory><graph-theory><reductions><space-complexity>', 'CreationDate': '2013-02-21T18:41:55.347', 'Id': '10017'},16731:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I need a good book which starts from quite beginner to learn about calculating the complexity of Algorithm??</p>\n', 'ViewCount': '480', 'Title': 'Book to learn Algorithm Complexity', 'LastActivityDate': '2013-02-24T10:59:41.620', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '6669', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2013-02-24T06:37:31.737', 'Id': '10042'},16732:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a question have to answer, so that, if anyone have the answer, please help me.</p>\n\n<p>The problem is: Give a self-contained proof that $\\mathsf{L} \\neq \\mathsf{PSPACE}$\nwhere: </p>\n\n<p>$\\qquad \\mathsf{L}      = \\{ L \\mid L \\text{ is a language decidable in logarithmic space} \\}$ and</p>\n\n<p>$\\qquad  \\mathsf{PSPACE} = \\{ L \\mid L \\text{ is a language decidable in polynomial space}\\}$.</p>\n', 'ViewCount': '111', 'Title': 'Relationship between L and PSPACE', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-25T10:39:03.237', 'LastEditDate': '2013-03-25T10:39:03.237', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'OwnerDisplayName': 'user14332', 'PostTypeId': '1', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-03-25T06:42:58.217', 'Id': '10764'},16733:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '115', 'Title': 'Why does a polynomial-time language have a polynomial-sized circuit?', 'LastEditDate': '2013-04-08T14:41:49.757', 'AnswerCount': '2', 'Score': '2', 'OwnerDisplayName': 'John Smith', 'PostTypeId': '1', 'OwnerUserId': '4631', 'Body': '<p>I wish to understand why P is a subset of PSCPACE, that is why a polynomial-time langauge does have a polynomial-sized circuit. I read many proofs like <a href="http://www.stanford.edu/~rrwill/week3.pdf" rel="nofollow">this one here on page 2-3</a>, but all the proofs use the same technique used in the Cook-Levin theorem to convert the computation of M on an n-bit input x to a polynomial sized circuit. </p>\n\n<p>What I don\'t understand is that the resulting circuit is dependent on the input x, because what is being converted into a circuit is the computation of M on the specific input x. By definition of PSIZE, the same circuit must work for all the inputs in a fixed length, and thus is not dependent on one specific input. </p>\n\n<p>So how is the process of creating a poly-sized circuit family for a poly-time deterministic Turing machine works exactly?</p>\n', 'Tags': '<complexity-theory><time-complexity><space-complexity><complexity-classes><polynomial-time>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:41:49.757', 'CommentCount': '1', 'AcceptedAnswerId': '11121', 'CreationDate': '2013-04-07T21:22:54.587', 'Id': '11117'},16734:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>When Savitch\'s famous theorem is stated, one often sees the requirement that $S(n)$ be space constructible (interestingly, it is omitted in Wikipedia). My simple question is: Why do we need this? I understand the requirement for $S(n)$ being in $\\Omega(\\log n)$, which is clear from the proof. But no proof I have seen so far explicitly uses that $S(n)$ is space constructable.</p>\n\n<p>My explanation: in order to call the procedure REACH (or PATH or whatever you like to call it), the last parameter needs to be "spelled out", and in order not to leave our space bounds of S(n) for one call, we must not need more than $S(n)$ space to write it down. </p>\n', 'ViewCount': '106', 'Title': "Why is one often requiring space constructibility in Savitch's theorem?", 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-11T06:54:59.833', 'LastEditDate': '2013-04-10T13:33:01.197', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '11217', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<complexity-theory><space-complexity><complexity-classes><nondeterminism>', 'CreationDate': '2013-04-09T18:45:00.597', 'Id': '11168'},16735:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>We are given an (unsorted) list $L=(a_1,\\dots,a_n)$ of numbers of size $n$, where $a_i\\in \\{ 1,\\dots,B\\}$. </p>\n\n<p>We want to find the minimum number $x$ from $\\{ 1,\\dots,B\\} \\backslash L$. </p>\n\n<blockquote>\n  <p>What is the space complexity of this problem ? (The space to store the input, $L$, does not count.) What if the input $L$ is in a stream which you can only read from left to right for at most constant number of passes ?</p>\n</blockquote>\n\n<p>The obvious way to solve this is just to copy $L$ into the working memory and then (in-place) sort $L$, and find $x$ in the obvious way. This algorithm uses space of size $n$.</p>\n\n<p>Can we do better ?</p>\n', 'ViewCount': '283', 'Title': 'Space complexity for finding the minimum number outside the list of numbers', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-15T17:29:27.610', 'LastEditDate': '2013-04-10T08:52:21.597', 'AnswerCount': '4', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4706', 'Tags': '<algorithms><space-complexity><streaming-algorithm>', 'CreationDate': '2013-04-09T22:56:11.750', 'FavoriteCount': '1', 'Id': '11174'},16736:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '176', 'Title': 'What is a compact way to represent a partition of a set?', 'LastEditDate': '2013-04-16T00:36:16.213', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '7741', 'FavoriteCount': '2', 'Body': '<p>There exist <a href="http://cs.stackexchange.com/q/3414/7741">efficient data\nstructures</a> for representing set\npartitions. These data structures have good time complexities for operations\nlike Union and Find, but they are not particularly space-efficient.</p>\n\n<p><strong>What is a space-efficient way to represent a partition of a set?</strong></p>\n\n<p>Here is one possible starting point:</p>\n\n<p>I know that the <a href="http://en.wikipedia.org/wiki/Partition_of_a_set#Counting_partitions">number of\npartitions</a>\nof a set with $N$ elements is $B_N$, the $N$-th <a href="http://en.wikipedia.org/wiki/Bell_number">Bell\nnumber</a>. So the optimal space\ncomplexity for representing a partition of a set with $N$ elements is\n$\\log_2(B_N)$ bits. To find such a representation, we could look for a\none-to-one mapping between (the set of partitions of a set of $N$ elements) and\n(the set of integers from $1$ to $B_N$).</p>\n\n<p>Is there such a mapping that is efficient to compute? What I mean by\n"efficient" is that I want to convert this compact representation\nto / from an easy-to-manipulate representation (such as a list of lists) in time\npolynomial in $N$ or $\\log_2(B_N)$.</p>\n', 'Tags': '<data-structures><combinatorics><space-complexity><sets><partitions>', 'LastEditorUserId': '7741', 'LastActivityDate': '2013-04-17T19:39:41.237', 'CommentCount': '1', 'AcceptedAnswerId': '11348', 'CreationDate': '2013-04-16T00:14:19.900', 'Id': '11345'},16737:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>For the following question:</p>\n\n<p>If B is an element of PSPACE and A is an element of PSPACE-Complete, and A polynomial reduces to B, then B is an element of PSPACE-Complete.</p>\n\n<p>I am trying to prove this, but I don't understand how to get started. Can anyone help please?</p>\n", 'ViewCount': '45', 'Title': 'Showing transitivity of PSPACE?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-23T09:10:18.867', 'LastEditDate': '2013-04-23T09:10:18.867', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<complexity-theory><reductions><proof-techniques><space-complexity>', 'CreationDate': '2013-04-23T02:15:09.323', 'Id': '11506'},16738:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m trying to solve this question in order to review for my exam, and this one has got me a bit stumped. From the looks of it, it seems like a fairly straight-forward question, but I can\'t figure out what steps to begin with.</p>\n\n<blockquote>\n  <p>Let $M$ be a linear-space Turing machine consisting of a single tape. We say $M$ is a linear-space Turing machine if M halts on every input, and if there are constants $c$ and $n_{0}$ such that for all inputs $x\\in \\Sigma^{\\ast}$ of length $n\\geq n_{0}$, $M$ running on $x$ visits at most $c\\cdot n$ tape squares.</p>\n  \n  <p>Prove that for some constant $d$, $M$ runs in time $O(2^{dn})$.</p>\n</blockquote>\n\n<p>I have a couple of ideas to begin with. First, my intuition tells me that I just have to build an algorithm that runs according to those rules and accepts/rejects in time $O(2^{dn})$. Secondly, theres a hint that tells me to "consider the number of configurations", however, I\'m not sure on how to incorporate that.</p>\n\n<p>Thank you in advance for any help.</p>\n', 'ViewCount': '209', 'Title': 'Proving that Turing Machine M runs in time $O(2^{dn})$', 'LastEditorUserId': '7492', 'LastActivityDate': '2013-05-06T23:39:09.417', 'LastEditDate': '2013-05-06T23:39:09.417', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '11563', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7904', 'Tags': '<turing-machines><space-complexity>', 'CreationDate': '2013-04-26T04:02:53.980', 'Id': '11561'},16739:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'd like to know if I have the right intuition and my answer is headed the correct way.</p>\n\n<p>I am given a function\n$ f = \\{0, 1\\}^* \\rightarrow  \\{0, 1\\}^* $ that is computable in space $O(\\log n)$ assume that for every $x \\in \\{0, 1\\}^*$, $f$ is length preserving, $|f(x)| = |x|$.</p>\n\n<p>Define \n$$L = \\left\\{ x\\#y \\mid \\ x, y \\in \\{0, 1\\}^*, |x| = |y|, \\ \\text{and} \\ f(x) = f(y)\\right\\}$$</p>\n\n<p>I am suppose to prove that $ L \\in  {\\sf DSPACE}(\\log n) $.</p>\n\n<p>Please correct me if my intuition is incorrect. </p>\n\n<p>My solution would be to build a decider $M$ which is a Turing machine.</p>\n\n<p>$M$ takes inputs $x$ and $y$, run the function $f$ on input $x$ and $y$ and if the lengths of the two strings are equal then accept, otherwise reject.</p>\n\n<p>Now the Turing machine runs in $ O(\\log n) $ because the function $f$ is computable in $ O(\\log n)  + O(\\log n) = O(\\log n) $ and comparing the length returned by the function is $ O(1) $\nThus the language is decidable by a Turing machine that is run in $ O(\\log n) $ and only takes Space $ O(\\log n) $.</p>\n", 'ViewCount': '64', 'Title': 'Proving language in Space Complexity', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-04-27T08:00:09.567', 'LastEditDate': '2013-04-27T07:44:47.950', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '11599', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7920', 'Tags': '<space-complexity>', 'CreationDate': '2013-04-26T21:33:45.053', 'Id': '11588'},16740:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm trying to find complexity class of finding winning strategy for first player in following game:</p>\n\n<p>Intance of 'Stones' game is:</p>\n\n<ul>\n<li>finite set $X$</li>\n<li>relation $R \\subseteq X^3$</li>\n<li>set $Y \\subseteq X$ and node $f \\in X$</li>\n</ul>\n\n<p>At the beggining we place stone in every element of $Y$. \nEvery player in his turn can move stone from $x$ to $z$ iff. $\\exists y.R(x, y, z) \\wedge y\\ has\\ stone\\ placed\\ in\\ it$.\nPlayer who places stone in $f$ wins.</p>\n\n<p>I think it's $PSPACE-complete$, but I was trying to proove this for some time, and I run out of ideas.</p>\n\n<p>I won't lie, it's homework assignment for my complexity class. Any help will be highly appreciated.</p>\n", 'ViewCount': '54', 'Title': "'Stones' game complexity", 'LastActivityDate': '2013-06-01T03:24:19.843', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8469', 'Tags': '<complexity-theory><space-complexity><complexity-classes><game-theory>', 'CreationDate': '2013-06-01T03:24:19.843', 'FavoriteCount': '1', 'Id': '12407'},16741:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am studying now for a test in my complexity course. When I solved previous exams I saw the following question : Prove that the language $L$ of all directed graphs on $n$ vertices that contain exactly $10\\sqrt(n)$ strongly connected components is in $NL$. </p>\n\n<p>We saw in class that checking whether a directed graph contains exactly $C$ strongly connected components is in $NL$ for any fixed $C$, but I thought about this question the whole day and I absolutely have no idea how to do it in $NL$ when then number of SCC required is $10\\sqrt(n)$. In the test this question was worth 20 points, so it shouldn't be too hard so I thought that maybe I am missing something important.<br>\nAny ideas people?</p>\n", 'ViewCount': '145', 'Title': 'Checking whether a directed graph on n vertices contains exactly 10*sqrt(n) strongly connected components is in non-deterministic logspace', 'LastActivityDate': '2013-06-28T05:07:36.833', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12942', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4631', 'Tags': '<complexity-theory><space-complexity><nondeterminism>', 'CreationDate': '2013-06-27T22:34:14.210', 'Id': '12932'},16742:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<pre><code>"The designer of an algorithm needs to balance between space complexity and time\ncomplexity." - Comment on the validity of the statement in the context of recursive\nalgorithms.\n</code></pre>\n\n<p>This is a question from my university\'s previous paper. But i couldn\'t find a decent answer. Actually i am confused about how can a developer minimize the time-complexity for any recursive function. I get that if there is a <strong>tail-recursion</strong> then space complexity can be minimized. But can\'t get the idea of time-complexity.  </p>\n', 'ViewCount': '2006', 'Title': 'Time complexity and space complexity in recursive algorithm', 'LastActivityDate': '2013-07-05T16:00:28.187', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13058', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8987', 'Tags': '<algorithms><time-complexity><space-complexity>', 'CreationDate': '2013-07-03T10:49:10.123', 'Id': '13055'},16743:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '169', 'Title': "Is the memory-runtime tradeoff an equivalent of Heisenberg's uncertainty principle?", 'LastEditDate': '2013-08-08T10:40:15.420', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9571', 'FavoriteCount': '3', 'Body': '<p>When I work on an algorithm to solve a computing problem, I often experience that speed can be increased by using more memory, and memory usage can be decreased at the price of increased running time, but I can never force the product of running time and consumed memory below a clearly palpable limit. This is formally similar to Heisenberg\'s uncertainty principle: the product of the uncertainty in position and the uncertainty in momentum of a particle cannot be less than a given threshold.</p>\n\n<p>Is there a theorem of computer science, which asserts the same thing? I guess it should be possible to derive something similar from the theory of Turing Machines.</p>\n\n<p>(I asked this question originally on <a href="http://stackoverflow.com/questions/18108578/the-uncertainty-principle-of-computer-science">StackOverflow</a>.)</p>\n', 'Tags': '<algorithms><time-complexity><space-complexity><performance>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-08T10:40:15.420', 'CommentCount': '3', 'AcceptedAnswerId': '13664', 'CreationDate': '2013-08-07T16:45:48.973', 'Id': '13661'},16744:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '134', 'Title': 'Set combination data structure (And storage complexity)', 'LastEditDate': '2013-09-09T12:06:57.553', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10038', 'FavoriteCount': '1', 'Body': '<p>I have already posted this question on <a href="http://stackoverflow.com/questions/18669727/set-combination-data-structure-and-storage-complexity">Stackoverflow</a>, but I\'m starting to think that this is the right place.</p>\n\n<p>I have a problem where I am required to associate unique combinations from a set (unique subsets) to a given value. e.g.: Let <code>S={a, b, c, d}</code>, the required data structure should perform the following:</p>\n\n<p><strong>Key -> value</strong></p>\n\n<pre><code>{a,b} -&gt; value1\n{a,c} -&gt; value2\n{c,d} -&gt; value3\n</code></pre>\n\n<ul>\n<li>Property 1: The length of the set in the key is fixed (In this\nexample it\'s fixed to 2).</li>\n<li>Property 2: The data structure does not\nhold all possible subsets of S.</li>\n</ul>\n\n<p><strong>Question 1</strong>: What is the storage complexity of a simple Map holding these values? O(N!)? (given that |S| = N and it\'s not fixed)</p>\n\n<p><strong>Question 2</strong>: Is there any efficient data structure that could store such elements? (The most important efficiency would be required in storage complexity)</p>\n', 'Tags': '<data-structures><space-complexity><sets>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-09T20:20:08.697', 'CommentCount': '4', 'AcceptedAnswerId': '14221', 'CreationDate': '2013-09-08T05:34:12.877', 'Id': '14208'},16745:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>As the question states, how do we prove that $\\textbf{NTIME}(f(n)) \\subseteq \\textbf{DSPACE}(f(n))$?</p>\n\n<p>Can anyone point me to a proof or outline it here? Thanks!</p>\n', 'ViewCount': '105', 'Title': 'NTIME(f) subset of DSPACE(f)', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-09T02:19:16.840', 'LastEditDate': '2013-09-20T17:45:09.420', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10237', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2013-09-20T16:26:15.297', 'Id': '14475'},16746:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I am unclear about finding the memory complexity of an algorithm.</p>\n\n<p>Some places refer memory complexity as what container would be carrying for instance:</p>\n\n<pre><code>for i = 1 to n-1\n     if d[i] == d[i + 1]\n           d[i] = (d[i] + 5) mod 13\n</code></pre>\n\n<p>Is considered as having $\\theta(N)$ memory complexity.</p>\n\n<p>At some other places how much data we write to a container is a complexity for instance:</p>\n\n<pre><code>reverse_list(n)\n\n    Stack res\n    while (n != NULL)\n         res push n\n         n = n-&gt;next\n    while (res != null) \n         a = pop res\n         print a\n</code></pre>\n\n<p>Is considered as having a memory complexity of $\\theta(N)$ too. Moreover:</p>\n\n<p>Such thing is considered having $\\theta(1)$ memory complexity</p>\n\n<pre><code>reverse_list(head)\n    last = NULL;\n    while(last != head)\n        current = head\n        while(current-&gt;next != last)\n            current = current-&gt;next\n        print current\n        last = current\n</code></pre>\n\n<p>I know how these algorithms work and what they do, but I don't understand how are we meant to be analysing their memory complexity. Could someone explain that please?</p>\n", 'ViewCount': '472', 'Title': 'Memory complexity?', 'LastEditorUserId': '8849', 'LastActivityDate': '2013-10-28T15:14:42.793', 'LastEditDate': '2013-10-28T15:14:42.793', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '16464', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8849', 'Tags': '<complexity-theory><algorithm-analysis><asymptotics><space-complexity>', 'CreationDate': '2013-10-27T04:26:35.907', 'Id': '16461'},16747:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given three numbers $m$, $n$ and $p$ in interleaved binary encoding<sup>1</sup>, it\'s obviously possible to check in $O(1)$ space whether $m+n=p$. It\'s less obvious<sup>2</sup> that it isn\'t possible  to check in $O(1)$ space whether $m\\cdot n=p$. I wonder whether one can prove that it isn\'t possible to check in $O(\\log N)$ space<sup>3</sup> whether $m\\cdot n=p$. On the other hand, are there any known non-trivial upper bounds on the space complexity of this problem, like $O(N/\\log N)$? </p>\n\n<p>The problem described above is a simplified version of the "Multiplication decision problem: Is the $k$th bit of the product of $m$ and $n$ a one?" Since this problem is more "powerful" (and also better known), I wonder whether one can show that this problem can\'t be decided in $O((\\log N)^2)$ space.</p>\n\n<hr>\n\n<p><sub>\n1. The interleaved binary encoding starts with the lowest significant bit, and allows "leading" zeros for the most significant bits.\n</sub></p>\n\n<p><sub>\n2. The proof idea I have in mind would use such an algorithm as building block for a decision procedure of Robinson arithmetic. I call this less obvious, because the fact that Robinson arithmetic is undecidable may be well known, but still remains non-trivial.\n</sub></p>\n\n<p><sub>\n3. Here $N$ is the length of the input $m$, $n$ and $p$ in binary encoding.\n</sub></p>\n', 'ViewCount': '82', 'Title': 'Known bounds on space complexity of multiplication decision problem', 'LastEditorUserId': '1557', 'LastActivityDate': '2013-10-27T19:35:21.797', 'LastEditDate': '2013-10-27T14:32:42.443', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1557', 'Tags': '<space-complexity><binary-arithmetic>', 'CreationDate': '2013-10-27T12:32:23.403', 'Id': '16469'},16748:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u"<p>I'm trying to prove that the language SPACE TMSAT (where SPACE TMSAT = {\u27e8$M$, $w$, $1^n$\u27e9 : DTM $M$ accepts $w$ in space $n$}) is PSPACE-complete.</p>\n\n<p>My solution is as follows:<br>\nSPACE TMSAT $= \\{&lt;M,w,1^{n}&gt; :$ DTM $M$ accepts $w$ in space $n\\}$ can only be computed by running machine $M$ on $w$. As this forces the allowance of the computation of any PSPACE language, SPACE TMSAT is PSPACE-complete.</p>\n\n<p>Does this solution make sense? Am I being too hand wavy? Any other suggestions or critiques? Thanks!</p>\n", 'ViewCount': '100', 'ClosedDate': '2013-11-10T16:59:53.130', 'Title': 'Proving that the language SPACE TMSAT is PSPACE-complete?', 'LastActivityDate': '2013-11-06T08:49:32.537', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11153', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-11-04T02:38:41.303', 'Id': '16690'},16749:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I would like some hints on how to approach this problem, I know for instance that $TQBF$ is $PSPACE$-$Complete$, so it can solved in poly space and any other $PSPACE$-$Complete$ problems can be log spaced reduced to $TQBF$. I believe that I need to employ the space hierarchy theorem in some way but I am not sure how, this is a homework question so I just want a hints. Thank you! </p>\n', 'ViewCount': '117', 'Title': 'Prove that $TQBF \\notin SPACE(n^{\\frac{1}{3}})$', 'LastActivityDate': '2013-12-11T08:44:59.787', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '18870', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10880', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-11-27T22:03:52.387', 'Id': '18426'},16750:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>While thinking about different calculi for predicate logic (like natural deduction and sequent calculus), I noticed that these calculi are (often) presented in a form suitable for "human computers". A "human computer" is limited to use <a href="http://en.wikipedia.org/wiki/Write_once_read_many" rel="nofollow">write once read many</a> (WORM) memory when processing large amounts of data. Pure functional programming also seems to favor a WORM memory model. In fact, it seems to me that the WORM memory model is so natural that classifying it as <a href="http://en.wikipedia.org/wiki/Unconventional_computing" rel="nofollow">unconventional computing</a> might underestimate its importance. (Understanding the strengths and limitations of the computing resources available to humans is important.)</p>\n\n<p>What is known about the relation between space and time complexity for machines with WORM memory? What are the keywords to google for available material related to these questions? Do we known whether the time complexity will remain the same, if a small (for example C*log(WORM memory)^n) amount of normal memory is added?</p>\n', 'ViewCount': '91', 'Title': 'Relation between space and time complexity for machines with write once read many (WORM) memory', 'LastEditorUserId': '1557', 'LastActivityDate': '2014-03-03T00:13:28.570', 'LastEditDate': '2013-12-13T09:09:01.290', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22210', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1557', 'Tags': '<time-complexity><runtime-analysis><space-complexity>', 'CreationDate': '2013-12-13T00:04:24.253', 'Id': '18939'},16751:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a problem $A$ which was shown to be PSPACE-complete by reduction from planning. \nHowever, $A$ can also be transformed into reachability problem which is NL-complete. </p>\n\n<p>I know that $NL=NSPACE(log \\ n)$ and $PSPACE=NSPACE$.  </p>\n\n<p>Does this mean $A$ is also NL-complete? IF yes, does it make any difference in this context to say whether $A$ is PSPACE-complete or NL-complete ?</p>\n', 'ViewCount': '40', 'Title': 'If a problem is PSPACE-complete what do we know about NL-completeness', 'LastEditorUserId': '4598', 'LastActivityDate': '2013-12-30T11:18:50.060', 'LastEditDate': '2013-12-30T10:57:07.170', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19374', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-12-30T10:46:46.743', 'Id': '19373'},16752:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '96', 'Title': 'Is DSPACE properly contained in NSPACE?', 'LastEditDate': '2014-01-17T22:20:45.957', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12901', 'FavoriteCount': '0', 'Body': '<p>It may be a dumb question, but is $\\mathsf{DSPACE}(f(n)) \\subset \\mathsf{NSPACE}(f(n))$ or is $\\mathsf{DSPACE}(f(n)) \\subseteq \\mathsf{NSPACE}(f(n))$?  In other words, is the containment relation proper or not?  Wikipedia says the first one, while the ComplexityZoo says the other one.</p>\n', 'Tags': '<complexity-theory><complexity-classes><space-complexity>', 'LastEditorUserId': '755', 'LastActivityDate': '2014-01-18T14:14:48.173', 'CommentCount': '1', 'AcceptedAnswerId': '19797', 'CreationDate': '2014-01-17T20:15:15.043', 'Id': '19794'},16753:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u"<p>I am looking for implementation of the set data type. That is, we have to</p>\n\n<ul>\n<li>maintain a dynamic subset $S$ (of size $n$) from the universe $U = \\{0, 1, 2, 3, \\dots , u \u2013 1\\}$ of size $u$ with</li>\n<li>operations <code>insert(x)</code> (add an element <code>x</code> to $S$) and <code>find(x)</code> (checks whether element <code>x</code> is a member of $S$).</li>\n</ul>\n\n<p>I don't care about other operations. For orientation, in applications I'm working with we have $u \\approx 10^{10}$.</p>\n\n<p>I know of implementations that provide both operations in time $O(1)$, so I worry mostly about the size of data structure. I expect <em>billions</em> of entries but want to avoid swapping as much as possible.</p>\n\n<p>I am willing to sacrifice runtime if necessary. Amortised runtime of $O(\\log n)$ is what I can admit; expected runtimes or runtimes in $\\omega(\\log n)$ are not admissable.</p>\n\n<p>One idea I have is that if $S$ can be represented as a union of ranges <code>[xmin, xmax]</code>, then we will be able to save on storage size with the price of some performance decrease. Also, some other data patterns are possible, like <code>[0, 2, 4, 6]</code>.</p>\n\n<p>Could you please point me to data structures which can do something like that?</p>\n", 'ViewCount': '155', 'Title': 'Looking for a set implementation with small memory footprint', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-03T09:34:06.393', 'LastEditDate': '2014-01-31T08:03:57.357', 'AnswerCount': '2', 'CommentCount': '11', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '11850', 'Tags': '<data-structures><efficiency><space-complexity><sets><dictionaries>', 'CreationDate': '2014-01-29T16:42:55.737', 'Id': '20070'},16754:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have a social network in the form of an undirected graph $G = (V,E)$ with distinct non-negative integer keys. For each node $u \\in V$, let the set $\\Gamma(u) = \\{ v \\in V : (u,v) \\in E \\}$ be the <strong><em>neighbourhood</em></strong> of $u$. Clearly, I got that $d(u) = \\left | \\Gamma(u) \\right |$, where $d(u)$ is the <strong><em>degree</em></strong> of $u$.</p>\n\n<p>I now want to split $\\Gamma(u)$ into two sets of nodes</p>\n\n<p>$$\\Gamma_{\\text{low}}(u)  = \\{ v \\in V : v \\in \\Gamma(u) \\text{ and } v &lt; u \\}$$\n$$\\Gamma_{\\text{high}}(u) = \\{ v \\in V : v \\in \\Gamma(u) \\text{ and } v &gt; u \\}$$</p>\n\n<p>i.e. $\\Gamma_{\\text{low}}(u)$ and $\\Gamma_{\\text{high}}(u)$ contain neighbours of $u$ whose key is less than or greater than $u$'s, respectively.</p>\n\n<p>Assuming that the graph has got $m$ edges, is there a way to obtain an upper bound for $d_{\\text{low}}(u) = \\left | \\Gamma_{\\text{low}}(u) \\right |$ and $d_{\\text{high}}(u) = \\left | \\Gamma_{\\text{high}}(u) \\right |$ for varying $m$? I just can obtain the following relationship</p>\n\n<p>$$\\sum_{u \\in V} d_{\\text{low}}(u) + \\sum_{u \\in V} d_{\\text{high}}(u) = 2m,$$</p>\n\n<p>because the graph is undirected. I read somewhere that $d(u) = O\\left ( \\sqrt{m} \\right )$ is a good bound for social networks, but how do I prove it?</p>\n", 'ViewCount': '45', 'Title': 'Need an upper bound for node degree', 'LastActivityDate': '2014-01-30T14:19:42.420', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '13243', 'Tags': '<algorithms><graph-theory><space-complexity><social-networks>', 'CreationDate': '2014-01-30T14:19:42.420', 'Id': '20108'},16755:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I know that a logspace transducer is a deterministic Turing machine that enables us to use log-space complexity. I do not understand though why that is correct. Whatever algorithms can be implemented in that machine are automatically of log-space complexity? Why is that?</p>\n', 'ViewCount': '33', 'Title': 'Logspace Transducer', 'LastActivityDate': '2014-02-23T20:28:34.030', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14957', 'Tags': '<turing-machines><space-complexity>', 'CreationDate': '2014-02-23T20:08:30.823', 'Id': '21954'},16756:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m looking for some clarification on some concepts/facts I came across while studying for a class.</p>\n\n<p>I was reading the following wikipedia article. The below specific section and statement intrigued me when looking it over.</p>\n\n<p><a href="http://en.wikipedia.org/wiki/Computational_complexity_theory#Important_complexity_classes" rel="nofollow">http://en.wikipedia.org/wiki/Computational_complexity_theory#Important_complexity_classes</a>\n"It turns out that PSPACE = NPSPACE and EXPSPACE = NEXPSPACE by Savitch\'s theorem"</p>\n\n<p>I also read that NTMs can be simulated by DTMs but that the shortest accepting computation of the DTM is exponential with respect to the shortest accepting computation of the target NTM.</p>\n\n<p><strong>My questions are:</strong></p>\n\n<p>1.) Are PSPACE and NPSPACE the set of all problems that require at least polynomial space to be solved on Deterministic and Non-deterministic Turing machines respectively?</p>\n\n<p>2.) If so, is the actual size of the polynomial space required dependent on the size of the input?</p>\n\n<p>3.) For P and NP, they are each the sets of problems that require at least polynomial time to be solved on DTMs and NTMs respectively correct?</p>\n\n<p>4.) Is the reason that the shortest accepting computation of a DTM simulating a target NTM is exponential with respect to the shortest accepting computation of an NTM due to the exponential explosion of the number of configurations that an NTM supports as input grows for a given problem?</p>\n\n<p>5.) My last and overarching question is: Are the differences in the set of problems that can be solved in polynomial time on DTMs versus NTMs related to time/space tradeoffs where DTMs can\'t run some polynomial NTM algorithms in polynomial time because they don\'t have the same "space" that an NTM has available to it?</p>\n\n<p>I\'d also appreciate any reading you can suggest to me on time/space tradeoffs and NTMs versus DTMs.</p>\n', 'ViewCount': '109', 'Title': 'Relation of Space and Time in Complexity?', 'LastActivityDate': '2014-02-28T04:20:01.920', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '22110', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '14819', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2014-02-27T20:46:01.303', 'FavoriteCount': '2', 'Id': '22109'},16757:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>$ALL_{REGEX}$ is the computational problem of determining for regular expression x if $L(x) = \\Sigma^*$.  In a proof for $ALL_{REGEX} \\in PSPACE$, the following non-deterministic turing machine $M(R)$ on regular expression $R$ is given</p>\n\n<p>Convert R to an NFA $N = (Q,\\Sigma,\\delta,S,F)$;   $K = S$;  </p>\n\n<p>While $K \\cap F \\neq \\emptyset$</p>\n\n<ol>\n<li>Non-deterministically guess a character $a \\in \\Sigma$</li>\n<li>S' = Compute the new set of states from character $a$ and states $K$</li>\n<li>K = S'</li>\n</ol>\n\n<p>The proof states that iff $M$ does not halt, then $L(R) = \\Sigma^*$.  Suppose we have $\\Sigma = \\{a,b\\}$ and R = a*. Why doesn't this machine halt?  Won't there be a single path of guesses (namely, a*) that goes on forever, implying the whole machine does as well?</p>\n\n<p>The algorithm goes prove that after $2^{|Q|}$ steps, we know the language must be $\\Sigma^*$, so we accept instead of looping.  I understand the intuition of the algorithm and how it would be implemented deterministically  , but I'm confused as to how the algorithm above works when the NTM formalism accepts if any path accepts and it is making me question my understanding of NTMs.</p>\n", 'ViewCount': '29', 'Title': 'ALL_{REGEX} in PSPACE algorithm', 'LastEditorUserId': '1784', 'LastActivityDate': '2014-03-12T17:56:18.223', 'LastEditDate': '2014-03-12T17:49:36.407', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1784', 'Tags': '<turing-machines><space-complexity>', 'CreationDate': '2014-03-12T17:34:32.667', 'Id': '22549'},16758:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '49', 'Title': 'Language with $\\log\\log n$ space complexity?', 'LastEditDate': '2014-03-16T15:11:57.433', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15348', 'FavoriteCount': '1', 'Body': "<p>We know that every non-regular language can be recognized with $ \\Omega\n (\\log\\log n) $ space complexity.</p>\n\n<p>I'm looking for an example of a language which is $ \\Theta\n (\\log\\log n) $ space complexity (if such exists).</p>\n", 'Tags': '<formal-languages><space-complexity>', 'LastEditorUserId': '683', 'LastActivityDate': '2014-03-16T15:37:57.397', 'CommentCount': '1', 'AcceptedAnswerId': '22681', 'CreationDate': '2014-03-16T14:35:46.383', 'Id': '22676'},16759:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am working through Sipser, and I am trying to understand some of the algorithms described in Space Complexity, but I am having a hard time understanding the presentation of the material (especially Savitch\'s theorem). I have a very strong intuition for time complexity, but I don\'t understand how space complexity fits into a heirarchy of time complexity, and I think it has to do with the fact that it is all discussed in terms of Turing machines. It is hard to see how space and time are related when I\'m wasting time untangling convoluted algorithms described in terms of Turing machines.</p>\n\n<p><strike>Does anyone have any advice on how to think about Turing machines vis-a-vis contemporary computation in general? It is unintuitive to think about algorithms in terms of input strings, tapes, and machines simulating machines. I don\'t feel like I am leveraging my existing knowledge of computers and programming to more deeply understand the proofs and algorithms being presented.</strike></p>\n\n<p>I think I just need help understanding how space varies based on the data structure of the input. For some input of size $n$, are the bits required to represent each entity of the input negligible? Say our language is a set of objects that are all of a certain type, and each object is massive. How does space usage vary vs. a similar language with very small objects?</p>\n\n<p>Edit: I understand now that space complexity fits in with time complexity because they are both <em>resources</em> used to determine whether some string is a member of a language; Or in other words, whether some element belongs to a particular problem (<a href="http://cs.stackexchange.com/q/22742/15660">see here</a>).</p>\n', 'ViewCount': '58', 'Title': 'How to Study Space Complexity', 'LastEditorUserId': '15660', 'LastActivityDate': '2014-03-18T04:12:44.430', 'LastEditDate': '2014-03-18T04:12:44.430', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15660', 'Tags': '<turing-machines><space-complexity>', 'CreationDate': '2014-03-18T01:56:41.580', 'Id': '22741'},16760:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>In "Introduction to the Theory of Computation" by Sipser, Savitch\'s theorem is explained as an improvement to a naive storage scheme for simulating non-deterministic Turing machines (NTM). I am going to quote the text verbatim, because quite frankly I don\'t fully understand it (which is why I was unable to really ask my question in enough detail):</p>\n\n<blockquote>\n  <p>We need to simulate an $f(n)$ space NTM deterministically. A naive\n  approach is to proceed by trying all the branches of the NTM\u2019s\n  computation, one by one. The simulation needs to keep track of which\n  branch it is currently trying so that it is able to go on to the next\n  one. But a branch that uses $f(n)$ space may run for $2^{O(f(n))}$\n  steps and each step may be a nondeterministic choice. Exploring the\n  branches sequentially would require recording all the choices used on\n  a particular branch in order to be able to find the next branch.\n  Therefore, this approach may use $2^{O(f(n))}$ space, exceeding our\n  goal of $O(f^2(n))$ space. (Sipser, "Introduction to the Theory of Computation" 334)</p>\n</blockquote>\n\n<p>He goes on to describe Savitch\'s use of a subroutine called $CANYIELD$, a TM that decides whether some configuration $c_2$ is reachable from some other configuration $c_1$ in $t$ steps. It is recursively defined, so that $CANYIELD(c_1, c_n, t)$ results in two recursive calls $CANYIELD(c_1, c_m, t/2)$ and $CANYIELD(c_m, c_n, t/2)$, and so on until the "distance" between configurations is $0$ or $1$, or it is deemed unreachable. I think this can also be described as $STCON$ on a configuration graph of the TM in question.</p>\n\n<p>So, there are two questions I have.</p>\n\n<ol>\n<li>I understand how the size of each level and the depth of $CANYIELD$ results in no more than $O(f^2(n))$ use of space, but I don\'t understand how the intermediate configuration $c_m$ is found. Is this just not important given that all we care about is space? How do we know that the space used to obtain $c_m$ is negligible?</li>\n<li>I don\'t understand why we need $2^{O(f(n))}$ space in the naive approach. Why can\'t we "forget" about branches we\'ve executed, so that we are still using at most the space required to go all the way down one branch?</li>\n</ol>\n', 'ViewCount': '90', 'Title': "The crux of Savitch's Theorem", 'LastEditorUserId': '15660', 'LastActivityDate': '2014-03-24T13:36:21.720', 'LastEditDate': '2014-03-22T21:32:55.710', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15660', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2014-03-18T04:32:50.640', 'Id': '22745'},16761:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I want to show that $CO-2Col \\le_L USTCON$ (Log-Space reduction)</p>\n\n<h2>$USTCON$</h2>\n\n<blockquote>\n  <p>The $s-t$ connectivity problem for <strong>undirected</strong> graphs is\n  called $USTCON$.</p>\n  \n  <p>[Input]: An undirected graph $G=(V,E)$, $s,t \\in V$.</p>\n  \n  <p>[Output]: 1 iff $s$ is connected to $t$ in $G$.</p>\n</blockquote>\n\n<hr>\n\n<h2>$CO-2Col$</h2>\n\n<blockquote>\n  <p>A graph is $2$-colorable if there is a way to color the vertices\n  of $G$ with $2$ colors, such that for every edge the two vertices\n  on the edge are colored differently. $CO-2Col$ is the following\n  problem:</p>\n  \n  <p>[Input]: An undirected graph $G$.</p>\n  \n  <p>[Output]: 1 iff $G$ is NOT $2$-colorable.</p>\n</blockquote>\n\n<hr>\n\n<p>My <strong>solution</strong> is for an input graph $G$ the reduction outputs $(G\',s,t)$ where\n $s$ an arbitrary vertex of $G$, $t$ is one of its neighbours and\n$G\'=G^2$ namely an edge $(u,v)\\in E(G\')$,iff there is $w \\in V (w \\ne u,v)$\nsuch that $(u,w)\\in E(G)$ and $(w,v)\\in E(G)$. </p>\n\n<p>$G$ is bipartite \niff $G\'$ is not connected (and $s$ and $t$ belongs to different\nparts).</p>\n\n<p>But this only works when the input graph $G$ is <strong>connected</strong>.</p>\n\n<p>A counter example: (if we choose s,t to be A,B)</p>\n\n<p><img src="http://i.stack.imgur.com/JYLSD.jpg" alt="Counter example"></p>\n\n<p>How can I improve my reduction that it will work at the unconnected case? or maybe a new reduction is needed?</p>\n\n<p>Thanks!</p>\n', 'ViewCount': '89', 'Title': 'Log-Space Reduction $CO-2Col \\le_L USTCON$', 'LastActivityDate': '2014-03-20T20:01:06.013', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22829', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15890', 'Tags': '<complexity-theory><reductions><space-complexity>', 'CreationDate': '2014-03-19T21:19:01.533', 'Id': '22826'},16762:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Consider the "Generalized Geography" game: on directed graph G with selected start node, players take turns moving along edges, without ever going back to previously visited nodes.  Last player to move wins.</p>\n\n<blockquote>\n  <p>GG = {  : G is a directed graph, b is a node in G, and the next\n                     player to play has a winning strategy for generalized\n                     geography from start node b, i.e., there are moves for\n                     the next player to win no matter how opponent plays }</p>\n</blockquote>\n\n<p>This problem is well-known to be in PSPACE and EXPTIME-hard. My question is:\nIf we allow repetitions in GG, it still belongs to EXPTIME-hard?</p>\n', 'ViewCount': '59', 'Title': 'Generalized Geography with repetitions', 'LastEditorUserId': '39', 'LastActivityDate': '2014-03-22T20:01:27.593', 'LastEditDate': '2014-03-22T20:01:27.593', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15966', 'Tags': '<graph-theory><time-complexity><space-complexity>', 'CreationDate': '2014-03-21T11:50:18.843', 'FavoriteCount': '0', 'Id': '22901'},16763:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Define the complexity class $C$ to be the class of all languages that can be verified by a TM that has:</p>\n\n<ul>\n<li>Input tape: Read only, move in both directions.</li>\n<li>Witness tape: Read only, move only in one direction.</li>\n<li>Work tape: Read-Write, move in both directions.</li>\n</ul>\n\n<p>The machine itself is deterministic (the guesses are the value of the witness tape). The space complexity is the size of the work tape, and is polynomial. We say the machine\naccepts an input if and only if there exists a setting for the witness tape, with which the\nmachine accepts.</p>\n\n<p>Prove: $C = \\mathrm{PSPACE}$</p>\n\n<p>Well, it's obvious that $\\mathrm{PSPACE} \\subset C$ since any TM $M$ can be converted into a TM $M'$ that simply ignores its witness tape and runs in the same space complexity as $M$.</p>\n\n<p>However, I'm struggling with the other direction. The problem is that the witness can be exponential in the input and I can't see how we can enumerate over all witnesses using only polynomial space.</p>\n\n<p>edit: I had a mistake, the witness tape can only be read in one direction.</p>\n", 'ViewCount': '36', 'Title': 'Polynomial space complexity with exponential size witnesses', 'LastEditorUserId': '7068', 'LastActivityDate': '2014-03-22T18:32:45.640', 'LastEditDate': '2014-03-22T18:32:45.640', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22912', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7068', 'Tags': '<complexity-theory><space-complexity><complexity-classes>', 'CreationDate': '2014-03-21T17:49:32.217', 'Id': '22907'},16764:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '11', 'Title': 'Generalized Geography with repetitions', 'LastEditDate': '2014-03-22T20:01:21.090', 'AnswerCount': '0', 'Score': '2', 'OwnerDisplayName': 'user3195997', 'PostTypeId': '1', 'OwnerUserId': '15966', 'FavoriteCount': '0', 'Body': '<p>Consider the "Generalized Geography" game: on directed graph G with selected start node, players take turns moving along edges, without ever going back to previously visited nodes. Last player to move wins.</p>\n\n<blockquote>\n  <p>GG = { : G is a directed graph, b is a node in G, and the next player to play has a winning strategy for generalized geography from start node b, i.e., there are moves for the next player to win no matter how opponent plays }</p>\n</blockquote>\n\n<p>This problem is well-known to be in PSPACE and EXPTIME-hard. My question is: If we allow repetitions in GG, it still belongs to EXPTIME-hard?</p>\n', 'ClosedDate': '2014-03-22T20:01:36.047', 'Tags': '<graph-theory><time-complexity><space-complexity>', 'LastEditorUserId': '39', 'LastActivityDate': '2014-03-22T20:01:21.090', 'CommentCount': '0', 'CreationDate': '2014-03-21T11:53:26.130', 'Id': '22945'},16765:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given an integer $n$, calculate $n!=n\\times(n-1)\\times(n-2)\\dotsc 3\\times2\\times1$. </p>\n\n<p>What is the best time and space complexity of calculating $n!$?</p>\n\n<p>P.S. I do not have any idea about this topic. I was using MATLAB and I needed to compute $200!$ but it said "Out of memory"!! That\'s why I am asking.</p>\n', 'ViewCount': '31', 'Title': 'What is the time/space complexity of $n!$? Can $n!$ has polynomial space complexity?', 'LastActivityDate': '2014-03-29T22:21:47.410', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '23233', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15654', 'Tags': '<time-complexity><space-complexity>', 'CreationDate': '2014-03-29T21:29:34.247', 'Id': '23231'},16766:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I was wondering how I could go about creating an algorithm that gets all the cliques in a graph in PSPACE</p>\n\n<p>So far, based on some of the readings I've done, I am considering to use bit-strings (that have a length equal to the number of vertices in the graph). Then, for every possible subset of the vertices, a turing machine writes bit-strings in order and checks if the subset is a clique. On the side there will also be a counter that counts the number of cliques </p>\n\n<p>This is where I am stuck so far. Can anyone help me improve my solution (or tell me whats wrong with it)? Thanks very much</p>\n", 'ViewCount': '48', 'ClosedDate': '2014-04-02T06:20:16.330', 'Title': 'Clique and PSPACE', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-02T06:20:01.417', 'LastEditDate': '2014-04-02T06:20:01.417', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16368', 'Tags': '<complexity-theory><graphs><space-complexity><enumeration>', 'CreationDate': '2014-04-02T01:55:22.447', 'Id': '23331'},16767:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given a DAG\n$G$\nand a vertex\n$v$\n, consider the following \ngame:\nWe can place a pebble on a vertex\n$u$\nif all its predecessors have pebbles on them.\nWe can remove a pebble from a vertex any time.\nThe goal is to place a pebble on the vertex\n$v$\n. THE goal is to reduce the number of pebbles\nneeded to pebble the vertex\n$v$\n. Consider the following language:\n{\n($G; v; p$)\n|\nthere is a pebbling strategy that uses at most\n$p$\npebbles and places a pebble on\n$v$\n}\nwhere\n$G$\nis a DAG. Show that the language is\nDSPACE\n(\n$O\n(\nn^2\n)$), where\n$n$\nis the\nnumber of vertices of\nG</p>\n', 'ViewCount': '17', 'ClosedDate': '2014-04-07T14:04:37.933', 'Title': 'pebbling is DSPACE($O(n^2)$)', 'LastActivityDate': '2014-04-07T11:50:54.337', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '-1', 'OwnerDisplayName': 'user3505352', 'PostTypeId': '1', 'OwnerUserId': '16533', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2014-04-07T05:34:47.737', 'Id': '23512'},16768:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I understand this is a slightly vague question, but there are results for P vs. NP, such as the question cannot be easily resolved using oracles. Are there any results like this which have been shown for P vs. NP but have not been shown for P vs PSPACE, so that there is hope that certain proof techniques might resolve P vs PSPACE even though they cannot resolve P vs NP? And are there any non-trivial results that say that if P = PSPACE then there are implications that do not necessarily hold under P = NP? Or anything else non-trivial in the literature that suggests it's easier to prove P != PSPACE than it is to prove P != NP?</p>\n", 'ViewCount': '96', 'Title': 'Has there been any more progress on P vs. PSPACE compared to P vs. NP?', 'LastActivityDate': '2014-04-13T22:02:49.173', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2014-04-13T18:27:42.120', 'FavoriteCount': '1', 'Id': '23745'},16769:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I would like to study some basic logspace algorithms. I have studied about the some of the problems, but most of the problems I am unable to follow in detai. Can some one suggest me the best references (books or lecture notes) where these explained clearly. </p>\n\n<p>Thank you.</p>\n', 'ViewCount': '32', 'ClosedDate': '2014-04-26T16:00:56.397', 'Title': 'On Logspace algorithms', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-26T16:01:06.850', 'LastEditDate': '2014-04-26T16:01:06.850', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6522', 'Tags': '<algorithms><reference-request><space-complexity>', 'CreationDate': '2014-04-25T13:56:42.783', 'Id': '24102'},16770:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I can't understand what my professor wrote about these inclusions concerning deterministic classes:</p>\n\n<p>$$\nDTIME(f) \\subseteq DSPACE(f) \\subseteq \\sum_{c\\in\\Bbb N}DTIME(2^{c(log+f)})  \n$$</p>\n\n<p>I understood the first inclusion:</p>\n\n<blockquote>\n  <p>The Turing Machine needs to do at least one step in order to check the\n  next cell on tape</p>\n</blockquote>\n\n<p>I didn't get the second one:</p>\n\n<blockquote>\n  <p>The number of configurations of the Turing Machine with fixed space is finite, and the computation must stop within a maximum number of steps equal to these settings, otherwise wewould have a cycle.</p>\n</blockquote>\n\n<p>I don't understand the argument of the summation: why that $2$ and that $c(log+f)$?\nWhy is it written like that?</p>\n", 'ViewCount': '78', 'Title': 'Inclusion of complexity classes (Deterministic Turing Machine)', 'LastActivityDate': '2014-04-28T17:47:37.320', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '24192', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17046', 'Tags': '<turing-machines><time-complexity><space-complexity><complexity-classes>', 'CreationDate': '2014-04-28T15:51:17.557', 'Id': '24185'}