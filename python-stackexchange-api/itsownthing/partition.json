{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>A <a href="http://en.wikipedia.org/wiki/Partition_of_a_set" rel="nofollow">partition of a set</a> S is a separation of the set into an arbitrary number of non-empty, pairwise disjoint subsets whose union is exactly S. What manner of a data structure should be used to represent a partition of a set if the following methods need to be optimized:</p>\n\n<ol>\n<li>moving an element from one part to another, possibly an entirely new one, and</li>\n<li>iterating over the parts of the partition.</li>\n</ol>\n\n<p>A naive way of prioritizing 1 would be a hash/tree/whatever mapping from set elements to "part labels", but iterating over the parts would require O(N) for first constructing the actual parts from the labels. 2 is naively prioritized as a hash/tree/whatever set of hash/tree/whatever sets, but then moving elements around, especially to new subsets, incurs that memory management overhead.</p>\n\n<p>Is there a way to get the best of both worlds? The implementation I need is Python but I imagine this is a cross-language question.</p>\n', 'ViewCount': '219', 'Title': 'Data structure for partition of a set', 'LastEditorUserId': '39', 'LastActivityDate': '2012-09-03T21:31:03.673', 'LastEditDate': '2012-09-03T21:31:03.673', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '4', 'OwnerDisplayName': 'user1448338', 'PostTypeId': '1', 'Tags': '<data-structures><partitions><sets>', 'CreationDate': '2012-07-12T16:32:56.523', 'Id': '3414'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p><a href="http://en.wikipedia.org/wiki/Partition_refinement">Partition refinement</a> is a technique in which you start with a finite set of objects and progressively split the set. Some problems, like DFA minimization, can be solved using partition refinement quite efficiently. I don\'t know of any other problems that are usually solved using partition refinement other than the ones listed on the Wikipedia page. Out of all these problems, the Wikipedia page mentions two for which algorithms based on partition refinement run in linear time. There\'s the lexicographically ordered topological sort [1] and an algorithm for <a href="http://en.wikipedia.org/wiki/Lexicographic_breadth-first_search">lexicographic breadth-first search</a> [2].</p>\n\n<blockquote>\n  <p>Are there any other examples or references to problems that can be solved using partition refinement very efficiently, meaning something better than loglinear in terms of time?</p>\n</blockquote>\n\n<hr>\n\n<p>[1] <a href="http://epubs.siam.org/doi/abs/10.1137/0205005">Sethi, Ravi, "Scheduling graphs on two processors", SIAM Journal on Computing 5 (1): 73\u201382, 1976.</a></p>\n\n<p>[2] <a href="http://epubs.siam.org/doi/abs/10.1137/0205021">Rose, D. J., Tarjan, R. E., Lueker, G. S., "Algorithmic aspects of vertex elimination on graphs", SIAM Journal on Computing 5 (2): 266\u2013283, 1976.</a></p>\n', 'ViewCount': '157', 'Title': 'Problems for which algorithms based on partition refinement run faster than in loglinear time', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-05T01:32:41.660', 'LastEditDate': '2012-10-04T22:21:19.390', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<algorithms><reference-request><data-structures><partitions><sets>', 'CreationDate': '2012-10-02T17:25:18.093', 'FavoriteCount': '1', 'Id': '4843'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given a set $A=\\{a_{1},a_{2},a_{3},\\ldots,a_{n}\\}$, then construct  a set $P=\\{p_{1}, p_{2}, p_{3}, \\ldots , p_{n}\\}$ such that</p>\n\n<ol>\n<li><p>$|p_{i}|=a_{i}$, and </p></li>\n<li><p>$\\sum_{i = 1,}^{n}p_{i} = 0$.</p></li>\n</ol>\n\n<p>This problem is NP-complete, which I want to prove.</p>\n\n<p>How do I do it? </p>\n\n<p>I am thinking of a reduction from the subset sum problem. But the problem is that because of the mod.</p>\n', 'ViewCount': '248', 'Title': 'Showing a partition-like problem is NP-complete', 'LastEditorUserId': '472', 'LastActivityDate': '2012-11-22T03:37:17.053', 'LastEditDate': '2012-11-22T03:37:17.053', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4635', 'Tags': '<np-complete><reductions><partitions>', 'CreationDate': '2012-11-19T06:31:23.380', 'Id': '6757'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a bunch of databases, each having different access patterns, such that each puts a different amount of load on its database cluster. I would like to distribute them around my set of database clusters such that the workload for the clusters is evenly distributed. </p>\n\n<p>I looked at the <a href="http://en.wikipedia.org/wiki/3-partition_problem" rel="nofollow"><em>k</em>-partition problem</a>, which sounds close to what I want, except each of my database clusters has a different load capacity. That means I need an algorithm that minimizes what percent of load capacity is used on all clusters, whereas the <em>k</em>-partition problem minimizes the integer load on each cluster. </p>\n\n<p>Does such an algorithm exist? And can anyone point me to a sample implementation of it?</p>\n', 'ViewCount': '113', 'Title': 'How to distribute items of varying sizes into bins of varying sizes, such that percent utilization across all bins is minimized?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-12-23T05:49:49.143', 'LastEditDate': '2012-12-23T05:49:49.143', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4679', 'Tags': '<algorithms><partitions>', 'CreationDate': '2012-11-21T16:44:16.083', 'FavoriteCount': '2', 'Id': '6821'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<blockquote>\n  <p><strong>Subset-sum:</strong> Given a list of numbers, find if a non-empty sublist has sum 0 (there\'s a variation where we want sum=k instead of 0, but 0 is easier for analysis)</p>\n  \n  <p><strong>Partition:</strong> Given a list, can it be partitioned into two non-empty sublists with equal sum?</p>\n</blockquote>\n\n<p>I want to reduce subset-sum to partition. The reductions I found so far are same as <a href="http://cs.stackexchange.com/questions/6111/how-can-i-reduce-subset-sum-to-partition">this one</a> but it has following faults :</p>\n\n<ol>\n<li>For $B=0$, you can always partition $L\'$ into $\\{2S-0\\}$, $\\{S+0\\} U L$.</li>\n<li>It supposes $2S-B$ and $S+B$ have to go to different partitions! You could have both of them in same partition along with elements that sum to $-S$, hence total sum $= 2S$ as needed.</li>\n</ol>\n', 'ViewCount': '284', 'Title': 'reducing subset-sum to partition', 'LastEditorUserId': '4717', 'LastActivityDate': '2012-11-25T05:55:50.390', 'LastEditDate': '2012-11-24T20:21:14.430', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '6882', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4717', 'Tags': '<complexity-theory><np-complete><reductions><partitions>', 'CreationDate': '2012-11-24T20:06:48.693', 'Id': '6877'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://en.wikipedia.org/wiki/3-partition_problem" rel="nofollow">3-Partition</a> problem is $\\mathsf{NP}$-Complete in a strong sense meaning there is no pseudo-polynomial time algorithm for it unless $\\mathsf{P}=\\mathsf{NP}$. I\'m looking for the fastest known exact algorithm that solves 3-Partition. Is there a fast (e.g subexponential) algorithm for 3-Partition? Is it possible to solve it faster than using SAT solvers?</p>\n', 'ViewCount': '284', 'LastEditorDisplayName': 'user742', 'Title': 'Fastest known algorithm for 3-Partition problem', 'LastActivityDate': '2013-03-27T15:53:45.660', 'LastEditDate': '2013-03-27T15:53:45.660', 'AnswerCount': '0', 'CommentCount': '10', 'Score': '4', 'OwnerDisplayName': 'user742', 'PostTypeId': '1', 'Tags': '<algorithms><np-complete><partition-problem>', 'CreationDate': '2013-03-26T12:06:40.963', 'Id': '10805'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '176', 'Title': 'What is a compact way to represent a partition of a set?', 'LastEditDate': '2013-04-16T00:36:16.213', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '7741', 'FavoriteCount': '2', 'Body': '<p>There exist <a href="http://cs.stackexchange.com/q/3414/7741">efficient data\nstructures</a> for representing set\npartitions. These data structures have good time complexities for operations\nlike Union and Find, but they are not particularly space-efficient.</p>\n\n<p><strong>What is a space-efficient way to represent a partition of a set?</strong></p>\n\n<p>Here is one possible starting point:</p>\n\n<p>I know that the <a href="http://en.wikipedia.org/wiki/Partition_of_a_set#Counting_partitions">number of\npartitions</a>\nof a set with $N$ elements is $B_N$, the $N$-th <a href="http://en.wikipedia.org/wiki/Bell_number">Bell\nnumber</a>. So the optimal space\ncomplexity for representing a partition of a set with $N$ elements is\n$\\log_2(B_N)$ bits. To find such a representation, we could look for a\none-to-one mapping between (the set of partitions of a set of $N$ elements) and\n(the set of integers from $1$ to $B_N$).</p>\n\n<p>Is there such a mapping that is efficient to compute? What I mean by\n"efficient" is that I want to convert this compact representation\nto / from an easy-to-manipulate representation (such as a list of lists) in time\npolynomial in $N$ or $\\log_2(B_N)$.</p>\n', 'Tags': '<data-structures><combinatorics><space-complexity><sets><partitions>', 'LastEditorUserId': '7741', 'LastActivityDate': '2013-04-17T19:39:41.237', 'CommentCount': '1', 'AcceptedAnswerId': '11348', 'CreationDate': '2013-04-16T00:14:19.900', 'Id': '11345'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Partition problem is a well known NP-complete problem. In the definitions I have seen, the input is assumed to be a multiset of integers and we want to decide the existance of a partition into two sets that have the same sum.</p>\n\n<blockquote>\n  <p>Is the partition problem still NP-complete if all input integers are distinct (no integer is repeated)?</p>\n</blockquote>\n', 'ViewCount': '82', 'Title': 'Partition problem with distinct integers', 'LastActivityDate': '2013-07-02T06:10:49.613', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13032', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete><partition>', 'CreationDate': '2013-07-02T05:03:25.180', 'Id': '13030'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been looking for an algorithm which divides an undirected, weighted, planar and simple graph into $k$ disjoint subgraphs. Here, the graph is sparse, $k$ is fixed, and there are no negative edge weights. After cutting, each subgraph must be connected (i.e. there must be a path between any two vertices of the subgraph which is only composed of vertices in that subgraph).</p>\n\n<p>However, unlike most existing work on graph partitioning out there, I don't intend to obtain subgraphs that contain the same approximate number of vertices. Instead, I would like these subgraphs to have similar sum of edge weights. In other words, I would like to minimize the sum of edge weights of the subgraph with maximal weight and ideally cut long (weighted) edges.</p>\n\n<p>Is there a name for this problem? I wasn't able to find anything about this on the web. Also, how can I approach this problem?</p>\n", 'ViewCount': '185', 'Title': 'Dividing a weighted planar graph into $k$ subgraphs with balanced weight', 'LastEditorUserId': '9431', 'LastActivityDate': '2013-11-06T15:14:17.837', 'LastEditDate': '2013-08-03T14:22:17.707', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9431', 'Tags': '<graph-theory><weighted-graphs><cluster><partition-problem>', 'CreationDate': '2013-08-02T04:01:20.273', 'FavoriteCount': '1', 'Id': '13571'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I know that the set partitioning problem defined like this:</p>\n\n<p>Given $S = \\left\\{ x_1, \\ldots x_n \\right\\}$, find $S_1$ and $S_2$ such that $S_1 \\cap S_2 = \\emptyset$, $S_1 \\cup S_2 = S$ and $\\sum_{x_i \\in S_1} x_i=\\sum_{x_i \\in S_2} x_i.$</p>\n\n<p>is NP-complete. But I don't understand why (or am not even sure if) the following problem is NP-complete:</p>\n\n<p>Given $S = \\left\\{ x_1, \\ldots x_n \\right\\}$, find $S_1$ and $S_2$ such that $S_1 \\cap S_2 = \\emptyset$, $S_1 \\cup S_2 = S$ and $\\vert \\sum_{x_i \\in S_1} x_i-\\sum_{x_i \\in S_2} x_i \\rvert$ is minimized.</p>\n\n<p>The paper 'The Differencing Method of Set Partitioning' by Karp and Karmarkar and some others say that it is NP-complete. But, if I have a sample solution to this problem, I can not tell whether it is an optimal solution (unlike in the first problem) and therefore I feel it NP-hard. If this is not true, how can I conclude that it is NP-complete? Thanks! </p>\n", 'ViewCount': '123', 'Title': 'Is the set partitioning problem NP complete?', 'LastActivityDate': '2013-12-09T18:45:42.057', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11962', 'Tags': '<complexity-theory><polynomial-time><partition-problem>', 'CreationDate': '2013-12-09T18:10:13.013', 'Id': '18782'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given array $A = \\{ a_{1},a_{2}, ..., a_{n}\\}$ and integer $k; 0 \\lt k \\le n$, partition array $A$ into $k$ subarrays, such that</p>\n\n<p>$A\'_{1} = \\{a_{1}, ...,a_{x}\\}$</p>\n\n<p>$A\'_{2} = \\{a_{x+1},...,a_{y}\\}$</p>\n\n<p>$...$</p>\n\n<p>$A\'_{k} = \\{a_{z+1},...,a_{n}\\}$</p>\n\n<p>where each subarray $A\'_{1},A\'_{2}, ...,A\'_{k}$ has sum of its elements closest to $\\sigma; \\sigma = \\frac{\\sum_{i = 1}^{n} {a_{i}}}{k}$</p>\n\n<p>Example:  $A = \\{{5,6,1,3,4,10\\}}, k = 3$</p>\n\n<p>$\\sigma = \\frac{29}{3} = 9.\\overline{66} \\approx 10$</p>\n\n<p>Best solution to split array is:</p>\n\n<p>$A\'_{1} = \\{5,6\\}$</p>\n\n<p>$A\'_{2} = \\{1,3,4\\}$</p>\n\n<p>$A\'_{3} = \\{10\\}$</p>\n\n<p>with sums $11, 8, 10$</p>\n\n<p>One way to measure "badness" of each solution, is to define function $h(A_{1},...,A_{k}) = \\sum_{i = 1}^{k} {(s_{i} - \\sigma)^2}$, where $s_{i}$ is sum of elements of subarray $A_{i}$</p>\n\n<p>Can you point me towards the solution? I\'ve been trying for a few days now, and I\'m no closer to an algorithm than I was few days ago.</p>\n', 'ViewCount': '112', 'Title': 'Partition array into K subsets, each with balanced sum', 'LastActivityDate': '2013-12-22T04:45:51.627', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12270', 'Tags': '<arrays><partitions>', 'CreationDate': '2013-12-21T22:44:40.127', 'Id': '19181'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Given are a 2D plane and a array of points in this plane, with every point having an integer value assigned.</p>\n\n<p>Is there an algorithm which, when given a ratio a/b, divides the plane with a straight line, so that the values of the points are distributed as close as possible to the given ratio? </p>\n\n<p>Points may be on the dividing line, then the are counted to the 'left/upper' partition.</p>\n", 'ViewCount': '53', 'Title': 'Partition points in a plane with a straigth line', 'LastActivityDate': '2013-12-28T20:30:41.743', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '19346', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11258', 'Tags': '<algorithms><computational-geometry><partition>', 'CreationDate': '2013-12-26T12:46:45.640', 'FavoriteCount': '0', 'Id': '19299'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I was proposed (in school) to develop an approach to solve optimally the balanced partition problem. I tried the pseudo-linear algorithms but SUM is very large (~1M) and so O(S*N) cant run under available time (1000ms). I talked to the teacher and with N =&lt; 60 he recommended the brute force (we are learning recursion). I've tried some approaches but I cant find a recursive algorithm that runs under 1 second. Its possible as some students got an solution that runs in less than 100ms.</p>\n\n<p>What is an efficient recursive approach to this problem given data with this magnitude?</p>\n", 'ViewCount': '27', 'LastEditorDisplayName': 'user14946', 'Title': 'Balanced partition problem for N =< 60 and very large sums', 'LastActivityDate': '2014-02-22T22:18:40.147', 'LastEditDate': '2014-02-22T22:18:40.147', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'OwnerDisplayName': 'user14946', 'PostTypeId': '1', 'Tags': '<np-complete><optimization><partition-problem>', 'CreationDate': '2014-02-22T22:09:20.530', 'Id': '21932'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>You are given two things: A fixed initial 'model' partition of an interval, e.g.</p>\n\n<pre><code>I------I---I-----I-------I----...\n</code></pre>\n\n<p>where each <code>-</code> or <code>I</code> represents an element in a discrete time series and the <code>I</code>s are the partition boundaries.  This can also be represented as a sequence of subinterval lengths, i.e. 7, 4, 6, 8, ...</p>\n\n<p>Then, you're given a new set of subinterval lengths; and the task is to arrange these in such a way as to get as many coincident <code>I</code>s as possible.  Or equivalently, you are given a new partition on an interval of the same length (though, critically, the new partition may have greater or fewer elements) and the task is to shuffle the subintervals around to maximize alignment.  So if the model was</p>\n\n<pre><code>I------I---I-----I-------I----I\n</code></pre>\n\n<p>and you are given 2, 11, 5, 12, i.e.</p>\n\n<pre><code>I-I----------I----I-----------I\n</code></pre>\n\n<p>then the solution would be 11, 2, 12, 5, </p>\n\n<pre><code>I----------I-I-----------I----I\n           *             *\n</code></pre>\n\n<p>achieving alignment at 2 locations (marked with an asterisk, compare to model).</p>\n\n<p>There is an additional constraint: The locations of the aligned subintervals must be distributed approximately randomly throughout the length of the solution.  The simplest means of getting a partition with at least some alignment to the model would be to build the new partition segment by segment, drawing without replacement from the collection of test segments, aligning where possible.  But this would strongly bias the occurrences of alignment towards the beginning of the time series, and is therefore not allowed.  There is of course also the brute force O(n!) enumeration but my series are little too long for that.</p>\n\n<p>Naturally a solution that finds the optimal permutation would be great, but one that is efficient and gets a permutation with a substantial fraction of the possible alignment would also be good.  My current version is a variation on the 'simple' algorithm derived above, except only drawing from a small subcollection of subintervals so as to avoid bias.  I know it can be improved upon!</p>\n", 'ViewCount': '66', 'Title': 'Permute the subintervals of an interval partition to most closely align with a model partition', 'LastEditorUserId': '16410', 'LastActivityDate': '2014-04-03T23:56:25.543', 'LastEditDate': '2014-04-03T12:56:05.663', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '23405', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16410', 'Tags': '<algorithms><permutations><partitions>', 'CreationDate': '2014-04-03T11:28:45.423', 'Id': '23391'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a problem in which I need to find an optimal graph cut that maximizes an objective over vertices (versus edge weights). I have looked at the literature but have not been able to find any similar problems to which I can map to. Perhaps someone can give some insight or point me to a similar problem from the graph theory literature.</p>\n\n<p>The problem is as follows, given a graph $G=(V,E)$, where there exists a path from any vertex $x_i$ to any other vertex $x_j$ (1 connected component) and each vertex has an associated weight $w_j$. Find a partition which removes $E_p$ edges $(E_p \\subset E)$ to create exactly $k$ connected components. The partition seeks to maximize a function over the $k$ subgraphs $\\sum\\limits_{i=1}^k f(W_i)$ where $W_i$ is the set of all weights on vertices in subgraph $i$. The $f$ I am specifically interested in is $f(W_i)=|W_i|\\,\\mathrm{mean}(W_i)^2 $, but I think any resources for a similar problem with a different $f$ would be helpful. </p>\n', 'ViewCount': '41', 'Title': 'Edge cuts with vertex weights', 'LastEditorUserId': '16985', 'LastActivityDate': '2014-04-23T08:03:23.563', 'LastEditDate': '2014-04-23T08:03:23.563', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '16985', 'Tags': '<graph-theory><cluster><partition-problem>', 'CreationDate': '2014-04-22T12:27:06.003', 'FavoriteCount': '1', 'Id': '24026'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Assume I have some positive numbers $a_1,\\ldots,a_n$ and a number $k \\in \\mathbb{N}$. </p>\n\n<p>I want to partition these numbers into exactly $k$ sets $A_1,\\ldots,A_k$ such that the weighted arithmetic mean</p>\n\n<p>$$\\text{cost}(A_i,\\ldots,A_k)=\\sum_{i=1}^{k}\\frac{|A_i|}{n}c(A_i)$$</p>\n\n<p>is minimal, where $c(A_i)=\\sum_{a \\in A_i}a$ is simply the sum of all numbers in $A_i$.</p>\n\n<p>Is there actually a (polynomial) algorithm to do this or is this a (<strong>NP</strong>) hard problem? </p>\n\n<p>I tried to reduce it to some NP-hard problems but didn't get anywhere, especially because the numbers are nonnegative and thus in an optimal partition big sets need to have smaller weight which seems to be some kind of balancing problem instead of a packing problem (which I am more familiar with).</p>\n", 'ViewCount': '23', 'Title': 'Minimum weighted arithmetic mean partion?', 'LastEditorUserId': '6970', 'LastActivityDate': '2014-04-29T20:54:41.280', 'LastEditDate': '2014-04-29T20:19:59.883', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24234', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6970', 'Tags': '<optimization><np-hard><np><partitions>', 'CreationDate': '2014-04-29T20:10:23.417', 'Id': '24232'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I understand Partition Problem is NP-complete.</p>\n\n<p>Given we have a magic black box that can answer Yes or No for the partition problem. I was wondering how to come up with a polynomial time algorithm to find the actual set using this black box. </p>\n\n<p>Thank you. </p>\n', 'ViewCount': '12', 'Title': 'How to find partition set of a Partition Problem using its decision problem', 'LastActivityDate': '2014-05-01T00:50:48.473', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24280', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17233', 'Tags': '<complexity-theory><np-complete><partition-problem>', 'CreationDate': '2014-05-01T00:39:31.503', 'Id': '24279'}}