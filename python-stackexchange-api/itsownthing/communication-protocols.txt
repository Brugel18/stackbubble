{'Body': "<p>I need to recover a data block from a repeated stream of data. I'm looking to see what algorithms may already exist for this as it does not feel like a novel situation.</p>\n\n<p>Here are the specifics:</p>\n\n<ol>\n<li>There is an N-length block of data contained in a stream</li>\n<li>The block is repeated many times in the stream</li>\n<li>the data is highly corrupted, some bytes could just be wrong, where as others can be detected as missing (erasures)</li>\n<li>There is a function <code>F(data)</code> which can say if a block represents valid data (the probability of a false positive is virtually zero)</li>\n<li><code>F</code> can also provide a probability value that even if the block is not valid data whether the block itself is valid (but just has too much corruption to be recovered)</li>\n<li>The chance of corrupted data is very low compared to missing data</li>\n</ol>\n\n<p>For example, say I have this data stream and wish to recover the 10 length sequence <code>1234567890</code>. The data is just a rough visual example (I can't guarantee recovery is actually possible from this bit). A <code>.</code> represents a missing byte, and <code>&lt;break&gt;</code> indicates an unknown block of data (no data  and not length known). Note also the <code>Q</code>s as an example of corrupt data.</p>\n\n<p><code>23.5678901.3456789&lt;break&gt;2345678..1..4567QQ012345678..3456</code></p>\n\n<p>How can I take such a stream of data and recovery probably blocks of N data? As the actual data includes forward error recovery the block recovery need not be perfect. All it needs to do is give probable reconstructed blocks of data and the <code>F</code> function will attempt to do error recovery.  Thus I expect <code>F</code> fill have to be called several times. </p>\n\n<p>I'd like to find something better than simply calling <code>F</code> at each point in the stream since the error rate could be high enough that no single run block of N can be recovered -- the repetitions in the stream must be used somehow.</p>\n", 'ViewCount': '41', 'Title': 'Block detection in repeated stream', 'LastEditorUserId': '1642', 'LastActivityDate': '2012-05-25T11:53:58.550', 'LastEditDate': '2012-05-25T11:53:58.550', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2072', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1642', 'Tags': '<algorithms><online-algorithms><communication-protocols>', 'CreationDate': '2012-05-25T04:33:48.567', 'Id': '2064'}{'ViewCount': '222', 'Title': 'Why is it seemingly easier to resume torrent downloads than browser downloads?', 'LastEditDate': '2012-06-07T22:37:41.390', 'AnswerCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1414', 'FavoriteCount': '0', 'Body': '<p>I really wonder how torrent downloads can be resumed at later point of time.\nIf such a technology exists, then why is it not possible in browsers?</p>\n\n<p>It is often not possible to pause a browser download so that it can be resumed at a later point of time. Often, the download will start again from the beginning. But in the case of a torrent download, you can resume anytime.</p>\n\n<p>One reason I could think of is that a browser makes an HTTP connection to the server which contains the file, and when this connection breaks, there is no data regarding how much file was saved so no resume is possible.</p>\n\n<p>Is there a fundamental reason why torrent downloads are easier to resume than web downloads?</p>\n', 'Tags': '<computer-networks><communication-protocols>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-08T00:40:40.473', 'CommentCount': '2', 'AcceptedAnswerId': '2268', 'CreationDate': '2012-06-07T11:05:30.010', 'Id': '2251'}{'Body': '<p>I\'m looking at collision detection in communication protocols, in particular <a href="http://en.wikipedia.org/wiki/Carrier_sense_multiple_access_with_collision_detection" rel="nofollow">Carrier sense multiple access with collision detection (CSMA/CD)</a>. According to what I\'ve read on Wikipedia, a collision seems to cause the wave of the outgoing signal and the wave of the incoming signal to overlap. Thus, the signal has values with more amplitude than allowed for a "1-bit". This could be used as a working collision detection algorithm.</p>\n\n<p>However, what\'s the use of the "Jam signal", as explained in <a href="http://en.wikipedia.org/wiki/Carrier_sense_multiple_access_with_collision_detection" rel="nofollow">the same Wikipedia article</a>, then? It says that the CRC has to be faulted, but we already have a collision detection algorithm.</p>\n', 'ViewCount': '308', 'Title': 'Jamming signal useless in CSMA / CD?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-15T20:44:57.460', 'LastEditDate': '2013-01-15T20:44:57.460', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '8949', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '3181', 'Tags': '<computer-networks><communication-protocols><encoding-scheme>', 'CreationDate': '2013-01-15T07:55:13.747', 'Id': '8943'}{'Body': "<p>This is what I know:</p>\n\n<ul>\n<li>GBN weakness is the fact that when the window size is too large, the number of packets in the pipeline grows and one packet error causes the retransmition of many packets unnecessarily. </li>\n<li>Selective Repeat solves this by acknowleding just the suspicious packets, which sightly makes performance better, but if a wrong window size is chosen, then the reciever doesn't know if a packet is being retransmitted or another packet is being sent by first time.</li>\n</ul>\n\n<p>So, back to the question, what other important performance differences exists between these protocols?</p>\n", 'ViewCount': '3018', 'Title': 'Performance differences between Go-Back-N and Selective Repeat ARQ protocols?', 'LastEditorUserId': '7492', 'LastActivityDate': '2013-05-12T07:31:21.147', 'LastEditDate': '2013-05-05T15:45:27.530', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11960', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7492', 'Tags': '<computer-networks><communication-protocols>', 'CreationDate': '2013-05-02T02:20:04.770', 'Id': '11715'}{'Body': "<p>Suppose I type in the website <code> www.youtube.com.</code> The computer first asks a local domain name server (DNS) what the IP address of this website is. If it can't find it, it then asks the root server, etc. This is recursive querying. </p>\n\n<p>How does DNS work if there is no recursive querying? Is the root server the only one that is used to find the IP address of the website?</p>\n", 'ViewCount': '208', 'Title': 'How does DNS work if there is no recursive querying?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-09-20T18:27:37.903', 'LastEditDate': '2013-09-19T13:35:42.077', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10224', 'Tags': '<computer-networks><communication-protocols>', 'CreationDate': '2013-09-19T13:07:06.660', 'Id': '14440'}{'Body': '<p>I am having trouble understanding how TCP works. I have looked at the Wikipedia page and there references, and I cannot seem to understand the table showing the TCP segment structure.</p>\n\n<p>I understand that TCP is a way to ensure that the file that is being sent through the Internet comes through completed. IP is often referred to as TCP/IP as TCP is commonly used. TCP is slower than IP request (in milliseconds). TCP divides a file up to be sent through IP requests and re-assembled on the other side, and does checks through-out the process to ensure all segments come through, and error free, if there is an error or missing segment, it sends a request to get the missing/broke segment.</p>\n\n<p><a href="http://en.wikipedia.org/wiki/Transmission_Control_Protocol#TCP_segment_structure" rel="nofollow">TCP segment structure</a> </p>\n\n<p>This is for my COMP 200 course. I will be using answers here in my paper, cited and credited.</p>\n\n<p>EDIT--</p>\n\n<p>I believe I am miss-reading the table shown in the link.</p>\n\n<p>Tell me if I am wrong but when I see the TCP segment I see the source port and destination port as a line of code 32 bits in length consisting of 0\'s and 1\'s the first 16 bit are the source port the second set is the destination port.</p>\n\n<p>0110100111010100 0110010111100110</p>\n\n<p>and then the rest in the table. It is the table that is throwing me off I do not understand what is happening.</p>\n', 'ViewCount': '39', 'ClosedDate': '2013-11-15T16:08:26.287', 'Title': 'How does TCP work', 'LastEditorUserId': '11390', 'LastActivityDate': '2013-11-15T04:20:03.310', 'LastEditDate': '2013-11-15T04:20:03.310', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11390', 'Tags': '<communication-protocols>', 'CreationDate': '2013-11-15T03:12:26.323', 'Id': '18037'}{'Body': '<p>What is a known strategy to approach a situation where short bursts of data are being sent very often over a high bandwidth, high latency cable? I am aware of cubic but even that does not utilize a 10GBps cable in a short burst scenario.</p>\n\n<p>Lets say I have a distributed network where a single computer is sending tasks to many other computers. The computers then respond with a short answer 50-100KB. We need to receive these answers as quickly as possible.</p>\n\n<p>What are the consideration and do we determine the optimal initial congestion window size? </p>\n\n<p>Assumptions:</p>\n\n<ol>\n<li>Using TCP Cubic.</li>\n<li>Bursts are arrive with a Poisson distribution.</li>\n<li>Goal is to get the data as quickly as possible.</li>\n<li>Two scenarios, limited or vast buffer size.</li>\n</ol>\n', 'ViewCount': '23', 'Title': 'Picking an optimal initial congestion window size (high bw, high latency and short bursts)?', 'LastEditorUserId': '14875', 'LastActivityDate': '2014-04-23T13:15:33.887', 'LastEditDate': '2014-04-23T13:15:33.887', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14875', 'Tags': '<computer-networks><network-flow><communication-protocols>', 'CreationDate': '2014-03-18T19:07:01.763', 'Id': '22765'}{'Body': '<p>I\'m studying Distributed Systems and synchronization and I didn\'t catch this solution of totally ordered multicast with Lamport timestamps. I read that it doesn\'t need ack to deliver a message to the application, but</p>\n\n<blockquote>\n  <p>"It is sufficient to multicast any other type of message, as long as that message has a timestamp larger than the received message. The condition for delivering a message m to the application, is that another message has been received from each other process with a large timestamp. This guarantees that there are no more messages underway with a lower timestamp."</p>\n</blockquote>\n\n<p>This is a definition from a book. I tried to apply this definition to an example but I guess that something is wrong.</p>\n\n<h3>Example.</h3>\n\n<blockquote>\n  <p>There are 4 processes and they multicast the following messages (second number in parentheses is timestamp) :<br>\n  P1 multi-casts (m11, 5);  (m12, 12); (m13, 14);<br>\n  P2 multi-casts (m21, 6); (m22, 14);<br>\n  P3 multi-casts (m31, 5); (m32, 7); (m33, 11);<br>\n  P4 multi-casts (m41, 8); (m42, 15); (m43, 19).</p>\n</blockquote>\n\n<p>Supposing that there are no acknoledgments, can I guess which messages can be delivered and which not? Based on definition, my guess is that only m11 and m31 can be delivered to the application, because all the other messages received will have a timestamp greater, but this seems very strange, and I think I didn\'t understand the delivery condition very well. I have an exam next week and in general I\'d like to understand this mechanism.</p>\n', 'ViewCount': '73', 'Title': 'totally ordered multicast with Lamport timestamp', 'LastEditorUserId': '16819', 'LastActivityDate': '2014-04-20T13:25:52.457', 'LastEditDate': '2014-04-20T13:25:52.457', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '16819', 'Tags': '<distributed-systems><computer-networks><synchronization><communication-protocols><message-passing>', 'CreationDate': '2014-04-16T07:26:03.173', 'FavoriteCount': '1', 'Id': '23847'}{'Body': '<p>Why does packet don\'t need trailer/footer while frame needs it?</p>\n\n<p>I am trying to understand networking concept regarding OSI &amp; TCP/IP layering. I have googled a bit and it says that the footer in data link layer pdu (frame) is needed as a mark of the end of the pdu.</p>\n\n<p>But why does packet data etc in the layers above it doesn\'t need footer to mark the end of the pdu as well?</p>\n\n<p><img src="http://i.stack.imgur.com/ndZjU.gif" alt="enter image description here"></p>\n', 'ViewCount': '18', 'Title': "Why does packet data don't need trailer/footer while frame needs it?", 'LastEditorUserId': '13022', 'LastActivityDate': '2014-04-21T07:28:28.700', 'LastEditDate': '2014-04-21T07:28:28.700', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16948', 'Tags': '<computer-networks><communication-protocols>', 'CreationDate': '2014-04-21T06:35:21.200', 'Id': '23976'}