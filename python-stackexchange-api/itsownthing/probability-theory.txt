{'Body': '<p>You have one coin. You may flip it as many times as you want. </p>\n\n<p>You want to generate a random number $r$ such that $a \\leq r &lt; b$ where $r,a,b\\in \\mathbb{Z}^+$. </p>\n\n<p>Distribution of the numbers should be uniform. </p>\n\n<p>It is easy if $b -a = 2^n$:</p>\n\n<pre><code>r = a + binary2dec(flip n times write 0 for heads and 1 for tails) \n</code></pre>\n\n<p>What if $b-a \\neq 2^n$?</p>\n', 'ViewCount': '2142', 'Title': 'Generating uniformly distributed random numbers using a coin', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-24T21:55:20.950', 'LastEditDate': '2012-04-29T20:51:09.547', 'AnswerCount': '7', 'CommentCount': '0', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '244', 'Tags': '<algorithms><probability-theory><randomness><random-number-generator>', 'CreationDate': '2012-03-21T03:12:00.883', 'FavoriteCount': '4', 'Id': '570'}{'ViewCount': '292', 'Title': 'What are the uses of Markov Chains in CS?', 'LastEditDate': '2012-05-16T23:21:38.910', 'AnswerCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '147', 'FavoriteCount': '2', 'Body': "<p>We all know that Markov Chains can be used for generating real-looking text (or real-sounding music). I've also heard that Markov Chains has some applications in the image processing, is that true? What are some other uses of MCs in CS?</p>\n", 'ClosedDate': '2014-02-02T01:34:04.247', 'Tags': '<probability-theory><markov-chains>', 'LastEditorUserId': '39', 'LastActivityDate': '2014-01-25T16:51:31.947', 'CommentCount': '13', 'CreationDate': '2012-03-22T16:36:41.237', 'Id': '663'}{'Body': '<p>This problem is taken from <a href="https://www.interviewstreet.com/challenges/dashboard/#problem/4eed18ded76fe">interviewstreet.com</a></p>\n\n<p>We are given an array of integers $Y=\\{y_1,...,y_n\\}$ that represents $n$ line segments such that endpoints of segment $i$ are $(i, 0)$ and $(i, y_i)$. Imagine that from the top of each segment a horizontal ray is shot to the left, and this ray stops when it touches another segment or it hits the y-axis. We construct an array of n integers, $v_1, ..., v_n$, where $v_i$ is equal to length of ray shot from the top of segment $i$. We define $V(y_1, ..., y_n)\r\n= v_1 + ... + v_n$.</p>\n\n<p>For example, if we have $Y=[3,2,5,3,3,4,1,2]$, then $[v_1, ..., v_8] = [1,1,3,1,1,3,1,2]$, as shown in the picture below:</p>\n\n<p><img src="http://i.stack.imgur.com/bZ04e.png" alt="enter image description here"></p>\n\n<p>For each permutation $p$ of $[1,...,n]$, we can calculate $V(y_{p_1}, ..., y_{p_n})$. If we choose a uniformly random permutation $p$ of $[1,...,n]$, what is the expected value of $V(y_{p_1}, ..., y_{p_n})$?</p>\n\n<p>If we solve this problem using the naive approach it will not be efficient and run practically forever for $n=50$. I believe we can approach this problem by indepdently calculating the expected value of $v_i$ for each stick but I still need to know wether there is another efficient approach for this problem. On what basis can we calculate the expected value for each stick independently?</p>\n', 'ViewCount': '899', 'Title': 'How to approach Vertical Sticks challenge', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-10T11:00:33.150', 'LastEditDate': '2012-04-06T17:28:56.150', 'AnswerCount': '5', 'CommentCount': '1', 'Score': '16', 'OwnerDisplayName': 'Anantha Krishnan', 'PostTypeId': '1', 'Tags': '<algorithms><probability-theory>', 'CreationDate': '2012-04-06T07:44:24.677', 'FavoriteCount': '2', 'Id': '1076'}{'Body': '<p>I was interested on evaluating a catalogue that students would be using to observe how is it being used probabilistically. </p>\n\n<p>The catalogue works by choosing cells in a temporal sequence, so for example:</p>\n\n<ul>\n<li>Student A has: ($t_1$,$Cell_3$),($t_2$,$Cell_4$)</li>\n<li>Student B has: $(t_1,Cell_5),(t_2,Cell_3),(t_3,Cell_7)$. </li>\n</ul>\n\n<p>Assume that the cells of the table are states of a <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Model</a>, so the transition between states would map in the real world to a student going from a given cell to another.</p>\n\n<p>Assuming that the catalogue is nothing more than guidance, it is expected to have a certain kind of phenomenon to occur on a given artifact. Consider this artifact to be unique, say, for example a program. </p>\n\n<p>What happens to this program is a finite list of observations, thus, for a given cell we have a finite list of observations for following the suggestion mentioned on that cell. On a HMM this would be then the probability associated to a state to generate a given observation in this artifact. </p>\n\n<p>Finally, consider the catalogue to be structured in a way that initially it is expected that the probability to start in a given cell is equal. The catalogue does not suggest any starting point. </p>\n\n<ul>\n<li><p><strong>Question 1</strong>: Is the mapping between the catalogue and the HMM appropriate?</p></li>\n<li><p><strong>Question 2</strong>: Assuming question 1 holds true. Consider now that we train the HMM using as entries $(t_1,Cell_1), (t_2,Cell_3) , ... (t_n,Cell_n)$ for the students. Would the trained HMM, once asked to generate the transition between states that it is most likely yields as result what is the most used way by the people who used the catalogue for a given experiment $\\epsilon$? </p></li>\n</ul>\n', 'ViewCount': '74', 'Title': 'Is it viable to use an HMM to evaluate how well a catalogue is used?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-19T02:04:32.233', 'LastEditDate': '2012-04-22T16:09:37.950', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '1132', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<probability-theory><empirical-research><modelling><hidden-markov-models>', 'CreationDate': '2012-04-07T23:04:00.013', 'Id': '1122'}{'ViewCount': '260', 'Title': 'How does variance in task completion time affect makespan?', 'LastEditDate': '2012-04-13T22:15:45.380', 'AnswerCount': '2', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '69', 'FavoriteCount': '0', 'Body': "<p>Let's say that we have a large collection of tasks $\\tau_1, \\tau_2, ..., \\tau_n$ and a collection of identical (in terms of performance) processors $\\rho_1, \\rho_2, ..., \\rho_m$ which operate completely in parallel. For scenarios of interest, we may assume $m \\leq n$. Each $\\tau_i$ takes some amount of time/cycles to complete once it is assigned to a processor $\\rho_j$, and once it is assigned, it cannot be reassigned until completed (processors always eventually complete assigned tasks). Let's assume that each $\\tau_i$ takes an amount of time/cycles $X_i$, not known in advance, taken from some discrete random distribution. For this question, we can even assume a simple distribution: $P(X_i = 1) = P(X_i = 5) = 1/2$, and all $X_i$ are pairwise independent. Therefore $\\mu_i = 3$ and $\\sigma^2 = 4$.</p>\n\n<p>Suppose that, statically, at time/cycle 0, all tasks are assigned as evenly as possible to all processors, uniformly at random; so each processor $\\rho_j$ is assigned $n/m$ tasks (we can just as well assume $m | n$ for the purposes of the question). We call the makespan the time/cycle at which the last processor $\\rho^*$ to finish its assigned work, finishes the work it was assigned. First question:</p>\n\n<blockquote>\n  <p>As a function of $m$, $n$, and the $X_i$'s, what is the makespan $M$? Specifically, what is $E[M]$? $Var[M]$?</p>\n</blockquote>\n\n<p>Second question:</p>\n\n<blockquote>\n  <p>Suppose $P(X_i = 2) = P(X_i = 4) = 1/2$, and all $X_i$ are pairwise independent, so $\\mu_i = 3$ and $\\sigma^2 = 1$. As a function of $m$, $n$, and these new $X_i$'s, what is the makespan? More interestingly, how does it compare to the answer from the first part?</p>\n</blockquote>\n\n<p>Some simple thought experiments demonstrate the answer to the latter is that the makespan is longer. But how can this be quantified? I will be happy to post an example if this is either (a) controversial or (b) unclear. Depending on the success with this one, I will post a follow-up question about a dynamic assignment scheme under these same assumptions. Thanks in advance!</p>\n\n<p><strong>Analysis of an easy case: $m = 1$</strong></p>\n\n<p>If $m = 1$, then all $n$ tasks are scheduled to the same processor. The makespan $M$ is just the time to complete $n$ tasks in a complete sequential fashion. Therefore,\n$$\\begin{align*}\r\n E[M]\r\n &amp;= E[X_1 + X_2 + ... + X_n] \\\\\r\n &amp;= E[X_1] + E[X_2] + ... + E[X_n] \\\\\r\n &amp;= \\mu + \\mu + ... + \\mu \\\\\r\n &amp;= n\\mu\r\n\\end{align*}$$\nand\n$$\\begin{align*}\r\n Var[M]\r\n &amp;= Var[X_1 + X_2 + ... + X_n] \\\\\r\n &amp;= Var[X_1] + Var[X_2] + ... + Var[X_n] \\\\\r\n &amp;= \\sigma^2 + \\sigma^2 + ... + \\sigma^2 \\\\\r\n &amp;= n\\sigma^2 \\\\\r\n\\end{align*}$$</p>\n\n<p>It seems like it might be possible to use this result to answer the question for $m &gt; 1$; we simply need to find an expression (or close approximation) for $\\max(Y_1, Y_2, ..., Y_m)$ where $Y_i = X_{i\\frac{n}{m} + 1} + X_{i\\frac{n}{m} + 2} + ... + X_{i\\frac{n}{m} + \\frac{n}{m}}$, a random variable with $\\mu_Y = \\frac{n}{m}\\mu_X$ and $\\sigma_Y^2 = \\frac{n}{m}\\sigma_X^2$. Is this heading in the right direction?</p>\n", 'Tags': '<probability-theory><scheduling><parallel-computing>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-07T11:20:11.647', 'CommentCount': '1', 'AcceptedAnswerId': '1251', 'CreationDate': '2012-04-12T20:03:55.620', 'Id': '1236'}{'ViewCount': '1359', 'Title': 'Randomized Selection', 'LastEditDate': '2012-04-18T19:51:56.180', 'AnswerCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1134', 'FavoriteCount': '2', 'Body': u'<p>The randomized selection algorithm is the following:</p>\n\n<p>Input: An array $A$ of $n$ (distinct, for simplicity) numbers and a number $k\\in [n]$</p>\n\n<p>Output: The the "rank $k$ element" of $A$ (i.e., the one in position $k$ if $A$ was sorted)</p>\n\n<p>Method:</p>\n\n<ul>\n<li>If there is one element in $A$, return it</li>\n<li>Select an element $p$ (the "pivot") uniformly at random</li>\n<li>Compute the sets $L = \\{a\\in A : a &lt; p\\}$ and $R = \\{a\\in A : a &gt; p\\}$</li>\n<li>If $|L| \\ge k$, return the rank $k$ element of $L$.</li>\n<li>Otherwise, return the rank $k - |L|$ element of $R$</li>\n</ul>\n\n<p>I was asked the following question:</p>\n\n<blockquote>\n  <p>Suppose that $k=n/2$, so you are looking for the median, and let $\\alpha\\in (1/2,1)$\n  be a constant.  What is the probability that, at the first recursive call, the \n  set containing the median has size at most $\\alpha n$?</p>\n</blockquote>\n\n<p>I was told that the answer is $2\\alpha - 1$, with the justification "The pivot selected should lie between $1\u2212\\alpha$ and $\\alpha$ times the original array"</p>\n\n<p>Why? As $\\alpha \\in (0.5, 1)$, whatever element is chosen as pivot is either larger or smaller than more than half the original elements. The median always lies in the larger subarray, because the elements in the partitioned subarray are always less than the pivot. </p>\n\n<p>If the pivot lies in the first half of the original array (less than half of them), the median will surely be in the second larger half, because once the median is found, it must be in the middle position of the array, and everything before the pivot is smaller as stated above. </p>\n\n<p>If the pivot lies in the second half of the original array (more than half of the elements), the median will surely first larger half, for the same reason, everything before the pivot is considered smaller. </p>\n\n<p>Example:</p>\n\n<p>3 4 5 8 7 9 2 1 6 10</p>\n\n<p>The median is 5.</p>\n\n<p>Supposed the chosen pivot is 2. So after the first iteration, it becomes:</p>\n\n<p>1 2 ....bigger part....</p>\n\n<p>Only <code>1</code> and <code>2</code> are swapped after the first iteration. Number 5 (the median) is still in the first greater half (accroding to the pivot 2). The point is, median always lies on greater half, how can it have a chance to stay in a smaller subarray?</p>\n', 'Tags': '<algorithms><algorithm-analysis><probability-theory><randomized-algorithms>', 'LastEditorUserId': '657', 'LastActivityDate': '2012-04-18T19:51:56.180', 'CommentCount': '5', 'AcceptedAnswerId': '1343', 'CreationDate': '2012-04-18T08:21:27.190', 'Id': '1334'}{'ViewCount': '250', 'Title': 'Algorithm to chase a moving target', 'LastEditDate': '2012-04-20T22:53:41.330', 'AnswerCount': '1', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '69', 'FavoriteCount': '4', 'Body': "<p>Suppose that we have a black-box $f$ which we can query and reset. When we reset $f$, the state $f_S$ of $f$ is set to an element chosen uniformly at random from the set $$\\{0, 1, ..., n - 1\\}$$ where $n$ is fixed and known for given $f$. To query $f$, an element $x$ (the guess) from $$\\{0, 1, ..., n - 1\\}$$ is provided, and the value returned is $(f_S - x) \\mod n$. Additionally, the state $f_S$ of$f$ is set to a value $f_S&#39; = f_S \\pm k$, where $k$ is selected uniformly at random from $$\\{0, 1, 2, ..., \\lfloor n/2 \\rfloor - ((f_S - x) \\mod n)\\} $$</p>\n\n<p>By making uniformly random guesses with each query, one would expect to have to make $n$ guesses before getting $f_S = x$, with variance $n^2 - n$ (stated without proof).</p>\n\n<p>Can an algorithm be designed to do better (i.e., make fewer guesses, possibly with less variance in the number of guesses)? How much better could it do (i.e., what's an optimal algorithm, and what is its performance)?</p>\n\n<p>An efficient solution to this problem could have important cost-saving implications for shooting at a rabbit (confined to hopping on a circular track) in a dark room.</p>\n", 'Tags': '<algorithms><probability-theory><randomized-algorithms>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-04-10T13:45:31.237', 'CommentCount': '3', 'AcceptedAnswerId': '1976', 'CreationDate': '2012-04-20T14:48:58.600', 'Id': '1392'}{'Body': '<p>Let $a \\neq b$ be two integers from the interval $[1, 2^n].$ Let $p$ be a random prime with $ 1 \\le p \\le n^c.$ Prove that\n$$\\text{Pr}_{p \\in \\mathsf{Primes}}\\{a \\equiv  b \\pmod{p}\\} \\le c \\ln(n)/(n^{c-1}).$$</p>\n\n<p>Hint: As a consequence of the prime number theorem, exactly $n/ \\ln(n) \\pm o(n/\\ln(n))$ many numbers from $\\{ 1, \\ldots, n \\}$ are prime.</p>\n\n<p>Conclusion: we can compress $n$ bits to $O(\\log(n))$ bits and get a quite small false-positive rate.</p>\n\n<p>My question is how can i proove that $$\\text{Pr}_{p \\in \\mathsf{Primes}}\\{a \\equiv  b \\pmod{p}\\} \\le c \\ln(n)/(n^{c-1})$$?</p>\n', 'ViewCount': '118', 'Title': 'Prove fingerprinting', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-06T23:19:40.733', 'LastEditDate': '2012-05-06T22:16:55.400', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1704', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1393', 'Tags': '<probability-theory><information-theory><coding-theory><number-theory>', 'CreationDate': '2012-05-06T18:34:00.527', 'Id': '1692'}{'Body': u"<p>Consider a board of $n$ x $n$ cells, where $n = 2k, k\u22652$. Each of the numbers from $S = \\left\\{1,...,\\frac{n^2}{2}\\right\\}$ is written to two cells so that each cell contains exactly one number.</p>\n\n<p>How can I show that $n$ cells $c_{i, j}$ can be chosen with one cell per row and one cell per column such that no pair of cells contains the same number.</p>\n\n<p>This was an example problem for an exam I'm studying for. I tried it now for several hours but I can't get it right. I think random permutations can help here but I am not sure.</p>\n", 'ViewCount': '148', 'Title': 'Extracting non-duplicate cells in a particular matrix with repeated entries', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-14T22:26:26.120', 'LastEditDate': '2012-05-13T08:48:33.960', 'AnswerCount': '2', 'CommentCount': '14', 'AcceptedAnswerId': '1817', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1393', 'Tags': '<combinatorics><probability-theory>', 'CreationDate': '2012-05-12T09:44:44.333', 'Id': '1803'}{'ViewCount': '79', 'Title': 'Making random sources uniformly distributed', 'LastEditDate': '2012-05-19T14:50:50.590', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1393', 'FavoriteCount': '0', 'Body': '<p>How do I build a random source that outputs the bits 0 and 1 with $prob(0) = prob(1) = 0.5$. We have access to another random source $S$ that outputs $a$ or $b$ with independent probabilities $prob(a)$ and $prob(b) = 1 - prob(a)$ that are unknown to us.</p>\n\n<p>How do I state an algorithm that does the job and that does not consume more than an expected number of\n$(prob(a) \\cdot prob(b))^{-1}$ symbols of $S$ between two output bits and prove its correcteness?</p>\n', 'Tags': '<algorithms><probability-theory><randomized-algorithms><randomness>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-19T19:13:23.613', 'CommentCount': '1', 'AcceptedAnswerId': '1934', 'CreationDate': '2012-05-19T14:14:55.337', 'Id': '1921'}{'ViewCount': '174', 'Title': 'Deterministic and randomized communication complexity of set equality', 'LastEditDate': '2012-06-06T13:47:19.663', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1393', 'FavoriteCount': '1', 'Body': u'<p>Two processors $A, B$ with inputs $a \\in  \\{0, 1\\}^n$ (for $A$) and $b \\in  \\{0, 1\\}^n$\n(for $B$) want to decide whether $a = b$. $A$ does not know $B$\u2019s input and vice versa.</p>\n\n<p>A can send a message $m(a) \\in  \\{0, 1\\}^n$ which $B$ can use to decide $a = b$. The communication and computation rules are called a <em>protocol</em>.</p>\n\n<ul>\n<li>Show that every deterministic protocol must satisfy $|m(a)| \\ge  n$.</li>\n<li>State a randomized protocol that uses only $O(\\log_2n)$ Bits. The protocol should always accept if $a = b$ and accept with probability at most $1/n$ otherwise. Prove its correctness.</li>\n</ul>\n', 'Tags': '<algorithms><probability-theory><randomized-algorithms>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-06-06T13:47:19.663', 'CommentCount': '5', 'AcceptedAnswerId': '1978', 'CreationDate': '2012-05-19T14:30:57.650', 'Id': '1922'}{'Body': '<p>A source provides a stream of items $x_1, x_2,\\dots$ . At each step $n$ we want to save a random sample $S_n \\subseteq \\{ (x_i, i)|1 \\le i \\le n\\}$ of size $k$, i.e. $S_n$ should be a uniformly chosen sample from all $\\tbinom{n}{k}$ possible samples consisting of seen items. So at each step $n \\ge k$ we must decide whether to add the next item to $S$ or not. If so we must also decide which of the current items to remove from $S$ .</p>\n\n<p>State an algorithm for the problem. Prove its correctness.</p>\n', 'ViewCount': '158', 'Title': 'Online generation of uniform samples', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-03T01:02:26.967', 'LastEditDate': '2012-05-19T15:31:20.837', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '1931', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1393', 'Tags': '<algorithms><probability-theory><randomized-algorithms><randomness><online-algorithms>', 'CreationDate': '2012-05-19T14:38:52.510', 'Id': '1923'}{'Body': '<p>There is a family of random graphs $G(n, p)$ with $n$ nodes (<a href="https://en.wikipedia.org/wiki/Random_graph">due to Gilbert</a>). Each possible edge is independently inserted into $G(n, p)$ with probability $p$. Let $X_k$ be the number of cliques of size $k$ in $G(n, p)$.</p>\n\n<p>I know that $\\mathbb{E}(X_k)=\\tbinom{n}{k}\\cdot p^{\\tbinom{k}{2}}$, but how do I prove it?</p>\n\n<p>How to show that $\\mathbb{E}(X_{\\log_2n})\\ge1$ for $n\\to\\infty$? And how to show that $\\mathbb{E}(X_{c\\cdot\\log_2n}) \\to 0$ for $n\\to\\infty$ and a fixed, arbitrary constant $c&gt;1$?</p>\n', 'ViewCount': '297', 'Title': 'Number of clique in random graphs', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-28T09:46:02.827', 'LastEditDate': '2012-05-28T09:46:02.827', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '2119', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1393', 'Tags': '<graph-theory><combinatorics><probability-theory><random-graphs>', 'CreationDate': '2012-05-27T23:41:29.403', 'Id': '2118'}{'ViewCount': '785', 'Title': 'How to prove correctness of a shuffle algorithm?', 'LastEditDate': '2012-05-30T08:13:00.493', 'AnswerCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '1642', 'FavoriteCount': '2', 'Body': "<p>I have two ways of producing a list of items in a random order and would like to determine if they are equally fair (unbiased).</p>\n\n<p>The first method I use is to construct the entire list of elements and then do a shuffle on it (say a Fisher-Yates shuffle). The second method is more of an iterative method which keeps the list shuffled at every insertion. In pseudo-code the insertion function is:</p>\n\n<pre><code>insert( list, item )\n    list.append( item )\n    swap( list.random_item, list.last_item )\n</code></pre>\n\n<p>I'm interested in how one goes about showing the fairness of this particular shuffling. The advantages of this algorithm, where it is used, are enough that even if slightly unfair it'd be okay. To decide I need a way to evaluate its fairness.</p>\n\n<p>My first idea is that I need to calculate the total permutations possible this way versus the total permutations possible for a set of the final length. I'm a bit at a loss however on how to calculate the permutations resulting from this algorithm. I also can't be certain this is the best, or easiest approach.</p>\n", 'Tags': '<algorithms><proof-techniques><probability-theory><randomized-algorithms><randomness>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-01T11:23:35.340', 'CommentCount': '5', 'AcceptedAnswerId': '2156', 'CreationDate': '2012-05-29T07:11:15.180', 'Id': '2152'}{'ViewCount': '86', 'Title': 'Probabilities of duplicate mail detection by comparing notes among servers', 'LastEditDate': '2012-06-07T21:50:16.117', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1788', 'FavoriteCount': '1', 'Body': '<p>I have the following problem:</p>\n\n<blockquote>\n  <p>We want to implement a filtering strategy in e-mail servers to reduce the number of spam messages. Each server will have a buffer, and before sending an e-mail, it checks whether there is a duplicate of the same message in its own buffer and contacts k distinct neighboring servers at random to check whether the duplicate is in another buffer. In case any duplicate message is detected, it will be deleted as spam, otherwise it will be sent after all negative replies are received.</p>\n  \n  <p>Let us assume that there are N mail servers, and that a spammer sends M copies of each spam mail. We assume that all copies are sent simultaneously and that each mail is routed to a mail server randomly.</p>\n</blockquote>\n\n<p>Given M, N and k I need to find out the probabilities that no spam message is deleted (i.e. no server detects spam), all spam messages are deleted (all servers detect spam) and spam messages are deleted from at at least one server.</p>\n\n<p>So far, I have used combinations without repetition to find out the cases that need to be taken into account for an M and N. Now I need to find out the probability that one server receives at least two copies of a message, but I am at complete loss. Could you please provide some insight into the problem?</p>\n', 'Tags': '<combinatorics><probability-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-08T12:04:59.917', 'CommentCount': '0', 'AcceptedAnswerId': '2266', 'CreationDate': '2012-06-07T21:27:13.443', 'Id': '2263'}{'Body': '<p><a href="http://en.wikipedia.org/wiki/Coq" rel="nofollow">COQ</a> is an interactive theorem prover that uses the calculus of inductive constructions, i.e. it relies heavily on inductive types. Using those, discrete structures like natural numbers, rational numbers, graphs, grammars, semantics etc. are very concisely represented.</p>\n\n<p>However, since I grew to like the proof assistant, I was wondering whether there are libraries for uncountable structures, like real numbers, complex numbers, probability bounds and such. I am of course aware that one cannot define these structures inductively (at least not as far as I know), but they can be defined axiomatically, using for instance the <a href="http://en.wikipedia.org/wiki/Real_number#Axiomatic_approach" rel="nofollow">axiomatic approach</a>.</p>\n\n<p>Is there any work that provides basic properties, or even probabilistic bounds like Chernoff bound or union bound as a library?</p>\n', 'ViewCount': '185', 'Title': 'Does there exist any work on creating a Real Number/Probability Theory Framework in COQ?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-08T12:14:12.083', 'LastEditDate': '2012-06-08T12:08:11.160', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '2281', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1534', 'Tags': '<probability-theory><coq><real-numbers><uncountability>', 'CreationDate': '2012-06-08T11:28:23.800', 'Id': '2280'}{'ViewCount': '445', 'Title': 'Is rejection sampling the only way to get a truly uniform distribution of random numbers?', 'LastEditDate': '2012-08-17T17:42:18.317', 'AnswerCount': '3', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '2', 'Body': '<p>Suppose that we have a random generator that outputs\nnumbers in the range $[0..R-1]$ with uniform distribution and we\nneed to generate random numbers in the range $[0..N-1]$\nwith uniform distribution.</p>\n\n<p>Suppose that $N &lt; R$ and $N$ does not evenly divide $R$;\nin order to get a <strong>truly uniform distribution</strong> we can use the\n<a href="http://en.wikipedia.org/wiki/Rejection_sampling">rejection sampling</a> method:</p>\n\n<ul>\n<li>if $k$ is the greatest integer such that $k N &lt; R$</li>\n<li>pick a random number $r$ in $[0..R-1]$</li>\n<li>if $r &lt; k N$ then output $r \\mod N$, otherwise keep trying with other random numbers r\', r", ... until the condition is met</li>\n</ul>\n\n<blockquote>\nIs rejection sampling the only way to get a truly uniform discrete distribution?\n</blockquote>\n\n<p>If the answer is yes, why? </p>\n\n<p>Note: if $N &gt; R$ the idea is the same: generate a random number $r\'$ in $[0..R^m-1], R^m &gt;= N$, for example $r\' = R(...R(R r_1 + r_2)...)+r_m$ where $r_i$ is a random number in the range $[0..R-1]$</p>\n', 'Tags': '<probability-theory><randomness><random-number-generator><sampling>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-08-18T14:29:51.573', 'CommentCount': '1', 'AcceptedAnswerId': '2619', 'CreationDate': '2012-07-04T07:46:04.420', 'Id': '2605'}{'Body': '<p>I have read that the degree of nodes in a "knowledge" graph of people roughly follows a power law distribution, and more exactly can be approximated with a Pareto-Lognormal distribution.</p>\n\n<p>Where can I find a kind of algorithm that will produce a random graph with this distribution?</p>\n\n<p>See for example the paper <a href="http://www.cs.ucsb.edu/~alessandra/papers/ba048f-sala.pdf" rel="nofollow">Revisiting Degree Distribution Models for Social Graph Analysis</a> (page 4, equation 1) for a mathematical description (distribution function) of the kind of distribution I\'m interested in.</p>\n', 'ViewCount': '226', 'Title': 'How to random-generate a graph with Pareto-Lognormal degree nodes?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-18T04:40:16.137', 'LastEditDate': '2012-07-05T07:42:21.527', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '2808', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2060', 'Tags': '<algorithms><graph-theory><probability-theory><randomness>', 'CreationDate': '2012-07-04T11:43:54.893', 'Id': '2608'}{'Body': '<p>There is a time series of say $100$ data points. I wish to assign symbols of $0, 1, 2$ for each unique data point. The issue is I have tried but got stuck since no matter I specify the symbols, the program just outputs probability of $1$\'s and $0$\'s. The following are the questions:</p>\n\n<ol>\n<li>How to find probability or correct my code so that it outputs probablities when number of symbols size > 2?</li>\n<li>How to calculate entropy annd mutual information for this case. I don\'t know although I have read Matlab\'s entropy calculation <a href="http://www.mathworks.com/matlabcentral/fileexchange/14888" rel="nofollow">Mutual Information &amp; Entropy</a> but alas cannot follow how to apply in this case.</li>\n</ol>\n', 'ViewCount': '186', 'Title': 'Time series probability and mutual information', 'LastEditorUserId': '472', 'LastActivityDate': '2012-07-27T09:16:56.967', 'LastEditDate': '2012-07-27T09:16:56.967', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2693', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<probability-theory><information-theory>', 'CreationDate': '2012-07-11T03:18:57.770', 'Id': '2688'}{'Body': '<p>Lets say I have node A that connects to 10 other nodes. 6 of those nodes have Property 1 and the other 4 have Property 2. How can I easily determining the probability of landing on a node with property 1 randomly while traversing the graph?</p>\n\n<h1>Abstract Example</h1>\n\n<p>To clarify this problem, I\'m trying to choose the most probable path.</p>\n\n<p>I have a node $v$ with 10 edges going out, and 6 of the nodes on the other end have a certain property $A$, while 4 have a certain property $B$. Now, each of the 10 nodes also has 10 edges going out, and at the end there are 10 nodes, some with property $A$, some with property $B$. The key here is that each property denotes <strong>an occurrence of something.</strong> Using multiple nodes here is basically a replacement for weighted edges. Rather than having an edge with weight 6 leading to $A$, I have 6 occurrences of $A$. I know this sounds counterintuitive, but this is actually a smaller part of a much, much large problem.</p>\n\n<p>I want to find the most likely sequence of something occurring. We can see that there is a 0.6 probability of $A$ occurring. How can I easily determine that?</p>\n\n<p>Basicslly, the question comes down to how can I traverse a graph of probabilities made from a graph of occurrences without having to completely generate a new graph. The brute force method to this would be to start at $v$, count the number of occurrences of $A$ and the number of occurrences of $B$, determine the probability of each, and then on a new graph have an edge from $v$ to $A$ with a weight 0.6. Adter that, you would then go to each occurrence of A, make a list of the difference occurrences branching from that, find the probability of each (with the many occurrences of $A$ acting as one node), then on the new graph, add an edge to each occurrence.</p>\n\n<p>This may seem like a lot of work, but with the algorithm that I am designing, each node may have a dozen properties. I want to be able to quickly traverse the graph taking the most likely path through certain properties, which could be different for each property of every combination of properties.</p>\n\n<h1>Applied Example</h1>\n\n<p><img src="http://i.stack.imgur.com/GHJwZ.jpg" alt="The basic graph."></p>\n\n<p>Now, let\'s say that each node on this graph represents an event. Each event can have 9 different properties, and each event is dependent on the last one. For the sake of argument, let\'s that that the property being considered here is property 4. That doesn\'t really matter, I\'m only noting it to point out that different properties lead to different simplified graphs (more below).</p>\n\n<p>On <em>Level 0</em> of the first graph (the black graph), we have event 1 takes occurs. Causing event 1 to occur causes a set of 13 other events to occur on <em>Level 1</em>, $\\{A,A,A,A,A,A,B,B,B,B,C,C,D\\}$. We can see that out of all of the events, $A$ is the most common result for property 4.</p>\n\n<p>Now that we know what property to look for, we can look at the events on <em>Level 2.</em> The first occurrence of $A$ causes a set of events where property 4 is $\\{E,G,G\\}$, the second occurrence of $A$ causes a set of events where property 4 is $\\{E,F,G\\}$, and so on. Now, we have all these separate nodes, but we can pretend that they are actually one big node since we are only looking at one property.</p>\n\n<p>Because of this, the set of property 4 of events that occur on <em>Level 2</em> is $\\{E,G,G,E,F,G,G,H,I,G,G,G,G,E,F,G\\}$. The highest probability of the next event is that of $G$ where the probability is $9/16$.</p>\n\n<p>This yields us the simplified graph shown below:</p>\n\n<p><img src="http://i.stack.imgur.com/mF7GZ.jpg" alt=""></p>\n\n<p>This shows us the most likely value of property 4 after we initiate event 1 and allow it to go two steps. If event 1 occurs, the most likely value for property 4 will be $A$. After another event in the chain reaction occurs, the most likely value of property 4 will be $G$.</p>\n\n<p>And before you ask, <strong>no, a longest-path algorithm is not appropriate for this application.</strong> It would take another 3 pages to explain why that is, but basically, it doesn\'t matter if $D$ has the lowest probability but the events after it all have very high probabilities, we need to look at each edge independently.</p>\n\n<h1>Methods that Won\'t Work</h1>\n\n<p>One possible method I could use would be to render a graph for each separate property, but that would just be too much. I could generate the graph for property 4 and yield the graph in the second image, but if I added one more occurrence anywhere in the original graph, I would have to regenerate the graph for every single property, which is too much work when you are dealing with tens or hundreds of thousands of nodes.</p>\n\n<p>So, the question remains: is there a tried and true algorithm for calculating probabilities for the next level as I move along the graph, or will I have to develop something on my own?</p>\n', 'ViewCount': '280', 'Title': 'Determining Probability from a Graph', 'LastEditorUserId': '2214', 'LastActivityDate': '2014-01-21T22:53:27.153', 'LastEditDate': '2012-07-23T18:16:33.980', 'AnswerCount': '1', 'CommentCount': '28', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2214', 'Tags': '<graphs><probability-theory>', 'CreationDate': '2012-07-23T12:30:30.980', 'FavoriteCount': '2', 'Id': '2875'}{'Body': "<p>A Naive Bayes predictor makes its predictions using this formula:</p>\n\n<p>$$P(Y=y|X=x) = \\alpha P(Y=y)\\prod_i P(X_i=x_i|Y=y)$$</p>\n\n<p>where $\\alpha$ is a normalizing factor. This requires estimating the parameters $P(X_i=x_i|Y=y)$ from the data. If we do this with $k$-smoothing, then we get the estimate</p>\n\n<p>$$\\hat{P}(X_i=x_i|Y=y) = \\frac{\\#\\{X_i=x_i,Y=y\\} + k}{\\#\\{Y=y\\}+n_ik}$$</p>\n\n<p>where there are $n_i$ possible values for $X_i$. I'm fine with this. However, for the prior, we have</p>\n\n<p>$$\\hat{P}(Y=y) = \\frac{\\#\\{Y=y\\}}{N}$$</p>\n\n<p>where there are $N$ examples in the data set. Why don't we also smooth the prior? Or rather, <em>do</em> we smooth the prior? If so, what smoothing parameter do we choose? It seems slightly silly to also choose $k$, since we're doing a different calculation. Is there a consensus? Or does it not matter too much?</p>\n", 'ViewCount': '1530', 'Title': 'Smoothing in Naive Bayes model', 'LastEditorUserId': '88', 'LastActivityDate': '2012-08-08T02:02:36.983', 'LastEditDate': '2012-08-08T02:02:36.983', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2341', 'Tags': '<machine-learning><probability-theory><statistics>', 'CreationDate': '2012-08-02T15:47:28.573', 'FavoriteCount': '1', 'Id': '3005'}{'Body': "<p>We have a set X of N elements. We want to get a new set X' having a size M &lt; N.</p>\n\n<pre><code>Choose a first element x from X and put it in X'\nfor each element x in (X - X')\n  Let x' the element from X' which is the closest to x (that is x' = argmin distance(x, x') for all x' in X')\n  d = distance(x, x')\n  if ( uniform_random([0,1]) &lt; d / f )\n     add x to X'\n</code></pre>\n\n<p>How can I choose the value f such that the size of the set X' at the end will be for instance the half of the size of X (that is, M approximates or equals N/2). I suppose that I should choose f such that the probability d / f equals 1/2 (or approximates 1/2 for most values of d), but how to do that ?</p>\n\n<p>Additional details (that are not necesarily usefull for this question): the elements are actually vectors, and the distance between two vectors is the euclidean distance.</p>\n\n<p>Note that d is not a constant (while f is a constant that I want to fix). d depends on the distance between each element x and its closest element x', so d is not always the same.</p>\n\n<p>Suppose that the order in which we test the elements x is always random. For any set X, if we choose the value of f relatively small then we will get a relatively hight number of elements in the final set X', if we choose the value of f relatively big we will get a relatively small number of elements in the final set X'. If I experimentally vary the value of f many times I can always (for any set X) find a value of f for which the final number of elements in X' approaches N/2. So experimentally I can find a good value for f if I test many times which different values of f, but I want to determine it heuristically (not by testing many times and varying f).</p>\n\n<p><strong>EDIT:</strong>\nBy the way, the only one method which seems to give an acceptable results is: let mean_d the mean distance of each x to its nearest x'. We put f = 2mean_d, thus the probability d/f = d/(2mean_d) usually approximate 1/2 if the most of distances d are not far from mean_d. We also put f = (2mean_d)+d' where d' depends on how many distances are higher than mean_d, or f = (2mean_d)-d' where d' depends on how many distances are less than mean_d. Does this make sense ? Do you think it can be improved ?</p>\n", 'ViewCount': '36', 'Title': 'Heuristically determine a value f such that a probability d/f approaches 1/2', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-21T13:07:23.583', 'LastEditDate': '2012-09-21T13:07:23.583', 'AnswerCount': '3', 'CommentCount': '10', 'Score': '0', 'OwnerDisplayName': 'user995434', 'PostTypeId': '1', 'OwnerUserId': '2895', 'Tags': '<probability-theory><mathematical-analysis><heuristics><statistics>', 'CreationDate': '2012-09-17T18:57:42.773', 'Id': '4631'}{'Body': '<p>I am studying algorithms from CLRS book. I try to understand the difference between </p>\n\n<ul>\n<li>probability of hiring the $i$th person out of $n$ and</li>\n<li>probability of hiring the $i$th person out of $n$ persons based on ranks.</li>\n</ul>\n\n<p>Using the normal probability, we know the answer for the first one is $\\frac{1}{n-i}$ and the answer for the second is given as $\\frac{1}{i}$ in the CLRS book. I am unable to understand the concept here. How is it $\\frac{1}{i}$? Can it also be $\\frac{1}{n-i}$ taking in ranks, too?</p>\n\n<p>We have n candidates lined up for an intertiew.Once a candidate is interviewed he is given a rank.If the rank of the next candidate is greater the current greatest rank he is hired and his rank is now the current greatest rank</p>\n\n<pre><code>HireAssistant(n)\n   best=0\n   for i=1 to n\n       interview candidate i\n       if candidate i better than candidate best\n          best=i\n          hire candidate i\n</code></pre>\n', 'ViewCount': '252', 'Title': 'Hiring one person out of n -- rank and probablity', 'LastEditorUserId': '3004', 'LastActivityDate': '2012-09-30T15:08:06.810', 'LastEditDate': '2012-09-29T19:03:51.817', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '4791', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '3004', 'Tags': '<probability-theory>', 'CreationDate': '2012-09-29T06:12:16.587', 'Id': '4790'}{'Body': '<p>This is a GRE practice question. </p>\n\n<p><img src="http://i.stack.imgur.com/dUavw.png" alt="BST n=8"></p>\n\n<p>If a node in the binary search tree above is to be located by binary tree search, what is the expected number of comparisons required to locate one of the items (nodes) in the tree chosen at random?</p>\n\n<p>(A) 1.75 </p>\n\n<p>(B) 2 </p>\n\n<p>(C) 2.75 </p>\n\n<p>(D) 3 </p>\n\n<p>(E) 3.25</p>\n\n<p>My answer was 3 because $n=8$ and $\\lg(n)$ comparisons should be made, and $\\lg(8) = 3$. But the correct answer is 2.75. Can someone explain the correct answer? Thanks!</p>\n', 'ViewCount': '1385', 'Title': 'Average number of comparisons to locate item in BST', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-10-16T15:02:35.267', 'LastEditDate': '2012-10-15T08:13:09.373', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6089', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4198', 'Tags': '<binary-trees><probability-theory><search-trees><average-case>', 'CreationDate': '2012-10-15T06:49:28.390', 'Id': '6085'}{'Body': '<p>When one shuffles playing cards, the goal is evidently to achieve a possibly big derangement\nof a given deck. For manual shuffling there are terms like inshuffle, outshuffle etc. I like\nto know whether there is a sensible general measure of derangements of n objects and\nefficient algorithm to compute that measure and eventually also to determine the set representing maximal derangements.</p>\n', 'ViewCount': '75', 'Title': 'Maximal derangements', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-27T16:09:47.163', 'LastEditDate': '2012-10-26T14:22:26.237', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4349', 'Tags': '<combinatorics><probability-theory><permutations>', 'CreationDate': '2012-10-26T10:31:49.767', 'Id': '6322'}{'Body': '<p>We throw two coins in a row and thus get the event space $\\{ZZ, WW, ZW, WZ\\}$. \nEach of the 4 elementary events has a probability $1/4$.\nhow can I construct 3 binary random variable $x_1$, $x_2$, $x_3$ about this event space, which are 2-fold independent, but not independent.</p>\n', 'ViewCount': '162', 'Title': 'Construction of binary random variable', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-02T11:26:02.913', 'LastEditDate': '2012-10-30T16:41:55.883', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1402', 'Tags': '<probability-theory><sampling>', 'CreationDate': '2012-10-30T13:53:15.393', 'FavoriteCount': '0', 'Id': '6386'}{'ViewCount': '439', 'Title': 'How asymptotically bad is naive shuffling?', 'LastEditDate': '2012-11-06T20:49:40.330', 'AnswerCount': '2', 'Score': '22', 'PostTypeId': '1', 'OwnerUserId': '242', 'FavoriteCount': '3', 'Body': "<p>It's well-known that this 'naive' algorithm for shuffling an array by swapping each item with another randomly-chosen one doesn't work correctly:</p>\n\n<pre><code>for (i=0..n-1)\n  swap(A[i], A[random(n)]);\n</code></pre>\n\n<p>Specifically, since at each of $n$ iterations, one of $n$ choices is made (with uniform probability), there are $n^n$ possible 'paths' through the computation; because the number of possible permutations $n!$ doesn't divide evenly into the number of paths $n^n$, it's impossible for this algorithm to produce each of the $n!$ permutations with equal probability.  (Instead, one should use the so-called <em>Fischer-Yates</em> shuffle, which essentially changes out the call to choose a random number from [0..n) with a call to choose a random number from [i..n); that's moot to my question, though.)</p>\n\n<p>What I'm wondering is, how 'bad' can the naive shuffle be?  More specifically, letting $P(n)$ be the set of all permutations and $C(\\rho)$ be the number of paths through the naive algorithm that produce the resulting permutation $\\rho\\in P(n)$, what is the asymptotic behavior of the functions </p>\n\n<p>$\\qquad \\displaystyle M(n) = \\frac{n!}{n^n}\\max_{\\rho\\in P(n)} C(\\rho)$ </p>\n\n<p>and </p>\n\n<p>$\\qquad \\displaystyle m(n) = \\frac{n!}{n^n}\\min_{\\rho\\in P(n)} C(\\rho)$?  </p>\n\n<p>The leading factor is to 'normalize' these values: if the naive shuffle is 'asymptotically good' then </p>\n\n<p>$\\qquad \\displaystyle \\lim_{n\\to\\infty}M(n) = \\lim_{n\\to\\infty}m(n) = 1$.  </p>\n\n<p>I suspect (based on some computer simulations I've seen) that the actual values are bounded away from 1, but is it even known if $\\lim M(n)$ is finite, or if $\\lim m(n)$ is bounded away from 0?  What's known about the behavior of these quantities?</p>\n", 'Tags': '<algorithms><algorithm-analysis><asymptotics><probability-theory><randomness>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-10T04:07:42.843', 'CommentCount': '13', 'AcceptedAnswerId': '6596', 'CreationDate': '2012-11-06T19:22:56.410', 'Id': '6519'}{'Body': "<p>I have a contiguous ordered data structure (0 based index): </p>\n\n<pre><code>x= [1/3, 1/3, 1/3]\n</code></pre>\n\n<p>Let's say I selected index 1 and increased the probability by 1/3. Rest of the probabilities each decrease by 1/6 and the total probability remains P = 1.</p>\n\n<pre><code>x= [1/6, 2/3, 1/6]\n</code></pre>\n\n<p>Let's say I selected index 2 and increased the probability by 1/3. Rest of the probabilities in total need to decrease by 1/3 to make the total probability remain P= 1.</p>\n\n<pre><code>x= [1/10, 2/5, 1/2]\n</code></pre>\n\n<p>Is there a name for this kind of data structure? I'd like to research that name and use a library instead of my custom rolled code if possible.</p>\n", 'ViewCount': '98', 'Title': 'probability wheel, redistribution of probabilities', 'LastEditorUserId': '4640', 'LastActivityDate': '2012-11-18T20:08:04.633', 'LastEditDate': '2012-11-18T16:00:11.837', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6745', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4640', 'Tags': '<data-structures><probability-theory>', 'CreationDate': '2012-11-18T14:39:44.920', 'Id': '6741'}{'Body': '<p>Assume that we are given a real life graph, DBLP network in my case, where degree distribution of nodes follows a power law (many nodes have 1, 2 neighbors, and only a few nodes have hundreds of neighbors).</p>\n\n<p>A random walk ends when it returns to the initial node or when the walk takes 3 steps.\nIf we start random walks from each node on this graph, should we start equal number of walks from each node? If so, nodes with small degrees will often return to where they started, and we will not learn big portions of the network. This is because small degree nodes are neighbors of small degree nodes more often, so there will not be many paths to walk on.</p>\n\n<p>I believe there should be a way to decide on the number of walks to minimize computational costs. </p>\n', 'ViewCount': '174', 'Title': 'How many random walks to start from each node?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-11-22T03:31:55.453', 'LastEditDate': '2012-11-22T03:31:55.453', 'AnswerCount': '1', 'CommentCount': '9', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4649', 'Tags': '<graph-theory><graphs><probability-theory><random-walks>', 'CreationDate': '2012-11-19T06:40:05.413', 'FavoriteCount': '1', 'Id': '6758'}{'Body': "<p>There are N players and M objects, each of the objects has a value. Each player has a strategy in choosing an object. Each round a player will choose an object, many players can choose the same object. However the value of each object is divided evenly among every player that has chosen it. There will be 9000 rounds(choices) per game. Our goal is to maximize the values that we accumulate at the end of the game.</p>\n\n<p>Question: how can I build a probability distribution function for each playing assuming that their decisions are random variables?</p>\n\n<p>Current Approach: My current approach is to count the frequency of a player choosing a specific object and dividing by the total number of rounds, that would give a probability a player is likely to choose that specific object.</p>\n\n<p>Problem: With each player playing aggressively trying to be unpredictable as possible(noise), with my current approach the probability distribution functions are not accurate(9000 rounds doesn't seem to be enough data). Is there a better way to build these distribution functions?</p>\n\n<p>Note: I've read somewhere that (Bayes model and HMM) are more superior than frequency counts, but I am not sure how to adapt it to this situation.</p>\n", 'ViewCount': '114', 'Title': 'Building probability distribution functions from observation', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-20T09:28:55.593', 'LastEditDate': '2012-11-20T09:28:55.593', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4365', 'Tags': '<machine-learning><probability-theory><modelling>', 'CreationDate': '2012-11-20T00:58:46.293', 'Id': '6775'}{'Body': '<p>For Shamir\'s secret sharing scheme (<a href="http://dx.doi.org/10.1145/359168.359176" rel="nofollow">doi 10.1145/359168.359176</a>), one obtains a random polynomial $q$ of degree at most $n-1$ (over $\\mathbb{Z}_p[x]$).  The constant coefficient of this polynomial is defined to be the key.  Then the scheme sends to player $i$ the value $q(i)$ (for $i \\leq k$ for some fixed $k$). The interpolation theorem says that if $n$ players come together, then I can use interpolation to reconstruct the polynomial (there is a unique polynomial $p$ of degree at most $n-1$ such that $p(i)=q(i)$ .. in otherwords $p=q$.  So that I can grab the constant coefficient of $p$ and it must be the same as the constant coefficient of $q$, and hence must be the key).</p>\n\n<p>The question I have, is that what if the polynomial is degree less than $n-1$.  There seems to be nothing in the construction as described by Shamir that prevents this.  However, Shamir states that $n-1$ players cannot reconstruct the polynomial.</p>\n\n<p>The problem I am having is that there seems to be a "most of the time" clause missing. If I happen to pick a degree one polynomial then any two players can reconstruct the polynomial.  So is it that the players do not know the degree of the polynomial, or that the probability of picking a small degree polynomial is low enough that the probability of two participants guessing the key is still the same as random guessing, or am I missing something else.</p>\n', 'ViewCount': '73', 'Title': 'Condition in Shamir Secret Sharing Scheme', 'LastEditorUserId': '157', 'LastActivityDate': '2012-11-28T06:29:54.707', 'LastEditDate': '2012-11-28T06:05:45.310', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4774', 'Tags': '<probability-theory><cryptography>', 'CreationDate': '2012-11-28T05:34:05.030', 'Id': '6981'}{'Body': '<p>I have just read <a href="http://en.wikipedia.org/wiki/Mental_poker" rel="nofollow">mental poker</a>, described in this <a href="http://people.csail.mit.edu/rivest/ShamirRivestAdleman-MentalPoker.pdf" rel="nofollow">fascinating paper(PDF)</a> by cryptographic greats Adi Shamir, Ron Rivest, and Leonard Adleman.</p>\n\n<p>Assuming I have a website, (TTP) how can I prove to the player that the hand dealt to him is fair? Most importantly how can I prove that I didn\'t bruteforce until an unfair hand is dealt to him to gain house edge, are there any C# implentations of such code?</p>\n', 'ViewCount': '129', 'Title': 'Mental poker: proving dealt hand is fair', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-15T22:49:18.767', 'LastEditDate': '2012-12-08T23:15:38.550', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4939', 'Tags': '<probability-theory><cryptography><board-games>', 'CreationDate': '2012-12-08T21:20:39.903', 'FavoriteCount': '2', 'Id': '7257'}{'ViewCount': '432', 'Title': 'Discrepancy between heads and tails', 'LastEditDate': '2012-12-26T14:53:11.573', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '5195', 'FavoriteCount': '4', 'Body': "<p>Consider a sequence of $n$ flips of an unbiased coin. Let $H_i$ denote the absolute value of the excess of the number of heads over tails seen in the first $i$ flips. Define $H=\\text{max}_i H_i$. Show that $E[H_i]=\\Theta ( \\sqrt{i} )$ and $E[H]=\\Theta( \\sqrt{n} )$. </p>\n\n<p>This problem appears in the first chapter of `Randomized algorithms' by Raghavan and Motwani, so perhaps there is an elementary proof of the above statement. I'm unable to solve it, so I would appreciate any help.</p>\n", 'Tags': '<probability-theory><randomized-algorithms>', 'LastEditorUserId': '3011', 'LastActivityDate': '2012-12-31T01:55:08.807', 'CommentCount': '0', 'AcceptedAnswerId': '7601', 'CreationDate': '2012-12-26T07:03:36.157', 'Id': '7600'}{'Body': '<p>When we say that in random graph we add an edge with a certain fixed probability, what do we actually mean?</p>\n\n<p>For example if probability is 0.5, does that mean that we can just add two edges in a graph because 0.5+0.5=1.</p>\n', 'ViewCount': '222', 'Title': 'Random graph model', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-29T01:36:11.837', 'LastEditDate': '2012-12-29T00:43:23.927', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '7633', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4624', 'Tags': '<graph-theory><probability-theory>', 'CreationDate': '2012-12-28T15:48:20.620', 'Id': '7629'}{'Body': '<p>I have frequency data for different events under two conditions, resulting in sets of frequencies F1 and F2. I would like to normalize the frequencies of events under condition 1 by their frequencies under condition 2. However, there are events that occur in condition 1 but not condition 2, resulting in divide-by-zero problems when I attempt to normalize.</p>\n\n<p>For raw count data, I understand that there are a number of smoothing techniques (e.g. Witten-Bell) that can help sort this out, but I only have the frequencies, not the individual counts. In other words, I have frequencies like {0, 0.1, 0.2, 0.7} which could correspond to counts of {0, 1, 2, 7}, {0, 10, 20, 70}, etc. Are there any algorithms that are able to smooth this type of frequency data?</p>\n', 'ViewCount': '55', 'Title': 'Smoothing frequencies without count data', 'LastActivityDate': '2013-01-08T17:58:49.037', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7836', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4927', 'Tags': '<algorithms><probability-theory>', 'CreationDate': '2013-01-07T22:14:09.180', 'Id': '7821'}{'Body': '<p>There is the well-known method of unbiasing of bit sequences due to von Neumann. Are there similar schemes applicable to other sequences, e.g. the result of throwing a normal die?</p>\n', 'ViewCount': '68', 'Title': 'Unbiasing of sequences', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-04T16:46:37.613', 'LastEditDate': '2013-02-04T15:48:25.047', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6437', 'Tags': '<reference-request><probability-theory>', 'CreationDate': '2013-02-04T11:48:38.783', 'Id': '9469'}{'Body': '<p>I am learning about information theory and mutual information. However, I am quite confused with MI(Mutual information) vs. PMI(Pointwise mutual information) especially signs of MI and PMI values. Here are my questions.    </p>\n\n<ul>\n<li><p>Is MI values a non-negative value or it can be either positive or negative? If it is always a non-negative value, why is it ?</p></li>\n<li><p>As I search online, the PMI can be positive or negative values and the MI is the expected value of all possible PMI. However, expected value can be positive or negative. If MI is really the expected value of PMI, why is it always positive ?</p></li>\n</ul>\n\n<p>Did I misunderstand anything of MI and PMI here ? Thank you very much,</p>\n', 'ViewCount': '320', 'Title': 'Pointwise mutual information vs. Mutual information?', 'LastActivityDate': '2013-03-09T07:54:28.433', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10401', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7161', 'Tags': '<probability-theory><information-theory><entropy>', 'CreationDate': '2013-03-09T00:08:48.040', 'Id': '10396'}{'Body': '<p>I went to listen to a workshop and someone from the audience asked the presenter how the moments can improve the <a href="https://en.wikipedia.org/wiki/Mutual_information" rel="nofollow">mutual information</a>. I am learning about MI (Mutual Information) so didn\'t have enough knowledge to understand what it means. Then, I did some research but I still have some confusion. I am wondering if someone who has more knowledge about this can clarify things for me. Here are my questions:</p>\n\n<ul>\n<li><p>Mutual information is usually calculated by bin functions to estimate the probability of two random variables which can be a case of two vectors $X$ and $Y$. Is the moment generating function another way to estimate probability?</p></li>\n<li><p>If moment generating functions can present the probability of $X$ and $Y$, how do we calculate it? </p></li>\n<li><p>Does a MI have a moment generating function?</p></li>\n<li><p>If MI has a moment generating function, how can we present a MI of $X$ and $Y$ by its moment functions?</p></li>\n</ul>\n', 'ViewCount': '96', 'Title': 'Mutual information and moment generating functions', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-03-17T19:08:39.583', 'LastEditDate': '2013-03-17T19:08:39.583', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10524', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7161', 'Tags': '<probability-theory><information-theory><bioinformatics>', 'CreationDate': '2013-03-14T00:20:20.677', 'Id': '10513'}{'ViewCount': '1994', 'Title': 'Applying Expectation Maximization to coin toss examples', 'LastEditDate': '2013-03-20T11:17:21.013', 'AnswerCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '7329', 'FavoriteCount': '3', 'Body': '<p>I\'ve been self-studying the Expectation Maximization lately, and grabbed myself some simple examples in the process:</p>\n\n<p>From <a href="http://cs.dartmouth.edu/~cs104/CS104_11.04.22.pdf">here</a>: There are three coins $c_0$, $c_1$ and $c_2$ with $p_0$, $p_1$ and $p_2$ the respective probability for landing on Head when tossed. Toss $c_0$. If the result is Head, toss $c_1$ three times, else toss $c_2$ three times. The observed data produced by $c_1$ and $c_2$ is like this: HHH, TTT, HHH, TTT, HHH. The hidden data is the result of $c_0$. Estimate $p_0$, $p_1$ and $p_2$.</p>\n\n<p>And from <a href="http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf">here</a>: There are two coins $c_A$ and $c_B$ with $p_A$ and $p_B$ being the respective probability for landing on Head when tossed. Each round, select one coin at random and toss it ten times; record the results. The observed data is the toss results provided by these two coins. However, we don\'t know which coin was selected for a particular round. Estimate $p_A$ and $p_B$.</p>\n\n<p>While I can get the calculations, I can\'t relate the ways they are solved to the original EM theory. Specifically, during the M-Step of both examples, I don\'t see how they\'re maximizing anything. It just seems they are recalculating the parameters and somehow, the new parameters are better than the old ones. Moreover, the two E-Steps don\'t even look similar to each other, not to mention the original theory\'s E-Step.</p>\n\n<p>So how exactly do these examples work?</p>\n', 'Tags': '<probability-theory><statistics>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-20T16:09:52.617', 'CommentCount': '4', 'AcceptedAnswerId': '10657', 'CreationDate': '2013-03-20T05:13:18.053', 'Id': '10637'}{'Body': "<p>In many papers I've read that it is well known that the Shannon entropy of a random variable can be converted to min-entropy (up to small statistical distance) by taking independent copies of the variable.\nCan anyone explain to me what exactly this means?</p>\n", 'ViewCount': '182', 'Title': 'Shannon Entropy to Min-Entropy', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-29T02:00:25.320', 'LastEditDate': '2013-03-28T11:59:20.143', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10881', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '7468', 'Tags': '<terminology><probability-theory><entropy>', 'CreationDate': '2013-03-28T09:38:33.157', 'Id': '10862'}{'ViewCount': '476', 'Title': 'Negligible Function in Cryptography', 'LastEditDate': '2013-04-06T12:01:29.477', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4799', 'FavoriteCount': '1', 'Body': '<p>In the field of Cryptography and Computation Complexity there is a notion of negligible function.</p>\n\n<p>I have some difficulties in understanding intuition behind this notion. The following are some definitions from Chapter 9. Cryptography from the textbook Computation Complexity. A modern approach by Arora and Barak with extensive use of negligible function. There my question after every definition about negligible function.</p>\n\n<blockquote>\n  <p>Before proceeding further, we make a simple definition that will greatly  simplify notation throughout this chapter.</p>\n  \n  <p><strong>Definition of negligible function</strong>. a function $\\epsilon : \\mathbb{N} \\rightarrow [0,1]$ is called negligible if $\\epsilon(n)=n^{-\\omega(1)}$. </p>\n  \n  <p>Because negligible functions tend to zero very fast as their input grows, events that happen with negligible probability can be safely ignored in most practical and theoretical settings.</p>\n</blockquote>\n\n<p>So far so good, it\'s just the definition of negligible function, the only point is why do we need to care about this function if it <em>"can be safely ignored".</em></p>\n\n<blockquote>\n  <p><strong>The notion of computational secure function</strong>.$k \\in_R \\{0,1\\}^n, x \\in_R \\{0,1\\}^m, Pr [A(E_k(x))=(i,b) s.t. x_i=b] \\leq \\frac{1}{2}+\\epsilon(n)$.</p>\n</blockquote>\n\n<p>Less intuitive usage of negligible function. As I understood, in general, $A$ can with probability 0.5 guess uniformly distributed $x_i$, therefore it makes sence to expected lower bound of success to be $\\leq \\frac{1}{2}$, however it\'s $\\leq \\frac{1}{2} + \\epsilon(n)$, it we can "safely ignore" $\\epsilon(n)$ why to mention it, and the second point is it possible to run $A$ some fixed finite number of times to get probability infinitely close to 1?</p>\n\n<blockquote>\n  <p><strong>Definition of one-way function</strong>. $x\\in_R\\{0,1\\}^n, y=f(x), Pr[A(y)=x\' s.t. f(x\')=y] &lt; \\epsilon(n)$</p>\n</blockquote>\n\n<p>In this case, the usage of negligible function is very intuitive, the success probability is upper bounded by negligible function $\\epsilon(n)$. I am not sure how it\'s correlated with existence of computationally secure encryption scheme (of course =0 is preferable by encryption scheme), however if $\\epsilon(n)$ can be safely ignored than it\'s ok.</p>\n\n<p>The problem is I am not quite understand why do we need negligible function. By mentioning few definition I tried to be more specific about what exactly I don\'t understand. </p>\n\n<p>I would appreciate if anyone can shed the light on the usage of negligible function</p>\n', 'Tags': '<complexity-theory><probability-theory><cryptography>', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-04-07T13:22:40.707', 'CommentCount': '0', 'AcceptedAnswerId': '11074', 'CreationDate': '2013-04-06T09:45:34.340', 'Id': '11073'}{'Body': '<p>I have difficulties in understanding the notion of density for distribution.</p>\n\n<p><strong>Notion of density for distribution</strong>. A distribution $H$ over $\\{0,1\\}^n$ has density $\\sigma$ if for every $x \\in \\{0,1\\}^{n}$, $Pr[H=x] \\leq \\frac{1}{2^n\\sigma}$.</p>\n\n<p>The following is my desperate tries to understand the notion.\nif $H$ is uniform distribution over $\\{0,1\\}^n$ then  for every $x \\in \\{0,1\\}^n$, $Pr[H=x]=\\frac{1}{2^n}$.</p>\n\n<p>if a distribution $H$ has density $\\sigma = 1$ then $P[H=x]\\leq\\frac{1}{2^n}$, so distribution $H$ is upper bounded by the uniform distribution.</p>\n\n<p>if a distribution $H$ has density $\\sigma = \\frac{1}{2}$ then $P[H=x]\\leq\\frac{1}{2^{n-1}}$, so distribution $H$ is upper bounded by the uniform distribution over $\\{0,1\\}^{n-1}$.</p>\n\n<p>if a a distribution $H$ has density $\\sigma = \\frac{1}{2^n}$ then $P[H=x]\\leq 1$.</p>\n\n<p>So density $\\sigma$ might determine the part of distribution over $2^n$ where the actual "probabilistic weight" should be placed? However it\'s always upper bounded, therefore we can always say something about the upper bound?</p>\n\n<p>As you see I don\'t have intuition behind this notion and I would appreciate any help.</p>\n', 'ViewCount': '42', 'Title': 'The notion of density of distribution', 'LastEditorUserId': '1379', 'LastActivityDate': '2013-04-17T09:22:50.767', 'LastEditDate': '2013-04-17T06:58:12.263', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '11363', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><probability-theory>', 'CreationDate': '2013-04-16T13:38:56.990', 'Id': '11354'}{'Body': u"<p>I have my end of year exams next Thursday. I'm generally doing fine but I am having some major issues with this strand of my course, this has to be the biggest issue I have. So, here is the question in the past paper:</p>\n\n<blockquote>\n  <p>You have been tasked with determining the validity of a \n    manufacturer\u2019s claim that their widget is more reliable than their main \n    competitors\u2019 widgets.</p>\n  \n  <p>In order to verify this assertion you test a sample of 25 widgets from \n    the manufacturer\u2019s range and find a mean pass rate of 992 per 1000\n    with a standard deviation of 15 per 1000.</p>\n  \n  <p>Previous studies have shown that the mean pass rate of all other \n    widgets on the market is 979.4 per1000.</p>\n  \n  <p>In order to increase the confidence in the making a decision about \n    the null hypothesis you choose a 99.5% confidence level and find the \n    corresponding t-table value to be 2.947.</p>\n  \n  <ul>\n  <li>State the null hypothesis.</li>\n  </ul>\n</blockquote>\n\n<p>I have revision notes in front of me, but I just don't understand what this question is actually asking. Am I just writing down my own hypothesis, or do I need to use this equation?</p>\n\n<blockquote>\n  <p>H0; \u03bc<br>\n    H1; \u03bc</p>\n</blockquote>\n\n<p>If anyone could go through step by step for what I need to do, then that would be fantastic. My notes are just confusing! </p>\n", 'ViewCount': '96', 'Title': 'Null Hypothesis in Analysis and Testing', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-23T17:35:28.500', 'LastEditDate': '2013-04-23T17:35:28.500', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '11521', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7857', 'Tags': '<probability-theory><statistics><reliability>', 'CreationDate': '2013-04-23T15:32:38.180', 'Id': '11519'}{'Body': "<p>I have been studying Artificial Intelligence and I have noticed that the Bayes' rule allows us to infer the posterior probability if a variable. But, my question is, what does the word, or phrase, 'posterior' mean in this context with regard to the Bayes' rule?</p>\n", 'ViewCount': '112', 'Title': "What does the posterior probability of a variable mean in the Bayes' rule?", 'LastActivityDate': '2013-04-28T18:33:14.427', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11633', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7919', 'Tags': '<artificial-intelligence><probability-theory>', 'CreationDate': '2013-04-28T10:52:15.983', 'Id': '11630'}{'Body': u'<p>In Bernard Chazelle\'s book <em>The Discrepancy Method</em>, which is <a href="http://www.cs.princeton.edu/~chazelle/pubs/book.pdf" rel="nofollow">available free as a PDF from the author\'s website</a>, the very first statement requiring thought by the reader (on page 3, just before Theorem 1) is obtained by a simple probability argument.  Unfortunately, I fail to follow the intended argument.  Could someone enlighten me?</p>\n\n<p>Here $\\chi(S_i) = \\sum_{v\\in S_i} \\chi(v)$ is the <em>discrepancy</em> of the set $S_i$ with respect to a function $\\chi$ that assigns weights to each element.</p>\n\n<blockquote>\n  <p>Given a set system $(V,S)$, with $|V| = n$ and $|S| = m$, pick a random coloring $\\chi$, meaning that for each $v_j$, the "color" $\\chi(v_j)$ is chosen randomly, uniformly, and independently, in $\\{-1,1\\}$.  We say that $S_i$ is <em>bad</em> if $|\\chi(S_i)| &gt; \\sqrt{2|S_i|\\ln (2m)}$.  By Chernoff\'s bound, we immediately derive\n  $$Pr[S_i \\text{ is bad}] &lt; \\frac{1}{m};$$</p>\n</blockquote>\n\n<p>and now the bit I don\'t follow:</p>\n\n<blockquote>\n  <p>therefore, with nonzero probability, no $S_i$ is bad.</p>\n</blockquote>\n\n<p>Clearly this holds if the $m$ events "$S_i$ is not bad" are mutually independent.  It also holds by a form of the <a href="http://en.wikipedia.org/wiki/Lov%C3%A1sz_local_lemma" rel="nofollow">Lov\xe1sz Local Lemma</a> if these events form the edges of a hypergraph (with $V$ as vertices) that is "nice enough".  But I don\'t see why this is immediately apparent in every case, as the author seems to imply.  If the $n$ individual values $\\chi(v_j)$ are iid, then I simply don\'t see that the $m$ events "$S_i$ is not bad" are necessarily of a nice enough form to use the probabilistic method, and they certainly don\'t seem to be iid.</p>\n\n<p>What am I missing?</p>\n\n<p>Any counterexample must be rather large (with the size of $m$ exponential in $|S_i|$), so I provisionally do believe the statement.  But I would like a convincing proof, or a pointer to another reference.</p>\n', 'ViewCount': '42', 'Title': "Chazelle's discrepancy book: greedy method", 'LastEditorUserId': '5323', 'LastActivityDate': '2013-05-03T10:18:17.243', 'LastEditDate': '2013-05-03T07:01:44.673', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11754', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '5323', 'Tags': '<reference-request><combinatorics><probability-theory><books>', 'CreationDate': '2013-05-03T06:55:55.880', 'Id': '11752'}{'Body': '<p>I am given an oracle $A$ that takes input samples from two distributions $\\chi_1$  and $\\chi_2$.</p>\n\n<p>Suppose we have $Pr_{x \\sim \\chi_1}[A(x) = 1] = p_1$ and $Pr_{x \\sim \\chi_2}[A(x) = 1] = p_2$, where $p_1 \\neq p_2$.</p>\n\n<p>In general, how can we use $A$ to construct a distinguisher to determine whether the input samples are from $\\chi_1$ or $\\chi_2$? And how good is the running time of such distinguisher?</p>\n\n<p>Thank you very much! :)</p>\n', 'ViewCount': '87', 'Title': 'How to distinguish whether a sample is from distribution $\\chi_1$ or $\\chi_2$?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-06T11:33:38.173', 'LastEditDate': '2013-05-07T11:07:54.823', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8051', 'Tags': '<complexity-theory><probability-theory>', 'CreationDate': '2013-05-05T03:57:06.787', 'Id': '11795'}{'Body': "<p>I want to compare in a practical sense two methods of random permutations -- one theoretically perfect, namely that of Fisher and Yates, and another ad hoc, let's\ncall it X. A way of comparison I could think of is the following:</p>\n\n<p>One starts from the standard configuration of n objects [0, 1, 2, ...., n-1] and\napply each method a fairly large number of times successively to permute them\nand each time one computes the Hamming distance of the result from the standard\nconfiguaration. One obtains thus the frequency distribution of the Hamming distances\nfor each method. If these are fairly comparable to each other, then X could be\n practically employed in place of the theoretically perfect one.</p>\n\n<p>Is this line of thought of mine correct? Does anyone have an idea of a better method\nof comparison? Thanks in advance.</p>\n", 'ViewCount': '53', 'Title': 'Compare two methods of random permutations', 'LastActivityDate': '2013-05-08T12:34:55.713', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6437', 'Tags': '<probability-theory>', 'CreationDate': '2013-05-08T09:47:32.440', 'Id': '11887'}{'Body': '<p>Given a Bayesian Network $N$, one can build a junction/joint tree $JT$ over $N$ by applying series of steps (namely, moralisation,triangulation..etc). Then we can use $JT$ to answer queries over $N$.</p>\n\n<p>My question is: what makes BN decomposable into $JT$? The structure (along with the CPTs) must exhibit certain conditions otherwise any graphical model is decomposable.  </p>\n', 'ViewCount': '97', 'Title': 'What makes Bayesian Networks decomposable into joint trees?', 'LastActivityDate': '2013-05-15T08:38:34.180', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12035', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<graph-theory><probability-theory><trees>', 'CreationDate': '2013-05-13T02:30:42.550', 'Id': '11983'}{'Body': "<p>I have seen a lot of explanations of what Bayesian networks are, but I simply cannot wrap my head around their use in code. So here is my three part question. </p>\n\n<ol>\n<li>Am I right in my definition of bayes nets? Bayesian networks are a way to (visually) portray how variables/events are linked and how they will affect each other. Probabilities can be added to each node to give you a greater sense of what will happen. In conjunction with an acting AI, bayes nets are used to predict the AI's actions and inform what it should be doing, ie giving minimax a better prediction.</li>\n<li>Can you give a pseudo code representation of a bayes net? </li>\n<li><p>Let's get a little more specific. I have a creature simulator, the creature has a home where he sleeps and, there are patches of grass where he eats. There are other creatures out there that he wants to avoid because they will fight him. So his action -> reaction set is: </p>\n\n<p>{hungry->find food -> eat food<br>\ntiered -> go to shelter -> sleep<br>\nin danger -> avoid other creature<br>\nunder attack -> run to shelter}</p>\n\n<p>I am trying to express this as an mdp so that it will learn what actions are best when; and what are the best spots(most prosperous &amp; least dangerous) on the map.\nHow, if at all, am I supposed to use a bayes net? If the situation requires probabilities feel free to add your own, pseudo code also appreciated.</p></li>\n</ol>\n", 'ViewCount': '141', 'Title': 'What is the purpose of Bayesian networks?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-26T11:19:18.883', 'LastEditDate': '2013-08-26T11:19:18.883', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8147', 'Tags': '<terminology><machine-learning><artificial-intelligence><probability-theory>', 'CreationDate': '2013-05-13T15:29:28.663', 'Id': '11992'}{'Body': '<p>Is it proper to view conditional probabilities, such as the forms:</p>\n\n<p>P(a|c)</p>\n\n<p>P(a|c,d)</p>\n\n<p>P(a, b|c, d)</p>\n\n<p>...and so forth, as being tensors?</p>\n\n<p>If so, does anyone know of a decent introductory text (online tutorial, workshop paper, book, etc) which develops tensors in that sense for computer scientists/machine learning practitioners?</p>\n\n<p>I have found a number of papers, but those written at an introductory level are written for physicists, and those written for computer scientists are rather advanced.  </p>\n', 'ViewCount': '69', 'Title': 'Conditional Probabilities as Tensors?', 'LastActivityDate': '2013-05-17T23:18:12.193', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1940', 'Tags': '<machine-learning><probability-theory><statistics>', 'CreationDate': '2013-05-17T23:18:12.193', 'Id': '12100'}{'Body': "<p>I'm taking a grad level randomized algorithms course in the fall. The professor is known for being very detail oriented and mathematically rigorous, so I will be required to have an in-depth understanding of probability. What would be a good probability book to learn from that would be intuitive, but also have some mathematical rigor to it?</p>\n", 'ViewCount': '79', 'Title': 'Randomized Algorithms Probability', 'LastActivityDate': '2013-05-19T13:03:22.573', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '12133', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8242', 'Tags': '<probability-theory><randomized-algorithms>', 'CreationDate': '2013-05-18T14:20:52.533', 'Id': '12113'}{'Body': '<p>I\'m doing some exam study and came across a question I\'m not really sure on. Consider the Bayesian network below:</p>\n\n<p><img src="http://i.stack.imgur.com/V3BGw.png" alt="enter image description here"></p>\n\n<p>Let\'s denote "Disease" with $D$ and "Symptom" with $S$.</p>\n\n<p>I want to find $P(D \\mid S_A, S_B)$ but it\'s not working for me. I\'ve tried (among other things) to apply this rule:</p>\n\n<p>$\\qquad \\displaystyle P(x_1, x_2, \\dots , x_n) = P(x_i \\mid parents(x_i))$ </p>\n\n<p>Which leads me to:</p>\n\n<p>$\\qquad\\begin{align}\n  P(D \\mid S_A, S_B) &amp;= \\frac{P(D, S_A, S_B)}{P(S_A, S_B)} \\\\\n  &amp;= \\frac{1}{\\alpha} \\cdot P(D) \\cdot P(S_A \\mid D) \\cdot P(S_B \\mid D, S_A) \n\\end{align}$</p>\n\n<p>where $\\alpha = P(S_A, S_B) $</p>\n\n<p>However, I\'m not really sure how to calculate my $\\alpha$ value. I\'ve tried making $D$ a hidden variable and calculating it like that, but my final answer was less than $P(D)$ was, so it can\'t be right.</p>\n\n<p>Could someone please guide me through this? I\'m not really sure what I\'m doing wrong.</p>\n', 'ViewCount': '63', 'Title': 'Exact Inference in Bayesian Networks', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-11T10:20:16.920', 'LastEditDate': '2013-06-11T10:20:16.920', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8614', 'Tags': '<probability-theory>', 'CreationDate': '2013-06-11T04:52:06.410', 'Id': '12608'}{'ViewCount': '373', 'Title': 'Understanding an example of coin toss expectation maximization', 'LastEditDate': '2013-06-24T08:36:24.557', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8784', 'FavoriteCount': '0', 'Body': '<p>I\'ve been trying to get my head around Expectation maximization algorithms, and I thought I\'d start simple. I found this 3-coin example here: <a href="http://cs.dartmouth.edu/~cs104/CS104_11.04.22.pdf" rel="nofollow">http://cs.dartmouth.edu/~cs104/CS104_11.04.22.pdf</a>  I understand the calculation of all of the probabilities but I don\'t understand how the recalculation of lambda, p1 and p2 is actually done. (Page 18)</p>\n\n<p>I understand how the maximization of a log-likelihood/likelihood function by differentiation works, but can\'t figure out the recalculation method here.</p>\n\n<p>Can anyone explain why the recalculation of lambda, p1 and p2 take the form they do? </p>\n', 'ClosedDate': '2013-07-16T10:28:00.093', 'Tags': '<probability-theory><statistics>', 'LastEditorUserId': '8784', 'LastActivityDate': '2013-07-01T21:12:08.380', 'CommentCount': '3', 'AcceptedAnswerId': '13019', 'CreationDate': '2013-06-21T10:42:06.143', 'Id': '12811'}{'Body': '<p>Should the independence assumption on which the Naive Bayes (NB) classifier is based, be taken into account when applying Expectation Maximization(EM) to infer missing values?</p>\n\n<p>The Naive Bayes classifier assumes that all attributes are independent given the class variable. \nNormally, the given structure of a Bayesian Network would be exploited by the EM algrithm. However, the NB classifier still performs well enough when the assumption is not met. So it is entirely plausible to have a dataset, in which the assumption does not (entirely) hold and to succesfully train a Naive Bayes classifier.</p>\n\n<p>I am inclined to disregard the independence assumption as it does not (neccesarily) stem from domain-knowledge, but is just a consequence of the simplifying assumptions inherent to Naive Bayes. Am i right in doing so? </p>\n', 'ViewCount': '27', 'Title': "Should Expectation Maximization take into account the Naive Bayes' independence assumption?", 'LastActivityDate': '2013-06-21T12:21:43.560', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8515', 'Tags': '<probability-theory><classification>', 'CreationDate': '2013-06-21T12:21:43.560', 'Id': '12815'}{'Body': '<p>When analysing treaps (or, equivalently, BSTs or Quicksort), it is not too hard to show that</p>\n\n<p>$\\qquad\\displaystyle \\mathbb{E}[d(k)] \\in O(\\log n)$</p>\n\n<p>where $d(k)$ is the depth of the element with rank $k$ in the set of $n$ keys.\nIntuitively, this seems to imply that also</p>\n\n<p>$\\qquad\\displaystyle \\mathbb{E}[h(T)] \\in O(\\log n)$</p>\n\n<p>where $h(T)$ is the height of treap $T$, since</p>\n\n<p>$\\qquad\\displaystyle h(T) = \\max_{k \\in [1..n]} d(k)$.</p>\n\n<p>Formally, however, there does not seem to be an (immediate) relationship. We even have</p>\n\n<p>$\\qquad\\displaystyle \\mathbb{E}[h(T)] \\geq \\max_{k \\in [1..n]} \\mathbb{E}[d(k)]$</p>\n\n<p>by Jensen\'s inequality. Now, one can show expected logarithmic height via tail bounds, using more insight into the distribution of $d(k)$.</p>\n\n<p>It is easy to construct examples of distributions that skrew with above intuition, namely extremely asymmetric, heavy-tailed distributions. The question is, can/do such occur in the analysis of algorithms and data structures?</p>\n\n<p>Are there example for data structures $D$ (or algorithms) for which</p>\n\n<p>$\\qquad\\displaystyle \\mathbb{E}[h(D)] \\in \\omega(\\max_{e \\in D} \\mathbb{E}[d(e)])$?</p>\n\n<p>Nota bene:</p>\n\n<ul>\n<li><p>Of course, we have to interpret "depth" and "height" liberally if we consider structures that are not trees. Based on the posts Wandering Logic links to, "Expected average search time" (for $1/n \\cdot \\sum_{e \\in D} \\mathbb{E}[d(e)]$) and "expected maximum search time" (for $\\mathbb{E}[h(D)]$) seem to be used.</p></li>\n<li><p>A <a href="http://math.stackexchange.com/q/426998/3330">related question</a> on math.SE has yielded an interesting answer that may allow deriving useful bounds on $\\mathbb{E}[h(D)]$ given suitable bounds on $\\mathbb{E}[d(e)]$ and $\\mathbb{V}[d(e)]$.</p></li>\n</ul>\n', 'ViewCount': '93', 'Title': 'Can expected "depth" of an element and expected "height" differ significantly?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-23T20:06:53.820', 'LastEditDate': '2013-06-23T16:04:31.497', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12833', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<algorithms><data-structures><algorithm-analysis><probability-theory><average-case>', 'CreationDate': '2013-06-22T16:23:33.990', 'Id': '12830'}{'ViewCount': '130', 'Title': 'distance between histograms', 'LastEditDate': '2013-06-25T19:10:37.723', 'AnswerCount': '2', 'Score': '1', 'OwnerDisplayName': 'Hani Gotc', 'PostTypeId': '1', 'OwnerUserId': '9033', 'Body': '<p>I have 2 histograms that represent the height of characters in 2 images. \nexample: </p>\n\n<ul>\n<li>1 <strong>**</strong></li>\n<li>2 <strong><em>*</em>***</strong></li>\n<li>3 <strong><em>*</em>**<em>*</em></strong></li>\n<li>.</li>\n<li>.</li>\n<li>.</li>\n<li>100 <strong><em>*</em>**<em>*</em>**</strong></li>\n</ul>\n\n<p>For these 2 histograms I compute the peaks. And To <strong>check</strong> if these 2 images are <strong>similar</strong> I compute the interseciton between the indices of the 2 images.\nExample:\nFor image 1 the indices of the peaks are 1, 10 and 13\nfor image 2 the indices of the peals are 1,10, 14.\nImage1 Inter Image1 = 2 So these images are similar.</p>\n\n<p>But I feel that the intersection is not enough. I think that i should also use the size of the buckets of the histograms peaks.</p>\n\n<p>Is there  a way to use to both of them to measure the similarity in <strong>1 function</strong> So that I can have a stable similarity function?</p>\n', 'Tags': '<machine-learning><probability-theory><statistics>', 'LastEditorUserId': '19', 'LastActivityDate': '2013-06-25T19:10:37.723', 'CommentCount': '1', 'AcceptedAnswerId': '12898', 'CreationDate': '2013-06-18T11:00:45.170', 'Id': '12846'}{'ViewCount': '180', 'Title': 'Computer science problems related to music?', 'LastEditDate': '2013-07-10T08:56:09.893', 'AnswerCount': '3', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2529', 'FavoriteCount': '1', 'Body': '<p>Are there any CS problems, preferably open, that are related to music or musical theory somehow? I would think of problem with musical notation but also probabilities when randomizing according to a scale or a tonality or general what is considered harmony in frequencies and physics, electromagnetism and waveforms. </p>\n\n<p>Can you give examples of the area I want to know of?</p>\n\n<p>For instance, given an algorithm that guesses a melody, how successful will the melody be in resembling an artist or likewise decision problem that could be feasible or what do you think?</p>\n', 'Tags': '<probability-theory><decision-problem><probabilistic-algorithms>', 'LastEditorUserId': '31', 'LastActivityDate': '2013-07-16T07:52:42.197', 'CommentCount': '2', 'AcceptedAnswerId': '13200', 'CreationDate': '2013-07-10T08:06:34.607', 'Id': '13199'}{'Body': '<p>Given a set $S$ of $k$ numbers in $[0, N)$.\nThe task is to randomly generate numbers in the range $[0, N)$ such that none belongs to $S$.</p>\n\n<p><strong>Edit</strong> - Also given an API to generate random numbers between $[0, N)$. We have to use it  to randomly generate numbers in the range $[0, N)$ such that none belongs to $S$.</p>\n\n<p>I would also like a generic strategy for such questions. Another one I came across was to generate random numbers between [0,7] given a random number generator that generates numbers in range [0, 5].</p>\n', 'ViewCount': '225', 'Title': 'Generate random numbers from an interval with holes', 'LastEditorUserId': '9166', 'LastActivityDate': '2013-07-17T16:03:32.970', 'LastEditDate': '2013-07-15T07:05:30.703', 'AnswerCount': '2', 'CommentCount': '6', 'AcceptedAnswerId': '13272', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9166', 'Tags': '<algorithms><probability-theory><sampling><random-number-generator>', 'CreationDate': '2013-07-14T13:12:52.417', 'Id': '13271'}{'Body': "<p>I have a real function $f:\\mathbb{{R}}^{d}\\mapsto\\mathbb{R}$, where\n$d&gt;1$. The question is how to compute the level set $A=\\left\\{ \\theta:f\\left(\\theta\\right)\\geq a\\right\\} $.\nI am a statistician knowing very few things about computer science.\nI would appreciate very much if anyone could suggest some reference, methods\nand/or alogirthms.</p>\n\n<p>In my problem, $f\\left(\\theta\\right)=\\sum_{i=1}^{N}\\log g\\left(\\mathbf{z}_{i};\\theta\\right)$,\nwhere $g\\left(\\mathbf{z}_{i};\\theta\\right)$ is a probability density\nfunction of $\\mathbf{z}_{i}$ parameterized by a vector of parameters\n$\\theta$. $\\mathbf{z}_1,\\ldots, \\mathbf{z}_N$ are observed samples. For example, $g\\left(\\mathbf{z}_{i};\\theta\\right)$ is the density function of\na normal distribution with variance $1$\n$$\ng\\left(\\mathbf{z}_{i};\\theta\\right)=\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\left(y_{i}-\\mathbf{x}_{i}'\\theta\\right)^{2}}{2}\\right).\n$$\nHere $\\mathbf{z}_{i}=\\left(y_{i},\\mathbf{x}_{i}\\right)'$.</p>\n", 'ViewCount': '60', 'Title': 'How to compute a level set $A=\\left\\{ \\theta:f\\left(\\theta\\right)\\geq a\\right\\} $', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-20T21:29:32.707', 'LastEditDate': '2013-07-20T20:50:44.000', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9264', 'Tags': '<algorithms><probability-theory><mathematical-analysis><real-numbers>', 'CreationDate': '2013-07-20T19:24:23.690', 'Id': '13365'}{'Body': '<p>I\'m studying randomized algorithms and I sometimes come across results like</p>\n\n<blockquote>\n  <p>(1) The algorithm has an expected $O(f(n))$ cost.</p>\n</blockquote>\n\n<p>and</p>\n\n<blockquote>\n  <p>(2) With constant probability, the cost is bounded by $O(f(n))$.</p>\n</blockquote>\n\n<p>I\'m perfectly fine with statements like (2), but I\'m puzzled to what extent a statement like (1) is useful: \nFor certain probability distributions of a random variable, the expected value itself occurs with less than constant probability; for other distributions, it occurs with $1-1/n$ probability. Of course, in many cases, (1) is extended via concentration bounds to show high probability, but in cases where this isn\'t done, it doesn\'t seem that a statement on the "expected cost" lets us derive any implications on the actual performance of the algorithm, right?</p>\n', 'ViewCount': '88', 'Title': 'Interpretation of "expected cost" of an algorithm', 'LastEditorUserId': '9398', 'LastActivityDate': '2013-07-29T15:43:02.297', 'LastEditDate': '2013-07-29T03:06:35.717', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9398', 'Tags': '<probability-theory><randomized-algorithms>', 'CreationDate': '2013-07-29T01:58:55.503', 'Id': '13484'}{'Body': '<p>Consider 2 stations that share the same bus. Both stations are perfect synchronized each other and when they have packets to transmit, they are starting the transmission in the beginning of a same slot. Transmission is as follows: when base $i$ has a packet to transmit attempts with probability $p_i, i=1,2$. Different stations make the random selection independently and corresponding probabilities are $p_1=0.5, p_2=0.25$. Initially the station 1 has 2 packets for station 2, while the other has no package. </p>\n\n<p>What is the average number of slots in order all packets reach their destinations? Then if station 1 has 1 packet for station 2 and station 2 has 1 packet for station 1, what is the average number of slots? We are using slotted-Aloha.</p>\n', 'ViewCount': '328', 'Title': 'Average number of slots needed in slotted-Aloha', 'LastEditorUserId': '472', 'LastActivityDate': '2013-07-31T18:55:28.610', 'LastEditDate': '2013-07-31T18:55:28.610', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13517', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9412', 'Tags': '<probability-theory><computer-networks>', 'CreationDate': '2013-07-29T19:23:59.420', 'Id': '13498'}{'Body': '<p>I am looking for references for the following problem: \nI have a very special class of regular languages and my aim is to express (and to justify my conjecture) that this class itself is very small in some way (as a subset of the regular languages) and that the languages contained in this class are rather "bloated". </p>\n\n<p>For the latter point, I could prove that all languages in the class have a large diameter with respect to many common metrics on strings. However, I want to consider the following: Given a language from the class, we know it has a large diameter, but does it also have a large "volume" (that is, measure), or put differently, if I choose randomly a finite word, is there anything meaningful to say about how "probable" it is that the word belongs to the language? Of course, we can lift the problem: Picking a random language, how probable is it to get a language in the class?</p>\n\n<p>Are there any references or standard approaches for looking at classes of (regular) languages from this point of view (or is this considered as generally uninteresting)?</p>\n', 'ViewCount': '113', 'Title': 'Measures and probability in formal language theory', 'LastActivityDate': '2013-08-07T07:33:27.500', 'AnswerCount': '2', 'CommentCount': '11', 'AcceptedAnswerId': '13652', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<formal-languages><reference-request><regular-languages><probability-theory>', 'CreationDate': '2013-08-06T12:18:54.883', 'FavoriteCount': '1', 'Id': '13631'}{'Body': "<p>Currently, I'm delving into Analysis of Algorithms and I've discovered that I would need to improve my knowledge of Probability Theory. Any recommendation? Where do I start?\nThanks in advance!</p>\n", 'ViewCount': '195', 'Title': 'Recommended readings for Probability theory applied to algorithms', 'LastActivityDate': '2013-08-09T19:23:00.830', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '13690', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9085', 'Tags': '<algorithms><algorithm-analysis><probability-theory>', 'CreationDate': '2013-08-09T11:23:03.367', 'FavoriteCount': '4', 'Id': '13687'}{'ViewCount': '163', 'Title': "Little's law and average time on a system with a switch", 'LastEditDate': '2013-08-14T20:56:35.160', 'AnswerCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9412', 'FavoriteCount': '0', 'Body': '<p>We have a switch with $2$ lines of input and $2$ output. Each line is $10 Mbps$. The size of packets is fixed and is $1KB$. The $1^{st}$ line of input is active (transferring packets) $40\\%$ of the time, while the $2{nd}$ line is active $70\\%$ of the time. $\\frac{1}{4}$ of <strong>packets of input $1$</strong> (with arrival) directed to buffer of output line $1$, while the $\\frac{3}{4}$ directed to buffer of output line $2$. Respectively $\\frac{1}{2}$ of <strong>packets of input $2$</strong> go to buffer 1 and $\\frac{1}{2}$ to buffer $2$. Buffers $1$ and $2$ are monitored and we know that tha average number of packets in buffer $1$ is $3$ packets and in buffer $2$ is $4.5$ packets.There is also an external measurement system that measures the total time of packet input $1$ to the switch.Based on these measurements calculated the average time of packets of input $1$ in the system for those that are directed to output $1$ is $5mse$c and to output $2$ is $7msec$ . Find the average residence time of packets of input line $2$ that are directed to buffer $1$ and the average time in the system (for the same packets)</p>\n\n<p>note: the residence time of one packet on switch, is the time spent on buffer plus the transmission time from the output line</p>\n\n<p>Consider these cases:\n1) consider packets sit in the buffer until they are done being transmitted\n2) assume the transmitter works on one packet at a time and removes the packet from the buffer while it is working on it</p>\n', 'Tags': '<probability-theory><computer-networks>', 'LastEditorUserId': '9412', 'LastActivityDate': '2013-08-14T20:56:35.160', 'CommentCount': '2', 'AcceptedAnswerId': '13714', 'CreationDate': '2013-08-11T12:35:58.580', 'Id': '13705'}{'Body': u'<p>I have the following Bayesian Network and need help with answering the following query.</p>\n\n<p><img src="http://i.stack.imgur.com/30XAh.jpg" alt="enter image description here"></p>\n\n<p><strong>EDITED:</strong></p>\n\n<p>Here are my solutions to questions a and b:</p>\n\n<p><strong>a)</strong></p>\n\n<pre><code>P(A,B,C,D,E) = P(A) * P(B) * P(C | A, B) * P(D | E) * P(E | C)\n</code></pre>\n\n<p><strong>b)</strong></p>\n\n<pre><code>P(a, \xacb, c \xacd, e) = P(a) * P(\xacb) * P(c | a, b) * P(\xacd | \xacb) * P(e | c)\n\n= 0.02 * 0.99 * 0.5 * 0.99 * 0.88 = 0.0086\n</code></pre>\n\n<p><strong>c)</strong></p>\n\n<p>P(e | a, c, \xacb)</p>\n\n<p>This is my attempt:</p>\n\n<pre><code>a \xd7  \u2211 P(a, \xacb, c, D = d, e) =\n     d\n\n a \xd7 \u2211  { P(a) * P(\xacb) * P(c | a, b) * P(d) * P(e | c) + P(a) * P(\xacb) * P(c | a,b)    *P(\xacd)\n     d                                                                  + P(e | c) }\n</code></pre>\n\n<p>Note that a is the alpha constant and that a = 1/ P(a,\xacb, c) </p>\n\n<p>The problem I have is that I don\'t know how to compute the constant a that the sum is multiplied by. I would appreciate help because I\'m preparing for an exam and have no solutions available to this old exam question.</p>\n', 'ViewCount': '74', 'Title': 'Bayesian Network - Inference', 'LastEditorUserId': '4658', 'LastActivityDate': '2013-08-20T20:50:50.297', 'LastEditDate': '2013-08-20T19:51:09.100', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '13846', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4658', 'Tags': '<probability-theory>', 'CreationDate': '2013-08-18T20:32:42.753', 'Id': '13803'}{'Body': '<p>Suppose that there is an algorithm which sorts a sequence of $n$ elements</p>\n\n<p>$$a_1, a_2, ..., a_n$$</p>\n\n<p>Each of the $a_i$ is chosen with probability $1/k$ from a set of $k$ distinct integer numbers. </p>\n\n<p>Is it true, given that $k \\to \\infty$, that:</p>\n\n<ol>\n<li>The probability that any two of incoming sequence elements are equal, tends to $0$?</li>\n<li>The probability that the incoming sequence is already sorted, tends to $\\frac{1}{n!}$?</li>\n</ol>\n\n<p>Why / why not?</p>\n', 'ViewCount': '58', 'Title': 'Sort algorithm input probabilities', 'LastActivityDate': '2013-09-07T20:14:07.100', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '14199', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1198', 'Tags': '<probability-theory><sorting>', 'CreationDate': '2013-09-07T19:28:12.583', 'Id': '14198'}{'ViewCount': '117', 'Title': 'Probability that a uniformly random sequence is already sorted', 'LastEditDate': '2013-09-09T02:32:58.133', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1198', 'FavoriteCount': '1', 'Body': "<p>Now I tried tackling this question from different perspectives (and already asked a couple of questions here and there), but perhaps only now can I formulate it well and ask you (since I have no good ideas).</p>\n\n<p>Let there be $k, n \\in\\mathbb{Z_+}$. These are fixed.</p>\n\n<p>Consider a set of $k$ integers $S=\\{0, 1, 2, ... k-1\\}$.</p>\n\n<p>We form a sequence  $a_1, a_2, ..., a_n$ by picking numbers from $S$ at random with equal probability $1/k$.</p>\n\n<p>The question is - what is the probability of that sequence to be sorted ascending, i.e. $a_1 \\leq a_2 \\leq ... \\leq a_n$? </p>\n\n<p>Case $k \\to \\infty$:</p>\n\n<p>This allows us to assume (with probability tending to $1$) that all elements $a_1, ..., a_n$ are different. It means that only one ordering out of $n!$ possible is sorted ascending. </p>\n\n<p>And since all orderings are equally likely (not sure why though), the probability of the sequence to be sorted is</p>\n\n<p>$$\\frac{1}{n!}.$$</p>\n\n<p>Case k = 2:</p>\n\n<p>Now we have zeroes and ones which come to the resulting sequence with probability $0.5$ each. So the probability of any particular n-sequence is $\\frac{1}{2^n}$. </p>\n\n<p>Let us count the number of possible sorted sequences:</p>\n\n<p>$$0, 0, 0, \\ldots, 0, 0$$\n$$0, 0, 0, \\ldots, 0, 1$$\n$$0, 0, 0, \\ldots, 1, 1$$\n$$\\ldots$$\n$$0, 0, 1, \\ldots, 1, 1$$\n$$0, 1, 1, \\ldots, 1, 1$$\n$$1, 1, 1, \\ldots, 1, 1$$</p>\n\n<p>These total to $(n+1)$ possible sequences. Now again, any sequence is equally likely, so the probability of the sequence to be sorted is </p>\n\n<p>$$ \\frac{n+1}{2^n}. $$</p>\n\n<p>Question:</p>\n\n<p>I have no idea how to generalize it well for arbitrary $k, n$. Maybe we can tackle it together since my mathematical skills aren't really that high. </p>\n", 'Tags': '<combinatorics><probability-theory><sorting>', 'LastEditorUserId': '755', 'LastActivityDate': '2013-09-09T02:32:58.133', 'CommentCount': '0', 'AcceptedAnswerId': '14211', 'CreationDate': '2013-09-08T07:29:56.110', 'Id': '14209'}{'Body': u'<p>Suppose I have a connected graph with $n$ vertices and $n\u22121$ edges, that is in form of a tree. Now, I will add the number of vertices in the tree and uniformly randomly select a vertex. I break the graph at this selected vertex, deleting the vertex and the edges connected to it. Now, I again repeat the same thing at all of the left components (sub-trees) until I am left with one vertex for which the answer is inherently $1$. What will be the expectation of the sum obtained by adding the number of vertices recursively in such a problem?</p>\n\n<p>For example, I have 3 vertices, A, B and C in which A is connected to B as well as C, but B and C are not connected. Like, B--A--C. Now, I could select any one vertex out of three with probability 1/3, so I add 3. Now, if I had selected A, I would repeat this for B and C separately adding one for each case. Otherwise, selecting B or C, I would have repeated it on A--C or B--A respectively, adding 2 and selecting each node again with probability 1/2.</p>\n\n<p>I agree the problem is weakly written, here is a formulation suggested by <a href="http://cs.stackexchange.com/users/5167/karolis-juodel">Karolis Juodel\u0117</a>:\nI\'m looking for the expected value of $f(G) = \\left|V_G\\right| + \\sum f(G_i)$ where $G_i$ are components remaining after removing a random vertex of $G$.</p>\n', 'ViewCount': '61', 'Title': 'Which component sizes do we observe while randomly deconstructing a tree?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-11-28T21:37:06.417', 'LastEditDate': '2013-11-28T21:37:06.417', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8619', 'Tags': '<graphs><probability-theory><trees>', 'CreationDate': '2013-09-10T17:58:03.147', 'Id': '14252'}{'ViewCount': '57', 'Title': 'Post-selection and complexity theory', 'LastEditDate': '2013-09-17T08:32:43.633', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Body': "<p>I read about post-selection and didn't understand the meaning behind this thing. I didn't understand the Wikipedia article well, so what is a simple but understandable explanation of post-selection and how to use it in complexity?   </p>\n", 'ClosedDate': '2013-09-30T07:56:33.610', 'Tags': '<complexity-theory><terminology><probability-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-17T16:55:42.447', 'CommentCount': '3', 'AcceptedAnswerId': '14371', 'CreationDate': '2013-09-16T20:53:29.813', 'Id': '14364'}{'Body': "<p>Consider the following random process.  We have a $10\\times 10$ grid.  At each time step, we pick a random empty grid cell (selected uniformly at random from among all empty cells) and place a marker in that grid cell.  As soon as we have five contiguous markers in a line (in a row, column, or diagonal), we stop.</p>\n\n<p>I'm given a grid containing some markers in some positions, and I'd like to estimate how long until the process stops if we start from that configuration (i.e., the number of additional time steps until five-in-a-line occurs).  I would be happy with any reasonable metric for that: e.g., the expected time until it stops, or the value $t$ such that there's a probability $0.5$ that the process will stop in $\\le t$ time steps.  I'd be happy with an estimate of any such metric.</p>\n\n<p>Is there any efficient algorithm to estimate this metric, given a configuration where some markers have already been placed?  I'm hoping for something faster than random simulation (repeatedly simulating the process and computing an estimate based upon the resulting empirical distribution).</p>\n", 'ViewCount': '129', 'Title': 'Estimating the time until we obtain five-in-a-row?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-25T20:05:32.690', 'LastEditDate': '2013-10-04T06:45:50.277', 'AnswerCount': '1', 'CommentCount': '12', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<algorithms><combinatorics><probability-theory><approximation>', 'CreationDate': '2013-10-02T04:18:07.603', 'FavoriteCount': '1', 'Id': '14745'}{'Body': "<p>I would like to measure what is the probability that given some data and it's CRC32 checksum there is some other data with the same checksum.<br>\nRunning the simulation is not feasible because of the 2^32 possible values.<br>\nRunning the simulation for the birthday problem is feasible (check if there is a collision among n checksums)<br>\nIs there a way to infer the probability mentioned above by simulating the birthday problem?</p>\n", 'ViewCount': '83', 'Title': 'Measuring uniformity of CRC32 by using birthday problem', 'LastActivityDate': '2013-10-29T13:37:07.183', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '-3', 'PostTypeId': '1', 'OwnerUserId': '5081', 'Tags': '<probability-theory>', 'CreationDate': '2013-10-29T10:27:32.513', 'Id': '16536'}{'Body': '<p>consider a program that generates a <a href="http://en.wikipedia.org/wiki/Random_walk" rel="nofollow">random walk</a> using a <a href="http://en.wikipedia.org/wiki/Pseudorandom_number_generator" rel="nofollow">PRNG</a>, as in following pseudocode. it uses <a href="http://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic" rel="nofollow">arbitrary precision arithmetic</a> such that there is no limit on variable values (ie no overflow).</p>\n\n<pre><code>srand(x)\nz = 0\nwhile (z &gt;= 0)\n{\n  r = rand(100)\n  if (r &lt;= 50) z -= 1\n  else z += 1\n}\n</code></pre>\n\n<p>the PRNG is inited with seed <code>x</code> <em>(also arbitrary precision).</em> the PRNG <code>rand(100)</code> generates a value between <code>0..99</code>. hence for 51 values the accumulator var <code>z</code> is decremented, for 49 values it is incremented.</p>\n\n<p>it is expected due to the <a href="http://en.wikipedia.org/wiki/Law_of_large_numbers" rel="nofollow">law of large numbers</a> that this program will halt for all initial seeds <code>x</code>. however, </p>\n\n<blockquote>\n  <p>how does one prove it will halt for all initial seeds <code>x</code>?</p>\n</blockquote>\n\n<p>it seems such a proof must depend on the details of the construction of the PRNG. am assuming there exist PRNGs such that a different random sequence is generated for every initial seed <code>x</code> (ie the infinite set of naturals). that in itself may be up for question. are such PRNGs known? where are they used? etc.. so an answer may come up with an arbitrary PRNG for the purposes of the question. a single example fulfilling the criteria would be an acceptable answer.</p>\n\n<p>looking for related literature, similar problems/proof considered, etc.</p>\n', 'ViewCount': '58', 'Title': 'proof of convergence in arbitrary precision PRNGs', 'LastActivityDate': '2013-11-19T00:38:41.127', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<algorithms><reference-request><probability-theory><pseudo-random-generators><random-walks>', 'CreationDate': '2013-11-18T21:52:05.343', 'FavoriteCount': '1', 'Id': '18132'}{'Body': '<p>I have this nondeterministic pda:\n$$\\Sigma=  \\{a,b,c\\}$$</p>\n\n<p>and </p>\n\n<p>$$\nL=\\{\\omega\\  \\epsilon\\ \\Sigma^*\\ |\\ \\omega\\ = \\alpha\\beta\\beta^R\\gamma\\ and\\ \\alpha,\\beta,\\gamma\\ \\epsilon\\ \\Sigma^*\\ and\\ |\\beta|\\ &gt;3 \\}\n$$</p>\n\n<p>So once i have create the NPDA, i have to calculate the probability of accepting a correct word, i know it depends on the size of $\\alpha$ and the "free" jumps ($\\varepsilon,\\varepsilon-&gt;\\varepsilon$).\nMy problem is that i can\'t find the exact function of probability can someone explain me how to do it?</p>\n\n<p>Thanks.</p>\n', 'ViewCount': '90', 'Title': 'help with the probability of acceptance of a Nondeterministic Pushdown automata', 'LastActivityDate': '2013-11-29T22:57:27.457', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '18468', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '11695', 'Tags': '<context-free><probability-theory><pushdown-automata><nondeterminism>', 'CreationDate': '2013-11-29T11:15:00.567', 'Id': '18464'}{'ViewCount': '67', 'Title': 'Naive Bayes Intuition', 'LastEditDate': '2013-12-22T08:13:28.823', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8473', 'FavoriteCount': '1', 'Body': "<p>I have some difficulties in understanding the intuition behind Naive Bayes Classification.</p>\n\n<p>In general, I do understand every argument of the definition, however I don't understand why it's correct and why any other argument is incorrect.</p>\n\n<p>Start from the beginning:</p>\n\n<p><strong>Goal:</strong> $v_{MAP} = argmax_{v_i} p(v_i|a_1...a_n)$</p>\n\n<p>the goal is simply to find the maximum aposteriori of the value of the target function given the set of features Note,  here we don't mention the hypothesis, because we are not interested in hypothesis.</p>\n\n<p>After developing the formula with Bayes formula, we get</p>\n\n<p>$argmax_{v_i} p(v_i)p(a_1...a_n|v_i)$</p>\n\n<p>Now, the trick goes $p(a_1...a_n|v_i)=\\prod_{j} p(a_j|v_i)$</p>\n\n<p>The question is why in the very begging, having the formula of</p>\n\n<p>$v_{MAP} = argmax_{v_i} p(v_i|a_1...a_n)$</p>\n\n<p>I cannot apply the trick $p(v_i|a_1...a_n)=\\prod_{j} p(v_i|a_j)$</p>\n\n<p>It's just a reverse direction, in addition we don't have to calculate the prior probability of $p(v_i)$, so for me it looks like the better way to go.</p>\n\n<p>What's wrong with my reasoning.</p>\n", 'Tags': '<machine-learning><probability-theory>', 'LastEditorUserId': '8473', 'LastActivityDate': '2013-12-22T19:48:04.187', 'CommentCount': '1', 'AcceptedAnswerId': '19185', 'CreationDate': '2013-12-21T11:32:10.787', 'Id': '19175'}{'Body': '<p>An adversary gives you a set of items whose total size is $x$ (he gets to choose how $x$ is distributed. e.g. there may be $k-1$ items of size $\\frac{x}{k}$ and 2 items of size $\\frac{x}{2k}$).</p>\n\n<p>The item are now randomly distributed into $2x$ bins (you may assume $2x\\in \\mathbb{N}$).</p>\n\n<p>What\'s the probability (i.e. what can we guarantee to achieve for any adversarial choice)  no bin contains items with total size > 1?</p>\n\n<hr>\n\n<p>For example, if the adversary chose all items (except for the last one) to be of size $\\frac{1}{2} + \\epsilon$ , then we have $2x-1$ items that no two of them can fit in a single bin. The last item can fit everywhere. hence the probability is bounded by (relaxing to $2x-1$ bins):</p>\n\n<p>$\\frac{(2x-1)!}{(2x-1)^{2x-1}} &lt; e^{-(2x-1)}$ .</p>\n\n<p>On the other hand, all I know for a general item set is that a "good" coloring exist (easy to see using the first fit algorithm).</p>\n\n<p>Any ideas?</p>\n', 'ViewCount': '27', 'Title': 'Adversarial bin packing', 'LastEditorUserId': '12486', 'LastActivityDate': '2013-12-31T09:37:08.750', 'LastEditDate': '2013-12-31T09:37:08.750', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12486', 'Tags': '<combinatorics><probability-theory><lower-bounds><knapsack-problems><packing>', 'CreationDate': '2013-12-31T09:24:16.570', 'Id': '19398'}{'Body': '<p>I was trying to understand better the definition of a strong PSRG and I came across this expression which I am trying to understand better:</p>\n\n<p>$$ Pr_{r \\in \\{0,1\\}^l}[A(r) = \\text{"yes"}]$$</p>\n\n<p>Where r is a truly random bit string and A is a polynomial time deterministic machine.\nI\'ve been having some problems understanding what this expression means conceptually (or intuitively). </p>\n\n<p>So far these are some of my thoughts and I will try to point out my doubts too.</p>\n\n<p>A is just a standard TM so we can image that on l steps, it will yield $2^l$ branches. Each branch has a chance of occurring depending on which r occurs. Therefore, I was wondering if the above probability expression just mean "the fraction of branches that out yes"? Is that basically the same as the chance that A will output yes on the given random bit string? The thing that was confusing me and I was not sure how to deal with it was that, A(r) always outputs the same thing ("yes" or "no") on a given r (say it always accepts or rejects if r = 1010100 or something), it didn\'t seem to me that it a probabilistic sense, unless we randomly choose r. So I was wondering how the community interpreted this equation and what it mean.</p>\n\n<p>Also, since this is a probability, it seems to me that A(r) is just r.v. that only takes two values (yes or no), right? So this distribution only has two probability values, the one that A outputs yes or no, right? I was wondering how that related to the string r and I was not sure how to resolve this.</p>\n', 'ViewCount': '32', 'Title': 'Interpreting probabilistic time turning machines', 'LastEditorUserId': '13012', 'LastActivityDate': '2014-01-24T19:23:21.040', 'LastEditDate': '2014-01-24T19:23:21.040', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19943', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '13012', 'Tags': '<terminology><probability-theory><randomized-algorithms><randomness>', 'CreationDate': '2014-01-24T04:54:38.433', 'Id': '19932'}{'Body': '<p>I am learning Probabilistic Graphical Models with the help of the videos on Coursera. I am in week 4 and I see cliques being mentioned often. But the graphs being discussed are cluster graphs. So are the cliques and clusters the same?</p>\n', 'ViewCount': '47', 'Title': 'In Probabilistic Graphical Models, are Cliques and Clusters the same?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-09T08:02:50.520', 'LastEditDate': '2014-02-07T07:39:57.253', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12813', 'Tags': '<graph-theory><terminology><probability-theory><graphical-models>', 'CreationDate': '2014-02-06T22:07:25.603', 'Id': '21406'}{'Body': "<p>I'm a CS undergrad so my math/CS knowledge is not that deep so please correct me if my premise is flawed or I have made some incorrect assumptions.</p>\n\n<p>So I was thinking, much in the way that some primality testers are probabilistic(they give you yes or no but have a chance to be wrong). Would it be possible to build a probabilistic halting problem solver? One that reports within a certain degree of error, whether a problem halts or not?</p>\n", 'ViewCount': '70', 'Title': 'Possible to construct a probabilistic halting problem solver?', 'LastActivityDate': '2014-02-13T02:24:54.360', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '13245', 'Tags': '<probability-theory><halting-problem><probabilistic-algorithms>', 'CreationDate': '2014-02-12T23:13:06.320', 'FavoriteCount': '1', 'Id': '21581'}{'Body': '<p>Consider the following soft margin loss function: $\\max(0, 1-yf(x))$.  I have the problem of needing to compute the conditional probability $p(y|x)$ corresponding to this function and am having trouble making the connection between conditional probability and this function.  I have come across a few papers (e.g. <a href="http://www.unc.edu/~yfliu/papers/lum.pdf" rel="nofollow">http://www.unc.edu/~yfliu/papers/lum.pdf</a>) that say that "soft classifiers explicitly calculate the class conditional probabilities", but I do not understand how as the output of a classifier is not a probability.  Can someone please explain what I am missing?</p>\n', 'ViewCount': '73', 'Title': 'Soft Margin Loss and Conditional Probabilities', 'LastEditorUserId': '683', 'LastActivityDate': '2014-03-31T12:54:01.220', 'LastEditDate': '2014-03-11T11:50:27.197', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15425', 'Tags': '<machine-learning><probability-theory><classification>', 'CreationDate': '2014-03-11T08:42:06.473', 'Id': '22494'}{'ViewCount': '360', 'Title': 'Is this method really uniformly random?', 'LastEditDate': '2014-03-25T22:35:47.140', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '16107', 'FavoriteCount': '2', 'Body': "<p>I have a list and want to select a random item from the list.</p>\n\n<p>An algorithm which is said to be random:</p>\n\n<blockquote>\n  <p>When you see the first item in the list, you set it as the selected item.</p>\n  \n  <p>When you see the second item, you pick a random integer in the range [1,2]. If it's 1, then the new item becomes the selected item. Otherwise you skip that item.</p>\n  \n  <p>For each item you see, you increase the count, and with probability 1/count, you select it. So at the 101st item, you pick a random integer in the range [1,101]. If it's 100, that item is the new selected node.</p>\n</blockquote>\n\n<p>Is it really uniformly random?</p>\n\n<p><strong>My thoughts are:</strong></p>\n\n<p>As the number of nodes increases, the probability for them being selected \ndecreases, so the best chance of selection is for items 1, 2, 3, ..., not for 20, 21, ..., 101.</p>\n\n<p>Each node will not have equal probability of being selected.</p>\n\n<p>Please clarify, as I have trouble understanding this.</p>\n", 'Tags': '<algorithms><probability-theory><randomized-algorithms><sampling>', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-03-25T22:35:47.140', 'CommentCount': '5', 'AcceptedAnswerId': '23041', 'CreationDate': '2014-03-25T17:55:00.713', 'Id': '23038'}{'Body': "<p>I am facing hard time understanding min-entropy.</p>\n\n<p>Fix $v \\in \\{0,1\\}^{n/2}$, let $F\\colon \\{0,1\\}^n \\to \\{0,1\\}^{n/2}$ be chosen randomly, and let $X_v$ be a string chosen uniformly at random among $F^{(-1)}(v)$ (or a special string $\\epsilon$ if $F^{(-1)}(v) = \\emptyset$). We want to compute the probability that $H_\\infty(X_v) \\leq n/4$ (over the choice of $F$), where $H_\\infty(X_v)=-\\log(\\max_{x}\\{\\Pr[X_v=x]\\})$ is the <em>min-entropy</em> of $X_v$.</p>\n\n<p>It's not obvious what approach is needed to solve such things! It would be helpful if one could explain where to start...</p>\n", 'ViewCount': '45', 'Title': 'Min-entropy of a random pre-image of a random function', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-02T17:29:49.140', 'LastEditDate': '2014-04-02T16:38:26.167', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '23355', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Tags': '<probability-theory>', 'CreationDate': '2014-04-01T14:48:04.393', 'Id': '23319'}{'Body': u"<p>That's the problem</p>\n\n<p>$$y=(x,w,\\rho) = \\begin{cases}\n 1 &amp; \\sum_{i=1}^3 w_ix_i &gt;\\rho\\\\\n 0 &amp; \\text{otherwise}\n\\end{cases},$$</p>\n\n<p>where $x=\\{x_1,x_2,x_3\\}$ are inputs, $w=\\{w_1,w_2,w_3\\}$ are weights and\n$\\rho$ is the threshold value.</p>\n\n<p>The problem asks to find an opportune set of weights that can \nclassify these inputs.</p>\n\n<p>$$A = \\{(1, 2, 0), (\u22121, 3, 0), (\u22122, \u22123, 0)\\},$$ \n$$B = \\{(0,1,2),(9,0,1),(\u22123,\u22123,3)\\}.$$</p>\n\n<p>The first step is to assign a random weights to all inputs</p>\n\n<p>$w_1= 0.5$, $w_2= 0.7$, $w_3=0.3$.</p>\n\n<p>For the first example\n$(1,2,0)$ that I know is part of the A class</p>\n\n<p>$\\sum_{i=1}^3 w_ix_i=1.9 &lt; \\rho~ \\Rightarrow y=0$ is the result.</p>\n\n<p>I need to update the weights but I can't understand how.</p>\n\n<p>The formula is</p>\n\n<p>$w_i'=w_i*n*x(t-y)$.</p>\n\n<p>Correct?</p>\n", 'ViewCount': '51', 'Title': 'Perceptron learning rule for classification', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T08:18:17.777', 'LastEditDate': '2014-04-09T11:47:08.043', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '-3', 'PostTypeId': '1', 'OwnerUserId': '12495', 'Tags': '<artificial-intelligence><probability-theory><neural-networks><classification>', 'CreationDate': '2014-04-09T09:05:18.430', 'Id': '23589'}{'Body': '<p>To add onto the question, how are elliptical differential equations applicable in this context?</p>\n\n<p>I was listening to a talk about Bayesian networks and someone asked if they were using differential elliptical equations in the context of linear relaxation.</p>\n', 'ViewCount': '21', 'ClosedDate': '2014-04-26T12:17:39.360', 'Title': 'What is linear relaxation in the context of bayesian networks?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-23T06:00:46.480', 'LastEditDate': '2014-04-23T06:00:46.480', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17012', 'Tags': '<machine-learning><probability-theory><linear-programming>', 'CreationDate': '2014-04-23T03:43:13.713', 'Id': '24039'}