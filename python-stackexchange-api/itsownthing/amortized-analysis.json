{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '2489', 'Title': 'Does there exist a priority queue with $O(1)$ extracts?', 'LastEditDate': '2012-03-19T19:11:15.323', 'AnswerCount': '9', 'Score': '25', 'PostTypeId': '1', 'OwnerUserId': '92', 'FavoriteCount': '6', 'Body': '<p>There are a great many data structures that implement the priority-queue interface:</p>\n\n<ul>\n<li>Insert: insert an element into the structure</li>\n<li>Get-Min: return the smallest element in the structure</li>\n<li>Extract-Min: remove the smallest element in the structure</li>\n</ul>\n\n<p>Common data structures implementing this interface are (min)<a href="http://en.wikipedia.org/wiki/Heap_%28data_structure%29">heaps</a>.</p>\n\n<p>Usually, the (amortized) running times of these operations are:</p>\n\n<ul>\n<li>Insert: $\\mathcal{O}(1)$ (sometimes $\\mathcal{O}(\\log n)$)</li>\n<li>Get-Min: $\\mathcal{O}(1)$</li>\n<li>Extract-Min: $\\mathcal{O}(\\log n)$</li>\n</ul>\n\n<p>The <a href="http://en.wikipedia.org/wiki/Fibonacci_heap">Fibonacci heap</a> achieves these running times for example. Now, my question is the following:</p>\n\n<blockquote>\n  <p>Is there a data structure with the following (amortized) running times?</p>\n</blockquote>\n\n<ul>\n<li>Insert: $\\mathcal{O}(\\log n)$</li>\n<li>Get-Min: $\\mathcal{O}(1)$</li>\n<li>Extract-Min: $\\mathcal{O}(1)$</li>\n</ul>\n\n<p>If we can construct such a structure in $\\mathcal{O}(n)$ time given sorted input, then we can for instance find line intersections on pre-sorted inputs with $o\\left(\\frac{n}{\\log n}\\right)$ intersections strictly faster than if we use the \'usual\' priority queues.</p>\n', 'Tags': '<data-structures><amortized-analysis><priority-queues>', 'LastEditorUserId': '31', 'LastActivityDate': '2013-01-04T21:08:37.440', 'CommentCount': '4', 'AcceptedAnswerId': '537', 'CreationDate': '2012-03-19T14:31:46.663', 'Id': '524'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1671', 'Title': 'Data structure with search, insert and delete in amortised time $O(1)$?', 'LastEditDate': '2012-05-22T07:32:22.800', 'AnswerCount': '2', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '1120', 'FavoriteCount': '7', 'Body': '<p>Is there a data structure to maintain an ordered list that supports the following operations in $O(1)$ amortized time? </p>\n\n<ul>\n<li><p><strong>GetElement(k)</strong>: Return the $k$th element of the list.</p></li>\n<li><p><strong>InsertAfter(x,y)</strong>: Insert the new element y into the list immediately after x.  </p></li>\n<li><p><strong>Delete(x)</strong>: Remove x from the list.</p></li>\n</ul>\n\n<p>For the last two operations, you can assume that x is given as a pointer directly into the data structure; InsertElement returns the corresponding pointer for y.  InsertAfter(NULL, y) inserts y at the beginning of the list.</p>\n\n<p>For example, starting with an empty data structure, the following operations update the ordered list as shown below:</p>\n\n<ul>\n<li>InsertAfter(NULL, a) $\\implies$ [a]</li>\n<li>InsertAfter(NULL, b) $\\implies$ [b, a]</li>\n<li>InsertAfter(b, c) $\\implies$ [b, c, a]</li>\n<li>InsertAfter(a, d) $\\implies$ [b, c, a, d]</li>\n<li>Delete(c) $\\implies$ [b, a, d]</li>\n</ul>\n\n<p>After these five updates, GetElement(2) should return d, and GetElement(3) should return an error.</p>\n', 'Tags': '<data-structures><time-complexity><asymptotics><amortized-analysis>', 'LastEditorUserId': '72', 'LastActivityDate': '2013-08-06T14:07:23.407', 'CommentCount': '8', 'AcceptedAnswerId': '7807', 'CreationDate': '2012-05-21T07:35:55.077', 'Id': '1970'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I understood what amortized analysis does, but can anyone tell me what is the main purpose of this kind of analysis?</p>\n\n<p>What I understood:</p>\n\n<p>Let say we have 3 three operations a,b,c used 1,2 and 3 times to achieve d. Based on aggregate analysis a,b and c are used 2 times each. Is this correct?</p>\n\n<p>I am trying to understand the advantages of this in CLRS but I am completely lost. For example in dynamic programming we save the answers to sub problems in tables which helps us reduce the running time(lets say from exponential to polynomial). But I am unable to get a complete picture of amortized analysis.</p>\n', 'ViewCount': '356', 'Title': 'Advantages of amortized analysis', 'LastEditorUserId': '2755', 'LastActivityDate': '2014-05-03T23:17:14.713', 'LastEditDate': '2012-11-25T07:34:07.733', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '6873', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '3004', 'Tags': '<time-complexity><algorithm-analysis><amortized-analysis>', 'CreationDate': '2012-11-24T07:49:27.967', 'Id': '6865'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In <a href="http://en.wikipedia.org/wiki/Fibonacci_heap" rel="nofollow">Fibonacci heaps</a>, we keep a mark field for every node in the heap. Initially all the nodes are unmarked. Once a node is deleted, its parent is marked. If a node is deleted and its parent is already marked, the parent will be cut and inserted into the root list. I just wonder what the purpose of marking is? What happens if we cut the parent just the first time without marking it? Does it change the time complexity of the operations? How?</p>\n', 'ViewCount': '275', 'Title': 'What is the purpose of Mark field in Fibonacci Heaps?', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-19T09:58:56.557', 'LastEditDate': '2012-12-19T09:58:56.557', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7510', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1672', 'Tags': '<data-structures><heaps><amortized-analysis>', 'CreationDate': '2012-12-19T08:11:04.093', 'Id': '7505'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I need help figuring the potential function for a max heap so that extract max is completed in $O(1)$ amortised time. I should add that I do not have a good understanding of the potential method. </p>\n\n<p>I know that the insert function should "pay" more in order to reduce the cost of the extraction, and this has to be in regards to the height of the heap (if $ \\lfloor \\log(n) \\rfloor $ gives the height of the heap should the insert be $2\\log(n)$ or $ \\sum_{k=1}^n 2\\log(k) $)</p>\n', 'ViewCount': '783', 'Title': 'Potential function binary heap extract max O(1)', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-14T20:34:01.887', 'LastEditDate': '2013-01-14T20:34:01.887', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7901', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '5384', 'Tags': '<data-structures><runtime-analysis><heaps><amortized-analysis>', 'CreationDate': '2013-01-11T23:41:04.057', 'Id': '7894'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '267', 'Title': 'Questions about amortised analysis', 'LastEditDate': '2013-01-19T18:04:21.067', 'AnswerCount': '4', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '5053', 'FavoriteCount': '3', 'Body': '<p>As a preperation of an exam about algorithms and complexity, I am currently solving old exercises. One concept I have already been struggling with when I encountered it for the first time is the concept of amortised analysis. What is amortised analysis and how to do it? In our lecture notes, it is stated that "amortised analysis gives bounds for the "average time" needed for certain operation and it can also give a bound for the worst case". That sounds really useful but when it comes to examples, I have no idea what I have to do and even after having read the sample solution, I have no idea what they are doing.</p>\n\n<blockquote>\n  <p>Let\'s add up 1 in base 2, i.e. 0, 1, 10, 11, 100, 101, 110, 111, 1000, ... Using amortised analysis, show that in each step only amortised constantly many bits need to be changed.</p>\n</blockquote>\n\n<p>(the exercise originally is in German, so I apologise for my maybe not perfectly accurate translation)</p>\n\n<p>Now the standard solution first defines $\\phi(i) := c \\cdot \\# \\{\\text{1-bits in the binary representation}\\}$ for some constant $c &gt; 0$. I think this is what is called the potential function which somehow corresponds to the excessive units of time (but I have no idea why I would come up with this particular definition). Assuming that we have to change $m$ bits in the $i$-th step. Such a step always is of the form</p>\n\n<p>$$\\dots \\underbrace{0 1 \\dots 1}_m \\to \\dots \\underbrace{1 0 \\dots 0}_m.$$</p>\n\n<p>This statement is understandable to me, however again I fail to see the motivation behind it. Then, out of nowhere, they come up with what they call an "estimate"</p>\n\n<p>$$a(i) = m + c(\\phi(i) - \\phi(i-1)) = m + c(-m + 2)$$</p>\n\n<p>and they state that for $c=1$, we get $a(i)=2$ which is what we had to show.</p>\n\n<p>What just happened? What is $a(i)$? Why can we choose $c=1$? In general, if I have to show that in each step only amortised constantly many "units of time" are needed, does that mean that I have to show that $a(i)$ is constant?</p>\n\n<p>There are a few other exercises regarding amortised analysis and I don\'t understand them either. I thought if someone could help me out with this one, I could give the other exercises another try and maybe that\'ll help me really grasp the concept.</p>\n\n<p>Thanks a lot in advance for any help.</p>\n', 'Tags': '<algorithm-analysis><proof-techniques><amortized-analysis>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-21T09:05:29.557', 'CommentCount': '2', 'AcceptedAnswerId': '9023', 'CreationDate': '2013-01-18T10:20:25.633', 'Id': '9021'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1342', 'Title': 'Why is push_back in C++ vectors constant amortized?', 'LastEditDate': '2013-02-01T22:45:15.410', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '2860', 'FavoriteCount': '2', 'Body': '<p>I am learning C++ and noticed that the running time for the push_back function for vectors is constant "amortized." The documentation further notes that "If a reallocation happens, the reallocation is itself up to linear in the entire size."</p>\n\n<p>Shouldn\'t this mean the push_back function is $O(n)$, where $n$ is the length of the vector? After all, we are interested in worst case analysis, right?</p>\n\n<p>I guess, crucially, I don\'t understand how the adjective "amortized" changes the running time.</p>\n', 'Tags': '<algorithms><time-complexity><amortized-analysis>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-02-01T22:45:15.410', 'CommentCount': '1', 'AcceptedAnswerId': '9382', 'CreationDate': '2013-02-01T07:17:05.997', 'Id': '9380'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am trying to understand how to do the amortized cost for a dynamic table. Suppose we are using the accounting method.</p>\n\n<p>Let A of size m be an array of n elements. When $n = m$, then we create a new array of size $4m$, and then copy the elements of A to the new array. When $n = \\frac{m}{4}$, then you create a new array of size $\\frac{m}{4}$, and copy the elements to that array.</p>\n\n<p>What I am confused about is how to calculate the costs.\nFrom what I know so far:\nBefore the first expansion, you pay two dollars to insert. <code>1$</code> for the insert, and <code>1$</code> you just store with the element, so that you can use that later for a copy operation.</p>\n\n<p>Then when you expand it, you use that stored <code>$</code> to move the element to the new array.\nNow in the new array the elements won't have any <code>$</code> with them. But now as you insert a new element, you use <code>3$</code>. <code>1$</code> for the insert, then one more for itself (for a future copy), and one more for the previous element that was just copied.</p>\n\n<p>The problem here is, what if you have an array like this:</p>\n\n<p><code>1$ 2$</code></p>\n\n<p>Then insert an element</p>\n\n<p><code>1$ 2 3$ _ _ _ _ _</code></p>\n\n<p>Now how do you handle a delete operation?</p>\n", 'ViewCount': '207', 'Title': 'How to compute amoritized cost for a dynamic array?', 'LastEditorUserId': '7492', 'LastActivityDate': '2013-05-05T18:24:05.000', 'LastEditDate': '2013-05-05T18:24:05.000', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<data-structures><algorithm-analysis><amortized-analysis>', 'CreationDate': '2013-03-09T01:47:07.637', 'Id': '10399'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>If you have a dynamic array where the size $s$ becomes $4s$ when you fill the array and there are no delete operations. How much do you spend per insert?</p>\n\n<p>I am asking because when the size doubles, you only spend 3 dollars per insert (based on <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/lec13.pdf" rel="nofollow">this</a> analysis). But when you make the size 4 times bigger, then for some of the inserts you would need to spend 3\\$ and for the rest you spend 2$?</p>\n\n<p>Is this right? Or do we always need to spend the same amount? And if there is extra we just store it in the bank?</p>\n', 'ViewCount': '23', 'ClosedDate': '2013-03-11T07:35:40.160', 'Title': 'amortized analysis accounting method', 'LastEditorUserId': '683', 'LastActivityDate': '2013-03-11T01:51:14.870', 'LastEditDate': '2013-03-11T01:51:14.870', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<amortized-analysis>', 'CreationDate': '2013-03-11T01:50:59.557', 'Id': '10445'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>If you have an array that expands when it is completely filled and the new size is \n<code>N = N + 1 + ceiling(log2(N))</code> (N is the current size, and then N becomes the new size)\n(log2 is log base 2).</p>\n\n<p>How can you do an amortized analysis for this? It is confusing because the size of the expansion of the array increases as N increases.</p>\n', 'ViewCount': '211', 'ClosedDate': '2013-03-11T07:36:23.980', 'Title': 'How to do amortized analysis for an expanding array?', 'LastActivityDate': '2013-03-11T05:08:05.053', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<amortized-analysis>', 'CreationDate': '2013-03-11T02:57:54.880', 'Id': '10446'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am trying to calculate the amortized cost of a dynamic array, that\'s size becomes 4 times the size when the array is filled. (when you re-size, you create a new one and copy the elements there).</p>\n\n<p><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/lec13.pdf" rel="nofollow">Here</a> is what I am reading from. (starts at pg. 30)\nThis example has the array doubling when it is filled.</p>\n\n<p>This is my potential function analysis so far:\nBut in the end I am getting 7-2i, I don\'t think it can be like that. I think the i\'s should cancel out.</p>\n\n<p>Does anyone know whats wrong?</p>\n\n<p>Potential of the array after the $i^{th}$ insertion is $\\Phi(D_i) = 4i - 4^{\\left\\lceil \\log_{4}i\\right\\rceil}$.</p>\n\n<p>Assume $4^{\\left\\lceil \\log_{4}0\\right\\rceil} = 0$.</p>\n\n<p>The amortized cost of the $i^{th}$ insertion is:</p>\n\n<p>$\\^c_i = c_i + \\Phi(D_i)-\\Phi(D_{i-1})$</p>\n\n<p>$~~~= \\{ i$ if $i-1$ is an exact power of $4$</p>\n\n<p>$~~~~~~~\\{ 1$ otherwise</p>\n\n<p>$~~~~~~~+ (4i-4^{\\left\\lceil \\log_{4}i\\right\\rceil})-(4(i-1)-4^{\\left\\lceil \\log_{4}\n(i-1)\\right\\rceil})$</p>\n\n<p>$~~~= \\{ i$ if $i-1$ is an exact power of $4$</p>\n\n<p>$~~~~~~~\\{ 1$ otherwise</p>\n\n<p>$~~~~~~~+ 4-4^{\\left\\lceil \\log_{4}i\\right\\rceil}+4^{\\left\\lceil \\log_{4}(i-1)\\right\\rceil}$</p>\n\n<p>Case 1 ($i-1$ is an exact power of $4$):</p>\n\n<p>$\\^c_i = i + 4-4^{\\left\\lceil \\log_{4}i\\right\\rceil}+4^{\\left\\lceil \\log_{4}(i-1)\\right\\rceil}$</p>\n\n<p>$~~~= i + 4-4(i-1)+(i-1)$</p>\n\n<p>$~~~= i + 4-4i+4+i-1$</p>\n\n<p>$~~~= 7-2i$</p>\n', 'ViewCount': '25', 'ClosedDate': '2013-03-12T10:25:30.603', 'Title': 'Potential function in amortized analysis', 'LastActivityDate': '2013-03-12T02:25:07.893', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<algorithms><algorithm-analysis><proof-techniques><amortized-analysis>', 'CreationDate': '2013-03-12T02:25:07.893', 'Id': '10463'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I cannot really find a source that does not use the same examples provided by CLRS. I need a simpler example than <code>MULTI-POP</code> example. Could someone provide an example and explain me:</p>\n\n<p>a) What is the difference between worst-case analysis and amortised analysis?</p>\n\n<p>b) What is the difference between average-case analysis and amortised analysis?</p>\n\n<p>c) In plain English(with using minimal notations), how can we provide a complexity(especially I am interested in potential method)</p>\n', 'ViewCount': '89', 'Title': 'Basics of Amortised Analysis', 'LastActivityDate': '2013-10-28T16:55:38.243', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8849', 'Tags': '<algorithm-analysis><asymptotics><amortized-analysis><average-case>', 'CreationDate': '2013-10-28T15:14:12.807', 'FavoriteCount': '1', 'Id': '16502'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '74', 'Title': 'Finding farthest item in an array with duplicates', 'LastEditDate': '2013-11-06T00:17:00.597', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9694', 'FavoriteCount': '1', 'Body': "<p>I have an array $A[]$ of size $L$, which contains numbers in the range $1 \\ldots N$.  Here $L&gt;N$, so the array will contain repetitions.  If $x,y$ are two numbers that are both present in the array, define the distance $d(x,y)$ to be the minimum difference in positions where $x,y$ appear, i.e.,</p>\n\n<p>$$d(x,y) = \\min \\{|i-j| : A[i]=x, A[j]=y\\}.$$</p>\n\n<p>Given a number $x$ that is present in the array, I need to find the number $y$ in the array distance from $x$ is as large as possible.  In other words, given $x$, I am trying to find $y$ that makes $d(x,y)$ as large as possible (subject to the restriction that $y$ is a number in $A[]$).</p>\n\n<p>Can this be done in $o(L)$ time per query?  It's OK to do some pre-processing of the array.</p>\n\n<p>For example, suppose the array is $[1,3,2,3,4,5,3]$.  Then $d(5,3)=1$, since there is a $5$ one position away from a $3$ (a $5$ appears at index $5$ and a $3$ appears at index $6$).  If the query is $x=5$, the correct answer is $y=1$, since this makes the value of $d(5,y)$ as large as possible.</p>\n", 'Tags': '<algorithms><arrays><amortized-analysis>', 'LastEditorUserId': '755', 'LastActivityDate': '2013-11-06T00:47:25.973', 'CommentCount': '4', 'AcceptedAnswerId': '16756', 'CreationDate': '2013-11-05T14:58:45.963', 'Id': '16739'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Imagine that we have an array like structure A with n elements all of which are initially 0.\n($A[i]=0$)</p>\n\n<p>What is a data structure that supports the following operations:</p>\n\n<p>1) Given an element A[i]=0 set A[i] to 1 in <strong>O(1) worst case</strong></p>\n\n<p>2) Given the index i return A[i] in <strong>O(1) worst case</strong></p>\n\n<p>3) Given the index i retrun the smallest $j\\geq i$ such that $A[j]=0$ or $-1$ if there is no such index in <strong>amortized time as small as possible</strong>  </p>\n\n<p>Obviously an array supports the first 2. It doesnt not support 3). How to modify it?</p>\n', 'ViewCount': '82', 'Title': 'array with a twist', 'LastActivityDate': '2013-12-05T06:59:31.867', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '18633', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11821', 'Tags': '<amortized-analysis>', 'CreationDate': '2013-12-05T01:57:00.997', 'Id': '18626'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>When talking about general data structure design, my lecture notes talk about one of the concerns being cost of operations. As well as the individual cost, it mentions amortized cost. But then it goes on to say:</p>\n\n<blockquote>\n  <p>Amortized cost can be:</p>\n  \n  <ul>\n  <li>absolute (e.g. for every sequence \u03c3 of operations (O(n log n))</li>\n  <li>competitive (e.g. for every sequence \u03c3 of operations O(OPT(\u03c3)))</li>\n  </ul>\n  \n  <p>where OPT(\u03c3) is the optimal cost of clairvoyant algorithms</p>\n</blockquote>\n\n<p>I can\'t really make any sense of this. Googling <a href="https://en.wikipedia.org/wiki/Page_replacement_algorithm#The_theoretically_optimal_page_replacement_algorithm" rel="nofollow">throws up this</a> but I can\'t see the relevance to data structures more generally. Can anyone help me understand the quoted text?</p>\n', 'ViewCount': '134', 'Title': 'What is a clairvoyant algorithm?', 'LastEditorUserId': '10036', 'LastActivityDate': '2014-02-11T22:58:46.517', 'LastEditDate': '2014-02-11T22:58:46.517', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '20037', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10036', 'Tags': '<algorithms><terminology><data-structures><amortized-analysis>', 'CreationDate': '2014-01-28T10:31:46.363', 'Id': '20035'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>This is a question I have stumbled upon in my textbook, and didn't really know how to approach:</p>\n\n<p>Given a $k$-bit binary counter.\nWe have an operation Increment, which adds 1 to the counter.\nWe add a new operation Decrement, which subtracts 1 from the counter.\nProve that the cost for executing $n$ operations is $\\Theta(nk)$.</p>\n", 'ViewCount': '32', 'ClosedDate': '2014-03-12T09:25:27.037', 'Title': 'Binary counter amortized analysis', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-03-10T12:12:13.747', 'LastEditDate': '2014-03-10T11:34:25.743', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14724', 'Tags': '<algorithms><algorithm-analysis><amortized-analysis>', 'CreationDate': '2014-03-10T10:34:20.833', 'Id': '22460'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm a having trouble analyzing this algorithm.\nThis is a binary counter that supports only increments in $2^i$ values\nit's implemented in this way:\nstarting from the $i$-th location change all the straight $1$'s to $0$'s and the first $0$ to $1$.</p>\n\n<p>So I analyzed the W.C to be $O(\\log n)$ because the worst case is we need to increment by $1$ a $2^i-1$ number.\nNow for the amortized I thought using the accounting method, charging for each change from $0$ to $1$ $2\\$$ amortized cost, since each time we increment we flip at most one $0$ to $1$. and put $1\\$$ on each $1$ bit to pay from flipping it back to $0$. so at most the amortized cost is $2\\$$ which means amortized $O(n)$. if it's correct than what's the difference from a regular binary counter? I don't think I understand...</p>\n", 'ViewCount': '39', 'Title': 'Custom binary counter supports only increment in $2^i$ values amortized analysis', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-03-22T06:26:40.153', 'LastEditDate': '2014-03-22T06:26:40.153', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '15693', 'Tags': '<algorithms><algorithm-analysis><amortized-analysis>', 'CreationDate': '2014-03-21T22:43:51.283', 'Id': '22916'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>How can we add n positive integers with binary expansion $l_1$, $l_2$,...$l_n$ bits so that the total complexity is $O (\\sum l_i)$ for $i = {1,...,n}$ ? More importantly, how can show this complexity using amortized analysis (the potential method)?</p>\n\n<p>I know the elementary school addition of 2 numbers of length $s$ and $r$ is $O(r+s)$ and hence, the addition of n integers is $O(\\sum l_i)$. However, what potential function would you use to prove that bound? I don't seem to have any intuition on that... Maybe use a function similar to the standard binary counter example (number of 1's in the binary representation of the number)..?</p>\n", 'ViewCount': '57', 'Title': 'Amortized Analysis for Addition of $n$ numbers', 'LastActivityDate': '2014-03-26T09:43:41.157', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13063', 'Tags': '<algorithms><algorithm-analysis><amortized-analysis>', 'CreationDate': '2014-03-25T02:55:52.887', 'Id': '23027'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><em>The following may contain errors. It is precisely because I am not\nsure I understand the topic that I am asking questions. I do not have\nbooks about it and could not find an adequate reference on the web.</em></p>\n\n<p>I am discussing a problem regarding an enumeration of strings that\nshould be in <strong>amortized constant delay</strong>. From what I understood (but\nunderstanding that is part of my question), this means that the average\ntime taken for each answer should be independent of the size of the\nanswer, so that the total cost is $O(n)$ where $n$ is the number of\nanswers.</p>\n\n<p>My discussion partner went on to assert (I believe) that amortized\nconstant delay is possible for enumerating the strings accepted by a\ntrie, but not for enumerating the paths of a DAG. And I am at loss to\nsee a significant difference, since proper use of a stack should let\nme explore the DAG as if it had been exploded into a trie (by\nduplicating whatever is below a merge vertex).</p>\n\n<p>The only real difference I can see is that the accepting nodes of a\ntrie can be labeled with a single symbol identifier characterizing the accepted word (turning the trie\ninto a Moore machine) so that the total cost is only a traversal of\nthe trie, with single step output of the symbol label when traversing an\naccepting node.</p>\n\n<p>Such labeling identification is not possible for a DFA structured as a DAG, since an\naccepting node can correspond to different paths. The only way to name\npaths is to describe them in extenso (or nearly so: enough to disambiguate merges), so that the cost\nof the output by itself is already something like $O(n\\times s)$ where\n$s$ is the size of the longest path, thus entailing the same time cost\njust for doing the output.</p>\n\n<p>Where do I err, and what is the accepted wisdom and knowledge on this topic?\nPointers to web references are useful too.</p>\n', 'ViewCount': '31', 'Title': 'What is hiding behind amortized constant delay enumeration?', 'LastActivityDate': '2014-04-02T10:58:09.810', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8321', 'Tags': '<complexity-theory><graphs><strings><amortized-analysis><enumeration>', 'CreationDate': '2014-04-02T10:58:09.810', 'Id': '23337'}}