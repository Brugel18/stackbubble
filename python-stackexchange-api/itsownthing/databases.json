580:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In database normalization, 1NF (no multivalued attributes), 2NF (all non-PK attributes depending only on PK attributes) and 3NF (all non-PK attributes depending on all of the PK attributes) are widely known. The 4NF (no part of the PK depending on other part of the PK) is less known, but still reasonably known.</p>\n\n<p>Much less known are the 5NF, 6NF and the intermediates EKNF (Elementary Key normal form), BCNF (Boyce-Codd normal form - 3.5) and DKNF (Domain/Key normal form - 5.5). What exactly are that? Given a database schema, how do I determine if any table violates one of these much less knows normal forms?</p>\n', 'ViewCount': '206', 'Title': 'How to determine if a database schema violates one of the less known normal forms?', 'LastEditorUserId': '24', 'LastActivityDate': '2012-12-09T08:47:04.460', 'LastEditDate': '2012-03-09T16:48:31.170', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '95', 'Tags': '<database-theory><databases>', 'CreationDate': '2012-03-09T07:21:34.827', 'FavoriteCount': '1', 'Id': '151'},581:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Consider the following query:</p>\n\n<pre><code>SELECT Customer.Name FROM Customer\nINNER JOIN Order on Order.CustomerId = Customer.Id\nWHERE Customer.Preferred = True AND\n      Order.Complete = False\n</code></pre>\n\n<p>Let\'s suppose all of the relevant attributes (Customer.Preferred, Order.Complete, Order.CustomerId and Customer.Id) are indexed. How can I evaluate this as quickly as possible?</p>\n\n<p>Standard optimization advice would say that I should do the select on each table first, then the join using sort-merge or whatever the cardinality would imply. But this involves two passes through the data - I\'m wondering if there\'s a better way.</p>\n\n<hr>\n\n<p><strong>EDIT</strong>: I think asking if there was a "better way" was too ill-defined. Suppose we are trying to find $\\sigma_a(A)\\bowtie_j\\sigma_b(B)$. Observe that we can find this in $O(\\alpha)$ (where $\\alpha$ is the cardinality of $\\sigma_a(A)$) with the following pseudocode:</p>\n\n<pre><code>for each a in A:\n   find foreign tuple in B  // constant-time, if using hash table\n   check if foreign tuple meets foreign constraint  // again, constant time\n</code></pre>\n\n<p>As mentioned by some answerers, there are various minor permutations (do the for loop over B instead, etc.). But they all seem to be $O(\\alpha)$ or $O(\\beta)$. Is there a better way?</p>\n\n<p>Note that if it the query were a self join, we could just do the merge part of a sort-merge join, (since our indexes would already be sorted) which would run in time proportional to the number of results. So I ask if a similar thing can be done here.</p>\n\n<p>I am more than happy to accept a proof that there is no better method as an answer. I believe that there is no faster algorithm, but I\'m unable to prove it.</p>\n', 'ViewCount': '86', 'Title': 'Optimizing a join where each table has a selection', 'LastEditorUserId': '1590', 'LastActivityDate': '2012-06-11T21:35:22.203', 'LastEditDate': '2012-06-11T21:35:22.203', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1590', 'Tags': '<optimization><database-theory><relational-algebra><databases>', 'CreationDate': '2012-05-21T20:03:25.400', 'FavoriteCount': '0', 'Id': '1980'},582:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '66', 'Title': 'Anonymization of dataset preserving unique identities', 'LastEditDate': '2012-09-19T12:12:46.070', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2826', 'FavoriteCount': '1', 'Body': "<p>The $k$-anonymization paradigm (and its refinements) means to create datasets where every tuple is identical with $k-1$ others.</p>\n\n<p>However I'm in a situation where people are in the dataset many times. And I want to follow their progress through the health care system, so I need to know who is who. If I give each person a unique ID, which is necessary in this situation, a linking attack from within the table is possible!</p>\n\n<p>Does anyone know of any relevant theory or have attempted to deal with similar problems?</p>\n\n<p>I'm inclined to think it is impossible to give any good guarantee of anonymity in this situation.</p>\n\n<p>This will possibly be used for my MSc thesis topic.</p>\n", 'Tags': '<algorithms><security><databases>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-09-19T14:59:00.877', 'CommentCount': '6', 'AcceptedAnswerId': '4615', 'CreationDate': '2012-09-19T06:31:34.257', 'Id': '4611'},583:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have shown my work below for the problem and would appreciate if someone can let me know if I'm on the right track or point me in the right direction if not. </p>\n\n<p>An 8 processor file server handles a million operations each day. If each processor remains idle 5% of the time what is the utilization of the entire file server? </p>\n\n<p>I believe the utilization of the entire file server is 95% because it says all processors at idle 5% of the time. Is this correct?</p>\n\n<p>If the file server is fully utilized how much more work could it do? </p>\n\n<p>We know the file server does 10^6 operations each day and we know each processor is utilized 95% of the time.  Thus 10^6 / .95 = 1,052,632 operations / day would be the total number of operation if it were fully utilized.  </p>\n\n<p>The last question has me a little stumped: If 10% of the operations are used to move files between processors, how efficient is the file server? </p>\n", 'ViewCount': '118', 'Title': 'How to determine the Utilization and Efficiency of a file server?', 'LastEditorUserId': '41', 'LastActivityDate': '2014-04-24T23:19:09.250', 'LastEditDate': '2013-01-21T09:31:32.920', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '1480', 'Tags': '<computer-architecture><databases><performance>', 'CreationDate': '2012-10-20T22:14:29.313', 'Id': '6201'},584:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '398', 'Title': 'What are the different types of databases?', 'LastEditDate': '2012-11-09T03:21:27.437', 'AnswerCount': '2', 'Score': '3', 'OwnerDisplayName': 'sashank', 'PostTypeId': '1', 'OwnerUserId': '4421', 'FavoriteCount': '1', 'Body': '<p>Is there is a study or classification available on different types of databases? (Examples include structured, unstructured, semi structured relational, object oriented, folksonomies, etc.) </p>\n', 'Tags': '<terminology><reference-request><databases>', 'LastEditorUserId': '4519', 'LastActivityDate': '2012-11-09T03:21:27.437', 'CommentCount': '0', 'AcceptedAnswerId': '6557', 'CreationDate': '2012-10-31T23:17:00.447', 'Id': '6423'},585:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<blockquote>\n  <p>The access patterns of user requests may be <strong>static</strong>, so that they do\n  not change over time, or dynamic. It is obviously considerably easier to plan for\n  and manage the <strong>static</strong> environments than would be the case for dynamic distributed\n  systems. Unfortunately, it is difficult to find many real-life distributed applications\n  that would be classified as <strong>static</strong>. The significant question, then, is not whether a\n  system is static or dynamic, but how dynamic it is. Incidentally, it is along this\n  dimension that the relationship between the distributed database design and query\n  processing is established.</p>\n</blockquote>\n\n<p>What does it mean for an access pattern to be \u201cstatic\u201d? Could you show a practical example of a static access pattern?</p>\n', 'ViewCount': '84', 'Title': 'Static access pattern in Distributed Databases', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-04T21:55:20.093', 'LastEditDate': '2012-12-04T21:55:20.093', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7140', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4827', 'Tags': '<distributed-systems><databases>', 'CreationDate': '2012-12-04T00:17:57.830', 'Id': '7139'},586:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The last step in the design process is the physical design, which maps the local conceptual schemas to the physical storage devices available at the corresponding sites.</p>\n\n<p>What meaning of corresponding sites ? How look like in design ?</p>\n', 'ViewCount': '50', 'Title': 'In DDBMS, What meaning of corresponding sites?', 'LastActivityDate': '2012-12-10T09:51:54.203', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4827', 'Tags': '<distributed-systems><database-theory><databases>', 'CreationDate': '2012-12-10T09:51:54.203', 'Id': '7299'},587:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Can anybody please solve the following problem step-by-step with explanations, using bond energy and vertical partitioning to obtain a vertical fragmentation of the set of attributes.</p>\n\n<p>I need to understand how bond energy and vertical partitioning algorithm work with this problem. The problem is in the following link: <a href="http://download.bwor.net/V_Fragment.jpg" rel="nofollow">Problem of Vertical Fragment</a></p>\n', 'ViewCount': '206', 'Title': 'Bond energy and vertical partitioning to get a vertical fragmentation in distributed dbms', 'LastEditorUserId': '3011', 'LastActivityDate': '2012-12-23T00:05:20.297', 'LastEditDate': '2012-12-23T00:05:20.297', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4827', 'Tags': '<distributed-systems><database-theory><databases>', 'CreationDate': '2012-12-22T22:21:46.577', 'Id': '7547'},588:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have a system in existence which works on parent-child model.</p>\n\n<ol>\n<li>They share common attributes, as they belong to same class.</li>\n<li>A parent can enforces certain data on any user selected attribute, and the data is required to be propagated down the hierarchy for the same attribute in all children and their children.</li>\n<li>For a given attribute, if a child's parent dies (object gets destroyed) or child has not been enforced by parent, child can behave the same way, like in point #2, (on user request) for its children.</li>\n</ol>\n\n<p>My system is pretty big (in database). For example:</p>\n\n<ul>\n<li>Each object of the class has 150 atributes.</li>\n<li>There are in total about 8 million attributes for objects created. Hence, the objects are close to 53,333.</li>\n<li>There is a single parent for the objects. Its a big tree.</li>\n</ul>\n\n<p>If I want to enforce data on the top most parent for a single attribute, it takes about 8 mins for it to complete.</p>\n\n<p>Does anyone know a model which can perform faster than hierarchical model, but similar to behaviour?</p>\n", 'ViewCount': '47', 'Title': 'Optimization of Hierarchical Data Propagation', 'LastEditorUserId': '5402', 'LastActivityDate': '2013-08-05T14:39:58.180', 'LastEditDate': '2013-08-05T11:48:31.827', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5402', 'Tags': '<algorithms><databases><performance>', 'CreationDate': '2013-01-13T11:08:33.473', 'Id': '7922'},589:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Lets say I have a global dataset and I run queries over those data set.\nFor example my dataset would be</p>\n\n<ul>\n<li>#id, #Name, #Employee, #Birthdate, #number_of_children</li>\n<li>1, Nick, Nasa, 1982, 1</li>\n<li>2, Jack, Exon, 1985, 5</li>\n<li>3, Tom, ABCD, 1978, 0</li>\n</ul>\n\n<p>And I can run queryies on those dataset.\nsample queries would be\n* #Query => #Result_ids \n* (Name starts with A) => [1]\n* (Birthdate before 1983 and have children ) => [1]</p>\n\n<p>I want to store those queries on a data structure and I want to be able to do set operations on those queries like intersection and union. So an example union operation would be.</p>\n\n<p>(Birthdate before 1983) intersection (have children) => (Birthdate before 1983 and have children)</p>\n\n<p>I also want to be able to findout if one query is subset or superset of another one. For example.</p>\n\n<p>(Birthdate before 1983) is superset of (Birthdate before 1980)\n(Have 3 children) is subset of (Have more than 1 children)</p>\n\n<p>(Name = Jack and born in 1980) is subset of (Born before 1990)</p>\n\n<p>I will have a program that will have thousands of queries. And it will combine those queries to make more variety of queries. When I have a new query, I will compare it with existing queries to see if I have an exact query in store or have a superset.</p>\n\n<p>Can anybody suggest me a data structure that is fast enough to store and operate on those data?</p>\n', 'ViewCount': '48', 'Title': 'Algorithm for query comparison', 'LastEditorUserId': '39', 'LastActivityDate': '2013-03-03T20:53:50.943', 'LastEditDate': '2013-03-03T20:53:50.943', 'AnswerCount': '0', 'CommentCount': '8', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7123', 'Tags': '<databases><data-sets>', 'CreationDate': '2013-03-03T12:58:15.987', 'Id': '10228'},5810:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am writing a program to store, retrieve and delete "blocks" of data of varying sizes.</p>\n\n<p>The way it currently works is by keeping a database storing the locations of the blocks and the locations of free space in the file.</p>\n\n<p>The file is split into pages such that in each page there are no two free chunk spaces next to each other (During a delete operation, any free chunks which are adjacent are merged into one bigger chunk)</p>\n\n<p>The problem with this is that I am seeing horrible IO performance when removing a bunch of blocks and inserting new ones of different sizes (blocks range from 1k to about 200k and may be written anywhere in the file provided they fit in an existing free chunk in the file. If no such free chunk is found, a new page is created at the end of the file).</p>\n\n<p>Can anyone suggest a way to improve on this, or maybe point me in the right direction?</p>\n', 'ViewCount': '44', 'Title': 'Random file access in a block based file format', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-28T00:41:38.463', 'LastEditDate': '2013-03-27T12:14:28.923', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7438', 'Tags': '<efficiency><databases><filesystems>', 'CreationDate': '2013-03-27T10:08:47.073', 'Id': '10822'},5811:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In the context of database theory, what does semantic closure mean (linguistically speaking, i.e. not the mathematical definition)</p>\n\n<p>If <strong>X</strong> is the set of attributes of $F$, then the semantic closure $F^+$ of $F$ is defined as follows:<br>\n$F^+=\\{$ <strong>Y</strong> $\\rightarrow$ <strong>Z</strong> $\\ |\\ $ <strong>Y</strong> $\\cup$ <strong>Z</strong> $\\subseteq$ <strong>X</strong> $\\wedge\\ F \\models$ <strong>Y</strong> $\\rightarrow$ <strong>Z</strong> $\\}$<br>\n$F \\models $ <strong>Y</strong> $\\rightarrow$ <strong>Z</strong> means that any database instance that satisfies every functional dependency of $F$ also satisfies <strong>Y</strong> $\\rightarrow$ <strong>Z</strong></p>\n', 'ViewCount': '297', 'Title': 'What is semantic closure?', 'LastActivityDate': '2013-04-11T08:30:38.237', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '11049', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7583', 'Tags': '<databases>', 'CreationDate': '2013-04-04T20:07:44.613', 'FavoriteCount': '1', 'Id': '11030'},5812:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>In database query processing, the approximate time for selection operation using primary index when equality is on key is $2(b_s + b_t)$ where $b_s$ is disk seek time and $b_t$ is disk transfer time (assuming one level of indexing), because one seek and transfer time will be needed for finding the index and another one will be for the actual data.  </p>\n\n<p>But what will happen if the equality is on a no- key value? Since now we cannot search in the index, don't we have to do a linear search?</p>\n", 'ViewCount': '52', 'Title': 'Approximate time for selection operation using index when equality is on nonkey', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-15T15:11:13.230', 'LastEditDate': '2013-04-14T11:22:36.033', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11326', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '778', 'Tags': '<runtime-analysis><search-algorithms><databases>', 'CreationDate': '2013-04-14T06:08:19.807', 'Id': '11301'},5813:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>So I'm just starting to learn about query processing and such in databases and I'm having some trouble.  I don't really understand how to compute the minimum number of block reads given a relation and a query I guess you could say.  If anyone could help me out, it'd be much appreciated.  Here is an example that I'm working on:</p>\n\n<ul>\n<li>R1(A,B,C) A is a primary key and C is a foreign key to R2.C</li>\n<li>R2(C,D,E) C is a primary key</li>\n<li>R1 has 20,000 records, with 200 records per block. There is a primary B+-tree index on\nA with height h = 3</li>\n<li>R2 has 45,000 records, with 4,500 records per block. There is a primary B+-tree index\non C with height hC = 3 and a secondary B+-tree index on D with height hD = 2.</li>\n</ul>\n\n<p>Find the minimum number of block reads for each statement.  I can only hold one block of memory for each relation at a time. </p>\n\n<ul>\n<li>Where B=1(R1)</li>\n<li>Where C=1(R2)</li>\n</ul>\n\n<p>I'm not looking for answers.  I'm looking for explanation of how to actually do it and guide me along the way.  Aka equations, etc. It's kind of difficult to find anything beneficial online at all. </p>\n", 'ViewCount': '79', 'Title': 'Computing number of block reads given relational algebra statement', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-24T06:20:57.237', 'LastEditDate': '2013-04-24T06:20:57.237', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '11512', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7233', 'Tags': '<database-theory><databases><relational-algebra>', 'CreationDate': '2013-04-22T16:03:39.790', 'Id': '11492'},5814:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>Using the following relations:</p>\n\n<pre><code>consultant(id,Name,Skill) \n\nCustomerCompany(Id,name Address, Phone, Email, WebAddr,Market)\n\nproject(id,StartDate,EndDate,ConsultantID,CustomerId,Days)\n\nInvoice(id,Date,Customer,Amount,Status)\n</code></pre>\n\n<p>Im trying to work out the following scenario using SQL and Relational algebra</p>\n\n<p>Find the names of the consultants and the names of customers, where the consultant has worked for the customer, and the customer received an invoice in the range of GBP 100k to 200k</p>\n\n<p>Using SQL i have:</p>\n\n<pre><code>Select I.amount, C.name \nfrom CustomerCompany C, Invoice I \nwhere I.Customer= C.id and &gt; all\n( \n  select C.name, Con.Name \n  from CustomerCompany, Con Consultant \n  where i.amount between 100 and 200\n );\n</code></pre>\n\n<p>Relational algebra:</p>\n\n<pre><code>amount = \u03c3(Invoice, amount&gt;=100 and amount&lt;=200)\n\njoininv= \u24cd(amount, Customer, CustomerCompany, id)\n\njoincon \u24cd(joiniv, Consultant id, Project, ConsultantID)\n\n\u03c0 =(joincon, name, Name)\n</code></pre>\n\n<p>I was wondering if write or wrong?</p>\n\n<p>Thanks for any help!</p>\n', 'ViewCount': '69', 'Title': 'relational algebra and SQL', 'LastEditorUserId': '4306', 'LastActivityDate': '2013-05-11T19:24:17.987', 'LastEditDate': '2013-05-11T15:02:54.793', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8054', 'Tags': '<databases><relational-algebra>', 'CreationDate': '2013-05-09T16:24:35.557', 'Id': '11913'},5815:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '223', 'Title': 'Are all databases reducible to this ultimate abstract database design?', 'LastEditDate': '2013-05-16T06:03:33.037', 'AnswerCount': '1', 'Score': '1', 'OwnerDisplayName': 'SG1', 'PostTypeId': '1', 'OwnerUserId': '8220', 'Body': '<p>I\'ve designed a few databases in my time, and on more than one occasion the drive to abstract common elements from specific tables has led me to create generic top-level tables which contain those common elements.  For example:</p>\n\n<pre><code>Table      Column         Column\n\nHamburgers Item           Topping\n           Cheeseburger   Tomatoes\n           Mushroomburger Swiss\n</code></pre>\n\n<p>Could be "simplified" ("normalized") as:</p>\n\n<pre><code>Table      Column         Column\n\nFoodTypes  ID             Name\n           1              Hamburger\n           2              Topping\n\nFood       Item           TypeID\n           Cheeseburger   1\n           Mushroomburger 1\n           Tomatoes       2\n           Swiss          2\n</code></pre>\n\n<p>Recently I\'ve gone over the deep end with this approach, abstracting and re-abstracting a fairly complex database design until I was left with something both very simple and yet completely un-resembling of the actual data being stored.</p>\n\n<p>This has led me to the conclusion that all databases could be "summarized" in a single monstrous table called "Entries" with columns:</p>\n\n<pre><code>ID       Type     Value1     Value2\n</code></pre>\n\n<p>For example:</p>\n\n<pre><code>ID       Type     Value1     Value2\n4321     Item     \n8746     Descrip  4321       Food\n5673     Item     \n9876     Descrip  5673       Hamburger\n0341     Item     \n1234     Descrip  0341       Lettuce\n5478     Relation 5673       0341\n2381     Descrip  5478       Topping\n2244     Relation 5673       4321\n2160     Descrip  2244       Class\n4436     Relation 0341       4321\n7547     Descrip  4436       Class\n</code></pre>\n\n<p>Here, using these 4 columns in 1 table, I have created two objects sharing a common superclass, given them an attribute, and defined not only a relationship between them but the class of that relationship as well.  We could now say "Lettuce is a Topping of Hamburger, both of which are Foods".</p>\n\n<p>There would of course be a set of rules for this system, but that is beyond the scope of this question.</p>\n\n<p>My question is, is this not logically the case?  If so (or if there is a different, "correct" answer), what is this in relation to real databases?  Does such a system exist, or should it not?</p>\n\n<p>I\'m not sure if I\'ve gone far enough in my analysis, and I feel like I\'m on the verge of some insight which is profoundly obvious to mathematicians and computer scientists (like "yes, all relational data can be described in terms of binary operands like F[a, b]).</p>\n', 'Tags': '<databases><normal-forms>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-16T14:42:31.970', 'CommentCount': '1', 'AcceptedAnswerId': '12065', 'CreationDate': '2013-05-16T02:00:25.800', 'Id': '12060'},5816:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '409', 'Title': '"At least one" clause in Relational Algebra', 'LastEditDate': '2013-05-30T23:49:18.537', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8123', 'FavoriteCount': '1', 'Body': '<p>I\'m fairly new to the syntax of relational algebra, and I\'m having a hard time understanding how I could set a "at least one" clause. </p>\n\n<p>Example: I have:</p>\n\n<ul>\n<li>a table with books (listing the title, year published and ID), </li>\n<li>a table with authors (listing their name and ID),</li>\n<li>a table which lists what author wrote what book (through a tuple of the IDs mentioned before).</li>\n</ul>\n\n<p>How could I, in relational algebra, get "All the authors that have published at least one book per year between 2008 and 2010"?</p>\n\n<p>I have figured this so far. At step "b", the Natural join is used since both tables have PublicationID in common. Thus, the resulting table is |PublicationID|AuthorID|Year|. So I\'m simply missing the step "c", where I don\'t understand how to gather a sub-set of the authors that published at least one book per year between 2008 and 2010. </p>\n\n<p>$ a \\leftarrow \\pi_{PublicationID,Year} (Publication)$ </p>\n\n<p>$ b \\leftarrow a \\bowtie AuthorPublication $ </p>\n\n<p>$ c \\leftarrow \\sigma_{something} $</p>\n', 'Tags': '<database-theory><databases><relational-algebra>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-30T23:49:55.977', 'CommentCount': '5', 'AcceptedAnswerId': '12227', 'CreationDate': '2013-05-22T16:16:54.920', 'Id': '12218'},5817:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In database theory, there is a notion of transitive closure over relations. I am wondering if join operator over relations is also a special case of transitive closure?</p>\n', 'ViewCount': '155', 'Title': 'What is the difference between Transitive Closure and Join?', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-07-22T12:28:31.773', 'LastEditDate': '2013-05-27T07:03:04.287', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '2', 'OwnerDisplayName': 'heykell', 'PostTypeId': '1', 'OwnerUserId': '8413', 'Tags': '<database-theory><databases>', 'CreationDate': '2013-05-27T00:52:41.530', 'Id': '12301'},5818:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '102', 'Title': 'Preventing oversell, allocation of limited resources with overlapping properties', 'LastEditDate': '2013-05-29T12:21:39.890', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8380', 'FavoriteCount': '1', 'Body': '<p>I am trying to solve problem of preventing oversell of limited resources.</p>\n\n<p>Consider resources (people) who are described by set of properties where each property belongs to different category (example properties from four categories:  male, age 25-30, 2 children, interested in games).</p>\n\n<p>Buyers want to allocate access to resources. Buyers can specify subset of categories and one property from each category (example: allocate 1000 males, age 25-30 or allocate 100 females, age 25-30, interested in music).</p>\n\n<p>In my real life example I have 6m+ possible set of properties (profiles) where for each set of properties I know how many profiles exists.</p>\n\n<p>My initial approach was to build a graph like one below:</p>\n\n<p><img src="http://i.imgur.com/gQsXfWB.png" alt="alt text"></p>\n\n<p>and then traverse using edge weights, for instance validating if demand for 100 females, age2 can be satisfied:</p>\n\n<ol>\n<li>check if size(female, age2) &lt; 100</li>\n<li>for each parent:\n<ol>\n<li>check if size(parent) &lt; 100 and go to 2.</li>\n</ol></li>\n<li>for each child:\n<ol>\n<li>check if size(child) &lt; 100 * weight(edge(node, child)) go to 1.</li>\n</ol></li>\n</ol>\n\n<p>(above algorithm is simplified as does not prevent visiting same node multiple times)</p>\n\n<p>It all works fine when graph is small, however when number of nodes and edges (dependencies) between nodes (profile universe groups) grows it does not scale very well.</p>\n\n<p>Consider example:</p>\n\n<ul>\n<li>large graph, 6m nodes, 20m+ edges</li>\n<li>buyer wants to allocate 1000 males (and there are only males and females in gender category)</li>\n</ul>\n\n<p>algorithm would start with top-level \'male\' node which probably has 10m+ outgoing edges and 10m+ checks would be required (and probably each of those 10m outgoing edges has incoming edges which need to be checked as well).</p>\n\n<p>I was trying to find different approach but failed. I was trying to google out existing solutions but seems like I am unable to even name problem properly. Any reference to what is this problem similar to would be good for me as a starting point.</p>\n\n<p>Thanks for comments/help.</p>\n\n<p>Two more graphs to present exponential growth of the graph:\n3 categories\n<img src="http://i.imgur.com/gLg6Y6i.png" alt="alt text"></p>\n\n<p>4 categories\n<img src="http://i.imgur.com/0TM4mSy.png" alt="alt text"></p>\n\n<p><strong>Update</strong></p>\n\n<p>Regarding size, assuming 8 categories of properties where each category has: 2, 6, 6, 6, 6, 8, 1140, 150 values respectively then estimated number of profiles: 2*6^4*8*1140*150 ~= 3.5 * 10^9. Number of nodes in graph: at least 7 * 10^9, number of edges in graph: at least 140 * 10^9.</p>\n\n<p><strong>Update #2</strong></p>\n\n<p>Formula for number of nodes is:</p>\n\n<p>$\\sum_{i&lt;n}\\prod_{k&lt;i \\atop j_1, j_2, ..., j_k &lt; n} s_{j_{1}} ... s_{j_{n}}$</p>\n\n<p>where $n$ is number of categories and $s_x$ is size of category $x$.</p>\n\n<p>So in my example there would be 11\'169\'108\'657 nodes.</p>\n\n<p><strong>Update #3</strong></p>\n\n<p>As per @Raphael advice - I have reduced number of nodes and now formula is:</p>\n\n<p>$\\sum_{i&lt;n-M}\\prod_{k&lt;i \\atop j_1, j_2, ..., j_k &lt; n} s_{j_{1}} ... s_{j_{n}}$</p>\n\n<p>where $M&lt;n$ and assumed that distribution of resources across smallest slices of universe is equal.\nAt the same time removed lot of edges from graph.</p>\n\n<p>Example of sub-graph size reduction:\n<img src="http://i.stack.imgur.com/SSSU8.png" alt="Example of sub-graph size reduction"></p>\n', 'Tags': '<algorithms><databases><counting>', 'LastEditorUserId': '8380', 'LastActivityDate': '2013-05-29T12:21:39.890', 'CommentCount': '6', 'AcceptedAnswerId': '12327', 'CreationDate': '2013-05-27T10:45:05.100', 'Id': '12304'},5819:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have many vectors in my database. They are in high dimensions such as:</p>\n\n<ul>\n<li>$v_1$ : $\\langle 23, 23, 1, 33, 103, 219, \\dots \\rangle$</li>\n<li>$v_2$ : $\\langle 92, 83, 1, 33, 239, 192, \\dots \\rangle$</li>\n<li>...</li>\n</ul>\n\n<p>I will use Hamming distance to calculate their difference: The\ndifference between $v_1$ and $v_2$ is $4$ because elements $3$\nand $4$ are the same and others are difference.</p>\n\n<p>Now, I want to use Locality Sensitive Hashing (LSH) to put those\nvectors into different bins.</p>\n\n<blockquote>\n  <p>What kind of hash function can I use for this case?</p>\n</blockquote>\n\n<p>I have read some article about universal hash function, but I am\nnot sure can I use it and how to ensure that the probability for\nthe similar vectors going to the same bin is higher than those\nnon-similar one.</p>\n\n<p>Here is the way that I think how should I use the universal hash\nfunction for my task.</p>\n\n<p>I will first divide those high dimensions vectors into sub-vectors:\n$$x : 23, 23 \\; | \\; 1, 33 \\;  | \\; 103, 219 \\; | \\; \\dots$$</p>\n\n<p>sub1-x : 23 23<br>\nsub2-x : 1 33<br>\nsub3-x : 103 219<br></p>\n\n<p>The following function will be used for each sub-vector:\n$$sum_{i=0}^{r} a_{i}x_{i} \\mod m$$</p>\n\n<p>Basically this is a dot product, a = {a_1, a_2, ... a_i}, x =\n{23, 23, 1, 33, 103, 219 ...}, m is a prime.</p>\n\n<p><ul>\n<li>Different combination of {a} will form a different hash table, one hash table is used for one sub-vector.</li>\n<li>I can now hash the data into bins, <strong>but the question is</strong></p>\n\n<blockquote>\n  <p>Is this an LSH method?  I don't know that two similar vectors  will go into the same bin with a high probability.</li>\n  </ul></p>\n</blockquote>\n", 'ViewCount': '159', 'Title': 'Find similar vector by Locality Sensitive Hashing', 'LastEditorUserId': '4249', 'LastActivityDate': '2013-07-30T08:00:31.173', 'LastEditDate': '2013-07-30T08:00:31.173', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '13352', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9238', 'Tags': '<hash><databases><hash-tables><string-metrics>', 'CreationDate': '2013-07-18T14:41:29.760', 'Id': '13334'},5820:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I've been reading about the differences between <strong>serializability</strong> and <strong>linearizability</strong>, which are both consistency criteria for replicated systems such as replicated databases. However, I don't know in which cases linearizability would be needed, even though it's stronger than serializability.</p>\n\n<p>Could you come up with scenarios where such strong property would actually be necessary?</p>\n", 'ViewCount': '368', 'Title': 'Who needs linearizability?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-07-31T16:03:40.023', 'LastEditDate': '2013-07-31T16:03:40.023', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '13490', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9348', 'Tags': '<databases>', 'CreationDate': '2013-07-25T18:58:15.520', 'Id': '13441'},5821:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Suppose we have two entities $A$ and $B$ and some relationship between them. If there is an $M:N$ relationship between them (i.e. an $M$ on the line connecting $A$ to the relationship and an $N$ connecting the relationship to $B$), how do we read this? Would it be the following: A single instance of $A$ is related to $N$ of $B$ and a single instance of $B$ is related to $M$ of $A$?</p>\n', 'ViewCount': '76', 'Title': 'E-R diagram and relationships', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-27T10:29:27.910', 'LastEditDate': '2013-08-27T10:24:39.920', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9849', 'Tags': '<terminology><databases>', 'CreationDate': '2013-08-26T18:49:31.027', 'Id': '13953'},5822:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In this table B is foreign key referring to the primary key A with on delete cascade option.What will be the result after deleting (4,3) and how\nA:1 4 2 9 3 5\nB:3 3 4 2 9 4</p>\n', 'ViewCount': '33', 'Title': 'result after applying on delete cascade', 'LastActivityDate': '2013-10-08T05:37:17.600', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14898', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10380', 'Tags': '<databases>', 'CreationDate': '2013-10-07T12:18:32.693', 'Id': '14882'},5823:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>In a database system, say there are $N$ transactions each having $m_1,m_2,\\dots,m_N$ operations. How many  concurrent schedules are possible?</p>\n\n<p>$(m_1+m_2+....+m_n)!$ is the number of possible interleavings.<br>\nIs this number equal to number of concurrent schedules? Serial schedules have to be discarded from the total number?</p>\n', 'ViewCount': '88', 'Title': 'Number of concurrent schedules in database', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-13T16:51:50.990', 'LastEditDate': '2014-01-13T19:36:57.920', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '12377', 'Tags': '<concurrency><databases>', 'CreationDate': '2013-12-26T03:35:16.750', 'Id': '19295'},5824:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>As we know, if we want to design and implement a programming language like JAVA, C++ and C language, we will reference the compilation theory. Similarly, if we would like to design and implement a data exchange format language, like JSON and Google protocol buffer to store the serialized objects, what theory shall we use to solve the problem? More precisely, does there exist a domain that study how to design a data exchange format and its corresponding books and publications?</p>\n\n<p>The format shall be terse, robust, readable and have efficient en/decoding. The dilemma between binary format and textual format etc.</p>\n', 'ViewCount': '35', 'ClosedDate': '2014-01-30T23:05:45.850', 'Title': 'The research area of data exchange format,i.e. the format that stores serialized objects', 'LastEditorUserId': '13038', 'LastActivityDate': '2014-01-30T19:28:28.310', 'LastEditDate': '2014-01-30T19:28:28.310', 'AnswerCount': '0', 'CommentCount': '12', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13038', 'Tags': '<data-structures><databases>', 'CreationDate': '2014-01-22T15:42:36.227', 'Id': '19893'},5825:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m trying to separate a weird relationship. It goes like this:</p>\n\n<ol>\n<li>One waiter can serve more than one kind of drink and one kind of drink can be served by more than one waiter.</li>\n<li>One waiter can wear more than one kind of shirt (eg different uniforms daily, or random uniform assignments, etc), and one kind of shirt can be worn by more than one waiter.</li>\n</ol>\n\n<p>There are two many-to-many relationships here that share the waiters, but can be separately resolved. But because they share the waiters entity, then many kinds of drinks can be served while wearing many kinds of shirts.</p>\n\n<p>The relational model looks like this:</p>\n\n<p><img src="http://i.stack.imgur.com/AoRal.png" alt="the model"></p>\n\n<p>My question is, how do I resolve this? It doesn\'t look like it lends itself easily to being decomposed into one-to-many relationships.</p>\n\n<p>Edit: I changed the image to fit in better with the description, but the problem that results here is the waiter-drinks and waiter-shirt entities still exist as a result of normalizing the drinks and waiters relationship (that is many-to many) and the waiter and shirt (also many-to-many). The resulting entities then have a many-to-many relationship as waiter-drinks and waiter-shirt.</p>\n\n<p>Where am I wrong?</p>\n', 'ViewCount': '47', 'Title': 'Resolving many to many relationships?', 'LastEditorUserId': '15032', 'LastActivityDate': '2014-03-30T07:53:44.673', 'LastEditDate': '2014-02-28T07:44:10.080', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15032', 'Tags': '<databases><relational-algebra>', 'CreationDate': '2014-02-25T16:54:23.817', 'Id': '22028'},5826:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>How to display distinct rows from single column without using DISTINCT keyword and [having count(*) > 1 ] ?  My question is can we do this using sub-queries or co-related sub query ?\nIf yes how we can do this ?</p>\n\n<p>Please let me know.\nThanks.</p>\n', 'ViewCount': '18', 'ClosedDate': '2014-03-03T03:13:58.500', 'Title': 'How to display distinct rows from single column without using DISTINCT keyword and count() function?', 'LastActivityDate': '2014-03-02T17:16:35.497', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12467', 'Tags': '<database-theory><databases>', 'CreationDate': '2014-03-02T17:16:35.497', 'Id': '22199'},5827:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Lets say you have a data model that consists of a 2D grid of integer points. This grid is sparsely populated and boundless in x and y (up to the max of a 32-bit integer).</p>\n\n<p>What is the best way to index these points in order to have an optimised lookup on an arbitrary (x,y) coordinate? Is an O(1) lookup solution possible?</p>\n', 'ViewCount': '105', 'Title': 'What is the best way to index lookups on a 2D array of integers that is boundless in x and y?', 'LastActivityDate': '2014-03-11T19:28:28.083', 'AnswerCount': '5', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15254', 'Tags': '<algorithms><optimization><databases><data-sets>', 'CreationDate': '2014-03-04T02:39:54.287', 'Id': '22251'},5828:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Does anybody know any toy database / relations that are particularly good and also <strong>complete</strong> to demonstrate and test relational algebra concepts?  I'm hoping some database researchers should have already made that and improved over long time from pedagogical practices.</p>\n", 'ViewCount': '14', 'Title': 'In search for toy relations to test relational algebra', 'LastActivityDate': '2014-03-12T03:44:29.897', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15575', 'Tags': '<databases><relational-algebra>', 'CreationDate': '2014-03-12T03:44:29.897', 'Id': '22528'},5829:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I know that if the set of free variables for a relational calculus query is equal to the set of range-restricted variables then the query is (roughly) safe. I also can identify free variables. However, I do not understand what range-restricted variables are at all, and I can't find any comprehensible explanations anywhere. Can anyone give me a hand? This is for domain relational calculus.</p>\n", 'ViewCount': '32', 'Title': 'Relational calculus: what is a range-restricted variable?', 'LastActivityDate': '2014-04-08T18:55:51.657', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16564', 'Tags': '<databases>', 'CreationDate': '2014-04-08T18:55:51.657', 'Id': '23559'},5830:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have the standard problem of BCNF in front of me, in the table hospital we have:</p>\n\n<pre><code>----------------------------------\n| doctor |  department | patient |\n----------------------------------\n| dr.Tom | Paediatric  | Martin  |\n| dr.Eve | Ophthalmo.. | Martin  |\n| dr.Ann | Paediatric  | Sarah   |\n| ...    | ...         | ...     |\n----------------------------------\n</code></pre>\n\n<ul>\n<li>Each patient has a doctor assigned for each different department</li>\n<li>A patient can be in different departments</li>\n<li>Each department can have multiple doctors</li>\n</ul>\n\n<p>Therefore when identifying the candidate keys I get these functional dependences (correct?):</p>\n\n<ul>\n<li>$ patient, doctor \\implies department $ (candidate key)</li>\n<li>$ patient, department \\implies doctor $ (candidate key)</li>\n<li>$ doctor \\implies department $</li>\n</ul>\n\n<p>On a previous exam paper it says: in this scenario would the above BCNF issue have occurred regardless of which candidate key have been chosen as the actual primary key (considering that the normalisation that preceded BCNF - potentially)?</p>\n\n<p>How would you approach such question?</p>\n', 'ViewCount': '23', 'Title': 'Boyce-Codd Normal form and violation issue', 'LastActivityDate': '2014-04-15T18:09:05.010', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16802', 'Tags': '<database-theory><databases>', 'CreationDate': '2014-04-15T18:09:05.010', 'Id': '23823'},5831:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>let's consider a table with</p>\n\n<pre><code>carID | hireDate | manufactory | model | custID | custName | outletNo | outletLoc\n</code></pre>\n\n<p>I want to evaluate all the <strong>functional dependencies</strong> to bring in first, second and then third normal form.</p>\n\n<ul>\n<li><p>Functional dependencies</p>\n\n<pre><code>carID,hireDate -&gt; custID\n</code></pre></li>\n<li><p>Partial dependencies</p>\n\n<pre><code>carID-&gt;manufactory, model, outletNo**\n</code></pre></li>\n<li><p>Transitive dependencies</p>\n\n<pre><code>custID-&gt;custName\noutletNo-&gt;outletLoc\n</code></pre></li>\n</ul>\n\n<p>Since a car is in a outlet only I have in the partial dependecies this:</p>\n\n<pre><code>carID-&gt;manufactory, model, outletNo**\n</code></pre>\n\n<p>However this leads to anomalies in insertion (imagine adding a car with no outlet), so should not that be like this?</p>\n\n<pre><code>carID-&gt;manufactory, model\ncarID-&gt;outletNo\n</code></pre>\n\n<p>But isn't this still an normalisation anomaly? </p>\n", 'ViewCount': '65', 'Title': 'Functional dependencies with the same key?', 'LastActivityDate': '2014-04-23T15:04:45.723', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16802', 'Tags': '<database-theory><databases>', 'CreationDate': '2014-04-18T11:55:15.453', 'Id': '23909'},5832:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The query is given as follows:</p>\n\n<pre><code>Select T1.A \nFROM T1,T2,T3\nWHERE T1.A = T2.A\nAND T1.B=T3.B\nAND T1.C=T3.C\n</code></pre>\n\n<p>TABLE T1,T2 AND T3 ARE HAVING 4,8, AND 16 PARTITIONS.\n(USE nested loops,sort merge and hash join as available methods of join)</p>\n\n<p>4 processors means, this query should run in parallel.\nso the table blocks will be accessed in parallel.</p>\n', 'ViewCount': '9', 'ClosedDate': '2014-04-26T12:05:58.080', 'Title': 'How to prepare execution plan for given sql query on a server having 4 processors', 'LastEditorUserId': '17091', 'LastActivityDate': '2014-04-26T13:52:21.703', 'LastEditDate': '2014-04-26T13:52:21.703', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '17091', 'Tags': '<optimization><databases>', 'CreationDate': '2014-04-26T08:59:05.430', 'Id': '24124'},5833:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u"<p>I'm finding it difficult to locate any documentation on how transactions are implemented in most SQL engines \u2013 principally MySQL \u2013 and, as of yet, haven't had the time to dig into the code myself.</p>\n\n<p>I can think of three bad ways:</p>\n\n<ol>\n<li><strong>Keep track of each query and reverse its effects</strong>; this would be slow, inefficient and error-prone.</li>\n<li><strong>Take a snapshot of the table's memory table and overwrite it</strong>. Slow for large tables, would require double the table size's worth of memory.</li>\n<li><strong>Run a query twice, once at a 'meta-level' to get the internal row IDs for each changed row, then store copy those rows' state, before running the query for 'real' the second time</strong>. This is the best way I can think of doing it, but it would still seem to take a lot longer than it takes for transactions to work.</li>\n</ol>\n\n<p>How do production SQL servers handle transactions?</p>\n", 'ViewCount': '12', 'Title': 'SQL Transactions', 'LastActivityDate': '2014-05-01T17:29:40.343', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '17256', 'Tags': '<databases>', 'CreationDate': '2014-05-01T17:29:40.343', 'Id': '24296'},5834:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '28', 'Title': 'Does "serializable" also mean that it\'s lockable', 'LastEditDate': '2014-05-04T02:15:47.543', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17292', 'FavoriteCount': '2', 'Body': '<p>Here\'s an final exam question for a Database Fundamentals class. I\'ve read the book, stuff online.. I can\'t figure out if "<em>serializable</em>" also means that the schedule is <code>lockable</code> or not. What I mean is.. I understand that for the schedule to be isolated, you have to have non-conflicting <em>reads</em> &amp; <em>writes</em>, but then it also says "if the transactions are not isolated(i.e., serializable).." </p>\n\n<p>By determining if the schedule is isolated, does this include determining if locks(lock-W(x), lock-R(x)) and unlocks can be placed inside the schedule, is <code>"serializable"</code> both <em>isolated</em> and <em>lockable</em>?</p>\n\n<p><code>lockable</code> - can locks and unlocks be placed inside the schedule at appropriate R/W-intervals.</p>\n\n<p>Here\'s the question:</p>\n\n<p><a href="http://imgur.com/KzNaNuZ" rel="nofollow"><img src="http://i.imgur.com/KzNaNuZ.png" title="Hosted by imgur.com" /></a></p>\n', 'Tags': '<databases>', 'LastEditorUserId': '17292', 'LastActivityDate': '2014-05-04T02:15:47.543', 'CommentCount': '2', 'AcceptedAnswerId': '24357', 'CreationDate': '2014-05-03T04:21:42.973', 'Id': '24340'}