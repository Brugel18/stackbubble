{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '668', 'Title': 'Type-checking algorithms', 'LastEditDate': '2012-04-29T12:25:23.307', 'AnswerCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '95', 'FavoriteCount': '4', 'Body': '<p>I am starting a personal bibliographic research on type-checking algorithms and want some tips. What are the most commonly used type-checking algorithms, strategies and general techniques?</p>\n\n<p>I am particularly interested in complex type-checking algorithms that were implemented in widely known strongly static typed languages such as, for example, C++, Java 5+, Scala or others. I.E, type-checking algorithms that are not very simple due to the very simple typing of the underlying language (like Java 1.4 and below).</p>\n\n<p>I am not per se interested in a specific language X, Y or Z. I am interested in type-checking algorithms regardless of the language that they target. If you provide a answer like "language L that you never heard about which is strongly typed and the typing is complex has a type-checking algorithm that does A, B and C by checking X and Y using the algorithm Z", or "the strategy X and Y used for Scala and a variant Z of A used for C# are cool because of the R, S and T features that works in that way", then the answers are nice.</p>\n', 'Tags': '<algorithms><programming-languages><reference-request><type-checking>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-29T12:25:23.307', 'CommentCount': '15', 'AcceptedAnswerId': '152', 'CreationDate': '2012-03-09T05:27:29.120', 'Id': '148'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Minimum bandwidth problem is to a find an ordering of graph nodes on integer line that minimizes the largest distance between any two adjacent nodes. </p>\n\n<p>The decision problem is NP-complete even for binary trees. <a href="http://www.jstor.org/stable/10.2307/2100947" rel="nofollow">Complexity Results for Bandwidth Minimization. Garey, Graham, Johnson and Knuth, SIAM J. Appl. Math., Vol. 34, No.3, 1978</a>.</p>\n\n<p>What is the best known efficient approximability result for computing minimum bandwidth on binary trees? What is best known conditional hardness of approximation result? </p>\n', 'ViewCount': '174', 'Title': 'Approximation of minimum bandwidth on binary trees', 'LastEditorUserId': '472', 'LastActivityDate': '2012-05-24T21:14:57.037', 'LastEditDate': '2012-04-02T11:58:13.790', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '988', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete><reference-request><approximation>', 'CreationDate': '2012-03-15T14:56:56.453', 'Id': '416'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '499', 'Title': 'Decidable restrictions of the Post Correspondence Problem', 'LastEditDate': '2012-09-21T13:15:50.123', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '1', 'Body': '<p>The <a href="http://en.wikipedia.org/wiki/Post_correspondence_problem" rel="nofollow">Post Correspondence Problem</a> (PCP) is undecidable.</p>\n\n<p>The <em>bounded version of the PCP</em> is $\\mathrm{NP}$-complete and the <em>marked version of the PCP</em> (the words of one of the two lists are required to differ in the first letter) is in $\\mathrm{PSPACE}$ [1].</p>\n\n<ol>\n<li>Are these restricted versions used to prove some complexity results of other problems (through reduction)?</li>\n<li>Are there other restricted versions of the PCP that make it decidable (and in particular $\\mathrm{PSPACE}$-complete)?</li>\n</ol>\n\n<p>[1] "<a href="http://dx.doi.org/10.1016/S0304-3975%2899%2900163-2" rel="nofollow">Marked PCP is decidable</a>" by V. Halava, M. Hirvensalo, R. De Wolf (1999)</p>\n', 'Tags': '<complexity-theory><computability><reference-request>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-21T13:15:50.123', 'CommentCount': '0', 'AcceptedAnswerId': '4638', 'CreationDate': '2012-03-23T17:15:49.773', 'Id': '701'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '229', 'Title': 'Research on evaluating the performance of cache-obliviousness in practice', 'LastEditDate': '2012-03-26T20:58:01.420', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '472', 'FavoriteCount': '2', 'Body': u'<p><a href="http://en.wikipedia.org/wiki/Cache-oblivious_algorithm" rel="nofollow">Cache-oblivious algorithms and data structures</a> are a rather new thing, introduced by Frigo et al. in <a href="http://userweb.cs.utexas.edu/~pingali/CS395T/2009fa/papers/coAlgorithms.pdf" rel="nofollow">Cache-oblivious algorithms, 1999</a>. Prokop\'s <a href="http://www.google.fi/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CCYQFjAA&amp;url=http%3A%2F%2Fsupertech.csail.mit.edu%2Fpapers%2FProkop99.pdf&amp;ei=Dc1tT-aLI8bm4QSC4YjAAg&amp;usg=AFQjCNHWhtzqOQqUonQWHduna8_nbQYx2g&amp;sig2=Nf_YDGY3NZLj7q0FY6TZgw" rel="nofollow">thesis</a> from the same year introduces the early ideas as well.</p>\n\n<p>The paper by Frigo et al. present some experimental results showing the potential of the theory and of the cache-oblivious algorithms and data structures. Many cache-oblivious data structures are based on static search trees. Methods of storing and navigating these trees have been developed quite a bit, perhaps most notably by Bender et al. and also by Brodal et al. Demaine gives a nice <a href="http://www.cs.uwaterloo.ca/~imunro/cs840/DemaineCache.pdf" rel="nofollow">overview</a>.</p>\n\n<p>The experimental work of investigating the cache behaviour in practice was done at least by Ladner et al. in <a href="http://www.cs.amherst.edu/~ccm/cs34/papers/ladnerbst.pdf" rel="nofollow">A Comparison of Cache Aware and Cache Oblivious Static Search Trees Using Program Instrumentation, 2002</a>. Ladner et al. benchmarked the cache behaviour of algorithms solving the binary search problem, using the classic algorithm, cache-oblivious algorithm and cache-aware algorithm. Each algorithm was benchmarked with both implicit and explicit navigation methods. In addition to this, the thesis by <a href="http://www.diku.dk/forskning/performance-engineering/frederik/thesis.pdf" rel="nofollow">R\xf8nn, 2003</a> analyzed the same algorithms to quite high detail and also performed even more thorough testing of the same algorithms as Ladner et al.</p>\n\n<p><strong>My question is</strong></p>\n\n<blockquote>\n  <p>Has there been any newer research on <em>benchmarking</em> the cache behaviour of cache-oblivious algorithms in <em>practice</em> since? I\'m especially interested in the performance of the static search trees, but I would also be happy with any other cache-oblivious algorithms and data structures.</p>\n</blockquote>\n', 'Tags': '<algorithms><data-structures><computer-architecture><reference-request><cpu-cache>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-03-26T20:58:01.420', 'CommentCount': '1', 'AcceptedAnswerId': '741', 'CreationDate': '2012-03-24T13:51:44.963', 'Id': '740'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What is a good beginner computer science book for a young adult, say, a 15 year old? I want to get started in CS, but have no idea where to start. I have limited experience in programming.</p>\n', 'ViewCount': '628', 'Title': 'Computer Science Book for Young Adults', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-27T10:37:57.800', 'LastEditDate': '2012-04-22T16:19:19.600', 'AnswerCount': '6', 'CommentCount': '2', 'Score': '14', 'OwnerDisplayName': 'Solomon081', 'PostTypeId': '1', 'Tags': '<education><reference-request>', 'CreationDate': '2012-03-22T20:52:09.317', 'FavoriteCount': '3', 'Id': '888'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '430', 'Title': 'Quantum lambda calculus', 'LastEditDate': '2012-04-02T03:49:36.880', 'AnswerCount': '1', 'Score': '19', 'PostTypeId': '1', 'OwnerUserId': '55', 'FavoriteCount': '5', 'Body': '<p>Classically, there are 3 popular ways to think about computation: Turing machine, circuits, and lambda-calculus (I use this as a catch all for most functional views). All 3 have been fruitful ways to think about different types of problems, and different fields use different formulation for this reason. </p>\n\n<p>When I work with quantum computing, however, I only ever think about the circuit model. Originally, QC was defined in terms of <a href="http://cs.stackexchange.com/q/125/55">quantum Turing machines</a> but as far as I understand, this definition (although equivalent to quantum circuits if both are formulated carefully) has not been nearly as fruitful. The 3rd formulation (in terms of lambda-calculus or similar functional settings) I am completely unfamiliar with. Hence my questions:</p>\n\n<ul>\n<li><p><strong>What are useful definitions of quantum lambda-calculus (or other functional paradigms)?</strong></p></li>\n<li><p><strong>What subfields of QIP gain deeper insight from using this formulation instead of the circuit model?</strong></p></li>\n</ul>\n\n<hr>\n\n<h3>Notes</h3>\n\n<p>I am aware that I am ignoring many other popular formalisms like cellular automata, RAM-models, etc. I exclude these mostly because I don\'t have experience with thinking in terms of these models classically, let alone <a href="http://cstheory.stackexchange.com/q/6932/1037">quantumly</a>. </p>\n\n<p>I am also aware that there are popular alternatives in the quantum setting, such as measurement-based, topological, and adiabatic. I do not discuss them because I am not familiar with the classical counterparts.</p>\n', 'Tags': '<lambda-calculus><quantum-computing><reference-request><computation-models>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-20T22:51:58.170', 'CommentCount': '3', 'AcceptedAnswerId': '1400', 'CreationDate': '2012-04-02T00:30:46.053', 'Id': '971'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>My question goes to those who are concerned with computational biology algorithmics. I'm going to take a course on bioinformatics this fall; the problem, however, is that I have too little background in biology and chemistry to feel prepared for that cycle of lections (I was rather weak at these subjects at school).</p>\n\n<p>Could you recommend any books that would provide a good introduction to the questions of natural sciences that bioinformatics focuses on?</p>\n", 'ViewCount': '196', 'Title': 'Introductory books on nature sciences behind bioinformatics', 'LastEditorUserId': '6416', 'LastActivityDate': '2013-01-14T23:06:35.373', 'LastEditDate': '2013-01-14T20:32:01.657', 'AnswerCount': '4', 'CommentCount': '8', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '162', 'Tags': '<algorithms><reference-request><education><bioinformatics>', 'CreationDate': '2012-04-09T09:12:41.920', 'FavoriteCount': '3', 'Id': '1156'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '509', 'Title': 'Classification of intractable/tractable satisfiability problem variants', 'LastEditDate': '2012-04-14T10:19:29.120', 'AnswerCount': '1', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '2', 'Body': '<p>Recently I found in a paper [1] a special symmetric version of SAT called the <strong>2/2/4-SAT</strong>. But there are many $\\text{NP}$-complete variants out there, for example: <strong>MONOTONE NAE-3SAT</strong>, <strong>MONOTONE 1-IN-3-SAT</strong>, ...</p>\n\n<p>Some other variants are tractable: $2$-$\\text{SAT}$, Planar-NAE-$\\text{SAT}$, ...</p>\n\n<p>Are there survey papers (or web pages) that classify all the (weird) $\\text{SAT}$ variants that have been proved to be $\\text{NP}$-complete (or in $\\text{P}$) ?</p>\n\n<hr>\n\n<ol>\n<li><a href="https://www.aaai.org/Papers/AAAI/1986/AAAI86-027.pdf">Finding a shortest solution for the $N$x$N$ extension of the 15-Puzzle is intractable</a> by D. Ratner and M. Warmuth (1986)</li>\n</ol>\n', 'Tags': '<complexity-theory><reference-request><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-14T10:19:29.120', 'CommentCount': '2', 'AcceptedAnswerId': '1235', 'CreationDate': '2012-04-12T17:59:00.553', 'Id': '1234'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '88', 'Title': 'Where can I find good study material on Role Mining?', 'LastEditDate': '2012-04-16T18:15:31.373', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1045', 'FavoriteCount': '1', 'Body': u'<p>I need to cover these topics in Role Mining. If anyone knows good site which well summarizes the topics and concepts are well explained please help out.</p>\n\n<p>Basic role mining problem<br>\n\u2022 Delta-approx RMP<br>\n\u2022 Min-noise RMP<br>\n\u2022 Nature of the RMP problems<br>\n\u2022 Mapping RMP to database tiling problem<br>\n\u2022 Minimum tiling problem<br>\n\u2022 Mapping min-noise RMP to database tiling problem<br>\n\u2022 Mapping RMP to minimum biclique cover problem<br></p>\n', 'Tags': '<education><reference-request><security><access-control>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-16T18:15:31.373', 'CommentCount': '0', 'AcceptedAnswerId': '1248', 'CreationDate': '2012-04-13T06:06:48.493', 'Id': '1246'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m looking for a list of informed search algorithms, also known as heuristic search algorithms. </p>\n\n<p>I\'m aware of: </p>\n\n<ol>\n<li><p><a href="http://en.wikipedia.org/wiki/Best-first_search" rel="nofollow">best-first search</a></p>\n\n<ul>\n<li>Greedy best-first search</li>\n<li><a href="http://en.wikipedia.org/wiki/A%2a_search_algorithm" rel="nofollow">A* search</a></li>\n</ul></li>\n</ol>\n\n<p>Are there more best-first algorithm or other informed searches that are not best-first?</p>\n', 'ViewCount': '289', 'Title': 'Survey of informed search algorithms?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-10-09T08:02:07.933', 'LastEditDate': '2012-04-16T20:08:11.290', 'AnswerCount': '3', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '935', 'Tags': '<algorithms><reference-request><artificial-intelligence><search-algorithms>', 'CreationDate': '2012-04-16T09:53:58.100', 'FavoriteCount': '2', 'Id': '1300'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am studying different approaches for the definition of computation with continuous dynamical systems. I have been trying to find a nice introduction to the theory of <a href="http://en.wikipedia.org/wiki/State_transition_system">"State transition systems"</a> but failed to do so.</p>\n\n<p>Does anybody know a modern introduction to the topic? \nOf particular interest would be something dealing with computability.</p>\n', 'ViewCount': '186', 'Title': 'What is a good reference to learn about state transition systems?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-18T18:45:31.160', 'LastEditDate': '2012-04-18T18:45:31.160', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '715', 'Tags': '<computability><automata><reference-request><computation-models>', 'CreationDate': '2012-04-18T09:13:20.920', 'FavoriteCount': '1', 'Id': '1335'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '201', 'Title': 'What is the name of this logistic variant of TSP?', 'LastEditDate': '2012-04-23T14:25:32.307', 'AnswerCount': '3', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '472', 'FavoriteCount': '1', 'Body': '<p>I have a logistic problem that can be seen as a variant of $\\text{TSP}$. It is so natural, I\'m sure it has been studied in Operations research or something similar. Here\'s one way of looking at the problem.</p>\n\n<p>I have $P$ warehouses on the Cartesian plane. There\'s a path from a warehouse to every other warehouse and the distance metric used is the Euclidean distance. In addition, there are $n$ different items. Each item $1 \\leq i \\leq n$ can be present in any number of warehouses. We have a collector and we are given a starting point $s$ for it, say the origin $(0,0)$. The collector is given an order, so a list of items. Here, we can assume that the list only contains distinct items and only one of each. We must determine the shortest tour starting at $s$ visiting some number of warehouses so that the we pick up every item on the order.</p>\n\n<p>Here\'s a visualization of a randomly generated instance with $P = 35$. Warehouses are represented with circles. Red ones contain item $1$, blue ones item $2$ and green ones item $3$. Given some starting point $s$ and the order ($1,2,3$), we must pick one red, one blue and one green warehouse so the order can be completed. By accident, there are no multi-colored warehouses in this example so they all contain exactly one item. This particular instance is a case of <a href="http://en.wikipedia.org/wiki/Set_TSP_problem" rel="nofollow">set-TSP</a>.</p>\n\n<p><img src="http://i.stack.imgur.com/5kKsj.png" alt="An instance of the problem."></p>\n\n<p>I can show that the problem is indeed $\\mathcal{NP}$-hard. Consider an instance where each item $i$ is located in a different warehouse $P_i$. The order is such that it contains every item. Now we must visit every warehouse $P_i$ and find the shortest tour doing so. This is equivalent of solving an instance of $\\text{TSP}$.</p>\n\n<p>Being so obviously useful at least in the context of logistic, routing and planning, I\'m sure this has been studied before. I have two questions:</p>\n\n<ol>\n<li>What is the name of the problem?</li>\n<li>How well can one hope to approximate the problem (assuming $\\mathcal{P} \\neq \\mathcal{NP}$)? </li>\n</ol>\n\n<p>I\'m quite happy with the name and/or reference(s) to the problem. Maybe the answer to the second point follows easily or I can find out that myself.</p>\n', 'Tags': '<algorithms><optimization><reference-request><approximation>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-04-23T18:22:16.660', 'CommentCount': '4', 'AcceptedAnswerId': '1464', 'CreationDate': '2012-04-22T15:35:56.930', 'Id': '1440'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '665', 'Title': 'Dealing with intractability: NP-complete problems', 'LastEditDate': '2013-06-06T14:11:05.583', 'AnswerCount': '6', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '1219', 'FavoriteCount': '8', 'Body': '<p>Assume that I am a programmer and I have an NP-complete problem that I need to solve it. What methods are available to deal with NPC problems? Is there a survey or something similar on this topic?</p>\n', 'Tags': '<algorithms><reference-request><np-complete><efficiency><reference-question>', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-06T14:11:05.583', 'CommentCount': '4', 'AcceptedAnswerId': '1481', 'CreationDate': '2012-04-24T03:28:23.417', 'Id': '1477'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Will there be a need to change the definitions of security if we have quantum computers? What cryptographic constructions will break? Do you know a survey or an article that explains what will be needed to change?</p>\n', 'ViewCount': '314', 'Title': 'What is the difference between classical crypto and post-quantum crypto?', 'LastEditorUserId': '69', 'LastActivityDate': '2012-04-30T19:48:18.947', 'LastEditDate': '2012-04-30T17:21:10.673', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1318', 'Tags': '<reference-request><cryptography><quantum-computing>', 'CreationDate': '2012-04-30T17:11:36.020', 'FavoriteCount': '1', 'Id': '1595'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>[<em>previously appearing in cstheory, it was closed there and introduced here instead</em>]</p>\n\n<p>Given an edge-weighted graph $G=(V,E)$ the problem of finding the shortest path is known to be in P ---and indeed a simple approach would be Dijkstra\'s algorithm which can solve this problem in $O(V^2)$. A similar problem is to find the maximum path in $G$ from a source node to a target node and this can be solved with Integer Programming so that, as far as I know, this is not known to be in P.</p>\n\n<p>Now, the problem of finding a path in $G$ such that it deviates the minimum from a given target value (typically larger than the optimal distance but less than the maximum distance that separates the source and target nodes) has been conjectured to be in EXPTIME (see section "Conventions" of <a href="http://search-conference.org/index.php/Main/SOCS09program" rel="nofollow">A depth-first approach to target-value search</a> in the proceedings of SoCS 2009). In particular, this paper addresses this particular problem for  directed acyclic graphs (DAGs). A previous work is <a href="http://www.uwosh.edu/faculty_staff/furcyd/search_symposium_2008/schedule.html" rel="nofollow">Heuristic Search for Target-Value Path Problem</a>. There is event a US Patent of this algorithm <a href="http://www.google.es/patents?hl=es&amp;lr=&amp;vid=USPATAPP12497353&amp;id=gojwAAAAEBAJ&amp;oi=fnd&amp;dq=%22depth-first+search+for+target+value+problems%22&amp;printsec=abstract#v=onepage&amp;q=%22depth-first%20search%20for%20target%20value%20problems%22&amp;f=false" rel="nofollow">US 2011/0004625</a>.</p>\n\n<p>I\'ve been searching for related problems in other fields of Computer Science and Mathematics and strikingly, I have found none though this problem is clearly relevant in practice ---there are tons of opportunities to look for a specific target value instead of the minimum or the maximum path.</p>\n\n<p>Do you know related problems to this or additional bibliographical references to this problem? Any information on this problem including studies of their complexity would be very welcome</p>\n\n<p><strong>Note</strong>: as already pointed out by Jeffe in cstheory, proving this problem to be in EXPTIME is trivial and the authors probably meant EXPTIME-complete.</p>\n', 'ViewCount': '121', 'Title': 'Target-Value Search (& II)', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-08T20:16:41.033', 'LastEditDate': '2012-05-09T15:50:10.143', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1337', 'Tags': '<algorithms><complexity-theory><reference-request><search-algorithms>', 'CreationDate': '2012-05-02T12:21:24.380', 'Id': '1634'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have had problems accepting the complexity theoretic view of "efficiently solved by parallel algorithm" which is given by the class <a href="https://en.wikipedia.org/wiki/NC_%28complexity%29">NC</a>:</p>\n\n<blockquote>\n  <p>NC is the class of problems that can be solved by a parallel algorithm in time $O(\\log^cn)$ on $p(n) \\in O(n^k)$ processors with $c,k \\in \\mathbb{N}$.</p>\n</blockquote>\n\n<p>We can assume a <a href="https://en.wikipedia.org/wiki/Parallel_random_access_machine">PRAM</a>.</p>\n\n<p>My problem is that this does not seem to say much about "real" machines, that is machines with a finite amount of processors. Now I am told that "it is known" that we can "efficiently" simulate a $O(n^k)$ processor algorithm on $p \\in \\mathbb{N}$ processors.</p>\n\n<p>What does "efficiently" mean here? Is this folklore or is there a rigorous theorem which quantifies the overhead caused by simulation?</p>\n\n<p>What I am afraid that happens is that I have a problem which has a sequential $O(n^k)$ algorithm and also an "efficient" parallel algorithm which, when simulated on $p$ processors, also takes $O(n^k)$ time (which is all that can be expected on this granularity level of analysis if the sequential algorithm is asymptotically optimal). In this case, there is no speedup whatsover as far as we can see; in fact, the simulated parallel algorithm may be <em>slower</em> than the sequential algorithm. That is I am really looking for statements more precise than $O$-bounds (or a declaration of absence of such results).</p>\n', 'ViewCount': '260', 'Title': 'How to scale down parallel complexity results to constantly many cores?', 'LastActivityDate': '2012-05-03T22:04:13.333', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '1648', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><reference-request><parallel-computing>', 'CreationDate': '2012-05-03T08:08:30.570', 'Id': '1647'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am currently reviewing the potentials of cloud computing regarding energy efficiency and green IT. In connection with this review I am having a look on techniques for increasing energy-efficiency in data centers (computing), hardware, networking and storage devices.</p>\n\n<p>Specificially for computing/servers I have found already a few:</p>\n\n<ul>\n<li>energy-aware scheduling techniques utilizing frequency and voltage scaling </li>\n<li>virtualization to consolidate server resources</li>\n<li>energy-saving hardware, e.g. ACPI, several processor techniques, especially for mobile devices etc.</li>\n</ul>\n\n<p>However, for networking devices it is rather hard to get information about energy-saving technologies. I have read that people are thinking about new protocols and alternative routing methods to be able to switch off hardware if the network is under low load. Does anyone know of such examples? </p>\n\n<p>Which other points should be added, either for networking or computing</p>\n', 'ViewCount': '146', 'Title': 'What techniques exist for energy-efficient computing and networking?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-24T15:04:08.463', 'LastEditDate': '2012-05-10T15:17:18.700', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1413', 'Tags': '<reference-request><computer-architecture><operating-systems><computer-networks><power-consumption>', 'CreationDate': '2012-05-08T10:05:00.307', 'Id': '1729'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '182', 'Title': 'How do I classify my emulator input optimization problem, and with which algorithm should I approach it?', 'LastEditDate': '2012-05-10T05:41:50.040', 'AnswerCount': '2', 'Score': '9', 'OwnerDisplayName': 'GManNickG', 'PostTypeId': '1', 'OwnerUserId': '1436', 'FavoriteCount': '1', 'Body': '<p>Due to the nature of the question, I have to include lots of background information (because my question is: how do I narrow this down?) That said, it can be summarized (to the best of my knowledge) as:</p>\n\n<p><strong>What methods exist to find local optimums on extremely large combinatorial search spaces?</strong></p>\n\n<h2>Background</h2>\n\n<p>In the tool-assisted superplay community we look to provide specially-crafted (not generated in real-time) input to a video game console or emulator in order to minimize some cost (usually time-to-completion). The way this is currently done is by playing the game frame-by-frame and specifying the input for each frame, often redoing parts of the run many times (for example, the <a href="http://tasvideos.org/2020M.html">recently published</a> run for <em>The Legend of Zelda: Ocarina of Time</em> has a total of 198,590 retries).</p>\n\n<p><strong>Making these runs obtain their goal usually comes down to two main factors: route-planning and traversal.</strong> The former is much more "creative" than the latter.</p>\n\n<p>Route-planning is determining which way the player should navigate overall to complete the game, and is often the most important part of the run. This is analogous to choosing which sorting method to use, for example. The best bubble sort in the world simply isn\'t going to outperform a quick-sort on 1 million elements.</p>\n\n<p>In the desire for perfection, however, traversal (how the route is carried out) is also a huge factor. Continuing the analogy, this is how the sorting algorithm is implemented. Some routes can\'t even be performed without very specific frames of input. This is the most tedious process of tool-assisting and is what makes the production of a completed run takes months or even years. It\'s not a <em>difficult</em> process (to a human) because it comes down to trying different variations of the same idea until one is deemed best, but humans can only try so many variations in their attention-span. The application of machines to this task seems proper here.</p>\n\n<p><strong>My goal now is to try to automate the traversal process in general for the Nintendo 64 system</strong>. The search space for this problem is <em>far</em> too large to attack with a brute-force approach. An n-frame segment of an N64 run has 2<sup>30n</sup> possible inputs, meaning a mere 30 frames of input (a second at 30FPS) has 2<sup>900</sup> possible inputs; it would be impossible to test these potential solutions, let alone those for a full two-hour run.</p>\n\n<p>However, I\'m not interested in attempting (or rather, am not going to even try to attempt) total global optimization of a full run. Rather, <strong>I would like to, given an initial input, approximate the <em>local</em> optimum for a particular <em>segment</em> of a run (or the nearest <em>n</em> local optimums, for a sort of semi-global optimization)</strong>. That is, given a route and an initial traversal of that route: search the neighbors of that traversal to minimize cost, but don\'t degenerate into trying all the cases that could solve the problem.</p>\n\n<p>My program should therefore take a starting state, an input stream, an evaluation function, and output the local optimum by minimizing the result of the evaluation.</p>\n\n<h2>Current State</h2>\n\n<p>Currently I have all the framework taken care of. This includes evaluating an input stream via manipulation of the emulator, setup and teardown, configuration, etc. And as a placeholder of sorts, the optimizer is a very basic genetic algorithm. It simply evaluates a population of input streams, stores/replaces the winner, and generates a new population by mutating the winner stream. This process continues until some arbitrary criteria is met, like time or generation number.</p>\n\n<p><strong>Note that the slowest part of this program will be, by far, the evaluation of an input stream</strong>. This is because this involves emulating the game for <em>n</em> frames. (If I had the time I\'d write my own emulator that provided hooks into this kind of stuff, but for now I\'m left with synthesizing messages and modifying memory for an existing emulator from another process.) On my main computer, which is fairly modern, evaluating 200 frames takes roughly 14 seconds. As such, I\'d prefer an algorithm (given the choice) that minimizes the number of function evaluations.</p>\n\n<p>I\'ve created a system in the framework that manages emulators concurrently. As such <strong>I can evaluate a number of streams at once</strong> with a linear performance scale, but practically speaking the number of running emulators can only be 8 to 32 (and 32 is really pushing it) before system performance deteriorates. This means (given the choice), an algorithm which can do processing while an evaluation is taking place would be highly beneficial, because the optimizer can do some heavy-lifting while it waits on an evaluation.</p>\n\n<p>As a test, my evaluation function (for the game <em>Banjo Kazooie</em>) was to sum, per frame, the distance from the player to a goal point. This meant the optimal solution was to get as close to that point as quickly as possible. Limiting mutation to the analog stick only, it took a day to get an <em>okay</em> solution. (This was before I implemented concurrency.)</p>\n\n<p>After adding concurrency, I enabled mutation of A button presses and did the same evaluation function at an area that required jumping. With 24 emulators running it took roughly 1 hour to reach the goal from an initially blank input stream, but would probably need to run for days to get to anything close to optimal.</p>\n\n<h2>Problem</h2>\n\n<p><strong>The issue I\'m facing is that I don\'t know enough about the mathematical optimization field to know how to properly model my optimization problem</strong>! I can roughly follow the conceptual idea of many algorithms as described on Wikipedia, for example, but I don\'t know how to categorize my problem or select the state-of-the-art algorithm for that category.</p>\n\n<p><strong>From what I can tell, I have a combinatorial problem with an extremely large neighborhood</strong>. On top of that, <strong>the evaluation function is extremely discontinuous, has no gradient, and has many plateaus</strong>. Also, there aren\'t many constraints, though I\'ll gladly add the ability to express them if it helps solve the problem; I would like to allow specifying that the Start button should not be used, for example, but this is not the general case.</p>\n\n<h2>Question</h2>\n\n<p><strong>So my question is: how do I model this? What kind of optimization problem am I trying to solve? Which algorithm am I suppose to use?</strong> I\'m not afraid of reading research papers so let me know what I should read!</p>\n\n<p>Intuitively, a genetic algorithm couldn\'t be the best, because it doesn\'t really seem to learn. For example, if pressing Start seems to <em>always</em> make the evaluation worse (because it pauses the game), there should be some sort of designer or brain that learns: "pressing Start at any point is useless." But even this goal isn\'t as trivial as it sounds, because sometimes pressing start <em>is</em> optimal, such as in so-called "pause backward-long-jumps" in <em>Super Mario 64</em>! Here the brain would have to learn a much more complex pattern: "pressing Start is useless except when the player is in this very specific state <em>and will continue with some combination of button presses</em>." </p>\n\n<p>It seems like I should (or the machine could learn to) represent input in some other fashion more suited to modification. Per-frame input seems too granular, because what\'s really needed are "actions", which may span several frames...yet many discoveries are made on a frame-by-frame basis, so I can\'t totally rule it out (the aforementioned pause backward-long-jump requires frame-level precision). It also seems like the fact that input is processed serially should be something that can be capitalized on, but I\'m not sure how.</p>\n\n<p><strong>Currently I\'m reading about (Reactive) Tabu Search, Very Large-scale Neighborhood Search, Teaching-learning-based Optimization, and Ant Colony Optimization.</strong></p>\n\n<p>Is this problem simply too hard to tackle with anything other than random genetic algorithms? Or is it actually a trivial problem that was solved long ago? Thanks for reading and thanks in advance for any responses.</p>\n', 'Tags': '<reference-request><machine-learning><combinatorics><optimization><search-problem>', 'LastEditorUserId': '1436', 'LastActivityDate': '2014-01-19T16:02:17.470', 'CommentCount': '2', 'AcceptedAnswerId': '2947', 'CreationDate': '2012-05-09T06:34:52.220', 'Id': '1774'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have trouble understanding the cyclic coordinate method. How does it differ with the <a href="http://en.wikipedia.org/wiki/Pattern_search_%28optimization%29" rel="nofollow">Hook and Jeeves method</a> and the <a href="http://en.wikipedia.org/wiki/Rosenbrock_methods" rel="nofollow">Rosenbrock method</a>?</p>\n\n<p>From a past exam text:</p>\n\n<blockquote>\n  <p>Describe the cyclic coordinate method and outline the similarities and the \n  differences between the Cyclic Coordinate method, the Hooke and Jeeves \n  method, and the Rosenbrock method.</p>\n</blockquote>\n\n<p>I would appreciate a good reference, I\'m having trouble finding any.</p>\n', 'ViewCount': '258', 'Title': 'Cyclic coordinate method: how does it differ from Hook & Jeeves and Rosenbrock?', 'LastEditorUserId': '4304', 'LastActivityDate': '2012-11-27T17:35:21.360', 'LastEditDate': '2012-11-27T17:35:21.360', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '3', 'OwnerDisplayName': 'qurty', 'PostTypeId': '1', 'Tags': '<algorithms><reference-request><optimization><numerical-analysis>', 'CreationDate': '2012-05-06T17:32:23.577', 'Id': '1792'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Most of us know the correspondence between <a href="http://en.wikipedia.org/wiki/Combinatory_logic" rel="nofollow">combinatory logic</a> and <a href="http://en.wikipedia.org/wiki/Lambda_calculus" rel="nofollow">lambda calculus</a>. But I\'ve never seen (maybe I haven\'t looked deep enough) the equivalent of "typed combinators", corresponding to the simply typed lambda calculus. Does such thing exist? Where could one find information about it?</p>\n', 'ViewCount': '218', 'Title': 'Is there a typed SKI calculus?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-14T15:47:46.390', 'LastEditDate': '2012-05-14T15:47:16.223', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '1818', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1300', 'Tags': '<logic><reference-request><lambda-calculus><type-theory>', 'CreationDate': '2012-05-13T01:39:47.143', 'Id': '1816'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Some frontmatter: I\'m a recreational computer scientist and employed software engineer. So, pardon if this prompt seems somewhat out of left field -- I routinely play with mathematical simulcra and open problems when I have nothing better to do. </p>\n\n<p>While playing with the <a href="http://en.wikipedia.org/wiki/Riemann_hypothesis" rel="nofollow">Riemann hypothesis</a>, I determined that the <a href="http://en.wikipedia.org/wiki/Prime_gap" rel="nofollow">prime gap</a> can be reduced to a recurrence relation based on the intersection of all $n-1$ complementary functions formed by the multiples of each previous prime number (keen observers will note this is a generalization of the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes" rel="nofollow">Sieve of Eratosthenes</a>). If this makes absolutely no sense to you, don\'t worry -- it\'s still frontmatter.</p>\n\n<p>Seeing how these functions related, I realized that the next instance of each prime can be reduced to the first intersection of these functions, recurring forward infinitely. However, I could not determine if this is tractable in polytime and polyspace. Thus: <strong>what I\'m looking for is an algorithm that can determine the first intersection of $n$ discrete (and, if applicable, monotonic) functions in polynomial time and space. If no such algorithm currently exists or can exist, a terse proof or reference stating so is sufficient.</strong> </p>\n\n<p>The closest I can find so far is <a href="http://en.wikipedia.org/wiki/Dykstra%27s_projection_algorithm" rel="nofollow">Dykstra\'s projection algorithm</a> (yes, that\'s R. L. Dykstra, not <a href="http://en.wikipedia.org/wiki/Edsger_Dijkstra" rel="nofollow">Edsger Dijkstra</a>), which I believe reduces itself to a problem of <a href="http://en.wikipedia.org/wiki/Linear_programming#Integer_unknowns" rel="nofollow">integer programming</a> and is, therefore, NP-hard. Similarly, if one performs a transitive set intersection of all of the applicable points (as they\'re currently understood to be bounded), we must still constrain ourselves to exponential space for our recurrence due to the current weak bound of $\\ln(m)$ primes for any real $m$ (and therefore, $e^n$ space for each prime $n$).</p>\n\n<p>Globally, I\'m wondering if my understanding of the reduction of the problem is wrong. I don\'t expect to solve the Riemann hypothesis (or any deep, open problem in this space) any time soon. Rather, I\'m seeking to learn more about it by playing with the problem, and I\'ve hit a snag in my research.</p>\n', 'ViewCount': '109', 'Title': 'Polytime and polyspace algorithm for determining the leading intersection of n discrete monotonic functions', 'LastEditorUserId': '472', 'LastActivityDate': '2013-03-23T16:24:14.963', 'LastEditDate': '2013-03-23T16:24:14.963', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '10705', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '958', 'Tags': '<algorithms><reference-request><discrete-mathematics>', 'CreationDate': '2012-05-13T23:01:03.153', 'Id': '1828'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There are lots of attempts at proving either $\\mathsf{P} = \\mathsf{NP} $ or $\\mathsf{P} \\neq \\mathsf{NP}$, and naturally many people think about the question, having ideas for proving either direction.</p>\n\n<p>I know that there are approaches that have been proven to not work, and there are probably more that have a history of failing. There also seem to be so-called <em>barriers</em> that many proof attemps fail to overcome. </p>\n\n<p>We want to avoid investigating into dead-ends, so what are they?</p>\n', 'ViewCount': '6113', 'Title': 'How not to solve P=NP?', 'LastEditorUserId': '6716', 'LastActivityDate': '2014-03-26T03:42:53.937', 'LastEditDate': '2013-06-06T14:08:25.930', 'AnswerCount': '5', 'CommentCount': '5', 'Score': '41', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><reference-request><history><p-vs-np><reference-question>', 'CreationDate': '2012-05-17T01:24:29.327', 'FavoriteCount': '24', 'Id': '1877'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>As follows <a href="http://cs.stackexchange.com/questions/1828/polytime-and-polyspace-algorithm-for-determining-the-leading-intersection-of-n-d">from my previous question</a>, I\'ve been playing with the <a href="http://en.wikipedia.org/wiki/Riemann_hypothesis">Riemann hypothesis</a> as a matter of recreational mathematics. In the process, I\'ve come to a rather interesting recurrence, and I\'m curious as to its name, its reductions, and its tractability towards the solvability of the gap between prime numbers.</p>\n\n<p>Tersely speaking, we can define the <em>gap</em> between each prime number as a recurrence of preceding <em>candidate</em> primes. For example, for our base of $p_0 = 2$, the next prime would be:</p>\n\n<p>$\\qquad \\displaystyle p_1 = \\min \\{ x &gt; p_0 \\mid -\\cos(2\\pi(x+1)/p_0) + 1 = 0)  \\}$</p>\n\n<p>Or, as we see by <a href="http://m.wolframalpha.com/input/?i=-cos%28%28x%2b1%29%2a2%2api/2%29%20%2b%201%20=%200">plotting this out</a>: $p_1 = 3$.</p>\n\n<p>We can repeat the process for $n$ primes by evaluating each candidate prime recurring forward. Suppose we want to get the next prime, $p_2$. Our candidate function becomes:</p>\n\n<p>$\\qquad \\displaystyle \\begin{align}\np_2 = \\min\\{ x &gt; p_1 \\mid f_{p_1}(x) + (&amp;(-\\cos(2\\pi(x+1)/p_1) + 1) \\\\\n                                   \\cdot &amp;(-\\cos(2\\pi(x+2)/p_1) + 1)) = 0\\}\n\\end{align}$</p>\n\n<p>Where:</p>\n\n<p>$\\qquad \\displaystyle f_{p_1}(x) = -\\cos(2\\pi(x+1)/p_0) + 1$, as above.</p>\n\n<p>It\'s easy to see that each component function only becomes zero on integer values, and it\'s equally easy to show how this captures our AND- and XOR-shaped relationships cleverly, by exploiting the properties of addition and multiplication in the context of a system of trigonometric equations.</p>\n\n<p>The recurrence becomes:</p>\n\n<p>$\\qquad f_{p_0} = 0\\\\\n\\qquad p_0 = 2\\\\\n\\qquad \\displaystyle\n  f_{p_n}(x) = f_{p_{n-1}}(x) + \\prod_{k=2}^{p_{n-1}} (-\\cos(2\\pi(x+k-1)/p_{n-1}) + 1)\\\\\n \\qquad \\displaystyle\n p_n = \\min\\left\\{ x &gt; p_{n-1} \\mid f_{p_n}(x) = 0\\right\\}$</p>\n\n<p>... where the entire problem hinges on whether we can evaluate the $\\min$ operator over this function in polynomial time. This is, in effect, a generalization of the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Eratosthenes</a>.</p>\n\n<p>Working Python code to demonstrate the recurrence:</p>\n\n<pre><code>from math import cos,pi\n\ndef cosProduct(x,p):\n    """ Handles the cosine product in a handy single function """\n    ret = 1.0\n    for k in xrange(2,p+1):\n        ret *= -cos(2*pi*(x+k-1)/p)+1.0\n    return ret\n\ndef nthPrime(n):\n    """ Generates the nth prime, where n is a zero-based integer """\n\n    # Preconditions: n must be an integer greater than -1\n    if not isinstance(n,int) or n &lt; 0:\n        raise ValueError("n must be an integer greater than -1")\n\n    # Base case: the 0th prime is 2, 0th function vacuous\n    if n == 0:\n        return 2,lambda x: 0\n\n    # Get the preceding evaluation\n    p_nMinusOne,fn_nMinusOne = nthPrime(n-1)\n\n    # Define the function for the Nth prime\n    fn_n = lambda x: fn_nMinusOne(x) + cosProduct(x,p_nMinusOne)\n\n    # Evaluate it (I need a solver here if it\'s tractable!)\n    for k in xrange(p_nMinusOne+1,int(p_nMinusOne**2.718281828)):\n        if fn_n(k) == 0:\n            p_n = k\n            break\n\n    # Return the Nth prime and its function\n    return p_n,fn_n\n</code></pre>\n\n<p>A quick example:</p>\n\n<pre><code>&gt;&gt;&gt; [nthPrime(i)[0] for i in range(20)]\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\n</code></pre>\n\n<p>The trouble is, I\'m now in way over my head, both mathematically and as a computer scientist. Specifically, I am not competent with <a href="http://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a>, with defining <a href="http://en.wikipedia.org/wiki/Uniform_space#Uniform_cover_definition">uniform covers</a>, or with the <a href="http://en.wikipedia.org/wiki/Complex_plane">complex plane</a> in general, and I\'m worried that this approach is either flat-out <em>wrong</em> or hides a lurking horror of a 3SAT problem that elevates it to NP-completeness.</p>\n\n<p>Thus, I have three questions here:</p>\n\n<blockquote>\n  <ol>\n  <li>Given my terse recurrence above, is it possible to deterministically compute or estimate the location of the zeroes in polynomial time and space?</li>\n  <li>If so or if not, is it hiding <em>any other</em> subproblems that would make a polytime or polyspace solution intractable?</li>\n  <li>And if by some miracle (1) and (2) hold up, what dynamic programming improvements would you make in satisfying this recurrence, from a high level? Clearly, iteration over the same integers through multiple functions is inelegant and quite wasteful.</li>\n  </ol>\n</blockquote>\n', 'ViewCount': '333', 'Title': 'Proving the (in)tractability of this Nth prime recurrence', 'LastEditorUserId': '958', 'LastActivityDate': '2012-05-24T08:38:32.067', 'LastEditDate': '2012-05-24T08:38:32.067', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '958', 'Tags': '<complexity-theory><reference-request><recurrence-relation><mathematical-analysis>', 'CreationDate': '2012-05-22T00:50:48.443', 'FavoriteCount': '3', 'Id': '1984'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '253', 'Title': 'Machine Learning algorithms based on "structural risk minimization"?', 'LastEditDate': '2012-05-23T15:42:06.250', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1603', 'FavoriteCount': '1', 'Body': '<p>Which machine learning algorithms (besides SVM\'s) use the principle of <a href="https://en.wikipedia.org/wiki/Structural_risk_minimization" rel="nofollow">structural risk minimization</a>?</p>\n', 'Tags': '<reference-request><machine-learning>', 'LastEditorUserId': '137', 'LastActivityDate': '2012-05-23T15:42:06.250', 'CommentCount': '5', 'AcceptedAnswerId': '2007', 'CreationDate': '2012-05-22T20:03:45.760', 'Id': '2006'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>For my pet project I need to cluster some data which could be easily represented as graph, so I want to use this as an opportunity to educate myself and play with various algorithms. I'd prefer the book on graph clustering as it often more self contained but articles are fine too. Back in the days I used to work in the field of numerical linear algebra so I'd also prefer algebraical view on things (so books which view graph as a matrix with specific properties are more accessible to me).</p>\n\n<p>p.s. I've tried scholar.google.com but was overwhelmed by vast number of results.  </p>\n", 'ViewCount': '81', 'Title': 'Could someone suggest me a good introductory book or an article on graph clustering?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-25T14:29:21.953', 'LastEditDate': '2012-05-25T14:19:42.963', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '2077', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1647', 'Tags': '<algorithms><graphs><graph-theory><reference-request><books>', 'CreationDate': '2012-05-25T13:00:28.593', 'Id': '2076'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p><a href="http://cs.stackexchange.com/questions/1984/proving-the-intractability-of-this-nth-prime-recurrence">As discussed in this question,</a> I drafted a spec algorithm that hinges on finding a specific root of a system of trigonometric equations satisfying the following recurrence:</p>\n\n<p>$\\qquad f_{p_0} = 0\\\\\n\\qquad p_0 = 2\\\\\n\\qquad \\displaystyle\n  f_{p_n}(x) = f_{p_{n-1}}(x) + \\prod_{k=2}^{p_{n-1}} (-\\cos(2\\pi(x+k-1)/p_{n-1}) + 1)\\\\\n \\qquad \\displaystyle\n p_n = \\min\\left\\{ x &gt; p_{n-1} \\mid f_{p_n}(x) = 0\\right\\}$</p>\n\n<p><a href="http://www.wolframalpha.com/input/?i=%E2%88%92cos%282%CF%80%28x%2b1%29/2%29%2b1%2b%28%E2%88%92cos%282%CF%80%28x%2b1%29/3%29%2b1%29%28%E2%88%92cos%282%CF%80%28x%2b2%29/3%29%2b1%29%2b%28%E2%88%92cos%282%CF%80%28x%2b1%29/5%29%2b1%29%28%E2%88%92cos%282%CF%80%28x%2b2%29/5%29%2b1%29%28%E2%88%92cos%282%CF%80%28x%2b3%29/5%29%2b1%29%28%E2%88%92cos%282%CF%80%28x%2b4%29/5%29%2b1%29=0%20for%20x" rel="nofollow">Playing with this system a bit over on Wolfram|Alpha</a>, it seems I can get specific answers to the recurrence from their <a href="http://en.wikipedia.org/wiki/Computer_algebra_system" rel="nofollow">computer algebra system</a>. Unfortunately, I can find no specific documentation on the methods they\'re using to solve my equations.</p>\n\n<p>My question, then: </p>\n\n<blockquote>\n  <p>What methods (and what time and space complexities) do computer algebra systems use to solve these forms of equations? I suspect the <a href="http://en.wikipedia.org/wiki/Gr%C3%B6bner_basis" rel="nofollow">Gr\xf6bner basis</a> is commonly used, but I could be very wrong.</p>\n</blockquote>\n', 'ViewCount': '163', 'Title': 'Complexity of computer algebra for systems of trigonometric equations', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-28T18:02:17.160', 'LastEditDate': '2012-05-28T18:02:17.160', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '958', 'Tags': '<reference-request><runtime-analysis><mathematical-analysis><computer-algebra><mathematical-software>', 'CreationDate': '2012-05-28T09:20:37.547', 'FavoriteCount': '1', 'Id': '2121'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>It is a trivial exercise in finite automata to show that there is no algorithm that can detect all the viruses, yet there are many software companies selling Anti Virus Software.</p>\n\n<p>Is there any part of CS that deals with Viruses and Anti Viruses ?</p>\n\n<p>PS : I am not asking about non CS related justification of to have AV or not, but only what category/subject within CS they come under, if any. If AV is not a subject within CS then that is also an acceptable answer, are there any refrences within CS context to Viruses and AV's? </p>\n", 'ViewCount': '579', 'Title': 'What is the branch of Computer Science that studies how Anti Virus programs work?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-29T03:19:50.450', 'LastEditDate': '2012-05-28T15:36:52.600', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1663', 'Tags': '<reference-request><security>', 'CreationDate': '2012-05-28T13:18:23.817', 'FavoriteCount': '5', 'Id': '2130'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'d like to understand the <a href="https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm" rel="nofollow">Baum-Welch algorithm</a>. I liked <a href="http://www.youtube.com/watch?v=7zDARfKVm7s&amp;feature=related" rel="nofollow">this video</a> on the Forward-Backward algorithm so I\'d like a similar one for Baum-Welch.</p>\n\n<p>I\'m having trouble coming up with good resources for Baum-Welch. Any ideas?</p>\n', 'ViewCount': '275', 'Title': 'Any very user friendly resources on the Baum-Welch algorithm?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-29T18:34:46.793', 'LastEditDate': '2012-05-28T23:52:50.387', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '3364', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1680', 'Tags': '<algorithms><reference-request><hidden-markov-models>', 'CreationDate': '2012-05-28T23:43:11.757', 'Id': '2149'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '338', 'Title': 'How to read typing rules?', 'LastEditDate': '2012-05-29T17:09:34.050', 'AnswerCount': '3', 'Score': '7', 'OwnerDisplayName': 'suls', 'PostTypeId': '1', 'OwnerUserId': '1745', 'FavoriteCount': '1', 'Body': '<p>I started reading more and more language research papers. I find it very interesting and a good way to learn more about programming in general. However, there usually comes a section where I always struggle with (take for instance part three of <a href="http://math.andrej.com/wp-content/uploads/2012/03/eff.pdf">this</a>) since I lack the theoretical background in computer science: Type Rules.</p>\n\n<p>Are there any good books or online resources available to get started in this area? <a href="http://en.wikipedia.org/wiki/Type_rules">Wikipedia</a> is incredibly vague and doesn\'t really help a beginner.</p>\n', 'Tags': '<logic><reference-request><terminology><type-theory>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-29T19:29:45.030', 'CommentCount': '2', 'AcceptedAnswerId': '2160', 'CreationDate': '2012-05-29T07:18:09.443', 'Id': '2155'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What would be the standard topics covered in an \'Advanced Placement Computer Science A\' test? Is there any good study reference someone can share? </p>\n\n<p><strong>Edit: Answer</strong></p>\n\n<p>An adjustment for my search term returned a <a href="http://en.wikipedia.org/wiki/Advanced_Placement_Computer_Science" rel="nofollow">Wikipedia page</a> just for this type of exam and the AB version.</p>\n', 'ViewCount': '156', 'Title': 'Advanced placement CS A Exam', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-11T18:48:24.533', 'LastEditDate': '2012-06-06T22:15:10.363', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '2210', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1499', 'Tags': '<reference-request><education>', 'CreationDate': '2012-06-02T22:50:40.283', 'Id': '2206'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Many areas in the world suffer from conflicts between two groups (usually ethnic or religious). For the purpose of this question, I assume that most people of both sides want to live in peace, but there are few extremists who incite hatred and violence. The goal of this question is to find an objective way to filter out those extremists.</p>\n\n<p>Imagine a town with 2 conflicting groups, A and B, each has N people. I propose the following voting scheme (which I explain from the point of view of group A, but it\'s entirely symmetric for the other group):</p>\n\n<ul>\n<li><strong>equality-rule</strong>: The number of people in each group must always remain equal.</li>\n<li><strong>expel-vote</strong>: At any time, each person of group A can claim that a certain person of group B is "extremist", and start a vote. If more than 50% of the people in group A agree, then that certain person is expelled from town.</li>\n<li><strong>counter-vote</strong>: To keep the equality-rule, a single person of group A should also leave the town. This person is selected by a vote between the people in group B (i.e. each person in group B votes for a single person in group A, and the one with most votes is expelled from town).</li>\n</ul>\n\n<p>My intuition is that:</p>\n\n<ul>\n<li>On one hand, this scheme encourages people to be nice to people of the other group, so that they won\'t be subject to expel-votes.</li>\n<li>On the other hand, the equality rule encourages people to think twice before starting an expel-vote, because this will put them in danger of expel in the counter-vote.</li>\n</ul>\n\n<p>[ADDITION]\nSeveral questions can be asked about this scheme, for example:</p>\n\n<ul>\n<li>Under what conditions does it diverge to a situation where people vote and counter-vote, until the number of citizens in one of the groups reaches 0? </li>\n<li>Under what conditions does it stabilize on a situation where the two group has more than 0 citizens? </li>\n<li>Under what conditions, the stable number of citizens is more than half the initial number?</li>\n</ul>\n\n<p>Note that this scheme does not even try to reach an objective measure of "extremism". The only goal is stability.</p>\n\n<p>I would like to know, has this voting scheme has been studied in the past?</p>\n', 'ViewCount': '127', 'Title': 'voting scheme for peaceful coexistence', 'LastEditorUserId': '72', 'LastActivityDate': '2012-06-08T21:14:05.203', 'LastEditDate': '2012-06-07T16:33:57.103', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '2291', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><game-theory><voting>', 'CreationDate': '2012-06-07T09:11:00.850', 'Id': '2249'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was reading something about the concept of walks in a graph b/w a start vertex and a terminating vertex in a graph and then suddenly a problem struck me, is there any algorithm or a method that can be used to enumerate all the distinct walks from a start vertex to a terminal vertex in a graph, if so can you all point me to some relevant links to study this problem and what are some applications of solving this problem?</p>\n', 'ViewCount': '233', 'Title': 'Enumerating all the walks in a graph between a start vertex and a terminal vertex?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-09T03:44:41.467', 'LastEditDate': '2012-06-08T12:29:16.630', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'OwnerDisplayName': 'Coder', 'PostTypeId': '1', 'Tags': '<algorithms><reference-request><graph-theory>', 'CreationDate': '2012-06-05T13:10:08.960', 'FavoriteCount': '2', 'Id': '2274'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given a <a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar" rel="nofollow">parsing expression grammar</a> (PEG) grammar and the name of the start production, I would like to label each node with the set of characters that can follow it.  I would be happy with a good approximation that is conservative -- if a character can follow a node then it must appear in the follower set.</p>\n\n<p>The grammar is represented as a tree of named productions whose bodies contain nodes representing</p>\n\n<ol>\n<li>Character</li>\n<li>Concatenation</li>\n<li>Union</li>\n<li>Non-terminal references</li>\n</ol>\n\n<p>So given a grammar in ABNF style syntax:</p>\n\n<pre><code>A := B (\'a\' | \'b\');\nB := (\'c\' | \'d\') (B | ());\n</code></pre>\n\n<p>where adjacent nodes are concatenated, <code>|</code> indicates union, single quoted characters match the character they represent, and upper case names are non-terminals.</p>\n\n<p>If the grammar\'s start production is <code>A</code>, the annotated version might look like</p>\n\n<pre><code>A := \n  (\n    (B /* [ab] */)\n    (\n      (\'a\' /* eof */)\n    | \n      (\'b\' /* eof */)\n    /* eof */\n    )\n  /* eof */\n  );\n\nB :=\n  (\n    (\n      (\'c\' /* [abcd] */)\n      |\n      (\'d\' /* [abcd] */)\n    /* [abcd] */\n    )\n    (\n      (B /* [ab] */)\n      |\n      ( /* [ab] */)\n    /* [ab] */\n    )\n  );\n</code></pre>\n\n<p>I want this so that I can do some simplification on a PEG grammar.  Since order is important in unions in PEG grammars, I want to partition the members of unions based on which ones could accept the same character so that I can ignore order between partition elements.</p>\n\n<p>I\'m using OMeta\'s grow-the-seed scheme for handling direct left-recursion in PEG grammars, so I need something that handles that.  I expect that any scheme for handling scannerless CF grammars with order-independent unions that is conservative or correct would be conservative for my purposes.</p>\n\n<p>Pointers to algorithms or source code would be much appreciated.</p>\n', 'ViewCount': '87', 'Title': 'Computing follow sets conservatively for a PEG grammar', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-16T18:02:43.013', 'LastEditDate': '2012-06-09T18:04:51.030', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '2297', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1298', 'Tags': '<formal-languages><reference-request><formal-grammars><parsers>', 'CreationDate': '2012-06-08T21:42:44.733', 'Id': '2292'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '549', 'Title': 'Categorisation of type systems (strong/weak, dynamic/static)', 'LastEditDate': '2012-06-10T10:37:44.360', 'AnswerCount': '3', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '1808', 'FavoriteCount': '5', 'Body': '<p>In short: how are type systems categorised in academic contexts; particularly, where can I find reputable sources that make the distinctions between different sorts of type system clear?</p>\n\n<p>In a sense the difficulty with this question is not that I can\'t find an answer, but rather that I can find too many, and none stand out as correct. The background is I am attempting to improve an article on the Haskell wiki about <a href="http://www.haskell.org/haskellwiki/Typing">typing</a>, which currently claims the following distinctions:</p>\n\n<ul>\n<li>No typing: The language has no notion of types, or from a typed perspective: There is exactly one type in the language. Assembly language has only the type \'bit pattern\', Rexx and Tk have only the type \'text\', core MatLab has only the type \'complex-valued matrix\'.</li>\n<li>Weak typing: There are only few distinguished types and maybe type synonyms for several types. E.g. C uses integer numbers for booleans, integers, characters, bit sets and enumerations.</li>\n<li>Strong typing: Fine grained set of types like in Ada, Wirthian languages (Pascal, Modula-2), Eiffel</li>\n</ul>\n\n<p>This is entirely contrary to my personal perception, which was more along the lines of:</p>\n\n<ul>\n<li>Weak typing: Objects have types, but are implicitly converted to other types when the context demands it. For example, Perl, PHP and JavaScript are all languages in which <code>"1"</code> can be used in more or less any context that <code>1</code> can.</li>\n<li>Strong typing: Objects have types, and there are no implicit conversions (although overloading may be used to simulate them), so using an object in the wrong context is an error. In Python, indexing an array with a string or float throws a TypeError exception; in Haskell it will fail at compile time.</li>\n</ul>\n\n<p>I asked for opinions on this from other people more experienced in the field than I am, and one gave this characterisation:</p>\n\n<ul>\n<li>Weak typing: Performing invalid operations on data is not controlled or rejected, but merely produces invalid/arbitrary results.</li>\n<li>Strong typing: Operations on data are only permitted if the data is compatible with the operation.</li>\n</ul>\n\n<p>As I understand it, the first and last characterisations would call C weakly-typed, the second would call it strongly-typed. The first and second would call Perl and PHP weakly-typed, the third would call them strongly-typed. All three would describe Python as strongly-typed.</p>\n\n<p>I think most people would tell me "well, there is no consensus, there is no accepted meaning of the terms". If those people are wrong, I\'d be happy to hear about it, but if they are right, then how <em>do</em> CS researchers describe and compare type systems? What terminology can I use that is less problematic?</p>\n\n<p>As a related question, I feel the dynamic/static distinction is often given in terms of "compile time" and "run time", which I find unsatisfactory given that whether or not a language is compiled is not so much a property of that language as its implementations. I feel there should be a purely-semantic description of dynamic versus static typing; something along the lines of "a static language is one in which every subexpression can be typed". I would appreciate any thoughts, particularly references, that bring clarity to this notion.</p>\n', 'Tags': '<reference-request><programming-languages><type-theory>', 'LastEditorUserId': '1808', 'LastActivityDate': '2013-03-24T16:37:01.173', 'CommentCount': '6', 'AcceptedAnswerId': '2402', 'CreationDate': '2012-06-09T15:07:40.477', 'Id': '2301'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I look for information about grammars which can be described by a non-linear equation such as a quadratic equation:</p>\n\n<p>$\\qquad \\displaystyle G \\to G G a \\mid b$</p>\n\n<p>or</p>\n\n<p>$\\qquad \\displaystyle G \\to G G \\mid y G z \\mid z G y \\mid \\varepsilon$</p>\n\n<p>While there is lots of material about linear grammars, their connection with regular languages etc. "quadratic grammars" ( a term, which doesn\'t even seem to exist ) are only mentioned when an author presents some counterexamples for a parsing algorithm in order to show its limitations. </p>\n\n<p>Is there an autonomous treatment of grammars which can be described by general polynomial equations?</p>\n', 'ViewCount': '230', 'Title': 'Non-linear grammars', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-07T19:01:19.597', 'LastEditDate': '2012-06-10T10:55:35.600', 'AnswerCount': '1', 'CommentCount': '9', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1811', 'Tags': '<reference-request><formal-grammars>', 'CreationDate': '2012-06-09T21:52:20.670', 'Id': '2303'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>Turing machines have a <a href="https://en.wikipedia.org/wiki/Turing_machine#Formal_definition">formal</a> symbol alphabet, state and transition-rules based description of how a computation is done.   </p>\n\n<p><a href="https://en.wikipedia.org/wiki/Actor_model">The Actor Model</a> is sometimes mentioned as a more powerful computational-model than Turing machines (not in what it can compute, but in other aspects).  </p>\n\n<ol>\n<li>Is The Actor Model a full fledged Turning machine alternative as a computational model?  </li>\n<li>Does The Actor Model also have such a symbol-based formal computation description akin to the Turing machine?</li>\n<li>Are the actors assumed to be Turing machine equivalent - since each message is processed sequentially (and atomically)?</li>\n</ol>\n\n<p>There are many theoretical results based on Turing machines, e.g. the halting problem, decidability, relation to G\xf6del\'s incompleteness theorem etc.  </p>\n\n<p>Can these proofs be formally generalize to the Actor Model? Has this been done?</p>\n', 'ViewCount': '233', 'Title': 'Turing Machine-Like Formalism for The Actor Model', 'LastEditorUserId': '41', 'LastActivityDate': '2013-07-20T09:20:54.697', 'LastEditDate': '2013-07-20T09:20:54.697', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '1813', 'Tags': '<terminology><computability><reference-request><programming-languages><computation-models>', 'CreationDate': '2012-06-10T05:42:02.043', 'Id': '2311'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm looking for some standard terminology, metrics and/or applications of the consideration of density and sequentiality of algorithms.</p>\n\n<p>When we measure algorithms we tend to give the big-Oh notation such as $O(n)$ and usually we are measuring time complexity. Somewhat less frequently, though still often, we'll also measure the space complexity of an algorithm.</p>\n\n<p>Given current computing systems however the density of memory and the sequence in which it is accessed plays a major role in the practical performance of the algorithm. Indeed there are scenarios where a time complexity algortihm of $O(\\log n)$ with disperse random memory access can be slower than a $O(n)$ algorithm with dense sequential memory access. I've not seen these aspects covered in formal theory before; surely it must exist and I'm just ignorant here.</p>\n\n<p>What are the standard metrics, terms, and approaches to this space density and access sequentiality?</p>\n", 'ViewCount': '82', 'Title': 'Complexity of space density and sequentiality', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-10T11:44:37.957', 'LastEditDate': '2012-06-10T11:33:14.040', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '2318', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1642', 'Tags': '<complexity-theory><reference-request><terminology><space-complexity>', 'CreationDate': '2012-06-10T09:29:46.877', 'Id': '2317'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The <a href="http://en.wikipedia.org/wiki/Expression_problem" rel="nofollow">Expression Problem</a>, populated by Philip Wadler,  is a often used to standard problem to evaluate programming languages.</p>\n\n<p>I think it is a very clear and popular example and I wonder if there are any similar standard problems that are possibly also as widely used and as clear.</p>\n\n<p>So, are there any similar standard problems?</p>\n\n<p>(In the case of Feature Oriented Programming (<a href="http://en.wikipedia.org/wiki/Feature_Oriented_Programming" rel="nofollow">link</a> <a href="http://en.wikipedia.org/wiki/FOSD_Program_Cubes#Applications" rel="nofollow">link</a>) I found some standard problems, like:\n- implementation of a stack with different features\n- implementation of linked lists\n- implementation of a calculator\n- the graph product line\n- stock broker and bank account examples\n- hierarchical display\n)</p>\n', 'ViewCount': '84', 'Title': u'Expression Problem \u2013 looking for a similar standard problem', 'LastActivityDate': '2012-06-11T20:57:37.057', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><programming-languages><software-engineering>', 'CreationDate': '2012-06-11T15:36:59.607', 'Id': '2332'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I want to determine which parts of an audio file contain speech respectively music.</p>\n\n<p>I hope someone has a made something like this or can tell me where to start. Can you please suggest some method or tutorial for doing the same?</p>\n', 'ViewCount': '107', 'Title': 'Speech vs Music classification', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-04T05:27:55.623', 'LastEditDate': '2012-06-12T22:14:41.623', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '2', 'OwnerDisplayName': 'Praveen', 'PostTypeId': '1', 'Tags': '<reference-request><pattern-recognition>', 'CreationDate': '2012-06-07T06:40:44.960', 'Id': '2351'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '310', 'Title': 'Online Learning Resources for Discrete Mathematics', 'LastEditDate': '2012-06-18T12:18:35.623', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1887', 'FavoriteCount': '1', 'Body': '<p>Are there any good Discrete mathematics learning web resources with problem sets?</p>\n', 'Tags': '<reference-request><education><discrete-mathematics>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-20T09:34:25.303', 'CommentCount': '1', 'AcceptedAnswerId': '2421', 'CreationDate': '2012-06-18T10:25:37.707', 'Id': '2404'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'ve finished most of the material in Cormen\'s Intro to Algorithms book and I am looking for an algorithms book that covers material beyond Corman\'s book. Are there any recommendations?</p>\n\n<p>NOTE: I asked this on stackoverflow but wasn\'t all too happy with the answer. </p>\n\n<p>NOTE: Looking at most of the comments I think ideally I would like to find a book that would cover the material of the the 787 course in <a href="http://www.cs.wisc.edu/academic-programs/courses/cs-course-descriptions">this course description</a>.</p>\n', 'ViewCount': '918', 'Title': 'Book for algorithms beyond Cormen', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-27T12:45:45.290', 'LastEditDate': '2012-06-27T12:45:45.290', 'AnswerCount': '3', 'CommentCount': '6', 'AcceptedAnswerId': '2505', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1790', 'Tags': '<algorithms><reference-request><books>', 'CreationDate': '2012-06-26T02:30:47.140', 'Id': '2495'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '139', 'Title': 'Find string that minimizes the sum of the edit distances to all other strings in set', 'LastEditDate': '2012-06-30T10:54:21.683', 'AnswerCount': '1', 'Score': '5', 'OwnerDisplayName': 'jmvidal', 'PostTypeId': '1', 'OwnerUserId': '2015', 'FavoriteCount': '1', 'Body': '<p>I have a set of strings $S$ and I am using the edit-distance (<a href="http://en.wikipedia.org/wiki/Levenshtein_distance" rel="nofollow">Levenshtein</a>) to measure the distance between all pairs.</p>\n\n<p>Is there an algorithm for finding the string $x$ which minimizes the sum of the distances to all strings in $S$, that is</p>\n\n<p>$\\arg_x \\min \\sum_{s \\in S} \\text{edit-distance}(x,s)$</p>\n\n<p>It seems like there should, but I can\'t find the right reference.</p>\n', 'Tags': '<algorithms><reference-request><strings><string-metrics>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-30T10:54:21.683', 'CommentCount': '0', 'AcceptedAnswerId': '2551', 'CreationDate': '2012-06-29T15:25:33.753', 'Id': '2546'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am having trouble finding good resources that give a worst case $O(n \\ln n)$ <a href="http://en.wikipedia.org/wiki/In-place_algorithm">in place</a> <a href="http://www.algorithmist.com/index.php/Stable_Sort">stable</a> sorting algorithm.  Does anyone know of any good resources?</p>\n\n<p>Just a reminder, in place means it uses the array passed in and the sorting algorithm is only allowed to use constant extra space.  Stable means that elements with the same key appear in the same order in the sorted array as they did in the original.</p>\n\n<p>For example, naive merge sort is worst case $O(n \\ln n)$ and stable but uses $O(n)$ extra space.  Standard quicksort can be made stable, is in place but is worst case $O(n^2)$.  Heapsort is in place, worst case $O(n \\ln n)$ but isn\'t stable.  <a href="http://en.wikipedia.org/wiki/Sorting_algorithm">Wikipedia</a> has a nice chart of which sorting algorithms have which drawbacks.  Notice that there is no sorting algorithm that they list that has all three conditions of stability, worst case $O(n \\ln n)$ and being in place.</p>\n\n<p>I have found a paper called <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.22.8523&amp;rep=rep1&amp;type=pdf">"Practical in-place mergesort"</a> by Katajainen, Pasanen and Teuhola, which claims to have a worst case $O(n \\ln n)$ in place stable mergesort variant.  If I understand their results correctly, they use (bottom-up?) mergesort recursively on the first $\\frac{1}{4}$ of the array and the latter $\\frac{1}{2}$ of the array and use the second $\\frac{1}{4}$ as scratch space to do the merge.  I\'m still reading through this so any more information on whether I\'m interpreting their results correctly is appreciated.</p>\n\n<p>I would also be very interested in a worst case $O(n \\ln n)$ in place stable quicksort.  From what I understand, modifying quicksort to be worst case $O(n \\ln n)$ requires <a href="http://en.wikipedia.org/wiki/Selection_algorithm#Linear_general_selection_algorithm_-_Median_of_Medians_algorithm">selecting a proper pivot</a> which would destroy the stability that it would otherwise normally enjoy.</p>\n\n<p>This is purely of theoretical interest and I have no practical application.  I would just like to know the algorithm that has all three of these features.</p>\n', 'ViewCount': '1193', 'Title': 'Worst case $O(n \\ln n)$ in place stable sort?', 'LastActivityDate': '2013-10-27T16:22:39.590', 'AnswerCount': '3', 'CommentCount': '5', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '67', 'Tags': '<algorithms><reference-request><sorting>', 'CreationDate': '2012-07-01T14:50:37.140', 'FavoriteCount': '2', 'Id': '2569'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Sometimes it is necessary to dig into Artificial Intelligence or specifically Machine Learning problems to make a research. Common googling (in my own experience) usually doesn't help much due to a lot of irrelevant or paid material among the results. Google Scholar in contrast is limited to scientific publications only, sometimes it is too narrow.</p>\n\n<p>I wonder if there is a kind of dedicated search engine over AI- and ML-related sites?</p>\n", 'ViewCount': '252', 'Title': 'Is there a search engine over Artificial Intelligence and Machine Learning -related sites?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-25T14:23:32.677', 'LastEditDate': '2012-07-05T07:14:50.053', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2068', 'Tags': '<reference-request><machine-learning><artificial-intelligence>', 'CreationDate': '2012-07-04T14:53:42.673', 'FavoriteCount': '2', 'Id': '2612'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm searching papers about the history and evolution of 2D geometry manipulation and engines, but I can't find what I'm looking for. Can someone help me with some recommended papers or recommended keywords? I'm looking for different approaches on the manipulation of 2D objects like rectangles, triangles, ellipses. </p>\n", 'ViewCount': '76', 'Title': '2D Geometry manipulation papers/search keywords', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-09T08:54:35.237', 'LastEditDate': '2012-07-09T08:54:35.237', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'OwnerDisplayName': 'canha', 'PostTypeId': '1', 'OwnerUserId': '2182', 'Tags': '<reference-request><computational-geometry>', 'CreationDate': '2012-07-06T22:16:15.143', 'Id': '2640'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I\'ve been reading a bit of the literature lately, and have found some rather interesting data-structures.</p>\n\n<p>I have researched various different methods of getting update times down to $\\mathcal{O}(1)$ worst-case update time [1-7].</p>\n\n<p>Recently I begun looking into lock-free data-structures, to support efficient concurrent access.</p>\n\n<p><strong>Have any of these worst-case $\\mathcal{O}(1)$ update-time techniques been used in the implementation of lock-free data structures?</strong></p>\n\n<p>I ask because; to me, they seem like the obvious practical extension of this "theoretical enhancement".</p>\n\n<hr>\n\n<ol>\n<li><p><a href="http://www.sciencedirect.com/science/article/pii/0020019083900996">Tarjan, Robert Endre. \u201cUpdating a Balanced Search Tree in O(1) Rotations.\u201d Information Processing Letters 16, no. 5 (1983): 253 \u2013 257.</a></p></li>\n<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.4630">Driscoll, J R, N Sarnak, D D Sleator, and R E Tarjan. \u201cMaking Data Structures Persistent.\u201d In Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, 109\u2013121. STOC  \u201986. New York, NY, USA: ACM, 1986.</a></p></li>\n<li><p><a href="http://dx.doi.org/10.1007/BF00299635">Levcopoulos, C., and Mark H. Overmars. \u201cA Balanced Search Tree with O(1) Worst Case Update Time.\u201d Acta Inf. 26, no. 3 (November 1988): 269\u2013277.</a></p></li>\n<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.9433">Fleischer, Rudolf. A Simple Balanced Search Tree With O(1) Worst-Case Update Time</a></p></li>\n<li><p><a href="http://dx.doi.org/10.1016/0020-0190%2894%2900115-4">Dietz, Paul F, and Rajeev Raman. \u201cA Constant Update Time Finger Search Tree.\u201d Information Processing Letters 52, no. 3 (1994): 147 \u2013 154.</a></p></li>\n<li><p><a href="http://dl.acm.org/citation.cfm?id=998223.998229">Lagogiannis, George, Christos Makris, Yannis Panagis, Spyros Sioutas, and Kostas Tsichlas. \u201cNew Dynamic Balanced Search Trees with Worst-case Constant Update Time.\u201d J. Autom. Lang. Comb. 8, no. 4 (July 2003): 607\u2013632.</a></p></li>\n<li><p><a href="http://www.cs.au.dk/~gerth/papers/stoc02.pdf">Brodal, Gerth St\xf8lting, George Lagogiannis, Christos Makris, Athanasios Tsakalidis, and Kostas Tsichlas. \u201cOptimal Finger Search Trees in the Pointer Machine.\u201d J. Comput. Syst. Sci. 67, no. 2 (September 2003): 381\u2013418.</a></p></li>\n</ol>\n', 'ViewCount': '506', 'Title': 'Lock-free, constant update-time concurrent tree data-structures?', 'LastEditorUserId': '1120', 'LastActivityDate': '2013-05-14T16:27:44.497', 'LastEditDate': '2012-07-18T05:21:06.267', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '1120', 'Tags': '<reference-request><data-structures><time-complexity><concurrency><search-trees>', 'CreationDate': '2012-07-10T20:04:39.177', 'FavoriteCount': '5', 'Id': '2680'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The only paper I can find about an implementation of a lossless video codec is an <a href="http://www.ffmpeg.org/~michael/ffv1.html" rel="nofollow">article by Michael Niedermayer</a> which explains the FF1V compression pipeline.</p>\n\n<p>I\'m wondering if anyone else has found any articles similar to this. I\'ve looked on IEEE and ACM and their articles mostly focus on one algorithm that\'s part of a compression pipeline.</p>\n', 'ViewCount': '45', 'Title': 'Lossless Video Compression Pipeline', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-18T01:38:44.553', 'LastEditDate': '2012-07-18T01:38:44.553', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2171', 'Tags': '<reference-request><data-compression><video>', 'CreationDate': '2012-07-15T19:38:34.497', 'Id': '2754'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am interested in exploring the world of <a href="http://en.wikipedia.org/wiki/BDI_software_agent" rel="nofollow">BDI agents</a> (software agents that possess "beliefs, desires, intentions", essentially the agent has knowledge of the world, a set of motivations, and carries out certain plans).</p>\n\n<p>I recently read A Canonical Agent Model for Healthcare Applications [1], which left me with a lot of questions, particularly about the specialization of different agent models for particular applications.  </p>\n\n<p>The particular modeling language used in their examples was ProForma, and I understand that this is more for the abstract specification of an agent, and that something like <a href="http://en.wikipedia.org/wiki/3APL" rel="nofollow">3APL</a> can be used as an actual programming language in this regard, with syntax like:</p>\n\n<pre><code>BELIEFBASE {\n    status(standby).\n    at(0,0).\n    location(r1,2,4).\n    location(r5,6,1).\n    dirty(r1).\n    dirty(r5).\n}\n</code></pre>\n\n<p>My question is, all of these systems clearly reflect years of cumulative efforts, and rather than jumping in to the deep end, I\'d like to ease into this world of research a bit more slowly.  Is there a canonical reference in this area that might be able to provide a more general overview of all of these levels of organization, and where the abstractions stop and the implementations begin?</p>\n\n<hr>\n\n<ol>\n<li>Fox J., Glasspool, D., Modgil, S. <a href="http://www.sdela.dds.nl/entityresearch/fox_glasspool_modgil.pdf" rel="nofollow">A Canonical Agent Model for Healthcare Applications</a>. <em>IEEE Intelligent Systems, 21</em>(6), 21-28, 2006.</li>\n</ol>\n', 'ViewCount': '60', 'Title': 'Canonical reference on agent-based computing', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-18T10:02:23.730', 'LastEditDate': '2012-07-18T10:02:23.730', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2776', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '88', 'Tags': '<reference-request><human-computing><agent-based-computing>', 'CreationDate': '2012-07-16T13:59:10.390', 'Id': '2764'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '106', 'Title': 'Determining how similar a given string is to a collection of strings', 'LastEditDate': '2012-07-22T09:43:50.247', 'AnswerCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '2185', 'FavoriteCount': '2', 'Body': '<p>I\'m not sure if this question belongs here and I apologize if not.  What I am looking to do is to develop a programmatic way in which I can probabilistically determine whether a given string "belongs" in a bag of strings.  For example, if I have bag of 10,000 US city names, and then I have the string "Philadelphia", I would like some quantitative measure of how likely \'Philadelphia\' is a US city name based on the US city names I already know.  While I know I won\'t be able to separate real city names from fake city names in this context, I would at least expect to have strings such as "123.75" and "The quick red fox jumped over the lazy brown dogs" excluded given some threshold.</p>\n\n<p>To get started, I\'ve looked at Levenshtein Distance and poked around a bit on how that\'s been applied to problems at least somewhat similar to the one I\'m trying to solve.  One interesting application I found was plagiarism detection, with one paper describing how Levenshtein distance was used with a modified Smith-Waterman algorithm to score papers based on how likely they were a plagarized version of a given base paper.  My question is if anyone could point me in the right direction with other established algorithms or methodologies that might help me.  I get the feeling that this may be a problem someone in the past has tried to solve but so far my Google-fu has failed me.</p>\n', 'Tags': '<algorithms><reference-request><string-metrics>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-22T09:43:50.247', 'CommentCount': '3', 'AcceptedAnswerId': '2780', 'CreationDate': '2012-07-16T21:29:07.047', 'Id': '2777'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '40', 'Title': 'Where can I find the data of the computer experiments in the book "Neural Networks and Learning Machines"?', 'LastEditDate': '2012-07-20T05:14:49.323', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '848', 'FavoriteCount': '1', 'Body': '<p>The book <a href="http://rads.stackoverflow.com/amzn/click/0131471392" rel="nofollow">"Neural Networks and Learning Machines"</a> by Simon Haykin has many computer experiments to which many exercises are related. But there seems to be no data for these experiments available online. Where can I find them?</p>\n', 'Tags': '<reference-request><data-sets>', 'LastEditorUserId': '88', 'LastActivityDate': '2012-07-20T05:14:49.323', 'CommentCount': '2', 'AcceptedAnswerId': '2831', 'CreationDate': '2012-07-17T14:00:26.707', 'Id': '2785'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>According to <a href="http://en.wikipedia.org/wiki/LR_parser#LR_and_Other_Kinds_of_Parsers">the Wikipedia article</a>, the L in $LR(k)$ means "left-to-right scan", and the "R" means "rightmost derivation."  However, in <a href="http://classes.engr.oregonstate.edu/eecs/winter2012/cs480/assignments/Knuth-1965-TranslationofLanguages.pdf">Knuth\'s original paper on $LR(k)$ grammars</a>, he defines $LR(k)$ (on page 610) as a language that is "translatable from left to right with bound $k$."</p>\n\n<p>I am guessing that this new terminology was chosen to complement $LL(k)$ parsing\'s "left-to-right scan, leftmost derivation."  That said, I don\'t know when the terminology changed meaning.</p>\n\n<p>Does anyone know where the newer acronym for $LR(k)$ comes from?</p>\n', 'ViewCount': '115', 'Title': 'When did $LR(k)$ acquire the meaning "left-to-right scan, rightmost derivation?"', 'LastEditorUserId': '41', 'LastActivityDate': '2012-07-17T22:09:46.040', 'LastEditDate': '2012-07-17T22:09:46.040', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2131', 'Tags': '<formal-languages><reference-request><terminology><formal-grammars><parsers>', 'CreationDate': '2012-07-17T19:10:32.620', 'FavoriteCount': '1', 'Id': '2791'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '464', 'Title': 'Standard or Top Text on Applied Graph Theory', 'LastEditDate': '2012-07-23T07:12:08.633', 'AnswerCount': '5', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1022', 'FavoriteCount': '3', 'Body': '<p>I am looking for a reference text on applied graph theory and graph algorithms.  Is there a standard text used in most computer science programs?  If not, what are the most respected texts in the field? I have Cormen et al.</p>\n', 'Tags': '<algorithms><graph-theory><reference-request><education><books>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-27T05:17:04.987', 'CommentCount': '6', 'AcceptedAnswerId': '2911', 'CreationDate': '2012-07-20T20:50:07.910', 'Id': '2845'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Let $f$ be a fixed time-constructable function.</p>\n\n<p>The classical universal simulation result for TMs (Hennie and Stearns, 1966) states that there is a two-tape TM $U$ such that given</p>\n\n<ul>\n<li>the description of a TM $\\langle M \\rangle$, and</li>\n<li>an input string $x$,</li>\n</ul>\n\n<p>runs for $g(|x|)$ steps and returns $M$'s answer on $x$. And $g$ can be taken to be any function in $\\omega(f(n)\\lg f(n))$.</p>\n\n<p>My questions are:</p>\n\n<blockquote>\n  <ol>\n  <li><p>What is the best known simulation result on a single tape TM? Does the result above also still hold?</p></li>\n  <li><p>Is there any improvement on [HS66]? Can we simulate TMs on a two-tape TM for $f(n)$ steps in a faster way? \n  Can we take $g(n)$ to be in $\\omega(f(n))$ in place of $\\omega(f(n)\\lg f(n))$?</p></li>\n  </ol>\n</blockquote>\n", 'ViewCount': '278', 'Title': 'Universal simulation of Turing machines', 'LastEditorUserId': '41', 'LastActivityDate': '2012-08-16T13:15:01.727', 'LastEditDate': '2012-08-16T11:33:15.097', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '3220', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<complexity-theory><reference-request><turing-machines><machine-models><simulation>', 'CreationDate': '2012-07-23T15:49:05.823', 'Id': '2878'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://www.scholarpedia.org/article/Kolmogorov-Sinai_entropy" rel="nofollow">Kolmogorov-Sinai entropy</a> (KS) explains the mathematical concept behind KS entropy. </p>\n\n<p>$$h ( T ) =\\sup\\limits_{\\xi} \\, h ( T , \\xi )$$</p>\n\n<p>defines the formula for KS where the left-hand side is nothing but the Shannon\'s entropy. In many papers I have seen that KS is defined as the supremum over source entropy. These conflicting views raises the following questions</p>\n\n<ol>\n<li>What is the difference between Shannon\'s entropy and source entropy (source entropy given by $\\lim \\frac{1}{n}\\cdot h(T)$ where $n$ is the length of the word or sequence,unsure though). </li>\n<li><p>Would source entropy be the entropy of the raw signal before it has been quantized or should it be that of the quantized?</p></li>\n<li><p>Is \'n\' the length of the data series or the number of quantization levels></p></li>\n<li><a href="http://mathworld.wolfram.com/TopologicalEntropy.html" rel="nofollow">Topological entropy</a> (TS) explains topological entropy whose formula looks exactly as KS. So, what is the difference since KS is also known as metric entropy and not known as Topological entropy?</li>\n</ol>\n', 'ViewCount': '174', 'Title': 'Source entropy and other questions related to information theory', 'LastEditorUserId': '157', 'LastActivityDate': '2012-10-23T15:06:28.490', 'LastEditDate': '2012-10-23T02:38:01.893', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<reference-request><information-theory><entropy>', 'CreationDate': '2012-07-25T00:41:25.497', 'Id': '2902'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am teaching myself program verification and am currently learning <a href="http://en.wikipedia.org/wiki/Proof_assistant" rel="nofollow">proof assistants</a>. I have the book <a href="http://www.cambridge.org/gb/knowledge/isbn/item2327697/?site_locale=en_GB" rel="nofollow">Handbook of Practical Logic and Automated Reasoning</a> which gives the proofs necessary for the understanding of such a system, but more importantly for me it also gives an implementation of the necessary algorithms as <a href="http://www.cl.cam.ac.uk/~jrh13/atp/index.html" rel="nofollow">OCAML source</a>.</p>\n\n<p>I know that some of the tools listed in <a href="http://en.wikipedia.org/wiki/List_of_model_checking_tools" rel="nofollow">Wikipedia: Model Checking tools</a> and <a href="http://anna.fi.muni.cz/yahoda/" rel="nofollow">YAHODA: Verifications Tools Database</a> are open source, but I also prefer it when the theory, proofs, algorithms and source code are presented at the same time reinforcing each other, and in a progression building up to a final application.</p>\n\n<p>Is there such a book for model checking?</p>\n\n<p>EDIT </p>\n\n<p>I may have found what I am looking for in <a href="http://www.springer.com/computer/theoretical+computer+science/book/978-1-4471-4128-0" rel="nofollow">Mathematical Logic for Computer Science</a> with <a href="http://code.google.com/p/mlcs/" rel="nofollow">Prolog source</a>. As I don\'t have the book, does anyone know if this book fits the requirement?</p>\n', 'ViewCount': '76', 'Title': 'Looking for a book that derives and constructs a model checking application', 'LastEditorUserId': '268', 'LastActivityDate': '2012-07-29T02:07:34.563', 'LastEditDate': '2012-07-28T21:16:21.650', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2931', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '268', 'Tags': '<reference-request><formal-methods><proof-assistants><model-checking>', 'CreationDate': '2012-07-27T13:10:10.487', 'Id': '2923'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I know that given two problems are undecidable it does not follow that their intersection must be undecidable. For example, take a property of languages $P$ such that it is undecidable whether the language accepted by a given pushdown automaton $M$ has that property. Clearly $P$ and $\\lnot P$ are undecidable (for a given $M$) but $P \\cap \\lnot P$ is trivially decidable (it is always false).</p>\n\n<p>I wonder if there are any "real life" examples which do not make use of the "trick" above? When I say "real life" I do not necessarily mean problems which people come across in their day to day life, I mean examples where we do not take a problem and it\'s complement. It would be interesting (to me) if there are examples where the intersection is not trivially decidable.</p>\n', 'ViewCount': '485', 'Title': 'Examples of undecidable problems whose intersection is decidable', 'LastEditorUserId': '769', 'LastActivityDate': '2012-08-02T11:57:36.140', 'LastEditDate': '2012-08-02T09:20:43.607', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '3002', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '769', 'Tags': '<reference-request><undecidability><decision-problem>', 'CreationDate': '2012-08-01T13:04:25.613', 'Id': '2982'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>We\'re running some benchmarks for an approximative query-answering system. It\'s sufficient to just think of it as running some SQL queries with joins. We are counting the results returned as part of the benchmark. However, the results often contain a lot of redundancy, so just counting results seems coarse.</p>\n\n<p>Consider the following table containing results for a query like "<em>for the US, give me its states and its car manufacturers</em>":</p>\n\n<pre><code>================================\n|| ?us_state | ?us_car_manu   ||\n||============================||\n|| Alabama   | Chrysler       ||\n|| Alaska    | Chrysler       ||\n|| ...         ...            ||\n|| Wyoming   | Chrysler       ||\n|| Alabama   | General Motors ||\n|| Alaska    | General Motors ||\n|| ...         ...            ||\n|| Wyoming   | General Motors ||\n|| Alabama   | Ford           ||\n|| Alaska    | Ford           ||\n|| ...         ...            ||\n|| Wyoming   | Ford           ||\n===============================\n</code></pre>\n\n<p>All 200 (50 \xd7 4) results are of course unique. However, given that there is an inherent Cartesian product, the number of results flatters the amount of "information content" or "entropy" of the table: every additional car manufacturer adds fifty results for the fifty US states. (Again, this is just an example; I\'m not interested in better ways to represent or run this particular query.)</p>\n\n<p>As such, we\'re looking for a metric that will give an indication as to the (loosely speaking) redundancy-free content in the table for better comparison of <em>content</em> across different results for different queries. Other result tables may contain a mix of different types of Cartesian products (e.g., consider generalising the query to any country, where each country itself has its own product of states and car manufacturers, etc.).</p>\n\n<p>Currently we\'re working off a simple metric which just counts unique term\u2013position combinations: for the above example, the metric gives 50 + 4 = 54. This may be sufficient for comparison, but is not sensitive to the combination of terms for individual results.</p>\n\n<p>Thanks to Wikipedia, I\'m aware of\u2014but not familiar with\u2014the notion of <a href="http://en.wikipedia.org/wiki/Entropy_%28information_theory%29" rel="nofollow">entropy in information theory</a>. However, I\'m unclear on how the concept of entropy could be applied to this use-case. (I\'m not interested in the entropy of the result strings; each term can be considered a "symbol".) Roughly speaking, each query variable could be considered as a free variable with the result terms in that column providing a set of possible outcomes and their frequency of occurrence being used as a probability mass function. This way I could compute the Shannon entropy for each column. But thereafter, I don\'t know how columns can be combined, or how tuples or results can be considered ... if a notion of conditional entropy would be better, etc.</p>\n\n<p>And so ...</p>\n\n<blockquote>\n  <p>Does anyone have pointers to related material on the measure of entropy/redundancy/etc. in tables or similar structures? </p>\n  \n  <p>Otherwise, does anyone have any ideas on how to use Shannon entropy in a convincing way for tabular data?</p>\n</blockquote>\n', 'ViewCount': '227', 'Title': 'Measuring entropy for a table (e.g., SQL results)', 'LastEditorUserId': '157', 'LastActivityDate': '2012-10-23T02:38:23.283', 'LastEditDate': '2012-10-23T02:38:23.283', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2357', 'Tags': '<reference-request><information-theory><data-compression><database-theory><entropy>', 'CreationDate': '2012-08-03T20:36:20.237', 'FavoriteCount': '1', 'Id': '3029'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '311', 'Title': 'Is there a repository for the hierarchy of proofs?', 'LastEditDate': '2012-08-13T05:42:14.743', 'AnswerCount': '4', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '268', 'FavoriteCount': '4', 'Body': '<p>I am self-learning <a href="http://en.wikipedia.org/wiki/Proof_assistant">proof assistants</a> and decided to start on some basic proofs and work my way up. Since proofs are based on other proofs and so form a hierarchy, is there a repository of the hierarchy of proofs?</p>\n\n<p>I know I can pick a particular proof-assistant and analyze its library to extract its hierarchy, however if I want to find the next proof in a chain to prove, I can\'t when it is not in the library.</p>\n\n<p>In my mind I picture a graph, probably a <a href="http://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>, of all of the known mathematical proofs that can be expressed using English statements, not <a href="http://www.billthelizard.com/2009/07/six-visual-proofs_25.html">proofs using pictures</a>. This would be the master map (a map in the sense of starting at one point and traveling to another point via intermediate points), and for a particular proof assistant, one would have a subgraph of the master map. Then if one wanted to create a proof using a proof assistant found on the master not on the subgraph, by comparing the two graphs one could get an idea of the work needed to create the missing proof(s) for the proof assistant. </p>\n\n<p>I am aware that mathematical proofs are not necessarily easily convertable for use with a proof assistant, however having a general idea of what to do is much better than none at all.</p>\n\n<p>Also by having the master map, I can see if there are mulitple paths from one point to antoher and choose a path that is more amenable for the particualr proof assistant.</p>\n\n<p>EDIT</p>\n\n<p>In searching I found something similar for <a href="http://dlmf.nist.gov/">mathematical functions</a>. I did not find one for proofs at the <a href="http://www.nist.gov/index.html">NIST</a></p>\n', 'Tags': '<reference-request><logic><proof-assistants>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-09-10T13:35:25.587', 'CommentCount': '4', 'AcceptedAnswerId': '3490', 'CreationDate': '2012-08-08T00:13:21.220', 'Id': '3086'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '205', 'Title': 'Introduction into first order logic verification', 'LastEditDate': '2012-08-13T05:27:52.237', 'AnswerCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2436', 'FavoriteCount': '1', 'Body': '<p>I am trying to teach myself different approaches to software verification. I have read some articles. As far as I learned, propositional logic with temporal generally uses model checking with SAT solvers (in ongoing - reactive systems), but what about first order Logic with temporal? Does it use theorem provers? Or can it also use SAT?</p>\n\n<p>Any pointers to books or articles for beginners in this matter is much appreciated.</p>\n', 'Tags': '<reference-request><logic><formal-methods><sat-solvers><software-verification>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-08-13T05:27:52.237', 'CommentCount': '2', 'AcceptedAnswerId': '3114', 'CreationDate': '2012-08-09T20:52:33.677', 'Id': '3110'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What I mean by a "symbolic regular expression" (if there already is a different name for this I\'m not aware of it) is a regular expression that may include exponents that are symbolic arithmetic expressions.  </p>\n\n<p>Example 1: $a^k|b^*$ means "either $k$ copies of $a$ or zero or more copies of $b$".<br>\nExample 2: $a^{k+1}|a^k$ means "either $k$ or $k+1$ copies of $a$".</p>\n\n<p>What I\'d like to do is disambiguate such regular expressions.  I know that to disambiguate a normal regular expression, you can convert it to an NFA, then a DFA, then back to a regular expression.</p>\n\n<p>The problem is not completely straightforward.  For example, $a^k|a^j$ is ambiguous if $j=k$ and unambiguous otherwise.  Thus, the appropriate output would be, for example,\n$$a^k \\text{ if } k=j, \\qquad a^k|a^j \\text{ otherwise.}$$</p>\n\n<p>Does anyone know if there has been anything written about this problem?</p>\n', 'ViewCount': '135', 'Title': 'How to disambiguate symbolic regular expressions', 'LastActivityDate': '2012-08-09T22:51:51.757', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2242', 'Tags': '<formal-languages><reference-request><regular-languages><regular-expressions><ambiguity>', 'CreationDate': '2012-08-09T22:51:51.757', 'Id': '3112'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I am looking for references and papers on the following topic.</p>\n\n<ol>\n<li><p>In <em>general</em>, some programming languages allow dynamic changes to classes. As an example, a new instance variable \u2018weight\u2019 can be added to the class <code>Edge</code> (the class of unweighted edges of graphs). But what should happen with existing edge objects?</p>\n\n<p>They can be upgraded to include the new instance variable with a default value, perhaps weight <code>0</code>, in the edge example. Or existing objects stay the same.</p></li>\n<li><p>In <em>context-oriented</em> programming, similar situations can arise, when a context is dynamically activated at run-time. This may affect changes to methods which are currently executed (although I am concerned at the single thread execution at the moment).</p></li>\n<li><p>Considering <em>design patterns</em>, when a proxy object wraps another object, references to the old object may expect certain invariants that the proxy object doesn\u2019t adhere to. This may also lead to inconsistencies when an object is wrapped/\u2019updated\u2019 with a proxy object.</p></li>\n</ol>\n\n<p>Are there any references that list possible ways to treat the problem in case of dynamic changes/activation? Like the options to keep the state consistent?</p>\n\n<p>I looked primarily in the communities of dynamic software evolution, context-oriented programming and software components. Are there other important communities I can search to find references?</p>\n', 'ViewCount': '35', 'Title': 'Dynamic changes to classes or context activation -- how to treat existing objects in a consistent way?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-14T01:18:12.753', 'LastEditDate': '2012-08-13T23:35:19.433', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3165', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><programming-languages><semantics><object-oriented>', 'CreationDate': '2012-08-13T22:06:34.507', 'Id': '3156'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for answers which provide short overview of models and current state of research for <a href="http://en.wikipedia.org/wiki/Automatic_parallelization" rel="nofollow">auto-parallelisation</a> of sequential code.</p>\n', 'ViewCount': '105', 'Title': 'What are current approaches to auto-parallelisation?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-18T05:21:42.593', 'LastEditDate': '2012-08-14T12:08:43.540', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '191', 'Tags': '<reference-request><compilers><parallel-computing><code-generation>', 'CreationDate': '2012-08-14T05:31:42.663', 'FavoriteCount': '2', 'Id': '3168'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>A classic application of divide and conquer is to solve the following problem:</p>\n\n<p><em>Given an array $a[1\\dots n]$ of distinct, comparable elements, count the number of inversion pairs in the array: pairs $(i,j)$ such that $a[i] \\gt a[j]$ and $i \\lt j$.</em></p>\n\n<p>One approach to this is to do a Merge Sort, but also counting of the number of inversion pairs in the sub-problems. During the merge step, we count the number of inversion pairs that span across the (two) sub-problems and add to the counts of the sub-problems.</p>\n\n<p>While this is good, and gives an $O(n\\log n)$ time algorithm, this messes up array.</p>\n\n<p>If we have the additional constraint that the array is read-only, then we can make a copy and deal with the copy, or use an additional data-structure like an order statistics balanced binary tree to do the counting, both of which use $\\Theta(n)$ space.</p>\n\n<p>The current question is to try and better the space, while not affecting the run time. i.e.</p>\n\n<blockquote>\n  <p>Is there an $O(n\\log n)$ time algorithm to count the number of\n  inversion pairs, which works on a read-only array and uses sub-linear\n  (i.e. $o(n)$) space?</p>\n</blockquote>\n\n<p>Assume a uniform cost RAM model and that the elements take $O(1)$ space and comparison between them is $O(1)$.</p>\n\n<p>A reference will do, but an explanation will be better :-)</p>\n\n<p>I tried searching the web, but could not find any positive/negative answer for this. I suppose this is just a curiosity.</p>\n', 'ViewCount': '946', 'Title': 'Counting inversion pairs', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-04T17:41:34.980', 'LastEditDate': '2012-08-15T20:07:04.477', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '139', 'Tags': '<algorithms><reference-request><arrays>', 'CreationDate': '2012-08-15T17:52:59.523', 'FavoriteCount': '3', 'Id': '3200'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '233', 'Title': 'Good text on algorithm complexity', 'LastEditDate': '2012-08-16T15:01:05.350', 'AnswerCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2530', 'FavoriteCount': '1', 'Body': '<p>Where should I look for a good introductory text in algorithm complexity? So far, I have had an Algorithms class, and several language classes, but nothing with a theoretical backbone. I get the whole complexity, but sometimes it\'s hard for me to differentiate between O(1) and O(n) plus there\'s the whole theta notation and all that, basic explanation of P=NP and simple algorithms, tractability. I want a text that covers all that, and that doesn\'t require a heavy mathematical background, or something that can be read through.</p>\n\n<p>LE: I\'m still in highschool, not in University, and by heavy mathematical background I mean something perhaps not very high above Calculus and Linear Algebra (it\'s not that I can\'t understand it, it\'s the fact that for example learning Taylor series without having done Calculus I is a bit of a stretch; that\'s what I meant by not mathematically heavy. Something in which the math, with a normal amount of effort can be understood). And, do pardon if I\'m wrong, but theoretically speaking, a class at which they teach algorithm design methods and actual algorithms should be called an "Algorithms" class, don\'t you think?\nIn terms of my current understanding, infinite series, limits and integrals I know (most of the complexity books I\'ve glanced at seemed to use those concepts), but you\'ve lost me at the Fast Fourier Transform.</p>\n', 'Tags': '<complexity-theory><reference-request><algorithm-analysis><education><books>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-08-16T15:37:01.093', 'CommentCount': '1', 'AcceptedAnswerId': '3222', 'CreationDate': '2012-08-15T18:15:23.667', 'Id': '3201'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '70', 'Title': 'Reference Request for Synthesis', 'LastEditDate': '2013-01-27T16:31:43.847', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2644', 'FavoriteCount': '1', 'Body': '<p>New to the world of software verification and synthesis. It was suggested to me that the book "Principles of Model Checking" is a good reference for verification, but I am clueless about synthesis. Could someone refer a good book?</p>\n', 'Tags': '<reference-request><formal-methods>', 'LastEditorUserId': '2100', 'LastActivityDate': '2013-01-27T16:31:43.847', 'CommentCount': '10', 'AcceptedAnswerId': '6948', 'CreationDate': '2012-08-26T21:17:54.387', 'Id': '3339'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '174', 'Title': 'References on teaching introductory programming courses', 'LastEditDate': '2013-07-15T20:26:33.433', 'AnswerCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1829', 'FavoriteCount': '3', 'Body': '<p>As the new semester starts soon, I am interested in research regarding the teaching of introductory programming courses. I would like to improve my university course and I am looking for scientific papers on that topic.</p>\n\n<p>One trend I have seen is that some students (a smaller group) are interested in computers or they have already some programming background. They are fine and learn a lot. But the majority of students struggle at the first step of programming (hard to set up Eclipse, a lot of errors at the beginning, etc.). Is this just my view or is this documented in literature?</p>\n\n<p>I would like to make this \'first step\' into programming as easy as possible for students. As a first start I found <a href="http://csis.pace.edu/~bergin/KarelJava2ed/Karel++JavaEdition.html" rel="nofollow">"A Gentle Introduction to the Art of Object-Oriented Programming in Java"</a> </p>\n', 'Tags': '<reference-request><education>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-07-15T20:26:33.433', 'CommentCount': '5', 'AcceptedAnswerId': '3460', 'CreationDate': '2012-09-07T01:05:40.213', 'Id': '3455'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've done some searching and it seems that fuzzy logic is used in (electronic) controllers. I'm interested in seeing how well it fares as a tool for reasoning. Are there any robots or programs that do clever things with it?</p>\n", 'ViewCount': '322', 'Title': 'Successful applications of fuzzy logic to reasoning in AI?', 'LastEditorUserId': '959', 'LastActivityDate': '2012-09-30T19:22:47.923', 'LastEditDate': '2012-09-30T19:22:47.923', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '959', 'Tags': '<reference-request><artificial-intelligence><reasoning>', 'CreationDate': '2012-09-10T03:15:42.077', 'Id': '3485'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '466', 'Title': 'What are the mathematical prerequisites for adaptive machine learning algorithms?', 'LastEditDate': '2012-09-28T09:36:27.647', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2798', 'FavoriteCount': '2', 'Body': '<p>I am a PhD student in Computer Science who switched his PhD a little bit towards ML algorithms combined with something else... I am an expert in that something else, say image processing, but not an expert in Machine Learning. What should I read/learn to get the ML mathematics right? Especially for adaptive learning algorithms.</p>\n', 'Tags': '<reference-request><machine-learning><education><learning-theory>', 'LastEditorUserId': '157', 'LastActivityDate': '2012-10-26T23:17:51.163', 'CommentCount': '2', 'AcceptedAnswerId': '6324', 'CreationDate': '2012-09-12T07:31:52.607', 'Id': '3510'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '152', 'Title': 'Recommended Reading for non-CS undergraduate student doing a research Project on Travelling Salesman Problem', 'LastEditDate': '2013-06-06T15:05:33.373', 'AnswerCount': '2', 'Score': '3', 'OwnerDisplayName': 'rrampage', 'PostTypeId': '1', 'OwnerUserId': '2642', 'FavoriteCount': '1', 'Body': '<p>I am an undergraduate student in Industrial Engineering. I have taken the topic of Travelling Salesman Problem as a Research Project for my final year. More specifically, I am focusing on <strong>Convex Hulls for solving the Euclidean TSP</strong>.</p>\n\n<p>I have gone through the published literature and have found that there are no approximation bounds for solving TSP using this method. I have just a little background in TheoCS (Started reading for fun since the last 3 months).</p>\n\n<p><strong>My Question:</strong> </p>\n\n<p>Additional Books / Papers needed for achieving a good understanding of the mathematical rigor of the problem.</p>\n\n<p>Here\'s what I am currently going through:</p>\n\n<ul>\n<li>Approximation Algorithms - Vazirani</li>\n<li>Introduction to Algorithms - CLRS</li>\n<li>Introduction to Graph Theory - Douglas West</li>\n<li>Randomized Algorithms - Motwani and Raghavan</li>\n</ul>\n\n<p>I have also completed an introductory online course on Algorithms by Udacity.</p>\n\n<p>I think I may need some background reading in Computational Geometry (Currently I do not know more than what I read in the chapter from Cormen)</p>\n\n<p>This is my first question here, so sincere apologies in case my question does not conform to the Community Standards.</p>\n\n<p>EDIT:</p>\n\n<p>A resource I stumbled across today: <a href="http://press.princeton.edu/titles/9531.html" rel="nofollow">In Pursuit of the Traveling Salesman - Mathematics at the Limits of Computation</a>.\nThis is a good book for popular reading, providing a survey of the problem and various methods that have been used to solve it.</p>\n', 'Tags': '<reference-request><optimization><books><traveling-salesman>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-06T15:05:33.373', 'CommentCount': '0', 'CreationDate': '2012-09-13T21:59:28.047', 'Id': '3539'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am a 16 year old male who has recently been gifted a big encyclopedia on computer science by a friend of mine. I am usually not that interested in computers and technology, but computer science has started to fascinate me. I do however intend to study Physics and/or Mathematics and not CS, so my question is, would it be useful to conduct a self-study of computer science? I'm not of course going for the level of a BSc but just the basics of CS (it is an encyclopedia with ~600 pages).</p>\n", 'ViewCount': '450', 'Title': 'Self-Study of Computer Science', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-06T05:16:08.670', 'LastEditDate': '2012-09-15T14:13:53.847', 'AnswerCount': '4', 'CommentCount': '2', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '2829', 'Tags': '<reference-request><education>', 'CreationDate': '2012-09-14T19:40:41.860', 'FavoriteCount': '2', 'Id': '3545'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am converting the OCaml <a href="http://caml.inria.fr/pub/docs/manual-ocaml/libref/Format.html" rel="nofollow">Format</a> module which does I/O and maintains state in a record with mutable values. As such it is a good candidate for me to convert to pure <a href="http://en.wikipedia.org/wiki/F_Sharp_%28programming_language%29" rel="nofollow">F#</a>, pure <a href="http://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29" rel="nofollow">C#</a> and a hybrid.</p>\n\n<p>Since this is a toss-up for me on the three versions, I am interested to know of any research papers that indicate that programmers may be moving to hybrid code of object-oriented and functional, calling one from the other, or staying with-in one programming family.</p>\n\n<p>Note: I am asking for research papers not subjective answers.</p>\n', 'ViewCount': '68', 'Title': 'Is there any research to indicate programmers are/are not moving to a hybrid of functional and object-oriented?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-15T14:14:19.027', 'LastEditDate': '2012-09-15T14:14:19.027', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '268', 'Tags': '<reference-request><programming-languages><functional-programming><object-oriented>', 'CreationDate': '2012-09-14T21:02:04.073', 'FavoriteCount': '1', 'Id': '3550'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>So we have the following table of processes , where A, B and $\\Gamma$ are the resources.</p>\n\n<p>Here is a pic that i drew with the processes and the resources.</p>\n\n<p><img src="http://i.stack.imgur.com/MzpAz.jpg" alt="Table"></p>\n\n<p>So the exact question is this: Using banker\'s algorithm, calculate the minimum values of $x$ and $y$ in order the system is Deadlock free.</p>\n\n<p>I have done pretty much <em>huge</em> paper work and found that $x,y$ should be the numbers 2 and 3. But in order to find this I run the algorithm on paper several times ; for $[x,y] = [0,0],[0,1],[1,0],[1,1],[1,2]$ etc. until I found that for pair $[x=2, y=3]$ the system is deadlock free!</p>\n\n<p>So, I think that I am missing the point. All this took me like 1 hour or so. Is there a simple method with less paperwork? </p>\n\n<p>Thanks a lot in advance!</p>\n', 'ViewCount': '680', 'Title': "Banker's Algorithm and deadlocks", 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-27T17:17:21.627', 'LastEditDate': '2012-09-17T17:54:25.173', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2865', 'Tags': '<algorithms><reference-request><concurrency>', 'CreationDate': '2012-09-17T16:34:15.583', 'Id': '4593'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a number of related questions about these two topics.</p>\n\n<p>First, most complexity texts only gloss over the class $\\mathbb{NC}$.  Is there a good resource that covers the research more in depth?  For example, something that discusses all of my questions below.  Also, I\'m assuming that $\\mathbb{NC}$ still sees a fair amount of research due to its link to parallelization, but I could be wrong.    The section in the complexity zoo isn\'t much help.</p>\n\n<p>Second, computation over a semigroup is in $\\mathbb{NC}^1$ if we assume the semigroup operation takes constant time.  But what if the operation does not take constant time, as is the case for unbounded integers?  Are there any known $\\mathbb{NC}^i$-complete problems?</p>\n\n<p>Third, since $\\mathbb{L} \\subseteq \\mathbb{NC}^2$, is there an algorithm to convert any logspace algorithm into a parallel version?</p>\n\n<p>Fourth, it sounds like most people assume that $\\mathbb{NC} \\ne \\mathbb{P}$ in the same way that $\\mathbb{P} \\ne \\mathbb{NP}$.  What is the intuition behind this?</p>\n\n<p>Fifth, every text I\'ve read mentions the class $\\mathbb{RNC}$ but gives no examples of problems it contains.  Are there any?</p>\n\n<p>Finally, <a href="http://cs.stackexchange.com/a/1656/2911">this answer</a> mentions problems in $\\mathbb{P}$ with sublinear parallel execution time.  What are some examples of these problems?  Are there other complexity classes that contain parallel algorithms that are not known to be in $\\mathbb{NC}$?</p>\n', 'ViewCount': '228', 'Title': 'Some questions on parallel computing and the class NC', 'LastEditorUserId': '2911', 'LastActivityDate': '2012-09-24T15:39:26.497', 'LastEditDate': '2012-09-21T19:18:26.083', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '2911', 'Tags': '<complexity-theory><reference-request><parallel-computing><complexity-classes>', 'CreationDate': '2012-09-21T18:50:22.743', 'FavoriteCount': '1', 'Id': '4659'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '292', 'Title': 'complexity of decision problems vs computing functions', 'LastEditDate': '2012-09-22T17:24:26.267', 'AnswerCount': '2', 'Score': '-8', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': u'<p>this is an area that admittedly Ive always found subtle about CS and occasionally trips me up, and clearly others. recently on tcs.se a user asked an apparently innocuous question about <a href="http://cstheory.stackexchange.com/questions/12682/is-the-n-queens-problem-np-hard">N-Queens being NP hard</a>, but it got downvoted there &amp; goes unanswered because the audience felt it was poorly phrased. </p>\n\n<p>the issue seems to be that some questions in CS have to be phrased as decision problems to measure their complexity, and it is not always obvious how to do that. also other questions are studied from the pov of computing a function with integer or string inputs and outputs, in which case eg their time or space complexity can be studied. for some NP complete problems eg SAT its proven that the decision problem (eg determining whether an answer exists) is roughly equivalent in time/space complexity to solving the function problem (finding a satisfying assignment), but of course thats not always the case.</p>\n\n<p>moreover much of CS theory is focused on NP complete problems [esp that presented to undergraduates in textbooks], which are nec. decision problems, which might lead to a mistaken impression that other types of problem formats are not as central to the theory. also NP complete is sometimes shown in a hierarchy that includes other complexity classes such as PSpace which can be used to measure <em>function</em> complexity in addition to <em>decision</em> complexity. </p>\n\n<p>think that the N-Queens example question &amp; related comments also shows that a bunch of related questions about the same problem in this case N-Queens can vary widely/dramatically in their complexity depending on slight variations of the phrasing. eg in this case:</p>\n\n<ul>\n<li>is there a solution to the N-Queens problem on a $n \\times n$ chessboard? this problem turns out to have O(1) time complexity\u2014 the answer is always Y.</li>\n<li>what is the complexity of finding a solution to the N-Queens problem given $n$ as the input referring to a square $n \\times n$ chessboard? as that question notes in comments by Peter Shor, an advanced and subtle thm from CS called "mahaney\'s" thm applies because it might refer to a "sparse input". also JeffE found a paper that says its in P.</li>\n<li>there is an NP complete or NP hard version of this problem if the squares are <em>irregularly specified</em> as the input. ie some kind of input that specifies the square allowed/unallowed locations (havent looked up the details).</li>\n</ul>\n\n<p><hr>\nwhile advanced theorists may find all this verging on trivial, feel its a legitimate area of focus which sometimes gets glossed over in theoretical treatments. my question</p>\n\n<blockquote>\n  <p>is there a reference somewhere that points/sorts out these kinds of subtleties/difficulties in formulating CS problems?</p>\n</blockquote>\n\n<p>it would be helpful if it also talks about how the issue relates to the complexity hierarchy. know that this is covered in some textbooks, but even then havent seen a nice concise discussion of that and wonder if anyone has a favorite ref for this type of issue. (suppose Garey and Johnson might have some discussion of this although dont have a copy close to check.)</p>\n\n<p>am not specifically focused on the N-Queens problem with this question, but an answer that sketches out the distinctions wrt N-Queens might be helpful. [eg an expanded explanation of Shor\'s comment how Mahaneys thm applies, the irregular board construction input format, etc]</p>\n\n<p>fyi here are two other example problems Ive noticed that can vary widely in complexity depending on various restrictions on the input</p>\n\n<p>[1] <a href="http://cs.stackexchange.com/questions/701/decidable-restrictions-of-the-post-correspondence-problem/4638">Post correspondence problem.</a> it can go from undecidable to NP complete or even in P depending on various restrictions on the solution.</p>\n\n<p>[2] Finding whether a regular expression is equivalent to all strings over the alphabet. with squaring this was shown to be in ExpSpace by Stockmeyer/Meyer, but restrictions on length lead to it to being in NP complete or P. see eg Chee Yap, <a href="http://cs.nyu.edu/yap/book/complexity/" rel="nofollow">Intro to Complexity classes</a>, ch5 on complete problems.</p>\n', 'ClosedDate': '2014-04-29T11:56:36.853', 'Tags': '<algorithms><complexity-theory><reference-request><time-complexity><np-complete>', 'LastEditorUserId': '699', 'LastActivityDate': '2012-10-01T00:23:22.727', 'CommentCount': '7', 'AcceptedAnswerId': '4674', 'CreationDate': '2012-09-22T16:57:55.790', 'Id': '4667'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In helping someone understand phrase generators for use with testing grammars, think compiler test cases, I noted that I have never found a phrase generator that is knowledgeable of the grammar, and is deterministic. The phrase generators I am talking about rely on the grammar of the language as input so that the user does not have to recreate the rules for the grammar into a format acceptable for the tool. The tool must accept a BNF grammar; I don\'t mind if the grammar has to be factored some for the tool before input. Tools that rely on a seed or generate a random seed are what I want to avoid.</p>\n\n<p>I am aware that one can use PROLOG to generate a parser and then run a query that outputs a set of results that are phrases used for testing. I also know that it is not uncommon for these result sets to have 10**15 answers for basic cases of a grammar like C++.</p>\n\n<p>Does anyone know of such tools? They can be commercial or open-source as I don\'t plan on using it, I have my own, I just want to verify my knowledge. </p>\n\n<p>EDIT</p>\n\n<p>The tool must encompass sematic knowledge of the compiler. In other words the phrases must be able to be compiled by a compiler, not just pass the syntactic rules.</p>\n\n<p>EDIT</p>\n\n<p>I agree that the comments and answers regarding deterministic are correct and I my use of the word here is not correct.</p>\n\n<p>What I am looking for is a tool that not only takes in a BNF grammar and can use it "as is" which would mean for a grammar like C++ a basic result sets with 10**30 items. That is not an accurate number but a realistic one based on a phrase generator I have that can report the number of results before generating the results. Since that size of a result set is impractical, I have given the tool the ability to enhance the grammar with constraints, thinking tree pruning. This allows one to generate phrases for one particular branch of the grammar, and also prune and limit the sub-braches and number of recursion over those branches. Even with the constraints each result item is a valid C++ file for use as input to a C++ compiler.</p>\n\n<p>I have a proof of concept of this already, but the difference between a proof of concept and useful tool is a lot of work. So while a seed can be reused and create deterministic results, it does not allow the user to determine the conditions.</p>\n', 'ViewCount': '113', 'Title': "Phrase generators for use with testing grammars that don't use a seed", 'LastEditorUserId': '268', 'LastActivityDate': '2012-09-24T13:14:33.833', 'LastEditDate': '2012-09-24T13:14:33.833', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '4698', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '268', 'Tags': '<reference-request><formal-grammars><context-free><parsing><software-testing>', 'CreationDate': '2012-09-23T13:37:55.380', 'Id': '4692'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m looking for good resources regarding <strong>Support Vector Machines</strong>, or suggestions where to start learning SVM.</p>\n\n<p>Already used references: </p>\n\n<ul>\n<li><p><a href="http://dde.binghamton.edu/kodovsky/svm/index.php?content=Material" rel="nofollow">Stanford ML course by Andrew Ng</a> is great place to star  </p></li>\n<li><p>A Tutorial on Support Vector Machines for Pattern Recognition, Burges, 1998<br>\n<a href="http://svms.org/tutorials/" rel="nofollow">SVM tutorials</a>   </p></li>\n<li><p>Neural Networks and Learning Machines, Third Edition  Learning with Kernels - SVM, A. Smola  </p></li>\n</ul>\n', 'ViewCount': '289', 'Title': 'Machine Learning - Support Vector Machines', 'LastEditorUserId': '867', 'LastActivityDate': '2014-04-27T23:29:08.580', 'LastEditDate': '2012-12-10T17:14:27.817', 'AnswerCount': '4', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2592', 'Tags': '<reference-request><machine-learning><data-mining>', 'CreationDate': '2012-09-26T20:12:16.970', 'FavoriteCount': '2', 'Id': '4750'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '145', 'Title': 'References on collective intelligence with respect to CS applications', 'LastEditDate': '2012-09-28T16:28:05.587', 'AnswerCount': '1', 'Score': '-4', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>In recent years the field of "collective intelligence" sometimes known as <a href="http://en.wikipedia.org/wiki/Web_2.0" rel="nofollow">Web 2.0</a> has had a big impact on computer science, software engineering, and software development. Stackexchange software itself is a large scale evolving application or implementation and experiment along the lines of harnessing collective intelligence. </p>\n\n<blockquote>\n  <p>What are some references especially with a CS angle on this connection between collective intelligence/Web 2.0 and CS?</p>\n</blockquote>\n', 'Tags': '<reference-request><education><software-engineering><books>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-09-28T16:28:05.587', 'CommentCount': '5', 'AcceptedAnswerId': '4769', 'CreationDate': '2012-09-27T18:26:13.057', 'Id': '4768'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1683', 'Title': 'Start learning about Theory of Distributed Systems?', 'LastEditDate': '2012-09-29T14:26:42.870', 'AnswerCount': '6', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '687', 'FavoriteCount': '8', 'Body': "<p>What's the best way that anyone can do to have a good introduction to the theory of distributed system, any books or references, and topics should be covered first and requirements to start learning in this topic.</p>\n", 'Tags': '<reference-request><education><distributed-systems>', 'LastEditorUserId': '157', 'LastActivityDate': '2013-02-18T20:06:39.400', 'CommentCount': '0', 'AcceptedAnswerId': '4798', 'CreationDate': '2012-09-29T14:24:11.433', 'Id': '4793'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1105', 'Title': 'Fast k mismatch string matching algorithm', 'LastEditDate': '2012-09-29T20:37:46.053', 'AnswerCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '3011', 'FavoriteCount': '2', 'Body': '<p>I am looking for a fast k-mismatch string matching algorithm. Given a pattern string P of length m, and a text string T of length n, I need a fast (linear time) algorithm to find all positions where P matches a substring of T with at most k mismatches. This is different from the k-differences problem (edit distance). A mismatch implies the substring and the pattern have a different letter in at most k positions. I really only require k=1 (at most 1 mismatch), so a fast algorithm for the specific case of k=1 will also suffice. The alphabet size is 26 (case-insensitive english text), so space requirement should not grow too fast with the size of the alphabet (eg., the FAAST algorithm, I believe, takes space exponential in the size of the alphabet, and so is suitable only for protein and gene sequences).</p>\n\n<p>A dynamic programming based approach will tend to be O(mn) in the worst case, which will be too slow. I believe there are modifications of the Boyer-Moore algorithm for this, but I am not able to get my hands on such papers. I do not have subscription to access academic journals or publications, so any references will have to be in the public domain.</p>\n\n<p>I would greatly appreciate any pointers, or references to freely available documents, or the algorithm itself for this problem. </p>\n', 'Tags': '<algorithms><reference-request><strings><string-metrics><substrings>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-04T09:58:32.560', 'CommentCount': '3', 'AcceptedAnswerId': '4855', 'CreationDate': '2012-09-29T19:47:41.390', 'Id': '4797'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What is a good textbook for a seminar about </p>\n\n<ul>\n<li>virtual environments,  virtual worlds,  augmented reality  and\nsimilar topics?</li>\n</ul>\n\n<p>The seminar is at the graduate studies level and is supposed to give introduction to virtual environments, technologies and applications as well as  current research directions.</p>\n\n<p>A creative commons license and availability online would be a plus.</p>\n\n<p>Here are my own results after some search:</p>\n\n<ul>\n<li><a href="http://www.intechopen.com/books/augmented-reality" rel="nofollow">Augmented Reality</a> - open access book at Intechopen</li>\n</ul>\n\n<p>I was suggested these books (no online access) at another source (ResearchGate):</p>\n\n<ul>\n<li>"Virtual Reality Technology" (Grigore C. Burdea, Philippe Coiffet)</li>\n<li>"Understanding Virtual Reality: Interface, Application, and Design" (William R. Sherman, Alan B. Craig) </li>\n<li>"Developing Virtual Reality Applications:Foundations of Effective Design" (Alan Craig , William R. Sherman)</li>\n<li>"Stepping into Virtual Reality " (Mario Gutierrez, F. Vexo, Daniel Thalmann)</li>\n</ul>\n\n<p>In your answer please comment, why do you suggest a particular source and why it is fundamental or current in the field.</p>\n', 'ViewCount': '39', 'Title': 'A text for virtual environments seminar', 'LastEditorUserId': '3019', 'LastActivityDate': '2012-10-04T07:36:44.627', 'LastEditDate': '2012-10-04T07:36:44.627', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '3019', 'Tags': '<reference-request><books><graphics><computer-games><hci>', 'CreationDate': '2012-09-30T20:44:48.760', 'Id': '4821'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p><a href="http://en.wikipedia.org/wiki/Partition_refinement">Partition refinement</a> is a technique in which you start with a finite set of objects and progressively split the set. Some problems, like DFA minimization, can be solved using partition refinement quite efficiently. I don\'t know of any other problems that are usually solved using partition refinement other than the ones listed on the Wikipedia page. Out of all these problems, the Wikipedia page mentions two for which algorithms based on partition refinement run in linear time. There\'s the lexicographically ordered topological sort [1] and an algorithm for <a href="http://en.wikipedia.org/wiki/Lexicographic_breadth-first_search">lexicographic breadth-first search</a> [2].</p>\n\n<blockquote>\n  <p>Are there any other examples or references to problems that can be solved using partition refinement very efficiently, meaning something better than loglinear in terms of time?</p>\n</blockquote>\n\n<hr>\n\n<p>[1] <a href="http://epubs.siam.org/doi/abs/10.1137/0205005">Sethi, Ravi, "Scheduling graphs on two processors", SIAM Journal on Computing 5 (1): 73\u201382, 1976.</a></p>\n\n<p>[2] <a href="http://epubs.siam.org/doi/abs/10.1137/0205021">Rose, D. J., Tarjan, R. E., Lueker, G. S., "Algorithmic aspects of vertex elimination on graphs", SIAM Journal on Computing 5 (2): 266\u2013283, 1976.</a></p>\n', 'ViewCount': '157', 'Title': 'Problems for which algorithms based on partition refinement run faster than in loglinear time', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-05T01:32:41.660', 'LastEditDate': '2012-10-04T22:21:19.390', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<algorithms><reference-request><data-structures><partitions><sets>', 'CreationDate': '2012-10-02T17:25:18.093', 'FavoriteCount': '1', 'Id': '4843'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am interested in <a href="http://en.wikipedia.org/wiki/Oriented_matroid" rel="nofollow">oriented matroids</a> in the context of directed graphs and optimization. Unfortunately, I know very little of the topic. Is there a book, article or a resource that serves as a good introduction to oriented matroids, especially in the context of directed graphs? It\'s a bonus if the resource is suitable for an (under)graduate level course and is preferably even free.</p>\n', 'ViewCount': '51', 'Title': 'What is a good resource to learn about oriented matroids in the context of digraphs and optimization?', 'LastActivityDate': '2012-10-13T20:53:20.050', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6047', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<reference-request><optimization><discrete-mathematics>', 'CreationDate': '2012-10-13T20:19:48.250', 'Id': '6046'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1566', 'Title': 'What is tail recursion?', 'LastEditDate': '2013-05-24T03:17:30.907', 'AnswerCount': '4', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2223', 'FavoriteCount': '3', 'Body': '<p>I know the general concept of recursion.  I came across the concept of <strong>tail recursion</strong> while studying the quicksort algorithm.  In this <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-4-quicksort-randomized-algorithms/" rel="nofollow">video of quick sort algorithm from MIT</a> at 18:30 seconds the professor says that this is a tail recursive algorithm.  It is not clear to me what tail recursion really means.</p>\n\n<p>Can someone explain the concept with a proper example?</p>\n\n<p><em>Some answers provided by the SO community <a href="http://stackoverflow.com/questions/11864006/why-is-quick-sort-called-a-tail-recursive-algorithm">here</a>.</em></p>\n', 'Tags': '<algorithms><reference-request><recursion>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:17:30.907', 'CommentCount': '6', 'AcceptedAnswerId': '7814', 'CreationDate': '2012-10-22T08:58:53.803', 'Id': '6230'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm trying to trace back the origin of the general concept of Discrete Event Simulation and found a 1968 article by Fishman and Kiviat mentioning the term. It is titled <em>The statistics of discrete-event simulation</em>.</p>\n\n<p>However, I'm unable to verify this as the origin of the term.</p>\n\n<p>Is there further historical information on this?</p>\n", 'ViewCount': '81', 'Title': 'Who conceived the concept of Discrete Event Simulation, and when?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-24T19:39:30.363', 'LastEditDate': '2012-10-24T15:09:26.083', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '26', 'Tags': '<reference-request><simulation><history>', 'CreationDate': '2012-10-24T11:21:38.397', 'Id': '6285'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I want to learn quantum computation and information. I am studying from Nielsen &amp; Chuang book for this.\nIs there any online vedio (lecture series) starts from\nbasics of quantum computation and information up to factorization, discrete log, search etc? </p>\n', 'ViewCount': '98', 'Title': 'Help need to learn Quantum Computation and Information', 'LastEditorUserId': '157', 'LastActivityDate': '2012-10-24T21:54:57.560', 'LastEditDate': '2012-10-24T17:01:17.093', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '6292', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4343', 'Tags': '<reference-request><education><quantum-computing>', 'CreationDate': '2012-10-24T12:51:39.047', 'Id': '6290'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was told that quantum computers are not computationally more powerful than Turing machines.\nCould someone kindly help in giving some literature references explaining that fact?</p>\n', 'ViewCount': '217', 'Title': 'References on comparison between quantum computers and Turing machines', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-30T05:24:51.813', 'LastEditDate': '2012-10-25T11:04:54.370', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '4349', 'Tags': '<computability><reference-request><turing-machines><quantum-computing>', 'CreationDate': '2012-10-24T20:44:35.533', 'Id': '6296'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '128', 'Title': 'What are some applications of binary finite fields in CS?', 'LastEditDate': '2012-10-27T22:33:00.597', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>I was looking at details on <a href="http://en.wikipedia.org/wiki/Finite_field" rel="nofollow">finite fields</a>. Finite binary fields, e.g. $\\mathbb{F_2}$, are used in CS in some places such as circuit theory [1]. </p>\n\n<blockquote>\n  <p>What are some key applications of finite fields in CS?</p>\n</blockquote>\n\n<p>I am also looking for uses of $\\mathbb{F_{2}^n}$ which <a href="http://mathworld.wolfram.com/FiniteField.html" rel="nofollow">Mathworld</a> shows can be represented as binary vectors.</p>\n\n<hr>\n\n<p>[1] <a href="http://eccc.hpi-web.de/report/2012/133/download/" rel="nofollow">Noga Alon and Gil Cohen. On Rigid Matrices and Subspace Polynomials. Electronic Colloquium on Computational Complexity, Report No. 133 (2012)</a>.</p>\n', 'Tags': '<algorithms><reference-request><discrete-mathematics><applied-theory>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-27T22:33:00.597', 'CommentCount': '4', 'AcceptedAnswerId': '6331', 'CreationDate': '2012-10-27T02:40:18.207', 'Id': '6326'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '398', 'Title': 'What are the different types of databases?', 'LastEditDate': '2012-11-09T03:21:27.437', 'AnswerCount': '2', 'Score': '3', 'OwnerDisplayName': 'sashank', 'PostTypeId': '1', 'OwnerUserId': '4421', 'FavoriteCount': '1', 'Body': '<p>Is there is a study or classification available on different types of databases? (Examples include structured, unstructured, semi structured relational, object oriented, folksonomies, etc.) </p>\n', 'Tags': '<terminology><reference-request><databases>', 'LastEditorUserId': '4519', 'LastActivityDate': '2012-11-09T03:21:27.437', 'CommentCount': '0', 'AcceptedAnswerId': '6557', 'CreationDate': '2012-10-31T23:17:00.447', 'Id': '6423'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've read first-order logic is in general undecidable, and that could be decidable only when working with unary operators. (I think that's propositional logic, correct me if I am wrong)</p>\n\n<p>The question is <strong>why arity leads to undecidable problems?</strong></p>\n\n<p>I would like to see some reference material, or at least some simple <em>example</em> of it, as a way to think in this passage from unary to n-ary and why it leads to undecidable problems. </p>\n", 'ViewCount': '157', 'Title': 'First-order logic arity defines decidability?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-06T10:58:10.357', 'LastEditDate': '2012-11-05T17:16:52.103', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '6489', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1396', 'Tags': '<reference-request><logic><undecidability><satisfiability><first-order-logic>', 'CreationDate': '2012-11-05T15:10:08.337', 'Id': '6488'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Looking for some tutorials / references that discuss Breadth First Search that takes into consideration the cost of paths, but could not find much information.</p>\n\n<p>Could someone refer a tutorial?</p>\n', 'ViewCount': '292', 'Title': 'Breadth First Search with cost', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-07T08:02:23.767', 'LastEditDate': '2012-11-06T14:28:43.053', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '6523', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4476', 'Tags': '<algorithms><reference-request><graphs><search-algorithms>', 'CreationDate': '2012-11-06T14:22:03.630', 'Id': '6514'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I need a concise definition of the "state of an object" in object-oriented programming (for a paper).</p>\n\n<p>For about half of a day I searched for a paper that I can cite on this topic, but I couldn\'t find one. All the papers I found were mostly general papers on object-oriented programming and they didn\'t define the state of an object.</p>\n\n<p>I am unsure, but my best guess is something like:\n<em>The state of an object is defined by the state of the instance variables of the object.</em></p>\n\n<p>I am searching for a definition of the state of an object and/or a reference on the topic.</p>\n\n<p>(btw, could I refer to the concept as "object state" or is this uncommon?)</p>\n', 'ViewCount': '1884', 'Title': 'Definition of the state of an object in OOP', 'LastEditorUserId': '1829', 'LastActivityDate': '2014-04-27T19:38:08.067', 'LastEditDate': '2012-11-07T16:03:17.703', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<terminology><reference-request><programming-languages><object-oriented>', 'CreationDate': '2012-11-07T14:07:34.027', 'Id': '6536'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Most of the classic examples of dynamic programming algorithms have run-times such as $n$ or $n^2$. Are there any natural examples with a $O(n \\log n)$ run-time?</p>\n', 'ViewCount': '301', 'Title': 'Dynamic programming algorithms with log in the run-time', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-09T08:03:51.553', 'LastEditDate': '2012-11-09T08:03:51.553', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '71', 'Tags': '<algorithms><reference-request><dynamic-programming>', 'CreationDate': '2012-11-07T22:35:41.207', 'FavoriteCount': '1', 'Id': '6546'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '83', 'Title': 'Who (and when) first defined interval graphs?', 'LastEditDate': '2012-11-21T14:59:55.280', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '26', 'FavoriteCount': '1', 'Body': '<p>I\'ve been searching google scholar for references and narrowed down the first mention to somewhere around <a href="http://books.google.com/ngrams/graph?content=interval%20graph&amp;year_start=1800&amp;year_end=2000&amp;corpus=15&amp;smoothing=0&amp;share=">1963</a> with a very weird jitter in 1949.</p>\n\n<p>So, I\'m trying to track down the original paper introducing interval graphs for citation, but it\'s been rather elusive so far.</p>\n', 'Tags': '<graph-theory><reference-request><history>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-21T17:36:52.917', 'CommentCount': '0', 'AcceptedAnswerId': '6816', 'CreationDate': '2012-11-21T13:26:08.517', 'Id': '6812'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Are there programming languages(or logic) that can implement(or express) a function $f:\\mathbb{N}\\to \\mathbb{N}$ if and only if $f$ is a computable bijective functions?</p>\n', 'ViewCount': '180', 'Title': 'A programming language that can only implement computable bijective functions?', 'LastEditorUserId': '13299', 'LastActivityDate': '2014-02-02T10:36:16.947', 'LastEditDate': '2014-02-02T10:36:16.947', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '6852', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<reference-request><programming-languages><logic><reversible-computing>', 'CreationDate': '2012-11-22T20:32:44.933', 'Id': '6840'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am reading Papadimitriou, Computational Complexity, page 24, where it is says </p>\n\n<blockquote>\n  <p>We say that $M$ accepts $L$ whenever for any string $x \\in (\\Sigma - \\{\\sqcup\\})^*$, if $x \\in L$, then $M(x) =$ ``yes\'\'; however, if $x\\notin L$, then $M(x) = \\nearrow$. </p>\n</blockquote>\n\n<p>The key issue is what happens for $x \\notin L$. This definition insists that $M$ must not halt for $x \\notin L$. Other sources I read, e.g., <a href="http://books.google.com/books?id=VQpJuiD3mHQC&amp;lpg=PA27&amp;dq=turing%20machine%20accepts&amp;pg=PA27#v=onepage&amp;q=turing%20machine%20accepts&amp;f=false" rel="nofollow">this</a> says that  if $x\\notin L$ then either $M$ does not halt, or $M$ halts at ``no\'\'. </p>\n\n<p>Prima facie this seems to me to be a significant difference. Could someone clarify to me if these definitions are equivalent and if there is no loss of generality in talking of acceptance in the sense of Papadimitriou? Or is only one of these definitions the correct one?</p>\n', 'ViewCount': '125', 'Title': 'Conflicting definitions of language accepted by Turing Machine?', 'LastEditorUserId': '1442', 'LastActivityDate': '2012-11-30T00:18:24.437', 'LastEditDate': '2012-11-29T21:10:14.513', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7027', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1442', 'Tags': '<reference-request><turing-machines>', 'CreationDate': '2012-11-29T19:40:18.567', 'Id': '7025'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Deterministic context-free languages are commonly defined using an <em>automaton</em> concept, the (restricted, deterministic) pushdown automaton. To some that is confusing, as the name <em>context-free</em> refers to a grammar type.</p>\n\n<p>I seem to remember there exists a characterization of the DCF languages using grammars. In my recollection it used a complicated equivalence on non-terminals. Can anyone provide a pointer to that work?</p>\n', 'ViewCount': '180', 'Title': 'Grammatical characterization of deterministic context-free languages', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-05T09:56:58.627', 'LastEditDate': '2012-11-30T12:42:38.430', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7047', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4287', 'Tags': '<reference-request><formal-grammars><context-free>', 'CreationDate': '2012-11-30T00:33:24.183', 'Id': '7031'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was wondering if someone knew the origin of the client server model. Where does the term come from (paper, software application, book)?</p>\n', 'ViewCount': '349', 'Title': 'What is the origin of the client server model?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-04T23:06:54.407', 'LastEditDate': '2012-12-02T11:34:11.250', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '7060', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '4809', 'Tags': '<terminology><reference-request><distributed-systems><history>', 'CreationDate': '2012-11-30T10:05:42.000', 'Id': '7038'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>It is well-known that 1-in-k SAT is NP-complete for k=3. What about for k > 3?</p>\n', 'ViewCount': '126', 'Title': 'Is 1-in-k SAT NP-complete for k > 3', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-02T11:41:55.400', 'LastEditDate': '2012-12-02T11:41:55.400', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'OwnerDisplayName': 'user12702', 'PostTypeId': '1', 'Tags': '<complexity-theory><reference-request><np-complete>', 'CreationDate': '2012-12-01T00:13:36.670', 'Id': '7098'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<blockquote>\n  <p>We are given two strings $x=x_1,x_2,x_3,\\ldots,x_m$ and $y=y_1,y_2,y_3,\\ldots,y_n$ over some finite alphabet.\n  We consider the problem of converting $x$ to $y$. Using the following operations:</p>\n  \n  <p>1.Substitution: replace one symbol by another one.</p>\n  \n  <p>2.Insertion: inserts one symbol</p>\n  \n  <p>3.Deletion: delete one symbol.</p>\n</blockquote>\n\n<p>For example, if $x$="logarithm" and $y$="algorithm", we convert $x$ to $y$ in the following way:</p>\n\n<ol>\n<li><p>start with "logarithm"</p></li>\n<li><p>inserting "a"at the front gives "alogarithm".</p></li>\n<li><p>deleting "o"gives "algarithm"</p></li>\n<li><p>replacing the second "a"by "o"gives "algorithm".</p></li>\n</ol>\n\n<p>The similarity problem between the string $x$ and $y$ is defined to be the minimum number of operations needed to convert $x$ to $y$.</p>\n\n<p>For example, the similarity between $x$="logarithm" and $y$="algorithm" is 3, because $x$ can be converted to $y$ using three operations. If the string $x$ has length $m$ and the string $y$ is empty, then the similarity between $x$ and $y$ is similar to $m$.</p>\n\n<p>Give a dynamic programming algorithm (in pseudocode) that computes, in $\\mathcal o(mn)$ time, the similarity between the string $x$ and $y$.</p>\n\n<p>It is as the edit distance problem but there is the corresponding minimization problem problem where we measure similarity instead of distance .  </p>\n', 'ViewCount': '400', 'Title': 'String similarity problem', 'LastEditorUserId': '3094', 'LastActivityDate': '2012-12-03T10:17:05.547', 'LastEditDate': '2012-12-02T20:38:06.193', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4828', 'Tags': '<algorithms><reference-request><dynamic-programming><strings>', 'CreationDate': '2012-12-02T19:47:18.867', 'Id': '7109'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Coming from the POV of someone who is thinking about pursuing a PhD in Computer science.</p>\n\n<p>I am having trouble deciding what I would focus my research on when I go for my PhD. See <a href="http://academia.stackexchange.com/questions/5579/choosing-your-research-area">also this question on academia.SE</a>.</p>\n\n<p>So I am thinking that reading/keeping current on what research is being done and what research papers are being released is a good source of....inspiration?  Plus good knowledge to know.</p>\n\n<p>Is there central place/database of/good starting place to see recently published CS research papers, or are they all hidden deep within the websites of the University they were written at?</p>\n', 'ViewCount': '870', 'Title': 'Where to find published research papers?', 'LastEditorUserId': '1157', 'LastActivityDate': '2014-01-14T09:20:31.970', 'LastEditDate': '2014-01-14T09:20:31.970', 'AnswerCount': '7', 'CommentCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '1157', 'Tags': '<reference-request>', 'CreationDate': '2012-12-03T21:59:05.837', 'FavoriteCount': '6', 'Id': '7136'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '223', 'Title': 'Studying Programming Language Theory', 'LastEditDate': '2013-02-17T01:14:39.193', 'AnswerCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '106', 'FavoriteCount': '2', 'Body': "<p>I have recently become extremely interested in understanding and proving aspects of (functional) programming languages.</p>\n\n<p>However as I dive deeper in, things like $\\lambda$ calculus, category theory, and denotational semantics are a little difficult to grok without proper explanation.</p>\n\n<p>I read SICP (quite an enlightening book) but I'm looking to dive deeper into the theory of functional programming. Are there any books/blogs/sites/you-name-it that would discuss the theory of functional programming languages from the ground up?</p>\n", 'Tags': '<reference-request><lambda-calculus><functional-programming><books>', 'LastEditorUserId': '106', 'LastActivityDate': '2013-02-18T01:07:53.190', 'CommentCount': '0', 'AcceptedAnswerId': '7323', 'CreationDate': '2012-12-11T04:40:37.923', 'Id': '7322'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '293', 'Title': 'Looking for a dictionary of math/CS notation', 'LastEditDate': '2012-12-13T17:11:42.787', 'AnswerCount': '3', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '2', 'Body': '<p>There is an at-times dizzying array of symbols used in math and CS papers. Yet many assume basic familiarity that seems rarely taught in one place. I am looking for a dictionary something like the following, especially from a CS perspective. </p>\n\n<ul>\n<li>It would list all the basic mathematical symbols and give their meanings and examples. It would talk about symbols that are sometimes used in equivalent ways. It would note common beginner mistakes.</li>\n<li>It would talk about the subtleties surrounding different meanings of a single symbol (much like multiple definitions of the same word in a dictionary). </li>\n<li>It would not merely be a very terse description of each symbol, such as one word descriptions like "subset".</li>\n<li>It would show how symbols are sometimes "overloaded". For example, $\\binom{x}{y}$ could have $z$ as an integer, but sometimes $z$ can be a set with this notation and it means to choose elements from this set. $[n]$ sometimes means a set of integers $1 \\ldots n$, or other times its a one-element array.</li>\n<li>It might talk about how to describe all kinds of different "objects" in terms of different symbols or equivalent ways of referring to them (but which are more clear) and the operations possible on those objects. In other words, kind of like an API for math objects.</li>\n</ul>\n\n<p>I.e. it would be also at times a "style manual" for different nuances in how to present mathematical writing. This would be a very helpful resource for anyone writing questions in mathematical stackexchanges, where many questions fail to make sense based on not fitting into tricky mathematical conventions.</p>\n\n<p>Some book introductions have many of these features. however ideally it would be a separate treatment. Also, ideally of course it would be online. There are tables of latex symbols, but they don\'t really fulfill many of the above criteria.</p>\n\n<blockquote>\n  <p>Has anyone seen a "dictionary of symbols" that matches these features?</p>\n</blockquote>\n\n<p>(Alternatively, it seems like an excellent wiki or FAQ project if good references like this don\'t exist.)</p>\n', 'Tags': '<terminology><reference-request><education>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-07-11T19:49:51.730', 'CommentCount': '3', 'AcceptedAnswerId': '7370', 'CreationDate': '2012-12-13T04:19:04.670', 'Id': '7367'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Mostly I am interested in characters 32 through 126 (space, special characters, numbers, and upper and lower case letters) but the others would be good to know as well, especially the del, backspace, tab, and newline characters.</p>\n\n<p>I have been told that there is a huge difference in the answer for different situations such as writing code versus writing a novel. Due to this problem I would like to use the average case for a large number of people with a wide variety of usage. Perhaps the same criteria that the people behind Dvorak used.</p>\n\n<p>I plan on experimenting with chorded keyboards and I wanted this data so that I could assign the most common characters to the easiest chords and assign the least common characters to the most difficult chords. I don't actually need it yet since I haven't found how to intercept and replace keyboard events yet. In theory I don't need it at all and I could set all the chords at random but I am a bit of a perfectionist and wanted to optimize and generalize it. The reason for ASCII characters is that it should ensure complete coverage barring the use of additional character sets.</p>\n", 'ViewCount': '340', 'Title': 'What is the Usage Frequency of ASCII Characters?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-19T23:42:16.413', 'LastEditDate': '2012-12-19T23:42:16.413', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '5122', 'Tags': '<reference-request><user-interface>', 'CreationDate': '2012-12-19T04:29:49.360', 'Id': '7501'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a background in computer architecture and only cursory understanding of process networks. For a paper I am writing I need to understand prefix monotonicity properly. </p>\n\n<p>For now I have "a stream transformer is prefix monotonic if its output for a given input record r is dependent only on the input stream up to and including r, and independent from whether r is the last record in the stream". But this was gathered by word-of-mouth and I am not sure it is the proper approach.</p>\n\n<p>I would welcome suggestions for:</p>\n\n<ul>\n<li>proper formal background and definitions;</li>\n<li>useful analogies to explain the concept to a newcomer (the audience of the paper needs to understand prefix monotonicity but may not be knowledgeable with TCS).</li>\n</ul>\n', 'ViewCount': '123', 'Title': 'What is prefix monotonicity?', 'LastActivityDate': '2013-06-03T14:32:09.153', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'OwnerDisplayName': 'kena', 'PostTypeId': '1', 'OwnerUserId': '1922', 'Tags': '<reference-request><terminology><nondeterminism>', 'CreationDate': '2013-01-01T13:03:26.163', 'Id': '7685'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Consider the following problem:</p>\n\n<p>Let $k$ be a constant. We are given a $k$-ary array $A_{d_1\\times\\ldots\\times d_k}$ of $0$ and $1$\'s. Let $N = \\prod_{i=1}^k d_i$. </p>\n\n<p>We want to create a data structure by preprocessing $A$ to perform the following type of query operations:</p>\n\n<ol>\n<li>Given the coordinates of a $k$-ary box $D$, is there a $1$ in the box?  </li>\n<li>Given the coordinates of a $k$-ary box $D$, return the position of a $1$ in the box (if there is one). </li>\n</ol>\n\n<p>The operations must be performed in constant time $O(1)$. The time complexity is measured on a RAM machine. The preprocessing time and space for the data structure are not important for us. </p>\n\n<p>The question is how much space (in bit complexity) do we need to store a datastructure allowing the above operations?</p>\n\n<p>The trivial lower-bound is $N$ bits since the array can be reconstructed for these queries (so the data structure should have at least the same amount of information in it).</p>\n\n<p>The trivial upper-bound is to store the answer to all of the queries. That would need $\\prod_{i=1}^k {d_i \\choose 2} = \\Theta(N^2)$ bits. However we suspect that this can be done much more efficiently.</p>\n\n<p>For example, consider the special case where $k=1$. In this case we can use a <a href="http://link.springer.com/chapter/10.1007/978-3-540-74450-4_41" rel="nofollow">succinct RMQ data structure</a> to solve the first problem, and the data structure takes $2N+o(N)$ bits to store.</p>\n\n<blockquote>\n  <p>What is an efficient data-structure for this task?<br>\n  How low can the space complexity (the number of bits) go to support these operations (or just the first operation)?</p>\n</blockquote>\n\n<p><strong>Update (1/15):</strong>\nIn the special case $k=1$, using $N +o(N)$ bits is sufficient (actually better, $\\log {N\\choose t}+O(t)$, where $t$ is the number of $1$\'s in $A$) by reducing the problem to a predecessor problem and using the reduction from predecessor problem to fully indexable dictionary (FID). See "<a href="http://arxiv.org/abs/0902.2648" rel="nofollow">More Haste, Less Waste: Lowering the Redundancy in Fully Indexable Dictionaries</a>" by Grossi, Orlandi, Raman and Rao (2009).</p>\n\n<p><strong>Update (6/27):</strong>\nAgain by reduce the problem to RMQ. We use a $k$-dimensional RMQ by <a href="https://www.siam.org/proceedings//soda/2010/SODA10_014_yuanh.pdf" rel="nofollow">Yuan and Atallah</a> to get a $O(n\\log n)$ upper bound on the amount of space required when $k$ is fixed. </p>\n', 'ViewCount': '316', 'Title': 'Bit complexity of O(1) time range query in a $k$-ary array', 'LastEditorUserId': '220', 'LastActivityDate': '2013-06-27T23:36:27.377', 'LastEditDate': '2013-06-27T23:36:27.377', 'AnswerCount': '1', 'CommentCount': '9', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<reference-request><data-structures><space-complexity>', 'CreationDate': '2013-01-10T20:52:45.990', 'FavoriteCount': '3', 'Id': '7876'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '259', 'Title': 'Is there a sometimes-efficient algorithm to solve #SAT?', 'LastEditDate': '2013-01-16T01:27:21.360', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '1786', 'FavoriteCount': '2', 'Body': '<p>Let $B$ be a boolean formula consisting of the usual AND, OR, and NOT operators and some variables.  I would like to count the number of satisfying assignments for $B$. That is, I want to find the number of different assignments of truth values to the variables of $B$ for which $B$ assumes a true value. For example, the formula $a\\lor b$ has three satisfying assignments; $(a\\lor b)\\land(c\\lor\\lnot b)$ has four. This is the <a href="https://en.wikipedia.org/wiki/Sharp-SAT">#SAT problem</a>.</p>\n\n<p>Obviously an efficient solution to this problem would imply an efficient solution to SAT, which is unlikely, and in fact this problem is #P-complete, and so may well be strictly harder than SAT. So I am not expecting a guaranteed-efficient solution.</p>\n\n<p>But it is well-known that there are relatively few really difficult instances of SAT itself. (See for example <a href="http://www.dcs.gla.ac.uk/~pat/cpM/papers/cheeseman91where.pdf">Cheeseman 1991, "Where the <em>really</em> hard problems are"</a>.) Ordinary pruned search, although exponential in the worst case, can solve many instances efficiently; resolution methods, although exponential in the worst case, are even more efficient in practice.  </p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Are any algorithms known which can quickly count the number of satisfying assignments of a typical boolean formula, even if such algorithms require exponential time in the general instance? Is there anything noticeably better than enumerating every possible assignment?</p>\n</blockquote>\n', 'Tags': '<complexity-theory><reference-request><satisfiability>', 'LastEditorUserId': '1786', 'LastActivityDate': '2013-06-25T05:37:04.663', 'CommentCount': '4', 'AcceptedAnswerId': '8953', 'CreationDate': '2013-01-16T00:21:03.510', 'Id': '8952'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For the $n$-th prime number $p_n$ the <em><a href="http://en.wikipedia.org/wiki/Primorial" rel="nofollow">primorial</a></em> $p_n\\#$ is defined as the product of the first $n$ primes.</p>\n\n<blockquote>\nWhat is the complexity of testing if a given number $n$ is a primorial?<br>\nIs it related in some way to the FACTORING problem?<br>\n</blockquote>\n', 'ViewCount': '46', 'Title': 'Complexity of testing if a number is a primorial', 'LastActivityDate': '2013-01-16T09:25:14.040', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '8962', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<complexity-theory><reference-request>', 'CreationDate': '2013-01-16T08:33:30.810', 'Id': '8960'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '162', 'Title': 'Complexity of a subset sum variant', 'LastEditDate': '2013-05-24T03:32:02.207', 'AnswerCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '1', 'Body': "<p>Is this variant of the subset sum problem easy/known?</p>\n\n<blockquote>\nGiven an integer $m$, and a set of positive integers $A = \\{x_1, x_2, ..., x_n\\}$ such that every $x_i$ has at most $k=2$ bits set to $1$ ($x_i = 2^{b_{i_1}}+2^{b_{i_2}},\\;\\; b_{i_1},b_{i_2}\\geq 0$); is there a subset $A' \\subseteq A$ such that the sum of its elements is equal to $m$ ?<br>\n</blockquote>\n\n<p>Is it in $\\sf{P}$? Is it still $\\sf{NP}$-complete?</p>\n\n<p>And if every $x_i$ has at most $k=3$ bits set to $1$? For $k=1$ the problem is trivial.</p>\n", 'Tags': '<complexity-theory><reference-request><decision-problem>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:32:02.207', 'CommentCount': '0', 'AcceptedAnswerId': '9004', 'CreationDate': '2013-01-17T13:23:39.540', 'Id': '8988'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>For testing automated theorem provers we have <a href="http://www.sfu.ca/~jeffpell/papers/75ATPproblems86.pdf" rel="nofollow">Seventy-Five Problems for Testing\nAutomatic Theorem Provers</a> by Pelletier.</p>\n\n<p>Are there any such standard/well regarded tests for a \u03bb-calculus that verify the evaluation?</p>\n\n<p>EDIT</p>\n\n<p>The best \u03bb-Calculus evaluator I have found so far is:</p>\n\n<p><a href="http://www.itu.dk/people/sestoft/lamreduce/lamframes.html" rel="nofollow">Lambda calculus reduction workbench</a> with info <a href="http://www.itu.dk/people/sestoft/lamreduce/index.html" rel="nofollow">here</a>.</p>\n\n<p>I like this one because<br>\n1. It is a working example that seems to corretly pass every example I can find.<br>\n2. Has a trace option for the output.<br>\n3. Can do multiple reduction strategies<br>\n    * normal order<br>\n    * call-by-name<br>\n    * head spine reduction<br>\n    * call-by-value<br>\n    * applicative order<br>\n    * hybrid normal order<br>\n    * hybrid applicative order<br>\n4. Has a list of pre defined abbreavtions such as<br>\n    * S, K, I<br>\n    * 0 - 5<br>\n    * pair<br>\n    * pred<br>\n    * succ<br>\n    * add<br>\n    * mul<br>\n5. Has source code in SML  </p>\n', 'ViewCount': '145', 'Title': u'Test cases for \u03bb-Calculus', 'LastEditorUserId': '268', 'LastActivityDate': '2013-02-07T02:10:20.710', 'LastEditDate': '2013-02-07T02:10:20.710', 'AnswerCount': '0', 'CommentCount': '10', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '268', 'Tags': '<reference-request><lambda-calculus><software-testing>', 'CreationDate': '2013-01-17T19:51:51.120', 'Id': '9001'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Several years ago I was self learning lisp by a book which I do not remember. As an example there was a recursively defined sequence which was said to be unknown to be finite or not for every input --- to generate a sequence you were required to provide two(?) initial values. At least that is how I remember.</p>\n\n<p>There was a Wikipedia article on it but I can't find it either. Does anyone know what I'm talking about?</p>\n", 'ViewCount': '26', 'Title': 'Name of a sequence that is unknown to stop on a given input', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-01-22T08:23:58.323', 'LastEditDate': '2013-01-22T08:23:58.323', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9085', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6507', 'Tags': '<reference-request><recurrence-relation>', 'CreationDate': '2013-01-22T08:14:20.350', 'Id': '9084'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There is a formula in wikipedia for the general case of josepus problem</p>\n\n<p><a href="http://en.wikipedia.org/wiki/Josephus_problem" rel="nofollow">Josephus Problem</a></p>\n\n<p>But there is no reference for it, I don\'t know where it came from and I need too find out...\nMaybe Donald Knuth\'s Art of Programming?</p>\n', 'ViewCount': '65', 'Title': 'A Formula For Generalized Josephus problem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-25T08:41:27.180', 'LastEditDate': '2013-01-25T08:31:48.273', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6524', 'Tags': '<reference-request><recursion>', 'CreationDate': '2013-01-23T18:46:18.270', 'Id': '9118'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '49', 'Title': 'Cache strategies, what reference article could I study?', 'LastEditDate': '2013-01-28T10:11:13.810', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2100', 'FavoriteCount': '1', 'Body': '<p>So as to optimize an application, I must implement data caching: not to recompute some data - those heavy on cpu but that don\'t change often.</p>\n\n<p>When playing with the idea, I imagined something like the way win32/MFC manages the windows screen i.e.:</p>\n\n<ul>\n<li>While a part is valid, it is not repainted.</li>\n<li>When a rectangle or a region is invalidated, this part is repainted during the next painting session - launched by the OS.</li>\n</ul>\n\n<p>I was imagining a way to validate and invalidate my cached value, so as to recompute only what is necessary when it is necessary.</p>\n\n<p>Then I read <a href="http://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow">this wikipedia page about Cache Algorithms</a>, and none of the listed algorithm was using the technique I explained above. So I feel ill at ease, and I need to read some work about caching. </p>\n\n<p>Do you know of some resources that I could rely on before I start implementing my own cache process ?</p>\n', 'Tags': '<reference-request><efficiency><cpu-cache>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-28T10:18:37.300', 'CommentCount': '3', 'AcceptedAnswerId': '9194', 'CreationDate': '2013-01-27T02:47:20.523', 'Id': '9187'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '157', 'Title': 'Building functionally complete boolean circuits out of trinary logic', 'LastEditDate': '2013-02-22T02:18:36.030', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>There are some not-very-commonly considered forms of <a href="http://en.wikipedia.org/wiki/Three-valued_logic" rel="nofollow">trinary logic</a> using 3 truth values. Even entire (unusual/rare) <a href="http://en.wikipedia.org/wiki/Ternary_computer" rel="nofollow">ternary computers</a> have been built from it.</p>\n\n<blockquote>\n  <p>Is there some knowledge or reference of how to convert some trinary logic systems into functionally complete boolean circuits/logic?</p>\n</blockquote>\n\n<p>"Functionally complete" means all boolean functions can be computed. I am asking the more general question above in case the following more specific question does not have an answer. The motivation is more this specific following case. Consider the following "trinary truth table" for a single trinary operator.</p>\n\n<pre><code>   a b c\n\na  a c a\nb  c b b\nc  a b c\n</code></pre>\n\n<blockquote>\n  <p>Is it possible to somehow create functionally complete boolean circuits out of the single above trinary truth table operator? Or, maybe it can be definitively proven it\'s not possible?</p>\n</blockquote>\n\n<p>I am also looking for any reference to that or something similar. </p>\n', 'Tags': '<reference-request><logic><reductions><circuits>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-02-22T02:18:36.030', 'CommentCount': '4', 'AcceptedAnswerId': '9215', 'CreationDate': '2013-01-27T18:15:08.947', 'Id': '9211'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>SAT [5] can be solved with resolution definitively, i.e. if the formula has a true assignment, resolution can find it, and if it cant be satisfied, resolution can show that no assignment exists (at least in exponential time/space.). [4] </p>\n\n<blockquote>\n  <p>Is there a good fully-self contained description somewhere of solving SAT with resolution?</p>\n</blockquote>\n\n<p>The descriptions on Wikipedia of resolution are focused on a single logical operation, not how to use it in an algorithm to solve SAT, and the Davis Putnam algorithm is described mostly in terms of 1st order logic. I am looking for a description of solving SAT with resolution that does not refer to 1st order logic, just in terms of boolean input variables. Online description is preferred if possible. The connection with DPLL would be helpful also.</p>\n\n<hr>\n\n<p>[1] <a href="http://en.wikipedia.org/wiki/Davis-Putnam_algorithm" rel="nofollow">Davis Putnam algorithm</a>, Wikipedia</p>\n\n<p>[2] <a href="http://en.wikipedia.org/wiki/Resolution_%28logic%29" rel="nofollow">Resolution in logic</a>, Wikipedia</p>\n\n<p>[3] <a href="http://en.wikipedia.org/wiki/DPLL_algorithm" rel="nofollow">Davis Putnam Logemann Loveland algorithm</a>, Wikipedia</p>\n\n<p>[4] <a href="http://cs.stackexchange.com/questions/9095/is-resolution-complete-or-only-refutation-complete">Is resolution complete or only refutation-complete?</a></p>\n\n<p>[5] <a href="http://en.wikipedia.org/wiki/Propositional_satisfiability" rel="nofollow">The boolean satisfiability problem</a></p>\n', 'ViewCount': '118', 'Title': 'Description of resolution algorithm as it applies to SAT', 'LastEditorUserId': '472', 'LastActivityDate': '2013-02-18T22:02:44.297', 'LastEditDate': '2013-02-18T22:02:44.297', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9235', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<algorithms><complexity-theory><reference-request><logic><np-complete>', 'CreationDate': '2013-01-28T01:57:42.843', 'Id': '9233'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have seen a few years back a nice and simple algorithm that, given a (finite) set of words in some alphabet, builds a context-free grammar for a language including these words and in some sense "natural" (e.g., the grammar doesn\'t produce all words in the alphabet). The algorithm is very simple,  it has something like 3--4 rules for grammar transformation attempted on each new word. Any help in finding it would be appreciated.</p>\n', 'ViewCount': '181', 'Title': 'Construct a context-free grammar for a given set of words', 'LastEditorUserId': '6591', 'LastActivityDate': '2013-12-10T07:31:05.390', 'LastEditDate': '2013-01-28T15:39:42.217', 'AnswerCount': '2', 'CommentCount': '9', 'AcceptedAnswerId': '9268', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6591', 'Tags': '<algorithms><formal-languages><reference-request><formal-grammars><machine-learning>', 'CreationDate': '2013-01-28T10:01:35.720', 'Id': '9246'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The <a href="http://en.wikipedia.org/wiki/XOR_linked_list" rel="nofollow">XOR linked list</a> is perhaps the most prominent example of storing a reversible hash of two values and using a known value and the stored hash value to derive the other value.  Is there a term for the general mechanism (or a way to describe it very concisely)?</p>\n\n<p>As a related question, are there other somewhat recognized examples of using this mechanism?</p>\n\n<p>In informally studying computer architecture, I have encountered what I think are two or three examples.  One was a suggestion for a MRU-based cache way predictor by XORing the MRU bit with a bit derived from the address; the derived bit is the "known" value.  The other was a similar, XORing the hysteresis bit of a branch predictor with a bit derived from branch information.  A possible third example might be the agree branch predictor which uses a (possibly static) per-branch prediction to bias entries in a dynamic predictor so that aliasing tends to be non-destructive.  A confirmation that these actually should be recognized as the same general mechanism as used by the XOR linked list would also be helpful.</p>\n', 'ViewCount': '63', 'Title': 'Is there a term for the general method used in XORed linked list?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-30T19:21:20.813', 'LastEditDate': '2013-01-30T12:44:52.830', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4577', 'Tags': '<terminology><reference-request><data-structures><lists>', 'CreationDate': '2013-01-29T19:59:22.903', 'FavoriteCount': '3', 'Id': '9284'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I wonder if two famous (and, IMHO, very nice) recreational problems are been studied in some general form.</p>\n\n<p>Here's the first.\nWe have 13 balls, all looking absolutely the same, with 12 of them having the same weight; we don't know whether the ball that has a different weight is heavier or lighter. We have a balance with two arms and, using it at most 3 times, it is required to identify the ball with different weight. \nFor the generalization below, I will consider a slightly different version of it: same scenario, but requesting the needed minimum number of times by which, in all cases, using the balance we can identify the different ball.</p>\n\n<p>Here's the second.\nWe have three card and we are in front of a door with three slot in which we can insert the cards. Each card is the correct one for exactly one slot and vice versa.\nEach slot is connected to a hidden circuit and, at the beginning, we don't know wheter a circuit is opened or closed (but at least one of them is opened).\nThe door will open only if all three circuits are closed.\nWe can change the state of a circuit solely by inserting all the three cards; when we insert all the cards, the circuits change state according to these rules: if a circuit is closed, it will open; if a circuit is opened, it will close only if the correct card is inserted in its slot.\nIn general, without knowing the initial states of the circuits, what is the minimum number of insertions by which the door will certainly open?</p>\n\n<p>We can generalize the above problems in obvious ways: the first problem by having $n$ balls (possibly, with $k$ of them having different weight), the second problem by having $n$ cards/slots/circuits (possibly, each card being correct for more than a slot/circuit). </p>\n\n<p>Are these general problems new? Any similar and well-studied one?</p>\n", 'ViewCount': '31', 'Title': "On the generalization of two recreational problems: request for references, if there's any", 'LastActivityDate': '2013-01-30T03:26:58.140', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9291', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1665', 'Tags': '<reference-request><combinatorics>', 'CreationDate': '2013-01-30T02:56:52.703', 'Id': '9289'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m having a real hard time solving recurrences using the substitution method.</p>\n\n<p>Show that: $T(n) = T(n/2) + 1$ is $O(\\lg n)$</p>\n\n<p>I thought this to be relatively easy:</p>\n\n<p>We have to show that $T(n) \\leq c \\lg n$</p>\n\n<p>Substitution gives me:</p>\n\n<p>$\\qquad\n  \\begin{align}\n    T(n) &amp;\\leq c \\lg(n/2) + 1 \\\\\n         &amp;= c \\lg n - c \\lg 2 + 1 \\\\\n         &amp;= c \\lg n - c + 1 \\\\\n         &amp;\\leq  c \\lg n\n\\end{align}$ </p>\n\n<p>for every c.</p>\n\n<p>I was under the impression this was it, but when I was looking for an answer, I came around a <a href="http://classes.soe.ucsc.edu/cmps101/Spring11/hw/hw2sol.pdf" rel="nofollow">much more elaborate answer on the web</a>, given  involving subtracting a constant. I don\'t get why that\'s needed, I thought I had shown what was needed.</p>\n\n<p>Any help would be greatly appreciate, starting Monday I\'m enrolled in an algorithms class and I don\'t want to get behind!</p>\n\n<p>We are using the CLRS book (surprise) and though I appreciate the amount of information in it, I\'d rather have some more resources. I\'ve really enjoyed a datastructures class and I really think I can enjoy this as well, but more resources would be very much appreciated.</p>\n', 'ViewCount': '100', 'ClosedDate': '2013-08-07T08:13:19.483', 'Title': 'Solving a simple recurrence', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-07T06:14:56.363', 'LastEditDate': '2013-01-30T20:56:16.523', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '5391', 'Tags': '<reference-request><proof-techniques><recurrence-relation>', 'CreationDate': '2013-01-30T20:13:17.710', 'Id': '9329'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '161', 'Title': 'Convergence of Simulated Annealing Based Algorithms', 'LastEditDate': '2013-01-31T14:01:23.310', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6550', 'FavoriteCount': '2', 'Body': "<p>I designed a simulated annealing-based optimization algorithm. My simulation shows that it converge fast. I am looking for some sort of proof to show that simulation annealing-based algorithm converge fast (based on satisfying some properties) to global/local optimal point and doesn't oscillate in the optimal points (or any related fast about its stability). Are there any useful literature about it?</p>\n", 'Tags': '<algorithms><reference-request><proof-techniques><optimization>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-02T04:03:50.740', 'CommentCount': '7', 'AcceptedAnswerId': '9400', 'CreationDate': '2013-01-31T00:36:58.170', 'Id': '9340'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I don\'t know the right name for this problem, or if there is a name, but it is inspired by my initial interpretation of the title of <a href="http://cs.stackexchange.com/questions/9155/streaming-knapsack-problem">this</a> question (my question is very different, so the link may be misleading). Anyways, my question is this:</p>\n\n<p>We are initially given a list of "items" to be filled in a knapsack of fixed size. Each item has a weight (bounded, integral) and value, and we need to maximize the total value of items in the knapsack. So far, this is identical to the 0/1 Knapsack problem. Now, at each step, we perform one of the following:</p>\n\n<ul>\n<li>Remove the first item in the list (first means encountered earliest)</li>\n<li>Add a new item to the list at the end.</li>\n</ul>\n\n<p>To keep the solution space small, we can assume that the maximum size of the list is fixed, so that it will behave like a fixed size buffer overflow - oldest item is removed before new item is added.</p>\n\n<p>Now, the list is smallish, so the initial instance of the knapsack on the original list can be performed to obtain the first solution. Now, <strong>after <em>every</em> operation</strong> on the list (addition or removal of items), we again want to find out the best way to fill a <strong>new (empty) knapsack with the items in the new list</strong>. And we want to do it <strong>without repeating a full knapsack algorithm</strong> on this slightly modified list (since there will be many such operations).</p>\n\n<p>Is there some way the results of the previous state can be utilized to speed up the process? Is there some information from the previous state that can <em>usually</em> speed up the process? Is there any research on this or some related problem? </p>\n\n<p>The pseudo-polynomial time DP algorithm can be adapted for the case where an item is added (since the table depends on the previous items), but I could not figure out how to deal with it in case the first item is removed from the list. Similarly, a branch-and-bound approach seems pointless. Any ideas or references?</p>\n', 'ViewCount': '189', 'Title': 'Dynamic Knapsack Problem - Algorithms and References', 'LastEditorUserId': '4751', 'LastActivityDate': '2013-02-01T19:15:14.520', 'LastEditDate': '2013-02-01T19:15:14.520', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4751', 'Tags': '<algorithms><reference-request><optimization><combinatorics><knapsack-problems>', 'CreationDate': '2013-02-01T11:46:06.723', 'Id': '9384'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been tasked with building a library of books on algorithms for our small company (about 15 people). The budget is more than 5k, but certainly less than 10k, so I can buy a fair number of books. All people here have at least a Bachelor's degree in CS or a closely related field, so while I will get some basic textbook like Cormen, I'm more interested in good books on advanced topics. (I will get Knuth's 4 volumes, BTW.)</p>\n\n<p>Some list of topics would be:</p>\n\n<ul>\n<li><p>Sorting algorithms</p></li>\n<li><p>Graph algorithms</p></li>\n<li><p>String algorithms</p></li>\n<li><p>Randomized algorithms</p></li>\n<li><p>Distributed algorithms</p></li>\n<li><p>Combinatorial algorithms</p></li>\n<li><p>etc.</p></li>\n</ul>\n\n<p>Essentially I'm looking for good recommendations on books about major topics within CS related to algorithms and data structures. Especially stuff that goes beyond what's typically covered in algorithm and data structure classes as part of a Bachelor's degree at a good school. I know the question is quite fuzzy, since I'm looking for generically useful material. The software we develop is mostly system level stuff handling large amounts of data.</p>\n\n<p>The ideal would also be to find anything that would cover fairly recent cool data structures and algorithms, which most people might not have heard about.</p>\n\n<hr>\n\n<p>EDIT: Here are some preliminary books that I think I should get:</p>\n\n<ul>\n<li><p>Introduction to Algorithms by Cormen et al. </p></li>\n<li><p>Algorithm Design by Kleinberg, Tardos</p></li>\n<li><p>The Art of Computer Programming Vol 1-4 by Knuth</p></li>\n<li><p>Approximation Algorithms by Vazirani</p></li>\n<li><p>The Design of Approximation Algorithms by Williamson, Shmoys</p></li>\n<li><p>Randomized Algorithms by Motwani, Raghavan</p></li>\n<li><p>Introduction to the Theory of Computation by Sipser</p></li>\n<li><p>Computational Complexity by Arora, Barak</p></li>\n<li><p>Computers and Intractability by Garey and Johnson</p></li>\n<li><p>Combinatorial Optimization by Schrijver</p></li>\n</ul>\n\n<p>A few other books my colleagues wanted that deal with techniques and algorithms for language design, compilers and formal methods are:</p>\n\n<ul>\n<li><p>Types and Programming Languages by Pierce</p></li>\n<li><p>Principles of Model Checking by Baier, Katoen</p></li>\n<li><p>Compilers: Principles, Techniques, and Tools by Aho, Lam, Sethi, Ullman</p></li>\n<li><p>The Compiler Design Handbook: Optimizations and Machine Code Generation, Second Edition by Srikant, Shankar</p></li>\n<li><p>The Garbage Collection Handbook: The Art of Automatic Memory Management by Jones, Hosking, Moss</p></li>\n</ul>\n", 'ViewCount': '368', 'Title': 'Algorithm books on a range of topics', 'LastEditorUserId': '6675', 'LastActivityDate': '2013-02-02T21:46:22.347', 'LastEditDate': '2013-02-02T19:14:58.860', 'AnswerCount': '5', 'CommentCount': '10', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6675', 'Tags': '<algorithms><reference-request><data-structures><books>', 'CreationDate': '2013-02-02T05:57:06.183', 'FavoriteCount': '2', 'Id': '9413'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There is the well-known method of unbiasing of bit sequences due to von Neumann. Are there similar schemes applicable to other sequences, e.g. the result of throwing a normal die?</p>\n', 'ViewCount': '68', 'Title': 'Unbiasing of sequences', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-04T16:46:37.613', 'LastEditDate': '2013-02-04T15:48:25.047', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6437', 'Tags': '<reference-request><probability-theory>', 'CreationDate': '2013-02-04T11:48:38.783', 'Id': '9469'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am considering what elements an operating system for Network On Chip systems might have and the issue of file systems looms large. NoCs have an embedded heritage, and their domain of use (at least initially) is likely to be similar tasks to embedded systems.</p>\n\n<p>But I cannot find any studies of embedded system file access patterns - there are a number of published studies on scientific and super computing file access patterns I have been able to read but nothing on embedded systems.</p>\n\n<p>Can anyone point me to some good papers on this?</p>\n', 'ViewCount': '48', 'Title': 'Studies of file access patterns in embedded systems', 'LastEditorUserId': '39', 'LastActivityDate': '2013-04-06T20:02:27.383', 'LastEditDate': '2013-02-04T23:31:05.717', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'OwnerDisplayName': 'adrianmcmenamin', 'PostTypeId': '1', 'OwnerUserId': '6712', 'Tags': '<reference-request><parallel-computing><filesystems>', 'CreationDate': '2013-02-03T23:04:39.543', 'Id': '9487'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '269', 'Title': 'Are link-cut trees ever used in practice, for max flow computation or other applications?', 'LastEditDate': '2013-02-05T10:22:43.413', 'AnswerCount': '2', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '6701', 'FavoriteCount': '2', 'Body': '<p>Many max flow algorithms that I commonly see implemented, Dinic\'s algorithm, push relabel, and others, can have their asymptotic time cost improved through the use of <a href="http://en.wikipedia.org/wiki/Link/cut_tree">dynamic trees</a> (also known as link-cut trees).</p>\n\n<ul>\n<li>Push relabel runs in $O(V^2E)$ or $O(V^3)$ or $O(V^2\\sqrt{E})$ normally, but with dynamic trees $O(VE \\log(V^2/E))$</li>\n<li>Dinic\'s algorithm runs in $O(V^2E)$, but with dynamic trees $O(VE\\log(V))$</li>\n</ul>\n\n<p>However, practical implementations of max-flow algorithms in most libraries don\'t seem to make use of this data structure.  Are dynamic trees ever used in practice for max flow computation? Or do they carry too much overhead to be useful for real world problem sizes?</p>\n\n<p>Are there any other problem domains where link cut trees are used?</p>\n\n<p>This question is related to a question that I asked on cstheory: <a href="http://cstheory.stackexchange.com/questions/16347/are-any-of-the-state-of-the-art-maximum-flow-algorithms-practical">Are any of the state of the art Maximum Flow algorithms practical?</a></p>\n', 'Tags': '<reference-request><graphs><data-structures><network-flow>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-05T21:59:44.773', 'CommentCount': '2', 'AcceptedAnswerId': '9521', 'CreationDate': '2013-02-05T04:36:34.087', 'Id': '9501'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>As a hobby, I have written a basic computer algebra system. My CAS handles expressions as trees. I have advanced it to the point where it can simplify expressions symbolically (i.e., sin(pi/2) returns 1), and all expressions can be reduced to a canonical form.  The CAS can also differentiate expressions.</p>\n\n<p>Using this paradigm, what kinds of algorithms are there for solving equations? An equation in my model would be represented as an (=) tree with two subtrees that are the left and right expressions. I know there is no "magic bullet" for solving all equations, but are there algorithms out there that are designed to symbolically solve an equation? If there aren\'t, what would be the general approach? What kind of classes can equations be split into (so that I might be able to implement an algorithm for each kind)? I don\'t want to use naive methods and then paint myself into a metaphorical corner.</p>\n', 'ViewCount': '136', 'Title': 'Computer Algebra: Algorithms for solving equations symbolically', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-09T09:37:37.693', 'LastEditDate': '2013-02-06T07:56:43.630', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6727', 'Tags': '<reference-request><computer-algebra>', 'CreationDate': '2013-02-06T07:02:12.597', 'Id': '9538'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '2244', 'Title': 'What use are groups, monoids, and rings in database computations?', 'LastEditDate': '2013-02-11T19:38:25.807', 'AnswerCount': '6', 'Score': '22', 'PostTypeId': '1', 'OwnerUserId': '3131', 'FavoriteCount': '21', 'Body': '<p>Why would a company like Twitter be interest in algebraic concepts like groups, monoids and rings. <a href="https://github.com/twitter/algebird">https://github.com/twitter/algebird</a></p>\n\n<p>All I could find is:</p>\n\n<blockquote>\n  <p>Implementations of Monoids for interesting approximation algorithms,\n  such as <a href="http://stackoverflow.com/questions/14790588/what-is-twitters-interest-in-abstract-algebra">Bloom filter</a>, <a href="http://stackoverflow.com/questions/12327004/how-does-the-hyperloglog-algorithm-work">HyperLogLog</a> and <a href="http://dimacs.rutgers.edu/~graham/pubs/papers/cmencyc.pdf">CountMinSketch</a>. These allow you\n  to think of these sophisticated operations like you might numbers, and\n  add them up in hadoop or online to produce powerful statistics and\n  analytics.</p>\n</blockquote>\n\n<p>and in another part of the GitHub page:</p>\n\n<blockquote>\n  <p>It was originally developed as part of Scalding\'s Matrix API, where\n  Matrices had values which are elements of \n  <a href="http://en.wikipedia.org/wiki/Monoid#Relation_to_category_theory">Monoids</a>, <a href="http://en.wikipedia.org/wiki/Group_%28mathematics%29">Groups</a>, or <a href="http://www.math.ku.dk/~gelvin/Modules.pdf">Rings</a>. Subsequently, it was clear that the code had broader application\n  within Scalding and on other projects within Twitter.</p>\n</blockquote>\n\n<p>What could this broader application be? within Twitter and for general interest?</p>\n\n<hr>\n\n<p>It seems like composition aggregations of databases have a monoid-like structure.</p>\n\n<p>Same question on quora: \n<a href="http://www.quora.com/Twitter-1/What-is-Twitters-interest-in-abstract-algebra-with-algebird">http://www.quora.com/Twitter-1/What-is-Twitters-interest-in-abstract-algebra-with-algebird</a></p>\n\n<hr>\n\n<p>I have math background but I\'m not computer scientist. It would be great to have "real-world" uses of monoids and semi-groups.  These are normally considered useless theoretical constructs, and ignored in many abstract algebra courses (for lack of anything interesting to say).</p>\n', 'Tags': '<reference-request><discrete-mathematics><database-theory><applied-theory><group-theory>', 'LastEditorUserId': '3131', 'LastActivityDate': '2013-02-11T23:40:20.447', 'CommentCount': '5', 'AcceptedAnswerId': '9687', 'CreationDate': '2013-02-10T21:59:23.007', 'Id': '9648'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was reading the ADA 95 reference manual. I came across these  two words in annexes \n Normative and informative . I couldnt find the difference between those. Your help will  be much appreciated.</p>\n', 'ViewCount': '232', 'Title': 'Difference between Normative annexes and Informative annexes in ADA 95', 'LastActivityDate': '2013-02-11T02:47:40.117', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9658', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7004', 'Tags': '<reference-request><programming-languages><books>', 'CreationDate': '2013-02-11T02:20:37.720', 'Id': '9657'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am reading on concurrent processes and algorithms which find infinite processes by searching the process graph recursively. </p>\n\n<p>Most of the material I have found is not for beginners. I am looking for references / algorithms that can help me understand:</p>\n\n<ol>\n<li>What are process graphs?</li>\n<li>How to search for infinite processes in these graphs?</li>\n</ol>\n\n<p>Thanks in advance</p>\n', 'ViewCount': '57', 'Title': 'Process graphs and finding infinite processes', 'LastActivityDate': '2013-02-20T09:10:02.277', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9962', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6854', 'Tags': '<reference-request><concurrency><process-algebras>', 'CreationDate': '2013-02-13T01:34:04.573', 'Id': '9727'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for a good survey/study of experimental results of heuristics for Knapsack problem (or implemented libraries in java/c++). Any help is appreciated!</p>\n', 'ViewCount': '92', 'Title': 'Experimental Survey on Different Heuristics for Knapsack Problem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-14T06:38:43.647', 'LastEditDate': '2013-02-14T06:38:43.647', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6550', 'Tags': '<reference-request><np-complete><optimization><heuristics>', 'CreationDate': '2013-02-13T16:57:46.143', 'Id': '9747'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What are some research papers which are really fundamental and led to the birth of a new field of study or a novel idea in Computer-Science?</p>\n', 'ViewCount': '133', 'ClosedDate': '2013-02-18T11:35:08.297', 'Title': 'Research papers in Computer Science', 'LastActivityDate': '2013-02-20T04:24:20.527', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2822', 'Tags': '<reference-request><research>', 'CreationDate': '2013-02-18T04:42:13.227', 'Id': '9883'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'ve taken an introductory database course where like many good database courses, they taught relational algebra, including $\\theta$-joins. However, I\'ve recently read E. F. Codd\'s 1970 paper, <a href="http://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf" rel="nofollow"><em>A Relational Model of Data for Large Shared Databanks</em></a>, and the concept of $\\theta$-joins is nowhere to be found. He does use the symbol  $\\theta$ in the paper in section 2.2 though, but to refer to something much more general than joins.</p>\n\n<p>In fact, Natural Joins are even defined slightly differently then the definition I\'m familiar with. It requires that the original relations be completely recoverable from the joined relation.</p>\n\n<p>So my question is when/in what paper/by who was the modern notion of the $\\theta$-join introduced that is often taught by universities? </p>\n\n<p><a href="http://en.wikipedia.org/wiki/Relational_algebra#.CE.B8-join_and_equijoin" rel="nofollow">(A link to Wikipedia\'s definition of a $\\theta$-join, similar to the one I learned in my course)</a></p>\n', 'ViewCount': '98', 'Title': 'Origin of theta-joins', 'LastActivityDate': '2013-03-03T05:53:03.093', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10211', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7046', 'Tags': '<reference-request><history><relational-algebra>', 'CreationDate': '2013-02-28T22:56:28.393', 'FavoriteCount': '1', 'Id': '10158'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for practical applications of Finite State Machines like DFA, NFA, Moore, Mealy machines...</p>\n\n<p>It would be helpful if someone point to examples from Linux Kernel. I know that DFA is used in string matching like KMP algorithm.</p>\n\n<p>What is the significance of NFA, Moore and Mealy machines?</p>\n', 'ViewCount': '1145', 'Title': 'Practical application of Finite State Machines', 'LastActivityDate': '2013-03-06T19:32:54.840', 'AnswerCount': '4', 'CommentCount': '3', 'AcceptedAnswerId': '10290', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '947', 'Tags': '<reference-request><automata><finite-automata>', 'CreationDate': '2013-03-05T03:25:55.350', 'FavoriteCount': '3', 'Id': '10280'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I think half the battle in answering this question lies in formulating it precisely! A search engine doesn\'t turn up much, so I was wondering if this is a well-known or well-studied question.</p>\n\n<p>My thoughts: I think the most straightforward way to formulate this question is as in my title: Given constants $t,s,k \\in \\mathbb{N}$, how many TMs are there that run in $t$ steps or fewer on all inputs of size $k$, and how many TMs are there that use $s$ tape squares or fewer on all inputs of size $k$? This seems like the most direct and simple way to ask the question, but we might want to restate it in a different way -- for example, given a function $p(k)$, how many TMs are there that run in time $p(k)$ on inputs of size $k$ for all $k$ (or how "dense" are these TMs)? This seems harder to me.</p>\n\n<p>We should probably fix a tape alphabet (or a Godel numbering??). We could consider two TMs with different but isomorphic state diagrams to be the same or different, either way.</p>\n\n<p>The immediate problem is that there are an infinite number: Take any TM that satisfies the criteria and add "dead states". I can think of two ways to deal with this. The first (which I don\'t like) is to add an additional parameter: how many TMs whose description has length $\\leq L$ satisfy the criteria? The second (which I prefer) is to consider two TMs <em>equivalent</em> on inputs of size $\\leq k$ if, for all such inputs, the TMs have exactly the same behavior (enter the same states and write/move on the tape identically). Then we would restrict to the minimal TM in each equivalence class, or just ask how many equivalence classes satisfy the criteria.</p>\n\n<p>Edit: As pointed out by Vor in the comments, the problem with the second approach is that it\'s basically the same as a circuit at that point. So how about the first one? Or is there a nicer way to formalize this question?</p>\n\n<p>Any references/literature, thoughts, or answers would be very interesting and appreciated!</p>\n', 'ViewCount': '129', 'Title': 'How many Turing Machines are there that run in time $t$ or in space $s$ on inputs of length $k$?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-07T12:15:33.460', 'LastEditDate': '2013-03-06T07:13:07.320', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4197', 'Tags': '<complexity-theory><reference-request><turing-machines><combinatorics>', 'CreationDate': '2013-03-05T17:46:58.547', 'Id': '10298'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '169', 'Title': 'Top Turing machine simulators on the web?', 'LastEditDate': '2013-03-09T02:47:07.830', 'AnswerCount': '3', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>There are many Turing machine simulators on the web of varying degrees of sophistication and can be highly useful for pedagogical purposes for students of widely varying ages, and they also have advanced theoretical value. </p>\n\n<p>What is a useful TM simulator available and what are its particular discriminating features that differ from other TM simulators available such that one would choose it and not another?</p>\n', 'ClosedDate': '2013-03-10T17:39:58.637', 'Tags': '<reference-request><turing-machines><compilers><education>', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-03-09T02:47:07.830', 'CommentCount': '7', 'AcceptedAnswerId': '10383', 'CreationDate': '2013-03-08T03:32:19.103', 'Id': '10379'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for good resources which have classified and solved typical large scale data processing in MapReduce framework (like graph algorithms, statistics, numerical algorithms ...). Any help is appreciated!</p>\n', 'ViewCount': '240', 'Title': 'Problem Solving in MapReduce Framework', 'LastEditorUserId': '157', 'LastActivityDate': '2013-03-17T21:28:11.707', 'LastEditDate': '2013-03-17T21:28:11.707', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '6550', 'Tags': '<algorithms><reference-request><parallel-computing>', 'CreationDate': '2013-03-11T16:34:31.853', 'FavoriteCount': '2', 'Id': '10453'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I\'m trying to figure out what are currently the two most efficent algorithms that permit, starting from a Left/Right pair of stereo images created using a traditional camera (so affected by some epipolar lines misalignment), to produce a pair of adjusted images plus their depth information by looking at their disparity.</p>\n\n<p>Actually I\'ve found lots of papers about these two methods, like:</p>\n\n<ul>\n<li>"Computing Rectifying Homographies for Stereo Vision" (Zhang - seems one of the best for rectification only)</li>\n<li>"Three-step image recti\ufb01cation" (Monasse)</li>\n<li>"Rectification and Disparity" (slideshow by Navab)</li>\n<li>"A fast area-based stereo matching algorithm" (Di Stefano - seems a bit inaccurate)</li>\n<li>"Computing Visual Correspondence with Occlusions via Graph Cuts" (Kolmogorov - this one produces a very good disparity map, with also occlusion informations, but is it efficient?)</li>\n<li>"Dense Disparity Map Estimation Respecting Image Discontinuities" (Alvarez - too long for a first review)</li>\n</ul>\n\n<p>Could someone please give me some advice for diving into this wide topic? </p>\n\n<p>What kind of algorithm/method should I treat first, considering that I\'ll work on a very simple input: a pair of left and right images and nothing else, no more information (some papers are based on additional, pre-obtained, calibration information)?</p>\n\n<p>Speaking about working implementations, the only interesting results I\'ve seen so far belongs to <a href="http://stereo.jpn.org/eng/stphmkr/index.html" rel="nofollow">this</a> piece of software, but only for automatic rectification, not disparity.</p>\n\n<p>I tried the "auto-adjustment" feature and it seems really effective. Too bad there is no source code.</p>\n', 'ViewCount': '120', 'Title': 'Stereo images rectification and disparity: which algorithms?', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-03-17T18:19:58.393', 'LastEditDate': '2013-03-17T18:19:58.393', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7314', 'Tags': '<algorithms><reference-request><image-processing>', 'CreationDate': '2013-03-17T16:33:52.137', 'FavoriteCount': '1', 'Id': '10584'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There is a land divided to $D$ districts.</p>\n\n<p>There are $C$ citizens.</p>\n\n<p>We want to divide the land to the citizens, such that each citizen receives a single land-plot in a single district.</p>\n\n<p>Each citizen prefers certain districts, however, the preference also depends on the size of plot. For example, Johnny prefers a plot of 1 dunam in the North to a plot of the 1 dunam in the South, however, he also prefers a plot of 1 dunam in the South to a plot of 0.5 dunams in the North.</p>\n\n<p>Ideally, we would like to divide the land in an envy-free manner, such that no citizen thinks that the plot given to another citizen is better (according to his subjective preferences) than the plot given to him.</p>\n\n<p>However, this is not always possible. For example, suppose there are 2 districts (North and South), each of size 1 dunam, and 3 citizens, all have the same preferences as Johnny. If two of them get a plot in the North and the third gets a plot in the South, then the first two get only 0.5 dunam each, and so they envy the third who gets 1 dunam. The other divisions are even worse (In the singular case where all citizens get 1/3 dunam in the North and the South remains empty, assume that it is invaded by a fourth citizen, so that all 3 citizens now envy the invader).</p>\n\n<p>So, I am looking for a procedure that will minimize the envy - whatever that means.</p>\n\n<p>Note that, in contrast to the standard <a href="http://en.wikipedia.org/wiki/Envy-free" rel="nofollow">envy-free cake-division algorithms</a>, I am not interested in geometric cuts of the land - the division of land to districts is pre-determined, and each person can get a plot in only one district.</p>\n', 'ViewCount': '63', 'Title': 'Minimal-envy land division', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-03-28T17:19:44.837', 'LastEditDate': '2013-03-27T01:27:18.037', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10746', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><game-theory>', 'CreationDate': '2013-03-21T06:23:21.400', 'Id': '10679'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '150', 'Title': 'Getting started with Program Analysis', 'LastEditDate': '2013-03-23T16:25:07.047', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '758', 'FavoriteCount': '0', 'Body': '<p>I\'m looking for resources on getting started with <a href="http://en.wikipedia.org/wiki/Program_analysis" rel="nofollow">program analysis</a>.</p>\n\n<p>The only book I\'ve found on the topic is the <a href="http://www.amazon.ca/Principles-Program-Analysis-Flemming-Nielson/dp/3540654100" rel="nofollow">Nielson &amp; Nielson</a> book.</p>\n\n<p>Other than that, it seems like there are only "compiler" books where "program analysis" would be a chapter, or something along those lines. </p>\n\n<p>Do people know of any other resources?</p>\n', 'Tags': '<reference-request><compilers><semantics>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-24T21:06:22.787', 'CommentCount': '2', 'AcceptedAnswerId': '10726', 'CreationDate': '2013-03-22T20:09:12.373', 'Id': '10696'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><em>Recently, I asked a <a href="http://math.stackexchange.com/q/334581/17111">question</a> on Math SE. No response yet. This question is related to that question, but more technical details toward computer science.</em></p>\n\n<p>Given two DFAs $A = (Q, \\Sigma, \\delta, q_1, F_1)$ and $B = (Q, \\Sigma, \\delta, q_2, F_2)$ where the set of states, the input alphabet and the transition function of $A$ and $B$ are the same, the initial states and the final(accepting) states could be different. Let $L_1$ and $L_2$ be the languages accepted by $A$ and $B$, respectively.</p>\n\n<p>There are four cases:</p>\n\n<ol>\n<li>$q_1 = q_2$ and $F_1 = F_2$.</li>\n<li>$q_1 \\neq q_2$ and $F_1 = F_2$.</li>\n<li>$q_1 = q_2$ and $F_1 \\neq F_2$.</li>\n<li>$q_1 \\neq q_2$ and $F_1 \\neq F_2$.</li>\n</ol>\n\n<p>My question is</p>\n\n<blockquote>\n  <blockquote>\n    <p>What are the differences between $L_1$ and $L_2$\n     in cases 2, 3 and 4?</p>\n  </blockquote>\n</blockquote>\n\n<p>I have a more specific question along this line,</p>\n\n<p>The transition monoid of an automaton is the set of all functions on the set of states\ninduced by input strings. See <a href="http://en.wikipedia.org/wiki/Semiautomaton">the page</a> for more details. The transition monoid can be regarded as a monoid acting on the set of states. See this <a href="http://en.wikipedia.org/wiki/Semigroup_action">Wiki page</a> for more details.</p>\n\n<p>In many literatures, an automaton is called strongly connected when the monoid action is transitive, i.e. there is always at least one transition (input string) from one state to another state.</p>\n\n<blockquote>\n  <blockquote>\n    <p>If $A$ and $B$ are strongly connected automata, what are the differences between $L_1$ and $L_2$ in cases 2, 3 and 4 above?</p>\n  </blockquote>\n</blockquote>\n\n<p>Any literatures discussing these issues in details?</p>\n\n<p>I have searched many books and articles and found nothing helpful so far. I believe I don\'t have the appropriate key words yet. Thus I am seeking help. Any pointers/references will be appreciated very much.</p>\n', 'ViewCount': '170', 'Title': 'Difference between the languages accepted by two DFAs with different initial state/accepting states?', 'LastActivityDate': '2013-03-24T11:48:30.127', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '10737', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '630', 'Tags': '<formal-languages><reference-request><finite-automata>', 'CreationDate': '2013-03-24T03:40:45.747', 'FavoriteCount': '1', 'Id': '10733'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '192', 'Title': 'Job scheduling with a bottleneck problem', 'LastEditDate': '2013-03-29T08:50:28.533', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '3', 'Body': '<p>Given $n$ jobs $J_1,J_2,...,J_n$, each job requires $T_i &gt; 0, T_i \\in N$ time to complete.</p>\n\n<p>Each job must be pre-processed and post-processed by a single machine M that can handle only <em>1 job at a time</em> and both phases require 1 unit of time. After being pre-processed, job $J_i$ is sent to a machine with unlimited power (that can handle in parallel an unlimited number of jobs) and it will be ready in time $T_i$, then it must be sent (<strong>immediately</strong>) to machine M again for post-processing. </p>\n\n<p><img src="http://i.stack.imgur.com/Y3BVv.png" alt="enter image description here"></p>\n\n<p>The associated decision problem is:</p>\n\n<p><em>Input:</em> the processing times $T_i &gt;0, T_i \\in \\mathbb{N}$ of $N$ jobs, an integer $K\\geq 2N$<br>\n<em>Question:</em> can we process all the jobs in time $\\leq K$ using the above "bottleneck" model ?</p>\n\n<blockquote>\nHas this problem a name?<br>\nWhat is its complexity? (is it in $\\sf{P}$ or is it $\\sf{NP}$-complete?)\n</blockquote>\n\n<p><strong>UPDATE 29 March:</strong><br>\nAs correctly noticed by M.Cafaro in his answer, the problem is similar to the \n<em>Unconstrained Minimum Finish Time Problem (UMFT)</em> (see Chapter 17 of \n<a href="http://books.google.it/books?id=MAY1ZstmGPkC">Handbook of Scheduling Algorithms</a>) which is $\\sf{NP}$-hard (proved in\n W. Kern and W. Nawijn, "Scheduling multi-operation jobs with time lags on a single machine", University of Twente, 1993). As I can see, there are some differences because in my model:</p>\n\n<ul>\n<li>the pre/post processing time is constant (1 unit of time)</li>\n<li>as soon as the job is completed it must immediately be post-processed (the UMFT model allows delays)</li>\n</ul>\n\n<p>I didn\'t found the Kern &amp; Nawijn proof online, so I still don\'t know if the above restrictions change the difficulty of the problem.</p>\n\n<p>Finally you can think the whole process like a single <em>cook robot</em> with a big oven; the robot can prepare different types of foods one at a time (all require the same time of preparation), put them in the oven, and as soon as they are cooked it must remove them from the oven and add some cold ingredients ... the "<em>cook robot problem</em>" :-)</p>\n', 'Tags': '<complexity-theory><reference-request><scheduling>', 'LastEditorUserId': '140', 'LastActivityDate': '2013-06-21T18:54:32.070', 'CommentCount': '11', 'AcceptedAnswerId': '12822', 'CreationDate': '2013-03-28T11:49:30.607', 'Id': '10869'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am interested in procedures for fair division of land (i.e. envy-free division, or at least proportional division).</p>\n\n<p>In contrast to the well-studied cake-division problem, land-division is two-dimensional, i.e., the preferences of the users may vary both horizontally and vertically. Therefore, it is not practical to limit the algorithm to parallel cuts.</p>\n\n<p>The only reference I found so far is <a href="http://www.worldscientific.com/doi/pdf/10.1142/S0218843009002051">Karthik Iyer and Michael Huhns, 2007</a>. They say that "We have not come across any constructive (algorithmic) solutions so far to the generic land division problem. All the papers have\noffered existential solutions to qualified versions of the problem."</p>\n\n<p>They themselves prove an O(n^2) algorithm for proportional land division, with certain limitations (e.g. each of the n agents must mark n rectangular regions with utility 1/n, and if the rectangles don\'t overlap too much, the algorithm guarantees that each agent gets one of its rectangles).</p>\n\n<p>Do you know of any newer references on this problem? I am interested specifically in practical algorithms, and they may be approximate.</p>\n', 'ViewCount': '121', 'Title': 'Fair division of two-dimensional cake', 'LastActivityDate': '2013-12-24T22:12:15.823', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><game-theory>', 'CreationDate': '2013-03-28T18:58:59.287', 'FavoriteCount': '1', 'Id': '10877'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Do you know of any kind of decomposition of graphs that involves centers, especially in the context of parametrized complexity? If so, please provide some reference. If not, do you see any reason (other than the potentially large size of centers) why such a notion isn\'t fruitful (e.g. subsumed by other notion)?</p>\n\n<p>I\'m looking for something similar to this:</p>\n\n<p>Let $G=(V,E)$ be an undirected graph. Its <em>central decomposition</em> is</p>\n\n<ul>\n<li>If $G$ is not connected: the set of central decompositions of its connected components.</li>\n<li>If $G$ is self-centered (radius equals diameter): $G$</li>\n<li>If $G$ is connected and not self-centered and its center is $C$: the pair $(I,O)$ where $I$ is the central decomposition of $G[C]$ and $O$ is the central decomposition of $G[V\\setminus C]$ (induced subgraphs of center and its complement)</li>\n</ul>\n\n<p>Its <em>central width</em> shall be the size of largest self-centered graph which appears in its central decomposition.</p>\n\n<p>The notion may also use other concepts (like complements, trees etc.), but it should use centers recursively. There is no need for uniqueness.</p>\n\n<p>I\'m <strong>not looking for</strong> e.g. <em>path distance decompositions</em> (see <a href="http://igitur-archive.library.uu.nl/math/2007-0104-200209/bodlaender_97_isomorphism.pdf" rel="nofollow">here</a>) where the root is the center, i.e. a map $d$ of a path $\\{p_0,\\dots,p_k\\}$ to $V$ where $d(p_i)=\\{v\\in V\\mid \\min_{c \\in C}\\mathrm{dist}(v,c) = i\\}$ ($C$ being the center of $G$).</p>\n', 'ViewCount': '58', 'Title': 'Decomposition of graphs that uses centers', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-04-03T15:31:28.617', 'LastEditDate': '2013-04-03T15:31:28.617', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><graph-theory><reference-request><parametrized-complexity>', 'CreationDate': '2013-03-29T21:09:20.307', 'Id': '10903'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Can anyone suggest me some good books on cryptography? I have just starting studying cryptography but I know elementary number theory, abstract algebra and algorithms. Also please mention the difficulty level of the book. </p>\n', 'ViewCount': '998', 'Title': 'A good introductory book on cryptography', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-02T07:48:42.810', 'LastEditDate': '2013-04-02T07:48:42.810', 'AnswerCount': '4', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '778', 'Tags': '<reference-request><cryptography><books>', 'CreationDate': '2013-03-31T16:45:31.587', 'Id': '10938'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>A graph $G$ is chordal if it doesn't have induced cycles of length $4$ or more. A clique tree $T$ of $G$ is a tree in which the vertices of the tree are the maximal cliques of $G$. An edge in $T$ corresponds to a minimal separator. The number of distinct clique trees can be exponential in the number of vertices in a chordal graph. </p>\n\n<p>The <em>reduced clique graph</em> $C_r(G)$ is the union of all clique trees of $G$. That is, it has all the same vertices, and all possible edges. What is the complexity of computing $C_r(G)$ for a given $G$?</p>\n\n<p>I think I once saw a presentation claiming $C_r(G)$ can be computed in $O(m+n)$ time without proof. This would mean it is as easy as computing a clique tree of $G$. Is there a reference that confirms this, or gives a slower algorithm for computing it?</p>\n", 'ViewCount': '118', 'Title': 'Given a chordal graph $G$, what is the complexity of computing the reduced clique graph $C_r(G)$?', 'LastActivityDate': '2013-07-20T21:55:57.460', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13369', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<algorithms><graph-theory><reference-request>', 'CreationDate': '2013-04-02T21:23:52.710', 'FavoriteCount': '1', 'Id': '10979'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am running some experiments with a maze, and trying different variations of A*. Based on my experiments, I have been able to form some opinion (that at least in those cases, graph checking is better than IDA). </p>\n\n<p>I am looking for online articles that have done similar experiments, comparing variations of A* with respect to expanded nodes, but have not come across anything concrete.</p>\n', 'ViewCount': '81', 'Title': 'Comparing variations of A*', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:52:54.573', 'LastEditDate': '2013-04-08T14:52:54.573', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '11136', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6966', 'Tags': '<algorithms><reference-request><artificial-intelligence><search-algorithms><empirical-research>', 'CreationDate': '2013-04-05T22:21:35.823', 'Id': '11067'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The context-free languages are <em>not</em> closed under complement, we know that.</p>\n\n<p>As far as I understand, context-free languages that are a subset of $a^*b^*$ for some letters $a,b$ are closed under complement(!?)</p>\n\n<p>Here is my argument. Each CF language $L$ has a semi-linear Parikh image $\\pi(L) = \\{ (m,n) \\mid a^mb^n \\in L \\}$. Semilinear sets are closed under complement. The set of vectors that represent the semi-linear set can easily be transformed into a linear grammar.</p>\n\n<p><strong>Question.</strong> Is there an easily accessible reference to this fact?</p>\n\n<p>Technically these languages are called <em>bounded</em>, i.e., a subset of $w_1^* \\dots w_k^*$ for some words $w_1,\\dots,w_k$.</p>\n\n<p>My motivation for this question is from a recent <a href="http://cs.stackexchange.com/questions/11106/why-is-the-following-language-not-context-free">question</a> on the context-freeness of $\\{ a^nb^m \\mid n^2 \\neq m \\}$. Its complement within $a^*b^*$ seems easier to handle.</p>\n', 'ViewCount': '277', 'Title': 'Are context-free languages in $a^*b^*$ closed under complement?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T19:08:24.873', 'LastEditDate': '2013-04-07T20:00:05.160', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '11142', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '4287', 'Tags': '<formal-languages><reference-request><context-free><closure-properties>', 'CreationDate': '2013-04-07T19:05:16.153', 'Id': '11110'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '59', 'Title': 'Independent set where two vertices need to have distance >= c', 'LastEditDate': '2013-04-08T03:03:23.500', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4259', 'FavoriteCount': '1', 'Body': "<p>An independent set (IS) in a graph is a set $V' \\subseteq V(G)$ of pairwise non-adjacent vertices. </p>\n\n<p>I am interested in the generalization $c$-IS where two nodes in  $V' \\subseteq V(G)$ need to have distance at least $c$ to any other vertex in $V'$.</p>\n\n<p>Has this problem been studied before? </p>\n", 'Tags': '<algorithms><reference-request><graphs>', 'LastEditorUserId': '4259', 'LastActivityDate': '2013-04-08T03:23:27.007', 'CommentCount': '1', 'AcceptedAnswerId': '11131', 'CreationDate': '2013-04-08T02:56:45.800', 'Id': '11129'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>If I am given a graph which forms a tree, I am interested in finding a vertex which maximizes the minimum distance to any leaf.</p>\n\n<p>I am sure this problem has been studied before.\nDoes anybody know the name of this problem or an algorithm for solving it?</p>\n', 'ViewCount': '250', 'Title': 'Given a tree, find a vertex which maximizes the minimum distance to any leaf', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-10T22:49:24.883', 'LastEditDate': '2013-04-10T21:35:43.710', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '11212', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7675', 'Tags': '<algorithms><graph-theory><reference-request><trees>', 'CreationDate': '2013-04-10T21:05:36.970', 'Id': '11208'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The Kolmogorov complexity of a string $x$ is the size of the smallest Turing machine $M$ that started on empty tape produces $x$. To make it computable, we can add a bound on the time used by $M$ to produce $x$: </p>\n\n<p>$C^{t}(x) = \\min \\{|M| : U(M) = x$ in less than $t(n)$ steps $ n = |x| \\}$ </p>\n\n<p>And for a nice function $f(n) &lt; n$ we can define:</p>\n\n<p>$C[f(n),t(n)] = \\{x : C^t(x) \\leq f(n), n = |x| \\}$</p>\n\n<p>i.e. the set of compressible strings $x$ (whose compressed program has size less than $f(n)$) and that can be generated in time $t(n)$.</p>\n\n<p>For example, for unbounded $f$, we have $C[f(n),n^k] \\subseteq C[f(n),n^{k+1}] \\subset C[f(n),\\infty]$</p>\n\n<blockquote>\n<ul><li>Is the first inclusion tight?</li>\n<li>What is known about the *size* of $C[f(n), n^{k+1}] \\setminus C[f(n), n^{k}]$ ?</li>\n<li>Are there known results for particular classes like $C[n/2,n^k]$?</li>\n</ul>\n</blockquote>\n', 'ViewCount': '51', 'Title': 'Interval density of time bounded Kolmogorov complexity', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-11T07:34:56.750', 'LastEditDate': '2013-04-11T07:34:56.750', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<complexity-theory><reference-request><descriptive-complexity><kolmogorov-complexity>', 'CreationDate': '2013-04-10T22:52:05.313', 'Id': '11214'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>It seems, from a quick (and incomprehensive) survey of the literature (e.g. N. Ailon, B. Chazelle, SIAM J. Comput. 39 (2009), 302-322.) that there are many fast algorithms (and constructions) for the Johnson-Lindenstrauss transform: $f \\in \\mathbb{R}^{d} \\to \\mathbb{R}^{k}$, for $n$ points in $\\mathbb{R}^d$ and $k \\in O(\\log n/\\epsilon)$. I'm interested in computing the <em>inverse</em> of J-L transform. I assume it is not unique in general. Are there any references I should be reading on the inverse transform of J-L?</p>\n\n<p>If I understand correctly, the FJLT transform (sparse times Hadamard times diagonal) can be represented by a matrix $R = PHD \\in \\mathbb{R}^{d \\times k}$. Note, I'm pretty much only interested in realizations of J-L transforms which are represented by matrices. Naively, I'd think that the inverse is some sort of Moore-Penrose pseudoinverse of $R$. Is this actually what people do?</p>\n\n<p><sub>(I wasn't exactly sure if this question is suitable for cstheory.SE, so I decide posting it here.)</sub></p>\n", 'ViewCount': '38', 'Title': 'Computing the inverse of Johnson-Lindenstrauss transform', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-12T07:19:48.957', 'LastEditDate': '2013-04-12T07:19:48.957', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7696', 'Tags': '<reference-request>', 'CreationDate': '2013-04-12T06:41:29.350', 'Id': '11250'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For a regular language $L$, let $c_n(L)$ be the number of words in $L$ of length $n$. Using Jordan canonical form (applied to the unannotated transition matrix of some DFA for $L$), one can show that for large enough $n$,\n$$ c_n(L) = \\sum_{i=1}^k P_i(n) \\lambda_i^n, $$\nwhere $P_i$ are complex polynomials and $\\lambda_i$ are complex "eigenvalues". (For small $n$, we may have additional terms of the form $C_k[n=k]$, where $[n=k]$ is $1$ if $n=k$ and $0$ otherwise. These correspond to Jordan blocks of size at least $k+1$ with eigenvalue $0$.)</p>\n\n<p>This representation seems to imply that if $L$ is infinite then asymptotically, $c_n(L) \\sim C n^k \\lambda^n$ for some $C,\\lambda&gt;0$. However, this is patently false: for the language $L$ over $\\{0,1\\}$ of all words of even length, $c_{2n}(L) = 2^{2n}$ but $c_{2n+1}(L) = 0$. This suggests that for some $d$ and for all $a \\in \\{0,\\ldots,d-1\\}$, either $c_{dm+a}(L) = 0$ for large enough $m$ or $c_{dm+a} \\sim C_a (dm+a)^{k_a} \\lambda_a^{dm+a}$. This is proved in <a href="http://algo.inria.fr/flajolet/Publications/FlSe02.ps.gz">Flajolet &amp; Sedgewick</a> (Theorem V.3), who attribute the proof to Berstel.</p>\n\n<p>The proof provided by Flajolet and Sedgewick is somewhat technical; so technical, in fact, that they only sketch it. I attempted a more elementary proof using Perron-Frobenius theory. We can regard the transition graph of the DFA as a digraph. If the digraph is primitive then the result follows almost directly from the Perron-Frobenius theorem. If the digraph is irreducible but imprimitive with index $r$, then by considering the "$r$th power" of the DFA (each transition corresponds to $r$ symbols), we get the same result. The difficult case is when the digraph is reducible. We can reduce to the case of a path of strongly connected components, and then we get the result by estimating sums of the form\n$$ \\sum_{m_1+\\cdots+m_k=m} \\prod_{i=1}^k \\lambda_i^{m_i}. $$\n(Each such sum corresponds to a particular way of accepting a word, going through the different components in a certain way.) This sum, in turn, can be estimated by pinpointing the largest term, which corresponds to $m_i \\propto \\log \\lambda_i$. For every eigenvalue which is repeated $r$ times, we get an extra factor of $\\Theta(m^{r-1})$.</p>\n\n<p>The proof has its rough edges: in the reducible case, we need to pass from terms asymptotic to $C \\lambda_i^m$ to the sum mentioned above, and then we need to estimate the sum.</p>\n\n<p>The proof by Flajolet and Sedgewick is perhaps simpler, but less elementary. Its starting point is the rational generating function of $c_n(L)$, and it involves induction on the number of pole magnitudes (!). The basic idea is that all eigenvalues of maximal modulus are roots of unity (if normalized by their modulus), due to a (moderately easy) theorem of Berstel. Choosing an appropriate $d$ and looking at words of length $dm+a$, all these eigenvalues become real. Considering the partial fraction expansion, we get that if the eigenvalue of maximal modulus "survives", then it determines the asymptotics, which are of the form $Cn^k\\lambda^n$. Otherwise, we find a new rational generating function which corresponds just to words of this length (using an Hadamard product), and repeat the argument. The aforementioned quantity keeps decreasing, and so eventually we find the desired asymptotics; $d$ might have to grow in the process, to reflect everything that happens in the inductive steps.</p>\n\n<blockquote>\n  <p>Is there a simple and elementary proof for the asymptotic property of $c_n(L)$?</p>\n</blockquote>\n', 'ViewCount': '449', 'Title': 'Asymptotics of the number of words in a regular language of given length', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-27T16:50:23.943', 'LastEditDate': '2013-04-16T09:30:24.363', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '22', 'PostTypeId': '1', 'OwnerUserId': '683', 'Tags': '<formal-languages><reference-request><regular-languages><asymptotics><combinatorics>', 'CreationDate': '2013-04-16T01:37:16.013', 'FavoriteCount': '6', 'Id': '11350'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm looking for a good book that explains these subjects in a readable way.\nAny suggestions ?</p>\n\n<p>I currently pursuing my BSC in computer science, and I just failed to pass the course introduction to thr theory of computation and complexity.\nI would like to have more reference and sources of knowledge so I can understand the subject better. Examples and solutions for various problems like proving undecidability, many to one reductions, etc can help me alot.</p>\n", 'ViewCount': '214', 'Title': 'Introduction to complexity and computability', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T14:20:11.200', 'LastEditDate': '2013-04-21T14:20:11.200', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5187', 'Tags': '<complexity-theory><computability><reference-request><books>', 'CreationDate': '2013-04-19T06:54:25.990', 'FavoriteCount': '1', 'Id': '11399'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>A set is sparse if it contains polynomially bounded number of strings of any given string length $n$ otherwise it is dense. All known NP-complete sets are dense. It was proven that P=NP if and only if there is a sparse NP-complete set (under Karp reduction).</p>\n\n<p>I would like to find the density of uniquely satisfiable 3SAT formulas. Is it super-polynomially dense or exponentially dense? What is known about the asymptotic lower bound on the number of 3SAT formulas with unique solutions?</p>\n', 'ViewCount': '84', 'Title': 'Asymptotic bounds on number of 3SAT formulas with unique solutions', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-01T23:30:50.850', 'LastEditDate': '2013-04-21T14:12:11.020', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11745', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><reference-request><np-complete><satisfiability>', 'CreationDate': '2013-04-19T12:56:38.680', 'Id': '11408'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>In Bernard Chazelle\'s book <em>The Discrepancy Method</em>, which is <a href="http://www.cs.princeton.edu/~chazelle/pubs/book.pdf" rel="nofollow">available free as a PDF from the author\'s website</a>, the very first statement requiring thought by the reader (on page 3, just before Theorem 1) is obtained by a simple probability argument.  Unfortunately, I fail to follow the intended argument.  Could someone enlighten me?</p>\n\n<p>Here $\\chi(S_i) = \\sum_{v\\in S_i} \\chi(v)$ is the <em>discrepancy</em> of the set $S_i$ with respect to a function $\\chi$ that assigns weights to each element.</p>\n\n<blockquote>\n  <p>Given a set system $(V,S)$, with $|V| = n$ and $|S| = m$, pick a random coloring $\\chi$, meaning that for each $v_j$, the "color" $\\chi(v_j)$ is chosen randomly, uniformly, and independently, in $\\{-1,1\\}$.  We say that $S_i$ is <em>bad</em> if $|\\chi(S_i)| &gt; \\sqrt{2|S_i|\\ln (2m)}$.  By Chernoff\'s bound, we immediately derive\n  $$Pr[S_i \\text{ is bad}] &lt; \\frac{1}{m};$$</p>\n</blockquote>\n\n<p>and now the bit I don\'t follow:</p>\n\n<blockquote>\n  <p>therefore, with nonzero probability, no $S_i$ is bad.</p>\n</blockquote>\n\n<p>Clearly this holds if the $m$ events "$S_i$ is not bad" are mutually independent.  It also holds by a form of the <a href="http://en.wikipedia.org/wiki/Lov%C3%A1sz_local_lemma" rel="nofollow">Lov\xe1sz Local Lemma</a> if these events form the edges of a hypergraph (with $V$ as vertices) that is "nice enough".  But I don\'t see why this is immediately apparent in every case, as the author seems to imply.  If the $n$ individual values $\\chi(v_j)$ are iid, then I simply don\'t see that the $m$ events "$S_i$ is not bad" are necessarily of a nice enough form to use the probabilistic method, and they certainly don\'t seem to be iid.</p>\n\n<p>What am I missing?</p>\n\n<p>Any counterexample must be rather large (with the size of $m$ exponential in $|S_i|$), so I provisionally do believe the statement.  But I would like a convincing proof, or a pointer to another reference.</p>\n', 'ViewCount': '42', 'Title': "Chazelle's discrepancy book: greedy method", 'LastEditorUserId': '5323', 'LastActivityDate': '2013-05-03T10:18:17.243', 'LastEditDate': '2013-05-03T07:01:44.673', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11754', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '5323', 'Tags': '<reference-request><combinatorics><probability-theory><books>', 'CreationDate': '2013-05-03T06:55:55.880', 'Id': '11752'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I am looking for the paper : "B. Awerbuch, A. Baratz, and D. Peleg, E\ufb03cient broadcast and light-weight spanners, Manuscript, (1991)."<br>\nIt claims that we can build $(\\alpha ,1+\\frac{4}{\\alpha -1})-LAST$ where LAST hold for "Light Approximation Shortest path Tree"<br>\nif not available could any one explain the algorithms used there ?  </p>\n', 'ViewCount': '50', 'Title': 'Light approximation for shortest path tree', 'LastEditorUserId': '139', 'LastActivityDate': '2013-05-07T07:25:47.910', 'LastEditDate': '2013-05-07T07:25:47.910', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Tags': '<algorithms><reference-request><approximation>', 'CreationDate': '2013-05-04T22:40:46.600', 'Id': '11786'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Runtime for many programming languages is typically analyzed either assuming each operation takes a constant amount of time, or assuming each operation takes a logarithmic amount of time in the size the the data being manipulated. From a practical perspective, this is reasonable since modern computers have essentially constant time memory access (albeit for a fixed amount of memory).</p>\n\n<p>However, from a theoretical perspective, it seems to me that this is a bad assumption.</p>\n\n<p>Since bits can't be stored denser than the Planck scale (which we are fast approaching), the number of bits we can store in a certain volume of space can grow at most linearly as volume grows. Further, since the speed of memory retrieval and storage is bounded by the speed of light, it makes a lot of sense to say that as the size of the data we store grows, the cost for storing and accessing it should grow. For instance, one could assume that storing and accessing the $n$th bit of data requires $\\sqrt[3]{n}$ time. (Since space is 3-dimensional).</p>\n\n<p>Presumably this has been discussed in the literature somewhere. Could anyone point me to some references? Have algorithms been analyzed using this model?</p>\n", 'ViewCount': '93', 'Title': "Why don't we scale the cost of memory access when analyzing runtime of algorithms?", 'LastActivityDate': '2013-05-06T10:20:24.770', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8065', 'Tags': '<reference-request><time-complexity><asymptotics><runtime-analysis>', 'CreationDate': '2013-05-06T05:14:51.447', 'FavoriteCount': '1', 'Id': '11818'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was told by my adviser (future one) to look into <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" rel="nofollow">libsvm</a> library or any other and try to get familiar with it.. to work on a programming project (on Machine Learning) (will start in a month).</p>\n\n<p>my background: Programming knowledge in Python, C.. doing Java now.</p>\n\n<p>So, where should I probably start? and How long it takes me to get into ML, SVM etc.. and be productive? Would I probably fit for this project? --considering my programming background (I so far have been much into Web development, wanted to take a change and have fun)</p>\n', 'ViewCount': '156', 'ClosedDate': '2013-05-12T15:53:20.787', 'Title': 'Can we understand SVM without knowledge of Machine Learning', 'LastActivityDate': '2013-05-07T22:02:28.073', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '11855', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8079', 'Tags': '<reference-request><machine-learning><data-mining>', 'CreationDate': '2013-05-07T14:16:44.423', 'Id': '11854'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is there a common code metric for "code redundancy" or "code cloning"?</p>\n\n<p>I think I read somewhere a definition, where the LOC (lines of code) of\nthe redundant code was measured.</p>\n\n<p>I also searched for references, but didn\'t find a paper that seemed like an good or trustworthy reference.</p>\n', 'ViewCount': '44', 'Title': 'Code metric for code redundancy or code cloning', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-05-09T01:46:25.000', 'LastEditDate': '2013-05-09T01:46:25.000', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><empirical-research>', 'CreationDate': '2013-05-08T00:29:13.067', 'FavoriteCount': '2', 'Id': '11872'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I would like to learn more about Amdahl's Law and other similar topics.  In what branch of computer science would one place Amdahl's law?  Could someone point me to a textbook or further reading (aside from Wikipedia or other sites that are found on the first page of a Google search) that discusses it?</p>\n", 'ViewCount': '158', 'Title': "Amdahl's Law and Computer Science", 'LastEditorUserId': '1636', 'LastActivityDate': '2013-05-10T14:07:31.147', 'LastEditDate': '2013-05-09T00:10:39.940', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '11934', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4429', 'Tags': '<reference-request><parallel-computing>', 'CreationDate': '2013-05-08T04:51:42.320', 'Id': '11878'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '760', 'Title': "What does 'true concurrency' mean?", 'LastEditDate': '2013-05-12T10:15:57.010', 'AnswerCount': '1', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '147', 'FavoriteCount': '2', 'Body': "<p>I often hear phrases like 'true concurrency semantics' and 'true concurrency equivalences' without any references. What does those terms mean and why are they important?</p>\n\n<p>What are some examples of true concurrency equivalences and what is the need for them? E.g. in which cases they are more applicable than more standard equivalences (bisimulation, trace equivalence, etc)?</p>\n", 'Tags': '<terminology><reference-request><concurrency>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-20T09:27:25.823', 'CommentCount': '0', 'AcceptedAnswerId': '11896', 'CreationDate': '2013-05-08T14:07:16.857', 'Id': '11893'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Consider the following <em>universe problem</em>.</p>\n\n<blockquote>\n  <p><strong>The universe problem.</strong> Given a finite set $\\Sigma$ for a class of languages, and an automaton accepting the language $L$, decide if $L=\\Sigma^*$.</p>\n</blockquote>\n\n<p>In [1], it is stated and proved that the universe problem is undecidable for a particular class of one-counter automata. This result then follows for the class of all non-deterministic one-counter automata. I\'m wondering if it is known whether this problem is still undecidable when we restrict the size of the input alphabet of the automaton. </p>\n\n<p>I think that with alphabet size 1 the problem becomes decidable, but what about size 2? And if that turns out to be decidable what is the smallest value of $n \\in \\mathbb{N}$ such that the problem is undecidable.</p>\n\n<p>I think it\'s probable that the answer to this question is known but I\'m having trouble finding an answer. If it is already known then I would appreciate a reference.</p>\n\n<hr>\n\n<p>[1] <a href="http://link.springer.com/article/10.1007%2FBF01744294">Ibarra, O. H. (1979). Restricted one-counter machines with undecidable universe problems. Mathematical systems theory, 13(1), 181-186</a></p>\n', 'ViewCount': '126', 'Title': 'Is the universe problem for one-counter automata with restricted alphabet size undecidable?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T15:29:14.707', 'LastEditDate': '2013-05-23T17:42:41.283', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12235', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '769', 'Tags': '<formal-languages><reference-request><automata><undecidability><decision-problem>', 'CreationDate': '2013-05-23T16:56:50.530', 'Id': '12233'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<h3>What I have</h3>\n\n<p>An iterative process based on the application of a very simple function to represent a rate, with total dependence among any iteration and its predecessor (one input parameter for (n)th iteration is the output parameter from the (n-1)th iteration). Specifically,</p>\n\n<p>$\\qquad  f(x, y, z) = x + \\frac{y - x}{z + 1}$</p>\n\n<p>with $x$ the modeled rate (typical value between 0 and 1),  $y$ the contribution of every new record to the learning about the rate (typical value 0 or 1) and $z$ some kind of convergence/learning speed parameter (typical value any integer between 30 and 900). While $y$ and $z$ are constant, $x$ would be the result of the previous calculation.</p>\n\n<h3>What I want</h3>\n\n<p>Some kind of manipulation of the function that allows some level of independence among sequential iterations, thus allowing parallelization.</p>\n\n<p>What I know (or believe to) so far:</p>\n\n<p>There is extensive published literature on parallel iterative methods, but most of them are about classical methods like <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_725.pdf" rel="nofollow">Map-Reduce for Machine Learning on Multicore</a> by Chu et al.</p>\n\n<p>But I\'m failing to recognize which of them I could "use" to help me with my simple function.</p>\n\n<p>Can someone help me pointing literature on the basics of function transformation aiming towards parallelization? Any thoughts on that matter will be very helpful.</p>\n', 'ViewCount': '90', 'Title': 'Parallelization of an iterative function application', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-28T17:28:44.497', 'LastEditDate': '2013-05-28T17:28:44.497', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8339', 'Tags': '<reference-request><parallel-computing>', 'CreationDate': '2013-05-24T19:55:24.613', 'Id': '12254'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am self-studying computer graphics (both 2d and 3d) and was wondering if someone could provide me with some references like websites, literature, etc.  </p>\n\n<p>I am a complete beginner to computer graphics so I would like to go bottom-up. I have been searching Google but mostly what I get are lecture notes which are, quite frankly, not-so-well explained. They are intended for students who attended those lectures.  </p>\n\n<p>So, references please for self-study.</p>\n', 'ViewCount': '137', 'Title': 'Computer Graphics reference request', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-04T09:50:16.193', 'LastEditDate': '2013-09-04T09:22:37.280', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '8418', 'Tags': '<reference-request><graphics><computer-vision>', 'CreationDate': '2013-05-28T20:46:56.150', 'Id': '12344'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://www.google.ca/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCwQFjAA&amp;url=http://www.cs.rpi.edu/~moorthy/Courses/modcomp/fall2005/slides/DPDA.ppt&amp;ei=qI6mUeD6KaKOigLr-YH4Cg&amp;usg=AFQjCNHdu1SacbRI9CaOjOvXxzNziaHtEQ&amp;sig2=DLSgGZ-VegxX1lFVSTZTCw&amp;bvm=bv.47244034,d.cGE">These lecture slides</a> sketch a proof that $L=\\{ a^n b^n \\mid n \\geq 0 \\} \\cup  \\{ a^n b^{2n} \\mid n \\geq 0 \\}$\ncannot be accepted by any Deterministic Pushdown Automaton. Unfortunately, the slides give no references as to where the proof comes from.</p>\n\n<p>I was wondering, does anybody know of an academic paper or textbook that gives a full proof? I\'d love to be able to cite it, but I haven\'t been able to find one.</p>\n', 'ViewCount': '143', 'Title': 'Paper with proof that $L=\\{ a^n b^n \\mid n \\geq 0 \\} \\cup \\{ a^n b^{2n} \\mid n \\geq 0 \\}$ is not Deterministic Context Free?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-11-29T20:10:06.177', 'LastEditDate': '2013-11-29T20:10:06.177', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '12367', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2253', 'Tags': '<formal-languages><reference-request><automata><pushdown-automata><nondeterminism>', 'CreationDate': '2013-05-29T23:32:51.367', 'Id': '12365'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For my thesis, I have created a development approach (consisting of schemes, an application template and prototype code) that should make it easier to develop and adapt applications for a specific platform.</p>\n\n<p>I have conducted interviews with developers of that platform to evaluate my approach. There where 5 interviewees and the feedback that I got from them is sufficient for my scope, I would say.</p>\n\n<p>However, in my thesis I would like to justify my decision that 5 evaluators are enough. Is there any scientific research or paper that suggests a certain number of evaluators for such a rather theoretical approach?</p>\n\n<p>I know <a href="http://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/" rel="nofollow">Nielsen\'s work about heuristic usability evaluation</a> which says that with 5 participants, you discover around 75% of all problems in <em>software usability / UI testing</em>.</p>\n\n<p>But as I said, my approach is no specific software product that has to be evaluated, but only the model itself, which is why I\'m looking for research in that area.</p>\n', 'ViewCount': '58', 'Title': 'Ideal number of participants for evaluation of development approach / software architecture', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T10:27:33.920', 'LastEditDate': '2013-09-02T10:25:45.363', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '8450', 'Tags': '<reference-request><software-engineering><empirical-research>', 'CreationDate': '2013-05-30T18:52:54.170', 'Id': '12378'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Do you know the name of the following problem and can you give a reference for its complexity (especially the relation to $\\mathsf{GraphIsomorphism}$ and/or other isomorphism/homomorphism problems)?</p>\n\n<blockquote>\n  <p>Given two metrics $d_1$ and $d_2: V^2 \\to \\mathbb{N}$. Does there exist a  permutation $\\pi$ on $V$ such that $d': V^2\\to \\mathbb{N}$ with \n  $$d'(u,v)=\\min \\{d_1(u,v),d_2(\\pi(u),\\pi(v))\\}$$\n  is a metric?</p>\n</blockquote>\n\n<p>Motivation: Think of two fishing nets. If you try to fasten every knot of one net to every knot of the other net, the maximal distance between two knots is determined by the length of the shorter thread in the two nets.</p>\n", 'ViewCount': '17', 'Title': 'Name and complexity of a problem concerning metrics', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-02T13:29:27.023', 'LastEditDate': '2013-06-02T13:29:27.023', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><reference-request><graph-isomorphism>', 'CreationDate': '2013-06-02T13:16:10.880', 'Id': '12431'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am making a survey of Artificial Intelligence Techniques applied to educational fields. Actually I would like to find papers related to machine learning techniques applied to automatic scoring of exams and automatically increasing the difficulty of the questions in an exam, but I have not found any.</p>\n\n<p>Does anybody has some references about that specific topic?</p>\n\n<p>Thanks</p>\n', 'ViewCount': '28', 'Title': 'machine learning applied to automatic assesment?', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-07T15:11:07.660', 'LastEditDate': '2013-06-07T15:11:07.660', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6430', 'Tags': '<reference-request><machine-learning>', 'CreationDate': '2013-06-07T13:51:05.323', 'Id': '12509'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>My question refers to the draft of <a href="http://www.liafa.jussieu.fr/~jep/PDF/MPRI/MPRI.pdf" rel="nofollow">Mathematical Foundations of Automata Theory</a>, IV.2.1 (pages 89ff in the pdf). I will repeat everything necessary nevertheless:</p>\n\n<p>Let $M,N$ be monoids and $\\varphi: M \\rightarrow N $ a monoid morphism. We say that a subset $L$ of $M$ is recognizable by $\\varphi$ if there is a subset $P$ of $N$ such that $L = \\varphi^{-1}(P)$. As is known, the rational languages are precisely the recognizable subsets of $\\Sigma^\\ast$.</p>\n\n<p>Furthermore, we define an equivalence relation $R_\\varphi$ by $u R_\\varphi v :\\Leftrightarrow \\varphi(u)=\\varphi(v)$. \nThis relation is a congruence relation, that is $\\forall s,t,u,v \\in M:s R_\\varphi t \\Rightarrow usv~R_\\varphi~utv$.</p>\n\n<p>We say that a congruence relation $R$ <em>saturates</em> $L$ if for all $u \\in L$, $uRv$ implies $v \\in L$.\nThen in the above document, the following proposition (IV.2.2, page 90) is stated:</p>\n\n<p>Let $\\varphi : M \\rightarrow N$ be a monoid morphism and let\n$L$ be a subset of $M$. The following conditions are equivalent:</p>\n\n<p>(1) $L$ is recognised by $\\varphi$</p>\n\n<p>(2) $L$ is saturated by $R_\\varphi$</p>\n\n<p>(3) $\\varphi^{-1}(\\varphi(L))=L$</p>\n\n<p>Proof. (1) implies (2). If $L$ is recognised by $\\varphi$, then $L=\\varphi^{-1}(P)$ for some subset $P$ of $N$. Thus if $x \\in L$ and $x R_\\varphi y$, one has $\\varphi(x) \\in P$ and since $\\varphi(x)=\\varphi(y), y \\in \\varphi^{-1}(P)=L$.</p>\n\n<p>(2) implies (3). If $x \\in \\varphi^{-1}(\\varphi(L))$, there is $y \\in L$ such that $\\varphi(x) = \\varphi(y)$, that is $x R_\\varphi y$. Thus, $x \\in L$, and $\\varphi^{-1}(\\varphi(L)) \\subseteq L$ follows. "$\\supseteq$" is trivial.</p>\n\n<p>(3) implies (1). Let $P:=\\varphi(L)$, then $\\varphi^{-1}(P)=L$. </p>\n\n<p>I want to weaken the assumptions made in the proposition. Namely, assume tgat the  $N$ in the above definitions is a proper groupoid (in fact, I need to deal with loops), that is, associativity and identity are lost. Further, $\\varphi$ need not be a morphism (the relation $R_\\varphi$, defined in the same way as above, a priori need not be a congruence anymore) and we restate (1) accordingly (as formally, the notion of a "recognable subset" is not defined for groupoids).\nThen my questions are</p>\n\n<blockquote>\n  <p>(1) Is $R_\\varphi$ still a congruence if we demand $\\varphi$ \n  to be a morphism of groupoids (loops)?</p>\n  \n  <p>(2) Does the proposition still hold? Does it if we assume that $R_\\varphi$ is  <em>not</em> a congruence?</p>\n  \n  <p>(3) What other sources (preferably monographs) are there that you recommend as comprehensive introductions to algebraic automata theory, esp. concerned with the role of monoids, semigroups (and maybe more general structures as groupoids) and their connection with automata and languages?</p>\n</blockquote>\n\n<p>Personally, I think they are both true, as for (2), neither the morphism properties, nor associativity nor congruences seem to be used in the proof. And for (1), I don\'t see where one would need associativity to prove it. \nBut it may well be that I overlooked something (which is why I ask...).</p>\n', 'ViewCount': '77', 'Title': 'Quasigroups, congruences and recognizable subsets', 'LastActivityDate': '2013-06-08T16:55:03.373', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '12536', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<formal-languages><reference-request><check-my-proof>', 'CreationDate': '2013-06-07T19:09:01.057', 'Id': '12515'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In Graph-Theory there are many ways for efficient approximation-algorithms to solve the Metric TSP. The best solution seems to be the Christofides Heuristic with a factor of 1.5 to the optimal solution. My Teacher said, there would be the so called $\\frac{4}{3}$-conjecture, which states: there might be a approximation solution for the metric tsp, that has only a $\\frac{4}{3}$-factor.</p>\n\n<p>But i cannot find any literature or further information about this assumption. Maybe you can?</p>\n', 'ViewCount': '54', 'Title': 'Where can i find literature about the $\\frac{4}{3}$-conjecture for approximation of the Metric TSP?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-10T14:49:29.627', 'LastEditDate': '2013-06-10T14:49:29.627', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '12594', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6828', 'Tags': '<complexity-theory><reference-request><np-complete><approximation><traveling-salesman>', 'CreationDate': '2013-06-10T10:33:26.633', 'Id': '12593'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I don't know whether it was a joke, but once I read what was referred to as a formal definition of a file in a versioning system such as git, hg or svn and that was something like a mathmetaical object like a homeomorphism or so, was that a joke or is there really computer science theory about versioning systems and mathematics of VCS?</p>\n", 'ViewCount': '43', 'Title': 'Is there a formal CS definition of VCS and file versions?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-15T15:30:11.253', 'LastEditDate': '2013-06-15T15:30:11.253', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2529', 'Tags': '<terminology><reference-request><discrete-mathematics><filesystems>', 'CreationDate': '2013-06-13T06:36:29.267', 'FavoriteCount': '1', 'Id': '12652'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '230', 'Title': 'Quantum computing roadmap', 'LastEditDate': '2013-06-14T19:38:39.543', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8667', 'FavoriteCount': '1', 'Body': '<p>I have to create a roadmap for the quantum computing technology. Looking around I found the <a href="http://en.wikipedia.org/wiki/Timeline_of_quantum_computing" rel="nofollow">timeline</a> on wikipedia that is pretty wide but does not highlight the key events in quantum computing research neither sets the possible future for research.</p>\n\n<p>Could somebody help me to define which are key events in the quantum computing fields? When (and why) we started to explore this technology, for which milestones we passed through and (maybe) what we can set as future milestones?</p>\n', 'Tags': '<reference-request><quantum-computing>', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-06-14T19:38:39.543', 'CommentCount': '3', 'AcceptedAnswerId': '12675', 'CreationDate': '2013-06-14T13:17:36.910', 'Id': '12672'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '141', 'Title': 'Largest reported speedup for a parallel computation?', 'LastEditDate': '2013-06-23T16:17:43.197', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '5323', 'FavoriteCount': '1', 'Body': u'<p>A parallel implementation of a computation is usually compared to a sequential version of the same computation.  The ratio of the time taken by the sequential version to the time taken by the parallel version is called the <em>speedup</em>.  So if 8 cores run their smaller parts of the computation in 2 time units, and one core runs the whole computation in 8 time units, then the speedup is 4.</p>\n\n<blockquote>\n  <p>What is the largest speedup reported for a real computation?</p>\n</blockquote>\n\n<p>It is possible to reach essentially infinite speedup in a search problem, since one of the parallel pieces of the search space may lead to a fast solution by that parallel instance, while the sequential solution has to work through the entire search space to get to that point.  More generally, I want to exclude any problem where one of the parallel processes can reach a shortcut.  So I am only interested in computations where the amount of work done by the parallel processes is the same as done by the sequential process.  This is common in solving PDEs by grid methods, or in discrete event simulation.\nSo with $n$ processors, one should never get more than $n$ speedup for these kinds of problems.</p>\n\n<p>I would also like to exclude embarrassingly parallel problems like parallel rendering, since there one really has a vast number of independent tiny problems.  I am interested in problems where it is not possible to partition the computation into strictly disjoint pieces.</p>\n\n<p>For a large speedup, one has to have many processors.  Given the restrictions on scope that I have conveniently labelled as "real computations", this question is then essentially about how efficiently the very large processor arrays that exist have been programmed.</p>\n\n<p>I am aware of reported speedups of ~500 using arrays of GPUs, but surely larger speedups exist.</p>\n\n<hr>\n\n<p><em>Edit:</em> To address some of the comments, I dug up some further motivation, which will hopefully be precise enough for the tastes of those more mathematically inclined.  This is quite different in style from the above, so I append it here as a postscript.</p>\n\n<p>For $n$ iid random variables $X_1, X_2,\\dots, X_n$ with mean $\\mu$,\ndenote their maximum by $X_{(n)}$ and their sum by $S_n$.\nO\'Brien has shown that $X_{(n)}/S_n \\to 0$ <a href="http://en.wikipedia.org/wiki/Convergence_of_random_variables#Almost_sure_convergence" rel="nofollow">almost surely</a> as $n \\to \\infty$ iff $\\mu &lt; \\infty$.</p>\n\n<p>Letting $X_i$ be the time taken by the $i$-th processor to complete its task, and assuming that there is a timeout/recompute mechanism to ensure that $\\mu$ is finite, this hints that the inverse of the speedup should be essentially unbounded.  (This is not necessarily the case: the techniques used may not carry over to the inverse, so I have to leave this a bit vague.)</p>\n\n<p>This is a nice theoretical prediction, and the question arises: <em>is this prediction borne out in practice?</em>  Or do implicit dependencies or diverging behaviours of the different processors (i.e. a breakdown in the iid assumption) tend to curtail this supposedly unbounded increase?</p>\n\n<p>The iid case corresponds to the embarrassingly parallel case.  Where the processors have to synchronize, independence breaks down.</p>\n\n<p>My question can therefore also be rephrased as: how badly does non-negligible dependence between parts of a computation as seen in practice affect the large-scale speedups that have been demonstrated?  Given that <a href="http://math.stackexchange.com/a/427162/3362">the bounds for expectation of the maximum in the non-independent case are quite weak</a>, some pointers to empirical data would be useful.</p>\n\n<ul>\n<li>G. L. O\'Brien, <em><a href="http://www.jstor.org/stable/3213043" rel="nofollow">A Limit Theorem for Sample Maxima and Heavy Branches in Galton-Watson Trees</a></em>, Journal of Applied Probability <strong>17</strong> 539\u2013545, 1980.</li>\n</ul>\n', 'Tags': '<reference-request><efficiency><parallel-computing>', 'LastEditorUserId': '5323', 'LastActivityDate': '2013-06-24T07:04:13.960', 'CommentCount': '18', 'AcceptedAnswerId': '12829', 'CreationDate': '2013-06-22T07:51:11.100', 'Id': '12826'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I cannot undertand how exactly the Stacked Generalisation works.</p>\n\n<p>I have tried to read <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.1533" rel="nofollow">the original paper</a> and also the <a href="http://users.rowan.edu/~polikar/RESEARCH/index_files/Ensemble.html" rel="nofollow">survey by Robi Polikar</a>. I understand that a meta-classifier is created and it is used to choose which classifier to use for each instance, but I can\'t understand how is it trained and how it really works.</p>\n\n<p>Please help me giving a good reference about the topic.</p>\n', 'ViewCount': '29', 'Title': 'Simple explanation for Stacked Generalisation ensemble method', 'LastActivityDate': '2013-06-22T18:09:21.123', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '851', 'Tags': '<reference-request><machine-learning>', 'CreationDate': '2013-06-22T18:09:21.123', 'Id': '12831'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>On the <a href="http://en.wikipedia.org/wiki/Circulation_problem" rel="nofollow">circulation problem page on wikipedia</a>, the multicommodity circulation problem formulation seems to be insufficient, since we can just set all but one flow to $0$, and reduce it to a circulation problem.</p>\n\n<p>I can\'t find any concrete description of multicommodity circulation problem to verify the correctness. There is only <a href="http://transci.journal.informs.org/content/8/4/355.full.pdf" rel="nofollow">one paper</a> I can find and it\'s behind a pay wall.</p>\n\n<p>Here is a formulation I thought to make more sense:</p>\n\n<p>Let $G=(V,E)$. $l_i,u,c_i:E\\to \\mathbb{R}$ for $1 \\leq i\\leq n$. We want to find a sequence of flow function $f_i$, such that:</p>\n\n<p>$$\n\\begin{align}\n\\text{min} &amp; \\sum_{(v,w) \\in E} c_i(v,w)f_i(v,w) \\\\\n\\text{s.t.} &amp; \\sum_{(v,w) \\in E} f_i(v,w) = 0 \\text{ for } 1 \\le i \\le n, v \\in V, \\\\\n&amp; l_i(v,w) \\leq f_i(v,w) \\text{ for } 1 \\le i \\le n, (v,w)\\in E\\\\\n&amp; \\sum_{i=1}^n f_i(v,w) \\leq u(v,w) \\text{ for } (v,w)\\in E\\\\\n\\end{align}\n$$</p>\n\n<p>Is this a formulation of multicommodity circulation problem?</p>\n', 'ViewCount': '71', 'Title': 'Multicommodity circulation formulation', 'LastEditorUserId': '220', 'LastActivityDate': '2013-07-06T13:07:35.350', 'LastEditDate': '2013-07-05T18:43:56.970', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12965', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<reference-request><optimization><network-flow>', 'CreationDate': '2013-06-29T09:56:58.443', 'Id': '12963'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '615', 'Title': 'Where can a student learn image processing?', 'LastEditDate': '2013-07-01T05:37:46.307', 'AnswerCount': '5', 'Score': '3', 'OwnerDisplayName': 'Little Child', 'PostTypeId': '1', 'OwnerUserId': '8418', 'FavoriteCount': '1', 'Body': '<p>I am a student of computer science with interest in image processing. I have learned how to apply a few effects to images like making them grayscale, sketching them out of lines, etc.  </p>\n\n<p>I would like to learn more about the algorithmic techniques  behind creative manipulation of images like making them sepia-tone, smudging them, etc.  </p>\n\n<p><strong>Can someone please point me in the right direction?</strong> \nHow do I learn the fundamentals of these algorithms? </p>\n', 'Tags': '<reference-request><image-processing>', 'LastEditorUserId': '31', 'LastActivityDate': '2013-07-03T22:38:40.973', 'CommentCount': '14', 'AcceptedAnswerId': '13005', 'CreationDate': '2013-06-30T10:09:46.973', 'Id': '12990'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm looking for empirical papers which investigate if a user can benefit from Q&amp;A sites like Stack Overflow. I welcome any papers related to this topic, e.g: </p>\n\n<ul>\n<li>an experiment, investigating if a specific task can be executed faster,</li>\n<li>an analysis, investigating if a user understands the solutions on Q&amp;A sites or if he just does copy&amp;paste without thinking about it,</li>\n<li>a comparative analysis of the code quality of users with access to Q&amp;A sites in contrast to users without internet access (but just offline documentation of APIs).</li>\n</ul>\n", 'ViewCount': '112', 'Title': 'Empirical studies about benefits of Q&A sites for programming', 'LastEditorUserId': '1636', 'LastActivityDate': '2014-01-24T14:29:31.617', 'LastEditDate': '2013-07-04T01:32:24.893', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8988', 'Tags': '<reference-request><software-engineering><empirical-research><social-networks>', 'CreationDate': '2013-07-03T11:36:45.447', 'Id': '13056'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Can somebody refer me to peer-reviewed papers studying the advantages or disadvantages of writing code in a functional style? Are there papers which discuss the applications of Lambda Calculus in fields such as Machine Learning, Language Design, etc.?</p>\n', 'ViewCount': '202', 'Title': 'Are there peer-reviewed papers studying the pros and cons of functional programming?', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-07-10T19:02:23.393', 'LastEditDate': '2013-07-04T05:35:51.533', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '8998', 'Tags': '<reference-request><programming-languages><machine-learning><lambda-calculus><functional-programming>', 'CreationDate': '2013-07-03T23:37:07.887', 'FavoriteCount': '7', 'Id': '13076'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Anyone knows where I can find information about Time-based Inductive Machine(TIM). Good explanation of the method or the source code of the original implementation could help.</p>\n', 'ViewCount': '26', 'Title': 'Time-based Inductive Machine', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-07T17:47:28.977', 'LastEditDate': '2013-07-07T17:47:28.977', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9067', 'Tags': '<terminology><reference-request><machine-learning>', 'CreationDate': '2013-07-07T13:47:47.017', 'Id': '13130'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Can someone please point me towards a rigorous derivation of the energy function of a discrete Hopfield network. What I want, is the derivation must start out with the structure of the network and prove that the critical points of the dynamical system can be obtained by minimization of some function (possibly by constructing the Lyapunov function of the dynamical system). I cannot seem to find such a rigorous proof. Thankyou! </p>\n', 'ViewCount': '135', 'Title': 'Derivation of the energy function of a hopfield network', 'LastActivityDate': '2013-07-09T15:40:53.530', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8912', 'Tags': '<reference-request><machine-learning><neural-networks>', 'CreationDate': '2013-07-07T14:17:15.630', 'Id': '13132'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I often interact with people who want to ask for an algorithm for a computational problem (or its complexity), but they don\'t express it in a rigorous way for us (computer scientists) to understand.</p>\n\n<p>Referring them to books like CLRS is not helpful because the examples there usually have a quite straightforward way of stating rigorously, e.g. given the adjacency list of a graph and two vertices in it compute the shortest path between those vertices.</p>\n\n<blockquote>\n  <p>Is there any good book (or some other resource) where a person with minimal knowledge of CS can learn how one should formulate and state computational problems in a rigorous way that is understandable to computer scientists? </p>\n</blockquote>\n\n<p>Preferably the book should have many examples of how to formulate computational problems rigorously from various domain and real world examples.</p>\n\n<hr>\n\n<h3>Clarification</h3>\n\n<p>To make the question more specific, let\'s assume that they know basic math/CS terminology like sets, functions, graphs, lists, etc. at the level of 1st/2nd year undergraduate CS student (which is the case with people who I have in mind). For example, they have read some introductory textbook like Aho and Ullman (although they might not have understood it completely).</p>\n\n<ul>\n<li>Al Aho and Jeff Ullman, <a href="http://infolab.stanford.edu/~ullman/focs.html" rel="nofollow">Foundations of Computer Science</a>, 1992.</li>\n</ul>\n', 'ViewCount': '244', 'Title': 'How to formulate a computational problem rigorously?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-10T18:58:51.437', 'LastEditDate': '2013-09-02T10:36:14.787', 'AnswerCount': '2', 'CommentCount': '13', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<algorithms><reference-request><books>', 'CreationDate': '2013-07-08T20:06:02.727', 'FavoriteCount': '2', 'Id': '13165'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is it common to have a different feature set for samples in the train set and in the test set?</p>\n\n<p>My use case is text categorization: when training, I use the words as the features. But when testing, I want to add hypernyms.</p>\n\n<p>For example, if the training set contained the sentence "I eat a fruit", and there is a test sentence "I eat an apple", then I want to have the word "fruit" as a feature of the test sentence, in addition to its words, so that it will be classified positive. However, I don\'t want to add those hypernyms in the training set - if the training set contained only "I eat an apple", I don\'t want the sentence "I eat a fruit" to be classified positive.</p>\n\n<p>So, I thought of having a small feature set for training, and a larger feature set for testing. </p>\n\n<p>Is this common? If so, I would be happy to have some references.</p>\n', 'ViewCount': '64', 'Title': 'Different feature sets for training and testing?', 'LastActivityDate': '2013-07-09T13:39:21.047', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><machine-learning>', 'CreationDate': '2013-07-09T07:37:30.840', 'Id': '13169'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>So, it's fairly easy to prove that if $L \\in DCFL$, then $L \\Sigma^* \\in DCFL$. Basically, you take the DPDA accepting $L$. You remove all transitions on final states, and then for each $a \\in \\Sigma$ and each final state $q$, you add a transition looping from $q$ to $q$ on $a$.</p>\n\n<p>I'm using this in a paper, and I'd love to not have to actually prove this construction is valid. It's easy, but it's about a half-page long. Since DPDAs have been studied almost exhaustively, I was wondering, does anybody know of a paper that proves this property?</p>\n", 'ViewCount': '138', 'Title': 'Reference request: proof that if $L \\in DCFL$, then $L \\Sigma^* \\in DCFL$', 'LastActivityDate': '2013-07-10T20:22:04.583', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '13215', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2253', 'Tags': '<formal-languages><reference-request><automata><closure-properties><pushdown-automata>', 'CreationDate': '2013-07-09T17:23:08.623', 'Id': '13179'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '576', 'Title': 'Decision problems in $\\mathsf{P}$ without fast algorithms', 'LastEditDate': '2013-07-12T05:17:37.383', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '472', 'FavoriteCount': '4', 'Body': u'<p>What are some examples of difficult decision problems that can be solved in polynomial time? I\'m looking for problems for which the optimal algorithm is "slow", or problems for which the fastest known algorithm is "slow".</p>\n\n<p>Here are two examples:</p>\n\n<ul>\n<li><p><strong>Recognition of perfect graphs.</strong> In their FOCS\'03 paper [1] Cornu\xe9jols, Liu and Vuskovic gave an $O(n^{10})$ time algorithm for the problem, where $n$ is the number of vertices. I\'m not sure if this bound has been improved upon, but as I understand it, more or less a breakthrough is needed to obtain a faster algorithm.</p></li>\n<li><p><strong>Recognition of map graphs.</strong> Thorup [2] gave a rather complex algorithm with the exponent being (about?) $120$. Perhaps this has been even dramatically improved upon, but I don\'t have a good reference.</p></li>\n</ul>\n\n<p>I\'m especially interested in problems that have practical importance, and obtaining a "fast" (or even a practical) algorithm has been open for several years.</p>\n\n<hr>\n\n<p>[1] Cornu\xe9jols, G\xe9rard, Xinming Liu, and Kristina Vuskovic. "A polynomial algorithm for recognizing perfect graphs." Foundations of Computer Science, 2003. Proceedings. 44th Annual IEEE Symposium on. IEEE, 2003.</p>\n\n<p>[2] Thorup, Mikkel. "Map graphs in polynomial time." Foundations of Computer Science, 1998. Proceedings. 39th Annual Symposium on. IEEE, 1998.</p>\n', 'Tags': '<algorithms><complexity-theory><reference-request>', 'LastEditorUserId': '41', 'LastActivityDate': '2014-04-04T20:09:25.113', 'CommentCount': '6', 'AcceptedAnswerId': '13227', 'CreationDate': '2013-07-10T15:22:02.280', 'Id': '13202'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been using Clojure for about 18 months. Recently, I've come across terms such as Monads, Continuations, et al which I'd like to learn about.</p>\n\n<p>I could visit Wikipedia and read about these two topics, but I'm looking for a reference which also help me learn about related matters that I don't even know exist. Is there a book on this particular topic (if it even qualifies as one)? Would I pick these things up by learning about type systems or language design in general? Should I just learn Haskell to get exposure?</p>\n", 'ViewCount': '119', 'Title': 'Reference request: Monads, continuations, and other functional CS concepts', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-07-23T23:26:24.237', 'LastEditDate': '2013-07-23T16:58:39.923', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '13399', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9306', 'Tags': '<reference-request><programming-languages><functional-programming><continuations>', 'CreationDate': '2013-07-23T16:00:17.800', 'Id': '13398'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm wondering, what is the time-complexity of determining emptiness for 2-way DFAs? That is, finite automata which can move backwards on their read-only input tape.</p>\n\n<p>According to Wikipedia, they are equivalent to DFAs, though the equivalent DFA might be exponentially larger. I've found state complexity for their complements and intersections, but not for their emptiness-testing.</p>\n\n<p>Does anyone know of a paper where I could find this?</p>\n", 'ViewCount': '135', 'Title': 'What is the complexity of the emptiness problem for 2-way DFAs?', 'LastActivityDate': '2013-07-30T14:30:26.037', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13482', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2253', 'Tags': '<complexity-theory><formal-languages><reference-request><automata><finite-automata>', 'CreationDate': '2013-07-26T22:35:28.517', 'Id': '13456'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '128', 'Title': 'Getting started with Compiler Design', 'LastEditDate': '2013-08-07T07:34:30.817', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6466', 'FavoriteCount': '2', 'Body': '<p>This is the first time I will be studying compilers in depth. Can someone point me to best online resources (courses, articles, tutorials, video etc ) and books?   </p>\n\n<p>My main aim will be to do some practicals instead of just reading theory.-something where theory practical goes in parallel. So the reference must fulfill this expectations.</p>\n', 'ClosedDate': '2013-08-15T11:47:12.970', 'Tags': '<reference-request><compilers>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-07T07:34:30.817', 'CommentCount': '3', 'CreationDate': '2013-08-06T11:36:19.090', 'Id': '13630'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for references for the following problem: \nI have a very special class of regular languages and my aim is to express (and to justify my conjecture) that this class itself is very small in some way (as a subset of the regular languages) and that the languages contained in this class are rather "bloated". </p>\n\n<p>For the latter point, I could prove that all languages in the class have a large diameter with respect to many common metrics on strings. However, I want to consider the following: Given a language from the class, we know it has a large diameter, but does it also have a large "volume" (that is, measure), or put differently, if I choose randomly a finite word, is there anything meaningful to say about how "probable" it is that the word belongs to the language? Of course, we can lift the problem: Picking a random language, how probable is it to get a language in the class?</p>\n\n<p>Are there any references or standard approaches for looking at classes of (regular) languages from this point of view (or is this considered as generally uninteresting)?</p>\n', 'ViewCount': '113', 'Title': 'Measures and probability in formal language theory', 'LastActivityDate': '2013-08-07T07:33:27.500', 'AnswerCount': '2', 'CommentCount': '11', 'AcceptedAnswerId': '13652', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<formal-languages><reference-request><regular-languages><probability-theory>', 'CreationDate': '2013-08-06T12:18:54.883', 'FavoriteCount': '1', 'Id': '13631'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '140', 'Title': 'Getting started with Data Mining', 'LastEditDate': '2013-08-09T08:00:55.437', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9583', 'FavoriteCount': '1', 'Body': "<p>This is the first time that I'm looking in depth into the topic, although I've always been curious.\nCould someone let me know about online resources (courses, tutorials, etc) and books that cover the basics of the topic?\nI'd like to explore both the theoretical part and the more practical part of Data Mining.</p>\n", 'ClosedDate': '2013-08-15T11:46:53.423', 'Tags': '<reference-request><data-mining>', 'LastEditorUserId': '9583', 'LastActivityDate': '2013-08-13T14:58:55.720', 'CommentCount': '2', 'AcceptedAnswerId': '13682', 'CreationDate': '2013-08-08T18:29:17.430', 'Id': '13677'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '162', 'LastEditorDisplayName': 'user742', 'Title': 'Why are all problems in FPTAS also in FPT?', 'LastEditDate': '2013-09-08T10:00:18.023', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2131', 'FavoriteCount': '1', 'Body': '<p>According to <a href="https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme" rel="nofollow">the Wikipedia article on polynomial-time approximation schemes</a>:</p>\n\n<blockquote>\n  <p>All problems in FPTAS are fixed-parameter tractable.</p>\n</blockquote>\n\n<p>This result surprises me - these classes seem to be totally different from one another.  FPTAS characterizes problems by how easy they are to approximate, while FPT characterizes problems by their difficulty relative to some parameter.  Unfortunately, Wikipedia (as of the time I\'m asking this question) doesn\'t provide a citation for this.</p>\n\n<p>Is there a standard proof of this result?  Or is there a source I could consult to learn more about this connection?</p>\n', 'Tags': '<complexity-theory><reference-request><approximation><parametrized-complexity>', 'LastActivityDate': '2013-09-08T10:00:18.023', 'CommentCount': '5', 'AcceptedAnswerId': '13681', 'CreationDate': '2013-08-08T21:07:15.470', 'Id': '13679'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have here a directed graph that I used to perform <a href="http://en.wikipedia.org/wiki/Dinic%27s_algorithm" rel="nofollow">Dinic\'s algorithm</a> to find maximum flow. I need to adjust this graph and this algorithm to work with dynamic trees (i.e. the Sleator-Tarjan algorithm).</p>\n\n<p>I just wish I could find an image source or video that can help me visualize the steps. Something <a href="http://www.arl.wustl.edu/~jst//cse/542/text/sec19.pdf" rel="nofollow">like this</a> is really close. But I just really want to find thing to lead me step by step in a visual way or a way that doesn\'t involve pseudocode.</p>\n', 'ViewCount': '106', 'Title': "Understanding Dinic's algorithm using dynamic trees", 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-13T08:09:51.823', 'LastEditDate': '2013-08-13T08:09:51.823', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9626', 'Tags': '<algorithms><reference-request><network-flow>', 'CreationDate': '2013-08-12T20:48:37.890', 'Id': '13720'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For my Bachelor\'s thesis, I consider the class of languages recognized by symmetrical DFAs, that is, deterministic (complete) finite automata satisfying the following condition: </p>\n\n<p>Let $A$ be a complete DFA over the alphabet $\\Sigma$. If, for every $a\\in \\Sigma$ and every transition $u \\stackrel{a}{\\longrightarrow}v$ in $A$, there is a transition $v \\stackrel{a}{\\longrightarrow}u$ in $A$, we call $A$ a <em>symmetrical</em> DFA (<em>SDFA</em>). If $A$ is not complete, we call it a <em>partial</em> SDFA. We can regard an SDFA as an undirected, labeled graph in a natural way. </p>\n\n<p>I could find an algebraic characterization of the class of languages recognized by (complete as well as partial) SDFAs and deduce some closure properties. However, neither me nor my supervisor are aware of previous results concerning this particular class of regular languages (barring results like Reingold\'s $\\mathsf{SL = L}$ which might seem related). </p>\n\n<p>Motivated by a <a href="http://cs.stackexchange.com/questions/13631/measures-and-probability-in-formal-language-theory?noredirect=1#comment29176_13631">comment</a> that J.-E. Pin passed on <a href="http://cs.stackexchange.com/questions/13631/measures-and-probability-in-formal-language-theory">a related question I asked</a>, my question is now:</p>\n\n<blockquote>\n  <p>Are there results concerning these automata?</p>\n</blockquote>\n', 'ViewCount': '130', 'Title': 'Results on the languages recognized by undirected DFAs', 'LastActivityDate': '2013-08-16T06:31:23.137', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '13760', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<formal-languages><reference-request><regular-languages><finite-automata>', 'CreationDate': '2013-08-15T10:27:23.167', 'Id': '13759'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '73', 'Title': 'Mealy machines to model ciphers', 'LastEditDate': '2013-08-18T03:18:05.613', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '25', 'FavoriteCount': '1', 'Body': u'<p>Similar questions have occurred quite a number of times <a href="http://cs.stackexchange.com/q/10280/25">(1)</a> <a href="http://cstheory.stackexchange.com/q/8539/869">(2)</a> <a href="http://cstheory.stackexchange.com/q/14811/869">(3)</a>, but I have, say, a specific instance of one. I\'m aware of a bunch of applications of finite automata, but would you provide an academic exposition of applications of finite state machines (like, e.g., Mealy machines) in cryptography and ciphers? There is a mention about things like that in Wikipedia article on Mealy machines (<a href="http://en.wikipedia.org/wiki/Mealy_machine#Applications" rel="nofollow">subsection \u201cApplications\u201d</a>). So the links to some academic texts play up on this are very appreciated. Alternatively would you share your thoughts on how to furnish this topic (FSM in cryptography) for students?</p>\n', 'ClosedDate': '2013-08-22T03:37:30.720', 'Tags': '<reference-request><automata><finite-automata><cryptography>', 'LastEditorUserId': '25', 'LastActivityDate': '2013-08-18T06:53:08.120', 'CommentCount': '1', 'AcceptedAnswerId': '13798', 'CreationDate': '2013-08-17T19:55:32.487', 'Id': '13795'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Please suggest some books on Parallel Algorithms which teach efficient programming techniques like the ones taught in Udacity course(Introduction to Parallel Programming with CUDA). Also wanted to know that from which reference book or papers are the concepts in the udacity course on Parallel Computing taught...? I wish to study more about such techniques which will make me an efficient parallel programmer...!</p>\n', 'ViewCount': '456', 'Title': 'Reference book for Parallel Computing and Parallel algorithms.', 'LastEditorUserId': '947', 'LastActivityDate': '2013-08-22T12:39:11.050', 'LastEditDate': '2013-08-22T12:39:11.050', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9779', 'Tags': '<reference-request><parallel-computing>', 'CreationDate': '2013-08-22T11:09:09.997', 'FavoriteCount': '1', 'Id': '13863'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am building a classifier for short texts in a chat system. My features are words and pairs of words.</p>\n\n<p>Naturally, the sentences contain spelling mistakes. If a particular wrong spelling of a certain word hasn't appeared in the training corpus, the classifier has no chance to identify it.</p>\n\n<p>I consider taking an existing spelling corrector, and integrate it with my current classifier, but I am not sure how to do it.</p>\n\n<p>Do you know of a paper that integrates an automatic spelling correction tool with a short text classifier? </p>\n", 'ViewCount': '76', 'Title': 'short text categorization with spelling correction', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-08-22T14:34:49.877', 'LastEditDate': '2013-08-22T11:42:58.863', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><machine-learning><natural-lang-processing><classification>', 'CreationDate': '2013-08-22T11:20:26.190', 'Id': '13864'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1789', 'Title': 'Which machine learning algorithms can be used for time series forecasts?', 'LastEditDate': '2013-08-26T13:02:49.107', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '9836', 'FavoriteCount': '3', 'Body': '<p>Currently I am playing around with time series forecasts (specifically for Forex). I have seen some scientific papers about echo state networks which are applied to Forex forecast. Are there other good machine learning algorithms for this purpose?</p>\n\n<p>It would also be interesting to extract "profitable" patterns from the time series.</p>\n', 'Tags': '<reference-request><machine-learning><artificial-intelligence>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-11T18:11:56.823', 'CommentCount': '1', 'AcceptedAnswerId': '14000', 'CreationDate': '2013-08-26T09:06:00.243', 'Id': '13937'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Most specifically, his use of small epsilon introduced at the end of section 1 of "Types, Abstraction and Parametric Polymorphism" is throwing me, but in general I would like references to symbols in the Type and Logical Relations literature.</p>\n', 'ViewCount': '51', 'Title': 'Looking for cheat sheet to J.C. Reynolds symbols', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-27T10:46:17.957', 'LastEditDate': '2013-08-27T10:46:17.957', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13957', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9831', 'Tags': '<terminology><reference-request><type-theory><abstract-data-types>', 'CreationDate': '2013-08-27T03:17:11.390', 'Id': '13954'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Where can I find <em>introductory</em> books, articles, notes or slides on Game Semantics?</p>\n\n<p>I have searched a lot on the internet but I\'m not satisfied by the material I found. It either is too informal, or it assumes too much knowledge of/attitude to other kind of semantics, and it\'s hard to follow for a beginner.</p>\n\n<p>Ideally the material shouldn\'t have any prerequisites, except a little of game theory and few concepts of semantics.</p>\n\n<p>Examples of the material that I\'ve found are:</p>\n\n<ul>\n<li><p><a href="http://www.pps.univ-paris-diderot.fr/~curien/Game-semantics.pdf" rel="nofollow">Notes on Game Semantics</a>: These are quite good, but they lack a bit of formalism at the beginning and I find some explanations or examples difficult to follow.</p></li>\n<li><p><a href="http://www.illc.uva.nl/lint/documents/workshop08/slides/abramsky_tutorial.pdf" rel="nofollow">Tutorial on Game Semantics</a>: Slides; they lack oral explanations.</p></li>\n</ul>\n', 'ViewCount': '41', 'Title': 'Reference introductory books or articles to Game Semantics', 'LastActivityDate': '2013-08-27T08:59:11.797', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7246', 'Tags': '<reference-request><semantics><game-theory>', 'CreationDate': '2013-08-27T08:59:11.797', 'Id': '13963'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Does anyone know where I could get an access to a project that contains all the artefacts (documents) that were created during the development? So I would like to get all the word, pdf, power designer, etc. files as well as all the source code. If possible, I would prefer that all this files are stored in some of the software reporitories.</p>\n', 'ViewCount': '26', 'ClosedDate': '2013-08-28T20:23:30.753', 'Title': 'Access to publicly available project with all the artefacts (files) created during the development', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-28T09:32:03.657', 'LastEditDate': '2013-08-28T09:32:03.657', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9853', 'Tags': '<reference-request><software-engineering><data-sets>', 'CreationDate': '2013-08-27T10:40:59.360', 'Id': '13970'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>When it comes to the design of algorithms, one often employs the following techniques:</p>\n\n<ul>\n<li>Dynamic Programming</li>\n<li>The Greedy-Strategy</li>\n<li>Divide-and-Conquer</li>\n</ul>\n\n<p>While for the first two methods, there are well-known theoretical foundations, namely the Bellman Optimality Principle and matroid (resp. greedoid) theory, I could not find such a general framework for algorithms based on D&amp;C. </p>\n\n<p>Firstly, I am aware of something that we (or rather, the prof) introduced  in a functional programming class,  called an "algorithmic skeleton", that arose in the context of combinators. As an example hereof, we gave such a skeleton for D&amp;C algorithms as follows: </p>\n\n<p><strong>Definition</strong>: Let $A,S$ be non-empty sets. We call the elements of $S$ <em>solutions</em>, and the elements of $P:=\\mathfrak{P}(A)$ (that is, the subsets of $A$) are referred to as <em>problems</em>.\nThen, a <em>D&amp;C-skeleton</em> is a 4-tuple $(P_\\beta, \\beta, \\mathcal{D}, \\mathcal{C})$, where: </p>\n\n<ul>\n<li>$P_\\beta$ is a predicate over the set of problems and we say that a problem $p$ is <em>basic</em> iff $P_\\beta(p)$ holds.</li>\n<li>$\\beta$ is a mapping $P_\\beta \\rightarrow S$ that assigns a solution to each basic problem. </li>\n<li>$\\mathcal{D}$ is a mapping  $P \\rightarrow \\mathfrak{P}(P)$ that divides each problem into a set of subproblems.</li>\n<li>$\\mathcal{C}$ is a mapping $P\\times \\mathfrak{P}(S) \\rightarrow S$ that joins the solutions (depending on kind of a "pivot problem") of the subproblems to produce a solution. </li>\n</ul>\n\n<p>Then, for a given skeleton $s=(P_\\beta, \\beta, \\mathcal{D}, \\mathcal{C})$ and a problem $p$, the following generic function $f_s: P\\rightarrow S$ computes a solution (in the formal sense) for $p$:</p>\n\n<p>$f_s(p)= \\left\\{\n  \\begin{array}{l l}\n    \\beta(p) &amp; \\quad \\text{if $p$ is basic}\\\\\n    \\mathcal{C}(p,f(\\mathcal{D}(p))) &amp; \\quad \\text{otherwise}\n  \\end{array} \\right.$</p>\n\n<p>where in the second line we use the notation $f(X) := \\{f(x)  : x\\in X\\}$ for subsets $X$ of the codomain of a mapping $f$.</p>\n\n<p>However, we did not further examine the underlying, "structural" properties of problems that can be formulated this way (as I said, it was a functional programming class and this was only a small example). Unfortunately, I could not find further reference on this very approach. Hence I don\'t think the above definitions are quite standard. If someone recognizes what I have stated above, I would be glad about related articles.</p>\n\n<p>Secondly, for the greedy strategy we have the famous result that a problem is correctly solved by the general greedy algorithm if and only if its solutions constitute a weighted matroid. Are there similar results for D&amp;C-algorithms (not necessarily based on the method outlined above)?</p>\n', 'ViewCount': '355', 'Title': 'Theoretical foundations of Divide and Conquer', 'LastActivityDate': '2014-01-27T13:03:11.173', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '20011', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<algorithms><reference-request><divide-and-conquer>', 'CreationDate': '2013-08-29T16:27:18.153', 'FavoriteCount': '4', 'Id': '14022'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In the <em>edge-disjoint paths problem</em> (EDP), we are given a (possibly directed) graph $G=(V,E)$, and a set of distinct source-sink pairs $\\{ (s_i,t_i) \\mid 1 \\leq i \\leq k \\}$, and we want to maximize the number of pairs that can be simultaneously connected in an edge-disjoint manner. When we add the constraint that the paths need to be <em>shortest paths</em>, we get the <em>edge-disjoint shortest paths</em> (EDSP) problem.</p>\n\n<p>According to [1], the EDSP problem is hard for a graph with unit edge lengths, even when the graph is planar. Furthermore, it claims this is so for both directed and undirected graphs.</p>\n\n<blockquote>\n  <p>What is known about the approximability of the EDSP problem?</p>\n</blockquote>\n\n<p>I\'m especially interested in results for undirected graphs. In [2], the authors seem to only consider variants of the EDP problem, but not the EDSP problem. Further following the references, it seems like the EDP problem has been studied extensively.</p>\n\n<hr>\n\n<p>[1] <a href="http://www.sciencedirect.com/science/article/pii/S0166218X97001212" rel="nofollow">Eilam-Tzoreff, Tali. "The disjoint shortest paths problem." Discrete applied mathematics 85.2 (1998): 113-138.</a></p>\n\n<p>[2] <a href="http://www.sciencedirect.com/science/article/pii/S0022000003000667" rel="nofollow">Guruswami, Venkatesan, et al. "Near-optimal hardness results and approximation algorithms for edge-disjoint paths and related problems." Journal of Computer and System Sciences 67.3 (2003): 473-496.</a></p>\n', 'ViewCount': '131', 'Title': 'Approximability of the edge-disjoint shortest paths problem', 'LastEditorUserId': '472', 'LastActivityDate': '2013-09-01T11:44:40.417', 'LastEditDate': '2013-09-01T11:44:40.417', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<algorithms><reference-request><shortest-path><approximation>', 'CreationDate': '2013-08-29T16:50:41.277', 'Id': '14023'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is there an "official" name for this slight variant of the well known <a href="http://en.wikipedia.org/wiki/Tag_system">Tag System</a> model of computation, and/or has it been used somewhere?</p>\n\n<ul>\n<li>a finite alphabet of symbols $\\Sigma$</li>\n<li>a halt symbol $H$</li>\n<li>an ordered set of production rules: \n$$P_i: \\alpha_i \\rightarrow \\beta_i, \\quad \\alpha_i \\in \\Sigma^+, \\beta_i \\in \\Sigma^* \\cup \\{H\\}$$</li>\n<li>the input $w$ is a string in $\\Sigma^+$</li>\n</ul>\n\n<p>The computation is:</p>\n\n<ol>\n<li>find the first production rule $P_i$ for which $w = \\alpha_i v$; </li>\n<li>replace $w = \\alpha_i v$ with $v\\beta_i$ (i.e. delete the prefix $\\alpha_i$ and append $\\beta_i$)</li>\n<li>halt when no production is found or $\\beta_i = H$</li>\n</ol>\n\n<p>This model differs from a tag system because 1) $\\alpha_i$ is a string and not a single symbol, 2) the number of characters deleted from the prefix is not fixed.</p>\n\n<p>It can easily simulate a $m$-tag system in "real-time" (for every rule $x \\rightarrow P(x)$ of the m-tag system add production rules $xv \\rightarrow P(x)$, $v \\in |\\Sigma|^{m-1}$) and therefore it can efficiently simulate a Turing machine.</p>\n', 'ViewCount': '50', 'Title': 'Tag system variant', 'LastActivityDate': '2013-10-30T04:01:57.713', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14051', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<reference-request><computation-models>', 'CreationDate': '2013-08-30T09:50:16.547', 'Id': '14034'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm interested in learning about how facial recognition works.  I'm especially interested in the algorithms or approach that is used.  What are the leading methods for facial recognition?  Is there a good overview or source to learn about a few of the most widely used algorithms for facial recognition?  What would be the best handful of research papers to read first?</p>\n", 'ViewCount': '90', 'Title': 'How does facial recognition work?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T10:59:55.660', 'LastEditDate': '2013-09-02T10:33:34.133', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<reference-request><computer-vision><pattern-recognition><facial-recognition>', 'CreationDate': '2013-09-02T04:54:02.340', 'Id': '14075'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Some humans can lip-read fairly well: by watching someone who is speaking, they can tell what the speaker is saying (even without hearing the speech).</p>\n\n<p>Has there been any work on building computer software to lip-read?  In other words, given a video of someone speaking, is it possible to build software to infer what the person is saying (with access only to the video stream, without audio)?  Has there been any research on this problem, or even deployed systems?</p>\n\n<p>Background and motivation: In the US, certain laws may forbid recording audio without consent.  However, there is generally no prohibition on recording video without consent of the people being recorded.  (That's why you see surveillance cameras all over the place, and why they record only video but never audio.)  I am curious whether technology has advanced enough that, solely from video, it might be possible for automated methods to tell what people are saying -- or whether that might become feasible in the near-future.  And, apart from the privacy implications, such a technology might be pretty useful.</p>\n", 'ViewCount': '117', 'Title': 'Automated lip-reading: inferring what someone is saying, based upon video of them speaking', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T10:57:04.990', 'LastEditDate': '2013-09-02T10:34:40.780', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<reference-request><computer-vision><pattern-recognition><facial-recognition>', 'CreationDate': '2013-09-02T05:05:58.230', 'Id': '14076'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m interested in the first appearance in the CS literature of the data structure described <a href="http://community.topcoder.com/tc?module=Static&amp;d1=tutorials&amp;d2=lowestCommonAncestor#Segment_Trees" rel="nofollow">here</a> which is used to answer Range Queries. Although I have come across the same data structure many times with the name <em>segment tree</em> (mostly in algorithmic competition sites), it seems that the same name is also used for <a href="http://en.wikipedia.org/wiki/Segment_tree" rel="nofollow">this</a> data structure which is quite different from the first one and has application in computational geometry.</p>\n\n<p>I\'d like to know who introduced the data structure described in the TopCoder tutorial and if another name was initially used as there seems to be a confusion between the two data structures that go by the same name.</p>\n', 'ViewCount': '130', 'Title': 'Origins of the Segment tree data structure', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-10T15:14:39.863', 'LastEditDate': '2013-09-09T09:34:27.603', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10010', 'Tags': '<reference-request><data-structures><trees>', 'CreationDate': '2013-09-06T12:32:28.053', 'Id': '14172'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am a starting Ph.D. student in computer science, and I am trying to understand some classic game-theory papers, such as those by Nash, Kalai and Smorodinsky.   But I find it hard to understand the mathematical parts. It seems that these papers were written by mathematicians, for mathematicians.</p>\n\n<p>Can you recommend a book that explains the mathematical preliminaries of game theory, to people without extensive mathematical background?</p>\n', 'ViewCount': '189', 'Title': 'High maths for game theory', 'LastActivityDate': '2013-09-16T10:42:28.270', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '14332', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><game-theory><mathematical-analysis>', 'CreationDate': '2013-09-13T13:43:55.123', 'FavoriteCount': '3', 'Id': '14289'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for some graph theory concepts and definitions around <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory#Embedding" rel="nofollow">embedding</a> a DAG into another DAG.  I could only find a few lines on Wikipedia around this so I wonder if someone can help me find good references for the important concepts and definitions.</p>\n\n<p>For example, assume I have a DAG $G=(E,V)$ where there are two types of edges, red and black.  $E_{red} \\subset E$, $E_{black} \\subset E$, and $E_{red} \\cap E_{black} =  \\emptyset$ .  </p>\n\n<p>I assume that the red edges represents some "core" DAG and the black edges represents "details".</p>\n\n<p>If I want to extract this "core" DAG, I might do something like this:</p>\n\n<p>Put $E_{red}$ and all related vertices into a new graph $G\' = (E\',V\')$.</p>\n\n<p>For every pair $e_p,e_c \\in E_{red}$, if $e_c$ is reachable from $e_p$ and there is no other $e \\in E_{red}$ on the path, then add the edge $(end(e_p),beginning(e_c))$ to $G\'$.</p>\n\n<p>$G\'$ might then be thought of as having removed the black edges (and thus the details) from $G$.</p>\n\n<p>My question is, what am I doing, and where can I read about embedding DAGs and extracting embeddings based on edge colors? </p>\n', 'ViewCount': '36', 'Title': 'Finding embedded DAG in another DAG based on colors', 'LastEditorUserId': '10168', 'LastActivityDate': '2013-09-17T12:17:54.980', 'LastEditDate': '2013-09-17T12:17:54.980', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10168', 'Tags': '<graph-theory><reference-request>', 'CreationDate': '2013-09-16T16:13:42.470', 'Id': '14358'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Let $G = (V, E)$ be a connected graph and let $M\\subseteq V$. We say that a vertex $v$ is <em>marked</em> if $v\\in M$.  The problem is to find a simple path in $G$ that visits the maximum possible number of marked vertices. The associated decision problem is: is there a simple path that visits every $v\\in M$?  </p>\n\n<p>The problem is obviously more general than the problem of finding a Hamiltonian path in an arbitrary graph, so it is NP-hard.  </p>\n\n<p>I see no obvious strategy; one can't simply disregard the unmarked vertices, since they (and their incident edges) may be part of the optimal path.  Indeed, omitting them may disconnect the graph completely.</p>\n\n<p>My questions:</p>\n\n<ol>\n<li>Does this problem have a well-known name?</li>\n<li>Are there any good approximation algorithms, heuristics, or simple reductions to problems I might know more about?</li>\n<li>Where can I find this problem discussed in the literature?</li>\n</ol>\n", 'ViewCount': '201', 'LastEditorDisplayName': 'user742', 'Title': 'Find a simple path visiting all marked vertices', 'LastActivityDate': '2013-09-20T09:24:48.873', 'LastEditDate': '2013-09-20T09:24:48.873', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1786', 'Tags': '<algorithms><graph-theory><reference-request><np-hard><hamiltonian-path>', 'CreationDate': '2013-09-17T21:18:50.210', 'Id': '14390'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Some complicated algorithms (<a href="http://en.wikipedia.org/wiki/Union-find">union-find</a>) have the nearly-constant inverse Ackermann function that appears in the asymptotic time complexity, and are worst-case time optimal if the nearly constant inverse Ackermann term is ignored. </p>\n\n<p>Are there any examples of known algorithms with running times that involve functions that grow fundamentally slower than inverse Ackermann (e.g. inverses of functions that are not equivalent to Ackermann under polynomial or exponential etc. transformations), that give the best-known worst-case time complexity for solving the underlying problem?</p>\n', 'ViewCount': '207', 'Title': 'Do functions with slower growth than inverse Ackermann appear in runtime bounds?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-18T21:26:09.597', 'LastEditDate': '2013-09-18T21:26:09.597', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<reference-request><algorithm-analysis><time-complexity><runtime-analysis>', 'CreationDate': '2013-09-17T23:51:31.520', 'FavoriteCount': '3', 'Id': '14392'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '197', 'Title': 'Bridge theorems for group theory and formal languages', 'LastEditDate': '2013-09-18T15:00:13.363', 'AnswerCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '3', 'Body': '<blockquote>\n  <p>Is there some natural or notable way to relate or link math <a href="http://en.wikipedia.org/wiki/Group_theory" rel="nofollow">groups</a> and CS <a href="http://en.wikipedia.org/wiki/Formal_language" rel="nofollow">formal languages</a> or some other core CS concept e.g. Turing machines?</p>\n</blockquote>\n\n<p>I am looking for references/applications. However note that I am aware of the link between semigroups and CS languages (namely via <a href="http://en.wikipedia.org/wiki/Semiautomaton" rel="nofollow">finite automata</a>). (Does this literature on semiautomata ever look at "group-automata"?)</p>\n\n<p>I have seen one paper many years ago that might come close, that converts TM transition tables into a binary operation, possibly sometimes a group in some cases, conceivably based on some kind of symmetry in the TM state table. It didn\'t explore that in particular, but also didn\'t rule it out.</p>\n\n<p>Also, in particular, regarding the large body of math research on <a href="http://en.wikipedia.org/wiki/Classification_of_finite_simple_groups" rel="nofollow">classification of finite groups</a>, does or could it have any meaning or interpretation in TCS? What is the "algorithmic lens" view of this massive edifice of mathematical research? What is it "saying" about a possible hidden structure in computation?</p>\n\n<p>This question is partly inspired by some other notes e.g.:</p>\n\n<ul>\n<li><p><a href="http://cstheory.stackexchange.com/questions/10916/uses-of-algebraic-structures-in-theoretical-computer-science?lq=1">Use of algebraic structures in TCS</a></p></li>\n<li><p><a href="http://rjlipton.wordpress.com/2013/06/20/three-theorems-about-growth/" rel="nofollow">RJ Lipton on Gromov\'s theorem</a></p></li>\n</ul>\n', 'Tags': '<formal-languages><reference-request><automata><discrete-mathematics><group-theory>', 'LastEditorUserId': '699', 'LastActivityDate': '2013-09-19T08:20:39.707', 'CommentCount': '4', 'AcceptedAnswerId': '14417', 'CreationDate': '2013-09-18T03:16:40.020', 'Id': '14398'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '68', 'Title': 'Reference for an undecidability proof', 'LastEditDate': '2013-10-04T06:49:58.733', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9625', 'FavoriteCount': '1', 'Body': '<p>I\'m searching for a reference of an undecidability proof that is as simple as possible and starts "from scratch".</p>\n\n<p>With "from scratch" I mean that it does not use some other undecidable problem to prove some undecidability (which is the usual case), I cannot wrap my mind about how proving undecidability that way (without a previous proof) could be possible.</p>\n\n<p>This question may be inspiring: <a href="http://math.stackexchange.com/questions/80745/an-example-of-an-easy-to-understand-undecidable-problem">An example of an easy to understand undecidable problem</a></p>\n\n<p>Also, I know this is probably not very objective, but it is important to me, it should be something as simple as possible, hopefully enough so that even I can understand it.</p>\n', 'ClosedDate': '2013-10-04T06:52:47.623', 'Tags': '<reference-request><proof-techniques><undecidability><decision-problem>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-04T06:49:58.733', 'CommentCount': '4', 'CreationDate': '2013-10-03T14:44:58.153', 'Id': '14788'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>There is a long-standing and seemingly ever-growing trend to reduce various (even undecidable) problems to SAT to get practically useful solvers, like for instance [1].</p>\n\n<p>I'm looking for some kind of survey or list of papers/projects that fall into this category.</p>\n\n<p>[1] Chad E. Brown: Satallax: An Automatic Higher-Order Prover. IJCAR 2012: 111-117</p>\n", 'ViewCount': '52', 'Title': 'Reductions to SAT', 'LastActivityDate': '2013-10-06T18:03:32.497', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '5405', 'Tags': '<reference-request><satisfiability>', 'CreationDate': '2013-10-06T18:03:32.497', 'Id': '14859'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Those terminologies confuse me. As I understand </p>\n\n<ul>\n<li>SAT solver: decide the satisfiability of propositional logic (using DPLL or Local Search).</li>\n<li>Decision procedure is a procedure to decide the satisfiability of a certain decidable first-order theory.</li>\n<li>SMT solver is a SAT solver + decision procedure.</li>\n<li>Theorem prover indicates something like Dynamic Logic, e.g. the KeY tool</li>\n<li>Constraint solver: I don't know.</li>\n</ul>\n\n<p>But I see people calling Z3 a theorem prover. So I don't know how to dishtinguish those terms. And what is the most general term for all of them? Thank you.</p>\n", 'ViewCount': '308', 'Title': 'Distinguish Decision Procedure vs SMT solver vs Theorem prover vs Constraint solver', 'LastEditorUserId': '8607', 'LastActivityDate': '2013-10-16T13:03:06.590', 'LastEditDate': '2013-10-16T13:03:06.590', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '8607', 'Tags': '<algorithms><terminology><reference-request><decision-problem>', 'CreationDate': '2013-10-09T12:25:45.727', 'FavoriteCount': '2', 'Id': '14946'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>After skimming <a href="http://www.lirmm.fr/~imbert/pdfs/constmult_arith18.pdf">Multiplication by a Constant is Sublinear (PDF)</a>, (<a href="http://ge.tt/6343C5u/v/0">slides (PDF)</a>, <a href="http://ge.tt/6343C5u/v/1">slides with notes (PDF)</a>) I was wondering if this could be extended to division by a constant in sublinear time?</p>\n\n<p>Additionally, what about division with a constant numerator, ie. "division of a constant"?</p>\n', 'ViewCount': '105', 'Title': 'Division by a constant', 'LastActivityDate': '2013-10-09T17:02:46.717', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14959', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2755', 'Tags': '<algorithms><reference-request><integers>', 'CreationDate': '2013-10-09T15:46:09.137', 'Id': '14954'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am reading "Neural Networks and Learning Machines" and in Chapter 11 the book covers Boltzman machines and it is stated "the network [Boltzmann machine] can perform pattern completion", but does not show how this would be done in practice, or how a Boltzmann machine could be used at all.</p>\n\n<p>As I am more the "hands-on" person, and the book is more on the theoretical side of science. I am currently looking for an practical example/paper/article on an Boltzmann machine, maybe even a simple (therefore small) educational implementation. </p>\n\n<p>I\'d appreciate any link/paper/article covering the (<strong>non-restricted</strong>) Boltzmann machine in an understandable ("hands-on") way.</p>\n', 'ViewCount': '43', 'Title': 'practical use of a Boltzmann machine', 'LastActivityDate': '2013-10-09T16:49:03.440', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '78', 'Tags': '<reference-request><neural-networks><boltzmann-machine>', 'CreationDate': '2013-10-09T16:49:03.440', 'Id': '14958'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>3-PARTITION is <a href="http://en.wikipedia.org/wiki/Strongly_NP-complete">strongly NP-complete</a>, i.e. it remains NP-complete even if the input is given in unary.</p>\n\n<p>I\'m searching two or three examples of (possibly well-known) <em>non-numeric problems</em> that have been proved to be NP-complete using a reduction from 3-PARTITION (and the reduction obviously relies on the strongly np-completeness). I would like the references to the original papers.</p>\n', 'ViewCount': '193', 'Title': 'Reduction examples from the strongly NPC problem 3-PARTITION', 'LastActivityDate': '2014-03-08T12:01:35.653', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '15028', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<reference-request><np-complete>', 'CreationDate': '2013-10-12T11:57:11.637', 'FavoriteCount': '1', 'Id': '15015'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m referring to regular expressions as language: \\begin{equation*}\n \\Sigma = \\{ ``a", ``b", ``(", ``)", ``*", ... \\}\n\\end{equation*} and \\begin{equation*}\n L = \\Sigma^* \\text{, which form a legal regular expression}\n\\end{equation*} I am not referring to their computational power. I did some research, but wasn\'t able to find anything relevant. Intuitively, I would imagine they\'re context-free, but am not sure how to attempt a proof.</p>\n\n<p>I am trying to use this as a lemma, so a reference, or recommendation for how to attempt a proof would be extremely helpful.</p>\n', 'ViewCount': '98', 'Title': 'Where in the Chomsky Hierarchy are Regular Expressions as a language?', 'LastActivityDate': '2013-10-15T19:40:06.070', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '16110', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10596', 'Tags': '<formal-languages><reference-request><regular-languages>', 'CreationDate': '2013-10-15T19:28:55.387', 'Id': '16109'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '92', 'Title': "Courcelle's Theorem: Looking for papers", 'LastEditDate': '2013-10-22T09:51:25.143', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1382', 'FavoriteCount': '1', 'Body': '<p>I am looking for an easy and introductory paper on the proof of <a href="http://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle\'s Theorem</a>. I am also interested in its connection to <a href="http://en.wikipedia.org/wiki/Parameterized_complexity">parameterized complexity</a> regarding the <a href="http://en.wikipedia.org/wiki/Treewidth">treewidth</a>.</p>\n\n<p>I am only a beginner in this field.</p>\n\n<p>Any suggestions?</p>\n', 'Tags': '<complexity-theory><graph-theory><reference-request><discrete-mathematics><parametrized-complexity>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-12T21:25:05.823', 'CommentCount': '0', 'AcceptedAnswerId': '16326', 'CreationDate': '2013-10-22T09:20:33.627', 'Id': '16324'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given two ordered sets of words $a_1, a_2, ..., a_k$, $b_1, b_2, ..., b_k$ taking values in some discrete alphabet $A$, a solution to the PCP problem is a sequence $i_1, ..., i_n$ taking values in $1, 2,..., k$ such that $a_{i_1}|a_{i_2}|...|a_{i_n}=b_{i_1}|b_{i_2}|...|b_{i_n}$ where $|$ means concatenation. $k$ can be called the length of the problem, $n$ the length of the solution and if we let $w$ be the length of the largest word in $a_1, a_2, ..., a_k, b_1, b_2, ..., b_k$, $w$ is called the width of the problem.</p>\n\n<p>I know that the PCP problem becomes decidable in several scenarios, for instance: for bounded $n$, or if $A$ is unary, etc. On the other hand for $k\\geq7$ PCP is still undecidable. My question is, is there any result known for bounded values of $w$? </p>\n', 'ViewCount': '43', 'Title': 'Undecidability of the PCP problem with bounded width', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-13T22:09:30.400', 'LastEditDate': '2013-11-13T22:09:30.400', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '16358', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10931', 'Tags': '<computability><reference-request><undecidability><decision-problem>', 'CreationDate': '2013-10-23T09:27:07.050', 'Id': '16357'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Let:</p>\n\n<ul>\n<li>$\\left\\{m_1, ~...~, m_k\\right\\}$ be a set of coprime natural numbers,</li>\n<li>$M=\\prod_{i=1}^{k} m_i$</li>\n<li>$X$ be a natural integer, such that $X &lt; M$</li>\n</ul>\n\n<p>Then $X$ can be expressed in the <a href="http://en.wikipedia.org/wiki/Residue_number_system" rel="nofollow">Residue Number System</a> as:</p>\n\n<p>$$X={\\left(x_1, ~...~, x_k\\right)}_{RNS\\left(m_1, ~...~, m_k\\right)}~.$$</p>\n\n<p>Where $\\forall_{m_i} \\left[\\left(x_i \\equiv X \\mod m_i\\right) ~~~ \\wedge ~~~0 \\le x_i &lt; m_i \\right]$.</p>\n\n<p>There are a plethora of papers attacking the problem of parity/magnitude comparison in <em>Residue Number Systems</em>; however many of these papers are focused on chip-depth or shaving large constants off of chip-area. I am finding it difficult to decipher if there are any exact algorithms that run faster than full binary reconstruction, which takes $\\sim \\mathcal{O}(k^2)$  time. (For simplicty/brevity, I am assuming small $m_i$, and constant-time modulo-multiplication/addition of each RNS "digit").</p>\n\n<p>Most of the papers\' novelties lie in some seeming "gimmick", but no real complexity decrease; examples of results:</p>\n\n<ul>\n<li>Fast inexact parity algorithms (usually work terribly when $X &lt; \\sqrt{M}$, or $|X| \\ll |M|$, where $\\left|n\\right|=\\text{size of }n=\\left\\lceil\\log_2n\\right\\rceil$)</li>\n<li>Algorithms that work quickly "most of the time"; ie. they use an inexact algorithm, and then the full CRT reconstruction or equivalent in the worst case</li>\n<li>The circuit they present competes with some other paper\'s circuit by some constant, or area/depth tradeoff, but makes no complexity advance</li>\n<li>Full CRT reconstruction of $X$, perhaps using some trick to save some constants</li>\n<li>Reconstruct/convert to another number system (including binary) where parity/comparison is easy, but:\n<ul>\n<li>this conversion/reconstruction takes $\\sim \\mathcal{O}(k^2)$ time,</li>\n<li>or it runs in $\\sim \\mathcal{O}(k)$, time but with $k$ processors,</li>\n<li>or it runs in $\\sim \\mathcal{O}(k)$ time because that is the depth of the circuit, but this is not algorithmic complexity,</li>\n<li>or it reuses previous components that must be there for RNS multiplication (saving circuit space), but still runs in $\\sim \\mathcal{O}(k^2)$ sequential-time, or $\\sim \\mathcal{O}(k)$ parallel-time</li>\n</ul></li>\n<li>Using a "core" function which basically boils down to a constant-trimmed-CRT, or an approximate CRT</li>\n<li>Using special moduli, makes individual operations simpler, but parity complexity stays the same</li>\n<li>Using special moduli, but limited number of moduli or can\'t have small $m_i$</li>\n<li>Base extension, saves some constant or allows parallel-ness, but complexity is again $\\sim \\mathcal{O}(k^2)$ sequential-time, or $\\sim \\mathcal{O}(k)$ parallel-time (for multiplication)</li>\n<li>Redundant moduli, but maintaining the redundant moduli takes  $\\sim \\mathcal{O}(k^2)$ sequential-time, or $\\sim \\mathcal{O}(k)$ parallel-time</li>\n<li>Using lookup tables to reduce depth of some parity, no complexity improvement</li>\n</ul>\n\n<p>Many of the papers do not address complexity at all, or do not address sequential complexity, or even more confusingly, some state the depth/parallel complexity without being precise that it is not sequential; until you read and decipher the entire paper, and discover it yourself.</p>\n\n<h3>Bottom line</h3>\n\n<p><strong>What are the best <em>sequential</em>, <em>worst-case</em>, complexity results in RNS<sup>*</sup> for <em>exact</em> parity checking or magnitude comparison?</strong></p>\n\n<p><sup><strong>*Results for RNS-<em>like</em> system would also be interesting, including special moduli sets</strong></sup></p>\n\n<hr>\n\n<p><sup><sup>\n<strong>More background info</strong>:\n</sup></sup></p>\n\n<p><sup><sup> Multiplication of two numbers in the same RNS base is simply pointwise modulo multiplication of the two numbers (this can be approximately linear time). However, overflow detection is difficult (it is difficult with addition as well). Multiplication seems much simpler, but parity and magnitude comparison of two numbers seems much more difficult. Magnitude comparison is simply determining which of two numbers is greater, $X \\stackrel{?}{&lt;} Y$, given <em>only</em> their RNS form with the same RNS bases. Parity is simply deciding if a number, $X={\\left(x_1, ~...~, x_k\\right)}_{RNS\\left(m_1, ~...~, m_k\\right)}$ is even or odd (obviously, $X$ is not given, only its RNS form). An interesting thing is that magnitude comparison and parity are related: If you were able to compute parity, then you can do comparison. To do comparison with parity, you do $(X - Y)$ (in RNS), and if it underflows, the parity will be unexpected. That is, normally, assuming $p(X) = X \\mod 2, ~~~ p(X) \\in \\{0,1\\}$ is the parity function, $p(X-Y) \\equiv p(X) + p(Y) \\mod 2$. However, if it underflows, it will wrap around to $M-1$. Therefore if the parity is off after $X-Y$, you know that $Y &gt; X$.\n</sup></sup></p>\n', 'ViewCount': '208', 'Title': 'Best complexity of parity/comparison in the Residue Number System', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-10-23T23:32:04.833', 'LastEditDate': '2013-10-23T23:32:04.833', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2755', 'Tags': '<algorithms><reference-request><integers><number-theory>', 'CreationDate': '2013-10-23T21:28:12.190', 'Id': '16374'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have read the following artice that defines the term "constructor anomaly":</p>\n\n<p>Cohen, Tal, and Joseph Gil. "Better Construction with Factories." journal of object technology 6.6 (2007): 103-123.\n<a href="http://www.jot.fm/issues/issue_2007_07/article3/" rel="nofollow">http://www.jot.fm/issues/issue_2007_07/article3/</a></p>\n\n<p>Where can I find examples and references on constructor anomalies? (also in the context of multiplie inheritance)</p>\n\n<p>Are constructor anomalies always due to a method call in the constructor or is it possiple to construct an example without method calls in the constructor?</p>\n', 'ViewCount': '120', 'Title': 'OOP: exampe and references on constructor anomalies', 'LastActivityDate': '2013-10-28T18:00:12.867', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '16511', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><programming-languages><object-oriented>', 'CreationDate': '2013-10-28T15:17:39.973', 'FavoriteCount': '1', 'Id': '16503'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Cutting problems are problems where a certain large object should be cut to several small objects. For example, imagine you have a factory that works with large boards of raw glass, of width W and length L. There are several buyers, each of which wants an unbounded number of small glass boards. Buyer $i$ wants boards of length $l_i$ and width $w_i$. Your goal is to cut small boards from the large board, such that the total used is maximized and the waste is minimized (There are also <a href="http://www.citeulike.org/user/erelsegal-halevi/article/1695945">other types of cutting and packing problems</a>).</p>\n\n<p>One common restriction in cutting problems is, that the cuts must be <strong>guillotine cuts</strong>, i.e., each existing rectangle can be cut only to two smaller rectangles; it is impossible to make L-shapes etc. Obviously, the maximum used area with guillotine cuts might be smaller than the maximum used area without restriction.</p>\n\n<p>My question is: <strong>Are there upper and lower bounds on the ratio between the optimal guillotine cut and the optimal general cut?</strong></p>\n\n<p>Related work: <a href="http://www.citeulike.org/user/erelsegal-halevi/article/7153709">Song et al. (2009)</a> describe an algorithm that uses a restricted type of guillotine cuts - <em>twice-guillotine cuts</em>. They prove, using geometric constraints, that the ratio between the maximum twice-guillotine cut to the maximum guillotine cut is bounded by <strong>$\\frac{6}{7}$</strong>. I am looking for a comparable result about the ratio between the maximum guillotine cut to the maximum general cut.</p>\n', 'ViewCount': '61', 'Title': 'guillotine cuts versus general cuts', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-10-29T07:48:31.090', 'LastEditDate': '2013-10-29T07:48:31.090', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><computational-geometry><lower-bounds><packing>', 'CreationDate': '2013-10-29T07:40:13.090', 'Id': '16533'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Let $S$ be a set of $n$ integers. Consider the following <em>weighted permutations problem</em>.</p>\n\n<blockquote>\n  <p>Let $m&lt;n$ be an integer. What is an efficient algorithm to enumerate all subsets of $m$ integers of $S$ such that they are listed in order of the sum of the integers in each subset?</p>\n</blockquote>\n\n<p>Each subset is a permutation, and each permutation has a total weight that is the sum of the integers in the permutation.</p>\n\n<p>The idea is to come up with an algorithm that is not the trivial algorithm of enumerating all subsets, and then sorting them, i.e. more of a "streaming" type algorithm. That is, efficiency in terms not so much of time but of "small" space.</p>\n\n<p>Maybe this is published somewhere in the literature although I have not seen it.</p>\n', 'ViewCount': '89', 'Title': 'Enumerating weighted permutations in sorted order problem', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-18T21:03:07.127', 'LastEditDate': '2013-11-18T21:03:07.127', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<algorithms><reference-request><sorting><efficiency><enumeration>', 'CreationDate': '2013-11-05T17:32:02.033', 'FavoriteCount': '1', 'Id': '16744'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m looking for the name of the following concept.</p>\n\n<p>Given a monoid $(M,\\oplus)$, and a finite set of generators $x_1,\\ldots,x_n$. The generators are the alphabets.</p>\n\n<p>We define the regular expression on the <a href="http://en.wikipedia.org/wiki/Word_%28group_theory%29" rel="nofollow">words</a> formed by the generators. We treat those words just like strings. </p>\n\n<p>For words $x$ and $y$, we write $x\\equiv y$ if $x$ and $y$ represent the same element in $M$.</p>\n\n<p>If $R$ is a regular expression, we define $L(R)$ to be the set of strings matched by $R$ and $L_M(R)$ as</p>\n\n<p>$$L_M(R) = \\{w\'|w\'\\equiv w,w\\in L(R)\\}$$.</p>\n\n<p>I\'m interested to know if there exist known literature on $L_M(R)$. </p>\n\n<p>Many problems related to $L_M(R)$ are undecidable, because the word problem on $M$ might be undecidable. I wonder if $M$ has a decidable word problem, does it imply we can decide if $L_M(R)=L_M(R\')$ for 2 regular expressions $R$ and $R\'$.</p>\n', 'ViewCount': '72', 'Title': 'Regular expression over a monoid', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-11T17:56:45.023', 'LastEditDate': '2013-11-11T10:28:52.773', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '17918', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<formal-languages><reference-request>', 'CreationDate': '2013-11-11T00:20:41.683', 'Id': '17897'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Let $G$ be a graph, and let $s$ and $t$ be two vertices of $G$. Can we efficiently sample a shortest $s$-$t$ path uniformly and independently at random from the set of all shortest paths between $s$ and $t$? For simplicity, we can assume $G$ is simple, undirected and unweighted.</p>\n\n<p>Even in many restricted graphs, the number of shortest paths between $s$ and $t$ can be exponential in the size of $G$. Therefore, we would naturally like avoid actually computing all the shortest $s$-$t$ paths. I don't know about the general case, but it seems to me that we can achieve this for some special graph classes.</p>\n\n<p>This feels like something someone must have considered before. Is there any existing research into this, or is this in fact simple to do even for general graphs?</p>\n", 'ViewCount': '187', 'Title': 'Efficiently sampling shortest $s$-$t$ paths uniformly and independently at random', 'LastActivityDate': '2013-11-12T15:18:07.457', 'AnswerCount': '2', 'CommentCount': '14', 'AcceptedAnswerId': '17929', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<graph-theory><reference-request><shortest-path><sampling>', 'CreationDate': '2013-11-11T14:36:27.297', 'FavoriteCount': '4', 'Id': '17917'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '90', 'Title': 'Published or widely known failures of Page Rank algorithm', 'LastEditDate': '2013-11-17T17:21:13.813', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '96', 'FavoriteCount': '1', 'Body': '<p>I use Google a lot for searching articles and publications. Occasionally, I find Google totally misses what I am looking for and I get completely unexpected results for some search queries. </p>\n\n<blockquote>\n  <p>What are the published or widely known failures of PageRank algorithm?</p>\n</blockquote>\n\n<p>EDIT: Changed the post to address comments.</p>\n', 'ClosedDate': '2013-11-17T01:13:31.840', 'Tags': '<algorithms><reference-request><searching>', 'LastEditorUserId': '96', 'LastActivityDate': '2013-11-17T17:21:13.813', 'CommentCount': '8', 'CreationDate': '2013-11-14T15:48:56.063', 'Id': '18018'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am trying to solve a 25k clauses 5k variables SAT problem. As it has been running for an hour (precosat) and I'd like to solve bigger ones afterwards, I'm looking for a multi-core SAT-Solver.</p>\n\n<p>As there seem to be many SAT-Solvers, I'm quite lost.</p>\n\n<p>Could anyone point me out the best one for my case?</p>\n\n<p>I'd also be happy if someone could give me the approximate time (if possible).</p>\n", 'ViewCount': '141', 'Title': 'Multicore SAT Solver', 'LastEditorUserId': '11382', 'LastActivityDate': '2014-02-05T14:17:31.637', 'LastEditDate': '2013-11-17T20:27:40.670', 'AnswerCount': '3', 'CommentCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '11382', 'Tags': '<algorithms><reference-request><parallel-computing><sat-solvers>', 'CreationDate': '2013-11-14T16:25:35.683', 'FavoriteCount': '1', 'Id': '18021'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I need to study fuzzy logic and its application in the field of A.I.<br></p>\n\n<p>I\'m reading "First Course On Fuzzy Theory and Application" (<a href="http://www.shahroodut.ac.ir/fa/download.php?id=1111119783" rel="nofollow">pdf</a>) (<a href="http://www.worldcat.org/oclc/56878880" rel="nofollow">WorldCat</a>), but not much of examples there and \nI couldn\'t find a solution manual for it.</p>\n\n<p>Any recommendation for a self study book ?</p>\n', 'ViewCount': '67', 'Title': 'Introductory book to fuzzy logic for Artificial Intelligence', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-18T21:18:54.847', 'LastEditDate': '2013-11-18T21:18:54.847', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11347', 'Tags': '<reference-request><logic><artificial-intelligence><books>', 'CreationDate': '2013-11-18T14:27:28.253', 'Id': '18117'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>consider a program that generates a <a href="http://en.wikipedia.org/wiki/Random_walk" rel="nofollow">random walk</a> using a <a href="http://en.wikipedia.org/wiki/Pseudorandom_number_generator" rel="nofollow">PRNG</a>, as in following pseudocode. it uses <a href="http://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic" rel="nofollow">arbitrary precision arithmetic</a> such that there is no limit on variable values (ie no overflow).</p>\n\n<pre><code>srand(x)\nz = 0\nwhile (z &gt;= 0)\n{\n  r = rand(100)\n  if (r &lt;= 50) z -= 1\n  else z += 1\n}\n</code></pre>\n\n<p>the PRNG is inited with seed <code>x</code> <em>(also arbitrary precision).</em> the PRNG <code>rand(100)</code> generates a value between <code>0..99</code>. hence for 51 values the accumulator var <code>z</code> is decremented, for 49 values it is incremented.</p>\n\n<p>it is expected due to the <a href="http://en.wikipedia.org/wiki/Law_of_large_numbers" rel="nofollow">law of large numbers</a> that this program will halt for all initial seeds <code>x</code>. however, </p>\n\n<blockquote>\n  <p>how does one prove it will halt for all initial seeds <code>x</code>?</p>\n</blockquote>\n\n<p>it seems such a proof must depend on the details of the construction of the PRNG. am assuming there exist PRNGs such that a different random sequence is generated for every initial seed <code>x</code> (ie the infinite set of naturals). that in itself may be up for question. are such PRNGs known? where are they used? etc.. so an answer may come up with an arbitrary PRNG for the purposes of the question. a single example fulfilling the criteria would be an acceptable answer.</p>\n\n<p>looking for related literature, similar problems/proof considered, etc.</p>\n', 'ViewCount': '58', 'Title': 'proof of convergence in arbitrary precision PRNGs', 'LastActivityDate': '2013-11-19T00:38:41.127', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<algorithms><reference-request><probability-theory><pseudo-random-generators><random-walks>', 'CreationDate': '2013-11-18T21:52:05.343', 'FavoriteCount': '1', 'Id': '18132'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Consider the linear programs </p>\n\n<p>\\begin{array}{|ccc|}\n\\hline\nPrimal: &amp; A\\vec{x} \\leq \\vec{b} \\hspace{.5cm} &amp; \n\\max \\vec{c}^T\\vec{x} \\\\\n\\hline\n\\end{array}\n\\begin{array}{|ccc|}\n\\hline\nDual: &amp; \\vec{c} \\leq \\vec{y}^TA \\hspace{.5cm} &amp;\n\\min \\vec{y}^T\\vec{b} \\\\\n\\hline\n\\end{array}</p>\n\n<p>The weak duality theorem states that \nif $\\vec{x}$ and $\\vec{y}$ satisfy the constraints then\n$\\vec{c}^T\\vec{x} \\leq \\vec{y}^T\\vec{b}$.\nIt has a short and slick proof using linear algebra:\n$\\vec{c}^T\\vec{x} \\leq  \\vec{y}^T A \\vec{x} \\leq \\vec{y}^T\\vec{b}$.</p>\n\n<p>The strong duality theorem states that if the $\\vec{x}$ is an optimal solution for the primal then there is $\\vec{y}$ which is a solution for the dual and \n$\\vec{c}^T\\vec{x} = \\vec{y}^T\\vec{b}$.</p>\n\n<p>Is there a similarly short and slick proof for the strong duality theorem?</p>\n', 'ViewCount': '213', 'Title': 'Short and slick proof of the strong duality theorem for linear programming', 'LastActivityDate': '2013-11-20T00:00:15.410', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<algorithms><reference-request><linear-programming><linear-algebra><duality>', 'CreationDate': '2013-11-19T09:39:14.263', 'Id': '18151'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '128', 'Title': 'Can Euclidean TSP be exactly solved in time better than (sym)metric TSP?', 'LastEditDate': '2013-11-20T22:51:30.667', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2755', 'FavoriteCount': '1', 'Body': u'<p>Symmetric/Metric TSP can be solved via the Held-Karp algorithm in $\\mathcal O(n^2 2^n)$.</p>\n\n<p>See <a href="http://epubs.siam.org/doi/abs/10.1137/0110015">A dynamic programming approach to sequencing problems</a> by Michael Held and Richard M. Karp, 1962.</p>\n\n<p>In <a href="http://faculty.cs.tamu.edu/chen/courses/689/2006/reading/w1.pdf">Exact Algorithms for NP-Hard Problems: A Survey (PDF)</a> Woeginger writes:</p>\n\n<blockquote>\n  <p>This result was published in 1962, and from nowadays point of view almost looks trivial. Still, it yields the best time complexity that is known today.</p>\n</blockquote>\n\n<p>Thus, this is the best known upper-bound.</p>\n\n<p><b>Question:</b></p>\n\n<blockquote>\n  <p>Are there any better results for Euclidean TSP? Or does that best-known bound apply to Euclidean TSP as well.</p>\n</blockquote>\n\n<p>How is Euclidean TSP different? Well,</p>\n\n<ul>\n<li>Euclidean TSP can be encoded into $\\mathcal O(n \\log m)$ space, where $n$ is the number of cities, and $m$ is the bound on the integer coordinates of the city locations. As opposed to (sym)metric TSP variants, which essentially require a distance matrix of size $\\mathcal O(n^2 \\log m)$. Thus, it might be easier to solve; for example, perhaps Euclidean TSP can be more easily encoded into k-SAT, because the distance function is implicit.</li>\n<li><p>Contrary to popular notion, Euclidean TSP\'s reduction from k-SAT is quite different from (sym)metric TSP. UHC (undirected Hamiltonian cycle), symmetric TSP, and metric TSP are pretty directly related to each-other. But formulations of reductions from (sym)metric TSP to Euclidean TSP are not easy to come by. Paragraph, from interesting article, <a href="http://rjlipton.wordpress.com/2012/04/22/the-travelling-salesmans-power/">The Travelling Salesman\u2019s Power</a> by K. W. Regan (bold mine):</p>\n\n<blockquote>\n  <p>Now the reductions from 3SAT to TSP, especially Euclidean TSP, are less familiar, and we ascribe this to their being far more \u201cexpansive.\u201d <b>Texts usually reduce 3SAT to Hamiltonian Cycle, then present the latter as a special case of TSP, but this does not apply to Euclidean TSP</b>. The ${\\mathsf{NP}}$-completeness of Euclidean TSP took a few years until being shown by Christos Papadimitriou, and a 1981 <a href="http://www.cs.technion.ac.il/~itai/publications/Algorithms/Hamilton-paths.pdf">paper</a> by him with Alon Itai and Jayme Luiz Szwarcfiter advertised a \u201cnew, relatively simple, proof.\u201d This proof uses vertex-induced subgraphs of the grid graph in the plane, for which the shortest possible TSP tour and any Hamiltonian cycle have the same length. Despite this simplification, the gadgets involved are large\u2014a diagram of one occupies most of one journal page.</p>\n</blockquote>\n\n<p>Hunting down k-SAT $\\rightarrow$ Euclidean TSP reductions is quite an adventure; so far I\'ve found two of them. One $\\rm k\\text{-}SAT \\rightarrow CircuitSAT \\rightarrow PlanarCircuitSAT \\rightarrow EuclideanTSP$, and another, even tougher one to find, $\\rm k\\text{-}SAT \\rightarrow DHC \\rightarrow UHC \\rightarrow PlanarUHC \\rightarrow EuclideanTSP$. The latter reduction can perhaps be seen to make Euclidean TSP parallel (sym)metric TSP.</p></li>\n</ul>\n', 'Tags': '<graph-theory><reference-request><time-complexity><np-hard><traveling-salesman>', 'LastEditorUserId': '2755', 'LastActivityDate': '2014-02-05T14:16:06.677', 'CommentCount': '0', 'AcceptedAnswerId': '18218', 'CreationDate': '2013-11-20T22:46:01.723', 'Id': '18209'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>CS sometimes seems take for granted that $\\mathcal O(\\text{poly}(n))$ is "easy", while $\\mathcal O\\left(2^{poly(n)}\\right)$ is "difficult". I am interested in research into "difficult" polynomial-time algorithms, where the best-case solution to the constructed problem runs in $\\Theta(n^c)$, where $c$ can be chosen to be large; but the solution could be tested in $O(n)$ time.</p>\n\n<p><b>Question:</b></p>\n\n<blockquote>\n  <p>Given an integer $c$, can we construct problems that would:</p>\n  \n  <ul>\n  <li>Take $\\Theta\\left(n^c\\right)$ best-case-time to solve,</li>\n  <li>While taking $\\tilde{\\mathcal O}(n)$ time, and $\\tilde{\\mathcal O}(n)$ space, to test a solution?</li>\n  </ul>\n</blockquote>\n\n<p>($\\tilde{\\mathcal O}(n)$ is <a href="https://en.wikipedia.org/wiki/Big_O_notation#Extensions_to_the_Bachmann.E2.80.93Landau_notations" rel="nofollow">soft-big-oh</a>, meaning $O(n \\log^k n)$ for some $k$)</p>\n\n<hr>\n\n<p>Something I note - I might be mistaken somewhere here - is that presumably, if there is a $\\mathcal O(n)$ algorithm to test the solution, then perhaps there can be a $\\mathcal O(n)$ reduction to $\\rm k\\text{-}SAT$. If so, and, if $\\rm P=NP$, and there was a polynomial-time algorithm, say ${\\rm S{\\small OLVE}}\\left(\\Phi(\\mathbf x)\\right) \\in O({|\\mathbf x|}^{\\alpha})$ time, then I think this might contradict our $\\Theta(n^c)$ problem, if $\\alpha &lt; c$.</p>\n\n<hr>\n\n<p>The motivation would be to research the possibility of having a "one-way-function", that is linear(ithmic)-time computable, and best-case "difficult"-polynomial-time invert-able, where "difficult" means a high degree polynomial, instead of the usual exponential-time definition of "difficult"; perhaps this might be able to be used for cryptography even if $\\rm P=NP$ (like "post-P-equals-NP-cryptography", similar to how there is a field of "post-quantum-cryptography").</p>\n', 'ViewCount': '156', 'Title': 'Can we construct problems that can be solved in $\\Theta(n^c)$ time, and tested in $O(n)$ time', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-12-10T15:31:18.290', 'LastEditDate': '2013-12-10T15:31:18.290', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2755', 'Tags': '<algorithms><reference-request><time-complexity><algorithm-synthesis>', 'CreationDate': '2013-11-21T14:40:26.493', 'FavoriteCount': '3', 'Id': '18223'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I came to know that the graphic processing unit have something called memory coalescing. On reading on it I was not clear on the topic. Is this any way related to Memory Level Parallelism.</p>\n\n<p>I have searched in Google but was not able to obtain a satisfactory answer. </p>\n\n<p>It would be helpful if someone gives a more comprehensive, easy-to-understand explanation.</p>\n', 'ViewCount': '216', 'Title': 'What is "memory coalescing"?', 'LastEditorUserId': '11539', 'LastActivityDate': '2013-11-22T06:01:41.810', 'LastEditDate': '2013-11-22T06:01:41.810', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '18243', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11539', 'Tags': '<terminology><reference-request><computer-architecture><memory-management>', 'CreationDate': '2013-11-21T17:58:55.743', 'Id': '18229'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '64', 'Title': 'Are there pseudorandom number generators (PRNG) with no finite period?', 'LastEditDate': '2013-11-22T11:16:09.327', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<blockquote>\n  <p>The typical and widely used <a href="http://en.wikipedia.org/wiki/Pseudorandom_number_generator" rel="nofollow">PRNG</a>, the <a href="http://en.wikipedia.org/wiki/Linear_congruential_generator" rel="nofollow">linear congruential generator</a> always has a finite (though possibly "long") period. Are there PRNGs that have no finite period?</p>\n</blockquote>\n\n<p>For this question it is not necessary that it be practical or used in real-world implementations.</p>\n', 'Tags': '<reference-request><number-theory><pseudo-random-generators>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-22T19:53:32.883', 'CommentCount': '1', 'AcceptedAnswerId': '18251', 'CreationDate': '2013-11-22T03:12:52.983', 'Id': '18250'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '223', 'Title': 'What classes of data structures can be made persistent?', 'LastEditDate': '2013-11-22T20:19:38.030', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2755', 'FavoriteCount': '6', 'Body': '<p><b><a href="http://en.wikipedia.org/wiki/Persistent_data_structure">Persistent data structures</a></b> are immutable data structures. Operations on them return a new "copy" of the data structure, but altered by the operation; the old data structure remains unchanged though. Efficiency is generally accomplished by sharing some of the underlying data, and avoiding full copying of the data structure.</p>\n\n<p><b>Questions:</b></p>\n\n<blockquote>\n  <ul>\n  <li><p>Are there results about classes of data structures that can be made to be persistent (while keeping the same or very similar complexities)?</p></li>\n  <li><p>Can <em>all</em> data structures be made persistent (while keeping the same or very similar complexities)?</p></li>\n  <li><p>Are any data structures known to be unable to be made persistent (while keeping the same or very similar complexities)?</p></li>\n  </ul>\n</blockquote>\n', 'Tags': '<reference-request><data-structures><functional-programming>', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-12-01T00:30:18.423', 'CommentCount': '8', 'AcceptedAnswerId': '18266', 'CreationDate': '2013-11-22T18:13:18.380', 'Id': '18262'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Some guy on the internet <a href="http://networkengineering.stackexchange.com/a/5133/296">recommends</a> using the same ntp server when it is required to troubleshoot asymmetric routes through ICMP, and it\'s somewhat important to have synchronised time between the two machines doing ICMP.</p>\n\n<p>Granularity of timestamps in ICMP is 1ms (unique per 24h period), assume packet roundtrip between the source and destination of at least 100ms, each way of at least 50ms, plus jitter.</p>\n\n<p>I find the recommendation of using the same ntp server unreasonable; for one, because it would seem that the likelihood of any given reliable ntp server, anywhere in the world, carrying correct time is much higher than the likelihood of transmitting said time through the internet over longer distances (plus with potential jitter and packet loss), e.g. a good collection of local servers is already the best you could do for the task at stake.</p>\n\n<p>Basically, my conjecture is that, should a single ntp server be shared, it won\'t necessarily be a good server for both hosts doing ICMP, and would not contribute to the clock between the two (and only two) machines being the most synchronised, compared to a good collection of local servers instead.</p>\n\n<p>What\'s the mathematical take on this?</p>\n', 'ViewCount': '45', 'Title': 'NTP: synchronisation of time between two machines for ICMP timestamping', 'LastActivityDate': '2013-11-24T20:59:38.447', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11551', 'Tags': '<algorithm-analysis><reference-request><optimization><computer-networks><synchronization>', 'CreationDate': '2013-11-24T20:59:38.447', 'Id': '18310'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>The <a href="https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol#Timestamp" rel="nofollow">ICMP timestamp</a> protocol is useful for determining which path \u2014 forward or reverse \u2014 is contributing to the jitter on the line.</p>\n\n<p>In an ideal world, all computers would have an excellent ntpd, and time accuracy of about 1ms (the granularity of ICMP timestamp) should not be a problem:</p>\n\n<pre><code>0       145.5   146 = 75 + 71\n1       142.7   142 = 72 + 70\n2       140.7   140 = 70 + 70\n3       146.7   146 = 76 + 70\n4       148.3   148 = 77 + 71\n5       157.5   157 = 87 + 70\n6       167.1   167 = 96 + 71\n7       166.3   166 = 95 + 71\n8       167.7   167 = 97 + 70\n9       159.0   159 = 88 + 71\n</code></pre>\n\n<p>However, in reality, as per <a href="http://stackoverflow.com/questions/20172028/awk-hping-print-difference-between-icmp-originate-receive/20186781#20186781">http://stackoverflow.com/questions/20172028/awk-hping-print-difference-between-icmp-originate-receive/20186781#20186781</a>, the data could be like this:</p>\n\n<pre><code>0       165.9   166 = -142113 + 142279\n1       160.2   160 = -142118 + 142278\n2       155.2   155 = -142122 + 142277\n3       156.5   156 = -142121 + 142277\n4       164.7   165 = -142112 + 142277\n5       164.4   164 = -142111 + 142275\n6       160.9   161 = -142114 + 142275\n7       158.1   158 = -142117 + 142275\n8       155.6   156 = -142119 + 142275\n9       143.0   143 = -142131 + 142274\n10      153.2   153 = -142120 + 142273\n11      157.1   157 = -142115 + 142272\n12      158.3   158 = -142114 + 142272\n13      148.6   149 = -142123 + 142272\n14      144.3   144 = -142127 + 142271\n15      145.3   145 = -142125 + 142270\n</code></pre>\n\n<p>Which still shows that only one path is responsible for the jitter, since only one value jumps up and down randomly, whereas the other one is decreasing monotonically (probably due to an actively-running ntpd, which is correcting the time as we ping).</p>\n\n<p>Another example could be less wrong-looking of the time not being synchronised, say:</p>\n\n<pre><code>0       165.9   166 = -113 + 279\n</code></pre>\n\n<p>Or, better yet:</p>\n\n<pre><code>0       165.9   166 = 7 + 159\n</code></pre>\n\n<p>Or, say, still wrong by some 10ms to 40ms, on a landline link from Alberta to Vogtland, but much less obvious:</p>\n\n<pre><code>0       165.9   166 = 59 + 107\n</code></pre>\n\n<p>How to make scientific sense of this data, for it to be easily presentable, and not blatantly wrong?</p>\n\n<p>Feel free to assume to have between 10 to 1000 measurement points, measured over a couple of seconds or minutes.</p>\n', 'ViewCount': '50', 'Title': 'How to present ping data from ICMP timestamp', 'LastActivityDate': '2013-11-28T06:12:49.997', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11551', 'Tags': '<algorithms><reference-request><computer-networks><synchronization>', 'CreationDate': '2013-11-25T20:05:35.750', 'Id': '18332'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '188', 'Title': 'Is there a TM that halts on all inputs but that property is not provable?', 'LastEditDate': '2013-11-27T22:07:04.507', 'AnswerCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '2', 'Body': '<blockquote>\n  <p>Does there exist a Turing machine that halts on all inputs but that property is not provable for some reason?</p>\n</blockquote>\n\n<p>I am wondering if this question has been studied. Note, "unprovable" could mean a "limited" proof system (which in the weak sense think the answer must be yes). I am of course interested in the strongest possible answer, i.e. one that is not provable to halt on all inputs in say <a href="http://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory">ZFC set theory</a> or whatever.</p>\n\n<p>It occurred to me this could be true of the <a href="http://en.wikipedia.org/wiki/Ackermann_function">Ackermann function</a> but I am hazy on the details. It doesn\'t seem like Wikipedia describes this aspect clearly.</p>\n', 'Tags': '<computability><reference-request><turing-machines><halting-problem>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-12-03T19:03:16.420', 'CommentCount': '3', 'AcceptedAnswerId': '18425', 'CreationDate': '2013-11-27T21:44:59.707', 'Id': '18424'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is it common to try to improve an algorithm by decomposing its action on a topological piece of data (e.g. graphs, geometric data) into a series of steps, each of which only makes a local change/perturbation in a confined neighborhood of the data while fixing the rest?</p>\n\n<p>One benefit of this "breakdown" is improved conceptual understanding, and it also facilitates induction proofs (possibly based on invariants that are preserved by each step). Does this "decomposition" have a name in algorithm design? The idea might be similar to Divide and Conquer.</p>\n\n<p>One might say that every individual step in an algorithm, like deleting an edge or labeling a vertex of a graph, is small enough to be considered "local", but I\'m talking more about the "decomposition" in a higher-level description, like how truncating a polyhedron is local but sorting a list is not (even though at the lowest level, comparisons, insertions and deletions are local).</p>\n\n<p><strong>Examples of decomposing into local transformations</strong></p>\n\n<ul>\n<li><p>Augustin Cauchy\'s proof of his <a href="http://en.wikipedia.org/wiki/Cauchy%27s_theorem_%28geometry%29" rel="nofollow">Rigidity Theorem</a> relied on his "<a href="http://www.cs.mcgill.ca/~cs507/projects/1998/sfreel/cauchylemma.html" rel="nofollow">Arm Lemma</a>" that opened up a convex planar chain by sequentially opening at each vertex. Although his proof was found to be wrong, he decomposed the opening algorithm into a series of "local opening moves", and he tried to prove that each local move preserved convexity of the chain. By induction, convexity would still hold after iterating over all vertices.</p></li>\n<li><p>The <em>pivot algorithm</em> for <a href="http://en.wikipedia.org/wiki/Self-avoiding_walk" rel="nofollow">self-avoiding walks</a> (SAW) transforms a SAW into another by rotating or reflecting part of the original SAW. <a href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="nofollow">Markov Chain Monte Carlo</a> can employ this transformation as a transition between SAW states to sample the space of SAWs.</p></li>\n<li><p>As an application of the above, one technique of <a href="http://en.wikipedia.org/wiki/Protein_folding#Computational_methods_for_studying_protein_folding" rel="nofollow">protein folding prediction</a> is to force an amino acid chain into several known protein structures, choose the one with the lowest energy (due to intermolecular forces), then let the chosen structure "relax" into a configuation with lower energy. Relaxation involves the prescription of a few "local moves", where small parts of the chain can "wriggle around" (e.g. subchains pivoting around their ends), and random wriggles are allowed for a period of time to let the chain "stabilize". Modelling the chain as an SAW allows pivots to be used as a "wriggle".</p></li>\n</ul>\n', 'ViewCount': '171', 'Title': 'Decomposing an Algorithm into Local Transformations/Perturbations', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-13T22:04:18.290', 'LastEditDate': '2013-12-13T13:27:28.013', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '11678', 'Tags': '<algorithms><terminology><reference-request><algorithm-design>', 'CreationDate': '2013-11-28T08:34:39.540', 'Id': '18438'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '92', 'Title': '"Unusual" coupling between a decision problem and a corresponding optimization problem', 'LastEditDate': '2013-12-04T18:21:05.133', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '2', 'Body': '<p>There seems to usually be a tight connection between <a href="http://en.wikipedia.org/wiki/Decision_problem" rel="nofollow">decision problems</a> and (corresponding) <a href="http://en.wikipedia.org/wiki/Optimization_problem" rel="nofollow">optimization problems</a> in general. However, is this always the case? </p>\n\n<blockquote>\n  <p>Are there examples where the typical "tight coupling" between a decision problem and the correponding optimization problem breaks down or behaves in an unusual way, e.g. have significantly different complexity?</p>\n</blockquote>\n\n<p>Or, maybe there is a case where there is a cluster of problems that are all closely related, but the "best" or "definitive" version is not obvious or apparent? Also, I am looking for any survey or broad overview or discussion of this apparent basic connection between decision and optimization problems.</p>\n\n<p>A similar question was asked <a href="http://cs.stackexchange.com/questions/939/optimization-version-of-decision-problems">here</a>, but the answers were highly theoretical and it did not seem to yield any specific or tangible examples.</p>\n', 'Tags': '<complexity-theory><reference-request><optimization><decision-problem>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-12-04T18:21:05.133', 'CommentCount': '5', 'AcceptedAnswerId': '18608', 'CreationDate': '2013-12-03T17:10:07.033', 'Id': '18575'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Upon reading  <a href="http://stackoverflow.com/q/20356678/1243762">Do source code optimizers exist?</a> I knew that such programs existed but the ones I have worked with use a set of rules to drive a transformation algorithm. <a href="http://stackoverflow.com/users/120163/ira-baxter">Ira Baxter</a> provided a link to the tools running the algorithms with his <a href="http://stackoverflow.com/a/20358310/1243762">answer</a> but what I was more after from the question was the rules. In the comments Ira noted the  <a href="http://www.bayfronttechnologies.com/itc76.pdf" rel="nofollow">Irvine Program Catalog</a>.</p>\n\n<p>Are there any more papers, sites, etc. that list such rules?</p>\n\n<p>I will accept any answer but have a preference for rules used with functional languages.</p>\n', 'ViewCount': '56', 'Title': 'Where can I find rules for source to source transformation optimization rules?', 'LastActivityDate': '2013-12-04T00:24:40.743', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18590', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '268', 'Tags': '<reference-request><term-rewriting>', 'CreationDate': '2013-12-03T21:46:11.533', 'Id': '18583'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am talking about a measurement plan for software metrics and I am looking for references.</p>\n\n<p>In emperical software engineering there are code level measurements ("software metrics" that measure, e.g., some property like a paprameter for the redundancy of the code and possibly also a parameter of coupling and cohesion of a large software system.</p>\n\n<p>I have a finished paper with software measurements, but the feedback to me was that the way the measurements parameters are derive can be more, say "systematic" or better put in relationship with the research goals. I am interested to improve my approach for my "future work" (My English is not native, so perhaps I don\'t use the right terms.)</p>\n\n<p>Are there references on a "measurement plan for software metric" that helps to systematically derive measurement parameters from research goals? (Similar to the <a href="http://en.wikipedia.org/wiki/GQM" rel="nofollow">goal question metric</a> but more focused at academia?) I would like to</p>\n', 'ViewCount': '35', 'Title': 'Code measurements in emperical software engineering: how to plan measurements?', 'LastEditorUserId': '1829', 'LastActivityDate': '2013-12-12T19:02:33.633', 'LastEditDate': '2013-12-12T19:02:33.633', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><object-oriented>', 'CreationDate': '2013-12-12T15:52:42.563', 'FavoriteCount': '1', 'Id': '18926'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '99', 'Title': 'What abbreviations to use in CS citations?', 'LastEditDate': '2014-02-10T08:51:53.487', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Body': '<p>What abbreviations should I use in computer science citations?</p>\n\n<p>I just found the <a href="http://www.computer.org/portal/web/publications/style_refs" rel="nofollow">IEEE style guide</a>. It lists abbreviations such as <code>Eng.</code>, and <code>Conf.</code>.</p>\n\n<p>What are standard journal abbreviations in CS, and where can I find a list?</p>\n\n<p>Any other abbreviations I should (not) use?</p>\n', 'ClosedDate': '2014-02-17T18:24:07.797', 'Tags': '<reference-request>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-10T08:51:53.487', 'CommentCount': '4', 'AcceptedAnswerId': '18941', 'CreationDate': '2013-12-12T23:52:10.627', 'Id': '18938'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '142', 'Title': 'Problems that are NP but polynomial on graphs of bounded treewidth', 'LastEditDate': '2013-12-16T12:50:01.927', 'AnswerCount': '4', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '4598', 'FavoriteCount': '1', 'Body': '<p>I <em>heard</em> <a href="http://www.youtube.com/watch?v=cQwhYtTfZCs&amp;list=PLawkBQ15NDElkyLbJBKwZCgA5jxsKRlK-&amp;index=22" rel="nofollow">here</a> that the Hamiltonian cycle problem is polynomial on graphs of bounded treewidth.</p>\n\n<p>I am interested in examples/references to different problems which is essentially hard but having polynomial complexity on graphs of bounded treewidth. </p>\n', 'Tags': '<complexity-theory><graph-theory><reference-request><np><polynomial-time>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-05T14:13:58.150', 'CommentCount': '0', 'AcceptedAnswerId': '19036', 'CreationDate': '2013-12-15T20:00:48.920', 'Id': '19019'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I came across an interesting procedure that ranks (sorts) a set of tuples, <em>not</em> by comparisons between tuples, but by the proximity between <em>next</em> tuple(s) and the set of tuples already ranked.</p>\n\n<p>Specifically, consider the ranking procedure as follows,</p>\n\n<p>Input: $D=\\{p_i\\mid p_i \\in \\mathbb{R}^2, i=1, 2,\\ldots,n\\}$, $i_{start} \\in \\{1, 2,\\ldots, n\\}$, and distance metric $f: 2^D \\times D \\mapsto \\mathbb{R}_{\\ge 0}$<br>\nOutput: $\\Pi = \\left[ i_1, i_2, \\ldots, i_n\\right]$</p>\n\n<ol>\n<li>$\\Pi \\gets \\left[~ \\right]$; // empty sequence</li>\n<li>$A \\gets \\emptyset$;  </li>\n<li>$i_{next} \\gets i_{start}$;  </li>\n<li>while $D \\neq \\emptyset$  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$\\Pi \\gets \\Pi \\oplus i_{next} $ // append $i_{next}$ to sequence</li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$A \\gets A \\bigcup \\left\\{ p_{i_{next}} \\right\\}$; // $p_{i_{next}}$ is a tuple from $D$ identified by subscript ${i_{next}}$  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$D \\gets D \\setminus \\left\\{p_{i_{next}}\\right\\}$;  // same $p_{i_{next}}$ as in line 6  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;${i_{next}} \\gets \\min \\bigl\\{\\arg_j\\,\\min_{p_j\\in D}\\,f(A, p_j) \\bigr\\}$; // not defined when $D = \\emptyset$   </li>\n</ol>\n\n<p>An example of the distance metric $f(A, p)$ is, say, the distance between 2D point $p$ and the centroid of 2D points in set $A$. As such, the procedure is literally the expansion of a cluster of 2D points, starting from a given point $p_{start}$, until all $n$ points from $D$ have been included. And the sequence $\\Pi$ records the order by which points from $D$ are included in the cluster.</p>\n\n<p>Could anyone shed some light on the literature, background, or well-known examples, of such ranking procedures? In particular, are there any previous results on the complexity bounds of such a procedure perhaps under different types of distance metrics?</p>\n', 'ViewCount': '93', 'Title': 'On ranking (sorting) by a varying distance metric', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-23T13:08:49.810', 'LastEditDate': '2013-12-23T13:08:49.810', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7644', 'Tags': '<algorithms><complexity-theory><reference-request><sorting><ranking>', 'CreationDate': '2013-12-19T18:41:36.297', 'FavoriteCount': '1', 'Id': '19128'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am curious whether the following problems has been studied before, but wasn't able to find any papers about it:</p>\n\n<p>Given a planar graph G, and two vertices s and t, find an st-path $P$ which minimizes the number of distinct faces of G which contain vertices of $P$ on their boundary.</p>\n\n<p>Does anybody know any references?  </p>\n", 'ViewCount': '70', 'Title': 'Finding an st-path in a planar graph which is adjacent to the fewest number of faces', 'LastActivityDate': '2013-12-20T00:57:12.100', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '12250', 'Tags': '<algorithms><graph-theory><reference-request>', 'CreationDate': '2013-12-20T00:57:12.100', 'Id': '19137'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>The PARTITION problem is NP-complete:</p>\n\n<p>INSTANCE: finite set $A$ and a size $s(a) \\in \\mathbb{Z}^+$ for each $a \\in A$<br>\nQUESTION: Is there a subset $A' \\subseteq A$ such that $\\sum_{a \\in A'} s(a) = \\sum_{a \\in A \\setminus A'} s(a)$ </p>\n\n<p>The problem remains NP-complete even if the elements are ordered as $a_1,a_2,...,a_{2n}$ and we require that $A'$ contains exactly one of $a_{2i-1},a_{2i}$ for $1 \\leq i \\leq n$ (Garey and Johnson, Computers and Intractability).</p>\n\n<p>This variant should be known as EVEN-ODD PARTITION.</p>\n\n<p>Do you see a quick reduction to prove its hardness? (or do you know the paper where it was first defined and proved)</p>\n", 'ViewCount': '77', 'Title': 'Hardness proof of EVEN-ODD PARTITION', 'LastActivityDate': '2013-12-25T21:35:45.377', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '19272', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<reference-request><np-complete>', 'CreationDate': '2013-12-25T10:46:58.100', 'Id': '19271'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for a reference for the following theorem:</p>\n\n<p>Let $G$ be a bipartite graph with partitions $X$ and $Y$, each with the same number of vertices ($n$).</p>\n\n<p>There is a nonempty subset $Y_1 \\subseteq Y$, and a partition of $X$ to disjoint subsets $X_1$ and $X_2$, such that:</p>\n\n<ul>\n<li>There is a complete matching between $X_1$ and a subset of $Y_1$;</li>\n<li>There are no edges between $X_2$ and $Y_1$.</li>\n</ul>\n\n<p>Intuitively, $X$ can be seen as a set of men and $Y$ can be seen as a set of women. An edge between $x \\in X$ and $y \\in Y$ means that "$x$ and $y$ like each other" ("like" is considered a symmetric relation). </p>\n\n<p>The goal is to find a subset of the women ($Y_1$) and a subset of the men ($X_1$), such that each man can marry a woman he likes without upsetting any of the other men ($X_2$), because no unmarried man likes any married woman.</p>\n\n<p>This sounds similar to <a href="https://en.wikipedia.org/wiki/Hall%27s_marriage_theorem" rel="nofollow">Hall\'s marriage theorem</a>, but the premise is simpler. And, I am mainly looking for a reference that I can cite.</p>\n\n<p>EDIT: Some special cases:</p>\n\n<ul>\n<li>If the graph is full (i.e. any man likes any woman), then we can take $Y_1=Y$, $X_1=X$, $X_2=\\phi$.</li>\n<li>If the graph is empty (i.e. no man likes no woman), then we can take $Y_1=Y$, $X_1=\\phi$, $X_2=X$.</li>\n<li>If there is $y \\in Y$ with no neighbours (i.e. a woman that doesn\'t like any man), then we can take $Y_1={y}$, $X_1=\\phi$, $X_2=X$.</li>\n<li>If there is $y \\in Y$ with a single neighbour $x \\in X$  (i.e. a woman that likes a single man), then we can take $Y_1={y}$, $X_1={x}$, $X_2=X-{x}$.</li>\n</ul>\n\n<p>The question becomes more problematic when all $y \\in Y$ have at least two neighbours.</p>\n', 'ViewCount': '63', 'Title': 'Partition a bipartite graph to a complete matching and an independent set', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-12-26T06:38:00.980', 'LastEditDate': '2013-12-26T06:38:00.980', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<graph-theory><reference-request>', 'CreationDate': '2013-12-25T16:31:05.593', 'Id': '19281'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I know that standard Bloom Filters only have operations like inserting elements and checking if an element belongs to filter, but are also some modification of Bloom filters which enable a delete operation--for example: counting Bloom filters. I heard also about another method, which uses a second filter. If I want to remove an element I have to 'insert' it into this second filter. I can't find how this proposed structure operates, any article about it, or even the name of the originator. Maybe someone can share with me with a link to any interesting articles about this method? I found a lot of articles about counting Bloom filters and other methods, but I can't find any description of this one.</p>\n", 'ViewCount': '101', 'Title': 'Deleting in Bloom Filters', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T11:35:49.423', 'LastEditDate': '2014-04-29T11:35:49.423', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12038', 'Tags': '<reference-request><data-structures><probabilistic-algorithms><bloom-filters><dictionaries>', 'CreationDate': '2013-12-25T22:52:19.973', 'Id': '19292'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>An exercise that was in a past session is the following:</p>\n\n<blockquote>\n  <p>Prove that there exists an undecidable subset of $\\{1\\}^*$</p>\n</blockquote>\n\n<p>This exercise looks very strange to me, because I think that all subsets are decidable.</p>\n\n<p>Is there a topic that I should read to find a possible answer?</p>\n', 'ViewCount': '545', 'Title': 'Undecidable unary languages (also known as Tally languages)', 'LastEditorUserId': '851', 'LastActivityDate': '2013-12-28T13:47:57.850', 'LastEditDate': '2013-12-28T13:47:57.850', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '19331', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '851', 'Tags': '<reference-request><turing-machines><undecidability>', 'CreationDate': '2013-12-27T18:20:42.287', 'Id': '19329'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '108', 'Title': 'Existence of NP problems with complexity intermediate between P and NP-hard', 'LastEditDate': '2014-01-07T08:03:04.937', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10447', 'FavoriteCount': '0', 'Body': "<p>Assuming P!=NP, there is a result that there are decision problems intermediate between P and NP-complete. That is, the class NP cannot be a union of two disjoint subsets: P and NP-complete.</p>\n\n<p>I could never quite understand the proof of the above result. The proof I saw in a textbook was starting with the assumption that one can enumerate all P and NP-hard problems, and then proceeding with a construction of a function that didn't fit in either. However, this construction seemed a bit fishy to me; in particular, the assumption that one can start with enumerated set of problems in a particular class, the NP.</p>\n\n<p>Could you refer me to a clear self-contained proof of the statement in the 1st paragraph? More generally, what would be a good reference for proofs of such results?</p>\n", 'Tags': '<complexity-theory><reference-request><np><p-vs-np>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-07T21:14:35.700', 'CommentCount': '0', 'AcceptedAnswerId': '19566', 'CreationDate': '2014-01-06T20:23:25.287', 'Id': '19543'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u"<p>Assume having a graph $G_{variables}=(V,U)$ where $V=\\{v_1,v_2,\u2026,v_n\\}$ is a set of variables; each variable $v_i\\in V$ is associated with a set of possible values (it's domain) $dom(v_i)$. </p>\n\n<p>Let $P$ be a search problem (i.e reachability problem) over graph $G=(O,E)$ where $O$ is the cartesian product of the variables domains. Let $T$ be a junction tree resulted from $G_{variables}$. $P$ can be also solved through searching every clique in $T$. I am looking for keywords/examples of such problems. $G_{variables}$ preferably to be DAG.  </p>\n", 'ViewCount': '30', 'Title': 'Search problems that can also be solved by junction trees and searching cliques', 'LastEditorUserId': '4598', 'LastActivityDate': '2014-01-10T04:15:00.893', 'LastEditDate': '2014-01-10T04:15:00.893', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<graph-theory><reference-request><search-algorithms><search-problem>', 'CreationDate': '2014-01-09T17:48:23.083', 'Id': '19602'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>(I\'m aware that software questions are better suited for stackoverflow, but since DFAs are not something that software developers usually care about, I hope it\'s alright if I ask here.)</p>\n\n<p>I\'m currently working on a project to do with regular overapproximations for context free languages. For this purpose, I need to implement stuff that requires me to represent regular languages in a minimized form, intersect them, complement them, etc. - i.e. everything that\'s easy and quick to do with DFAs. However, I\'m having a hard time finding still-maintained libraries for DFAs in C++. I could find <a href="http://augeas.net/libfa/index.html" rel="nofollow">libfa</a> which does everything quite nicely, but that\'s as far as I\'ve gotten. <a href="http://www.cse.ust.hk/faculty/dwood/.grail/" rel="nofollow">Grail</a> hasn\'t been maintained in 15+ years and the download link is dead. <a href="http://fado.dcc.fc.up.pt/" rel="nofollow">FAdo</a> seemed interesting initially, but it\'s in Python and I can\'t determine whether there\'s a way to use it as a C++ library, or whether it offers the functionality I mentioned above (the Docs are a bit slim).</p>\n\n<p>Do you know of C(++) libraries for DFAs that offer minimization, intersection and complementation that are free for academic use? I\'d like to have at least one alternative to libfa that I can use.</p>\n', 'ViewCount': '92', 'Title': 'C(++) library for DFAs - free for academic use', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-12T11:35:11.127', 'LastEditDate': '2014-01-12T11:35:11.127', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6689', 'Tags': '<reference-request><automata><finite-automata><mathematical-software>', 'CreationDate': '2014-01-12T04:18:00.143', 'FavoriteCount': '1', 'Id': '19664'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Let\'s suppose I have an image of a person and its corresponding background. Using OpenCV I can relatively easily get a silhouette of the person from the image. </p>\n\n<p>I am doing a project on human recognition using silhouettes and the only things I came up with for feature extraction are so called Granlund coefficients derived from Fourier coefficients and <a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#humoments" rel="nofollow">Hu moments</a> which provide me with features I can send to various classifiers I have. </p>\n\n<p>What I am further curious about is what other methods are there, if any, for feature extraction from silhouettes? </p>\n\n<p>EDIT: In accordance with the first commentator, I will expand my question. As I said, I have tried with Granlund coefficients and Hu moments, both of them are well documented standard techniques which you can find in OpenCV documentation and IEEE Xplore digital library (Granlund coefficients). </p>\n\n<p>Also, I didn\'t say anything specific about the features, I just want to know about various methods for silhouette feature extraction, other than the two mentioned above.</p>\n', 'ViewCount': '48', 'Title': 'Methods for silhouette feature extraction', 'LastEditorUserId': '9250', 'LastActivityDate': '2014-01-20T20:33:41.613', 'LastEditDate': '2014-01-20T20:33:41.613', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9250', 'Tags': '<reference-request><pattern-recognition>', 'CreationDate': '2014-01-14T22:21:28.913', 'Id': '19728'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for papers/methods (or at least problem examples) where the original search problem $P$ can be solved by either:</p>\n\n<ol>\n<li>Searching through the original graph. or</li>\n<li>By decomposing it into several subset of problems $P_1,P_2, \\dots,P_n$.</li>\n</ol>\n\n<p>Ideally $sol(P )=sol(P_1)\\cup sol(P_2)\\cup \\ldots \\cup(P_n)$ with no preprocessing (i.e the union of the subproblems correspond directly to the solution of the problem).  </p>\n\n<p>I have no constraint; though prefer the underlying graph to be a DAG and the problem to be a reachability problem. Google seems to fail on finding such papers. </p>\n', 'ViewCount': '74', 'Title': 'Decomposing the search problem into several small problems', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-19T12:32:29.493', 'LastEditDate': '2014-01-17T21:36:52.663', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '19804', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<graph-theory><reference-request><search-algorithms><search-problem>', 'CreationDate': '2014-01-17T18:59:51.023', 'Id': '19792'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I understand the restrictions, because a regular language is expressive enough to allow all types of tokens. And even if some context is needed in many languages to tokenize properly, they all seem to be "approximately" regular languages.</p>\n\n<p>Yet I would be interested if any attempt in any programming language, possibly esoteric language, has been taken to completely eschew the conventional division between type-3 lexers and type-2 parser.</p>\n', 'ViewCount': '33', 'Title': 'Has there been a lexer that takes in much more than a regular language?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-20T14:35:25.787', 'LastEditDate': '2014-01-20T09:14:37.250', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4289', 'Tags': '<reference-request><regular-languages><compilers>', 'CreationDate': '2014-01-19T23:12:01.723', 'Id': '19837'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Recently i\'ve been dealing with a problem that led me to the following questions:</p>\n\n<ul>\n<li>Is there a good algorithm to enumerate all maximum/perfect matchings in a general graph?</li>\n<li>Is there a good algorithm for finding all maximum/perfect matchings in a general graph?</li>\n<li>Are these two problems equivalent in their complexity?</li>\n</ul>\n\n<p>I\'ve stumbled upon the following references:</p>\n\n<ul>\n<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.8179&amp;rep=rep1&amp;type=pdf" rel="nofollow">Algorithms for Enumerating All Perfect Maximum and Maximal Matchings In Bipartite Graphs</a>- Suggesting an algorithm for enumerating all maximum matchings in a bipartite graph.</li>\n<li><a href="http://www.sciencedirect.com/science/article/pii/0893965994900450" rel="nofollow">Finding All the Perfect Matchings\nin Bipartite Graphs</a>- Suggesting an algorithm for finding all perfect matchings in bipartite graphs</li>\n</ul>\n\n<p>Both algorithms\' complexity depend on the number of perfect matchings in the graph (meaning exponential running time in the worst case).</p>\n\n<p>Moreover, both articles deal with bipartite graphs, I couldn\'t find similar articles dealing with the same problem in general graphs.</p>\n\n<p>I\'d appreciate information and references about the above problems.</p>\n', 'ViewCount': '131', 'Title': 'Counting and finding all perfect/maximum matchings in general graphs', 'LastEditorUserId': '10438', 'LastActivityDate': '2014-01-24T19:06:05.883', 'LastEditDate': '2014-01-24T16:12:01.350', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19926', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10438', 'Tags': '<algorithms><complexity-theory><graph-theory><reference-request><matching>', 'CreationDate': '2014-01-23T21:28:38.760', 'Id': '19924'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>We have had <a href="http://cs.stackexchange.com/search?q=cook+reduction+is%3Aquestion">several questions about the relation of Cook and Karp reductions</a>. It\'s clear that Cook reductions (polynomial-time Turing reductions) do not define the same notion of NP-completeness as Karp reductions (polynomial-time many-one reductions), which are usually used. In particular, Cook reductions can not separate NP from co-NP even if P $\\neq$ NP. So we should not use Cook reductions in typical reduction proofs. </p>\n\n<p>Now, students found a peer-reviewed work [1] that uses a Cook-reduction for showing that a problem is NP-hard. I did not give them full score for the reduction they took from there, but I wonder.</p>\n\n<p>Since Cook reductions <em>do</em> define a similar notion of hardness as Karp reductions, I feel they <em>should</em> be able to separate P from NPC resp. co-NPC, assuming P $\\neq$ NP. In particular, (something like) the following should be true:</p>\n\n<p>$\\qquad\\displaystyle L_1 \\in \\mathrm{NP}, L_2 \\in \\mathrm{NPC}_{\\mathrm{Karp}}, L_2 \\leq_{\\mathrm{Cook}} L_1 \\implies L_1 \\in \\mathrm{NPC}_{\\mathrm{Karp}}$.</p>\n\n<p>The important nugget is that $L_1 \\in \\mathrm{NP}$ so above noted insensitivity is circumvented. We now "know" -- by definition of NPC -- that $L_2 \\leq_{\\mathrm{Karp}} L_1$.</p>\n\n<p>As has been <a href="http://chat.stackexchange.com/transcript/message/13483686#13483686">noted by Vor</a>, it\'s not that easy (notation adapted):</p>\n\n<blockquote>\n  <p>Suppose that $L_1 \\in \\mathrm{NPC}_{\\mathrm{Cook}}$, then by definition, for all languages $L_2 \\in \\mathrm{NPC}_{\\mathrm{Karp}} \\subseteq \\mathrm{NP}$ we have $L_2 \\leq_{\\mathrm{Cook}} L_1$; and if the above implication is true then $L_1 \\in \\mathrm{NPC}_{\\mathrm{Karp}}$ and thus $\\mathrm{NPC}_{\\mathrm{Karp}} = \\mathrm{NPC}_{\\mathrm{Cook}}$ which is still an open question.</p>\n</blockquote>\n\n<p>There may be other differences between the two NPCs but co-NP.</p>\n\n<p>Failing that, are there any known (non-trivial) criteria for when having a Cook-reduction implies Karp-NP-hardness, i.e. do we know predicates $P$ with</p>\n\n<p>$\\qquad\\displaystyle L_2 \\in \\mathrm{NPC}_{\\mathrm{Karp}}, L_2 \\leq_{\\mathrm{Cook}} L_1, P(L_1,L_2) \\implies L_1 \\in \\mathrm{NPC}_{\\mathrm{Karp}}$?</p>\n\n<hr>\n\n<ol>\n<li><a href="http://dx.doi.org/10.1089/cmb.1994.1.337" rel="nofollow">On the Complexity of Multiple Sequence Alignment</a> by L. Wang and T. Jiang (1994)</li>\n</ol>\n', 'ViewCount': '71', 'Title': 'Can we construct a Karp reduction from a Cook reduction between NP problems?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-05T07:56:44.503', 'LastEditDate': '2014-02-05T07:56:44.503', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><reference-request><np-complete><reductions>', 'CreationDate': '2014-01-29T18:33:16.763', 'FavoriteCount': '1', 'Id': '20074'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'ve been looking into computer assisted music composition lately for my school project. While searching for literature I came across <a href="http://igm.rit.edu/~jabics/GenJam94/Paper.html" rel="nofollow">GenJam</a>, an interactive jazz improvisation software which uses genetic algorithms to produce musical phrases. </p>\n\n<p>I was wondering If anyone has done some work on computer generated music and could suggest term papers, books or other reading material I should look into. </p>\n', 'ViewCount': '72', 'Title': 'Computer Music Composition', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-31T22:36:37.800', 'LastEditDate': '2014-01-31T10:52:11.543', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '13272', 'Tags': '<algorithms><reference-request><genetic-algorithms>', 'CreationDate': '2014-01-31T10:24:17.680', 'FavoriteCount': '1', 'Id': '20150'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There is a new <a href="http://quant.stackexchange.com/">Quantitative Finance SE site</a>. However, I am interested in asking the "CS crowd": </p>\n\n<blockquote>\n  <p>What are some interesting key references or surveys on applying algorithms to stock trading analysis?</p>\n</blockquote>\n\n<p>There are many such references, however, I am particularly interested in those that would appeal to those with a CS background. Further, I am especially interested in those that find surprising applications of TCS or mathematics theory.</p>\n', 'ViewCount': '41', 'Title': 'Applications of algorithms to stock trading analysis', 'LastEditorUserId': '472', 'LastActivityDate': '2014-01-31T23:16:57.623', 'LastEditDate': '2014-01-31T23:16:57.623', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<reference-request><machine-learning><optimization><statistics>', 'CreationDate': '2014-01-31T22:55:00.353', 'Id': '20173'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given a set of colors $M$ and a graph $G=(V,E)$. Allocate the colors to minimize the number edges with same color on the two vertices of the edge (i.e. minimize pairs of adjoining vertices with same color.).</p>\n\n<p>This problem is different from standard <a href="http://en.wikipedia.org/wiki/Graph_coloring" rel="nofollow">coloring problem</a>. Could someone please provide some literature where this problem is studied?</p>\n', 'ViewCount': '134', 'Title': 'A variation of the graph coloring problem', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-07T23:19:01.293', 'LastEditDate': '2014-02-07T22:28:30.997', 'AnswerCount': '1', 'CommentCount': '10', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<graph-theory><reference-request><colorings>', 'CreationDate': '2014-02-07T17:30:35.593', 'FavoriteCount': '1', 'Id': '21431'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>As an applied person, I\'m facing one practical problem deciding whether a set of Wang tile could tile the plane periodically or aperiodically. Although both problems seem undecidable, but I\'m on a more practical aspect. Say, if the program accidentally ("or systematically") find some "periodic structure", then it stops and tells me there exists periodic pattern. If during running, it enumerates all the use of tile and finds that it simply cannot tile the plane, then it tell me this set of tiles cannot tile the plane. Even if the program didn\'t stop, then after running some steps, it returns me a few most ordered patterns that that could "possibly tile the plane".</p>\n\n<p>For practical purpose, I simply assume if the tessellation are up to some size (maybe 1000*1000) then I say "it could tile the plane practically".</p>\n\n<p>So my most interested question is: is there any established programs or algorithms that "try" to help me analyze a set of tile even if it might not halt ("but I could define some imposed halting condition").</p>\n\n<p>For context why I am interested in this problem, here\'s the links:</p>\n\n<ul>\n<li><p><a href="http://mathoverflow.net/questions/147374/coloring-in-lattice">Coloring in lattice</a></p></li>\n<li><p><a href="http://mathoverflow.net/questions/149565/reference-for-wang-tile">Reference for Wang Tile</a></p></li>\n<li><p><a href="http://mathoverflow.net/questions/157214/periodic-tiling-of-wang-tile">Periodic Tiling of Wang tile</a></p></li>\n</ul>\n\n<p>Also cross posted to <a href="http://mathoverflow.net/questions/157239/computational-approach-deciding-whether-a-set-of-wang-tile-could-tile-the-space">Math Overflow</a>.</p>\n', 'ViewCount': '47', 'Title': 'Computational approach deciding whether a set of Wang Tile could tile the space up to some size', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-10T21:51:57.717', 'LastEditDate': '2014-02-10T21:51:57.717', 'AnswerCount': '0', 'CommentCount': '8', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14553', 'Tags': '<reference-request><computational-geometry><tiling><mathematical-software>', 'CreationDate': '2014-02-10T20:27:06.353', 'FavoriteCount': '2', 'Id': '21502'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I would like to find a algorithm that will do the following:</p>\n\n<blockquote>\n  <p>Given two sets $A, B \\subseteq \\mathbb{R}$, where $|B| &gt; |A|$, find the largest subset $C \\subseteq B$, such that:</p>\n  \n  <p>$\\qquad |\\operatorname{mean}(A) - \\operatorname{mean}(C) |&lt; \\delta$ and</p>\n  \n  <p>$\\qquad |\\operatorname{std}(A) - \\operatorname{std}(C) | &lt; \\epsilon$ </p>\n</blockquote>\n\n<p>I think this problem is NP-hard, but I would like a good approximation that does reasonably well. An even harder version of this is to find the larget subset $C$ that matches not just the moments, but the histogram of $A$ to some quality metric. If you have a solution, or can point to same papers that would great!</p>\n\n<p>I am a neuroscientist, and this is for my research.</p>\n', 'ViewCount': '61', 'Title': 'Finding largest subset that matches moments', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T23:46:11.150', 'LastEditDate': '2014-02-12T08:37:57.857', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14589', 'Tags': '<algorithms><reference-request><optimization>', 'CreationDate': '2014-02-11T23:42:08.537', 'Id': '21545'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>While reading the research paper <a href="http://dl.acm.org/citation.cfm?id=2108244" rel="nofollow">Polylogarithmic Concurrent Data Structures from Monotone Circuits [@JACM\'2012]</a> by James Aspnes, Hagit Attiya, and Keren Censor-Hillel, I am not sure about some points and need some verification and explanation.  </p>\n\n<p>In the first three sections of the paper, the authors presents constructions of useful concurrent data structures, including <strong>max register</strong> and <strong>counters</strong> with bounded values, with step complexity that is <em>polylogarithmic</em> in the number of values the object can take or the number of operations applied to it. Specifically (and extremely in brief),  </p>\n\n<blockquote>\n  <p>The max register is an object $r$ supporting both <code>WriteMax(r,t)</code> and <code>ReadMax(r)</code> operations. It is recursively constructed from a tree of increasingly large max registers. The implementation is wait-free and linearizable.    </p>\n  \n  <p>The counter, supporting an <code>CounterIncrement()</code> operation and a <code>ReadCounter()</code> operation, is structured as a binary tree of max registers. The implementation is also wait-free and linearizable. </p>\n</blockquote>\n\n<p>My problems are as follows:</p>\n\n<blockquote>\n  <p>(1) <strong>On the max register:</strong> What is the space complexity, i.e., the number of base objects of multi-writer multi-reader (MWMR, for short) registers, of the recursive implementation?  </p>\n</blockquote>\n\n<p>[[<strong>In my opinion:</strong>]] It is $2m - 1$ for there is exactly one MWMR register for each node in the tree. In particular, the tree can be thought of as the logic structure of an underlying array of $2m-1$ MWMR registers.</p>\n\n<blockquote>\n  <p>(2) <strong>Also on the max register:</strong> Is it possible to implement a max register with only a single MWMR register? Are there any related work? </p>\n</blockquote>\n\n<p>[[<strong>(EDIT) In my opinion:</strong>]] I have found a <a href="http://www.cs.bgu.ac.il/~satcc112/wiki.files/Jayanti-Time-and-Space-Lower-Bounds.pdf" rel="nofollow">related paper: Time and Space Lower Bounds for Non-blocking Implementations [@PODC\'1996]</a>, in which Jayanti et al. show that </p>\n\n<blockquote>\n  <p>Operations must take $\\Omega(n)$ <strong>space</strong> and $\\Omega(n)$ steps in the worst case, for many common data structures, including (unbounded) max registers and (unbounded) counters, where $n$ is the number of concurrent processes.</p>\n</blockquote>\n\n<p>However, I have not realized similar conclusions concerning about value-bounded data structures. </p>\n\n<blockquote>\n  <p>(3) <strong>On both the max register and the counter:</strong> Are there any related work on the max&amp;min register supporting both <code>ReadMax(r)</code> and <code>ReadMin(r)</code>? Similarly, are there any related work on the inc&amp;dec counter supporting both <code>CounterIncrement()</code> and <code>CounterDecrement()</code>?</p>\n</blockquote>\n', 'ViewCount': '22', 'Title': 'Polylogarithmic value-bounded concurrent data structures such as max register, counter, and monotone circuit', 'LastEditorUserId': '4911', 'LastActivityDate': '2014-02-13T05:53:17.450', 'LastEditDate': '2014-02-13T05:53:17.450', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><data-structures><distributed-systems><concurrency>', 'CreationDate': '2014-02-12T08:03:37.973', 'Id': '21561'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I know that this is a known theorem but I can't find its proof. The theorem is: </p>\n\n<blockquote>\n  <p>The write-contention of any $n$-process wait-free consensus algorithm (implemented from any read-modify-write operations) is $n$.</p>\n</blockquote>\n\n<p>Can someone link me to a proof or an explanation?</p>\n", 'ViewCount': '38', 'Title': 'Proof of contention of the wait-free consensus algorithm', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-12T13:30:08.410', 'LastEditDate': '2014-02-12T13:30:08.410', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14602', 'Tags': '<algorithms><reference-request><proof-techniques><concurrency>', 'CreationDate': '2014-02-12T10:02:18.260', 'Id': '21566'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><strong>EDIT</strong></p>\n\n<p>As requested, a single question </p>\n\n<p><strong>Why can\'t arbitrary base conversion be done as fast as converting from base $b$ to base $b^k$ ?</strong> </p>\n\n<p>There is a big time complexity difference, so I am also interested in <em>further reading material about it</em>.</p>\n\n<hr>\n\n<p><strong>Old. Original question</strong></p>\n\n<p>Conversion between power-2-radix can be done faster than between non-power-of-2 radix, they can be even done in parallel, as every digit (or some groups of them) can be decoded independently of the rest.</p>\n\n<p>For example the binary number <code>00101001</code> can be converted to hexadecimal <code>0x29</code> nibble by nibble (<code>0010</code> and <code>1001</code>), and vice versa (i.e. every hex-digit can be parsed to 4 bits independently of the rest), but doing that conversion from to decimal (or any other non-power-of-2 radix) it\'s not so easy because digits affects each other.</p>\n\n<p>I\'ve seen time complexity of math operations in <a href="http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Arithmetic_functions" rel="nofollow">wikipedia</a>, and there is also a related question in <a href="http://stackoverflow.com/questions/17649524/time-complexity-to-convert-a-decimal-to-another-base">stackoverflow</a> saying time complexity of conversions of arbitrary digit length to be $\\mathcal{O}(M(n) log(n))$</p>\n\n<p>I\'m not interested in a "general time complexity bounds for any base conversion" but I would like to know more about the big differences in time complexity between power-of-2 conversions vs any other base conversions. </p>\n\n<p>It\'s could be a general fact about conversions that can be done faster if they are done between numbers where its bases are power among themselves, not only for 2, but the same to a base 10 to base 100.</p>\n\n<p>Is there any known proof or materials around this ?</p>\n', 'ViewCount': '185', 'Title': 'Time complexity of base conversion', 'LastEditorUserId': '1396', 'LastActivityDate': '2014-04-18T19:19:26.113', 'LastEditDate': '2014-02-21T12:31:12.923', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1396', 'Tags': '<complexity-theory><reference-request><time-complexity><binary-arithmetic>', 'CreationDate': '2014-02-17T13:58:42.143', 'FavoriteCount': '1', 'Id': '21736'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://courses.cs.vt.edu/~cs5204/fall07-kafura/Papers/TransactionalMemory/Linearizability.pdf" rel="nofollow">Linearizability</a> is a well-known correctness condition for concurrent objects.  It provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response. To prove linearizability of an implementation, it is necessary and sufficient to show that all its possible executions are linearizable with respect to some sequential specification. For this purpose, two common methods have been developed, as summarized in the paper <a href="http://dl.acm.org/citation.cfm?id=1993687" rel="nofollow">"Linearizable Implementations Do Not Suffice for Randomized Distributed Computation [@STOC\'2011]"</a>. </p>\n\n<p>However, what are typical methods for showing that some implementation is <em>not</em> linearizable? Logically, it is necessary to identify an execution which is not linearizable. But, how to achieve it? Are there some typical examples of demonstrating the non-linearizablity of an implementation in the literature?</p>\n', 'ViewCount': '30', 'Title': 'What are methods for showing that concurrent objects are not linearizable?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-18T13:05:12.033', 'LastEditDate': '2014-02-18T13:05:12.033', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><proof-techniques><concurrency>', 'CreationDate': '2014-02-18T12:24:11.333', 'Id': '21760'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><strong>Background:</strong> </p>\n\n<p>In section 4.2 of the paper <a href="http://dl.acm.org/citation.cfm?id=1993687" rel="nofollow">Linearizable Implementations Do Not Suffice for Randomized Distributed Computation@STOC\'2011</a>, the authors mentioned two typical proof strategies for linearizability of implementations. In the following, Let $O$ be the implemented object and let $H$ be a history over $O$.</p>\n\n<p>In one proof strategy, for each operation $op$ on $O$ a unique "linearization point" $pt(op)$ is assigned, which is a shared memory operation that occurs during the execution of operation $op$. A sequential history $S$ is formed by ordering the operations on $O$ in $H$ so that $op_1$ precedes $op_2$ in $S$ if and only if $pt (op_1) \\prec_{H} pt (op_2)$. The construction of $S$ guarantees agreement with the "happens before" order of operations on $O$ in $H$, and so the proof obligation for linearizability is only to show that $S$ is valid for $O$.</p>\n\n<p>In the second general proof strategy, the operations in a history $H$ are first ordered somehow into a valid sequence $S$, and the proof obligation is to show that $S$ is consistent with the "happens before"\norder of $H$. </p>\n\n<p>For instance, the practical constructions of sets and lists such as the "FineList", "OptimisticList", and "LazyList" described by Herlihy and Shavit in their book "The Art of Multiprocessor Programming" fall into the first category while the classic construction of atomic snapshot object and the implementation of atomic multi-writer register from atomic single-writer ones are in the second category.</p>\n\n<p><strong>My problems here are as follows:</strong></p>\n\n<blockquote>\n  <ol>\n  <li>Are there some implementations in the literature whose linearizability can be proved by <em>both</em> of the above-mentioned proof strategies? Such examples may be useful to help people understand and compare these two proof strategies better.</li>\n  <li>Are there any other proof strategies for linearizability used in the literature? It need not be general and can be specific to its particular problem.  </li>\n  </ol>\n</blockquote>\n', 'ViewCount': '22', 'Title': 'Proof strategies for linearizability of implementations', 'LastEditorUserId': '4911', 'LastActivityDate': '2014-02-21T02:06:02.073', 'LastEditDate': '2014-02-21T02:06:02.073', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><concurrency>', 'CreationDate': '2014-02-20T14:37:32.927', 'Id': '21847'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>In his famous <a href="https://www.princeton.edu/~hhalvors/restricted/kripke_intuitionism.pdf" rel="nofollow">Semantical Analysis of Intuitionistic Logic</a>,\nS. Kripke speaks of the "well-known mappings of intuitionistic logic\ninto the modal system S4". I\'m not sure which mappings Kripke means.\nOne guess would be K. G\xf6del\'s "Eine Interpretation des\nIntuitionistischen Aussagenkalk\xfcls" (translated into English as "An\nInterpretation of the Intuitionistic Propositional Calculus". I don\'t have\naccess to either.)</p>\n\n<p>Could somebody please point me towards a text that details these\ntranslations?</p>\n', 'ViewCount': '39', 'Title': 'Mapping intuitionistic logic to the modal logic S4', 'LastActivityDate': '2014-03-04T12:43:42.067', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '22267', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2887', 'Tags': '<reference-request><logic><modal>', 'CreationDate': '2014-03-03T12:58:35.777', 'Id': '22218'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="https://en.wikipedia.org/wiki/3-partition_problem" rel="nofollow">The 3-Partition problem (wiki)</a> is a $\\text{NP}$-complete problem which is to decide whether a given multiset of integers can be partitioned into triples that all have the same sum. It is well-known that the <a href="https://en.wikipedia.org/wiki/3SAT#3-satisfiability" rel="nofollow">3SAT problem</a> has a plenty of variants. Are there some variants of the 3-Partition problem discussed in the literature?</p>\n', 'ViewCount': '18', 'Title': 'Variants of the 3-Partition problem', 'LastActivityDate': '2014-03-08T13:03:42.250', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<complexity-theory><reference-request><np-complete>', 'CreationDate': '2014-03-08T13:03:42.250', 'Id': '22396'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '72', 'Title': 'Approximation algorithms for Euclidean Traveling Salesman', 'LastEditDate': '2014-04-13T09:51:49.107', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15429', 'FavoriteCount': '1', 'Body': "<p>I am trying to find a way to solve Euclidean TSP in a polynomial time. I looked at some papers but I couldn't decide which one is better. What is the general approximation algorithm for solving this problem in polynomial time?</p>\n", 'ClosedDate': '2014-04-13T09:54:22.080', 'Tags': '<algorithms><reference-request><approximation><traveling-salesman>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-13T09:51:49.107', 'CommentCount': '5', 'CreationDate': '2014-03-09T18:25:51.543', 'Id': '22438'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm looking for some statistics for </p>\n\n<ol>\n<li>the total number of operations possible by all the computers in all the world now.</li>\n<li>A capacity factor for this (i.e. what fraction of the potential operations are being performed)</li>\n<li>How this has changed over the last century.</li>\n</ol>\n\n<p>Something with a graph with world total FLOPS against time would be perfect. I'd also be interested in seeing the same thing for other measures of capacity, storage space, networking, whatever. I'm not having much luck finding anything but energy requirements.</p>\n", 'ViewCount': '36', 'ClosedDate': '2014-03-17T11:51:44.423', 'Title': 'Total world computational capacity', 'LastActivityDate': '2014-03-17T04:38:39.960', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'OwnerDisplayName': 'Lucas', 'PostTypeId': '1', 'OwnerUserId': '7641', 'Tags': '<reference-request><time-complexity>', 'CreationDate': '2014-03-16T17:19:09.190', 'FavoriteCount': '2', 'Id': '22692'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I would like to know whether there is a method to find similar questions for a given question, just like this stackexchange.com does.</p>\n\n<p>Is there any paper or tools?\nI tried keywords such as "deduplication" and "linking" but it was not successful.</p>\n', 'ViewCount': '18', 'Title': 'Is there a paper/implementation/tool on automatically finding/suggesting similar questions for a given question?', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-03-17T11:56:15.640', 'LastEditDate': '2014-03-17T11:56:15.640', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15765', 'Tags': '<reference-request><natural-lang-processing>', 'CreationDate': '2014-03-17T08:27:58.670', 'FavoriteCount': '1', 'Id': '22696'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>(The question is an extension of <a href="http://stackoverflow.com/questions/9404909/algorithms-for-compression-of-set-tries">this</a> unanswered question on stackoverflow)</p>\n\n<p>If we have a set of strings, we can efficiently represent them with <a href="http://en.wikipedia.org/wiki/Trie" rel="nofollow">tries</a>. Common branches can also be merged, resulting in a DAG instead of a tree that is even more compact.</p>\n\n<p>However, if we have a set of sets (i.e. the order does not matter), there are a lot of possible tries that represent the same set of elements.\nAn example can be found in the stackoverflow question I linked above.</p>\n\n<p><strong>Edit:</strong> For example, assume that we are given the following sets of integers.</p>\n\n<pre><code>{1,2,3,4,5}\n{1,2,6,7}\n{1,2,4,7}\n{1,3,5,7}\n</code></pre>\n\n<p>Two possible representations are shown below (trie on the left, DAG on the right)</p>\n\n<p><img src="http://i.stack.imgur.com/fJr2z.png" alt="enter image description here"></p>\n\n<p>My questions are:</p>\n\n<blockquote>\n  <ol>\n  <li>How hard is the problem of finding an optimal (i.e minimal) such trie? </li>\n  <li>Are there any fast algorithms for solving this problem?</li>\n  <li>If not, are there any fast algorithms that find "good" tries?</li>\n  <li>What about the DAG case?</li>\n  </ol>\n</blockquote>\n\n<p>In the scenario I have in mind there is an additional constraint that no set is a subset of another set.</p>\n\n<p>Any link/paper that is even slightly relevant to any of the questions is helpful.</p>\n', 'ViewCount': '75', 'Title': 'Efficiently representing a set of sets', 'LastEditorUserId': '691', 'LastActivityDate': '2014-03-20T05:23:28.300', 'LastEditDate': '2014-03-19T16:06:09.610', 'AnswerCount': '3', 'CommentCount': '8', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '691', 'Tags': '<reference-request><data-structures><strings>', 'CreationDate': '2014-03-19T14:31:35.070', 'FavoriteCount': '1', 'Id': '22807'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a friend working in wireless communications research. He told me that we can transmit more than one symbol in a given slot using one frequency (of course we can decode them at the receiver).</p>\n\n<p>The technique as he said uses a new modulation scheme. Therefore if one transmitting node transmits to one receiving node over a wireless channel and using one antenna at each node, the technique can transmit two symbols at one slot over one frequency.</p>\n\n<p>I am not asking about this technique and I do not know whether it is correct or not but I want to know if one can do this or not? Is this even possible? Can the Shannon limit be broken? Can we prove the impossibility of such technique mathematically?</p>\n\n<p>Other thing I want to know, if this technique is correct what are the consequences? For example what would such technique imply for the famous open problem of the interference channel? </p>\n\n<p>Any suggestions please? Any reference is appreciated.  </p>\n', 'ViewCount': '148', 'ClosedDate': '2014-04-02T13:18:01.173', 'Title': 'Can we break the Shannon capacity?', 'LastActivityDate': '2014-03-24T17:49:47.007', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '23014', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15913', 'Tags': '<reference-request><computer-networks>', 'CreationDate': '2014-03-24T17:01:40.950', 'FavoriteCount': '1', 'Id': '23009'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://en.wikipedia.org/wiki/Maximum_subarray_problem" rel="nofollow">Kadane Algorithm</a> is used to solve the maximum subarray problem which in simpler terms is to find the highest possible value of a continuous sub array in an array. </p>\n\n<p>One often cited application of Kadane Algorithm is that given the prices of the stock over X days , on which days should we buy and sell the stock in order to maximize given profit. These example is not practical at all as it is impossible to predict future prices of stocks and hence impossible to apply it . </p>\n\n<p>What are some real world application of Kadane algorithm?</p>\n', 'ViewCount': '30', 'Title': 'Practical Application of Kadane algorithm', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-26T08:20:17.887', 'LastEditDate': '2014-03-26T08:20:17.887', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12448', 'Tags': '<algorithms><reference-request><optimization>', 'CreationDate': '2014-03-26T01:38:44.523', 'Id': '23055'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Ok before I start I realise this is on the fringe of on-topic (I have read the Questions help for this site), particularly as this is not a real-world problem. However:</p>\n\n<ol>\n<li>I cannot find anything relevant on Google</li>\n<li>From a purist point of view surely it must fall within Computer Science?</li>\n</ol>\n\n<p>In any case, if I have overstepped a boundary then I apologise and welcome the  Closure as I am an avid user of other SE sites so I understand the issues.</p>\n\n<p>Caveats aside, here it is:\nI have long wondered if it would be possible to build a functioning computing system, using humans as discrete logic components, to solve problems that individual humans could not solve in a practical timesscale. For example, imagine a number of humans stranded on an island without any machines, that needed to crunch some complex numbers to escape.</p>\n\n<p>I imagine arranging people so that they receive inputs from other groups within the system, make simple decisions (perhaps binary decisions, perhaps not) and pass the outputs to other groups.</p>\n\n<p>Then I imagine some kind of programming language could be developed to control the data and computation flow and the language could be used to solve complex problems without individuals understanding the overall problem.</p>\n\n<p>So I guess the above is not an answerable question- but <strong>does anyone know of any research, books, papers or whatever</strong> on what it would take to achieve, what kinds of of problems could be addressed and potentially solved, what kind of control language could be deployed and how the architecture could be scaled up to handled more complex problems?</p>\n\n<p>I suppose, in essence, I am looking for anything on "idealised" atomic (as in self contained) and standard computing units that could be arranged at will- I am just thinking in human terms.</p>\n\n<p>I find the idea fascinating and alluring. I\'d love to try it out one day and see what performance could be achieved! Sorry for the tags I have used, as I was searching the tags here I quickly became aware I have no idea of the correct terminology for what I am thinking, though I am sure it exists within the field...</p>\n', 'ViewCount': '1937', 'Title': 'Using humans as components to build a computer?', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-03-27T08:10:19.003', 'LastEditDate': '2014-03-26T15:29:07.250', 'AnswerCount': '5', 'CommentCount': '13', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '16151', 'Tags': '<reference-request><human-computing>', 'CreationDate': '2014-03-26T13:58:32.413', 'FavoriteCount': '4', 'Id': '23075'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I was trying to find info about this Finite Automata type FAB (Finite Automata Bowl) and wasn't able to find a lot. It is basically the rules that apply to PDA apply to FAB except you drop the temporal order of the stack. So instead of being restricted to only removing the top symbol of the stack, you can remove any symbol of the bowl.</p>\n\n<p>The question is, does there exist a context-free language that is <em>not</em> accepted by an FAB?</p>\n", 'ViewCount': '57', 'Title': 'What is Finite Automata Bowl?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-31T07:58:15.327', 'LastEditDate': '2014-03-31T07:58:15.327', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '16197', 'Tags': '<terminology><reference-request><automata><finite-automata>', 'CreationDate': '2014-03-27T14:56:09.013', 'Id': '23128'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Every proof I can find of this result is by way of regular expressions. Is there any "constructive" proof that defines the corresponding DFA (probably NFA)? For instance the proof of concatenation closure is most often presented by demonstrating the NFA. I\'m just curious whether this is out there somewhere</p>\n', 'ViewCount': '162', 'Title': 'Does there exist a proof of closure of regular languages under regular substitution by giving the corresponding DFA?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-10T06:27:44.253', 'LastEditDate': '2014-03-31T08:21:05.427', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '23623', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15486', 'Tags': '<formal-languages><reference-request><finite-automata><closure-properties>', 'CreationDate': '2014-03-30T17:15:21.897', 'Id': '23265'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been researching on AdaBoost and GentleBoost classifiers, but can't seem to find a clear answer to the question:</p>\n\n<ul>\n<li>What is Adaboost better at classifying in computer vision?</li>\n<li>What is GentleBoost better at classifying?</li>\n</ul>\n\n<p>I've been told that AdaBoost is good for things with soft edges, like facial recognition, while GentleBoost is good for things with harder and more symmetrical features and edges, like vehicles. Is this true? Is there any proof for this or any evidence to back up this claim?</p>\n", 'ViewCount': '26', 'Title': 'Advantages of adaboost over gentleboost in applications, or vice versa?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-01T13:37:38.917', 'LastEditDate': '2014-04-01T13:37:38.917', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<algorithms><reference-request><machine-learning><classification><computer-vision>', 'CreationDate': '2014-04-01T10:34:09.543', 'FavoriteCount': '1', 'Id': '23316'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is there any algorithm which takes edges (given by its two end points), and determines in which cell (or cells) of grid it is?</p>\n\n<p>Grid has fixed dimensions and number of cells. Grid is represented by its cells with matrix. And every cell has list of edges that intersect that cell.</p>\n\n<p>Input is set of pair points, but I can also transform it in just set of points, or any other needed representation.\nOutput should be the mentioned grid with cells who contain list of edges that intersect that cell.</p>\n\n<p>Algorithm should be fast and robust, and by that I mean it covers special (degenerated) cases and that its time complexity is good.</p>\n\n<p>What I want to be able is to use that grid later for search, for example to answer me question like "Which cells does given edge AB(with end points A and B) intersect?" or "Give me all edges that intersect cell 12"(First row, second column).</p>\n', 'ViewCount': '44', 'Title': 'Algorithm for storing polygon edges into grid', 'LastEditorUserId': '16207', 'LastActivityDate': '2014-04-02T12:08:49.930', 'LastEditDate': '2014-04-02T12:08:49.930', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16207', 'Tags': '<reference-request><computational-geometry><search-algorithms>', 'CreationDate': '2014-04-01T16:03:33.280', 'Id': '23321'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Let me ask my general question using a specific example, namely range searching:</p>\n\n<p>Given a set of points in the plane and an axis parallel rectangle, report all points lying in the rectangle. </p>\n\n<p>If the rectangle contains $k$ points, then this can be solved in $O(\\log n + k)$ time (after some preprocessing). I understand that this is in some sense optimal, but what if the points obey some regularity?</p>\n\n<p>Obviously if they are from the integer grid, this can be solved in constant time.</p>\n\n<p>What is less obvious to me is the situation where the points lie equally spaced on some complicated curves: I could report to the user a set of curve-intervals tuples from which he can deduce the number of points. </p>\n\n<p>But am I actually still solving the problem, or am I just outsourcing the work to the user? </p>\n\n<p>I realize that the question is not very precise and I am not sure if such topics have been studied before. \nI would be interested in any literature reference, where algorithms produce output in a non-explicit way.</p>\n', 'ViewCount': '26', 'Title': 'Lower-bounds of running-time for output sensitive Algorithms', 'LastActivityDate': '2014-04-04T23:00:00.927', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '16358', 'Tags': '<reference-request><time-complexity><runtime-analysis>', 'CreationDate': '2014-04-04T23:00:00.927', 'Id': '23438'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm looking for public algorithm which gives the engine these abilities:</p>\n\n<ul>\n<li>Query by ranked terms</li>\n<li>Limit outcome by date/time range</li>\n</ul>\n\n<p>Basically, i'd like to concentrate articles (generally <code>title|text|timestamp</code>) identify the source and make N-N correlation to terms (is term for datasource same marking as term for dataentry?)</p>\n\n<p>Given the database of such information</p>\n\n<pre><code>entry_data_type:[type_id|title|description]\nentry_data:[entry_id|data_type_id|data_content]\nentry:[id|entry_type(data,source)|parent_entry_id|created|updated]\nterms(keywords):[id|keyword]\nentry2term:[entry_id|term_id|term_weight]\n</code></pre>\n\n<p>Where keywords are both automatically defined (text frequency analysis) and manually assigned (probably abstract terms in context to entry contents)</p>\n\n<p>I should be able to query by keywords like this: <code>kw1:3 kw2:10 kw3:-2 [range:-7 days]</code><br>\nand output shall be entries sorted by given keyword weights (pattern <code>keyword:weight</code>)</p>\n\n<p>I thought about something similar to EdgeRank, but that is social-graph-oriented, and I'm looking for more straight-forward solution (more selfish, meaning input filter is given by personal preferences, not social-graph-near preferences or social-score ranking)</p>\n\n<p>Also TF-IDF would have to be limited by time, so the document base to calculate the entry score is inserted in given date/time range only. Is there any possible break-down of TF-IDF ranking, eg. to pre-calculate raw-data for each day and then, based on query, merge them for given date-range?</p>\n\n<p>This question is independent of any particular programming language, platform, etc. I'm generally looking for keywords to look for, papers to read or ready implementations to study, but accepted are only answers not using paid or closed-source software parts or non-public-domain patents.</p>\n", 'ViewCount': '16', 'Title': 'TF-IDF query engine in context of terms weight', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-04-07T16:53:08.100', 'LastEditDate': '2014-04-07T16:53:08.100', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16077', 'Tags': '<reference-request><search-algorithms><statistics><search-problem><ranking>', 'CreationDate': '2014-04-07T01:30:29.197', 'Id': '23494'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '140', 'Title': 'If $\\log xy=\\log x+\\log y$ then why multiplication is harder than addition?', 'LastEditDate': '2014-04-08T17:51:22.997', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '16535', 'FavoriteCount': '1', 'Body': "<p>Someone told me that the $\\log$ function was introduced to make the calculation easier. If we have to calculate $xy$, we can calculate instead $\\log x+\\log y$ since $\\log xy=\\log x+\\log y$. How this can make the calculation easier? Maybe from a mathematician point of view but what about a computer scientist's point of view?</p>\n\n<p>If it makes the calcualtion easier then why people do not use it to simplify the complexity of the multiplication algorithms?</p>\n\n<p>From my own thinking, this transformation makes the calculation more difficult. How can we calculate the $\\log x$ and $\\exp x$ functions in a computer?</p>\n\n<p>Am I right? Any suggestions please? Thank you for your time.</p>\n", 'Tags': '<algorithms><complexity-theory><reference-request><education>', 'LastEditorUserId': '16535', 'LastActivityDate': '2014-04-08T20:37:30.863', 'CommentCount': '2', 'AcceptedAnswerId': '23564', 'CreationDate': '2014-04-08T16:13:52.080', 'Id': '23554'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>To understand the effectiveness and/or efficiency of a protocol implemented in distributed storage systems, it is often desirable to evaluate it in a quantitative way under a hypothetical model. </p>\n\n<p>Obviously, every model is an approximation to the reality and there is not an all-purpose one. I expect to do a mini survey of the models of distributed storage systems in the literature. Specifically, I am interested in the models on <em>system throughput, read/write rate, read/write pattern, read/write duration (interval), read/write latency, communication delay, failure pattern, and more professional ones such as data consistency, quorum size, recovery mechanism, and so on</em>. </p>\n\n<p>Therefore, I am requesting references, including but not limited to</p>\n\n<ol>\n<li>statistical reports of commercial/open source distributed storage systems</li>\n<li>hypothetical models used in research papers.<br>\na typical example: <a href="http://www.cs.odu.edu/~mukka/cs775s07/papers/availability.pdf" rel="nofollow">costs and availability of replicated services\n</a> which studies availability, consistency, partition. </li>\n<li>experimental results given in research papers, talks, and technical reports.<br>\ntypical examples: <a href="http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf" rel="nofollow">Dynamo in Amazon [section 6]</a> and <a href="http://infolab.stanford.edu/~usriv/papers/pnuts.pdf%5d" rel="nofollow">PNUTS in Yahoo! [section 5]</a>.</li>\n<li>personal comments on such topics from blogs, non-research articles, and you.</li>\n</ol>\n', 'ViewCount': '34', 'Title': 'What are the models of distributed storage systems in the literature?', 'LastEditorUserId': '4911', 'LastActivityDate': '2014-04-13T08:22:19.077', 'LastEditDate': '2014-04-13T08:22:19.077', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<reference-request><distributed-systems>', 'CreationDate': '2014-04-12T06:19:43.117', 'Id': '23690'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>For instance, the tape on a Turing machine is infinite, where as we usually only have a finite amount of available memory.  Secondly Turing machines are not really convenient IMHO for proving things about everyday algorithms on an everyday computer.</p>\n\n<p>I want a model that makes computations in a ring, namely $\\Bbb{Z}_p\\times \\dots \\times \\Bbb{Z}_p = (\\Bbb{Z}_p)^k$, where $p$ is prime (for a good reason... later on that).  Since that's what bytes on a computer look like they look like values in $\\Bbb{Z}_8$ and even some of the instructions on those bytes on modern computers cause wrap around that looks like that of $\\Bbb{Z}_8$.  It's obvious to me that any computation on my home PC can be done with computations in said ring.  But of course I'd have to prove that formally if I wrote a paper.  I can already write conditional assignments of a memory slot (element of $\\Bbb{Z}_p$), as the value of a polynomial in $\\Bbb{Z}_p[x_1, \\dots, x_k]$.</p>\n\n<p>It's hard to find literature on this, but to me it seems so obvious that this is a nice approach and I'm shocked that no one's considered this yet.  Or have they?  Links please...</p>\n", 'ViewCount': '247', 'ClosedDate': '2014-04-16T17:11:48.760', 'Title': 'Is there a model of computation, that tries to be realistic?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-16T12:18:13.993', 'LastEditDate': '2014-04-16T12:18:13.993', 'AnswerCount': '1', 'CommentCount': '11', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12373', 'Tags': '<reference-request><machine-models>', 'CreationDate': '2014-04-16T01:23:50.533', 'Id': '23840'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '46', 'Title': 'Matrix equality up to row/column permutations problem name', 'LastEditDate': '2014-04-16T10:32:07.080', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '2', 'Body': '<p>Sorry for the trivial question; has the following decision problem an "official" (possibly short) name?</p>\n\n<blockquote>\nGiven two  $n \\times m$ $\\text{0-1}$ (binary) matrices $M_1, M_2$ check if they are the same up to row and column permutations.\n</blockquote>\n\n<p>(something like the short names used in complexity theory for decision problems: e.g. 3SAT, GI (Graph Isomorphism), X3C (Exact Cover By Three Set), CLIQUE, ...)</p>\n', 'Tags': '<terminology><reference-request>', 'LastEditorUserId': '140', 'LastActivityDate': '2014-04-19T10:49:29.547', 'CommentCount': '6', 'AcceptedAnswerId': '23932', 'CreationDate': '2014-04-16T10:19:04.533', 'Id': '23850'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '41', 'Title': 'Dual-pivot Quicksort reference implementation?', 'LastEditDate': '2014-04-25T06:56:55.333', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7533', 'FavoriteCount': '2', 'Body': "<p>Has some sort of canonical - or reference - implementation of Dual-pivot Quicksort been posted anywhere?</p>\n\n<p>I would like to include that algorithm in a comparison among sorting algorithms for a specialized need that I have, but the Java versions I've seen appear to have various kinds of tweaks applied to them, like using Insertion Sort for small (sub-) arrays, which makes it harder to compare the fundamentals.</p>\n", 'Tags': '<algorithms><reference-request><sorting><quicksort>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-25T09:18:42.890', 'CommentCount': '7', 'AcceptedAnswerId': '24099', 'CreationDate': '2014-04-25T00:47:08.157', 'Id': '24092'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I would like to study some basic logspace algorithms. I have studied about the some of the problems, but most of the problems I am unable to follow in detai. Can some one suggest me the best references (books or lecture notes) where these explained clearly. </p>\n\n<p>Thank you.</p>\n', 'ViewCount': '32', 'ClosedDate': '2014-04-26T16:00:56.397', 'Title': 'On Logspace algorithms', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-26T16:01:06.850', 'LastEditDate': '2014-04-26T16:01:06.850', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6522', 'Tags': '<algorithms><reference-request><space-complexity>', 'CreationDate': '2014-04-25T13:56:42.783', 'Id': '24102'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '871', 'Title': 'Is there an anti-Bloom filter?', 'LastEditDate': '2014-04-29T11:35:57.480', 'AnswerCount': '4', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '5323', 'FavoriteCount': '4', 'Body': '<p>A <a href="https://en.wikipedia.org/wiki/Bloom_filter" rel="nofollow">Bloom filter</a> makes it possible to efficiently keep track of whether various values have already been encountered during processing.  When there are many data items then a Bloom filter can result in a significant memory saving over a hash table.  The main feature of a Bloom filter, which it shares with a hash table, is that it always says "not new" if an item is not new, but there is a non-zero probability that an item will be flagged as "not new" even when it is new.</p>\n\n<blockquote>\n  <p>Is there an "anti-Bloom filter", which has the opposite behaviour?</p>\n</blockquote>\n\n<p>In other words: is there an efficient data structure which says "new" if an item is new, but which might also say "new" for some items which are not new?</p>\n\n<p>Keeping all the previously seen items (for instance, in a sorted linked list) satisfies the first requirement but may use a lot of memory.  I am hoping it is also unnecessary, given the relaxed second requirement.</p>\n\n<hr>\n\n<p>For those who prefer a more formal treatment, write $b(x) = 1$ if the Bloom filter thinks $x$ is new, $b(x) = 0$ otherwise, and write $n(x) = 1$ if $x$ really is new and $n(x) = 0$ otherwise.</p>\n\n<p>Then $Pr[b(x) = 0 | n(x) = 0] = 1$; $Pr[b(x) = 0 | n(x) = 1] = \\alpha$; $Pr[b(x) = 1 | n(x) = 0] = 0$; $Pr[b(x) = 1 | n(x) = 1] = 1 - \\alpha$, for some $0 &lt; \\alpha &lt; 1$.</p>\n\n<p>I am asking: does an efficient data structure exist, implementing a function $b\'$ with some $0 &lt; \\beta &lt; 1$, such that $Pr[b\'(x) = 0 | n(x) = 0] = \\beta$; $Pr[b\'(x) = 0 | n(x) = 1] = 0$; $Pr[b\'(x) = 1 | n(x) = 0] = 1 - \\beta$; $Pr[b\'(x) = 1 | n(x) = 1] = 1$?</p>\n\n<hr>\n\n<p><strong>Edit:</strong> It seems this question has been asked before on StackExchange, as <a href="http://stackoverflow.com/questions/635728">http://stackoverflow.com/questions/635728</a> and <a href="http://cstheory.stackexchange.com/questions/6596">http://cstheory.stackexchange.com/questions/6596</a> with a range of answers from "can\'t be done" through "can be done, at some cost" to "it is trivial to do, by reversing the values of $b$".  It is not yet clear to me what the "right" answer is.  What <em>is</em> clear is that an LRU caching scheme of some sort (such as the one suggested by Ilmari Karonen) works rather well, is easy to implement, and resulted in a 50% reduction in the time taken to run my code.</p>\n', 'Tags': '<reference-request><data-structures><hash><bloom-filters><dictionaries>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T11:35:57.480', 'CommentCount': '3', 'AcceptedAnswerId': '24122', 'CreationDate': '2014-04-25T21:08:54.120', 'Id': '24118'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>how to get request header using any URL in php like as request header(Accept-Charset,Accept-Encoding,Host,Accept-Language,User-Agent,Accept)) </p>\n', 'ViewCount': '12', 'ClosedDate': '2014-04-28T07:39:39.317', 'Title': 'how to get request header using any url in php', 'LastActivityDate': '2014-04-28T06:22:02.787', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17136', 'Tags': '<reference-request>', 'CreationDate': '2014-04-28T06:22:02.787', 'Id': '24178'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been playing around with a simple probabilistic data structure which is very similar to a Bloom filter. Where a Bloom filter would use $k$ independent hash functions to choose $k$ of the $m$ bits to set, this structure uses $m$ hash functions, and sets each bit with probability $p$.</p>\n\n<p>This structure doesn't produce as low a false-positive rate as Bloom filters, but it seems to be extremely fast to compute, particularly if $m$ is some multiple of the machine word size and $p = 2^{-b}$ for some integer $b$: The hash functions can be computed in parallel by AND-ing $b$ independent $m$-bit hashes, and no dependent indexing or variable bitshifts are required.</p>\n\n<p>I'm certain someone's come up with this idea before me, and done a lot more advanced analysis and comparison of it than I'm qualified to do. Is there a particular name for this type of structure?</p>\n", 'ViewCount': '33', 'Title': 'Bloom filter variant', 'LastEditorUserId': '8410', 'LastActivityDate': '2014-04-29T17:07:58.197', 'LastEditDate': '2014-04-29T13:27:12.427', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24230', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8410', 'Tags': '<reference-request><data-structures><probabilistic-algorithms><bloom-filters><dictionaries>', 'CreationDate': '2014-04-29T10:55:19.287', 'Id': '24217'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m working on a paper and would like to review the origins of <a href="http://en.wikipedia.org/wiki/Kleene_star">Kleene\'s closure</a>. I am unable to find any article of Kleene\'s that has the original definition of the Kleene closure.</p>\n\n<p>Is there a paper by Kleene in which he first defines the Kleene closure?</p>\n', 'ViewCount': '74', 'Title': 'Where/when did Stephen Kleene first define the Kleene closure/star?', 'LastEditorUserId': '2205', 'LastActivityDate': '2014-04-30T07:25:55.133', 'LastEditDate': '2014-04-30T07:25:55.133', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '17192', 'Tags': '<formal-languages><reference-request><automata>', 'CreationDate': '2014-04-29T21:40:11.143', 'Id': '24237'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Dynamic Software Product Lines (DSPLS) are software product lines (SPLs) where features can be bound and unbound during program execution time. </p>\n\n<p>Is there a feature model and code available of an DSPL? I.e., where the model and the implementation is freely available for research purposes? I mean for regular SPLs there is the <a href="http://www.splot-research.org/" rel="nofollow">SPLOT website</a> for models and the several <a href="http://www.infosun.fim.uni-passau.de/spl/apel/Fuji/#download" rel="nofollow">Fuji exmaples</a> with implementaiton code are downloadable.</p>\n\n<p>I contacted one of the authors of a review paper on DSPLs:\nHallsteinsen, S., Hinchey, M., Park, S., &amp; Schmid, K. (2008). Dynamic software product lines. Computer, 41(4), 93-95.</p>\n\n<p>He answered me that he is not aware of any available DSPL! He said that some work is government funded or sponsored by companies and in both cases it is impossible to get anything, let alone code. However, the feature model and code excerpts that I am interested in can be easily anonymised.</p>\n\n<p>Is it true that there is not a single DSPL where the model and some implementation code is availiable?</p>\n\n<p>Are there any research groups I can possibly contact in this regard? Groups that might have a DSPL feature model or implementation that might be available for research? The feature model and implementation code can be anonymized.</p>\n\n<p>The reason for my question is that I am interested in analyzing DSPLs, but it seems impossible to get an DSPL anywhere; although there a numerous papers on DSPLs.</p>\n', 'ViewCount': '16', 'Title': 'Is there an available feature model and code of a dynamic software product line (DSPL)?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-30T19:33:43.090', 'LastEditDate': '2014-04-30T17:35:32.730', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<reference-request><software-engineering>', 'CreationDate': '2014-04-30T14:37:16.727', 'FavoriteCount': '1', 'Id': '24258'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Why does Program Synthesis seem to be defined in relation to program verification? Given a correct specification, why can't a program be synthesized (without reference to verification)?</p>\n\n<p>This question is specific to context of reactive program synthesis. For example, some explain that they perform model checking first, then synthesis.</p>\n", 'ViewCount': '23', 'ClosedDate': '2014-05-01T02:42:58.537', 'Title': 'Relation of program synthesis and verification', 'LastEditorUserId': '98', 'LastActivityDate': '2014-05-02T22:08:56.160', 'LastEditDate': '2014-05-02T22:08:56.160', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7579', 'Tags': '<reference-request><formal-methods><program-verification>', 'CreationDate': '2014-05-01T01:24:47.047', 'Id': '24283'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>A few years ago, I read a paper that gave me a deeper understanding of ecological data (<a href="https://bcrc.bio.umass.edu/courses/fall2010/grad/micbio697b/sites/default/files/madin_2008.pdf" rel="nofollow">Madin et al, 2008</a>). More recently, I read a paper in PLOS-ONE (<a href="https://dx.doi.org/10.1371/journal.pone.0091001" rel="nofollow">Villa et al 2014</a>) that describes a particularly powerful a software based on ontologies.</p>\n\n<p>I find both of these papers informative, engaging, and useful. I and others have applied concepts from the first paper to database design, and the new programming language in the second paper seems useful. So I was surprised when a colleague (senior math faculty at an R1 university) told me that he scoffed that "Ontology" was a bogus field, in the same vein as astrology and homeopathy.</p>\n\n<p>When presented these two papers from my field, he called the first a "typical example of bogus research" and the second "valid attempt to do meaningful research within a failed framework". He pointed to two compelling graphs from Google Trends, one for "semantic web" and one for "web ontology language". I know this isn\'t peer-reviewed, but it is straightforward evidence that interest in these topics (or at least these specific terms) is waning. Here is a similar query:</p>\n\n<p><img src="http://i.stack.imgur.com/bPkCV.png" alt="enter image description here"></p>\n\n<p>I would appreciate additional background so that I can better understand my colleague\'s perspective. Are there any references that would provide me with historical context and a background for understanding the limitations of research on and applications of Ontology?</p>\n', 'ViewCount': '61', 'ClosedDate': '2014-05-03T09:41:47.747', 'Title': 'Why is interest in the fields of ontology and semantics declining?', 'LastActivityDate': '2014-05-03T09:41:37.610', 'AnswerCount': '0', 'CommentCount': '8', 'Score': '2', 'OwnerDisplayName': 'Bob The Builder', 'PostTypeId': '1', 'OwnerUserId': '17286', 'Tags': '<reference-request><formal-languages><programming-languages><semantics>', 'CreationDate': '2014-05-01T02:44:51.360', 'FavoriteCount': '1', 'Id': '24298'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Problem: Input is an integer number $x$ that we know factors as $p_{i_1}\\cdot p_{i_2}\\ldots p_{i_n}$, where the $p_{i_j}$'s are distinct prime numbers. Output is the above factorization of $x$.</p>\n\n<p>Do you know any results/references for the time complexity of this factoring problem? </p>\n\n<p>Note: If the $p_{i_j}$'s are not assumed distinct, then the problem is just integer factorization. This is a very special case.</p>\n", 'ViewCount': '18', 'Title': 'Complexity of factoring products of distinct prime numbers', 'LastActivityDate': '2014-05-02T20:00:41.800', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6610', 'Tags': '<complexity-theory><reference-request><time-complexity><factoring>', 'CreationDate': '2014-05-02T16:15:36.450', 'Id': '24319'}}