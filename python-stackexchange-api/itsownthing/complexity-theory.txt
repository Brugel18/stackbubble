{'ViewCount': '227', 'Title': 'Is Smoothed Analysis used outside academia?', 'LastEditDate': '2012-05-16T23:22:33.777', 'AnswerCount': '2', 'Score': '15', 'OwnerDisplayName': 'user20', 'PostTypeId': '1', 'FavoriteCount': '2', 'Body': '<p>Did the <a href="http://en.wikipedia.org/wiki/Smoothed_analysis">smoothed analysis</a> find its way into main stream analysis of algorithms? Is it common for algorithm designers to apply smoothed analysis to their algorithms?</p>\n', 'Tags': '<algorithms><complexity-theory><algorithm-analysis>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-05-17T23:41:36.817', 'CommentCount': '6', 'AcceptedAnswerId': '100', 'CreationDate': '2012-03-07T06:57:12.917', 'Id': '74'}{'Body': '<p>Let\'s assume that $\\mathsf{P} \\neq \\mathsf{NP}$. $\\mathsf{NPI}$ is the class of problems in $\\mathsf{NP}$ which are neither in $\\mathsf{P}$ nor in $\\mathsf{NP}$-hard. You can find a list of problems conjectured to be $\\mathsf{NPI}$ <a href="http://cstheory.stackexchange.com/questions/79/problems-between-p-and-npc/">here</a>. </p>\n\n<p><a href="http://cstheory.stackexchange.com/questions/799/generalized-ladners-theorem">Ladner\'s theorem</a> tells us that if $\\mathsf{NP}\\neq\\mathsf{P}$ then there is an infinite hierarchy of $\\mathsf{NPI}$ problems, i.e. there are $\\mathsf{NPI}$ problems which are harder than other $\\mathsf{NPI}$ problems.</p>\n\n<blockquote>\n  <p>I am looking for candidates of such problems, i.e. I am interested in pairs of problems<br>\n  - $A,B \\in \\mathsf{NP}$,<br>\n  - $A$ and $B$ are conjectured to be $\\mathsf{NPI}$,<br>\n  - $A$ is known to reduce to $B$,<br>\n  - but there are no known reductions from $B$ to $A$.</p>\n</blockquote>\n\n<p>Even better if there are arguments for supporting these, e.g. there are results that $B$ does not reduce to $A$ assuming some conjectures in complexity theory or cryptography.</p>\n\n<p>Are there any <em>natural</em> examples of such problems?</p>\n\n<p>Example: Graph Isomorphism problem and Integer Factorization problem are conjectured to be in $\\mathsf{NPI}$ and there are argument supporting these conjectures. Are there any decision problems harder than these two but not known to be $\\mathsf{NP}$-hard?</p>\n', 'ViewCount': '833', 'Title': 'Natural candidates for the hierarchy inside NPI', 'LastEditorUserId': '41', 'LastActivityDate': '2013-01-27T05:50:00.267', 'LastEditDate': '2013-01-27T05:50:00.267', 'AnswerCount': '1', 'CommentCount': '18', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2012-03-07T07:33:15.413', 'Id': '78'}{'Body': '<p>According to <a href="http://books.google.ca/books?id=kWSZ0OWnupkC&amp;pg=PA224#v=onepage&amp;q&amp;f=false">Immerman</a>, the complexity class associated with <a href="http://en.wikipedia.org/wiki/SQL">SQL</a> queries is exactly the class of <em>safe queries</em> in $\\mathsf{Q(FO(COUNT))}$ (first-order queries plus counting operator): SQL captures safe queries. (In other words, all SQL queries have a complexity in $\\mathsf{Q(FO(COUNT))}$, and all problems in $\\mathsf{Q(FO(COUNT))}$ can be expressed as an SQL query.)</p>\n\n<p>Based on this result, from theoretical point of view, there are many interesting problems that can be solved efficiently but are not expressible in SQL. Therefore an extension of SQL which is still efficient seems interesting. So here is my question:</p>\n\n<blockquote>\n  <p>Is there an <strong>extension of SQL</strong> (implemented and <strong>used in the industry</strong>) which <strong>captures $\\mathsf{P}$</strong> (i.e. can express all polynomial-time computable queries and no others)?</p>\n</blockquote>\n\n<p>I want a database query language which stisfies all three conditions. It is easy to define an extension which would extend SQL and will capture $\\mathsf{P}$. But my questions is if such a language makes sense from the practical perspective, so I want a language that is being used in practice. If this is not the case and there is no such language, then I would like to know if there is a reason that makes such a language uninteresting from the practical viewpoint? For example, are the queries that rise in practice usually simple enough that there is no need for such a language?</p>\n', 'ViewCount': '234', 'Title': 'Extension of SQL capturing $\\mathsf{P}$', 'LastEditorUserId': '41', 'LastActivityDate': '2013-04-27T15:07:01.660', 'LastEditDate': '2012-03-12T21:56:17.563', 'AnswerCount': '3', 'CommentCount': '17', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<database-theory><complexity-theory><finite-model-theory><descriptive-complexity>', 'CreationDate': '2012-03-08T16:08:50.840', 'Id': '135'}{'ViewCount': '867', 'Title': 'Why polynomial time is called "efficient"?', 'LastEditDate': '2012-04-22T16:34:25.370', 'AnswerCount': '3', 'Score': '25', 'PostTypeId': '1', 'OwnerUserId': '157', 'FavoriteCount': '5', 'Body': "<p>Why in computer science any complexity which is at most polynomial is considered efficient?</p>\n\n<p>For any practical application<sup>(a)</sup>, algorithms with complexity $n^{\\log n}$ are way faster than algorithms that run in time, say, $n^{80}$, but the first is considered inefficient while the latter is efficient. Where's the logic?!</p>\n\n<p><sup>(a) Assume, for instance, the number of atoms in the universe is approximately $10^{80}$.</sup></p>\n", 'Tags': '<algorithms><complexity-theory><terminology><efficiency>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-04T19:18:03.357', 'CommentCount': '10', 'AcceptedAnswerId': '215', 'CreationDate': '2012-03-10T20:49:58.150', 'Id': '210'}{'Body': '<p>There is a reduction in Sipser\'s book "Introduction to the theory of computation" on page 286 from 3SAT to Hamiltonian path problem. </p>\n\n<blockquote>\n  <p>Is there a simpler reduction?</p>\n</blockquote>\n\n<p>By simpler I mean a reduction that would be easier to understand (for students).</p>\n\n<blockquote>\n  <p>Is there a reduction that uses linear number of variables?</p>\n</blockquote>\n\n<p>The reduction in Sipser uses $O(kn)$ variables where $k$ is the number of clauses and $n$ is the number of variables. In other words, it is possible for the reduction to blow the size from $s$ to $O(s^2)$. Is there a simple reduction where the size of the output of the reduction is linear in the size of its input? </p>\n\n<p>If it is not possible, is there a reason? Would that imply an unknown result in complexity/algorithms?</p>\n', 'ViewCount': '1482', 'Title': 'Easy reduction from 3SAT to Hamiltonian path problem', 'LastActivityDate': '2012-07-12T03:26:42.550', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '2701', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2012-03-11T20:22:28.390', 'FavoriteCount': '3', 'Id': '222'}{'Body': u"<p>Let's take as an example the 3d \u2192 2d reduction: What's the cost of simulating a 3d cellular automaton by a 2d cellular automaton?</p>\n\n<p>Here is a bunch of more specific questions:</p>\n\n<ol>\n<li><p>What kind of algorithms will have their time complexity changed, by how much?</p></li>\n<li><p>What would be the basic idea for the encoding; how is a 3d grid efficiently (or not efficiently\u2026) mapped to a 2d grid? (The challenge seems to achieve communication between two cells that where originally neighbors on the 3d grid, but are not neighbors anymore on the 2d grid). </p></li>\n<li><p>In particular, I'm interested in the complexity drift for exponential complexity algorithms (which I guess remains exponential whatever the dimension, is it the case?)</p></li>\n</ol>\n\n<p>Note: I'm not interested in low complexity classes for which the chosen I/O method has an influence on complexities. (Maybe the best is to assume that the I/O method is dimensionless: done locally on one specific cell during a variable amount of time steps.) </p>\n\n<hr>\n\n<p><em>Some context: I'm interested in parallel local graph rewriting, but those graphs are closer to 3d (or maybe \u03c9d\u2026) grids than to 2d grids, I'd like to know what to expect of a hardware implementation on a 2-dimentional silicon chip.</em></p>\n", 'ViewCount': '84', 'Title': 'Influence of the dimension of cellular automata on complexity classes', 'LastEditorUserId': '31', 'LastActivityDate': '2012-03-12T20:44:04.593', 'LastEditDate': '2012-03-12T17:34:06.217', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '254', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '68', 'Tags': '<complexity-theory><time-complexity><cellular-automata>', 'CreationDate': '2012-03-12T16:49:47.177', 'Id': '245'}{'Body': '<p>When reporting algorithmic complexity of an algorithm, one assumes the underlying computations are performed on some abstract machine (e.g. RAM) that approximates a modern CPU. Such models allow us to report time and space complexity of algorithms. Now, with the spread out of <a href="http://en.wikipedia.org/wiki/GPGPU">GPGPUs</a>, one wonders whether there are well known models where one can take into account power consumption as well.</p>\n\n<p>GPUs are well known to consume considerable amount of power and certain instructions fall into different categories of power consumption based on their complexity and location on the sophisticated chip. Hence instructions, from an energy of view, are not of unit (or even fixed) cost. A trivial extension would be assigning weights to operation cost, but I\'m looking for a powerful model where an operation/instruction might cost <em>non-constant</em> units of energy, e.g. polynomial amount (or even more complex e.g.: function of time elapsed since start of the algorithm; or taking into account probability of failure of cooling system, which will heat up the chips, and slow down the clock frequency etc.)</p>\n\n<p>Are there such models where non-trivial costs and faults can be incorporated?</p>\n', 'ViewCount': '144', 'Title': 'Is there an abstract machine that can capture power consumption?', 'LastEditorUserId': '48', 'LastActivityDate': '2012-03-26T15:00:28.613', 'LastEditDate': '2012-03-13T02:52:43.603', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '281', 'Score': '9', 'OwnerDisplayName': 'user20', 'PostTypeId': '1', 'Tags': '<complexity-theory><computer-architecture><power-consumption><machine-models>', 'CreationDate': '2012-03-13T00:48:16.690', 'Id': '271'}{'ViewCount': '336', 'Title': 'Decidable non-context-sensitive languages', 'LastEditDate': '2012-03-13T02:01:32.497', 'AnswerCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '95', 'FavoriteCount': '1', 'Body': '<p>It is arguable that most languages created to describe everyday problems are context-sensitives. In the other hand, it is possible and not hard to find some languages that are not recursive or even not recursively-enumerable.</p>\n\n<p>Between these two types are the recursive non-context-sensitive languages. Wikipedia gives one example <a href="http://en.wikipedia.org/wiki/Context-sensitive_language">here</a>:</p>\n\n<blockquote>An example of recursive language that is not context-sensitive is any recursive language whose decision is an EXPSPACE-hard problem, say, the set of pairs of equivalent regular expressions with exponentiation.</blockquote>\n\n<p>So the question: What others problems exists that are decidable but yet non-context-sensitive? Is this class of problems the same as decidable EXPSPACE-hard?</p>\n', 'Tags': '<formal-languages><complexity-theory><formal-grammars>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-13T03:17:33.480', 'CommentCount': '1', 'AcceptedAnswerId': '280', 'CreationDate': '2012-03-13T01:19:52.050', 'Id': '273'}{'ViewCount': '135', 'Title': 'Decision problem such that any algorithm admits an exponentially faster algorithm', 'LastEditDate': '2012-03-13T16:44:07.970', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '98', 'FavoriteCount': '1', 'Body': u'<p>In Hromkovi\u010d\'s <a href="http://www.ite.ethz.ch/publications/buch/index_EN">Algorithmics for Hard Problems</a> (2nd edition) there is this theorem (2.3.3.3, page 117):</p>\n\n<blockquote>\n  <p>There is a (decidable) decision problem $P$ such that for every algorithm $A$ that solves $P$ there is another algorithm $A&#39;$ that also solves $P$ and additionally fulfills<br>\n  $\\qquad \\forall^\\infty n \\in \\mathbb{N}. \\mathrm{Time}_{A&#39;}(n) = \\log_2 \\mathrm{Time}_A(n)$</p>\n</blockquote>\n\n<p>$\\mathrm{Time}_A(n)$ is the worst-case runtime of $A$ on inputs of size $n$ and $\\forall^\\infty$ means "for all but finitely many".</p>\n\n<p>A proof is not given and we have no idea how to go about this; it is quite counter-intuitive, actually. How can the theorem be proven?</p>\n', 'Tags': '<complexity-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-03-13T19:01:16.037', 'CommentCount': '1', 'AcceptedAnswerId': '321', 'CreationDate': '2012-03-13T13:38:18.297', 'Id': '310'}{'ViewCount': '2078', 'Title': "Why hasn't there been an encryption algorithm that is based on the known NP-Hard problems?", 'LastEditDate': '2012-03-15T07:04:19.330', 'AnswerCount': '4', 'Score': '51', 'PostTypeId': '1', 'OwnerUserId': '5', 'FavoriteCount': '8', 'Body': "<p>Most of today's encryption, such as the RSA, relies on the integer factorization, which is not believed to be a NP-hard problem, but it belongs to BQP, which makes it vulnerable to quantum computers. I wonder, why has there not been an encryption algorithm which is based on an known NP-hard problem. It sounds (at least in theory) like it would make a better encryption algorithm than a one which is not proven to be NP-hard.</p>\n", 'Tags': '<complexity-theory><np-hard><encryption><cryptography>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-22T00:58:17.060', 'CommentCount': '1', 'AcceptedAnswerId': '364', 'CreationDate': '2012-03-14T08:02:26.627', 'Id': '356'}{'Body': '<p>Given an instance of SAT, I would like to be able to estimate how difficult it will be to solve the instance.</p>\n\n<p>One way is to run existing solvers, but that kind of defeats the purpose of estimating difficulty. A second way might be looking a the ratio of clauses to variables, as is done for phase transitions in random-SAT, but I am sure better methods exist.</p>\n\n<p>Given an instance of SAT, are there some fast heuristics to measure the difficulty? The only condition is that these heuristics be faster than actually running existing SAT solvers on the instance.</p>\n\n<hr>\n\n<h3>Related question</h3>\n\n<p><a href="http://cstheory.stackexchange.com/q/4375/1037">Which SAT problems are easy?</a> on cstheory.SE. This questions asks about tractable sets of instances. This is a similar question, but not exactly the same. I am really interested in a heuristic that given a single instance, makes some sort of semi-intelligent guess of if the instance will be a hard one to solve.</p>\n', 'ViewCount': '287', 'Title': 'Measuring the difficulty of SAT instances', 'LastActivityDate': '2012-11-27T06:24:05.617', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '917', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<complexity-theory><satisfiability><heuristics>', 'CreationDate': '2012-03-15T05:00:23.853', 'FavoriteCount': '4', 'Id': '407'}{'Body': '<p>Minimum bandwidth problem is to a find an ordering of graph nodes on integer line that minimizes the largest distance between any two adjacent nodes. </p>\n\n<p>The decision problem is NP-complete even for binary trees. <a href="http://www.jstor.org/stable/10.2307/2100947" rel="nofollow">Complexity Results for Bandwidth Minimization. Garey, Graham, Johnson and Knuth, SIAM J. Appl. Math., Vol. 34, No.3, 1978</a>.</p>\n\n<p>What is the best known efficient approximability result for computing minimum bandwidth on binary trees? What is best known conditional hardness of approximation result? </p>\n', 'ViewCount': '174', 'Title': 'Approximation of minimum bandwidth on binary trees', 'LastEditorUserId': '472', 'LastActivityDate': '2012-05-24T21:14:57.037', 'LastEditDate': '2012-04-02T11:58:13.790', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '988', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete><reference-request><approximation>', 'CreationDate': '2012-03-15T14:56:56.453', 'Id': '416'}{'ViewCount': '3515', 'Title': 'How hard is counting the number of simple paths between two nodes in a directed graph?', 'LastEditDate': '2012-03-26T05:19:12.447', 'AnswerCount': '1', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '137', 'FavoriteCount': '5', 'Body': "<p>There is an easy polynomial algorithm to decide whether there is a path between two nodes in a directed graph (just do a routine graph traversal with, say, depth-first-search).</p>\n\n<p>However it seems that, surprisingly, the problem gets much harder if instead of testing for the existence we want want to <em>count</em> the number of paths.</p>\n\n<p>If we allow paths to reuse vertices then there is a dynamic programming solution to find the number of paths from <em>s</em> to <em>t</em> with <em>n</em> edges. <strong>However, if we only allow simple paths, that don't reuse vertices, the only solution I can think of is brute force enumeration of the paths</strong>, something that has exponential time complexity.</p>\n\n<p>So I ask,</p>\n\n<ul>\n<li>Is counting the number of simple paths between two vertices hard?</li>\n<li>If so, is it kind of NP-complete? (I say kind of because it is technically not a decision problem...)</li>\n<li>Are there other problems in P that have a hard counting versions like that too?**</li>\n</ul>\n", 'Tags': '<algorithms><complexity-theory><graph-theory>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-26T05:19:12.447', 'CommentCount': '3', 'AcceptedAnswerId': '445', 'CreationDate': '2012-03-15T18:22:52.533', 'Id': '423'}{'ViewCount': '754', 'Title': 'Decision problems vs "real" problems that aren\'t yes-or-no', 'LastEditDate': '2012-04-02T21:58:54.973', 'AnswerCount': '3', 'Score': '22', 'PostTypeId': '1', 'OwnerUserId': '157', 'FavoriteCount': '6', 'Body': '<p>I read in many places that some problems are difficult to approximate (it is  <a href="https://en.wikipedia.org/wiki/Hardness_of_approximation"><strong>NP-hard</strong> to approximate</a>  them). But approximation is not a decision problem: the answer is a real number and not Yes or No. Also for each desired approximation factor, there are many answers that are correct and many that are wrong, and this changes with the desired approximation factor!</p>\n\n<p>So how can one say that this problem is NP-hard?</p>\n\n<p><em>(inspired by the second bullet in <a href="http://cs.stackexchange.com/q/423/157">How hard is counting the number of simple paths between two nodes in a directed graph?</a>)</em></p>\n', 'Tags': '<complexity-theory><time-complexity><np-hard><approximation>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-29T16:31:13.863', 'CommentCount': '0', 'AcceptedAnswerId': '476', 'CreationDate': '2012-03-17T18:28:41.347', 'Id': '473'}{'Body': "<p>A polynomial-time Turing machine algorithm is considered efficient if its run-time, in the worst-case, is bounded by a polynomial function in the input size. I'm aware of the strong Church-Turing thesis:</p>\n\n<blockquote>\n  <p>Any reasonable model of computation can be efficiently simulated on Turing machines</p>\n</blockquote>\n\n<p>However, I'm not aware of solid theory for analyzing the computational complexity of algorithms of $\\lambda$-calculus.</p>\n\n<p>Do we have a notion of computational efficiency for every known model of computation? Are there any models that are only useful for computability questions but useless for computational complexity questions?</p>\n", 'ViewCount': '301', 'Title': 'Notions of efficient computation', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-02T03:50:01.950', 'LastEditDate': '2012-04-02T03:50:01.950', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><efficiency><computation-models>', 'CreationDate': '2012-03-20T15:52:42.367', 'FavoriteCount': '1', 'Id': '540'}{'ViewCount': '2045', 'Title': 'Intuition for logarithmic complexity', 'LastEditDate': '2012-06-18T13:16:23.193', 'AnswerCount': '7', 'Score': '44', 'PostTypeId': '1', 'OwnerUserId': '385', 'FavoriteCount': '16', 'Body': "<p>I believe I have a reasonable grasp of complexities like $\\mathcal{O}(1)$, $\\Theta(n)$ and $\\Theta(n^2)$.</p>\n\n<p>In terms of a list, $\\mathcal{O}(1)$ is a constant lookup, so it's just getting the head of the list.\n$\\Theta(n)$ is where I'd walk the entire list, and $\\Theta(n^2)$ is walking the list once for each element in the list.</p>\n\n<p>Is there a similar intuitive way to grasp $\\Theta(\\log n)$ other than just knowing it lies somewhere between $\\mathcal{O}(1)$ and $\\Theta(n)$?</p>\n", 'Tags': '<algorithms><complexity-theory><time-complexity><intuition>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-18T13:16:23.193', 'CommentCount': '6', 'AcceptedAnswerId': '582', 'CreationDate': '2012-03-21T05:51:41.653', 'Id': '581'}{'ViewCount': '893', 'Title': 'Logarithmic vs double logarithmic time complexity', 'LastEditDate': '2012-04-12T05:54:48.283', 'AnswerCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '652', 'FavoriteCount': '2', 'Body': '<p>In real world applications is there a concrete benefit when using $\\mathcal{O}(\\log(\\log(n))$ instead of $\\mathcal{O}(\\log(n))$ algorithms ?</p>\n\n<p>This is the case when one use for instance van Emde Boas trees instead of more conventional binary search tree implementations. \nBut for example, if we take $n &lt; 10^6$ then in the best case the double logarithmic algorithm outperforms the logarithmic one by (approximately) a factor of $5$. And also in general the implementation is more tricky and complex. </p>\n\n<p>Given that I personally prefer BST over VEB-trees, what do you think ?</p>\n\n<p><em>One could easily demonstrate that :</em></p>\n\n<p>$\\qquad \\displaystyle \\forall n &lt; 10^6.\\ \\frac{\\log n}{\\log(\\log(n))} &lt; 5.26146$</p>\n', 'Tags': '<algorithms><complexity-theory><binary-trees><algorithm-analysis><search-trees>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-26T03:54:23.937', 'CommentCount': '3', 'AcceptedAnswerId': '661', 'CreationDate': '2012-03-22T14:23:03.533', 'Id': '654'}{'Body': "<p>Many intractable $NP$-complete problems can be modeled as deciding whether a set of triples, $F=${$t_1, t_2, ..., t_n$} where each triple $t_i$ is a subset of three elements over base set $U=${$a_1, a_2, ..., a_k$}, satisfy some non-trivial property. For example, 3-edge coloring of cubic graphs can be modeled as the problem of deciding whether sets of triples satisfy that the elements in each triple must have different color. </p>\n\n<p>I'm looking for examples of non-trivial tractable properties ($P_2$) of sets of triples (which have polynomial time algorithms) given that the sets of triples already satisfies some other non-trivial property $P_1$. Non-trivial property means that there are infinite number of sets of triples that satisfy the property and infinite number of sets of triples that do not. Are all non-trivial properties $P_2$ of sets of triples intractable?</p>\n\n<p>Also, I'd appreciate a survey on the subject.</p>\n\n<p><strong>EDIT:</strong> Based on Ben's answer, I added the requirement that $F$ already satisfies some non-trivial property $P_1$ and we are asking weather it satisfies another no-trivial property $P_2$. For instance, in the 3-edge coloring example, the family of triples $F$ must represent the edges incident on the nodes of a cubic graph.</p>\n", 'ViewCount': '147', 'Title': 'Non-trivial tractable properties of triples', 'LastEditorUserId': '98', 'LastActivityDate': '2012-03-31T08:02:47.040', 'LastEditDate': '2012-03-31T07:24:38.273', 'AnswerCount': '2', 'CommentCount': '7', 'AcceptedAnswerId': '678', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory>', 'CreationDate': '2012-03-22T21:50:05.923', 'Id': '674'}{'ViewCount': '499', 'Title': 'Decidable restrictions of the Post Correspondence Problem', 'LastEditDate': '2012-09-21T13:15:50.123', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '1', 'Body': '<p>The <a href="http://en.wikipedia.org/wiki/Post_correspondence_problem" rel="nofollow">Post Correspondence Problem</a> (PCP) is undecidable.</p>\n\n<p>The <em>bounded version of the PCP</em> is $\\mathrm{NP}$-complete and the <em>marked version of the PCP</em> (the words of one of the two lists are required to differ in the first letter) is in $\\mathrm{PSPACE}$ [1].</p>\n\n<ol>\n<li>Are these restricted versions used to prove some complexity results of other problems (through reduction)?</li>\n<li>Are there other restricted versions of the PCP that make it decidable (and in particular $\\mathrm{PSPACE}$-complete)?</li>\n</ol>\n\n<p>[1] "<a href="http://dx.doi.org/10.1016/S0304-3975%2899%2900163-2" rel="nofollow">Marked PCP is decidable</a>" by V. Halava, M. Hirvensalo, R. De Wolf (1999)</p>\n', 'Tags': '<complexity-theory><computability><reference-request>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-21T13:15:50.123', 'CommentCount': '0', 'AcceptedAnswerId': '4638', 'CreationDate': '2012-03-23T17:15:49.773', 'Id': '701'}{'Body': "<p>The 3-Partition problem asks whether a set of $3n$ integers can be partitioned into $n$ sets of three integers such that each set sums up to some given integer $B$. The Balanced Partition problem asks whether $2n$ integers can be partitioned into two equal cardinality sets such that both sets have the same sum. Both problems are known to be NP-complete. However, 3-Partition is strongly NP-complete. I haven't seen in the literature any reduction from 3-Partition to Balanced Partition.</p>\n\n<p>I'm looking for (simple) reduction from the 3-Partition to the Balanced Partition problem.</p>\n", 'ViewCount': '661', 'Title': 'Reduction from 3-Partition problem to Balanced Partition problem', 'LastEditorUserId': '157', 'LastActivityDate': '2012-11-15T08:51:52.980', 'LastEditDate': '2012-03-31T06:46:55.977', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><reductions><np-complete>', 'CreationDate': '2012-03-25T23:50:10.927', 'FavoriteCount': '2', 'Id': '783'}{'ViewCount': '1006', 'Title': 'NP completeness proof of a spanning tree problem', 'LastEditDate': '2012-03-31T06:45:44.153', 'AnswerCount': '1', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '763', 'FavoriteCount': '3', 'Body': '<p>I am looking for some hints in a question asked by my instructor.</p>\n\n<p>So I just figured out this decision problem is $\\sf{NP\\text{-}complete}$:</p>\n\n<p>In a graph $G$, is there a spanning tree in $G$ that contain an exact set of $S=\\{x_1, x_2,\\ldots, x_n\\}$ as leafs. I figured out we can prove that it is $\\sf{NP\\text{-}complete}$ by reducing Hamiltonian path to this decisions problem.</p>\n\n<p>But my instructor also asked us in class:</p>\n\n<blockquote>\n  <p>would it also be $\\sf{NP\\text{-}complete}$ if instead of "exact set of $S$", we do </p>\n  \n  <p>"include the whole set of $S$ and possibly other leafs" or \n     "subset of $S$"</p>\n</blockquote>\n\n<p>I think "subset of S" would be $\\sf{NP\\text{-}complete}$, but I just can\'t prove it, I don\'t know what problem I can reduce it to this. As for "include the set of $S$..." I think it can be solved in polynomial time.</p>\n', 'Tags': '<complexity-theory><graphs><np-complete>', 'LastEditorUserId': '157', 'LastActivityDate': '2012-03-31T06:45:44.153', 'CommentCount': '2', 'AcceptedAnswerId': '822', 'CreationDate': '2012-03-27T03:43:11.057', 'Id': '808'}{'ViewCount': '382', 'Title': 'Proving that directed graph diagnosis is NP-hard', 'LastEditDate': '2012-03-27T13:53:00.233', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '766', 'FavoriteCount': '1', 'Body': "<p>I have a homework assignment that I've been bashing my head against for some time, and I'd appreciate any hints. It is about choosing a known problem, the NP-completeness of which is proven, and constructing a reduction from that problem to the following problem I'll call DGD (directed graph diagnosis).</p>\n\n<h3>Problem</h3>\n\n<blockquote>\n  <p>An instance of DGD $(V,E,k)$ consist of vertices $V = I \\overset{.}{\\cup} O \\overset{.}{\\cup} B$, directed edges $E$ and a positive integer $k$. There are three types of vertices: vertices with only incoming edges $I$, vertices with only outgoing edges $O$ and vertices with both incoming and outgoing edges $B$. Let furthermore $D=O\\times I$. </p>\n  \n  <p>Now, the problem is whether we can cover all nodes with at most $k$ elements of $D$, i.e.</p>\n  \n  <p>$\\qquad \\displaystyle \\exists\\,S\\subseteq D, |S|\\leq k.\\ \\forall\\, v\\in V.\\ \\exists\\,(v_1,v_2) \\in S.\\ v_1 \\to^* v \\to^* v_2 $</p>\n  \n  <p>where $a\\to^* b$ means that there is a directed path from $a$ to $b$.</p>\n</blockquote>\n\n<hr>\n\n<p>I think that the Dominating Set problem is the one I should be reducing from, because this too is concerned about covering a subset of nodes with another subset. I tried creating a DGD instance by first creating two nodes for each element of the dominating set, copying all edges, and then setting the $k$ of the DGD instance equal to that of the DS instance.</p>\n\n<p>Suppose a simple DS-instance with nodes $1$, $2$ and $3$ and edges $(1,2)$ and $(1,3)$. This is a yes-instance with $k = 1$; the dominating set in this case consists of only node $1$. Reducing with the method just described, this would lead to a DGD instance with two paths $(1 \\to 2 \\to 1&#39;)$ and $(1 \\to 3 \\to 1&#39;)$; to cover all nodes, just one pair $(1, 1&#39;)$ would be sufficient. This would have worked perfectly, were it not for the fact that the dominating set of the DS-instance cannot, of course, be determined in polynomial time, which is a requirement here.</p>\n\n<p>I have found that there are many good-looking ways to transform the edges and vertices when reducing, but my problem is somehow expressing DGD's $k$ in terms of DS's $k$. Dominating Set seemed a fitting problem to reduce from, but because of this I think that maybe I should try to reduce from a problem that has no such $k$?</p>\n", 'Tags': '<complexity-theory><np-hard><graph-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-25T16:54:54.900', 'CommentCount': '2', 'AcceptedAnswerId': '812', 'CreationDate': '2012-03-27T07:03:35.207', 'Id': '811'}{'Body': '<p>I <a href="http://blog.computationalcomplexity.org/2004/04/blum-complexity-measures.html" rel="nofollow">read</a> that the number of coin tosses of a probabilistic Turing machine (PTM) is not a <a href="http://en.wikipedia.org/wiki/Blum_axioms" rel="nofollow">Blum complexity measure</a>. Why?</p>\n\n<p>Clarification:</p>\n\n<p>Note that since the execution of the machine is not deterministic, one should be careful about defining the number of coin tosses for a PTM $M$ on input $x$ in a way similar to the time complexity for NTMs and PTMs. One way is to define it as the maximum number of coin tosses over possible executions of $M$ on $x$.</p>\n\n<p>We need the definition to satisfy the axiom about decidability of $m(M,x)=k$. We can define it as follows:</p>\n\n<p>$$\nm(M,x) =\n\\begin{cases}\nk &amp; \\text{all executions of $M$ on $x$ halt, $k=\\max$ #coin tosses} \\\\\n\\infty &amp; o.w. \\\n\\end{cases}\n$$</p>\n\n<p>The number of random bits that an algorithm uses is a complexity measure that appears in papers, e.g. "algorithm $A$ uses only $\\lg n$ random bits, whereas algorithm $B$ uses $n$ random bits".</p>\n', 'ViewCount': '119', 'Title': 'Is the number of coin tosses of a probabilistic Turing machine a Blum complexity measure?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-28T17:32:38.167', 'LastEditDate': '2012-03-28T17:32:38.167', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<computability><complexity-theory><randomness><probabilistic-algorithms>', 'CreationDate': '2012-03-27T20:35:16.207', 'Id': '835'}{'ViewCount': '603', 'Title': 'Reducing directed hamiltonian cycle to graph coloring', 'LastEditDate': '2012-03-31T06:51:22.663', 'AnswerCount': '1', 'Score': '5', 'OwnerDisplayName': 'Johan Sannemo', 'PostTypeId': '1', 'OwnerUserId': '1276', 'FavoriteCount': '1', 'Body': '<p>The 3-SAT problem can be reduced to both the graph coloring and the directed hamiltonian cycle problem, but is there any chain of reductions which reduce directed hamiltonian cycle to graph coloring in polynomial time?</p>\n', 'Tags': '<complexity-theory><np-complete><reductions>', 'LastEditorUserId': '157', 'LastActivityDate': '2012-03-31T06:51:22.663', 'CommentCount': '9', 'AcceptedAnswerId': '886', 'CreationDate': '2012-03-26T21:01:13.650', 'Id': '864'}{'ViewCount': '3631', 'Title': 'Knapsack problem -- NP-complete despite dynamic programming solution?', 'LastEditDate': '2012-03-31T07:11:40.927', 'AnswerCount': '3', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '848', 'FavoriteCount': '5', 'Body': '<p>Knapsack problems are easily solved by dynamic programming. Dynamic programming runs in polynomial time; that is why we do it, right?</p>\n\n<p>I have read it is actually an NP-complete problem, though, which would mean that solving the problem in polynomial problem is probably impossible.</p>\n\n<p>Where is my mistake?</p>\n', 'Tags': '<complexity-theory><np-complete><dynamic-programming>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-18T16:50:46.083', 'CommentCount': '1', 'AcceptedAnswerId': '910', 'CreationDate': '2012-03-31T05:44:11.187', 'Id': '909'}{'Body': '<p>It is known that each optimization/search problem has an equivalent decision problem. For example the shortest path problem</p>\n\n<blockquote>\n  <ul>\n  <li><strong>optimization/search version:</strong>\n  Given an undirected unweighted graph $G = (V, E)$ and two vertices $v,u\\in V(G)$, find a shortest path between $v$ and $u$.</li>\n  <li><strong>decision version:</strong> \n  Given an undirected unweighted graph $G = (V, E)$, two vertices $v,u\\in V(G)$ and a non-negative integer $k$. Is there a path in $G$ between $u$ and $v$ whose length is at most $k$?</li>\n  </ul>\n</blockquote>\n\n<p>In general, "Find $x^*\\in X$ s.t. $f(x^*) = \\min\\{f(x)\\mid x\\in X\\}$!" becomes "Is there $x\\in X$ s.t. $f(x) \\leq k$?". </p>\n\n<p>But is the reverse also true, i.e. is there an equivalent optimization problem for every decision problem? If not, what is an example of a decision problem that has no equivalent optimization problem?</p>\n', 'ViewCount': '1009', 'Title': 'Optimization version of decision problems', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-21T15:32:42.343', 'LastEditDate': '2012-04-01T08:47:48.317', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '15', 'OwnerDisplayName': 'bek', 'PostTypeId': '1', 'Tags': '<complexity-theory><optimization><search-problem><decision-problem>', 'CreationDate': '2012-03-31T06:30:08.680', 'FavoriteCount': '5', 'Id': '939'}{'ViewCount': '983', 'Title': '"NP-complete" optimization problems', 'LastEditDate': '2012-04-22T16:14:12.770', 'AnswerCount': '1', 'Score': '12', 'OwnerDisplayName': 'Aniket Schneider', 'PostTypeId': '1', 'OwnerUserId': '890', 'FavoriteCount': '3', 'Body': '<p>I am slightly confused by some terminology I have encountered regarding the complexity of optimization problems.  In an algorithms class, I had the <a href="http://en.wikipedia.org/wiki/Maximum_parsimony_%28phylogenetics%29#Problems_with_maximum_parsimony_phylogeny_estimation">large parsimony</a> problem described as NP-complete.  However, I am not exactly sure what the term NP-complete means in the context of an optimization problem.  Does this just mean that the corresponding decision problem is NP-complete?  And does that mean that the optimization problem may in fact be harder (perhaps outside of NP)?</p>\n\n<p>In particular, I am concerned about the fact that while an NP-complete decision problem is polynomial time verifiable, a solution to a corresponding optimization problem does not appear to be polynomial time verifiable.  Does that mean that the problem is not really in NP, or is polynomial time verifiability only a characteristic of NP decision problems?</p>\n', 'Tags': '<complexity-theory><np-complete><terminology>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:14:12.770', 'CommentCount': '6', 'AcceptedAnswerId': '989', 'CreationDate': '2012-04-02T04:39:45.650', 'Id': '982'}{'ViewCount': '2198', 'Title': 'Complexity of Towers of Hanoi', 'LastEditDate': '2012-04-04T19:15:22.400', 'AnswerCount': '1', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '898', 'FavoriteCount': '2', 'Body': '<p>I ran into the following doubts on the complexity of <a href="http://en.wikipedia.org/wiki/Tower_of_Hanoi">Towers of Hanoi</a>, on which I would like your comments.</p>\n\n<ul>\n<li><p><b>Is it in NP? </b> \nAttempted answer: Suppose Peggy (prover) solves the problem &amp; submits it to Victor (verifier). Victor can easily see that the final state of the solution is right (in linear time) but he\'ll have no option but to go through each of Peggy\'s moves to make sure she didn\'t make an illegal move. Since Peggy has to make a minimum of 2^|disks|  - 1  moves (provable), Victor too has to follow suit. Thus Victor has no polynomial time verification (the definition of NP), and hence can\'t be in NP.</p></li>\n<li><p><b> Is it in PSPACE </b> ? Seems so, but I can\'t think of how to extend the above reasoning. </p></li>\n<li><p><b> Is it PSPACE-complete? </b> Seems not, but I have only a vague idea. Automated Planning , of which ToH is a specific instance,  is PSPACE-complete. I think that Planning has far more hard instances than ToH. </p></li>\n</ul>\n\n<p><b> Updated </b>: Input = $n$, the number of disks; Output = disk configuration at each step. After updating this, I realized that this input/output format doesn\'t fit a decision problem. I\'m not sure about the right formalization to capture the notions of NP,PSPACE, etc. for this kind of problem.</p>\n\n<p><b> Update #2 </b>: After Kaveh\'s and Jeff\'s comments, I\'m forced to make the problem more precise: </p>\n\n<blockquote>\n  <p>Let the input be the pair of ints $(n,i)$ where $n$ is the number of disks. If the sequence of moves taken by the disks is written down in the format (disk-number,from-peg,to-peg)(disk-number, from-peg, to-peg)... from the first move to the last, and encoded in binary, output the $i$th bit.</p>\n</blockquote>\n\n<p>Let me know if I need to be more specific about the encoding. I suppose Kaveh\'s comment applies in this case?   </p>\n', 'Tags': '<complexity-theory><time-complexity>', 'LastEditorUserId': '898', 'LastActivityDate': '2012-04-04T19:58:27.353', 'CommentCount': '9', 'AcceptedAnswerId': '1043', 'CreationDate': '2012-04-02T21:49:28.057', 'Id': '999'}{'ViewCount': '310', 'Title': 'Showing that a problem in X is not X-Complete', 'LastEditDate': '2012-04-22T15:55:25.283', 'AnswerCount': '4', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '31', 'FavoriteCount': '1', 'Body': '<p>The <a href="http://en.wikipedia.org/wiki/Existential_theory_of_the_reals" rel="nofollow">Existential Theory of the Reals</a> is in <strong>PSPACE</strong>, but I don\'t know whether it is  <strong>PSPACE-Complete</strong>. If I believe that it is not the case,  how could I prove it?</p>\n\n<p>More generally, given a problem in some complexity class <strong>X</strong>, how can I show that it is <em>not</em> <strong>X-Complete</strong>? For example, <strong>X</strong> could be <strong>NP</strong>, <strong>PSPACE</strong>, <strong>EXPTIME</strong>.</p>\n', 'Tags': '<complexity-theory><proof-techniques>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T15:55:25.283', 'CommentCount': '1', 'AcceptedAnswerId': '1324', 'CreationDate': '2012-04-03T00:28:28.780', 'Id': '1002'}{'Body': u'<p>Consider the following problem.</p>\n\n<blockquote>\n  <p>Given a set $S$ of integers, a function $f : \\mathbb{Z} \\to \\mathbb{Z}$ and $k \\in  \\mathbb{Z}$, decide wether there is $X \\subseteq S$ such that $f\\left(\\sum_{x\\in X}x\\right)=k$.</p>\n</blockquote>\n\n<p>Is this still considered a <a href="https://en.wikipedia.org/wiki/Subset_sum">subset-sum problem</a>?</p>\n\n<p>For instance, given</p>\n\n<p>$\\qquad \\displaystyle S=\\{ \u22127, \u22123, \u22122, 5, 8\\}$</p>\n\n<p>and $k=0$, find a subset $X$ such that $f\\left(\\sum_{x\\in X}x\\right)=0$ for $f(y)=-3+y$. In this case, a solution is $X=\\{ -3,-2,8 \\}$.</p>\n', 'ViewCount': '280', 'Title': 'Subset Sum Requirements', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-09T02:29:27.840', 'LastEditDate': '2012-04-05T16:54:39.337', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '956', 'Tags': '<complexity-theory>', 'CreationDate': '2012-04-05T13:51:35.137', 'Id': '1053'}{'Body': '<p>Two things (this may be naive):</p>\n\n<ol>\n<li><p>Does anyone believe there is a sub-exponential time algorithm for the <a href="http://en.wikipedia.org/wiki/Subset_sum_problem" rel="nofollow">Subset-sum problem</a>? It seems obvious to me that you would have to look through all possible subsets to prove (the negation of) an existential statement. It seems obvious in the same way that if somebody asked you "Is $x$ in this list of $n$ numbers?", it\'s obvious that you would have to look through all $n$ numbers.</p></li>\n<li><p>If Subset-sum can be polynomial time reduced to <a href="http://en.wikipedia.org/wiki/K-SAT#3-satisfiability" rel="nofollow">3SAT</a> and we agree on (1), then doesn\'t that mean $NP \\neq P$?</p></li>\n</ol>\n', 'ViewCount': '503', 'Title': 'Subset-sum and 3SAT', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-08T16:41:26.820', 'LastEditDate': '2012-04-08T06:35:06.860', 'AnswerCount': '3', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '959', 'Tags': '<complexity-theory><time-complexity><np-complete><reductions>', 'CreationDate': '2012-04-07T21:28:36.573', 'Id': '1118'}{'ViewCount': '193', 'Title': 'What is the difference between "Decision" and "Verification" in complexity theory?', 'LastEditDate': '2012-04-22T16:09:00.167', 'AnswerCount': '2', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '603', 'FavoriteCount': '1', 'Body': '<p>In Michael Sipser\'s <em>Theory of Computation</em> on page 270 he writes:</p>\n\n<blockquote>\n  <p>P = the class of languages for which membership can be decided quickly.<br>\n  NP = the class of languages for which membership can be verified quickly.</p>\n</blockquote>\n\n<p>What is the difference between "decided" and "verified"?</p>\n', 'Tags': '<complexity-theory><terminology><decision-problem>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:09:00.167', 'CommentCount': '1', 'AcceptedAnswerId': '1141', 'CreationDate': '2012-04-08T18:57:17.230', 'Id': '1137'}{'Body': '<p>For every computable function $f$ does there exist a problem that can be solved at best in $\\Theta(f(n))$ time or is there a computable function $f$ such that every problem that can be solved in $O(f(n))$ can also be solved in $o(f(n))$ time?</p>\n\n<p>This question popped into my head yesterday. I\'ve been thinking about it for a bit now, but can\'t figure it out. I don\'t really know how I\'d google for this, so I\'m asking here. Here\'s what I\'ve come up with:</p>\n\n<p>My first thought was that the answer is yes: For every computable function $f$ the problem "Output $f(n)$ dots" (or create a string with $f(n)$ dots or whatever) can obviously not be solved in $o(f(n))$ time. So we only need to show that it can be solved in $O(f(n))$ time. No problem, just take the following pseudo code:</p>\n\n<pre><code>x = f(n)\nfor i from 1 to x:\n    output(".")\n</code></pre>\n\n<p>Clearly that algorithm solves the stated problem. And it\'s runtime is obviously in $\\Theta(f(n))$, so problem solved. That was easy, right? Except no, it isn\'t because you have to consider the cost of the first line. The above algorithm\'s runtime is only in $\\Theta(f(n))$ if the time needed to calculate $f(n)$ is in $O(f(n))$. Clearly that\'s not true for all functions<sup>1</sup>.</p>\n\n<p>So this approach didn\'t get me anywhere. I\'d be grateful for anyone pointing me in the right direction to figure this out properly.</p>\n\n<hr>\n\n<p><sup>1</sup> Consider for example the function $p(n) = \\cases{1 &amp; \\text{if $n$ is prime} \\\\ 2 &amp; \\text{otherwise}}$. Clearly $O(p(n)) = O(1)$, but there is no algorithm that calculates $p$ in $O(1)$ time.</p>\n', 'ViewCount': '311', 'Title': 'For every computable function $f$ does there exist a problem that can be solved at best in $\\Theta(f(n))$ time?', 'LastEditorUserId': '46', 'LastActivityDate': '2012-04-09T12:47:00.887', 'LastEditDate': '2012-04-08T19:41:58.480', 'AnswerCount': '3', 'CommentCount': '2', 'AcceptedAnswerId': '1146', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '46', 'Tags': '<complexity-theory>', 'CreationDate': '2012-04-08T19:06:59.353', 'Id': '1138'}{'ViewCount': '299', 'Title': 'A continuous optimization problem that reduces to TSP', 'LastEditDate': '2012-04-09T03:13:54.610', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '898', 'FavoriteCount': '0', 'Body': '<p>Suppose I am given a  finite set of points $p_1,p_2,..p_n$ in the plane, and asked to draw a twice-differentiable curve $C(P)$ through the $p_i$\'s, such that its perimeter is as small as possible. Assuming $p_i=(x_i,y_i)$ and $x_i&lt;x_{i+1}$, I can formalize this problem as:</p>\n\n<p><i> Problem 1 (edited in response to Suresh\'s comments) </i>Determine  $C^2$ functions $x(t),y(t)$ of a parameter $t$ such that the arclength $ L = \\int_{[t \\in 0,1]} \\sqrt{x&#39;^2+y&#39;^2}dt$  is minimized, with $x(0) = x_1, x(1) = x_n$ and for all $t_i: x(t_i) = x_i$, we have $y(t_i)=y_i)$. </p>\n\n<blockquote>\n  <p>How do I prove (or perhaps refute) that Problem 1 is NP-hard?</p>\n</blockquote>\n\n<p><i> Why I suspect NP-hardness </i>   Suppose the $C^2$ assumption is relaxed. Evidently, the function of minimal arclength is the Travelling Salesman tour of the $p_i$\'s.  Perhaps the $C^2$ constraint only makes the problem much harder?</p>\n\n<p><i> Context </i> A variant of this problem was posted on <a href="http://math.stackexchange.com/questions/23181/extremal-curve-passing-through-a-set-of-points">MSE</a>. It didn\'t receive an answer both there and on <a href="http://mathoverflow.net/questions/58885/extremal-curves-with-a-should-pass-through-constraint" rel="nofollow">MO</a>. Given that it\'s nontrivial to solve the problem, I want to establish how hard it is. </p>\n', 'Tags': '<complexity-theory><np-hard><optimization><computable-analysis>', 'LastEditorUserId': '898', 'LastActivityDate': '2012-04-10T00:58:18.347', 'CommentCount': '19', 'AcceptedAnswerId': '1185', 'CreationDate': '2012-04-08T20:08:11.753', 'Id': '1142'}{'Body': '<p><strong>I want to establish that this is part of my homework for a course I am currently taking.  I am looking for some assistance in proceeding, NOT AN ANSWER.</strong></p>\n\n<p>This is the question in question:</p>\n\n<blockquote>\n  <p>A 5-pointed-star in an undirected graph is a 5-clique. Show that\n  5-POINTED-STAR $\\in P$, where 5-POINTED-STAR = $\\{ &lt;G&gt;$ $: G$ contains a\n  5-pointed-star as a subgraph $\\}$.</p>\n</blockquote>\n\n<p>Where a clique is CLIQUE = $\\{(G, k) : G$ is an undirected graph $G$ with a $k$-clique $\\}$.</p>\n\n<p>Now my problem is that this appears to be solving the CLIQUE problem, determining whether a graph contains a clique with the additional constraint of having to determine that the CLIQUE forms a 5-pointed star.  This seems to involve some geometric calculation based on knowledge of a <a href="http://www.ehow.com/about_4606571_geometry-fivepoint-star.html">5-pointed star</a>.  However, in Michael Sipser\'s <em>Theory of Computation</em>, pg 268, there is a proof showing that CLIQUE is in $NP$ and on page 270 notes that,</p>\n\n<blockquote>\n  <p><em>We have presented examples of languages, such as HAMPATH and CLIQUE,\n  <strong>that are members of NP but that are not known to be in $P$.</em></strong> [emphasis added]</p>\n</blockquote>\n\n<p>If CLIQUE is not in $P$, why five pointed star be in $P$?  Is there something I\'m not seeing?\n<strong>Remember, this is a HOMEWORK PROBLEM and A DIRECT ANSWER WOULD NOT BE APPRECIATED.</strong>  Thanks!</p>\n', 'ViewCount': '369', 'Title': 'Finding a 5-Pointed Star in polynomial time', 'LastEditorUserId': '472', 'LastActivityDate': '2013-12-10T16:14:56.977', 'LastEditDate': '2012-04-08T21:20:42.257', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '1144', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '603', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-04-08T20:17:21.780', 'Id': '1143'}{'Body': "<p>I am interested in calculating the $n$'th power of a $n\\times n$ matrix $A$. Suppose we have an algorithm for matrix multiplication which runs in $\\mathcal{O}(M(n))$ time. Then, one can easily calculate $A^n$ in $\\mathcal{O}(M(n)\\log(n))$ time. Is it possible to solve this problem in lesser time complexity?</p>\n\n<p>Matrix entries can, in general, be from a semiring but you can assume additional structure if it helps.</p>\n\n<p>Note: I understand that in general computing $A^m$ in $o(M(n)\\log(m))$ time would give a $o(\\log m)$ algorithm for exponentiation. But, a number of interesting problems reduce to the special case of matrix exponentiation where m=$\\mathcal O(n)$, and I was not able to prove the same about this simpler problem.</p>\n", 'ViewCount': '975', 'Title': 'Complexity of computing matrix powers', 'LastEditorUserId': '984', 'LastActivityDate': '2012-04-10T09:49:46.710', 'LastEditDate': '2012-04-10T09:49:46.710', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '984', 'Tags': '<algorithms><complexity-theory><time-complexity><computer-algebra>', 'CreationDate': '2012-04-09T00:05:00.413', 'FavoriteCount': '2', 'Id': '1147'}{'Body': '<p>Let me start off by noting <strong>this is a homework problem, please provide only advice and related observations, NO DIRECT ANSWERS please</strong>.  With that said, here is the problem I am looking at:</p>\n\n<blockquote>\n  <p>Let HALF-CLIQUE = { $\\langle G \\rangle$ | $G$ is an undirected graph having a complete\n  subgraph with at least $n/2$ nodes, where n is the number of nodes in $G$\n  }. Show that HALF-CLIQUE is NP-complete.</p>\n</blockquote>\n\n<p>Also, I know the following:</p>\n\n<ul>\n<li>In terms of this problem a <em>clique</em>, is defined as an undirected subgraph of the input graph, wherein every two nodes are connected by an edge.  A <em>$k$-clique</em> is a clique that contains $k$ nodes.</li>\n<li>According to our textbook, Michael Sipser\'s "<em>Introduction to the Theory of Computation</em>", pg 268, that the problem CLIQUE = {$\\langle G,k\\rangle$ | $G$ is an undirected graph with a $k$-clique} is in NP</li>\n<li>Furthermore, according to the same source (on pg 283) notes that CLIQUE is in NP-Complpete (thus also obviously in NP).</li>\n</ul>\n\n<p>I think I have the kernel of an answer here, however I could use <em>some indication of what is wrong with it or any related points that might be relevant to an answer</em>.  This is the general idea I have so far,</p>\n\n<blockquote>\n  <p>Ok, I\'d first note that a certificate would simply be a HALF-QLIQUE of $\\text{size} \\geq n/2$.  Now it appears that what I would need to do is to create a verifier that is a polynomial time reduction from CLIQUE (which we know is NP-Complete) to HALF-CLIQUE.  My idea would be that this would be done by creating a Turing machine which runs the turing machine verifier in the book for CLIQUE with the additional constraint for HALF-CLIQUE.</p>\n</blockquote>\n\n<p>This sounds correct to me, but I don\'t really trust myself yet in this subject. Once again, I would like to remind everyone <strong>this is a HOMEWORK PROBLEM</strong> so please try to avoid answering the question.  Any guidance which falls short of this would be most welcome!   </p>\n', 'ViewCount': '1464', 'Title': 'HALF CLIQUE - NP Complete Problem', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-10T03:18:31.263', 'LastEditDate': '2012-04-10T03:18:31.263', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '1184', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '603', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-04-09T20:30:50.973', 'Id': '1176'}{'Body': "<p>Having a set $A$ of $n$ elements, let's say I want to calculate a function $f(A)$ that is sensitive to all parts of the input, i.e. depends on very member of $A$ (i.e. it is possible to change any member of $A$ to something else to obtain a new input $A&#39;$ s.t. value of $f$ on $A$ and $A&#39;$ are different).</p>\n\n<p>For example, $f$ could be the sum or the average.</p>\n\n<p>Is there a result that proves that, under some conditions, the time necessary to a deterministic Turing machine to compute $f$ will be $\\Omega(n)$?</p>\n", 'ViewCount': '109', 'Title': 'Lower bounds of calculating a function of a set', 'LastEditorUserId': '851', 'LastActivityDate': '2012-04-10T22:41:50.487', 'LastEditDate': '2012-04-10T22:41:50.487', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '1219', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '851', 'Tags': '<complexity-theory>', 'CreationDate': '2012-04-10T21:41:10.390', 'Id': '1218'}{'Body': '<p>An asymptotic lower bound such as exponential-hardness is generally thought to imply that a problem is "inherently difficult". Encryption that is "inherently difficult" to break is thought to be secure. </p>\n\n<p>However, an asymptotic lower bound does not rule out the possibility that a huge but finite class of problem instances are easy (eg. all instances with size less than $10^{1000}$).</p>\n\n<p>Is there any reason to think that cryptography being based on asymptotic lower bounds would confer any particular level of security? Do security experts consider such possibilities, or are they simply ignored? </p>\n\n<p>An example is the use of trap-door functions based on the decomposition of large numbers into their prime factors. This was at one point thought to be inherently difficult (I think that exponential was the conjecture) but now many believe that there may be a polynomial algorithm (as there is for primality testing). No one seems to care very much about the lack of an exponential lower bound.</p>\n\n<p>I believe that other trap door functions have been proposed that are thought to be NP-hard (see <a href="http://cs.stackexchange.com/q/356/98">related question</a>), and some may  even have a proven lower bound. My question is more fundamental: does it matter what the asymptotic lower bound is? If not, is the practical security of any cryptographic code at all related to any asymptotic complexity result?</p>\n', 'ViewCount': '199', 'Title': 'Are asymptotic lower bounds relevant to cryptography?', 'LastEditorUserId': '157', 'LastActivityDate': '2012-04-13T07:08:10.570', 'LastEditDate': '2012-04-13T07:08:10.570', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '1038', 'Tags': '<complexity-theory><cryptography><asymptotics>', 'CreationDate': '2012-04-11T16:44:36.490', 'FavoriteCount': '1', 'Id': '1226'}{'ViewCount': '509', 'Title': 'Classification of intractable/tractable satisfiability problem variants', 'LastEditDate': '2012-04-14T10:19:29.120', 'AnswerCount': '1', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '2', 'Body': '<p>Recently I found in a paper [1] a special symmetric version of SAT called the <strong>2/2/4-SAT</strong>. But there are many $\\text{NP}$-complete variants out there, for example: <strong>MONOTONE NAE-3SAT</strong>, <strong>MONOTONE 1-IN-3-SAT</strong>, ...</p>\n\n<p>Some other variants are tractable: $2$-$\\text{SAT}$, Planar-NAE-$\\text{SAT}$, ...</p>\n\n<p>Are there survey papers (or web pages) that classify all the (weird) $\\text{SAT}$ variants that have been proved to be $\\text{NP}$-complete (or in $\\text{P}$) ?</p>\n\n<hr>\n\n<ol>\n<li><a href="https://www.aaai.org/Papers/AAAI/1986/AAAI86-027.pdf">Finding a shortest solution for the $N$x$N$ extension of the 15-Puzzle is intractable</a> by D. Ratner and M. Warmuth (1986)</li>\n</ol>\n', 'Tags': '<complexity-theory><reference-request><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-14T10:19:29.120', 'CommentCount': '2', 'AcceptedAnswerId': '1235', 'CreationDate': '2012-04-12T17:59:00.553', 'Id': '1234'}{'Body': '<p>Often I see a sentence like this while reading texts on Computational Complexity:</p>\n\n<p>"For this special case of $\\text{TSP}$" or</p>\n\n<p>"This is a special case of $\\text{SAT}$" or</p>\n\n<p>"$k$-$\\text{PARTITION}$ is the following special case of $\\text{BIN PACKING}$" or</p>\n\n<p>"$\\text{SUBSET SUM}$ is a special case of $\\text{KNAPSACK}$" ad nauseam.</p>\n\n<p>What I find missing is the criterium to claim one problem is a special case of another.<br>\nWhat is the necessity of classifying one problem as a special case of another?  Does a special case always carry the complexity class as its  \'unspecial\' case?</p>\n\n<p>Often this is simply stated with no proof of relation between these problems.</p>\n\n<p>What requirements must be met for a problem to be a special case of another?</p>\n\n<p>How can I prove a new Language for a problem is a special case of an already existing problem?</p>\n', 'ViewCount': '158', 'Title': 'Complexity of Special Case Problems', 'LastEditorUserId': '157', 'LastActivityDate': '2012-04-14T10:22:42.377', 'LastEditDate': '2012-04-13T00:17:56.733', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '956', 'Tags': '<complexity-theory>', 'CreationDate': '2012-04-12T22:28:24.113', 'Id': '1237'}{'Body': '<p>I am taking a complexity course and I am having trouble with coming up with reductions between NPC problems. How can I find reductions between problems? Is there a general trick that I can use? How should I approach a problem that asks me to prove a problem is NPC?</p>\n', 'ViewCount': '417', 'Title': 'Finding reductions', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:05:26.590', 'LastEditDate': '2012-04-22T16:05:26.590', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '1068', 'Tags': '<complexity-theory><np-complete><proof-techniques><reductions>', 'CreationDate': '2012-04-13T01:29:02.757', 'FavoriteCount': '8', 'Id': '1240'}{'ViewCount': '902', 'Title': 'What is meant by "solvable by non deterministic algorithm in polynomial time"', 'LastEditDate': '2012-04-22T16:05:06.120', 'AnswerCount': '4', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '947', 'FavoriteCount': '2', 'Body': '<p>In many textbooks NP problems are defined as:</p>\n\n<blockquote>\n  <p>Set of all decision problems solvable by non deterministic algorithms in polynomial time</p>\n</blockquote>\n\n<p>I couldn\'t understand the part "solvable by non deterministic algorithms". Could anyone please explain that?</p>\n', 'Tags': '<complexity-theory><terminology><nondeterminism>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:05:06.120', 'CommentCount': '2', 'AcceptedAnswerId': '1247', 'CreationDate': '2012-04-13T05:35:10.410', 'Id': '1243'}{'ViewCount': '450', 'Title': 'Why is Relativization a barrier?', 'LastEditDate': '2012-04-15T01:47:45.337', 'AnswerCount': '3', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '639', 'FavoriteCount': '4', 'Body': "<p>When I was explaining the Baker-Gill-Solovay proof that there exists an oracle with which we can have, $\\mathsf{P} = \\mathsf{NP}$, and an oracle with which we can have $\\mathsf{P} \\neq \\mathsf{NP}$ to a friend, a question came up as to why such techniques are ill-suited for proving the $\\mathsf{P} \\neq \\mathsf{NP}$ problem, and I couldn't give a satisfactory answer. \\</p>\n\n<p>To put it more concretely, if I have an approach to prove $\\mathsf{P} \\neq \\mathsf{NP}$ and if I could construct oracles to make a situation like above happen, why does it make my method invalid? </p>\n\n<p>Any exposition/thoughts on this topic?</p>\n", 'Tags': '<complexity-theory><proof-techniques><relativization>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-11-18T00:26:03.123', 'CommentCount': '0', 'AcceptedAnswerId': '1273', 'CreationDate': '2012-04-14T13:39:56.047', 'Id': '1271'}{'ViewCount': '638', 'Title': 'NP-completeness of a spanning tree problem', 'LastEditDate': '2012-05-18T16:16:57.077', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1108', 'FavoriteCount': '0', 'Body': '<p>I was reviewing some NP-complete problems on this site, and I meet one interesting problem from </p>\n\n<p><a href="http://cs.stackexchange.com/questions/808/np-completeness-proof-of-a-spanning-tree-problem">NP completeness proof of a spanning tree problem</a></p>\n\n<p>In this problem, I am interested in the original problem, which the leaf set is precisely $S$. The author said that he can prove this by reducing it to the Hamiltonian path. However, I still cannot figure it out. Could anybody help me with this in details?</p>\n', 'Tags': '<complexity-theory><np-complete><graph-theory><spanning-trees>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-18T16:49:04.167', 'CommentCount': '3', 'AcceptedAnswerId': '1912', 'CreationDate': '2012-04-16T03:30:50.807', 'Id': '1299'}{'Body': '<p>This question is motivated by my <a href="http://cs.stackexchange.com/a/1328/96">answer</a> to another question in which I stated the fact that both Betweeness and Non-Betweeness problems are $NP$-complete. In the former problem there is a total order such that the betweeness constraint of each triple is enforced while in the later problem there is a total order such that the betweeness constraint of each triple is violated.</p>\n\n<p>What is the complexity of the following 3SAT variants?:</p>\n\n<p>3SAT_1={($\\phi$): $\\phi$ has an assignment that makes every clause false}</p>\n\n<p>3SAT_2={($\\phi$): $\\phi$ has an assignment such that exactly half of the clauses are true and the other half is false}</p>\n', 'ViewCount': '241', 'Title': 'Complexity of 3SAT variants', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-19T06:29:04.077', 'LastEditDate': '2012-04-19T05:46:18.327', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '1348', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><satisfiability>', 'CreationDate': '2012-04-18T23:45:16.777', 'Id': '1347'}{'ViewCount': '186', 'Title': 'What is co-something?', 'LastEditDate': '2012-04-20T10:18:16.487', 'AnswerCount': '2', 'Score': '5', 'OwnerDisplayName': 'Vanwaril', 'PostTypeId': '1', 'OwnerUserId': '1160', 'Body': '<p>What does the notation <code>co-</code> mean when prefixing <code>co-NP</code>, <code>co-RE</code> (recursively enumerable), or <code>co-CE</code> (computably enumerable) ?</p>\n', 'Tags': '<complexity-theory><computability><terminology>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-20T10:18:16.487', 'CommentCount': '4', 'AcceptedAnswerId': '1372', 'CreationDate': '2012-04-19T20:06:10.973', 'Id': '1370'}{'Body': '<p>I have a collection $P \\subseteq \\mathbb{R}^3$ of $N$ particles and there is a function $f : P^2 \\to \\mathbb{R}$. I want to find which configuration of the system minimizes the value of $f$. </p>\n\n<p>Can this problem (or similar ones) be reduced to TSP? Could you point me to literature on the topic?</p>\n\n<p>In my application, $f$ is the <a href="https://en.wikipedia.org/wiki/Van_der_Waals_force" rel="nofollow">atomic van der waals force</a>, which for each pair of particles of atoms is attractive or repulsive depending on some predefined thresholds.</p>\n\n<p>In addition, it would be great to have a list of concrete examples of problems that can be reduced to TSP.</p>\n', 'ViewCount': '135', 'Title': 'Complexity of an optimisation problem in 3D', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T15:44:16.733', 'LastEditDate': '2012-04-22T15:44:16.733', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1167', 'Tags': '<complexity-theory><optimization><search-problem>', 'CreationDate': '2012-04-20T11:26:44.303', 'FavoriteCount': '2', 'Id': '1388'}{'ViewCount': '545', 'Title': 'P-Completeness and Parallel Computation', 'LastEditDate': '2012-04-21T20:26:03.557', 'AnswerCount': '3', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '31', 'FavoriteCount': '1', 'Body': '<p>I was recently reading about algorithms for checking bisimilarity and read that the problem is <a href="http://en.wikipedia.org/wiki/P-complete">P-complete</a>. Furthermore, a consequence of this is that this problem, or any P-complete problem, is unlikely to have an efficient parallel algorithms.</p>\n\n<blockquote>\n  <p>What is the intuition behind this last statement?</p>\n</blockquote>\n', 'Tags': '<complexity-theory><parallel-computing>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-04-22T15:36:02.203', 'CommentCount': '1', 'AcceptedAnswerId': '1431', 'CreationDate': '2012-04-21T19:55:08.833', 'Id': '1415'}{'Body': '<p>I know that the 2D and 3D Knapsack problems are NPC, but is there any way to solve them in reasonable time if the instances are not very complicated? Would dynamic programming work?</p>\n\n<p>By 2D (3D) Knapsack I mean I have a square (cube) and a I have list of objects, all data are in centimeters and are at most 20m.</p>\n', 'ViewCount': '1006', 'Title': 'Algorithms for two and three dimensional Knapsack', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-29T10:36:33.367', 'LastEditDate': '2012-04-24T05:50:51.137', 'AnswerCount': '2', 'CommentCount': '9', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1219', 'Tags': '<algorithms><complexity-theory><np-complete><computational-geometry><knapsack-problems>', 'CreationDate': '2012-04-24T03:35:25.657', 'FavoriteCount': '1', 'Id': '1478'}{'Body': '<p>Consider a system of linear equations $Ax=0$, where $A$ is a $n\\times n$ matrix with rational entries. Assume that the rank of $A$ is $&lt;n$. What is the complexiy to check\nwhether it has a solution $x$ such that all entries of $x$ are stricly greater than 0 (namely, $x$ is a positive vector)? Of course, one can use Gauss elimination, but this seems not to be optimal.</p>\n', 'ViewCount': '573', 'Title': 'Complexity of checking whether linear equations have a positive solution', 'LastEditorUserId': '39', 'LastActivityDate': '2012-04-28T10:35:29.087', 'LastEditDate': '2012-04-26T00:21:41.243', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1236', 'Tags': '<algorithms><complexity-theory><linear-algebra>', 'CreationDate': '2012-04-25T12:24:02.827', 'FavoriteCount': '1', 'Id': '1500'}{'Body': '<p>My goal is to solve the following problem, which I have described by its input and output:</p>\n\n<p><strong>Input:</strong></p>\n\n<p>A directed acyclic graph $G$ with $m$ nodes, $n$ sources, and $1$ sink ($m > n \\geq 1$).</p>\n\n<p><strong>Output:</strong></p>\n\n<p>The <a href="https://en.wikipedia.org/wiki/Vc_dimension">VC-dimension</a> (or an approximation of it) for the neural network with topology $G$.</p>\n\n<p><strong>More specifics</strong>: </p>\n\n<ul>\n<li>Each node in $G$ is a sigmoid neuron. The topology is fixed, but the weights on the edges can be varied by the learning algorithm.</li>\n<li>The learning algorithm is fixed (say backward-propagation).</li>\n<li>The $n$ source nodes are the input neurons and can only take strings from $\\{-1,1\\}^n$ as input.</li>\n<li>The sink node is the output unit. It outputs a real value from $[-1,1]$ that we round up to $1$ or down to $-1$ if it is more than a certain fixed threshold $\\delta$ away from $0$. </li>\n</ul>\n\n<p>The naive approach is simply to try to break more and more points, by attempting to train the network on them. However, this sort of simulation approach is not efficient.</p>\n\n<hr>\n\n<h3>Question</h3>\n\n<p>Is there an efficient way (i.e. in $\\mathsf{P}$ when changed to the decision-problem: is VC-dimension less than input parameter $k$?) to compute this function? If not, are there hardness results?</p>\n\n<p>Is there a works-well-in-practice way to compute or approximate this function? If it is an approximation, are there any guarantees on its accuracy?</p>\n\n<h3>Notes</h3>\n\n<p>I asked a <a href="http://stats.stackexchange.com/q/25952/4872">similar question</a> on stats.SE but it generated no interest.</p>\n', 'ViewCount': '204', 'Title': 'Efficiently computing or approximating the VC-dimension of a neural network', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-10T02:12:14.187', 'LastEditDate': '2012-04-25T16:58:07.127', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<algorithms><complexity-theory><machine-learning><neural-networks><vc-dimension>', 'CreationDate': '2012-04-25T15:21:46.690', 'FavoriteCount': '1', 'Id': '1504'}{'Body': u'<p>We know that $st\\text{-}non\\text{-}connectivity$ is in <a href="http://en.wikipedia.org/wiki/NL_%28complexity%29" rel="nofollow">$\\mathsf{NL}$</a> by <a href="https://en.wikipedia.org/wiki/Immerman%E2%80%93Szelepcs%C3%A9nyi_theorem" rel="nofollow">Immerman\u2013Szelepcs\xe9nyi theorem</a> theorem and since $st\\text{-}connectivity$ is $\\mathsf{NL\\text{-}hard}$ therefore $st\\text{-}non\\text{-}connectivity$ is many-one log-space reducible to $st\\text{-}connectivity$. But is there a direct/combinatorial reduction that doesn\'t go through the configuration graph of the Turing machines in $\\mathsf{NL}$?</p>\n\n<blockquote>\n  <p><a href="http://en.wikipedia.org/wiki/St-connectivity" rel="nofollow">$\\mathsf{stConnectivity}$</a> (a.k.a. $stPATH$):</p>\n  \n  <p>Given directed graph $G$ and vertices $s$ and $t$,</p>\n  \n  <p>Is there a directed path from vertex $s$ to vertex $t$? </p>\n</blockquote>\n\n<hr>\n\n<h3>Clarifications:</h3>\n\n<p>You can assume a graph is given by its adjacency matrix (however this is not essential since standard representations of graphs are log-space convertible to each other.)</p>\n\n<p>It is possible to unpack the proof of $\\mathsf{NL\\text{-}hard}$ness of $st\\text{-}connectivity$ and move it into the proof so the proof does not use it that theorem as a lemma. However this is still the same construction essentially. What I am looking for is <em>not</em> this, I want a conceptually direct reduction. Let me give an analogy with the $\\mathsf{NP}$ case. We can reduce various $\\mathsf{NP\\text{-}complete}$ problems to each other by using the fact that they are in $\\mathsf{NP}$ therefore reduce to $SAT$ and $SAT$ reduces to the other problem. And we can unpack and combine these two reductions to get a direct reduction. However it is often possible to give a conceptually much simpler reduction that doesn\'t go through this intermediate step (you can remove mentioning it, but it is still there conceptually). For example, to reduce $HamPath$ or $VertexCover$ or $3\\text{-}Coloring$ to $SAT$ we don\'t say $HamPath$ is in $\\mathsf{NP}$ and therefore reduces to $SA$ since $SAT$ is $\\mathsf{NP\\text{-}hard}$. We can give a simple intuitive formula that is satisfiable iff the graph has a Hamiltonian path. \nAnother example, we have reductions from other problems in $\\mathsf{NL}$ to $st\\text{-}Connectivity$ which do not rely on $\\mathsf{NL\\text{-}complete}$ness of $st\\text{-}Connectivity$, e.g. $Cycle$, $StronglyConnected$, etc, they involve modification on the input graph (and do not refer to any Turing machines that is solving them). </p>\n\n<p>I still don\'t see any reason why this cannot be done for this one.\nI am looking for a reduction of this kind.</p>\n\n<p>It might be the case that this is not possible and any reduction would conceptually go through the $\\mathsf{NL\\text{-}hard}$ness result. However I don\'t see why that should be the case, why the situation would be different from the $\\mathsf{NP}$ case.\nObviously to give a negative answer to my question we would need to be more formal about when does a proof <em>conceptually</em> include another proof (which is proof theory question that AFAIK not settle in a satisfactory way). However note that for a positive answer one does not need such a formal definition and I am hoping that is the case. (I will think about how to formalize what I am asking in a faithful way when I find more free time. Essentially I want a reduction that would work even if we didn\'t know that the problem is complete for $\\mathsf{NL}$.)</p>\n\n<p>Using the proof of Immerman\u2013Szelepcs\xe9nyi theorem is fine, using $\\mathsf{NL\\text{-}complete}$ness of $stPATH$ and configuration graph of an $\\mathsf{NL}$ machine is what I want to avoid.</p>\n', 'ViewCount': '257', 'Title': 'Direct reduction from $st\\text{-}non\\text{-}connectivity$ to $st\\text{-}connectivity$', 'LastEditorUserId': '41', 'LastActivityDate': '2012-10-11T06:25:20.147', 'LastEditDate': '2012-10-09T18:13:36.133', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<complexity-theory><reductions><space-complexity>', 'CreationDate': '2012-04-25T20:28:48.090', 'FavoriteCount': '1', 'Id': '1509'}{'Body': '<p>I\'m studying for my final in theory of computation, and I\'m struggling with the proper way of answering whether this statement is true of false.</p>\n\n<p>By the <a href="https://en.wikipedia.org/wiki/Mapping_reducibility" rel="nofollow">definition</a> of $\\leq_m$ we can construct the following statement, </p>\n\n<p>$w \\in A \\iff f(w) \\in B \\rightarrow w \\notin A \\iff f(w) \\notin B$ </p>\n\n<p>This is where I\'m stuck, I want to say that since we have such computable function $f$ then it\'ll only give us the mapping from A to B if there is one, otherwise it wont. </p>\n\n<p>I don\'t know how to phrase this correctly, or if I\'m even on the right track.</p>\n', 'ViewCount': '776', 'Title': 'If A is mapping reducible to B then the complement of A is mapping reducible to the complement of B', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-23T07:12:26.980', 'LastEditDate': '2012-05-23T07:12:26.980', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1520', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '196', 'Tags': '<complexity-theory><computability><reductions>', 'CreationDate': '2012-04-26T20:00:07.483', 'Id': '1517'}{'Body': '<p>My book states this</p>\n\n<blockquote>\n  <ul>\n  <li>If a decision problem B is in P and\n  A reduces to B,\n  then decision problem A is in P.</li>\n  <li>A decision problem B is NP-complete if\n  B is in NP and\n  for every problem in A in NP, A reduces to B.</li>\n  <li>A decision problem C is NP-complete if\n  C is in NP and\n  for some NP-complete problem B, B reduces to C.</li>\n  </ul>\n</blockquote>\n\n<p>So my questions are</p>\n\n<blockquote>\n  <ol>\n  <li>If B or C is in NP-complete, and all problems in NP reduce to an NP-complete problem, using the first rule, how can any NP problem not be NP complete?</li>\n  <li>If A reduces to B, does B reduce to A?</li>\n  </ol>\n</blockquote>\n', 'ViewCount': '628', 'Title': 'All NP problems reduce to NP-complete problems: so how can NP problems not be NP-complete?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-03T16:24:01.647', 'LastEditDate': '2012-04-27T18:38:48.000', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '6', 'OwnerDisplayName': 'rubixibuc', 'PostTypeId': '1', 'OwnerUserId': '4772', 'Tags': '<complexity-theory><np-complete><decision-problem>', 'CreationDate': '2012-02-29T21:07:18.197', 'Id': '1526'}{'Body': "<p>I'm trying to solve a problem for class that is stated like so:</p>\n\n<blockquote>\n  <p>A bipartite graph is an undirected graph in which every cycle has even\n  length.  We attempt to show that the Hamiltonian cycle (a cycle that\n  passes through each node exactly once) problem polynomially reduces to\n  the Hamiltonian cycle problem in bipartite graphs. We need a function\n  $T:  \\{\\text{graphs}\\} \\to \\{\\text{bipartite graphs}\\}$ such that $T$ can be computed in\n  polynomial time and for any graph $G$, $G$ has Hamiltonian cycle iff $T(G)$\n  has a Hamiltonian cycle. Let $T(G)$ be the bipartite graph obtained by\n  inserting a new vertex on every edge. What is wrong with this\n  transformation?</p>\n</blockquote>\n\n<p>I think the problem with the transformation is that for $T(G)$ you need to insert an edge between each pair of vertices and not just insert a new vertex on every edge. I'm actually a bit stumped by this one. Any advice would be much appreciated! </p>\n", 'ViewCount': '355', 'Title': 'Finding the flaw in a reduction from Hamiltonian cycle to Hamiltonian cycle on bipartitie graphs', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-27T22:10:39.560', 'LastEditDate': '2012-04-27T22:10:39.560', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '2', 'OwnerDisplayName': 'thomascirca', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-04-24T00:09:38.290', 'Id': '1527'}{'ViewCount': '554', 'Title': 'Is Logical Min-Cut NP-Complete?', 'LastEditDate': '2012-04-28T09:50:58.277', 'AnswerCount': '1', 'Score': '17', 'OwnerDisplayName': 'amirv', 'PostTypeId': '1', 'OwnerUserId': '1280', 'FavoriteCount': '5', 'Body': "<h3>Logical Min Cut (LMC) problem definition</h3>\n\n<p>Suppose that $G = (V, E)$ is an unweighted digraph, $s$ and $t$ are two vertices of $V$, and $t$ is reachable from $s$. The LMC Problem studies how we can make $t$ unreachable from $s$ by the removal of some edges of $G$ following the following constraints:</p>\n\n<ol>\n<li>The number of the removed edges must be minimal.</li>\n<li>We cannot remove every exit edge of any vertex of $G$.</li>\n</ol>\n\n<p>This second constraint is called logical removal. So we look for a <em>logical, minimal removal</em> of some edges of $G$ such that $t$ would be unreachable from $s$.</p>\n\n<h3>Solutions attempts</h3>\n\n<p>If we ignore the logical removal constraint of LMC problem, it will be the min-cut problem in the unweighted digraph $G$, so it will be solvable polynomially (max-flow min-cut theorem). Furthermore, if we ignore the minimal removal constraint of the LMC problem, it will be again solvable polynomially because it is sufficient to find the vertex $k$ such that $k$ is reachable from $s$ and $t$ is not reachable from $k$. Then consider a path $p$ which is an arbitrary path from $s$ to $k$. Now consider the path $p$ as a subgraph of $G$: the answer will be every exit edge of the subgraph $p$. It is obvious that the vertex $k$ can be found by some DFS in $G$ in polynomial time. Hence, by considering just one of the constraints of LMC problem, it will be solvable polynomially.</p>\n\n<p>I tried to solve the LMC problem by a dynamic programming technique but the number of required states for solving the problem became exponential. Moreover, I tried to reduce some NP-Complete problems such as 3-SAT, max2Sat, max-cut, and clique to the LMC problem I didn't manage to find a reduction.</p>\n\n<p>I personally think that the LMC problem is NP-Complete even if $G$ is a binary DAG.</p>\n\n<h3>Questions</h3>\n\n<ol>\n<li>Is the LMC problem NP-Complete in an arbitrary digraph $G$? (main question)</li>\n<li>Is the LMC problem NP-Complete in an arbitrary DAG $G$?</li>\n<li>Is the LMC problem NP-Complete in an arbitrary binary DAG $G$?</li>\n</ol>\n", 'Tags': '<complexity-theory><graph-theory><np-complete>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-16T14:07:05.917', 'CommentCount': '23', 'CreationDate': '2012-04-26T07:52:24.317', 'Id': '1531'}{'ViewCount': '299', 'Title': 'Approximation algorithm for TSP variant, fixed start and end anywhere but starting point + multiple visits at each vertex ALLOWED', 'LastEditDate': '2012-04-28T09:30:21.653', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1282', 'FavoriteCount': '1', 'Body': '<p>NOTE: Due to the fact that the trip does not end at the same place it started and also the fact that every point can be visited more than once as long as I still visit all of them, this is not really a TSP variant, but I put it due to lack of a better definition of the problem.</p>\n\n<p>This problem was originally posted on StackOverflow, but I was told that this would be a better place. I got one pointer, which converted the problem from non-metric to a metric one.</p>\n\n<p>So..</p>\n\n<p>Suppose I am going on a hiking trip with n points of interest. These points are all connected by hiking trails. I have a map showing all trails with their distances, giving me a directed graph.</p>\n\n<p>My problem is how to approximate a tour that starts at a point A and visits all n points of interest, while ending the tour anywhere but the point where I started and I want the tour to be as short as possible.</p>\n\n<p>Due to the nature of hiking, I figured this would sadly not be a symmetric problem (or can I convert my asymmetric graph to a symmetric one?), since going from high to low altitude is obviously easier than the other way around.</p>\n\n<p>Since there are no restrictions regarding how many times I visit each point, as long as I visit all of them, it does not matter if the shortest path from a to d goes through b and c. Is this enough to say that triangle inequality holds and thus I have a metric problem?</p>\n\n<p>I believe my problem is easier than TSP, so those algorithms do not fit this problem. I thought about using a minimum spanning tree, but I have a hard time applying it to this problem, which under the circumstances, should be a metric asymmetric directed graph?</p>\n\n<p>What I really want are some pointers as to how I can come up with an approximation algorithm that will find a near optimal tour through all n points</p>\n', 'Tags': '<algorithms><complexity-theory><graphs><graph-theory><approximation>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-28T21:59:47.610', 'CommentCount': '5', 'AcceptedAnswerId': '1551', 'CreationDate': '2012-04-28T07:45:11.773', 'Id': '1542'}{'Body': "<p>Consider the following version of the Clique problem where the input is of size $n$ and we're asked to find a clique of size $k$. The restriction is that the decision procedure cannot change the input graph into any other representation and cannot use any other representation to compute its answer, other than $\\log(n^k)$ extra bits beyond the input graph. The extra bits can be used for example in the brute-force algorithm to keep track of the status of the exhaustive search for a clique, but the decision procedure is welcome to use them in any other way that still decides the problem.</p>\n\n<p>Is anything known at this point about the complexity of this? Has any work been done on other restrictions of Clique, and if so, could you direct me to such work?</p>\n", 'ViewCount': '210', 'Title': 'Restricted version of the Clique problem?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-05-02T14:51:57.830', 'LastEditDate': '2012-05-01T13:50:43.373', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1612', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '1295', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-05-01T03:08:47.587', 'Id': '1606'}{'Body': '<p>[<em>previously appearing in cstheory, it was closed there and introduced here instead</em>]</p>\n\n<p>Given an edge-weighted graph $G=(V,E)$ the problem of finding the shortest path is known to be in P ---and indeed a simple approach would be Dijkstra\'s algorithm which can solve this problem in $O(V^2)$. A similar problem is to find the maximum path in $G$ from a source node to a target node and this can be solved with Integer Programming so that, as far as I know, this is not known to be in P.</p>\n\n<p>Now, the problem of finding a path in $G$ such that it deviates the minimum from a given target value (typically larger than the optimal distance but less than the maximum distance that separates the source and target nodes) has been conjectured to be in EXPTIME (see section "Conventions" of <a href="http://search-conference.org/index.php/Main/SOCS09program" rel="nofollow">A depth-first approach to target-value search</a> in the proceedings of SoCS 2009). In particular, this paper addresses this particular problem for  directed acyclic graphs (DAGs). A previous work is <a href="http://www.uwosh.edu/faculty_staff/furcyd/search_symposium_2008/schedule.html" rel="nofollow">Heuristic Search for Target-Value Path Problem</a>. There is event a US Patent of this algorithm <a href="http://www.google.es/patents?hl=es&amp;lr=&amp;vid=USPATAPP12497353&amp;id=gojwAAAAEBAJ&amp;oi=fnd&amp;dq=%22depth-first+search+for+target+value+problems%22&amp;printsec=abstract#v=onepage&amp;q=%22depth-first%20search%20for%20target%20value%20problems%22&amp;f=false" rel="nofollow">US 2011/0004625</a>.</p>\n\n<p>I\'ve been searching for related problems in other fields of Computer Science and Mathematics and strikingly, I have found none though this problem is clearly relevant in practice ---there are tons of opportunities to look for a specific target value instead of the minimum or the maximum path.</p>\n\n<p>Do you know related problems to this or additional bibliographical references to this problem? Any information on this problem including studies of their complexity would be very welcome</p>\n\n<p><strong>Note</strong>: as already pointed out by Jeffe in cstheory, proving this problem to be in EXPTIME is trivial and the authors probably meant EXPTIME-complete.</p>\n', 'ViewCount': '121', 'Title': 'Target-Value Search (& II)', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-08T20:16:41.033', 'LastEditDate': '2012-05-09T15:50:10.143', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1337', 'Tags': '<algorithms><complexity-theory><reference-request><search-algorithms>', 'CreationDate': '2012-05-02T12:21:24.380', 'Id': '1634'}{'Body': '<p>Say I have a weighted undirected complete graph $G = (V, E)$. Each edge $e = (u, v, w)$ is assigned with a positive weight $w$. I want to calculate the minimum-weighted $(d, h)$-tree-decomposition. By $(d, h)$-tree-decomposition, I mean to divide the vertices $V$ into $k$ trees, such that the height of each tree is $h$, and each non-leaf node has $d$ children. </p>\n\n<p>I know it is definitely $\\text{NP}$-Hard, since minimum $(1, |V|-1)$-tree-decomposition is the minimum Hamilton path. But are there any good approximation algorithms?</p>\n', 'ViewCount': '214', 'Title': 'Approximate minimum-weighted tree decomposition on complete graphs', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-10T11:59:46.367', 'LastEditDate': '2012-05-10T11:59:46.367', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '11', 'OwnerDisplayName': 'Geni', 'PostTypeId': '1', 'OwnerUserId': '1354', 'Tags': '<algorithms><complexity-theory><graphs><graph-theory><approximation>', 'CreationDate': '2012-05-02T21:38:35.253', 'Id': '1640'}{'ViewCount': '1389', 'Title': 'How can we assume that basic operations on numbers take constant time?', 'LastEditDate': '2013-09-10T22:18:05.507', 'AnswerCount': '6', 'Score': '31', 'OwnerDisplayName': 'user742', 'PostTypeId': '1', 'FavoriteCount': '15', 'Body': "<p>Normally in algorithms we do not care about comparison, addition, or subtraction of numbers -- we assume they run in time $O(1)$.  For example, we assume this when we say that comparison-based sorting is $O(n\\log n)$, but when numbers are too big to fit into registers, we normally represent them as arrays so basic operations require extra calculations per element.</p>\n\n<p>Is there a proof showing that comparison of two numbers (or other primitive arithmetic functions) can be done in $O(1)$? If not why are we saying that comparison based sorting is $O(n\\log n)$?</p>\n\n<hr>\n\n<p><em>I encountered this problem when I answered a SO question and I realized that my algorithm is not $O(n)$ because sooner or later I should deal with big-int, also it wasn't pseudo polynomial time algorithm, it was $P$.</em></p>\n", 'Tags': '<algorithms><complexity-theory><algorithm-analysis><time-complexity><reference-question>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-10T22:18:05.507', 'CommentCount': '2', 'AcceptedAnswerId': '1661', 'CreationDate': '2012-05-03T00:06:31.453', 'Id': '1643'}{'Body': '<p>I have had problems accepting the complexity theoretic view of "efficiently solved by parallel algorithm" which is given by the class <a href="https://en.wikipedia.org/wiki/NC_%28complexity%29">NC</a>:</p>\n\n<blockquote>\n  <p>NC is the class of problems that can be solved by a parallel algorithm in time $O(\\log^cn)$ on $p(n) \\in O(n^k)$ processors with $c,k \\in \\mathbb{N}$.</p>\n</blockquote>\n\n<p>We can assume a <a href="https://en.wikipedia.org/wiki/Parallel_random_access_machine">PRAM</a>.</p>\n\n<p>My problem is that this does not seem to say much about "real" machines, that is machines with a finite amount of processors. Now I am told that "it is known" that we can "efficiently" simulate a $O(n^k)$ processor algorithm on $p \\in \\mathbb{N}$ processors.</p>\n\n<p>What does "efficiently" mean here? Is this folklore or is there a rigorous theorem which quantifies the overhead caused by simulation?</p>\n\n<p>What I am afraid that happens is that I have a problem which has a sequential $O(n^k)$ algorithm and also an "efficient" parallel algorithm which, when simulated on $p$ processors, also takes $O(n^k)$ time (which is all that can be expected on this granularity level of analysis if the sequential algorithm is asymptotically optimal). In this case, there is no speedup whatsover as far as we can see; in fact, the simulated parallel algorithm may be <em>slower</em> than the sequential algorithm. That is I am really looking for statements more precise than $O$-bounds (or a declaration of absence of such results).</p>\n', 'ViewCount': '260', 'Title': 'How to scale down parallel complexity results to constantly many cores?', 'LastActivityDate': '2012-05-03T22:04:13.333', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '1648', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><reference-request><parallel-computing>', 'CreationDate': '2012-05-03T08:08:30.570', 'Id': '1647'}{'ViewCount': '116', 'Title': 'Connection between castability and convexity', 'LastEditDate': '2012-05-10T13:53:55.323', 'AnswerCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1379', 'FavoriteCount': '1', 'Body': "<p>I am wondering if there are any connection between convex polygon and castable object? What can we say about castability of the object if we know that the object is convex polygon and vice versa.</p>\n\n<p>Let's gather together few basic things that we have to know.</p>\n\n<blockquote>\n  <p>The object is castable if it can removed from the mold.</p>\n  \n  <p>The polyhedron P can be removed from its mold by a translation in direction $\\vec{d}$  if and only if $\\vec{d}$ makes an angle of at  least $90^{\\circ}$ with the outward normal of all ordinary facets of P.</p>\n</blockquote>\n\n<p>For a arbitrary object testing for castability has time complexity $O(n^2)$. In my opinion, for a convex polygon if could be improved to linear time, because for every new top facet we should test that the vector $\\vec{d}$ makes an angle at least $90^{\\circ}$ with outward normal not of all but only of two adjacent ordinary facets of P. </p>\n\n<p>If this is true at least we have improvement in testing for castability in case of convex polygon.</p>\n\n<p>We else can we state about castability and convexity. Especially interesting to know, if castability tells us something about convexity.</p>\n", 'Tags': '<complexity-theory><time-complexity><computational-geometry>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-10T18:39:41.280', 'CommentCount': '5', 'AcceptedAnswerId': '1677', 'CreationDate': '2012-05-05T14:52:23.943', 'Id': '1671'}{'ViewCount': '1965', 'Title': 'how do you prove that SAT is NP-complete?', 'LastEditDate': '2012-05-10T15:12:40.890', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1412', 'FavoriteCount': '2', 'Body': '<p>As it is, how do you prove that SAT is NP-complete?</p>\n\n<p>I know what it means by NP-complete, so I do not need an explanation on that.</p>\n\n<p>What I want to know is how do you know that one problem, such as SAT, is NP-complete without resorting to reduction to other problems such as hamiltonian problem or whatever.</p>\n', 'Tags': '<complexity-theory><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-10T15:12:40.890', 'CommentCount': '5', 'AcceptedAnswerId': '1728', 'CreationDate': '2012-05-08T06:58:32.797', 'Id': '1726'}{'ViewCount': '132', 'Title': 'Explain $\\log_2(n)$ squared asymptotic run-time for naive nested parallel CREW PRAM mergesort', 'LastEditDate': '2012-05-09T15:58:31.630', 'AnswerCount': '1', 'Score': '3', 'OwnerDisplayName': 'Paul Caheny', 'PostTypeId': '1', 'OwnerUserId': '1427', 'Body': '<p>On from Page 1 of <a href="http://www.inf.ed.ac.uk/teaching/courses/dapa/note3.pdf" rel="nofollow">these lecture notes</a> it is stated in the final paragraph of the section titled CREW Mergesort:</p>\n\n<blockquote>\n  <p>Each such step (in a sequence of $\\Theta(\\log_2\\ n)$ steps) takes\n  time $\\Theta(\\log_2\\ s)$ with a sequence length of $s$. Summing these, we\n  obtain an overall run time of $\\Theta((\\log_2\\  n)^2)$ for $n$\n  processors, which is not quite (but almost!) cost-optimal.</p>\n</blockquote>\n\n<p>Can anyone show explicitly how the sum mentioned is calculated and the squared log result arrived at?</p>\n', 'Tags': '<algorithms><complexity-theory><parallel-computing>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-09T15:59:10.290', 'CommentCount': '0', 'AcceptedAnswerId': '1755', 'CreationDate': '2012-05-09T13:35:17.113', 'Id': '1754'}{'ViewCount': '148', 'Title': 'From FACTOR To KNAPSACK', 'LastEditDate': '2012-05-14T15:16:37.660', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '956', 'FavoriteCount': '1', 'Body': '<ol>\n<li><p>If there were an algorithm that factored in polynomial time by means of examining each possible factor of a complex number efficiently, could one not also use this algorithm to solve unbounded knapsack problems since two factors can be viewed as one value, say within the set for the knapsack problem, and the other being the number of copies of the first factor?</p>\n\n<p>FACTOR 15; 3, 5</p>\n\n<p>Unbounded KNAPSACK with value of 15 and the set of all integers; {5,5,5} andor {3,3,3,3,3}</p></li>\n<li><p>Would this mean FACTOR was NP-Complete?</p></li>\n<li><p>Would solving unbounded knapsack problems in polynomial time in this way prove P=NP?</p></li>\n</ol>\n', 'Tags': '<complexity-theory><np-complete><integers><knapsack-problems>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-14T15:31:43.257', 'CommentCount': '0', 'AcceptedAnswerId': '1808', 'CreationDate': '2012-05-12T09:26:26.863', 'Id': '1801'}{'ViewCount': '2317', 'Title': 'Are there NP problems, not in P and not NP Complete?', 'LastEditDate': '2012-05-12T23:47:17.100', 'AnswerCount': '4', 'Score': '14', 'OwnerDisplayName': 'vpiTriumph', 'PostTypeId': '1', 'OwnerUserId': '1472', 'FavoriteCount': '9', 'Body': "<p>Are there any known problems in $\\mathsf{NP}$ (and not in $\\mathsf{P}$) that aren't $\\mathsf{NP}$ Complete?  My understanding is that there are no currently known problems where this is the case, but it hasn't been ruled out as a possibility.  </p>\n\n<p>If there is a problem that is $\\mathsf{NP}$ (and not $\\mathsf{P}$) but not $\\mathsf{NP\\text{-}complete}$, would this be a result of no existing  isomorphism between instances of that problem and the $\\mathsf{NP\\text{-}complete}$ set?  If this case, how would we know that the $\\mathsf{NP}$ problem isn't 'harder' than what we currently identify as the $\\mathsf{NP\\text{-}complete}$ set?</p>\n", 'Tags': '<complexity-theory><np-complete><p-vs-np>', 'LastEditorUserId': '55', 'LastActivityDate': '2012-05-12T23:47:17.100', 'CommentCount': '5', 'AcceptedAnswerId': '1813', 'CreationDate': '2012-05-12T19:54:22.680', 'Id': '1810'}{'Body': "<p>What does the complexity class $\\oplus P^{\\oplus P}$ mean? I know that $\\oplus P$ is the complexity class which contains languages $A$ for which there is a polynomial time nondeterministic Turing machine $M$ such that $x \\in A$ iff the number of accepting states of the machine $M$ on the input $x$ is odd.</p>\n\n<p>But what does $\\oplus P^{\\oplus P}$ mean? I just can't follow what it actually does :)</p>\n\n<p>What are practical consequences of such complexity class and how it is possible to show that $\\oplus P^{\\oplus P} = \\oplus P$?</p>\n", 'ViewCount': '245', 'Title': 'What is complexity class $\\oplus P^{\\oplus P}$', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-15T08:01:04.303', 'LastEditDate': '2012-05-14T23:38:46.803', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1487', 'Tags': '<complexity-theory><terminology><complexity-classes>', 'CreationDate': '2012-05-14T16:02:11.397', 'Id': '1836'}{'ViewCount': '982', 'Title': 'How to prove that a constrained version of 3SAT in which no literal can occur more than once, is solvable in polynomial time?', 'LastEditDate': '2012-05-15T16:10:48.783', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '476', 'FavoriteCount': '4', 'Body': '<p>I\'m trying to work out an assignment (taken from the book <a href="http://www.cs.berkeley.edu/~vazirani/algorithms.html">Algorithms - by S. Dasgupta, C.H. Papadimitriou, and U.V. Vazirani</a>, Chap 8, problem 8.6a), and I\'m paraphrasing what it states:</p>\n\n<blockquote>\n  <p>Given that 3SAT remains NP-complete even when restricted to formulas in which\n  each literal appears at most twice, show that if each literal appears at most once, then the problem is solvable in polynomial time.</p>\n</blockquote>\n\n<p>I attempted to solve this by separating the clauses into multiple groups: </p>\n\n<ol>\n<li>Clauses which did not have any variable in common with the rest of the clauses</li>\n<li>Clauses which had only 1 variable in common</li>\n<li>Clauses which had 2 variables in common</li>\n<li>Clauses which had all 3 variables in common</li>\n</ol>\n\n<p>My reasoning was attempted along the lines that the # of such groups is finite (due to the imposed restriction of no literal being present more than once), and we could try to satisfy the most restricted group first (group 4) and then substitute the result in the lesser restricted groups (3, 2 and then 1), but I realized that this wasn\'t quite getting me anywhere, as this doesn\'t differ much from the case for the constrained version of 3SAT in which each literal can appear at most twice, which has been proven to be NP-complete. </p>\n\n<p>I tried searching online for any hints/solutions, but all I could get was <a href="http://www.cs.rpi.edu/~moorthy/Courses/CSCI2300/lab2011-9.html">this link</a>, in which the stated hint didn\'t make sufficient sense to me, which I\'m reproducing verbatim here:</p>\n\n<blockquote>\n  <p>Hint: Since each literal appears at most once, convert this problem to 2SAT problem - hence polynomial time, if a literal $x_i$ appears in clause $C_j$ and complement of $x_i$ (i.e., $\\overline{x_i}$) in clause $C_k$, construct a new clause clause $C_j \\lor \\overline{C_k}$.</p>\n</blockquote>\n\n<p>Both $C_j$ and $C_k$ have three literals each - I didn\'t get how I should go about converting it into 2SAT by doing $C_j \\lor \\overline{C_k}$ (or $\\overline{C_j \\lor C_k}$ if I read it incorrectly).</p>\n\n<p>Any help in either decrypting the hint, or providing a path I can explore would be really appreciated.</p>\n', 'Tags': '<complexity-theory><satisfiability><3-sat>', 'LastEditorUserId': '476', 'LastActivityDate': '2013-07-15T03:36:16.567', 'CommentCount': '0', 'AcceptedAnswerId': '1858', 'CreationDate': '2012-05-15T15:26:22.270', 'Id': '1852'}{'Body': '<p>I think I heard in somewhere that it has been proven that $\\mathsf{NP}$ is strictly contained in $\\mathsf{EXP}$, that is $\\mathsf{NP} \\subsetneq \\mathsf{EXP}$. Is this right? Wikipedia and book resources do not seem to bring me an answer..</p>\n\n<p>I just found a post similar to this, but I am not sure whether $\\mathsf{NP}$ is <em>strictly</em> contained in $\\mathsf{EXP}$.</p>\n', 'ViewCount': '634', 'Title': 'NP $\\subsetneq$ EXP?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-23T08:44:26.817', 'LastEditDate': '2013-05-24T08:03:36.003', 'AnswerCount': '1', 'CommentCount': '10', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1412', 'Tags': '<complexity-theory><complexity-classes><np>', 'CreationDate': '2012-05-15T15:36:25.137', 'FavoriteCount': '1', 'Id': '1853'}{'ViewCount': '783', 'Title': 'Rule of thumb to know if a problem could be NP-complete', 'LastEditDate': '2012-05-16T01:26:33.580', 'AnswerCount': '2', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '851', 'FavoriteCount': '3', 'Body': '<p>This question was inspired by <a href="http://stackoverflow.com/questions/10589995/algorithm-have-a-set-of-points-g-that-can-see-other-points-c-need-an-al/10590173#comment13716914_10590173">a comment on StackOverflow</a>.</p>\n\n<p>Apart from knowing NP-complete problems of the Garey Johnson book, and many others; is there a rule of thumb to know if a problem looks like an NP-complete one?</p>\n\n<p>I am not looking for something rigorous, but to something that works in most cases.</p>\n\n<p>Of course, every time we have to prove that  a problem is NP-complete, or a slight variant of an NP-complete one; but before rushing to the proof it would be great to have certain confidence in the positive result of the proof.</p>\n', 'Tags': '<complexity-theory><np-complete><intuition>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-17T17:15:47.970', 'CommentCount': '4', 'AcceptedAnswerId': '1863', 'CreationDate': '2012-05-15T18:27:59.127', 'Id': '1859'}{'Body': '<p>Since Integer Linear Programming is NP-complete, there is a Karp reduction from any problem in NP to it. I thought this implied that there is always a polynomial-sized ILP formulation for any problem in NP.</p>\n\n<p>But I\'ve seen papers on specific NP problems where people write things like "this is the first poly-sized formulation" or "there is no known poly-sized formulation". That\'s why I\'m puzzled.</p>\n', 'ViewCount': '246', 'Title': 'Does every NP problem have a poly-sized ILP formulation?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-11-18T22:33:09.293', 'LastEditDate': '2012-05-18T16:13:07.690', 'AnswerCount': '1', 'CommentCount': '12', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '1504', 'Tags': '<complexity-theory><np-complete><reductions><linear-programming>', 'CreationDate': '2012-05-15T19:21:47.390', 'FavoriteCount': '1', 'Id': '1860'}{'Body': '<p>There are lots of attempts at proving either $\\mathsf{P} = \\mathsf{NP} $ or $\\mathsf{P} \\neq \\mathsf{NP}$, and naturally many people think about the question, having ideas for proving either direction.</p>\n\n<p>I know that there are approaches that have been proven to not work, and there are probably more that have a history of failing. There also seem to be so-called <em>barriers</em> that many proof attemps fail to overcome. </p>\n\n<p>We want to avoid investigating into dead-ends, so what are they?</p>\n', 'ViewCount': '6113', 'Title': 'How not to solve P=NP?', 'LastEditorUserId': '6716', 'LastActivityDate': '2014-03-26T03:42:53.937', 'LastEditDate': '2013-06-06T14:08:25.930', 'AnswerCount': '5', 'CommentCount': '5', 'Score': '41', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><reference-request><history><p-vs-np><reference-question>', 'CreationDate': '2012-05-17T01:24:29.327', 'FavoriteCount': '24', 'Id': '1877'}{'ViewCount': '1059', 'Title': "Why isn't this undecidable problem in NP?", 'LastEditDate': '2013-10-05T23:00:15.917', 'AnswerCount': '3', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '1528', 'FavoriteCount': '2', 'Body': '<p>Clearly there aren\'t any undecidable problems in NP.  However, according to <a href="http://en.wikipedia.org/wiki/NP_%28complexity%29" rel="nofollow">Wikipedia</a>:</p>\n\n<blockquote>\n  <p>NP is the set of all decision problems for which the instances where the answer is "yes" have [.. proofs that are] verifiable in polynomial time by a deterministic Turing machine.</p>\n  \n  <p>[...]</p>\n  \n  <p>A problem is said to be in NP if and only if there exists a verifier for the problem that executes in polynomial time.</p>\n</blockquote>\n\n<p>Now consider the following problem:</p>\n\n<blockquote>\n  <p>Given a <a href="http://en.wikipedia.org/wiki/Diophantine_equation" rel="nofollow">Diophantine equation</a>, does it have any integer solutions?</p>\n</blockquote>\n\n<p>Given a solution, it\'s easy to verify in polynomial time that it really <em>is</em> a solution:  just plug the numbers into the equation.  Thus, the problem is in NP.  However, <em>solving</em> this problem is famously <a href="http://en.wikipedia.org/wiki/Hilbert%27s_tenth_problem" rel="nofollow">known to be undecidable</a>!</p>\n\n<p><em>(Similarly, it seems the halting problem should be in NP, since the "yes"-solution of "this program halts at the N-th step" can be verified in N steps.)</em></p>\n\n<p>Obviously there\'s something wrong with my understanding, but what is it?</p>\n', 'Tags': '<complexity-theory><computability><undecidability><decision-problem>', 'LastEditorUserId': '1528', 'LastActivityDate': '2013-10-05T23:00:15.917', 'CommentCount': '4', 'AcceptedAnswerId': '1902', 'CreationDate': '2012-05-17T16:50:51.853', 'Id': '1887'}{'ViewCount': '543', 'Title': 'An oracle to separate NP from coNP', 'LastEditDate': '2012-05-18T16:07:06.327', 'AnswerCount': '2', 'Score': '9', 'OwnerDisplayName': 'Stefan.M', 'PostTypeId': '1', 'OwnerUserId': '1487', 'FavoriteCount': '1', 'Body': '<p>How to prove that $\\mathsf{NP}^A \\neq \\mathsf{coNP}^A$ ? I am just looking for a such oracle TM $M$ and a recursive language $L(M) = L$ for which this holds. </p>\n\n<p>I know the proof where you show that there is an oracle $A$ such that $\\mathsf{P}^A \\neq \\mathsf{NP}^A$ and an oracle $A$ such that $\\mathsf{P}^A = \\mathsf{NP}^A$. I have a hint that I should find such oracle $A$ by extending the proof of $\\mathsf{P}^A \\neq \\mathsf{NP}^A$ but wherever I search and read, it is "obvious" or "straightforward" everywhere but I just do not see how prove it at all.</p>\n', 'Tags': '<complexity-theory><relativization>', 'LastEditorUserId': '41', 'LastActivityDate': '2013-06-05T18:50:54.327', 'CommentCount': '1', 'AcceptedAnswerId': '1911', 'CreationDate': '2012-05-13T22:04:12.257', 'Id': '1905'}{'Body': '<p>As follows <a href="http://cs.stackexchange.com/questions/1828/polytime-and-polyspace-algorithm-for-determining-the-leading-intersection-of-n-d">from my previous question</a>, I\'ve been playing with the <a href="http://en.wikipedia.org/wiki/Riemann_hypothesis">Riemann hypothesis</a> as a matter of recreational mathematics. In the process, I\'ve come to a rather interesting recurrence, and I\'m curious as to its name, its reductions, and its tractability towards the solvability of the gap between prime numbers.</p>\n\n<p>Tersely speaking, we can define the <em>gap</em> between each prime number as a recurrence of preceding <em>candidate</em> primes. For example, for our base of $p_0 = 2$, the next prime would be:</p>\n\n<p>$\\qquad \\displaystyle p_1 = \\min \\{ x &gt; p_0 \\mid -\\cos(2\\pi(x+1)/p_0) + 1 = 0)  \\}$</p>\n\n<p>Or, as we see by <a href="http://m.wolframalpha.com/input/?i=-cos%28%28x%2b1%29%2a2%2api/2%29%20%2b%201%20=%200">plotting this out</a>: $p_1 = 3$.</p>\n\n<p>We can repeat the process for $n$ primes by evaluating each candidate prime recurring forward. Suppose we want to get the next prime, $p_2$. Our candidate function becomes:</p>\n\n<p>$\\qquad \\displaystyle \\begin{align}\np_2 = \\min\\{ x &gt; p_1 \\mid f_{p_1}(x) + (&amp;(-\\cos(2\\pi(x+1)/p_1) + 1) \\\\\n                                   \\cdot &amp;(-\\cos(2\\pi(x+2)/p_1) + 1)) = 0\\}\n\\end{align}$</p>\n\n<p>Where:</p>\n\n<p>$\\qquad \\displaystyle f_{p_1}(x) = -\\cos(2\\pi(x+1)/p_0) + 1$, as above.</p>\n\n<p>It\'s easy to see that each component function only becomes zero on integer values, and it\'s equally easy to show how this captures our AND- and XOR-shaped relationships cleverly, by exploiting the properties of addition and multiplication in the context of a system of trigonometric equations.</p>\n\n<p>The recurrence becomes:</p>\n\n<p>$\\qquad f_{p_0} = 0\\\\\n\\qquad p_0 = 2\\\\\n\\qquad \\displaystyle\n  f_{p_n}(x) = f_{p_{n-1}}(x) + \\prod_{k=2}^{p_{n-1}} (-\\cos(2\\pi(x+k-1)/p_{n-1}) + 1)\\\\\n \\qquad \\displaystyle\n p_n = \\min\\left\\{ x &gt; p_{n-1} \\mid f_{p_n}(x) = 0\\right\\}$</p>\n\n<p>... where the entire problem hinges on whether we can evaluate the $\\min$ operator over this function in polynomial time. This is, in effect, a generalization of the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Eratosthenes</a>.</p>\n\n<p>Working Python code to demonstrate the recurrence:</p>\n\n<pre><code>from math import cos,pi\n\ndef cosProduct(x,p):\n    """ Handles the cosine product in a handy single function """\n    ret = 1.0\n    for k in xrange(2,p+1):\n        ret *= -cos(2*pi*(x+k-1)/p)+1.0\n    return ret\n\ndef nthPrime(n):\n    """ Generates the nth prime, where n is a zero-based integer """\n\n    # Preconditions: n must be an integer greater than -1\n    if not isinstance(n,int) or n &lt; 0:\n        raise ValueError("n must be an integer greater than -1")\n\n    # Base case: the 0th prime is 2, 0th function vacuous\n    if n == 0:\n        return 2,lambda x: 0\n\n    # Get the preceding evaluation\n    p_nMinusOne,fn_nMinusOne = nthPrime(n-1)\n\n    # Define the function for the Nth prime\n    fn_n = lambda x: fn_nMinusOne(x) + cosProduct(x,p_nMinusOne)\n\n    # Evaluate it (I need a solver here if it\'s tractable!)\n    for k in xrange(p_nMinusOne+1,int(p_nMinusOne**2.718281828)):\n        if fn_n(k) == 0:\n            p_n = k\n            break\n\n    # Return the Nth prime and its function\n    return p_n,fn_n\n</code></pre>\n\n<p>A quick example:</p>\n\n<pre><code>&gt;&gt;&gt; [nthPrime(i)[0] for i in range(20)]\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\n</code></pre>\n\n<p>The trouble is, I\'m now in way over my head, both mathematically and as a computer scientist. Specifically, I am not competent with <a href="http://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a>, with defining <a href="http://en.wikipedia.org/wiki/Uniform_space#Uniform_cover_definition">uniform covers</a>, or with the <a href="http://en.wikipedia.org/wiki/Complex_plane">complex plane</a> in general, and I\'m worried that this approach is either flat-out <em>wrong</em> or hides a lurking horror of a 3SAT problem that elevates it to NP-completeness.</p>\n\n<p>Thus, I have three questions here:</p>\n\n<blockquote>\n  <ol>\n  <li>Given my terse recurrence above, is it possible to deterministically compute or estimate the location of the zeroes in polynomial time and space?</li>\n  <li>If so or if not, is it hiding <em>any other</em> subproblems that would make a polytime or polyspace solution intractable?</li>\n  <li>And if by some miracle (1) and (2) hold up, what dynamic programming improvements would you make in satisfying this recurrence, from a high level? Clearly, iteration over the same integers through multiple functions is inelegant and quite wasteful.</li>\n  </ol>\n</blockquote>\n', 'ViewCount': '333', 'Title': 'Proving the (in)tractability of this Nth prime recurrence', 'LastEditorUserId': '958', 'LastActivityDate': '2012-05-24T08:38:32.067', 'LastEditDate': '2012-05-24T08:38:32.067', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '958', 'Tags': '<complexity-theory><reference-request><recurrence-relation><mathematical-analysis>', 'CreationDate': '2012-05-22T00:50:48.443', 'FavoriteCount': '3', 'Id': '1984'}{'ViewCount': '168', 'Title': 'DLOGTIME complexity class and testing the length of the input string', 'LastEditDate': '2012-05-23T09:49:14.147', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1412', 'FavoriteCount': '0', 'Body': '<p>I read that testing the length of the input string is in DLOGTIME.</p>\n\n<p>The question is how can testing the length of the input string be in DLOGTIME?</p>\n\n<p>$\\text{DLOGTIME} = O(\\log n)$, so what number would be in $n$? (as it seems that $n$ is definitely not the length of the input string..... or is it?)</p>\n\n<p>So, to summarize, can anyone show me how the algorithm performs and how it is in DLOGTIME? At this point, it seems to me that $n$ is just an arbitary number..</p>\n\n<p>Note: I know what binary search is :) so you do not need to explain me about what that is.</p>\n', 'Tags': '<complexity-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-23T16:49:43.233', 'CommentCount': '0', 'AcceptedAnswerId': '2013', 'CreationDate': '2012-05-23T03:55:40.013', 'Id': '2011'}{'Body': '<p>In the usual definition of probabilistic poly-time machine it is said that the machine halts in polynomial time for all inputs. </p>\n\n<p>Is the intention really to say that the machine halts for all inputs, or that if it halts it must be in polynomial time?</p>\n', 'ViewCount': '124', 'Title': 'Probabilistic poly-time machine always halts on all inputs?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-25T20:13:41.407', 'LastEditDate': '2012-05-25T11:15:04.400', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'OwnerDisplayName': 'user583311', 'PostTypeId': '1', 'Tags': '<complexity-theory><terminology><turing-machines><probabilistic-algorithms>', 'CreationDate': '2012-05-24T14:21:16.507', 'Id': '2047'}{'Body': "<p>We know that the $polyL$-hierarchy doesn't have complete problems, as it would conflict with the space hierarchy theorem. But: Are there complete problems for each level of this hierarchy?</p>\n\n<p>To be precise: Does the class $DSPACE(\\log(n)^k)$ have complete problems under $L$-reductions for each $k &gt; 0$?</p>\n", 'ViewCount': '162', 'Title': 'Complete Problems for $DSPACE(\\log(n)^k)$', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-27T12:41:04.607', 'LastEditDate': '2012-05-26T12:54:24.433', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '2106', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '641', 'Tags': '<complexity-theory><reductions><space-complexity>', 'CreationDate': '2012-05-26T09:28:27.063', 'Id': '2088'}{'ViewCount': '165', 'Title': 'Depth-2 circuits with OR and MOD gates are not universal?', 'LastEditDate': '2012-05-28T00:53:31.890', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '1661', 'FavoriteCount': '1', 'Body': '<p>It is well-known that every boolean function $f:\\{0,1\\}^n\\to \\{0,1\\}$ can be realized using a boolean circuit of depth 2 (over the variables, their negation and constant values) containing AND gates in the first level and one single OR gate in the upper level; this is simply the <a href="http://en.wikipedia.org/wiki/Disjunctive_normal_form" rel="nofollow">DNF representation</a> of $f$.</p>\n\n<p>Another type of gate which is of great interest in circuit complexity is the $MOD_m$ gate. The usual definition is the following:</p>\n\n<p>$$\\mathrm{MOD}_m(x_1,\\dots,x_k)=\\cases{\n  1 &amp; if \\(\\sum x_i \\equiv 0 \\mod m\\) \\\\\n  0 &amp; if \\(\\sum x_i \\not\\equiv 0 \\mod m\\) \\\\\n}$$</p>\n\n<p>These gates sometimes have surprising power; for example, any boolean function can be represented by a depth-2 circuit having only $\\mathrm{MOD}_6$ gates (this is folklore but I can elaborate is someone is interested).</p>\n\n<p>However, another folklore is that circuits with a single OR gate at the top and $\\mathrm{MOD}_m$ gates in the bottom layer (with $m$ being fixed once and for all, and in particular being the same for all the gates) is not universal, i.e. for any value of $m$, there are boolean functions that cannot be computed by $\\mathrm{OR} \\circ \\mathrm{MOD}_m$ circuit.</p>\n\n<p>I\'m looking for a proof for this claim, or at least some direction.</p>\n', 'Tags': '<complexity-theory><logic><circuits>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-05-28T00:53:31.890', 'CommentCount': '8', 'AcceptedAnswerId': '2109', 'CreationDate': '2012-05-27T10:29:22.540', 'Id': '2103'}{'Body': '<p>I have the following question from <a href="http://www.cs.princeton.edu/theory/complexity/" rel="nofollow">Computational Complexity - A modern Approach</a> by Sanjeev Arora and Boaz Barak:</p>\n\n<blockquote>\n  <p><em>[Q 4.1]</em><br>\n  Prove the existence of a universal TM for space bounded computation (analogously to the deterministic universal TM of Theorem 1.9). </p>\n</blockquote>\n\n<p>That is, prove that there exists a Turing Machine $SU$ such that for every string $\\alpha$ and input $x$, if the TM $M_\\alpha$ -- the TM represented by $\\alpha$ -- halts on $x$ before using $t$ cells of its work tape, then $SU(\\alpha, t, x) = M_\\alpha(x)$ and moreover, $SU$ uses at most $C\\cdot t$ cells of its work tape, where $C$ is a constant depending only on $M_\\alpha$.</p>\n\n<p>After checking theorem 1.9 and the universal TM with time bound, I see that the construct $SU(\\alpha, t, x)$ means that the Turing machine SU stops after $t$ steps. However if this is the case, then it means that we can create a Turing Machine equivalent to $M_\\alpha$ such that the new Turing Machine stops in $t$ steps where $t$ is the "space" used in the original.</p>\n\n<p>However, this seems a dubious interchange of space and time. If on the other hand, $t$ actually meant that the second machine stops within $t$ space, too, then the second part does not make sense any more because it says $SU$ uses $Ct$ cells, which is not $t$.</p>\n\n<p>So my question is how do I interpret this? Is the first interpretation really possible?</p>\n', 'ViewCount': '324', 'Title': 'Space bounded Turing Machine - clarification on Computational Complexity (book: Arora-Barak ) question 4.1', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-27T18:37:19.410', 'LastEditDate': '2012-05-27T18:23:04.883', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '2113', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1209', 'Tags': '<complexity-theory><terminology><turing-machines><space-complexity>', 'CreationDate': '2012-05-27T17:36:53.217', 'Id': '2110'}{'Body': '<p>I need to prove that $\\mathsf{NP}$ is a subset of the union of $\\mathsf{DTIME}(2^{n^c})$ for all $c &gt; 1$.</p>\n\n<p>Let $L$ be a language/decision problem in $\\mathsf{NP}$. Then $L$ can be decided given a polynomial-size certificate in polynomial time with a turing machine $M$. So then we enumerate all possible certificates of polynomial size. There are $2^l$ possible certificates for a certificate of length $l$. For a certificate of length up to $n^c$, there are $\\sum_{l=0}^{n^c} 2^l = 2^{n^c + 1} - 1$ many certificates. Each certificate can be decided in polynomial time, so we get that each problem in $\\mathsf{NP}$ can be done in $\\mathsf{DTIME}(2^{n^c}n^c)$. What am I doing wrong?</p>\n', 'ViewCount': '164', 'Title': 'Proving NP is a subset of the union of exponential DTIME', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-29T15:20:18.607', 'LastEditDate': '2012-05-29T07:52:22.427', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1682', 'Tags': '<complexity-theory><check-my-proof>', 'CreationDate': '2012-05-29T06:08:59.757', 'FavoriteCount': '1', 'Id': '2151'}{'ViewCount': '630', 'Title': 'NP-Completeness of a Graph Coloring Problem', 'LastEditDate': '2012-06-26T21:18:06.560', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1672', 'FavoriteCount': '3', 'Body': '<p><strong>Alternative Formulation</strong></p>\n\n<p>I came up with an alternative formulation to the below problem. The alternative formulation is actually a special case of the problem bellow and uses bipartite graphs to describe the problem. However, I believe that the alternative formulation is still NP-hard. The alternative formulation uses a disjoint set of incoming and outgoing nodes that simplifies the problem definition.</p>\n\n<p>Given $n$ outgoing and $n$ incoming nodes (the red and blue nodes in the figure respectively), and a set $w_{ij}$\'s of size $n \\times n$ of edge weights between the outgoing and incoming vertices. The goal of the problem is to color the thick edges in the figure so that for every incoming node, a condition holds.</p>\n\n<p><img src="http://i.stack.imgur.com/CsXJr.png" alt="Bipartite graph of the problem"></p>\n\n<blockquote>\n  <p>Given a set $\\{ O_i \\; | \\; i=1 \\dots n \\}$ of output vertices, a set $\\{ I_i\\; | \\; i=1 \\dots n \\}$ of input vertices, $n \\times n$ weights\n  $w_{ij} \\ge 0$ between $O_i$\'s and $I_j$\'s for $i,j=1 \\dots n$, and a positive\n  constant $\\beta$, find the minimum number of colors for the edges\n  $e_{ii}$ (thick edges in the above figure) such that for all $j=1 \\dots n$,</p>\n  \n  <p>$$ \\frac{w_{jj}}{1+\\sum_{c(i)=c(j),i \\neq j} w_{ij}} \\ge \\beta $$</p>\n  \n  <p>where $c(i)$ shows the color of the edge $e_{ii}$.</p>\n</blockquote>\n\n<hr>\n\n<p><strong>Old Formulation</strong></p>\n\n<p>The following problem looks NP-hard to me, but I couldn\'t show it. Any proof/comment to show the hardness or easiness of it is appreciated.</p>\n\n<blockquote>\n  <p>Assume $K_n=\\langle V,E \\rangle$ is a complete weighted directed graph\n  with $n$ nodes and $n(n-1)$ edges. Let $w_{ij} \\ge 0$ show the weight\n  of the edge $ij$ and $c(ij)$ shows the color of edge $ij$. Given a subset\n  of the edges $T \\subseteq E$ and a positive constant $\\beta$ the goal is:\n  find the minimum number of colors such that for each $e_{ij} \\in T$:</p>\n  \n  <p>$$ \\frac{w_{ij}}{1+\\sum_{c(kl)=c(ij),kl \\neq ij} w_{kj}} \\ge \\beta. $$\n  and\n  $$ c(ij) \\neq c(ik) \\quad for \\quad j \\neq k $$</p>\n</blockquote>\n\n<p>Please note that in the above problem, only the edges in $T$ needs to be colored. That is the problem can be solved in $\\mathcal{O}(|T|!)$.</p>\n\n<p><strong>Update:</strong></p>\n\n<p>After Tsuyoshi Ito\'s comment I updated the problem. The denominator is changed from $1+\\sum_{c(kj)=c(ij),k \\neq i,e_{kj} \\in T} w_{kj}$ to $1+\\sum_{c(kl)=c(ij),kl \\neq ij} w_{kj}$. Therefore, the denominator contains the weights outside $T$ as well. That\'s actually why I mentioned the complete graph in the definition.</p>\n\n<p>I also added an additional constraint $c(ij) \\neq c(ik) \\quad for \\quad j \\neq k$. That means, the outgoing edges from a node must be of different colors (but the incoming colors can be the same as long as the inequality holds). This puts an intuitive lower bound on the number of colors, which is the maximum out-degree of the nodes in $T$.</p>\n\n<p>As Tsuyoshi mentioned, $w_{ij}$\'s, $T$, and $\\beta$ are inputs to the problem and the edge colors are the output.</p>\n\n<p><strong>Update 2:</strong></p>\n\n<p>Problem does not enforce the edges $e_{ij}$ and $e_{ji}$ be of a same color.</p>\n', 'Tags': '<complexity-theory><graphs><graph-theory><np-complete>', 'LastEditorUserId': '1672', 'LastActivityDate': '2012-07-10T23:58:44.517', 'CommentCount': '11', 'AcceptedAnswerId': '2687', 'CreationDate': '2012-05-29T08:27:39.603', 'Id': '2157'}{'ViewCount': '1918', 'Title': 'Reducing minimum vertex cover in a bipartite graph to maximum flow', 'LastEditDate': '2012-11-09T11:07:26.610', 'AnswerCount': '2', 'Score': '7', 'OwnerDisplayName': 'Summer_More_More_Tea', 'PostTypeId': '1', 'OwnerUserId': '1727', 'FavoriteCount': '1', 'Body': '<p>Is it possible to show that the minimum vertex cover in a bipartite graph can be reduced to a maximum flow problem? Or to the minimum cut problem (then follow max-flow min-cut theorem, the claim holds).</p>\n\n<p>Intuitively: for each flow, pick one endpoint, then it is a minimum vertex cover in bipartite graph. But can it be shown rigorously?</p>\n', 'Tags': '<complexity-theory><graph-theory><reductions><network-flow>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-09T11:07:26.610', 'CommentCount': '0', 'CreationDate': '2012-06-03T02:37:49.540', 'Id': '2208'}{'Body': '<p>Is there any decision problem that is in a complexity class properly included in DLOGTIME? (except $O(1)$, of course)</p>\n\n<p>If there is, can we create complete problems for DLOGTIME? So, can there be reduction by $O(\\log(\\log n))$ or smaller?</p>\n', 'ViewCount': '66', 'Title': 'Complexity class that properly included in DLOGTIME', 'LastEditorUserId': '1636', 'LastActivityDate': '2013-06-28T11:02:54.960', 'LastEditDate': '2013-06-28T11:02:54.960', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1412', 'Tags': '<complexity-theory><time-complexity><complexity-classes>', 'CreationDate': '2012-06-04T08:35:54.763', 'FavoriteCount': '1', 'Id': '2221'}{'ViewCount': '286', 'Title': 'Are there complete problems for P and NP under other kinds of reductions?', 'LastEditDate': '2012-06-07T18:07:21.893', 'AnswerCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1412', 'FavoriteCount': '1', 'Body': '<p>I know that the complexity class $\\mathsf{P}$ has complete problems w.r.t. $\\mathsf{NC}$ and $\\mathsf{L}$ reductions.</p>\n\n<p>Are these two classes the only possible classes of reductions under which $\\mathsf{P}$ has complete problems?  </p>\n\n<p>Also, what classes of reduction can be used for $\\mathsf{NP}$ beside polynomial-time reductions?</p>\n', 'Tags': '<complexity-theory><reductions>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-07T21:29:11.087', 'CommentCount': '5', 'AcceptedAnswerId': '2236', 'CreationDate': '2012-06-04T08:41:03.090', 'Id': '2222'}{'Body': '<p>EDIT: ad hoc speed-ups are excluded.</p>\n\n<p>We have the result that <a href="http://homepages.cwi.nl/~rdewolf/resolutionlowerbound.pdf" rel="nofollow">propositional resolution requires exponential time</a>. The resolution result uses the proof of the pigeonhole principle as an example of a proof that takes exponential time. </p>\n\n<p>Let\'s also say we have a hypothetical algorithm M for SAT that runs in polynomial time. \n<strong>EDIT : M is correct, complete, sound, and general-purpose; it contains no ad hoc speed-up rules for the pigeonhole principle or any other theorem that requires exponential length in resolution.</strong> M takes its input in clausal form; we\'ll set up the input like a resolution proof where the consequent is negated to lead to unsatisfiability if the theorem is true. Now let\'s consider how the proof of the pigeonhole principle works in algorithm M with a strong condition C added:</p>\n\n<p>C. We are given that M simply transforms one clause (or set of clauses) to another clause (or set of clauses). Every such transformation is logically sound.</p>\n\n<p>Some questions; please point out the most fatal flaws:</p>\n\n<ol>\n<li>Given condition C above, and since M\'s rule system must be finite, correct, and complete, can we conclude that there is a translation from M\'s rule system to an equivalent set of expansions based on resolution?</li>\n<li>Are we now in a place where we can conclude that M would produce a computation that could be mapped by the translation in point 1 above into an impossible polynomial-time resolution proof of the pigeonhole principle?</li>\n</ol>\n', 'ViewCount': '178', 'Title': 'Resolution complexity versus a constrained SAT algorithm', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-05T20:21:32.660', 'LastEditDate': '2012-06-05T20:21:32.660', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1295', 'Tags': '<complexity-theory><logic><satisfiability><sat-solvers>', 'CreationDate': '2012-06-05T04:12:51.750', 'FavoriteCount': '1', 'Id': '2230'}{'ViewCount': '204', 'Title': 'Can joins be parallelized?', 'LastEditDate': '2012-06-07T14:49:58.440', 'AnswerCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1590', 'FavoriteCount': '1', 'Body': '<p>Suppose we want to join two relations on a predicate. Is this in NC?</p>\n\n<p>I realize that a proof of it not being in NC would amount to a proof that $P\\not=NC$, so I\'d accept evidence of it being an open problem as an answer.</p>\n\n<p>I\'m interested in the general case as well as specific cases (e.g. perhaps with some specific data structure it can be parallelized). </p>\n\n<p>EDIT: to bring some clarifications from the comments into this post:</p>\n\n<ul>\n<li>We could consider an equijoin $A.x = B.y$. On a single processor, a hash-based algorithm runs in $O(|A|+|B|)$ and this is the best we can do since we have to read each set</li>\n<li>If the predicate is a "black box" where we have to check each pair, there are $|A|\\cdot|B|$ pairs, and each one could be in or not, so $2^{ab}$ possibilities. Checking each pair divides the possibilities in half, so the best we can do is $O(ab)$.</li>\n</ul>\n\n<p>Could either of these (or some third type of join) be improved to $\\log^k n$ on multiple processors?</p>\n', 'Tags': '<complexity-theory><time-complexity><parallel-computing><database-theory><descriptive-complexity>', 'LastEditorUserId': '1590', 'LastActivityDate': '2012-07-07T01:35:55.073', 'CommentCount': '9', 'AcceptedAnswerId': '2410', 'CreationDate': '2012-06-05T17:38:32.240', 'Id': '2235'}{'ViewCount': '219', 'Title': 'Does High Order Functions provide more power to Functional Programming?', 'LastEditDate': '2012-06-06T12:46:42.487', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1763', 'FavoriteCount': '1', 'Body': '<p><em>I\'ve asked a similar question <a href="http://cstheory.stackexchange.com/questions/11652/does-high-order-functions-provide-more-power-to-functional-programming">on cstheory.SE</a>.</em></p>\n\n<p>According to <a href="http://stackoverflow.com/a/1990580/209629">this answer on Stackoverflow</a> there is an algorithm that on a non-lazy pure functional programming language has an $\\Omega(n \\log n)$ complexity, while the same algorithm in imperative programming is $\\Omega(n)$. Adding lazyness to the FP language would make the algorithm $\\Omega(n)$.</p>\n\n<p>Is there any equivalent relationship comparing a FP language with and without High Order Functions? Is it still Turing Complete? If it is, does the lack of High Order on FP makes the language less "powerful" or efficient? </p>\n', 'Tags': '<complexity-theory><lambda-calculus><functional-programming><turing-completeness>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-06T12:56:27.090', 'CommentCount': '2', 'AcceptedAnswerId': '2241', 'CreationDate': '2012-06-06T01:10:04.083', 'Id': '2240'}{'Body': '<p>I have a problem in my mind, I think it is a NPC problem but I don\'t know how to prove it.</p>\n\n<p>Here is the problem:</p>\n\n<p>There are <strong>k</strong> islands in a very big lake, and there are <strong>n</strong>  fan-shaped pontoons. Those pontoons are in the same size but have different initial directions and are in different original positions in the lake. The pontoons can rotate freely around its center of mass, and no cost associated with rotation.</p>\n\n<p>Now we need to move those pontoons so that all islands in the lake can be connected. We can guarantee the number of pontoons is enough to connect all the islands.</p>\n\n<p><strong>[Note]: We cannot reuse the pontoons!!</strong></p>\n\n<p>The task is to find the solution having the minimum total distance of the moving pontoons in order to make all islands connected. The distance of moving one pontoon can be calculated as the distance between the center of mass\'s original position and its deployed position.</p>\n\n<p>To make it clear, I have drawn such a figure. Suppose we have 3 islands A, B and C. They are located somewhere in the lake. And I have several fan-shaped pantoons. Now the solution is to find a minimum moving distance summation to connect A, B and C, shown in bottom part of the figure. Hope it help understand the problem. :)</p>\n\n<p><img src="http://i.stack.imgur.com/G6Hop.jpg" alt="enter image description here"></p>\n\n<p>It seems that the problem is a NPC one, but I don\'t know to prove it. Can anyone help me on this? </p>\n', 'ViewCount': '274', 'Title': 'Is connecting islands with pontoons NP-complete?', 'LastEditorUserId': '568', 'LastActivityDate': '2012-06-08T12:27:46.433', 'LastEditDate': '2012-06-08T12:27:46.433', 'AnswerCount': '3', 'CommentCount': '8', 'Score': '9', 'OwnerDisplayName': 'little-eyes', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><np-hard>', 'CreationDate': '2012-06-06T18:27:50.300', 'FavoriteCount': '1', 'Id': '2244'}{'Body': '<p>I am interested in the complexity of the restricted version of the vertex cover problem below:</p>\n\n<blockquote>\n  <p><strong>Instance:</strong> A bipartite graph $G =(L, R, E)$ and an integer $K$.</p>\n  \n  <p><strong>Question:</strong> Is there $S \\subset L$, $|S| \\leq K$ and every vertex in $R$ has a neighbor in $S$ $( S$ is vertex cover for $R)$</p>\n</blockquote>\n\n<p>Vertex cover is $\\mathsf{P}$ if $S \\subset L \\cup R$ and cover $L \\cup R$; and it is $\\mathsf{NP}$-complete for nonbipartite graphs. However, the problem I am looking at does not fit in either cases. Any pointers where I could find an answer will be appreciated.</p>\n', 'ViewCount': '215', 'Title': 'Restricted version of vertex cover', 'LastActivityDate': '2012-06-15T08:56:53.127', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'OwnerDisplayName': 'hbm', 'PostTypeId': '1', 'Tags': '<complexity-theory><algorithms><graph-theory>', 'CreationDate': '2012-06-09T12:55:36.820', 'FavoriteCount': '1', 'Id': '2302'}{'Body': "<p>I am aware that for a problem to be considered NP-Hard, any problem in NP must be reduceable to your problem (problem which you are trying to prove is NP-Hard).</p>\n\n<p>Let's assume that you have proven that a problem <code>Y</code> is NP-Hard, and you have a problem <code>X</code> which you know is in NP, and you would like to solve.</p>\n\n<p>To solve <code>X</code>, which of the following reductions would be carried out?</p>\n\n<ol>\n<li>X -> Y</li>\n<li>Y -> X</li>\n</ol>\n\n<p>Which of the following? i.e. would you reduce <code>X</code> to <code>Y</code> or vice-versa, if you would like to solve <code>X</code> which is in NP, and <code>Y</code> which is NP-Hard?</p>\n", 'ViewCount': '222', 'Title': 'Solve a problem through reduction', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-10T12:45:26.697', 'LastEditDate': '2012-06-10T11:29:36.043', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '1814', 'Tags': '<algorithms><complexity-theory><reductions><np-hard>', 'CreationDate': '2012-06-10T08:06:59.850', 'Id': '2312'}{'Body': "<p>I'm looking for some standard terminology, metrics and/or applications of the consideration of density and sequentiality of algorithms.</p>\n\n<p>When we measure algorithms we tend to give the big-Oh notation such as $O(n)$ and usually we are measuring time complexity. Somewhat less frequently, though still often, we'll also measure the space complexity of an algorithm.</p>\n\n<p>Given current computing systems however the density of memory and the sequence in which it is accessed plays a major role in the practical performance of the algorithm. Indeed there are scenarios where a time complexity algortihm of $O(\\log n)$ with disperse random memory access can be slower than a $O(n)$ algorithm with dense sequential memory access. I've not seen these aspects covered in formal theory before; surely it must exist and I'm just ignorant here.</p>\n\n<p>What are the standard metrics, terms, and approaches to this space density and access sequentiality?</p>\n", 'ViewCount': '82', 'Title': 'Complexity of space density and sequentiality', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-10T11:44:37.957', 'LastEditDate': '2012-06-10T11:33:14.040', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '2318', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1642', 'Tags': '<complexity-theory><reference-request><terminology><space-complexity>', 'CreationDate': '2012-06-10T09:29:46.877', 'Id': '2317'}{'Body': '<p>Maybe I am missing something obvious, but can it be that P = co-NP $\\subsetneq$ NP or vice versa? My feeling is that there must be some theorem that rules out this possibility.</p>\n', 'ViewCount': '193', 'Title': 'Can exactly one of NP and co-NP be equal to P?', 'LastActivityDate': '2012-06-12T22:12:12.280', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '2343', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '208', 'Tags': '<complexity-theory><p-vs-np>', 'CreationDate': '2012-06-12T16:45:58.787', 'FavoriteCount': '1', 'Id': '2341'}{'Body': '<p>Equipartition Problem:</p>\n\n<p>Instance: $2n$ positive integers $x_1,\\dots,x_{2n}$ such that their sum is even. Let $B$ denote half their sum, so that $\\sum x_{i} = 2B$.</p>\n\n<p>Query: Is there a subset $I \\subseteq [2n]$ of size $|I| = n$ such that $\\sum_{i \\in I} x_{i} = B$?</p>\n\n<p>Can the <a href="http://en.wikipedia.org/wiki/Partition_problem" rel="nofollow">partition problem</a> - same as the above but without the restriction on $|I|$ -  be reduced to the above problem ?</p>\n', 'ViewCount': '375', 'Title': 'Reduction to equipartition problem from the partition problem?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-22T09:48:20.123', 'LastEditDate': '2012-06-12T18:36:52.223', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '5', 'OwnerDisplayName': 'Shalabh', 'PostTypeId': '1', 'OwnerUserId': '2882', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2012-03-23T16:58:13.290', 'Id': '2347'}{'Body': '<p>Are there any problems in $\\mathsf{P}$ that have randomized algorithms beating lower bounds on deterministic algorithms? More concretely, do we know any $k$ for which $\\mathsf{DTIME}(n^k) \\subsetneq \\mathsf{PTIME}(n^k)$? Here $\\mathsf{PTIME}(f(n))$ means the set of languages decidable by a randomized TM with constant-bounded (one or two-sided) error in $f(n)$ steps. </p>\n\n<blockquote>\n  <p>Does randomness buy us anything inside $\\mathsf{P}$?</p>\n</blockquote>\n\n<p>To be clear, I am looking for something where the difference is asymptotic (preferably polynomial, but I would settle for polylogarithmic), not just a constant.</p>\n\n<p><em>I am looking for algorithms asymptotically better in the worst case. Algorithms with better expected complexity are not what I am looking for. I mean randomized algorithms as in RP or BPP not ZPP.</em></p>\n', 'ViewCount': '332', 'Title': 'Problems in P with provably faster randomized algorithms', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-29T08:14:04.840', 'LastEditDate': '2013-07-29T08:08:49.313', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '208', 'Tags': '<algorithms><complexity-theory><randomized-algorithms>', 'CreationDate': '2012-06-13T13:44:19.383', 'FavoriteCount': '4', 'Id': '2362'}{'Body': '<p>As the title says, has anyone found a polynomial time algorithm for checking whether two graphs having a Hamiltonian cycle are isomorphic? Is this problem NP-complete?</p>\n', 'ViewCount': '306', 'Title': 'Has anyone found polynomial algorithm on Hamiltonian cycle isomorphism?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:06:12.337', 'LastEditDate': '2013-05-24T03:06:12.337', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1866', 'Tags': '<complexity-theory><graph-theory><time-complexity>', 'CreationDate': '2012-06-15T15:28:43.047', 'FavoriteCount': '0', 'Id': '2383'}{'Body': u'<p>If we have an algorithm that need to run $n=2$ operations and then halt, I think we could say the problem it solves, is tractable, but if $n=10^{120}$ althought It could be theoretically solvable it seems to be intractable, and what about a problem that needs $n=10^{1000}$, or $n=10^{10^{1000}}$ operations, that\'s seems an intractable problem for sure.</p>\n\n<p>Then we see there is a k, from which $n\\ge k$ operations problems are intractable, and $n\\lt k$ are tractable ones.</p>\n\n<p>I doubt about that k to exist.. Where is the limit? Can a Technological advance turn some intractable problems <strong>for a given n</strong> into a tractable ? </p>\n\n<p>I would like to read your opinion.</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>I think this question is similar as asking if Church\u2013Turing thesis is correct, because if the difference about solving a computable problem in a Turing Machine and in any other Turing Complete Machine, is "only a constant" about the number of operations, then I think that asking about computable is the same as asking about effective calculability.. Now I see tractable means polynomial time, and inctractable is related with no polynomial time solution. But the difference between two machines, for the same (even tractable) problem, is about Church-Turing thesis. </p>\n', 'ViewCount': '129', 'Title': 'Which is the minimal number of operations for intractability?', 'LastEditorUserId': '1396', 'LastActivityDate': '2012-09-27T02:29:12.420', 'LastEditDate': '2012-09-27T02:29:12.420', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '2386', 'Score': '-4', 'PostTypeId': '1', 'OwnerUserId': '1396', 'Tags': '<complexity-theory><church-turing-thesis>', 'CreationDate': '2012-06-15T23:38:43.623', 'Id': '2385'}{'Body': '<p>I am guessing that this is correct for <code>3-EXP</code>, <code>4-EXP</code> etc...</p>\n\n<p>Basically I should find a problem in <code>2-EXP</code> that is not in <code>EXP</code>.\nAny examples ?</p>\n', 'ViewCount': '112', 'Title': 'How to prove 2-EXP != EXP', 'LastActivityDate': '2012-06-20T09:49:03.193', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2423', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1907', 'Tags': '<complexity-theory>', 'CreationDate': '2012-06-20T09:06:43.007', 'Id': '2422'}{'Body': '<p>I am reading "Efficient Cryptographic Schemes Provably as Secure as Subset Sum" by R. Impagliazzo and M. Naor (<a href="http://www.stevens.edu/algebraic/Files/SubsetSum/impagliazzo96efficient.pdf" rel="nofollow">paper</a>) and came across the following statement in the proof of Theorem 3.1 (pages 10-11):</p>\n\n<blockquote>\n  <p>Let $\\  l(n) = (1-c)n \\ $ for $ \\ c &gt; 0  \\ $ ...</p>\n  \n  <p>Given $a_1, a_2, \\cdots, a_n \\in \\{0,1\\}^{l(n)}$ and a target sum $T$, we construct an input to the collision finding algorithm as follows:</p>\n  \n  <ol>\n  <li><p>Let the collision finding algorithm select a (non-empty) $ s_1 \\in \\{0,1\\}^n $</p></li>\n  <li><p>compute $T\' = \\sum_{i \\in s_1} a_i$.  Choose a random $j$ such that $j \\in s_1$ and define $a_j\' = a_j - T\' + T$.</p></li>\n  <li><p>Give the instance $a_1, a_2, \\cdots , a_j\', \\cdots, a_n$ and $s_1$ to the algorithm that finds collisions.  The algorithm attempts to find $s_2$ such that $f_{(a_1, a_2, \\cdots, a_j\', \\cdots, a_n)}(s_2) = T\'$.</p></li>\n  </ol>\n  \n  <p>If the algorithm returns $s_2$ that collides with $s_1$ and $j \\notin s_2$, then <strong>$s_2$ is a solution to our original problem</strong>, since swapping $a_j$ and $a_j\'$ does not affect the sum over $s_2$.</p>\n</blockquote>\n\n<p>Where the emphasis is mine.</p>\n\n<p>Where $f$ concatenates $\\stackrel{\\rightarrow}{a}$ with the sum of the $a_i$\'s:</p>\n\n<p>$$ f( \\stackrel{\\rightarrow}{ a } , S) = f_{(a_1, a_2, \\cdots, a_n)}(S) = \\ \\stackrel{\\rightarrow}{a}, \\sum_{i \\in S} a_i \\mod 2^{l(n)} $$</p>\n\n<p>(taken from the top of page 3 from the same paper).</p>\n\n<p>For the life of me, I don\'t understand how $s_2$ is a solution to the original instance.  Can someone elaborate on what they mean?  What am I missing?</p>\n\n<p>The above definition for the subset sum problem is, if I\'m not mistaken, just another form of the <a href="http://garden.irmacs.sfu.ca/?q=op/theoretical_computer_science/subset_sums_equality" rel="nofollow">pigeonhole subset sum problem</a> (i.e. $\\sum_j a_j &lt; 2^n -1$ ).  If I read the above right, they are claiming that, given an oracle that finds collisions, they can then construct a solution to the original (pigeonhole) subset sum problem but I do not see how this is done.  Any help would be appreciated.</p>\n', 'ViewCount': '138', 'Title': 'Does a collision oracle for the pigeonhole subset sum problem produce solutions?', 'LastEditorUserId': '67', 'LastActivityDate': '2013-12-04T13:14:36.753', 'LastEditDate': '2012-06-21T22:17:31.350', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '67', 'Tags': '<complexity-theory><computability><np-complete><reductions>', 'CreationDate': '2012-06-21T20:44:25.477', 'Id': '2442'}{'Body': '<p>Here is a well-known problem.</p>\n\n<p>Given an array $A[1\\dots n]$ of positive integers, output the smallest positive integer not in the array.</p>\n\n<p>The problem can be solved in $O(n)$ space and time: read the array, keep track in $O(n)$ space whether $1,2,\\dots,n+1$ occured, scan for smallest element.</p>\n\n<p>I noticed you can trade space for time. If you have $O(\\frac{n}{k})$ memory only, you can do it in $k$ rounds and get time $O(k n)$. In a special case, there is obviously constant-space quadratic-time algorithm.</p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Is this the optimal tradeoff, i.e. does $\\operatorname{time} \\cdot \\operatorname{space} = \\Omega(n^2)$?\n  In general, how does one prove such type of bounds?</p>\n</blockquote>\n\n<p>Assume RAM model, with bounded arithmetic and random access to arrays in O(1).</p>\n\n<p>Inspiration for this problem: time-space tradeoff for palindromes in one-tape model (see for example, <a href="http://www.cs.uiuc.edu/class/fa05/cs475/Lectures/new/lec24.pdf" rel="nofollow">here</a>).</p>\n', 'ViewCount': '291', 'Title': 'Time-space tradeoff for missing element problem', 'LastEditorUserId': '72', 'LastActivityDate': '2012-06-29T22:18:45.900', 'LastEditDate': '2012-06-29T22:18:45.900', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '667', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-06-23T15:32:31.797', 'FavoriteCount': '1', 'Id': '2464'}{'Body': '<p>This is an example in my lecture notes.\nIs this function with time complexity $O(n \\log n)$?.\nBecause the worst case is the funtion goes into <code>else</code> branch, and 2 nested loops with time complexity of $\\log n$ and $n$, so it is $O(n \\log n)$. Am I right?</p>\n\n<pre><code>int j = 3;\nint k = j * n / 345;\nif(k &gt; 100){\n    System.out.println("k: " + k);\n}else{\n    for(int i=1; i&lt;n; i*=2){\n        for(int j=0; j&lt;i; j++){\n            k++;\n        }\n    }\n}\n</code></pre>\n', 'ViewCount': '557', 'Title': 'What is the time complexity of this function?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-26T23:13:31.913', 'LastEditDate': '2012-06-25T17:21:54.770', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '2497', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1895', 'Tags': '<complexity-theory><time-complexity><algorithm-analysis><runtime-analysis>', 'CreationDate': '2012-06-25T14:48:54.900', 'Id': '2487'}{'Body': "<p>If $L_1$ is NP-hard, $L_1 \\times L_2$ is NP-hard for every $L_2 \\neq \\emptyset$, where</p>\n\n<p>$\\qquad \\displaystyle L_1 \\times L_2 = \\{(w_1,w_2) \\mid w_1 \\in L_1, w_2 \\in L_2\\}$</p>\n\n<p>Is it true or false and why?</p>\n\n<p>I can't prove it but I also don't find counter example.</p>\n", 'ViewCount': '110', 'Title': 'Is NP-hard closed against cartesian product with arbitrary languages?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-07-04T12:39:56.033', 'LastEditDate': '2012-07-04T12:39:56.033', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'OwnerDisplayName': 'user9868', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2012-06-25T07:30:34.923', 'Id': '2489'}{'Body': '<p>Suppose we have a directed graph $G=(V,E)$ and two nodes $A$ and $B$.\nI would like to know if there are already algorithms for calculating the following decision problem: </p>\n\n<blockquote>\n  <p>Are there at least two paths between $A$ and $B$ of the same length?</p>\n</blockquote>\n\n<p>How about the complexity? Can I solve it in polynomial time?</p>\n\n<hr>\n\n<p>I would like to add a new constrain on the graph, maybe the problem is more solvable.\nOn adjacency matrix, every column is not empty. So, every node has at least one arrow on input and there is also at least one node connected to itself. So if the node is the $i$-th node, then $(i,i)$ is an edge in the graph.</p>\n', 'ViewCount': '363', 'Title': 'Finding at least two paths of same length in a directed graph', 'LastEditorUserId': '1974', 'LastActivityDate': '2012-07-03T20:59:07.823', 'LastEditDate': '2012-06-27T16:49:56.487', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '1974', 'Tags': '<complexity-theory><graph-theory><time-complexity><graphs>', 'CreationDate': '2012-06-26T12:12:27.963', 'FavoriteCount': '6', 'Id': '2498'}{'Body': "<p>My setup is something like this: I have a sequence of sets of integers $C_i (1\\leq i\\leq n)$, with $|C_i|$ relatively small - on the order of four or five items for all $i$.  I want to choose a sequence $x_i (1\\leq i\\leq n)$ with each $x_i\\in C_i$ such that the total variation (either $\\ell_1$ or $\\ell_2$, i.e. $\\sum_{i=1}^{n-1} |x_i-x_{i+1}|$ or  $\\sum_{i=1}^{n-1} \\left(x_i-x_{i+1}\\right)^2$) is minimized.  While it seems like the choice for each $x_i$ is 'local', the problem is that choices can propagate and have non-local effects and so the problem seems inherently global in nature.</p>\n\n<p>My primary concern is in a practical algorithm for the problem; right now I'm using annealing methods based on mutating short subsequences, and while they should be all right it seems like I ought to be able to do better.  But I'm also interested in the abstract complexity &mdash; my hunch would be that the standard query version ('is there a solution of total variation $\\leq k$?') would be NP-complete via a reduction from some constraint problem like 3-SAT but I can't quite see the reduction.  Any pointers to previous study would be welcome &mdash; it seems like such a natural problem that I can't believe it hasn't been looked at before, but my searches so far haven't turned up anything quite like it.</p>\n", 'ViewCount': '133', 'Title': 'Minimizing the total variation of a sequence of discrete choices', 'LastEditorUserId': '242', 'LastActivityDate': '2012-06-29T20:59:15.583', 'LastEditDate': '2012-06-28T22:07:25.153', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '2542', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '242', 'Tags': '<algorithms><complexity-theory><optimization>', 'CreationDate': '2012-06-28T21:57:56.210', 'Id': '2539'}{'Body': '<p>I\'ve been studying the <a href="http://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" rel="nofollow">Spearman\'s rank correlation coefficient</a></p>\n\n<p>$\\qquad \\displaystyle \\rho = \\frac{\\sum_i(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_i (x_i-\\bar{x})^2 \\sum_i(y_i-\\bar{y})^2}}$.</p>\n\n<p>for two lists $x_1, \\dots, x_n$ and $y_1, \\dots, y_n$. What\'s the <em>complexity</em> of the algorithm?</p>\n\n<p>Since the algorithm should just compute $n$ subtractions, is it possible to be $O(n)$ ?</p>\n', 'ViewCount': '204', 'Title': "What's the complexity of Spearman's rank correlation coefficient computation?", 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-05T14:00:32.050', 'LastEditDate': '2012-07-04T10:24:10.760', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2064', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-07-04T07:45:52.857', 'Id': '2604'}{'Body': '<p>The lookup time in perfect hash-tables is $O(1)$ in the worst case. Does that simply mean that the average should be $\\leq O(1)$?</p>\n', 'ViewCount': '163', 'Title': 'What is the average search complexity of perfect hashing?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-07-17T06:12:56.213', 'LastEditDate': '2012-07-17T06:12:56.213', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '2067', 'Tags': '<complexity-theory><time-complexity><asymptotics><hash-tables>', 'CreationDate': '2012-07-04T14:36:16.523', 'Id': '2610'}{'Body': '<p>In "Computers and Intractability A Guide to the Theory of NP-Completeness" textbook pp 236, "Sequencing to minimize tardy tasks" is NP-complete.<br>\nTo be specific the problem is as follows: </p>\n\n<p>For each task $t \\in T$, partial order $&lt;$ on $T$, a length $l(t)$, and a deadline $d(t)$ and a positive integer $K \\leq |T|$. Is there a one-processor schedule $s$ for $T$ that obeys the precedence constraints, that is $s$ is such that $t &lt; t\'$ implies $s(t)+l(t) &lt; s(t\')$, and such that there are at most $K$ tasks for which $s(t) + l(t) &gt; d(t)$? </p>\n\n<p>Now we associate each task with a release time $r(t)$ and $s(t)$ should be $\\geq r(t)$. Does the revised problem stay NP-completeness ?</p>\n', 'ViewCount': '186', 'Title': 'NP-completeness of scheduling to minimise tardy tasks with release times', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-09T08:34:55.763', 'LastEditDate': '2012-07-09T08:31:18.467', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '1', 'OwnerDisplayName': 'user1403806', 'PostTypeId': '1', 'OwnerUserId': '2090', 'Tags': '<complexity-theory><scheduling>', 'CreationDate': '2012-07-06T01:11:14.227', 'Id': '2633'}{'Body': "<p>Given Graphs $G=(V_1,E_1)$ and $H=(V_2,E_2)$. Can a graph isomorphic to $H$ be obtained from $G$ by a sequence of edge contractions ? We know this problem is NP-complete. What about if only a subset of edges are valid for contraction at each step of the sequence. For example when deciding the first edge for contraction, there are only a subset $E'\\subset E_1$ of edges eligible for contraction. If you pick $e\\in E'$ for contraction and get an intermediate graph then when deciding the second edge for contraction in this intermediate graph there are a subset $E''$ of edges eligible for contraction and so on. </p>\n\n<p>Does this problem stay NP-complete ? </p>\n", 'ViewCount': '267', 'Title': 'NP-completeness of graph isomorphism through edge contractions with an edge validity condition', 'LastEditorUserId': '39', 'LastActivityDate': '2012-07-09T09:35:13.907', 'LastEditDate': '2012-07-09T09:35:13.907', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2090', 'Tags': '<complexity-theory><computability><graphs><np-complete><np-hard>', 'CreationDate': '2012-07-06T02:40:35.660', 'Id': '2634'}{'ViewCount': '410', 'Title': 'NP-completeness and NP problems', 'LastEditDate': '2012-07-09T15:14:39.110', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2114', 'FavoriteCount': '2', 'Body': '<p>Suppose that someone found a polynomial algorithm for a NP-complete decision problem. Would this mean that we can modify the algorithm a bit and use it for solving the problems that are in NP, but not in NP-complete? Or would this just shows the availability of a polynomial algorithm for each NP problem indirectly?</p>\n\n<p>edit:\nI know that when NP-complete problems have polynomial algorithms, all NP problems must have polynomial algorithms. The question I am asking is that whether we can use the discovered algorithm for NP-complete to all NP problems just by modifying the algorithm. Or would we just know that NP problems must have a polynomial algorithm indirectly? </p>\n', 'Tags': '<complexity-theory>', 'LastEditorUserId': '2114', 'LastActivityDate': '2012-07-10T22:49:50.060', 'CommentCount': '1', 'AcceptedAnswerId': '2654', 'CreationDate': '2012-07-09T14:14:49.367', 'Id': '2653'}{'Body': '<p>I just learned that when we have a polynomial algorithm for NP-complete problems, it is possible to use that algorithm to solve all NP problems. </p>\n\n<p>So, the question is how we then distinguish non-NP-complete NP problems from NP-complete problems? It seems that all these problems will have a polynomial algorithm to convert into other problems...</p>\n', 'ViewCount': '146', 'Title': 'How do we distinguish NP-complete problems from other NP problems?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-17T13:41:22.427', 'LastEditDate': '2012-07-17T13:41:22.427', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '2659', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2114', 'Tags': '<complexity-theory><terminology><np-complete>', 'CreationDate': '2012-07-09T15:33:44.827', 'Id': '2655'}{'ViewCount': '604', 'Title': 'How hard is finding the discrete logarithm?', 'LastEditDate': '2012-07-09T23:57:38.123', 'AnswerCount': '2', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '1667', 'FavoriteCount': '2', 'Body': '<p>The <a href="http://en.wikipedia.org/wiki/Discrete_logarithm">discrete logarithm</a> is the same as finding $b$ in $a^b=c \\bmod N$, given $a$, $c$, and $N$.</p>\n\n<p>I wonder what complexity groups (e.g. for classical and quantum computers) this is in, and what approaches (i.e. algorithms) are the best for accomplishing this task.</p>\n\n<p>The wikipedia link above doesn\'t really give very concrete runtimes.  I\'m hoping for something more like what the best known methods are for finding such.</p>\n', 'Tags': '<algorithms><complexity-theory><time-complexity><discrete-mathematics>', 'LastEditorUserId': '1667', 'LastActivityDate': '2012-07-17T13:43:38.477', 'CommentCount': '1', 'AcceptedAnswerId': '2765', 'CreationDate': '2012-07-09T17:33:10.047', 'Id': '2658'}{'ViewCount': '1096', 'Title': 'Is finding the longest path of a graph NP-complete?', 'LastEditDate': '2012-07-17T13:39:12.770', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2114', 'FavoriteCount': '1', 'Body': '<p>The problem of finding the largest subgraph of a graph that has a Hamiltonian path can be restated as finding the longest path of a graph. Is this NP-complete? Also, is finding the $k$-length path of a graph NP-complete? Is it still NP-complete if we require the path to visit a given vertex?</p>\n', 'Tags': '<complexity-theory><graph-theory><np-complete>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-17T13:39:12.770', 'CommentCount': '0', 'AcceptedAnswerId': '2662', 'CreationDate': '2012-07-09T22:48:06.693', 'Id': '2660'}{'Body': u"<p>The question is exercise 1.9 from Arora-Barak's book <em>Computational Complexity \u2014 A Modern Approach</em>:</p>\n\n<hr>\n\n<p>Define a RAM Turing machine to be a Turing machine that has random access memory. We formalize this as follows: The machine has an infinite array A that is initialized to all blanks. It accesses this array as follows. One of the machine's work tapes is designated as the address tape. Also the machine has two special alphabet symbols denoted by R and W and an additional state we denote by q_access. Whenever the machine enters q_access, if its address tape contains 'i'R (where 'i' denotes the binary representation of i) then the value A[i] is written in the cell next to the R symbol. If its tape contains 'i'Wa (where a is some symbol in the machine's alphabet) then A[i] is set to the value a.</p>\n\n<p>Show that if a Boolean function $f$ is computable within time $T(n)$ (for some time constructible $T$) by a RAM TM, then is is in $\\mathrm{DTIME}(T(n)^2)$.</p>\n\n<hr>\n\n<p>The trivial solution by using an additional tape recording pairs (address,value) turns out to be in $\\mathrm{DTIME}(T(n)^3)$, since that tape can be of size $O(T(n)^2)$ with $O(T(n))$ pairs while the address of each pair can be of size $O(T(n))$.</p>\n", 'ViewCount': '225', 'Title': 'Prove that a boolean function computable in T(n) by a RAM machine is in DTIME(T(n)^2)', 'LastEditorUserId': '41', 'LastActivityDate': '2012-09-16T14:05:18.777', 'LastEditDate': '2012-08-17T14:04:18.113', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2121', 'Tags': '<complexity-theory><turing-machines><machine-models><simulation>', 'CreationDate': '2012-07-10T08:35:08.447', 'FavoriteCount': '1', 'Id': '2666'}{'Body': "<p>Given an undirected graph, I define a structure called <em>k-key</em> as a path containing $k$ vertices which are connected to a simple cycle which contains $k$ vertices as well.</p>\n\n<p>Here's the <em>k-key problem</em>: given an undirected graph $G$ and a number $k$, decide whether $G$ contains k $k$-key.</p>\n\n<p>I want to show that the k-key problem is a NP-complete.</p>\n\n<p>I want to make a reduction from the 'Undirected Hamiltonian Cycle' problem in which the input is a graph, and the problem is to decide whether it contains a Hamiltonian path. I already know that this problem is NP-complete. The input for the reduction would be an undirected graph $G$ and the output is $G'$ graph and $k$. Can you please help me understand what manipulation I should do to the original graph in order to show this reduction? And why should it work?</p>\n", 'ViewCount': '129', 'Title': 'The $\\text{k-key}$ problem', 'LastEditorUserId': '41', 'LastActivityDate': '2012-07-22T09:50:38.897', 'LastEditDate': '2012-07-17T05:56:17.920', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2678', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2126', 'Tags': '<complexity-theory><np-complete><reductions><np-hard>', 'CreationDate': '2012-07-10T18:16:52.777', 'Id': '2676'}{'ViewCount': '361', 'Title': 'Is Karp Reduction identical to Levin Reduction', 'LastEditDate': '2012-07-17T16:29:13.687', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2121', 'FavoriteCount': '2', 'Body': "<h3>Definition: Karp Reduction</h3>\n\n<p>A language $A$ is Karp reducible to a language $B$ if there is a polynomial-time computable function $f:\\{0,1\\}^*\\rightarrow\\{0,1\\}^*$ such that for every $x$, $x\\in A$ if and only if $f(x)\\in B$.</p>\n\n<h3>Definition: Levin Reduction</h3>\n\n<p>A search problem $V_A$ is Levin reducible to a search problem $V_B$ if there is polynomial time function $f$ that Karp reduces $L(V_A)$ to $L(V_B)$ and there are polynomial-time computable functions $g$ and $h$ such that</p>\n\n<ol>\n<li><p>$\\langle x, y \\rangle \\in V_A \\implies \\langle f(x), g(x,y) \\rangle \\in V_B$,</p></li>\n<li><p>$\\langle f(x), z \\rangle \\in V_B \\implies \\langle x, h(x,z) \\rangle \\in V_A$</p></li>\n</ol>\n\n<p>Are these reductions equivalent?</p>\n\n<hr>\n\n<p>I think the two definitions are equivalent. For any two $\\mathsf{NP}$ languages $A$ and $B$, if $A$ is Karp reducible to $B$, then $A$ is Levin reducible to $B$. </p>\n\n<p>Here is my proof:</p>\n\n<p>Let $x$ and $\\overline{x}$ be arbitrary instances of $A$ while $x'$ be that of $B$. \nSuppose $V_A$ and $V_B$ are verifiers of $A$ and $B$. \nLet $y$ and $\\overline{y}$ be arbitrary certificates of $x$ and $\\overline{x}$ according to $V_A$. \nLet $z$ be that of $x'$ according to $V_B$. </p>\n\n<p>Construct new verifiers $V'_A$ and $V'_B$ with new certificates $y'$ and $z'$:</p>\n\n<p>$V'_A(x,y'):$</p>\n\n<ol>\n<li>$y'=\\langle 0,\\overline{x},\\overline{y}\\rangle$: If $f(x)\\ne f(\\overline{x})$, reject. \nOtherwise output $V_A(\\overline{x},\\overline{y})$.</li>\n<li>$y'=\\langle 1,z\\rangle$: Output $V_B(f(x),z)$.</li>\n</ol>\n\n<p>$V'_B(x',z'):$</p>\n\n<ol>\n<li><p>$z'=\\langle 0,z\\rangle$: Output $V_B(x',z)$.</p></li>\n<li><p>$z'=\\langle 1,x,y\\rangle$: If $x'\\ne f(x)$, reject. \nOtherwise output $V_A(x,y)$.</p></li>\n</ol>\n\n<p>The polynomial-time computable functions $g$ and $h$ are defined as below:</p>\n\n<p>$g(x,y')$</p>\n\n<ol>\n<li><p>$y'=\\langle 0,\\overline{x},\\overline{y}\\rangle$: Output $\\langle 1,\\overline{x},\\overline{y}\\rangle$.</p></li>\n<li><p>$y'=\\langle 1,z\\rangle$: Output $\\langle 0,z\\rangle$.</p></li>\n</ol>\n\n<p>$h(x',z')$</p>\n\n<ol>\n<li><p>$z'=\\langle 0,z\\rangle$: Output $\\langle 1,z\\rangle$.</p></li>\n<li><p>$z'=\\langle 1,x,y\\rangle$: Output $\\langle 0,x,y\\rangle$.</p></li>\n</ol>\n\n<p>Let $Y_x$ be the set of all certificates of $x$ according to $V_A$ and $Z_{x'}$ be the set of all certificates of $x'$ according to $V_B$. \nThen the set of all certificates of $x$ according to $V'_A$ is $0\\overline{x}Y_\\overline{x}+1Z_{f(x)}$ such that $f(x)=f(\\overline{x})$, \nand the set of all certificates of $x'$ according to $V'_B$ is $0Z_{x'}+1\\overline{x}Y_\\overline{x}$ such that $x'=f(\\overline{x})$. </p>\n\n<p>(This is derived from the accepting language of $V'_A$ and $V'_B$.) </p>\n\n<p>Now let $x'=f(x)$, the rest part is easy to check.</p>\n", 'Tags': '<complexity-theory><reductions><check-my-proof>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-17T16:29:13.687', 'CommentCount': '1', 'AcceptedAnswerId': '2702', 'CreationDate': '2012-07-11T06:25:12.317', 'Id': '2689'}{'Body': '<p>Consider the set of graphs in which the maximum degree of the vertices is a constant number $\\Delta$ independent of the number of vertices. Is the vertex coloring problem (that is, color the vertices with minimum number of colors such that no pair of adjacent nodes have the same color) on this set still NP-hard? Why?</p>\n', 'ViewCount': '92', 'Title': 'Vertex coloring with an upper bound on the degree of the nodes', 'LastActivityDate': '2012-07-17T14:39:49.543', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2692', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1672', 'Tags': '<algorithms><complexity-theory><graph-theory><graphs><np-complete>', 'CreationDate': '2012-07-11T10:26:02.150', 'Id': '2690'}{'Body': '<p>Suppose that someone found an algorithm A for a NP problem (that is not NP-complete) that uses an algorithm B for PSPACE-complete or #P-complete problem during execution. (Remaining part of the algorithm takes polynomial time.)</p>\n\n<p>Then suppose there is also an algorithm C for a NP problem that uses the polynomial-consuming part of the algorithm A. The rest of the algorithm C is actually an algorithm that solves NP-complete problems.</p>\n\n<p>Then would this mean that PSPACE-complete or #P-complete collapse to NP-complete?</p>\n\n<p>If so or if not, why would it be like that?</p>\n\n<p>I am asking this question, because I seem to get confused during reading my computation textbook.</p>\n\n<p>Edit: \nI was a bit confused as in (or more accurately scalar function) math, if g(x)=f(h(x)) and g(x)=f(q(x)), h(x) and q(x) must be virtually the same. So, my question was virtually the aforementioned. That was the parallel I was making between algorithm A and C.</p>\n', 'ViewCount': '134', 'Title': 'Concept of reduction and algorithm', 'LastEditorUserId': '2114', 'LastActivityDate': '2012-07-17T14:53:25.060', 'LastEditDate': '2012-07-12T01:27:56.200', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '2700', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2114', 'Tags': '<complexity-theory>', 'CreationDate': '2012-07-11T23:31:04.943', 'Id': '2698'}{'ViewCount': '225', 'Title': 'Is SAT in P if there are exponentially many clauses in the number of variables?', 'LastEditDate': '2012-07-21T18:44:49.583', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1589', 'FavoriteCount': '1', 'Body': "<p>I define a <em>long CNF</em> to contain at least $2^\\frac{n}{2}$ clauses, where $n$ is the number of its variables. Let $\\text{Long-SAT}=\\{\\phi: \\phi$ is a satisfiable long CNF formula$\\}$. </p>\n\n<p>I'd like to know why $\\text{Long-SAT} \\in P$. First I thought it is $\\text{NPC}$ since I can do a polynomial-time reduction from $\\text{SAT}$ to $\\text{Long-SAT}$, no?</p>\n\n<p>But maybe I can reduce $\\text{2-SAT}$ to $\\text{Long-SAT}$? How do I do that?</p>\n", 'Tags': '<complexity-theory><np-complete><reductions><satisfiability><polynomial-time>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-21T19:06:47.027', 'CommentCount': '7', 'AcceptedAnswerId': '2705', 'CreationDate': '2012-07-12T08:19:40.860', 'Id': '2704'}{'Body': '<p>Given a directed graph $G$ and two nodes $s,t$, decide whether there is some node $s\'$ such that $s\'$ is reachable from $s$ while $t$ is <em>not</em> reachable from $s\'$.</p>\n\n<p>I am wondering whether this problem is in <a href="https://en.wikipedia.org/wiki/NL_%28complexity%29" rel="nofollow">NL</a>.</p>\n', 'ViewCount': '99', 'Title': 'Is finding dead-end nodes in NL?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-17T16:21:00.543', 'LastEditDate': '2012-07-17T16:21:00.543', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '2711', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1236', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2012-07-12T15:10:19.257', 'Id': '2710'}{'Body': '<p>Is $NP$ with oracle access to $NP$ larger than just $NP$? \nAs I understand $NP^\n{NP}$ is just a turing machine that can make queries to an other $NP$ machine if so than $NP$ can simulate $NP^{NP}$? Is there something wrong with this argument? </p>\n', 'ViewCount': '420', 'Title': 'Does $NP^{NP}=NP$?', 'LastActivityDate': '2012-07-13T11:04:59.540', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '6', 'OwnerDisplayName': 'Lisa', 'PostTypeId': '1', 'Tags': '<complexity-theory>', 'CreationDate': '2012-07-12T15:11:31.510', 'Id': '2712'}{'Body': '<p>Given a TSP instance $T$, decide whether changing the city coordinates by adding a vector of coordinates $v$ will change the optimal TSP objective by atleast $x$. The city coordinates are integers.</p>\n\n<p>The problem is in PSPACE but even the verification problem seems to be NP-hard. Is that true?</p>\n\n<p>If the verification problem is NP-hard, what exact complexity class does this problem belong to?</p>\n', 'ViewCount': '192', 'Title': 'What complexity class does this variation of traveling salesman problem belong to?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-06T15:04:38.777', 'LastEditDate': '2013-06-06T15:04:38.777', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2160', 'Tags': '<complexity-theory><reductions><np-hard><decision-problem><traveling-salesman>', 'CreationDate': '2012-07-13T23:45:51.823', 'Id': '2737'}{'ViewCount': '573', 'Title': 'A polynomial reduction from any NP-complete problem to bounded PCP', 'LastEditDate': '2012-07-22T09:53:07.957', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '2188', 'FavoriteCount': '5', 'Body': '<p>Text books everywhere assume that the <a href="https://en.wikipedia.org/wiki/Post_correspondence_problem"><em>Bounded</em> Post Correspondence Problem</a> is NP-complete (no more than $N$ indexes allowed with repetitions). However, nowhere is one shown a simple (as in, something that an undergrad can understand) polynomial time reduction from another NP-complete problem.</p>\n\n<p>However every reduction I can think of is exponential (by $N$ or by the size of the series) in run-time. Perhaps it can be shown that it is reducible to SAT?</p>\n', 'Tags': '<complexity-theory><np-complete><reductions>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-21T22:52:57.200', 'CommentCount': '0', 'AcceptedAnswerId': '2860', 'CreationDate': '2012-07-17T07:20:37.133', 'Id': '2783'}{'ViewCount': '3016', 'Title': 'How can I verify a solution to Travelling Salesman Problem in polynomial time?', 'LastEditDate': '2013-06-06T15:04:45.980', 'AnswerCount': '4', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '1558', 'FavoriteCount': '5', 'Body': '<p>So, <a href="http://en.wikipedia.org/wiki/Travelling_salesman_problem#Computational_complexity">TSP (Travelling salesman problem) decision problem is <strong>NP complete</strong></a>.</p>\n\n<p>But I do not understand how I can verify that a given solution to TSP is in fact optimal in polynomial time, given that there is no way to find the optimal solution in polynomial time (which is because the problem is not in P)?</p>\n\n<p>Anything that might help me see that the verification can in fact be done in polynomial time?</p>\n', 'Tags': '<complexity-theory><np-complete><traveling-salesman>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-06T15:04:45.980', 'CommentCount': '0', 'AcceptedAnswerId': '2835', 'CreationDate': '2012-07-20T07:25:47.367', 'Id': '2834'}{'Body': '<p>I am not sure I see it. From what I understand, edges and vertices are complements for each other and it is quite surprising that this difference exists.</p>\n\n<p>Is there a good / quick / easy way to see that in fact finding a Hamiltonian path should be much harder than finding a Euler path?</p>\n', 'ViewCount': '332', 'Title': 'Is it intuitive to see that finding a Hamiltonian path is not in P while finding Euler path is?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-07-24T06:14:09.933', 'LastEditDate': '2012-07-21T05:02:56.917', 'AnswerCount': '4', 'CommentCount': '1', 'AcceptedAnswerId': '2839', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1558', 'Tags': '<complexity-theory><graph-theory><np-complete><intuition>', 'CreationDate': '2012-07-20T08:16:19.113', 'Id': '2837'}{'Body': '<p>Modern SAT-solvers are very good at solving many real-world examples of SAT instances. However, we know how to generate hard ones: for instance use a <a href="http://cstheory.stackexchange.com/q/6755/1037">reduction from factoring to SAT</a> and give the RSA numbers as input.</p>\n\n<p>This raises the question: what if I take an easy example of factoring. Instead of taking two large primes on $n/2$ bits, what if I take a prime $p$ on $\\log n$ bits and a prime q on $n/\\log n$ bits, let $N = pq$ and the encode $\\mathrm{FACTOR}(N)$ as a SAT instance. $N$ would be an easy number to factor by brute-force search or sieve methods since one of the factors in so small; does a modern SAT-solver with some standard reduction from factoring to SAT also pick up on this structure?</p>\n\n<p><strong>Can top SAT-solvers factor $N = pq$ where $|p| = \\log n$ quickly?</strong></p>\n', 'ViewCount': '190', 'Title': 'Can top SAT-solvers factor easy numbers?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-07-22T05:29:43.467', 'LastEditDate': '2012-07-22T05:14:29.103', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<complexity-theory><satisfiability><sat-solvers><factoring>', 'CreationDate': '2012-07-22T00:41:51.747', 'FavoriteCount': '4', 'Id': '2857'}{'Body': "<p>Let $f$ be a fixed time-constructable function.</p>\n\n<p>The classical universal simulation result for TMs (Hennie and Stearns, 1966) states that there is a two-tape TM $U$ such that given</p>\n\n<ul>\n<li>the description of a TM $\\langle M \\rangle$, and</li>\n<li>an input string $x$,</li>\n</ul>\n\n<p>runs for $g(|x|)$ steps and returns $M$'s answer on $x$. And $g$ can be taken to be any function in $\\omega(f(n)\\lg f(n))$.</p>\n\n<p>My questions are:</p>\n\n<blockquote>\n  <ol>\n  <li><p>What is the best known simulation result on a single tape TM? Does the result above also still hold?</p></li>\n  <li><p>Is there any improvement on [HS66]? Can we simulate TMs on a two-tape TM for $f(n)$ steps in a faster way? \n  Can we take $g(n)$ to be in $\\omega(f(n))$ in place of $\\omega(f(n)\\lg f(n))$?</p></li>\n  </ol>\n</blockquote>\n", 'ViewCount': '278', 'Title': 'Universal simulation of Turing machines', 'LastEditorUserId': '41', 'LastActivityDate': '2012-08-16T13:15:01.727', 'LastEditDate': '2012-08-16T11:33:15.097', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '3220', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<complexity-theory><reference-request><turing-machines><machine-models><simulation>', 'CreationDate': '2012-07-23T15:49:05.823', 'Id': '2878'}{'Body': '<p>We know that $\\# \\textbf{P}$ is closed under polynomial sums, i.e., sum of polynomially many $\\# \\textbf{P}$ functions is still in $\\# \\textbf{P}$.</p>\n\n<p>Functions in $\\textbf{P}^{\\# \\textbf{P}}$ are those which make polynomially many (non-parallel) queries to an oracle for a $\\# \\textbf{P}$-Complete problem. So, the computational complexity of such problems must be a sum of polynomially many $\\# \\textbf{P}$ functions. Due to the closure property, this sum will be in $\\# \\textbf{P}$.</p>\n\n<p>If the above is right, then:\nWhat is the difference between the classes $\\# \\textbf{P}$-Complete and $P^{\\# \\textbf{P}}$ ?</p>\n\n<p>Thanks.</p>\n', 'ViewCount': '75', 'Title': 'distinction between $\\textbf{P}^{\\# \\textbf{P}}$ and $\\# \\textbf{P}$-Complete', 'LastEditorUserId': '2250', 'LastActivityDate': '2012-07-23T20:14:48.037', 'LastEditDate': '2012-07-23T19:21:53.127', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2250', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-07-23T19:15:54.727', 'FavoriteCount': '1', 'Id': '2880'}{'Body': '<p>Let $M_{1}$ and $M_{2}$ be two (non-deterministic) turing machines accepting the language $L \\subseteq \\Sigma^{\\ast}$.</p>\n\n<p>Is is right to claim that:</p>\n\n<p>$\\#M_{1} \\in \\textbf{#C}$ <em>if and only if</em> $\\#M_{2} \\in \\textbf{#C}$ ?</p>\n\n<p>where $\\textbf{#C}$ is a counting complexity class, that is closed under reductions (such as $\\textbf{#P}$, $\\textbf{#P-Hard}$, $\\textbf{GapP}$, $\\textbf{GapP-Hard}$, $\\textbf{PP}$, etc).</p>\n\n<p>If so, can we use the notation "$\\#L \\in \\textbf{#C}$" ?</p>\n', 'ViewCount': '46', 'Title': 'Counting certificates for a language', 'LastActivityDate': '2012-07-24T08:53:37.223', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'OwnerDisplayName': 'Pavithran Iyer', 'PostTypeId': '1', 'OwnerUserId': '2250', 'Tags': '<complexity-theory>', 'CreationDate': '2012-06-27T03:46:36.270', 'FavoriteCount': '1', 'Id': '2881'}{'Body': '<p>In Sipser\'s textbook "Introduction to the Theory of Computation, Second Edition," he defines nondeterministic time complexity as follows:</p>\n\n<blockquote>\n  <p>Let $N$ be a nondeterministic Turing machine that is a decider.  The <strong>running time</strong> of $N$ is the function $f : \\mathbb{N} \\rightarrow \\mathbb{N}$, where $f(n)$ is the maximum number of steps that $N$ uses on any branch of its computation on any input of length $n$ [...].</p>\n</blockquote>\n\n<p>Part of this definition says that the running time of the machine $N$ is the maximum number of steps taken by that machine on any branch.  Is there a reason that all branches are considered?  It seems like the length of the shortest accepting computation would be a better measure (assuming, of course, that the machine halts), since you would never need to run the machine any longer than this before you could conclude whether the machine was going to accept or not.</p>\n', 'ViewCount': '129', 'Title': 'Why does NTIME consider the length of the longest computation?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-24T08:48:55.467', 'LastEditDate': '2012-07-24T08:48:55.467', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '2892', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2131', 'Tags': '<complexity-theory><time-complexity><terminology><turing-machines><nondeterminism>', 'CreationDate': '2012-07-23T22:49:08.547', 'Id': '2887'}{'Body': '<p>What is the complexity of computing $n^{n^2},\\;n \\in \\mathbb{N}$?</p>\n', 'ViewCount': '206', 'Title': 'Complexity of computing $n^{n^2}$', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-30T19:25:30.803', 'LastEditDate': '2012-07-28T11:10:16.207', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '8', 'OwnerDisplayName': 'Croq', 'PostTypeId': '1', 'Tags': '<complexity-theory><integers><number-theory>', 'CreationDate': '2012-07-27T19:18:38.527', 'FavoriteCount': '1', 'Id': '2933'}{'Body': '<p>Is the <a href="http://en.wikipedia.org/wiki/Maximum_satisfiability_problem" rel="nofollow">MAX-SAT problem</a> NP-hard? From the Wikipedia page:</p>\n\n<blockquote>\n  <p>The MAX-SAT problem is NP-hard, since its solution easily leads to the solution of the boolean satisfiability problem, which is NP-complete</p>\n</blockquote>\n\n<p>I see that a given SAT problem can be reduced to a MAX-SAT problem: just solve the MAX-SAT problem for the boolean formula to see if all clauses can be satisfied. If yes, the SAT problem has the answer "yes", otherwise "no".</p>\n\n<p><strong>Question 1:</strong> What confuses me is that we have an optimization problem here, and no decision problem. So, can also optimization problems be considered as NP-hard? It only needs to be shown that the (optimization) problem can be reduced in polynomial-time to the SAT problem (or another NP-hard problem)?</p>\n\n<p><strong>Question 2:</strong> To reduce the SAT problem to MAX-SAT, we have to find a function $f$, which is computable in polynomial time, and with $p \\text{ in } \\text{SAT} \\Leftrightarrow f(p) \\text{ in } \\text{MAX-SAT}$.</p>\n\n<p>This is the definition I know about reduction. But here, we clearly can not find such a function $f$ since MAX-SAT is not a decision problem. How can a reduction be shown here?</p>\n', 'ViewCount': '738', 'Title': 'Is MAX-SAT NP-hard?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-07-31T17:37:12.083', 'LastEditDate': '2012-07-31T17:37:12.083', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'OwnerDisplayName': 'John Threepwood', 'PostTypeId': '1', 'OwnerUserId': '2313', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2012-07-30T15:10:19.573', 'Id': '2956'}{'ViewCount': '1705', 'Title': 'Generalised 3SUM (k-SUM) problem?', 'LastEditDate': '2012-08-02T02:55:51.060', 'AnswerCount': '3', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '26', 'FavoriteCount': '7', 'Body': '<p>The <a href="http://en.wikipedia.org/wiki/3SUM">3SUM</a> problem tries to identify 3 integers $a,b,c$ from a set $S$ of size $n$ such that $a + b + c = 0$.</p>\n\n<p>It is conjectured that there is not better solution than quadratic, i.e. $\\mathcal{o}(n^2)$. Or to put it differently: $\\mathcal{o}(n \\log(n) + n^2)$.</p>\n\n<p>So I was wondering if this would apply to the generalised problem: Find integers $a_i$ for $i \\in [1..k]$ in a set $S$ of size $n$ such that $\\sum_{i \\in [1..k]} a_i = 0$.</p>\n\n<p>I think you can do this in $\\mathcal{o}(n \\log(n) + n^{k-1})$ for $k \\geq 2$ (it\'s trivial to generalise the simple $k=3$ algorithm).<br>\nBut are there better algorithms for other values of $k$?</p>\n', 'Tags': '<complexity-theory><combinatorics><complexity-classes>', 'LastEditorUserId': '26', 'LastActivityDate': '2012-08-02T05:04:34.593', 'CommentCount': '0', 'AcceptedAnswerId': '2995', 'CreationDate': '2012-07-31T21:45:29.147', 'Id': '2973'}{'Body': "<p>Assume we have an optimization problem with function $f$ to maximize.</p>\n\n<p>Then, the corresponding decision problem 'Does there exist a solution with $f\\ge k$ for a given $k$?' can easily be reduced to the optimization problem: calculate the optimal solution and check if it is $\\ge k$.</p>\n\n<p>Now, I was wondering, is it always possible to do the reduction (in polynomial time) the other way around?</p>\n\n<p>For an example consider MAX-SAT: to reduce the optimization problem to the decision problem we can do a binary search in the integer range from 0 to the number of clauses. At each stoppage $k$ we check, with the decision problem solver, if there is a solution with $\\ge k$.</p>\n", 'ViewCount': '514', 'Title': 'Optimization problem vs decision problem - reduction', 'LastEditorUserId': '41', 'LastActivityDate': '2012-09-01T17:03:21.837', 'LastEditDate': '2012-08-02T06:18:37.633', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2313', 'Tags': '<complexity-theory><optimization><reductions><decision-problem>', 'CreationDate': '2012-08-01T13:08:35.477', 'FavoriteCount': '1', 'Id': '2983'}{'ViewCount': '748', 'Title': 'How fast can we find all Four-Square combinations that sum to N?', 'LastEditDate': '2012-08-02T16:54:45.280', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2334', 'FavoriteCount': '2', 'Body': '<p>A question was asked at Stack Overflow (<a href="http://stackoverflow.com/questions/11732555/how-to-find-all-possible-values-of-four-variables-when-squared-sum-to-n#comment15599644_11732555">here</a>):</p>\n\n<blockquote>\n  <p>Given an integer $N$, print out all possible\n  combinations of integer values of $A,B,C$ and $D$ which solve the equation $A^2+B^2+C^2+D^2 = N$.</p>\n</blockquote>\n\n<p>This question is of course related to <a href="http://en.wikipedia.org/wiki/Lagrange%27s_four-square_theorem" rel="nofollow">Bachet\'s Conjecture</a> in number theory (sometimes called Lagrange\'s Four Square Theorem because of his proof).  There are some papers that discuss how to find a single solution, but I have been unable to find anything that talks about how fast we can find <em>all</em> solutions for a particular $N$ (that is, all <em>combinations</em>, not all <em>permutations</em>).</p>\n\n<p>I have been thinking about it quite a bit and it seems to me that it can be solved in $O(N)$ time and space, where $N$ is the desired sum. However, lacking any prior information on the subject, I am not sure if that is a significant claim on my part or just a trivial, obvious or already known result.</p>\n\n<p>So, the question then is, how fast can we find all of the Four-Square Sums for a given $N$?</p>\n\n<hr>\n\n<p>OK, here\'s the (nearly) O(N) algorithm that I was thinking of.  First two supporting functions, a nearest integer square root function:</p>\n\n<pre><code>    // the nearest integer whose square is less than or equal to N\n    public int SquRt(int N)\n    {\n        return (int)Math.Sqrt((double)N);\n    }\n</code></pre>\n\n<p>And a function to return all TwoSquare pairs summing from 0 to N:</p>\n\n<pre><code>    // Returns a list of all sums of two squares less than or equal to N, in order.\n    public List&lt;List&lt;int[]&gt;&gt; TwoSquareSumsLessThan(int N)\n    {\n        //Make the index array\n        List&lt;int[]&gt;[] Sum2Sqs = new List&lt;int[]&gt;[N + 1];\n\n        //get the base square root, which is the maximum possible root value\n        int baseRt = SquRt(N);\n\n        for (int i = baseRt; i &gt;= 0; i--)\n        {\n            for (int j = 0; j &lt;= i; j++)\n            {\n                int sum = (i * i) + (j * j);\n                if (sum &gt; N)\n                {\n                    break;\n                }\n                else\n                {\n                    //make the new pair\n                    int[] sumPair = { i, j };\n                    //get the sumList entry\n                    List&lt;int[]&gt; sumLst;\n                    if (Sum2Sqs[sum] == null)\n                    {   \n                        // make it if we need to\n                        sumLst = new List&lt;int[]&gt;();\n                        Sum2Sqs[sum] = sumLst;\n                    }\n                    else\n                    {\n                        sumLst = Sum2Sqs[sum];\n                    }\n                    // add the pair to the correct list\n                    sumLst.Add(sumPair);\n                }\n            }\n        }\n\n        //collapse the index array down to a sequential list\n        List&lt;List&lt;int[]&gt;&gt; result = new List&lt;List&lt;int[]&gt;&gt;();\n        for (int nn = 0; nn &lt;= N; nn++)\n        {\n            if (Sum2Sqs[nn] != null) result.Add(Sum2Sqs[nn]);\n        }\n\n        return result;\n    }\n</code></pre>\n\n<p>Finally, the algorithm itself:</p>\n\n<pre><code>    // Return a list of all integer quads (a,b,c,d), where:\n    //      a^2 + b^2 + c^2 + d^2 = N,\n    // and  a &gt;= b &gt;= c &gt;= d,\n    // and  a,b,c,d &gt;= 0\n    public List&lt;int[]&gt; FindAllFourSquares(int N)\n    {\n        // get all two-square sums &lt;= N, in descending order\n        List&lt;List&lt;int[]&gt;&gt; Sqr2s = TwoSquareSumsLessThan(N);\n\n        // Cross the descending list of two-square sums &lt;= N with\n        // the same list in ascending order, using a Merge-Match\n        // algorithm to find all combinations of pairs of two-square\n        // sums that add up to N\n        List&lt;int[]&gt; hiList, loList;\n        int[] hp, lp;\n        int hiSum, loSum;\n        List&lt;int[]&gt; results = new List&lt;int[]&gt;();\n        int prevHi = -1;\n        int prevLo = -1;\n\n        //  Set the Merge sources to the highest and lowest entries in the list\n        int hi = Sqr2s.Count - 1;\n        int lo = 0;\n\n        //  Merge until done ..\n        while (hi &gt;= lo)\n        {\n            // check to see if the points have moved\n            if (hi != prevHi)\n            {\n                hiList = Sqr2s[hi];\n                hp = hiList[0];     // these lists cannot be empty\n                hiSum = hp[0] * hp[0] + hp[1] * hp[1];\n                prevHi = hi;\n            }\n            if (lo != prevLo)\n            {\n                loList = Sqr2s[lo];\n                lp = loList[0];     // these lists cannot be empty\n                loSum = lp[0] * lp[0] + lp[1] * lp[1];\n                prevLo = lo;\n            }\n\n            // do the two entries\' sums together add up to N?\n            if (hiSum + loSum == N)\n            {\n                // they add up, so cross the two sum-lists over each other\n                foreach (int[] hiPair in hiList)\n                {\n                    foreach (int[] loPair in loList)\n                    {\n                        // make a new 4-tuple and fill it\n                        int[] quad = new int[4];\n                        quad[0] = hiPair[0];\n                        quad[1] = hiPair[1];\n                        quad[2] = loPair[0];\n                        quad[3] = loPair[1];\n\n                        // only keep those cases where the tuple is already sorted\n                        //(otherwise it\'s a duplicate entry)\n                        if (quad[1] &gt;= quad[2]) //(only need to check this one case, the others are implicit)\n                        {\n                            results.Add(quad);\n                        }\n                        //(there\'s a special case where all values of the 4-tuple are equal\n                        // that should be handled to prevent duplicate entries, but I\'m\n                        // skipping it for now)\n                    }\n                }\n                // both the HI and LO points must be moved after a Match\n                hi--;\n                lo++;\n            }\n            else if (hiSum + loSum &lt; N)\n            {\n                lo++;   // too low, so must increase the LO point\n            }\n            else    // must be &gt; N\n            {\n                hi--;   // too high, so must decrease the HI point\n            }\n        }\n        return results;\n    }\n</code></pre>\n\n<p>As I said before, it should be pretty close to O(N), however, as Yuval Filmus points out, as the number of Four Square solutions to N can be of order (N ln ln N), then this algorithim could not be less than that.</p>\n', 'Tags': '<algorithms><complexity-theory><performance><number-theory>', 'LastEditorUserId': '2334', 'LastActivityDate': '2012-08-02T16:54:45.280', 'CommentCount': '5', 'AcceptedAnswerId': '3003', 'CreationDate': '2012-08-01T20:29:11.273', 'Id': '2988'}{'Body': '<p>In <em>"Introduction to Algorithms: 3rd Edition"</em> there is Theorem 34.2, which states</p>\n\n<blockquote>\n  <p>$P = \\{ L \\mid L \\text{ is accepted by a polynomial-time algorithm} \\}$</p>\n</blockquote>\n\n<p><em>"Accepted in polynomial-time"</em> is defined by:</p>\n\n<blockquote>\n  <p>$L$ is accepted in polynomial time by an algorithm $A$ if it is accepted by $A$\n      and if in addition there exists a constant $k$ such that for any length-n string $x\\in L$, \n      algorithm $A$ accepts $x$ in time $O(n^k)$.</p>\n</blockquote>\n\n<p><em>"Accepted"</em> is defined by:</p>\n\n<blockquote>\n  <p>The language accepted by an algorithm $A$ is the set of strings\n          $L = \\{ x \\in \\{0,1\\}^* \\mid A(x) = 1 \\}$,\n      that is, the set of strings that the algorithm accepts.</p>\n</blockquote>\n\n<p>But what if we take $k = 0$, and algorithm $A(\\cdot) = 1$, which just returns 1 for everything?\nWouldn\'t that mean, that $P$ is just class of all languages?</p>\n', 'ViewCount': '92', 'Title': 'Problem with the definition of P', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-02T08:33:12.717', 'LastEditDate': '2012-08-02T08:33:12.717', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '3000', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1552', 'Tags': '<complexity-theory><terminology><time-complexity><polynomial-time>', 'CreationDate': '2012-08-02T07:57:36.103', 'Id': '2999'}{'Body': "<p>Consider a sequence of $n$ positive real numbers $a_0,\\ldots,a_{n-1}$. Let $S_n$ be the set of permutations on $\\{0,\\ldots,n-1\\}$. </p>\n\n<p>We are interested to find</p>\n\n<p>$$\n\\max_{\\pi\\in S_n}\\left( \\min_{i=0}^{n-1}\\left( \\frac{a_{\\pi(i)}}{a_{\\pi(i-1)}} + \\frac{a_{\\pi(i)}}{a_{\\pi(i+1)}}\\right)\\right)\n$$</p>\n\n<p>The addition and subtraction in $\\pi$ is under mod n.</p>\n\n<p>It might be easier to consider the more general problem, where $b_0,\\ldots,b_{n-1}$ is a sequence of positive real numbers.</p>\n\n<p>$$\n\\max_{\\pi\\in S_n}\\left( \\min_{i=0}^{n-1}\\left( a_{\\pi(i)}(b_{\\pi(i-1)}+b_{\\pi(i+1)} )\\right)\\right)\n$$</p>\n\n<p>Is this problem $NP$-hard? I feel this problem is $NP$-Hard but I don't see any obvious reductions.</p>\n\n<p>The greedy approach: sort the numbers, then insert them one by one into the list such that it maximizes the minimum of the sum of quotients. Turns out to be not optimal.</p>\n\n<pre><code>Greedy Smallest First\n[5, 4, 4] 1.8\n[5, 5, 4, 4] 1.8\n[5, 5, 5, 4, 4] 1.8\n[5, 9, 5, 5, 4, 4] 1.5555555555555556\nGreedy: [5, 9, 5, 5, 4, 4] 1.5555555555555556\nBest: [4, 5, 4, 5, 9, 5] 1.6\n\nGreedy Largest First\n[5, 22, 20] 0.4772727272727273\n[4, 5, 22, 20] 1\n[4, 4, 5, 22, 20] 1.2\n[4, 3, 4, 5, 22, 20] 1.4772727272727273\n\nGreedy: [4, 3, 4, 5, 22, 20] 1.4772727272727273\nBest: [3, 4, 5, 20, 22, 4] 1.5\n</code></pre>\n", 'ViewCount': '114', 'Title': 'Find a permutation that maximize the minimum of $\\frac{a_n}{a_{n-1}} + \\frac{a_n}{a_{n+1}}$', 'LastEditorUserId': '220', 'LastActivityDate': '2012-08-02T20:31:07.420', 'LastEditDate': '2012-08-02T20:31:07.420', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2012-08-02T17:47:23.803', 'FavoriteCount': '3', 'Id': '3007'}{'Body': '<p>In the Subset Sum problem can some of the given numbers $a_1,a_2,a_3,\\dots,a_n$ be the same? For example, we might have $[1,1,1,2,3,4]$ and the target is $5$? Can I assume that I have a specific solution with numbers $2$ and $3$ and $1,1,1$ and $2$ is not?</p>\n', 'ViewCount': '216', 'Title': 'Does Subset Sum allow multisets?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-21T19:05:00.967', 'LastEditDate': '2012-08-03T06:07:44.717', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'OwnerDisplayName': 'Iraklis ', 'PostTypeId': '1', 'OwnerUserId': '2367', 'Tags': '<complexity-theory><terminology>', 'CreationDate': '2012-08-02T16:03:35.240', 'Id': '3010'}{'Body': "<p>What's the complexity of Conflict-Driven Clause Learning SAT solvers, compared to DPLL solvers? Was it proven that CDCL is faster in general? Are there instances of SAT that are hard for CDCL but easy for DPLL?</p>\n", 'ViewCount': '138', 'Title': 'Running time of CDCL compared to DPLL', 'LastEditorUserId': '472', 'LastActivityDate': '2012-11-25T21:52:35.260', 'LastEditDate': '2012-11-25T21:52:35.260', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3015', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2345', 'Tags': '<complexity-theory><time-complexity><efficiency><satisfiability><sat-solvers>', 'CreationDate': '2012-08-03T07:31:02.560', 'Id': '3014'}{'Body': '<p>Wondering about any known relations between <a href="http://qwiki.stanford.edu/index.php/Complexity_Zoo%3aR#rl" rel="nofollow">$\\mathsf{RL}$</a> complexity class (one sided error with logarithmic space) and its complementary class, $\\mathsf{coRL}$.</p>\n\n<p>Are they the same class?</p>\n\n<p>What are $\\mathsf{coRL}$\'s relation to $\\mathsf{NL}$, $\\mathsf{P}$?</p>\n', 'ViewCount': '99', 'Title': 'What is known about coRL and RL?', 'LastActivityDate': '2012-08-03T21:42:01.333', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3032', 'Score': '4', 'OwnerDisplayName': 'Uri', 'PostTypeId': '1', 'OwnerUserId': '2356', 'Tags': '<complexity-theory><complexity-classes><probabilistic-algorithms>', 'CreationDate': '2012-08-01T23:47:44.633', 'Id': '3031'}{'Body': "<p>I'm trying to understand the proof of the time hierarchy theorem appearing in sipser's book.  The proof requires a TM M to simulate an arbitrary TM N without too much slowdown. In particular, it is assumed that the encoding of N's tape alphabet using M's alphabet causes only a constant factor slowdown. This seems plausible since if N's alphabet is size k then M can use $\\log k$ cells to represent each symbol that N writes to the tape.</p>\n\n<p>But my question is this: If this is how the simulation works then before the simulation starts M will have to change the input so that each bit is repeated $\\log k$ times and I don't know how to do this without adding a quadratic term to the time. I should say its assumed that N's computation is no faster than $O(n\\log(n))$.   </p>\n", 'ViewCount': '140', 'Title': 'For the time hierarchy theorem, how is the input translated efficiently?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-05T12:18:07.830', 'LastEditDate': '2012-08-05T12:18:07.830', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2371', 'Tags': '<complexity-theory><turing-machines><simulation>', 'CreationDate': '2012-08-05T00:21:24.043', 'FavoriteCount': '1', 'Id': '3038'}{'Body': '<p>Let $S$ be a set of natural numbers. We consider $S$ under the divisibility partial order, i.e. $s_1 \\leq s_2 \\iff s_1 \\mid s_2$. Let </p>\n\n<p>$\\qquad \\displaystyle \\alpha(S) = \\max \\{|V| \\mid V\\subseteq S, V\\text{ an antichain }\\}$.</p>\n\n<p>If we consider the subset sum problem where the multiset of numbers are in $S$ ,  what can we say about about the complexity of the problem related to $\\alpha(S)$? It is simple to see if $\\alpha(S)=1$, then the problem is easy. Note it is easy even for the harder knapsack problem when $\\alpha(S)=1$<sup>$\\dagger$</sup>.</p>\n\n<hr>\n\n<p>$\\dagger$ <a href="http://dx.doi.org/10.1016/0167-6377%2893%2990044-H" rel="nofollow">Solving sequential knapsack problems</a> by M. Hartmann and T. Olmstead (1993)</p>\n', 'ViewCount': '210', 'Title': 'Subset sum problem with many divisibility conditions', 'LastEditorUserId': '41', 'LastActivityDate': '2013-07-20T09:09:39.243', 'LastEditDate': '2013-07-20T09:09:39.243', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<complexity-theory><number-theory><knapsack-problems>', 'CreationDate': '2012-08-12T04:42:56.943', 'FavoriteCount': '4', 'Id': '3132'}{'Body': '<p>The complexity class $\\newcommand{\\sharpp}{\\mathsf{\\#P}}\\sharpp$ is defined as </p>\n\n<p>$\\qquad \\displaystyle \\sharpp = \\{f \\mid \\exists \\text{ polynomial-time NTM } M\\ \\forall x.\\, f(x) = \\#\\operatorname{accept}_{M}(x)\\}$. </p>\n\n<p>It is known that $\\sharpp$ is closed under addition, multiplication and binomial coefficient. I was wondering if it is closed under power. For example, we are given a $\\sharpp$ function $f$ and another $\\sharpp$ function $g$. Is it true that $f^{g}$ or $g^{f}$ are $\\sharpp$ functions as well?  </p>\n\n<p>This is edit after the question has been answered.</p>\n\n<p>Is ($f$ modulo $g$) a $\\sharpp$ function? How about when we are given a $\\newcommand{\\FP}{\\mathsf{FP}}\\FP$ function $h$. Then is ($f$ modulo $h$) a $\\sharpp$ function? </p>\n', 'ViewCount': '139', 'Title': 'Is #P closed under exponentiation? modulo?', 'LastEditorUserId': '1093', 'LastActivityDate': '2012-08-12T23:36:10.113', 'LastEditDate': '2012-08-12T23:36:10.113', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3137', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1093', 'Tags': '<complexity-theory><turing-machines><closure-properties>', 'CreationDate': '2012-08-12T12:30:28.490', 'Id': '3134'}{'Body': '<p><em>Below, assume we\'re working with an infinite-tape Turing machine.</em></p>\n\n<p>When explaining the notion of time complexity to someone, and why it is measured relative to the input size of an instance, I stumbled across the following claim:</p>\n\n<blockquote>\n  <p>[..] For example, it\'s natural that you\'d need more steps to multiply two integers with 100000 bits, than, say multiplying two integers with 3 bits.</p>\n</blockquote>\n\n<p>The claim is convincing, but somehow hand-waving. In all algorithms I came across, the larger the input size, the more steps you need. In more precise words, the time complexity is a <a href="http://mathworld.wolfram.com/IncreasingFunction.html">monotonically increasing function</a> of the input size.</p>\n\n<blockquote>\n  <p>Is it the case that time complexity is <em>always</em> an increasing function in the input size? If so, why is it the case? Is there a <em>proof</em> for that beyond hand-waving?</p>\n</blockquote>\n', 'ViewCount': '222', 'Title': 'Why larger input sizes imply harder instances?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-08-14T13:24:07.873', 'LastEditDate': '2012-08-14T02:13:38.747', 'AnswerCount': '3', 'CommentCount': '10', 'AcceptedAnswerId': '3181', 'Score': '11', 'OwnerDisplayName': 'user20', 'PostTypeId': '1', 'Tags': '<complexity-theory><time-complexity><intuition>', 'CreationDate': '2012-08-13T23:09:10.920', 'Id': '3161'}{'Body': "<p>Let's say I have a bunch of cards or dominoes with one color on the left side of the\ncard and another color on the right. (The two colors could be the same.)\nDominoes can't be rotated so the color on each side is fixed. There is no\nlimit on the number of colors and colors can be repeated on cards.</p>\n\n<p>Dominoes are placed in a line, one after another.</p>\n\n<p>The rule is, the color on the right hand side of a domino must match the\ncolor on the left hand side of the domino placed next to it.</p>\n\n<p>The problem is, given a pool of dominoes, is it possible to put all of the\ndominoes in a line while following the rule? (I believe this is the same\nproblem as given a group of matrices is it possible to multiply them all\ntogether.)</p>\n\n<p>So for example given these dominoes: R-R, R-B, G-Y, GG-Y, Y-GG, R-R, R-B,\n..., R-B, B-R, P-G is it possible to form a straight line with all\nadjoining sides having the same color.</p>\n\n<p>My real question is this: Is the complexity of this problem (determining\nif it is possible to put all N dominoes in a line) NP?</p>\n", 'ViewCount': '65', 'Title': 'Complexity of domino tiling with dominoes placed in a line', 'LastEditorUserId': '39', 'LastActivityDate': '2012-08-14T09:23:57.177', 'LastEditDate': '2012-08-14T09:23:57.177', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'OwnerDisplayName': 'M Scott', 'PostTypeId': '1', 'Tags': '<complexity-theory>', 'CreationDate': '2012-08-06T18:32:37.990', 'Id': '3170'}{'ViewCount': '233', 'Title': 'Good text on algorithm complexity', 'LastEditDate': '2012-08-16T15:01:05.350', 'AnswerCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2530', 'FavoriteCount': '1', 'Body': '<p>Where should I look for a good introductory text in algorithm complexity? So far, I have had an Algorithms class, and several language classes, but nothing with a theoretical backbone. I get the whole complexity, but sometimes it\'s hard for me to differentiate between O(1) and O(n) plus there\'s the whole theta notation and all that, basic explanation of P=NP and simple algorithms, tractability. I want a text that covers all that, and that doesn\'t require a heavy mathematical background, or something that can be read through.</p>\n\n<p>LE: I\'m still in highschool, not in University, and by heavy mathematical background I mean something perhaps not very high above Calculus and Linear Algebra (it\'s not that I can\'t understand it, it\'s the fact that for example learning Taylor series without having done Calculus I is a bit of a stretch; that\'s what I meant by not mathematically heavy. Something in which the math, with a normal amount of effort can be understood). And, do pardon if I\'m wrong, but theoretically speaking, a class at which they teach algorithm design methods and actual algorithms should be called an "Algorithms" class, don\'t you think?\nIn terms of my current understanding, infinite series, limits and integrals I know (most of the complexity books I\'ve glanced at seemed to use those concepts), but you\'ve lost me at the Fast Fourier Transform.</p>\n', 'Tags': '<complexity-theory><reference-request><algorithm-analysis><education><books>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-08-16T15:37:01.093', 'CommentCount': '1', 'AcceptedAnswerId': '3222', 'CreationDate': '2012-08-15T18:15:23.667', 'Id': '3201'}{'Body': '<p>After looking at other questions and my textbook, I seem to get some confusion. </p>\n\n<p>I do get that when there is a polynomial algorithm of NPC, there is a polynomial algorithm for a NP problem. </p>\n\n<p>But the statement describing reduction seems obscure to me at least in the beginning of my studies in computational complexity. </p>\n\n<p>So, can we transform an exponential algorithm for NPC (which we have) into an exponential algorithm for another non-NPC NP problem in polynomial time? </p>\n', 'ViewCount': '103', 'Title': 'Can an exponential algorithm for an NPC problem be transformed into an algorithm for other NP problems in polynomial time?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-16T11:55:20.967', 'LastEditDate': '2012-08-16T09:30:50.490', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2540', 'Tags': '<complexity-theory><terminology><np-complete><reductions>', 'CreationDate': '2012-08-16T08:49:13.167', 'Id': '3216'}{'Body': '<p>I\'m reading few proofs which prove a given problem is NP complete. The proof technique has following steps.</p>\n\n<ol>\n<li>Prove that current problem is NP, i.e., given a certificate, prove\nthat it can be verified in polynomial time.</li>\n<li>Take any known NP-complete problem (call "Easy") and reduce <strong>all</strong>\nof it\'s instances to <strong>few</strong> instances of given problem (call\n"Hard"). Note this is <strong>not</strong> necessarily an 1:1 mapping.</li>\n<li>Prove that above reduction can be done in polynomial time.</li>\n</ol>\n\n<p>All is well here. Is this knowledge right "if you can solve any NP-complete problem in polynomial time, then all NP-complete problems can be solved in polynomial time" ?</p>\n\n<p>If yes, then as per above proof technique, let\'s say "Easy" problem can be solved in polynomial time, how does that imply "hard" can be solved in polynomial time? What am I missing here? Or is this true, that "hard" problem can be reduced to the "easy" problem too?</p>\n', 'ViewCount': '391', 'Title': 'How are all NP Complete problems similar?', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-08-16T23:07:03.297', 'LastEditDate': '2012-08-16T19:50:19.087', 'AnswerCount': '4', 'CommentCount': '1', 'AcceptedAnswerId': '3232', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2375', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-08-16T18:21:21.570', 'Id': '3226'}{'Body': '<p>In <a href="http://rads.stackoverflow.com/amzn/click/0072970545" rel="nofollow">Cormen\'s Algorithms book</a> on NP-completeness they prove various problems are NP-complete by reducing a previously proved NP-complete problem (call $K$) to current problem (call $L$). Each proof involves some clever construction which reduces all instances of $K$ to few instances of $L$. Here is the proof order they follow. <strong>CIRCUIT-SAT, SAT, 3 CNF-SAT, CLIQUE, VERTEX-COVER, HAM-CYCLE, TSP</strong>. e.g. in reducing <strong>VERTEX-COVER</strong> to <strong>HAM-CYCLE</strong> they use a <strong>widget</strong> which does the trick.</p>\n\n<p>After this <a href="http://cs.stackexchange.com/questions/3226/how-are-all-np-complete-problems-similar">previous question of mine</a>, I think one can reduce back. i.e. one can reduce <strong>HAM-CYCLE</strong> to <strong>VERTEX-COVER</strong> problem. I tried searching web for such reductions, but most of the link return the normal reduction order. I\'m interested to see if one can reduce in <strong>reverse order</strong>. i.e. TSP to HAM-CYCLE to VERTEX-COVER to CLIQUE to 3 CNF-SAT to SAT</p>\n\n<p>I\'m looking for reverse constructive proofs. I know all of these problems belong to NP-complete hence equivalent. </p>\n\n<p>You don\'t have to give complete proof as an answer. Proof sketches are fine too. If you can point me where these proofs are available online, that\'s completely fine too. I\'m just trying to lean how constructions are leveraged among problems that look so different on surface. Thanks!</p>\n', 'ViewCount': '744', 'Title': 'Reducing TSP to HAM-CYCLE to VERTEX-COVER to CLIQUE to 3 CNF-SAT to SAT', 'LastEditorUserId': '2375', 'LastActivityDate': '2012-09-18T03:26:11.287', 'LastEditDate': '2012-08-17T22:28:01.183', 'AnswerCount': '1', 'CommentCount': '10', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2375', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-08-17T14:19:49.773', 'Id': '3239'}{'Body': u"<p>If $L$ is an APX-hard language, doesn't the existence of a PTAS for $L$ trivially imply $\\mathsf{P} = \\mathsf{NP}$?</p>\n\n<p>Since for example metric-TSP is in APX, but it is not approximable within 220/219 of OPT [1] unless $\\mathsf{P} = \\mathsf{NP}$. Thus if there was a PTAS for $L$ we could reduce metric-TSP using a PTAS reduction to $L$ and thus can approximate OPT within arbitrary precision.</p>\n\n<p>Is my argument correct?</p>\n\n<hr>\n\n<p>[1] Christos H. Papadimitriou and Santosh Vempala. On the approximability Of the traveling salesman problem. Combinatorica, 26(1):101\u2013120, Feb. 2006. </p>\n", 'ViewCount': '206', 'Title': '$L$ APX-hard thus PTAS for $L$ implies $\\mathsf{P} = \\mathsf{NP}$', 'LastEditorUserId': '472', 'LastActivityDate': '2012-08-22T17:52:57.157', 'LastEditDate': '2012-08-20T09:00:14.813', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '3259', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2568', 'Tags': '<complexity-theory><np-complete><approximation>', 'CreationDate': '2012-08-17T21:15:08.610', 'Id': '3245'}{'Body': '<p>If we suppose that we start with an instance of $k$-SAT, and try converting the problem to an instance of $(k+m)$-SAT, where there are $(k+m)$ literals per clause, can we guarantee a reduction in the total amount of clauses?</p>\n\n<p><em>I realized after posting that we can\'t guarantee that the number of clauses can be reduced.  However, I wonder if we have $n$ clauses, could we get something like $n/k + O(1)$ clauses by some "reduction" technique?</em></p>\n\n<p>If so, how much can we guarantee the total number of clauses can be reduced by? For instance, if we start with $k$-SAT with $n_k$ clauses, what is the smallest guaranteed $n_{k+m}$, the new amount of clauses, that will result if we convert this instance to $(k+m)$-SAT?</p>\n\n<p>More importantly, how do we carry out this conversion?</p>\n', 'ViewCount': '179', 'Title': 'How much can we reduce the number of clauses by converting from $k$-SAT to $(k+m)$-SAT?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-09-20T21:25:20.007', 'LastEditDate': '2012-08-21T21:28:54.100', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1667', 'Tags': '<complexity-theory><logic><satisfiability>', 'CreationDate': '2012-08-21T10:18:09.717', 'FavoriteCount': '4', 'Id': '3270'}{'ViewCount': '468', 'Title': 'Types of reductions and associated definitions of hardness', 'LastEditDate': '2012-08-22T10:33:50.667', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2250', 'FavoriteCount': '3', 'Body': '<p>Let A be reducible to B, i.e., $A \\leq B$. Hence, the Turing machine accepting $A$ has access to an oracle for $B$. Let the Turing machine accepting $A$ be $M_{A}$ and the oracle for $B$ be $O_{B}$. The types of reductions:</p>\n\n<ul>\n<li><p>Turing reduction: $M_{A}$ can make multiple queries to $O_{B}$.</p></li>\n<li><p>Karp reduction: Also called "polynomial time Turing reduction": The input to $O_{B}$ must be constructed in polytime. Moreover, the number of queries to $O_{B}$ must be bounded by a polynomial. In this case: $P^{A} = P^{B}$.</p></li>\n<li><p>Many-one Turing reduction: $M_{A}$ can make only one query to $O_{B}$, during its the last step. Hence the oracle response cannot be modified. However, the time taken to constructed the input to $O_{B}$ need not be bounded by a polynomial.\nEquivalently: ($\\leq_{m}$ denoting many-one reduction)</p>\n\n<blockquote>\n  <p>$A \\leq_{m} B$ if $\\exists$ a computable function $f: \\Sigma^{\\ast} \\to \\Sigma^{\\ast}$ such that $f(x) \\in B \\iff x\\in A$.</p>\n</blockquote></li>\n<li><p>Cook reduction: Also called "polynomial time many-one reduction": A many-one reduction where the time taken to construct an input to $O_{B}$ must be bounded by a polynomial.\nEquivalently: ($\\leq^{p}_{m}$ denoting many-one reduction)</p>\n\n<blockquote>\n  <p>$A \\leq^p_{m} B$ if $\\exists$ a <em>poly-time</em> computable function $f: \\Sigma^{\\ast} \\to \\Sigma^{\\ast}$ such that $f(x) \\in B \\iff x\\in A$.</p>\n</blockquote></li>\n<li><p>Parsimonious reduction: Also called "polynomial time one-one reduction": A Cook reduction where every instance of $A$ mapped to a unique instance of $B$.\nEquivalently: ($\\leq^{p}_{1}$ denoting parsimonious reduction)</p>\n\n<blockquote>\n  <p>$A \\leq^p_{1} B$ if $\\exists$ a <em>poly-time</em> computable bijection $f: \\Sigma^{\\ast} \\to \\Sigma^{\\ast}$ such that $f(x) \\in B \\iff x\\in A$.</p>\n</blockquote>\n\n<p>These reductions preserve the number of solutions. Hence $\\#M_{A} = \\#O_{B}$.</p></li>\n</ul>\n\n<p>We can define more types of reductions by bounding the number of oracle queries, but leaving those out, could someone kindly tell me if I have gotten the nomenclature for the different types of reductions used, correctly.\nAre NP-complete problems defined with respect Cook reduction or parsimonious reduction? Can anyone kindly give an example of a problem that is NP-complete under Cook and not under parsimonious reduction.</p>\n\n<p>If I am not wrong, the class #P-Complete is defined with respect to Karp reductions.</p>\n', 'Tags': '<complexity-theory><np-complete><reductions><complexity-classes>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-19T20:30:35.610', 'CommentCount': '0', 'AcceptedAnswerId': '3290', 'CreationDate': '2012-08-22T05:45:07.493', 'Id': '3286'}{'Body': "<p>Say you have $m$ boolean inputs, and you are given a threshold $n$. You need to construct a boolean circuit  that evaluates to true if at least $n$ of the inputs true. You may use AND, OR, NOT, or XOR gates (restricted to fan-in two, with arbitrary fan-out). Asymptotically how small can you make this circuit? </p>\n\n<p>Any reasonably tight upper bound would be appreciated. I keep on thinking of ways to recursively construct such a circuit but I can't find anything good. Also, any results for any other reasonable basis of allowed gates would also be useful.</p>\n", 'ViewCount': '195', 'Title': 'Circuit size for "at least n inputs are true"', 'LastEditorUserId': '755', 'LastActivityDate': '2013-05-28T06:04:32.053', 'LastEditDate': '2013-05-28T06:04:32.053', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2610', 'Tags': '<complexity-theory><circuits>', 'CreationDate': '2012-08-22T18:03:27.640', 'FavoriteCount': '2', 'Id': '3291'}{'Body': '<p>An optimisation problem requires minimising some function $f(x)$, where $x$ is a\nvector of integers. What is the corresponding decision version of the problem?</p>\n', 'ViewCount': '31', 'Title': 'Produce decision version of the problem', 'LastEditorUserId': '472', 'LastActivityDate': '2012-08-22T20:13:03.270', 'LastEditDate': '2012-08-22T20:12:13.753', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '3294', 'Score': '1', 'OwnerDisplayName': 'Princeps Tairu', 'PostTypeId': '1', 'Tags': '<complexity-theory><optimization><reductions>', 'CreationDate': '2012-08-22T15:23:59.557', 'Id': '3293'}{'Body': '<p>The $\\text{NP-Complete}$ class of problems is defined w.r.t Karp Reductions, which are <strong>polytime many-one reductions</strong>. However, <em>they need not necessarily preserve the number of solutions</em>. A more restrictive type: <strong>polytime one-one reductions</strong> do indeed preserve the number of solutions.</p>\n\n<p>Suppose $f:\\Sigma^{\\ast}\\to \\mathbb{N}$ is a counting function in $\\text{#P}$ and the decision problem $f_{ &gt; 0}$ defined as: <strong>Is $f(x) &gt; 0$ ?</strong> is in $NP$.</p>\n\n<p>Now if $f_{&gt; 0}$ is in $\\text{NP-Complete}$, can we immediately tell that $f$ is in $\\text{#P-Complete}$ or, do we could only say so, if the reduction map (showing $\\text{NP-Completeness}$) was <strong>one-one</strong>.</p>\n', 'ViewCount': '148', 'Title': 'Hardness of counting solutions to NP-Complete problems, assuming a type of reduction', 'LastEditorUserId': '31', 'LastActivityDate': '2012-08-23T07:45:55.997', 'LastEditDate': '2012-08-23T07:45:55.997', 'AnswerCount': '0', 'CommentCount': '14', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2250', 'Tags': '<complexity-theory><reductions><complexity-classes>', 'CreationDate': '2012-08-22T23:09:57.760', 'FavoriteCount': '2', 'Id': '3295'}{'Body': "<p>Say we're given $n$ sets and the size of their union is $m$. We would like to construct a small set which contains at least $k$ of the $n$ given sets. </p>\n\n<p>Lets assume that $m$ is less than some polynomial in $n$, i.e.: $m &lt; P(n)$. In this case is there an efficient (polynomial) algorithm for the optimization problem:</p>\n\n<p>Find the smallest set which contains at least $k$ of the $n$ given sets.</p>\n", 'ViewCount': '147', 'Title': 'Find small superset of at least k of n given sets', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:27:49.990', 'LastEditDate': '2013-05-24T03:27:49.990', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2610', 'Tags': '<complexity-theory><np-complete><np-hard><polynomial-time>', 'CreationDate': '2012-08-24T21:24:54.527', 'FavoriteCount': '1', 'Id': '3321'}{'Body': '<blockquote>\n  <p><strong>Possible Duplicate:</strong><br>\n  <a href="http://cs.stackexchange.com/questions/1643/how-can-we-assume-comparison-addition-between-numbers-is-o1">How can we assume comparison, addition, &hellip; between numbers is $O(1)$</a>  </p>\n</blockquote>\n\n\n\n<p>When we calculate the time-complexity of some algorithm we make many simplifications (or assumptions) on our calculation. For instance we say that assume basic arithmetic operations are all constant time and we assume reading/writing to a memory location is constant time.</p>\n\n<p>I\'ve worked on some algorithms where these assumptions don\'t hold. I\'m looking for the background I need to properly approach/describe these algorithms. In particular I wish to know:</p>\n\n<ol>\n<li>What is the generic name for such a simplification/assumption?</li>\n<li>Is there a name for the basic model of simplifications we\'re using? (Assuming there is a common model)</li>\n</ol>\n\n<p><em>Note: I\'ve done work with cache-dependent/cache-oblivious algorithms. I understand how to calculate in that domain, but I\'m lacking the terminology/background to properly compare/contrast such algorithm analyis with that which don\'t consider the cache.</em></p>\n', 'ViewCount': '82', 'ClosedDate': '2012-08-30T13:10:54.383', 'Title': 'Complexity calculations, assumptions on basic costs', 'LastActivityDate': '2012-08-25T12:56:07.623', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '3333', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1642', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-08-25T07:37:10.563', 'FavoriteCount': '1', 'Id': '3327'}{'Body': '<p>Although the reduction from vertex cover problem to set cover problem is quite simple, I did not find anywhere the reduction in the opposite direction. From the similarity in the type of problems, I guess this reduction should be simple too. However, despite trying for some time, I could not develop this. So, any ideas how this reduction can be done?</p>\n', 'ViewCount': '902', 'Title': 'Reduction from set cover problem to vertex cover problem', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-30T15:54:51.960', 'LastEditDate': '2012-08-29T00:03:22.587', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2596', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-08-28T20:36:19.960', 'Id': '3354'}{'Body': "<p>For an assignment I have to program an application to schedule conversations. \nThere is an event where representatives of the elementary schools talks with the representatives of high schools. They will talk about the students that will be transferred to the highschool. There are approximately 200 elementary schools and 40 high schools that will be participating in this event. The schools already know which student is transferring to which high school. The conversations will only be between representatives of E and H from student that will be transferring to H.</p>\n\n<p>The rules are:</p>\n\n<ol>\n<li>The duration of each conversation is based on the amount of\nstudents per representatives.Each conversation last 5 minutes per student. If a group consist of 1 student, this conversation last 10 minutes.</li>\n<li>No timeclashes</li>\n<li>All the students of the same group will be scheduled together, so, a\nrepresentatives will only face the same representative once.</li>\n<li>Timespan is 13.00-19.00</li>\n<li>The waiting time of a representative is at most 20% of his time. A\nwaiting time is an empty timeslot between the 1st and last\nconversation.</li>\n<li>Schedules for 2 days</li>\n<li>Each representatives participate for 1 day.</li>\n</ol>\n\n<p>The problem is that I know that this is hard to solve, but I dont know if it's NP-hard. Right now I only know this problem is similar to a Job Shop Problem. What can I do to proof that my problem is NP-hard? I read that I need to reduce a known problem to my problem. But how do I do this? I have read different articles and books, but I still don't understand the steps to do it.</p>\n", 'ViewCount': '285', 'Title': 'How to reduce to an NP-hard problem?', 'LastEditorUserId': '2700', 'LastActivityDate': '2012-09-06T14:12:00.927', 'LastEditDate': '2012-09-06T14:12:00.927', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2700', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2012-09-05T15:53:58.833', 'FavoriteCount': '1', 'Id': '3439'}{'Body': "<p>I'm looking for a major in Theoretical Computer Science; specifically, I'm interested on complexity theory and probabilistic automata theory. As I'm graduating in one year, what advanced courses in math (like Galois theory or Harmonic analysis, for example) do you think would be useful to take over the next two semesters? Why?</p>\n", 'ViewCount': '264', 'Title': 'Math for TCS major', 'LastEditorUserId': '69', 'LastActivityDate': '2012-10-04T19:33:12.617', 'LastEditDate': '2012-09-07T16:02:18.477', 'AnswerCount': '1', 'CommentCount': '9', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '2753', 'Tags': '<complexity-theory><automata><education>', 'CreationDate': '2012-09-07T04:23:50.113', 'FavoriteCount': '2', 'Id': '3457'}{'Body': '<p>I\'m reading through <code>"Computers and Intractability: A guide to the Theory of NP-Completeness" by Michael R. Garey and David S. Johnson, p. 20</code> and I came across this concept of a function that is polynomially related to input lengths obtained using some encoding scheme. Let $$Len:D_{\\Pi}\\rightarrow \\mathbb Z^+$$ be a function that maps instances $\\in D_{\\Pi}$ (the set of instances of decision problem $\\Pi$) to positive integers (lengths). Let $x$ be the string obtained from $I\\in D_{\\Pi}$ under some encoding $e$. If there exist polynomials $p$ and $p\'$ such that $$Len(I) \\le p(|x|)$$ and $$|x| \\le p\'(Len(I)),$$ We say that $Len$ is polynomially related to the input lengths obtained by the encoding $e$. I cannot digest that; my understanding is that two encodings are polynomially related if converting from one another requires a polynomial amount of time. Can anybody clarify things a bit?</p>\n', 'ViewCount': '118', 'Title': 'Polynomially related lengths under two different encodings', 'LastEditorUserId': '19', 'LastActivityDate': '2012-09-09T01:38:36.957', 'LastEditDate': '2012-09-09T01:38:36.957', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3472', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2499', 'Tags': '<complexity-theory><polynomial-time><encoding-scheme>', 'CreationDate': '2012-09-07T20:30:18.560', 'Id': '3462'}{'ViewCount': '354', 'Title': 'Using a step-counting function in a Turing Machine construction', 'CommunityOwnedDate': '2012-09-11T12:58:07.527', 'LastEditDate': '2012-09-12T09:44:18.067', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2775', 'Body': "<p>I have an question relating to the elementary foundations of Turing Machine theory. I would like to have a clarification of the status of a function $\\phi$ (a mapping between TM indexes) I shall introduce in the formal question after the preamble. First to the preamble.</p>\n\n<p>Let us assume that we have a fixed Turing Machine language and corresponding Universal Turing Machine. Thus ${TM_i}$ is an enumeration of machines, with UTM say as the Universal Machine in that enumeration. Let us also introduce a numerical parameter <strong>c</strong> for this example: (for example <strong>c</strong> = 500).</p>\n\n<p>Now execution of any TM can be simulated on UTM.</p>\n\n<p><strong>EDIT (Explaining notation)</strong> I am using some notation in this question which I shall outline here. Let S be an arbitrary input string for TM, then I shall write:</p>\n\n<p>$$UTM(TM_i; S)$$</p>\n\n<p>to indicate that $TM_i$ is using S as its input. So we will have the equation:\n$$UTM(TM_i; S) = TM_i(S)$$\nsince UTM is Universal, and its purpose is simply to simulate TMs on their input. If S is a composition of x,y I shall write:\n$$UTM(TM_i;x,y)$$</p>\n\n<p>(End notation discussion.)</p>\n\n<p>Let us modify UTM to UTM2 (and using the above notation) with the following property when a given $TM_i$ is executed on UTM2:</p>\n\n<p>$UTM_2(TM_i;c,x) = UTM(TM_i;c,x) = TM_i(x)$ if $TM_i$ requires <strong>c</strong> steps or less to compute the output</p>\n\n<p>$UTM_2(TM_i;c,x)=0$ if $TM_i(x)$ requires at least <strong>c</strong> steps for computation</p>\n\n<p><strong>EDIT</strong> The original question with this second condition has been answered. In this edit I would like to modify the condition to the following (introducing UTM3 which also meets the first condition):</p>\n\n<p>$UTM_3 (TM_i; c, x) = [s]$ if $TM_i (x)$ requires at least <strong>c</strong> steps for computation.</p>\n\n<p>In this expression [s] is the string on the tape which results after <strong>c</strong> steps of computation by $TM_i$ on Input. (EDIT The corresponding state of $TM_i$ will not be a Final state (ACCEPT or REJECT), but just an arbitrary state $q_j$. This is because UTM3 stops executing after <strong>c</strong> steps, ignoring the Turing Machine convention requiring termination only in Final states.) As a result (almost) all input strings x, including those with |x| > c will be modified (in a maximum of c string positions) - expressed in Language terms many such strings will just have their ACCEPTANCE calculation prematurely terminated in a non-Final state - but some strings of arbitrary length will still be ACCEPTED by some Turing Machines in less than <strong>c</strong> steps (IE those for which ACCEPTANCE requires examining less than the first <strong>c</strong> terms.)</p>\n\n<p>So under UTM2/3 the output is determined partly by a (hidden) step counting function. Here UTM2/3 has taken on some of the role of an operating system, by monitoring the actual steps taken by the simulated machines, and using some step-counting variable to behave as above.</p>\n\n<p>(EDIT: We show below that UTM2/3 is a Universal Machine)and so capable of <em>executing</em> any TM - on any argument - it is provided with, at least as far as <strong>c</strong> steps. Despite this limitation I believe that an infinite number of (TM,input) pairs will result in a non-zero output. So most TMs executed on UTM2/3 will not behave as they do on UTM. In UTM3 the outputs will explicitly depend on x,i and c.(End preamble.)</p>\n\n<p>The question is whether any given $TM_i$ can be modified into $TM_{\\phi (i,c)}$ with the property that (generalising to arbitrary c):</p>\n\n<p>$UTM_3(TM_i; c, x)$ = $UTM (TM_{\\phi(i,c)}; x)$       (for all $x$ and $c$)</p>\n\n<p><strong>EDIT2\\phi</strong> Both questions for the $\\phi(i,c)$ have been answered. For reasons discussed below I want to modify the definition to $\\phi(i)$. This new definition is:</p>\n\n<p>$UTM_3(TM_i; c, x)$ = $UTM (TM_{\\phi(i)}; c,x)$ = $TM_{\\phi(i)}(c,x)$       (for all $x$ and $c$)</p>\n\n<p>This condition is meant to ensure that $TM_{\\phi (i)}$ is a correct simulation of $TM_i$.\nThe specific questions to be proven about $\\phi: (i) \\rightarrow i$ are: (i) Is $\\phi$ well defined and non-trivial; (ii) Is $\\phi$ recursive; (iii) Is $\\phi$ non-recursive? </p>\n\n<p>In the LHS of the above definitions c is an input, which is ignored by $TM_i$ but used by UTM3 to determine the stopping stage. Asking for $\\phi(x,c)$ made this a <em>fixed</em> parameter built into the definition of $TM_{\\phi(x,c)}$. However the correct UTM simulation will be given <strong>c</strong> as in the modified equation RHS. This parameter needs to be used by $TM_{\\phi(i)}$ along with its own input x, to construct the correct simulation. (EDIT) Of course since the UTM is a regular Universal Machine it simply simulates the execution of $TM_{\\phi(i)}$ - the parameters on <em>its</em> tape - like <strong>c</strong> - are meant for its TM's only.</p>\n\n<p>Note that a special symbol <strong>u</strong> could be introduced switching off the UTM3 counts, and so</p>\n\n<p>$$UTM3(TM_i;u,x) = UTM(TM_i;u,x) = TM_i(x)$$</p>\n\n<p>Also the same problem can be formulated for the original UTM2 (with modified $\\phi$).</p>\n\n<p>This question is a simplification of a problem I am trying to understand (I am a math but not a CS major, but have some textbooks like Hopcroft/Ullmann), and I hope that I can get some clarification on this piece.</p>\n", 'Tags': '<complexity-theory><computability><turing-machines>', 'LastEditorUserId': '2775', 'LastActivityDate': '2012-09-12T09:44:18.067', 'CommentCount': '6', 'AcceptedAnswerId': '3488', 'CreationDate': '2012-09-10T11:53:12.470', 'Id': '3487'}{'ViewCount': '173', 'Title': 'Length of the certificate in complexity classes', 'LastEditDate': '2012-10-10T20:04:46.300', 'AnswerCount': '3', 'Score': '3', 'OwnerDisplayName': 'Ingrid Morstrad', 'PostTypeId': '1', 'OwnerUserId': '2777', 'FavoriteCount': '1', 'Body': '<blockquote>\n  <p>A nondeterministic machine trying to decide membership in a language\n  is presented with a hint (called a "witness" or "certificate") which\n  proves membership (no such witness is provided for elements outside\n  the language; the definition is asymmetric).</p>\n</blockquote>\n\n<p>So, if a non-deterministic algorithm can solve a problem in O(f(n)) time, does this mean the length of the certificate is f(n) [Since it could try all the possible combinations and the length of the shortest one will be f(n)]? And the input size is n?</p>\n\n<p>Also, if a deterministic algorithm A exists that can verify a certificate in O(f(n)) time, how does this imply the existence of a non-deterministic algorithm that can solve the problem in O(f(n)) time?</p>\n', 'Tags': '<complexity-theory><terminology><nondeterminism>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-11T01:01:12.950', 'CommentCount': '2', 'CreationDate': '2012-09-10T08:11:06.193', 'Id': '3494'}{'Body': '<p>My question is related to the <a href="http://en.wikipedia.org/wiki/Integer_relation_algorithm" rel="nofollow">Integer Relation Detection Problem</a> which can be formulated as:</p>\n\n<p>$\\qquad a_1x_1 + a_2x_2 + \\cdots + a_nx_n = 0$</p>\n\n<p>Where $\\forall i. a_i\\in\\mathbb{Z} \\land a_i&lt;c \\land x\\in \\mathbb{R}$, and $\\exists i. a_i\\neq 0$. $c$ and vector $\\mathbf{x}$ are given, and the problem is to find a valid vector $\\mathbf{a}$ that satisfies these constraints.</p>\n\n<p>There are a few algorithms to solve this problem, listed on the wikipedia page linked.</p>\n\n<p>My question: are there algorithms for a solution to the same problem with the modification that</p>\n\n<p>$\\qquad a_1x_1 + a_2x_2 + \\cdots + a_nx_n = 1$?</p>\n\n<p>Or equivalently (I believe),</p>\n\n<p>$\\qquad a_1x_1 + a_2x_2 + \\cdots + a_nx_n = b$?</p>\n\n<p>The constant $b\\in \\mathbb R$ is a given.</p>\n\n<p>On <a href="http://math.stackexchange.com/questions/191545/integer-relation-that-equals-one">math.se</a> I ask for a polynomial time algorithm or proof that none exist, with not much luck. Here I ask if a solution to this is equivalent to a solution the knapsack problem (can the knapsack problem be reduced to this), and this would thus be NP-hard.</p>\n', 'ViewCount': '145', 'Title': 'Reduction from knapsack problem to Integer relation that equals one', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-12T22:38:34.833', 'LastEditDate': '2012-09-12T22:38:34.833', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2755', 'Tags': '<algorithms><complexity-theory><np-hard><number-theory><knapsack-problems>', 'CreationDate': '2012-09-11T02:29:27.720', 'FavoriteCount': '0', 'Id': '3503'}{'Body': u'<p>I am trying to understand this problem from <a href="https://docs.google.com/viewer?a=v&amp;q=cache%3azCRhhxjqT5cJ%3awww.cs.berkeley.edu/~vazirani/algorithms/chap8.pdf%20&amp;hl=en&amp;gl=us&amp;pid=bl&amp;srcid=ADGEEShy1bvJEehdocFNfXKJs7p_TSog4n_ktXYth1MI0n1aUBo_L5Wbd-gzn5OH3QMnAv8mHqNKXJ8t1CXv3rle7avzGFVFN7DliQEASoN2ikYTFglAz_PSPA9K1TW1nY9ybkd3w4OV&amp;sig=AHIEtbTJ6FYl_HzkdU7W-mDJO3BB27sKqw">Algorithms. by S. Dasgupta, C.H. Papadimitriou, and U.V. Vazirani, chapter8</a>, Pg281. Problem 8.19</p>\n\n<p>A <em>kite</em> is a graph on an even number of vertices, say $2n$, in which $n$ of the vertices form a clique\nand the remaining $n$ vertices are connected in a \u201ctail\u201d that consists of a path joined to one of the\nvertices of the clique. Given a graph $G$ and a goal $g$, the KITE problem asks for a subgraph which\nis a kite and which contains $2g$ nodes. Prove that KITE is NP-complete.</p>\n\n<p>Any pointers to start with this problem? I am completely lost with it.</p>\n', 'ViewCount': '675', 'Title': 'NP-complete proof from Dasgupta problem on Kite', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-12T10:58:38.283', 'LastEditDate': '2012-09-12T10:58:38.283', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3511', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2120', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-09-12T07:23:42.460', 'Id': '3509'}{'Body': "<p>How can i prove that the conversion from CNF to DNF is NP-Hard. I'm not asking for an answer, just some suggestions about how to go about proving it.</p>\n", 'ViewCount': '646', 'Title': u'CNF to DNF \u2014 conversion is NP Hard', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-12T22:32:03.810', 'LastEditDate': '2012-09-12T22:32:03.810', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '7', 'OwnerDisplayName': 'jkjk', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-hard><satisfiability><sat-solvers>', 'CreationDate': '2011-12-14T15:46:55.587', 'FavoriteCount': '4', 'Id': '3513'}{'Body': "<p>In algorithms and complexity we focus on the asymptotic complexity of algorithms, i.e. the amount of resources an algorithm uses as the size of the input goes to infinity. </p>\n\n<p>In practice, what is needed is an algorithm that would work fast on a finite (although possibly very large) number of instances.</p>\n\n<p>An algorithm which works well in practice on the finite number of instances that we are interested in doesn't need to have good asymptotic complexity (good performance on a finite number of instances doesn't imply anything regarding the asymptotic complexity). Similarly, an algorithm with good asymptotic complexity may not work well in practice on the finite number of instances that we are interested in (e.g. because of large constants).</p>\n\n<p>Why do we use asymptotic complexity? How do these asymptotic analysis related to design of algorithms in practice?</p>\n", 'ViewCount': '799', 'Title': 'Explaining the relevance of asymptotic complexity of algorithms to practice of designing algorithms', 'LastEditorUserId': '41', 'LastActivityDate': '2013-01-16T10:19:05.873', 'LastEditDate': '2012-09-13T01:08:53.377', 'AnswerCount': '4', 'CommentCount': '1', 'Score': '22', 'PostTypeId': '1', 'OwnerUserId': '41', 'Tags': '<algorithms><complexity-theory><education>', 'CreationDate': '2012-09-13T01:02:59.517', 'FavoriteCount': '8', 'Id': '3523'}{'ViewCount': '282', 'Title': 'Are there any problems that are easy to compute but hard to verify?', 'LastEditDate': '2012-09-20T19:08:06.137', 'AnswerCount': '1', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '903', 'FavoriteCount': '3', 'Body': '<p>Assuming P $\\neq$ NP, NP-complete problems are "hard to solve, but have answers that are easy to check."  Does it make any sense to consider the opposite, that is, problems for which it\'s easy to compute a correct answer, but hard to verify an arbitrary purported solution?</p>\n\n<p>I think such a problem would imply either: </p>\n\n<ol>\n<li><p>Exponentially many "correct" answers for any given input, because otherwise verification could be carried out by simply computing all of the correct answers.</p></li>\n<li><p>Some "correct" answers are easy to compute, but others are difficult to find.</p></li>\n</ol>\n', 'Tags': '<complexity-theory>', 'LastEditorUserId': '903', 'LastActivityDate': '2012-09-20T19:08:06.137', 'CommentCount': '5', 'AcceptedAnswerId': '4620', 'CreationDate': '2012-09-19T20:14:23.607', 'Id': '4619'}{'Body': '<p>Is it possible to reduce MaxUNSAT to <a href="http://en.wikipedia.org/wiki/Maximum_satisfiability_problem" rel="nofollow">MaxSAT</a> in a polynomial way ?</p>\n\n<p>When considering the MaxSAT problem, one often considers also the <code>MinUNSAT</code> problem, which is almost the same. And for a propositional formula <code>f</code> in <a href="http://en.wikipedia.org/wiki/Conjunctive_normal_form" rel="nofollow">CNF</a> it holds:</p>\n\n<pre><code>|f| = MaxSAT(f) + MinUNSAT(f)\n</code></pre>\n\n<p>where <code>|f|</code> is the number of clauses of f.</p>\n\n<p>When considering <code>MaxUNSAT</code> and the corresponding <code>MinSAT</code> problem, the same relationship holds:</p>\n\n<pre><code>|f| = MaxUNSAT(f) + MinSAT(f)\n</code></pre>\n\n<p>Now, I was wondering if there is also a relationship between those two pairs, e.g. to reduce <code>MaxSAT</code> to <code>MaxUNSAT</code> or <code>MinSAT</code> (or the other way round) ?</p>\n\n<p>Unfortunately, I could not figure out one by myself. And maybe there is none ?</p>\n\n<p><strong>Update 1:</strong> Inspired by Yuval Filmus\'s answer, I will give a reduction for my question.</p>\n\n<p><strong>Reduction from MaxUNSAT to its corresponding decision problem:</strong></p>\n\n<p>Let $\\phi = {C_1, ..., C_m}$ a set of clauses over the variables $x_1, ..., x_n$, then it holds:\n$$MaxUNSAT(\\phi) = BinarySearch(0, |\\phi|, MaxUNSAT(\\phi, k) )$$\nwith \n$$\nBinarySearch(start, end, CompareProcedure(k))\n:= \\\\\\text{Searches for the element $e$ between $start$ and $end$ with help of the $CompareProcedure(k)$, so that holds $CompareProcedure(e) = true$ and $CompareProcedures(e+1) = false$ }$$\nand\n$$MaxUNSAT(\\phi, k) := \\exists v\\in\\{0, 1\\}^n:\\sum_{i=1}^m 1 - I_v(C_i) \\geq k$$\nwhere $I_v$ is the interpretation of a propositional formula under assignment $v$.</p>\n\n<p><strong>Reduction from decision problem $MaxUNSAT(\\phi, k)$ to SAT:</strong></p>\n\n<p>One can reduce the devision problem $MaxUNSAT(\\phi, k)$ to the SAT problem by adding blocking variables to each clause and adding a cardinality constraint as propositional formula to limit the number of used clauses with help of the blocking variables.</p>\n\n<p>I can describe this in more detail, if needed.</p>\n\n<p><strong>Conculsion:</strong></p>\n\n<p>One can reduce the MaxUNSAT problem to the SAT problem and then solve the SAT problem with the MaxSAT problem. This is a reduction that works in polynomial time.</p>\n', 'ViewCount': '127', 'Title': 'How to reduce MaxUNSAT to MaxSAT?', 'LastEditorUserId': '2313', 'LastActivityDate': '2012-09-24T21:55:55.063', 'LastEditDate': '2012-09-24T21:55:55.063', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2313', 'Tags': '<complexity-theory><optimization><reductions><satisfiability>', 'CreationDate': '2012-09-20T08:42:23.210', 'Id': '4625'}{'Body': '<p>I have a number of related questions about these two topics.</p>\n\n<p>First, most complexity texts only gloss over the class $\\mathbb{NC}$.  Is there a good resource that covers the research more in depth?  For example, something that discusses all of my questions below.  Also, I\'m assuming that $\\mathbb{NC}$ still sees a fair amount of research due to its link to parallelization, but I could be wrong.    The section in the complexity zoo isn\'t much help.</p>\n\n<p>Second, computation over a semigroup is in $\\mathbb{NC}^1$ if we assume the semigroup operation takes constant time.  But what if the operation does not take constant time, as is the case for unbounded integers?  Are there any known $\\mathbb{NC}^i$-complete problems?</p>\n\n<p>Third, since $\\mathbb{L} \\subseteq \\mathbb{NC}^2$, is there an algorithm to convert any logspace algorithm into a parallel version?</p>\n\n<p>Fourth, it sounds like most people assume that $\\mathbb{NC} \\ne \\mathbb{P}$ in the same way that $\\mathbb{P} \\ne \\mathbb{NP}$.  What is the intuition behind this?</p>\n\n<p>Fifth, every text I\'ve read mentions the class $\\mathbb{RNC}$ but gives no examples of problems it contains.  Are there any?</p>\n\n<p>Finally, <a href="http://cs.stackexchange.com/a/1656/2911">this answer</a> mentions problems in $\\mathbb{P}$ with sublinear parallel execution time.  What are some examples of these problems?  Are there other complexity classes that contain parallel algorithms that are not known to be in $\\mathbb{NC}$?</p>\n', 'ViewCount': '228', 'Title': 'Some questions on parallel computing and the class NC', 'LastEditorUserId': '2911', 'LastActivityDate': '2012-09-24T15:39:26.497', 'LastEditDate': '2012-09-21T19:18:26.083', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '2911', 'Tags': '<complexity-theory><reference-request><parallel-computing><complexity-classes>', 'CreationDate': '2012-09-21T18:50:22.743', 'FavoriteCount': '1', 'Id': '4659'}{'ViewCount': '292', 'Title': 'complexity of decision problems vs computing functions', 'LastEditDate': '2012-09-22T17:24:26.267', 'AnswerCount': '2', 'Score': '-8', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': u'<p>this is an area that admittedly Ive always found subtle about CS and occasionally trips me up, and clearly others. recently on tcs.se a user asked an apparently innocuous question about <a href="http://cstheory.stackexchange.com/questions/12682/is-the-n-queens-problem-np-hard">N-Queens being NP hard</a>, but it got downvoted there &amp; goes unanswered because the audience felt it was poorly phrased. </p>\n\n<p>the issue seems to be that some questions in CS have to be phrased as decision problems to measure their complexity, and it is not always obvious how to do that. also other questions are studied from the pov of computing a function with integer or string inputs and outputs, in which case eg their time or space complexity can be studied. for some NP complete problems eg SAT its proven that the decision problem (eg determining whether an answer exists) is roughly equivalent in time/space complexity to solving the function problem (finding a satisfying assignment), but of course thats not always the case.</p>\n\n<p>moreover much of CS theory is focused on NP complete problems [esp that presented to undergraduates in textbooks], which are nec. decision problems, which might lead to a mistaken impression that other types of problem formats are not as central to the theory. also NP complete is sometimes shown in a hierarchy that includes other complexity classes such as PSpace which can be used to measure <em>function</em> complexity in addition to <em>decision</em> complexity. </p>\n\n<p>think that the N-Queens example question &amp; related comments also shows that a bunch of related questions about the same problem in this case N-Queens can vary widely/dramatically in their complexity depending on slight variations of the phrasing. eg in this case:</p>\n\n<ul>\n<li>is there a solution to the N-Queens problem on a $n \\times n$ chessboard? this problem turns out to have O(1) time complexity\u2014 the answer is always Y.</li>\n<li>what is the complexity of finding a solution to the N-Queens problem given $n$ as the input referring to a square $n \\times n$ chessboard? as that question notes in comments by Peter Shor, an advanced and subtle thm from CS called "mahaney\'s" thm applies because it might refer to a "sparse input". also JeffE found a paper that says its in P.</li>\n<li>there is an NP complete or NP hard version of this problem if the squares are <em>irregularly specified</em> as the input. ie some kind of input that specifies the square allowed/unallowed locations (havent looked up the details).</li>\n</ul>\n\n<p><hr>\nwhile advanced theorists may find all this verging on trivial, feel its a legitimate area of focus which sometimes gets glossed over in theoretical treatments. my question</p>\n\n<blockquote>\n  <p>is there a reference somewhere that points/sorts out these kinds of subtleties/difficulties in formulating CS problems?</p>\n</blockquote>\n\n<p>it would be helpful if it also talks about how the issue relates to the complexity hierarchy. know that this is covered in some textbooks, but even then havent seen a nice concise discussion of that and wonder if anyone has a favorite ref for this type of issue. (suppose Garey and Johnson might have some discussion of this although dont have a copy close to check.)</p>\n\n<p>am not specifically focused on the N-Queens problem with this question, but an answer that sketches out the distinctions wrt N-Queens might be helpful. [eg an expanded explanation of Shor\'s comment how Mahaneys thm applies, the irregular board construction input format, etc]</p>\n\n<p>fyi here are two other example problems Ive noticed that can vary widely in complexity depending on various restrictions on the input</p>\n\n<p>[1] <a href="http://cs.stackexchange.com/questions/701/decidable-restrictions-of-the-post-correspondence-problem/4638">Post correspondence problem.</a> it can go from undecidable to NP complete or even in P depending on various restrictions on the solution.</p>\n\n<p>[2] Finding whether a regular expression is equivalent to all strings over the alphabet. with squaring this was shown to be in ExpSpace by Stockmeyer/Meyer, but restrictions on length lead to it to being in NP complete or P. see eg Chee Yap, <a href="http://cs.nyu.edu/yap/book/complexity/" rel="nofollow">Intro to Complexity classes</a>, ch5 on complete problems.</p>\n', 'ClosedDate': '2014-04-29T11:56:36.853', 'Tags': '<algorithms><complexity-theory><reference-request><time-complexity><np-complete>', 'LastEditorUserId': '699', 'LastActivityDate': '2012-10-01T00:23:22.727', 'CommentCount': '7', 'AcceptedAnswerId': '4674', 'CreationDate': '2012-09-22T16:57:55.790', 'Id': '4667'}{'Body': '<p>If there is someone can prove that the problem "is P equals to NP?" is a NP-COMPLETE problem, what we can conclude from this?</p>\n', 'ViewCount': '198', 'Title': u'If the \u201cis P equals to NP?\u201d is a NP-COMPLETE, what does it tell us?. Some conclusions?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-09-26T22:18:03.690', 'LastEditDate': '2012-09-22T19:13:41.907', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '-1', 'OwnerDisplayName': 'TesterNP', 'PostTypeId': '1', 'Tags': '<complexity-theory><p-vs-np>', 'CreationDate': '2012-09-21T18:41:33.697', 'Id': '4671'}{'Body': "<p>Let's say $F$ is an oracle for a problem in  $\\mathbb{NP}$, but I cannot call this oracle with any input instance.  Instead, whenever I call $F$ I get returned a random instance and solution.  Thus, I know that $F$ is in fact capable of solving arbitrary $\\mathbb{NP}$-hard problems, I just can't specify which one I want it to solve.</p>\n\n<p>Is it possible to use such an oracle to solve an $\\mathbb{NP}$-complete problem faster?  My gut says no because the naive use of the oracle still requires $O(2^n)$ time by calling the oracle enough to check every solution.  I just can't think of a way to prove this.</p>\n", 'ViewCount': '124', 'Title': "Is an oracle ever useful if you can't control the input instances?", 'LastActivityDate': '2012-10-07T21:01:23.037', 'AnswerCount': '2', 'CommentCount': '5', 'AcceptedAnswerId': '4934', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2911', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2012-09-24T15:34:17.920', 'FavoriteCount': '1', 'Id': '4717'}{'Body': '<p>In question <a href="http://cs.stackexchange.com/questions/4625/how-to-reduce-maxunsat-to-maxsat">How to reduce MaxUNSAT to MaxSAT?</a> I was asking, how to reduce the MaxUNSAT problem to MaxSAT. With help of the given answer I could give a polynomial reduction : $MaxUNSAT \\leq decisionProblemMaxUNSAT \\leq SAT \\leq MaxSAT$.</p>\n\n<p><strong>Question:</strong> Is there a more direct reduction without much overhead from MaxUNSAT to MaxSAT (or to minUNSAT)?</p>\n\n<p>Because the two problems are very similiar, it seems there is a more direct reduction, but I could not figure out one.</p>\n\n<p>Something like $MaxUNSAT(\\phi) = MaxSAT(\\neg\\phi)$ (which does not work).</p>\n', 'ViewCount': '61', 'Title': 'How to reduce MaxUNSAT to MaxSAT in a (almost) direct way?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-03T21:41:01.693', 'LastEditDate': '2012-09-24T22:21:34.283', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2313', 'Tags': '<complexity-theory><optimization><reductions><satisfiability>', 'CreationDate': '2012-09-24T21:59:46.447', 'Id': '4724'}{'ViewCount': '155', 'Title': 'Reconstructing a data table from cross-tabulation frequencies', 'LastEditDate': '2013-04-05T21:42:23.620', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2847', 'FavoriteCount': '1', 'Body': '<p>Say there is a data table $D$ that we cannot see, with $M$ columns. We are given exact <a href="https://en.wikipedia.org/wiki/Cross_tabulation" rel="nofollow">cross-tabulation</a> frequencies for all ${M \\choose 2}$ pairs of columns, that is how often each combination of two values occurs.</p>\n\n<p>From the cross-tabulations, we can derive a set of possible rows $R$ of $D$ and maximum frequencies for each possible row.</p>\n\n<p>How can we reconstruct the original table $D$? If there is not enough information to do so, how can we construct a possible table $D\'$ that has the same cross-tab frequencies? In this case, is it possible to count the number of possible tables?</p>\n\n<p>(Edit: As Vor noted, define a table as an unordered collection of rows. A permutation of the rows of a table yields the same table.)</p>\n\n<hr>\n\n<p>For example, if $D$ has rows:</p>\n\n<pre><code>X  A  j\nY  A  k\nX  B  j\nX  B  j\n</code></pre>\n\n<p>We have three sets of cross-tab frequencies:</p>\n\n<pre><code>X  A  1\nX  B  2\nY  A  1\nY  B  0\n\nX  j  3\nX  k  0\nY  j  0\nY  k  1\n\nA  j  1\nA  k  1\nB  j  2\nB  k  2\n</code></pre>\n\n<p>I would like an algorithm which will take the cross-tab frequencies as input and output the original table or a possible original table.</p>\n', 'Tags': '<algorithms><complexity-theory><combinatorics><statistics>', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-04-07T14:24:45.853', 'CommentCount': '5', 'AcceptedAnswerId': '11102', 'CreationDate': '2012-09-28T20:16:24.500', 'Id': '4784'}{'ViewCount': '90', 'Title': 'Hardness and directions of reductions', 'LastEditDate': '2012-10-01T21:07:30.707', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2826', 'FavoriteCount': '1', 'Body': "<p>Let us say we know that problem A is hard, then we reduce A to the unknown problem B to prove B is also hard.</p>\n\n<p>As an example: we know 3-coloring is hard. Then we reduce 3-coloring to 4-coloring. By conflating one of the colors in the 3-coloring you have a 4-coloring, ergo 4-coloring is hard.</p>\n\n<p>That's the how. But why is this a proof that 4-coloring is hard? Is it that you can use the solution to the 4-coloring problem to solve the 3-coloring problem? If so, how? If not, why is it a valid proof?</p>\n\n<p>Bonus q: Must the polynomial reductions be able to go in both ways?</p>\n\n<p>Edit: if you would be able to explain why this is so by an example you would do the internet a favor. I couldn't find this explained in a concrete way anywhere.</p>\n", 'Tags': '<complexity-theory><np-complete><reductions>', 'LastEditorUserId': '2826', 'LastActivityDate': '2012-10-01T21:42:20.007', 'CommentCount': '2', 'AcceptedAnswerId': '4836', 'CreationDate': '2012-10-01T20:36:15.753', 'Id': '4835'}{'Body': u'<p>From <a href="http://en.wikipedia.org/wiki/Reduction_%28complexity%29" rel="nofollow">Wikipedia</a>:</p>\n\n<blockquote>\n  <p>Given two subsets A and B of N and a set of functions F from N to N\n  which is closed under composition, A is called reducible to B under F\n  if $$\n     \\exists f \\in F \\mbox{ . } \\forall x \\in \\mathbb{N} \\mbox{ . } x \\in A \\Leftrightarrow f(x) \\in B $$ We write $$\n     A \\leq_{F} B $$ Let S be a subset of P(N) and \u2264 a reduction, then S is called closed under \u2264 if $$\n     \\forall s \\in S \\mbox{ . } \\forall A \\in P(\\mathbb{N}) \\mbox{ . } A \\leq s \\Rightarrow A \\in S $$ A subset A of N is called hard for S\n  if $$\n     \\forall s \\in S \\mbox{ . } s \\leq A $$ A subset A of N is called complete for S if A is hard for S and A is in S.</p>\n</blockquote>\n\n<p>I am trying to relate the above definitions to those for problems: problem A can be reduced to problem B, a set of problems are NP-hard, a set of problems are NP-complete. But I don\'t know how to relate. I think one link I am missing is to see how a subset of problem can be seen as a subset of $\\mathbb{N}$?</p>\n', 'ViewCount': '266', 'Title': 'Understanding the definition of reduction', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-03T20:37:42.277', 'LastEditDate': '2012-10-03T20:37:42.277', 'AnswerCount': '1', 'CommentCount': '10', 'AcceptedAnswerId': '4851', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<complexity-theory><terminology><reductions>', 'CreationDate': '2012-10-03T13:27:53.813', 'Id': '4850'}{'Body': '<p>From <a href="http://en.wikipedia.org/wiki/Computational_complexity_theory#Complexity_classes" rel="nofollow">Wikipedia</a>:</p>\n\n<blockquote>\n  <p>The type of computational problem: <strong>The most commonly used problems are\n  decision problems</strong>. However, complexity classes can be defined based on\n  function problems, counting problems, optimization problems, promise\n  problems, etc.</p>\n</blockquote>\n\n<p>I also saw the definitions of NP-complete, NP-hard, NP, ..., are defined for decision problems only. I wonder why that is the case?</p>\n\n<p>Is it because any other problem can be equivalently converted to a decision problem? </p>\n', 'ViewCount': '213', 'Title': 'Why are decision problems commonly used in complexity theory?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-08T14:42:16.287', 'LastEditDate': '2012-10-05T16:14:22.417', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '4877', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<complexity-theory><terminology>', 'CreationDate': '2012-10-04T18:03:40.670', 'Id': '4874'}{'Body': '<p>From <a href="http://en.wikipedia.org/wiki/Computational_complexity_theory" rel="nofollow">Wikipedia</a></p>\n\n<blockquote>\n  <p><strong>a computational problem</strong> is understood to be a task that is in principle amenable to being solved by a computer (i.e. the problem can\n  be stated by a set of mathematical instructions). Informally, a\n  computational problem consists of <strong>problem instances</strong> and <strong>solutions</strong> to\n  these problem instances. For example, primality testing is the problem\n  of determining whether a given number is prime or not. The instances\n  of this problem are natural numbers, and the solution to an instance\n  is yes or no based on whether the number is prime or not.</p>\n  \n  <p>... A key distinction between analysis of algorithms and computational\n  complexity theory is that the former is devoted to <strong>analyzing the\n  amount of resources needed by a particular algorithm to solve a\n  problem</strong>, whereas the latter asks a more general question about <strong>all\n  possible algorithms that could be used to solve the same problem</strong>.</p>\n</blockquote>\n\n<p>So a problem can be solved by multiple algorithms. </p>\n\n<p>I was wondering if an algorithm can solve different problems, or can only solve one problem? Note that I distinguish a problem and its instances as in the quote.</p>\n', 'ViewCount': '96', 'Title': 'Relation between problems and algorithms', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-05T13:07:38.853', 'LastEditDate': '2012-10-05T11:02:18.093', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '4885', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<algorithms><complexity-theory><terminology>', 'CreationDate': '2012-10-05T04:36:59.257', 'Id': '4880'}{'Body': '<p>If I understand correctly, the complexity of solving a computational problem is defined in terms of which instance $I$ of the problem, what size $n$ of the problem instance, and what algorithm $A$ for solving the problem instance.</p>\n\n<p>Is the complexity of the problem at a given size $n$ of the problem instance defined as\n$$\n\\min_A \\max_{I\\in \\{\\text{instances of size }n\\}} \\text{complexity}(A,I,n)?\n$$\nNote that the solution to the above optimization $A^*(n)$ and $I^*(n)$ are both functions of instance size $n$.</p>\n\n<p>Or is the complexity of the problem defined for some same algorithm for all the problem instances and all sizes of the problem instances?</p>\n\n<p>Or is the complexity of the problem defined for some same instance for all the algorithms that solve the problem and all the problem instance sizes?</p>\n', 'ViewCount': '280', 'Title': 'Meaning of complexity of a computational problem', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-08T08:19:35.547', 'LastEditDate': '2012-10-05T13:42:44.587', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '4886', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<complexity-theory><terminology>', 'CreationDate': '2012-10-05T13:06:41.417', 'Id': '4884'}{'Body': '<p>I am trying to understand different interactive proof systems. Is there a typical problem for the complexity class MA (like graph-nonisomorphism is for AM)? Is there a problem in MA but not known to be in NP or BPP?</p>\n\n<p>Is there a reason that most books discuss AM in detail while merely glossing over MA, which seems to be the more natural proof system at least to me?</p>\n', 'ViewCount': '114', 'Title': '"Essential" problem for MA', 'LastEditorUserId': '41', 'LastActivityDate': '2013-04-03T23:56:22.440', 'LastEditDate': '2012-10-06T03:30:26.930', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '984', 'Tags': '<complexity-theory><interactive-proof-systems>', 'CreationDate': '2012-10-05T23:32:59.910', 'FavoriteCount': '1', 'Id': '4896'}{'Body': "<p><strong>Can I always increase the complexity of a problem via polynomial reduction?</strong> (in which case '<em>reduction</em>' is really a misnomer) For example, if I have a classic P problem (say, finding the smallest element in an array, by iterating through and making comparisons with the smallest value found thus far), what would be a corresponding problem in NP-complete (obtained via polynomial reduction)? Or, would it be possible to polynomially reduce a constant time (worst case) algorithm into a polynomial time algorithm (basically performing unnecessary executions for all n of the input for nothing)? </p>\n\n<p>As a side request, I'm looking for a basic reference that deals with how one problem (in P or NP-complete) can be reduced (in polynomial time) to a problem in (P or NP-complete). Most of the things I found online are beyond scope or vague. I'm looking for an easy way to figure out whether a certain Problem A (in P or NP-complete) can be polynomially reduced to a Problem B (in P or NP-complete).</p>\n", 'ViewCount': '326', 'Title': 'Clarifications on polynomial reducibility for problems in P and NP-complete', 'LastEditorUserId': '2835', 'LastActivityDate': '2012-10-08T22:46:53.090', 'LastEditDate': '2012-10-08T21:52:57.107', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '4961', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2835', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-10-08T21:45:59.520', 'Id': '4960'}{'ViewCount': '815', 'Title': 'What is the relationship between NP/NP-Complete/NP-Hard to time complexity?', 'LastEditDate': '2012-10-11T07:36:39.490', 'AnswerCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2835', 'FavoriteCount': '3', 'Body': "<p>I'm familiar with a few problems of each class and even though the definitions are based on sets and polynomial reducibility, I see a pattern with time complexity. NP problems appear to be $O(2^n)$ (minus the P problems of course), and NP-hard problems seem to be worse: $n^n$ or $n!$ (Chess, TSP). Is this a misleading interpretation?</p>\n", 'Tags': '<complexity-theory><terminology><time-complexity><np-hard>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-12T04:51:51.627', 'CommentCount': '2', 'AcceptedAnswerId': '5011', 'CreationDate': '2012-10-11T05:29:06.593', 'Id': '5009'}{'ViewCount': '2996', 'Title': 'How can I reduce Subset Sum to Partition?', 'LastEditDate': '2012-10-16T18:57:03.110', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '3048', 'FavoriteCount': '4', 'Body': '<p>Maybe this is quite simple but I have some trouble to get this reduction. I want to reduce <a href="http://en.wikipedia.org/wiki/Subset_sum_problem" rel="nofollow">Subset Sum</a> to  <a href="http://en.wikipedia.org/wiki/Partition_problem" rel="nofollow">Partition</a> but at this time I don\'t see the relation!</p>\n\n<p>Is it possible to reduce this problem using a Levin Reduction ?</p>\n\n<p>If you don\'t understand write for clarification!</p>\n', 'Tags': '<complexity-theory><np-complete><reductions>', 'LastEditorUserId': '3048', 'LastActivityDate': '2013-04-20T02:41:52.543', 'CommentCount': '0', 'AcceptedAnswerId': '6113', 'CreationDate': '2012-10-16T18:04:04.593', 'Id': '6111'}{'Body': u'<p>Suppose I have a formula, and a lying witness is attempting to make it evaluate to False.</p>\n\n<blockquote>\n  <p>Given a <a href="http://en.wikipedia.org/wiki/Truth_table" rel="nofollow">truth table</a> $c(F_1,\u2026, F_n)$, how could you force a lying\n   witness to contradict herself?</p>\n</blockquote>\n\n<p>A contradiction is simply when the witness\'s statements are logically impossible; i.e. that $x_1,x_2$ are each True, but $x_1 \\space AND\\space x_2$ is False.</p>\n\n<ul>\n<li>How can I characterize the set of all formula for which I force the witness to contradict herself?</li>\n<li>What complexity class does this problem fall in?</li>\n</ul>\n', 'ViewCount': '252', 'Title': 'Given a truth table, force a contradiction', 'LastEditorUserId': '4304', 'LastActivityDate': '2012-12-26T07:32:37.003', 'LastEditDate': '2012-11-26T07:05:41.493', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4222', 'Tags': '<complexity-theory><computability><np-complete><closure-properties><decision-problem>', 'CreationDate': '2012-10-16T23:32:35.117', 'FavoriteCount': '1', 'Id': '6116'}{'Body': '<p>Does there exist a procedure that determines if a polytime machine prints a certain string, and does so in less time than the machine itself takes to run?</p>\n\n<p>Define a machine $a$ that analyzes another machine $b$, input $i$, and string $r$:</p>\n\n<p>$a(b,i,r) = b(i) \\text{ prints } r$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $[T_b = O(n^k), k &gt;= 2]$</p>\n\n<p>Is there an $a$ with run-time $T_a \\in o(T_b)$ on all $b,i,r$?</p>\n', 'ViewCount': '89', 'Title': 'determine if a machine prints a certain string in less time than it takes to run the machine itself?', 'LastEditorUserId': '4223', 'LastActivityDate': '2012-11-29T23:05:04.600', 'LastEditDate': '2012-10-17T23:41:16.120', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4223', 'Tags': '<complexity-theory><time-complexity><turing-machines>', 'CreationDate': '2012-10-17T04:15:29.833', 'Id': '6117'}{'ViewCount': '123', 'Title': 'Complement of HAMPATH', 'LastEditDate': '2012-10-17T20:21:48.000', 'AnswerCount': '1', 'Score': '3', 'OwnerDisplayName': 'pnp', 'PostTypeId': '1', 'OwnerUserId': '4190', 'FavoriteCount': '1', 'Body': '<p>Is the complement of the <a href="http://en.wikipedia.org/wiki/Hamiltonian_path" rel="nofollow">Hamiltonian Path problem</a> known to be in $\\mathsf{NP}$? I could not find explanations saying that it is, but then neither were there any claims saying that it is <strong>not</strong> in $\\mathsf{NP}$.</p>\n', 'Tags': '<complexity-theory><decision-problem>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-10-17T20:28:58.323', 'CommentCount': '0', 'AcceptedAnswerId': '6135', 'CreationDate': '2012-10-17T12:01:25.203', 'Id': '6128'}{'Body': "<p>Are there any superpolynomial time set $\\mathsf{SP}$ in between $\\mathsf{P}$ and $\\mathsf{EXPTIME}$ such that the problem $\\mathsf{SP}=\\mathsf{NSP}$ has a known answer?</p>\n\n<p><strong>UPDATE</strong>: It must be defined by time and strictly between $\\mathsf{P}$ and $\\mathsf{EXPTIME}$. I was wondering, what if Cobham's thesis is wrong and we are fighting with $\\mathsf{P=NP}$ because of that thesis when the really useful question is another one? Maybe one that's even already answered?</p>\n", 'ViewCount': '81', 'Title': 'Superpolynomial time set such that SP=NSP is known?', 'LastActivityDate': '2012-10-17T18:28:03.410', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'OwnerDisplayName': 'Ignacio Calvo', 'PostTypeId': '1', 'Tags': '<complexity-theory><nondeterminism>', 'CreationDate': '2012-10-16T16:28:10.287', 'Id': '6132'}{'Body': "<p>I am not talking about NP-indeterminate class because those problems have to be shown to not exist either in P or NP-complete class and existence of such problems proves P!=NP. I am interested to know if we are half-way there i.e. problems that have been proven to be not NP-complete but are in NP but we don't know if they are in P as well.</p>\n\n<p>What about such problems whose deterministic polynomial solution was found only recently? Was primality testing such a problem?</p>\n\n<p>I would appreciate if the answers are given for someone like me who only has a high level understanding of computational complexity theory.</p>\n", 'ViewCount': '103', 'Title': 'Are there are problems in NP that have been shown to be not NP-complete but it is still not known if they are in P or not?', 'LastEditorUserId': '874', 'LastActivityDate': '2012-10-17T20:27:34.330', 'LastEditDate': '2012-10-17T19:58:43.487', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'OwnerDisplayName': 'Shimano', 'PostTypeId': '1', 'OwnerUserId': '4247', 'Tags': '<complexity-theory>', 'CreationDate': '2012-10-17T19:27:32.857', 'Id': '6134'}{'Body': '<p>Least cost travel by intermixing different airline routes having linear discount functions:</p>\n\n<p>Lowest air fare route chosen by mixing different routes provided by different airline having different discount functions (like some airline can give 25% discount if fare crosses $5k) so that total cost of travel is minimized after intermixing of different airline routes</p>\n\n<p>This is a graph problem. Let $E(k)$ be the set of edges/routes \nflown by $k$-th airline, also given cost of travel associated with \neach edge.</p>\n\n<p>For $n$ airlines we have $n$ sets of edges i.e $E(k)=\\{\\mbox{some edges}\\}$ for \nall $k=1.. n$. We need to find the route from given source $s$ to given destination $t$\nsuch that we end up paying least fare among all possible \nroutes. There is no restriction on number of edges in a route.</p>\n\n<p>This is an NP-hard problem. How can I prove it?</p>\n', 'ViewCount': '138', 'Title': 'Proving following problem NP Hard using known NP Hard partition problem', 'LastEditorUserId': '140', 'LastActivityDate': '2012-10-22T08:13:56.217', 'LastEditDate': '2012-10-22T06:45:28.780', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'OwnerDisplayName': 'abhishek', 'PostTypeId': '1', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2012-10-21T09:33:47.030', 'FavoriteCount': '1', 'Id': '6218'}{'Body': "<p>A threshold gate implementing a linear threshold function on $n$ boolean inputs $x_1, x_2 \\ldots, x_n$ is given by the equation:\n$w_1 x_1 + w_2 x_2 + \\ldots, w_n x_n \\ge t$\nwhere $w_1, \\ldots, w_n, t \\in \\mathbb{R}$. The $w_i$'s are called the weights of the threshold function and $t$ is called the threshold, and naturally, the gate fires a $1$ on an input $x$ if the weighted sum given by the equation above exceeds $t$. </p>\n\n<p>Now, almost everywhere in the literature on threshold circuits, I encounter this fact (which I am guessing, is folklore since I couldn't find a proof anywhere): The $w_i$'s in the linear equation above can be made integers (on $n \\log{n}$ bits), and a threshold circuit made up of these gates will still compute whatever was possible with real weights. I have given this some thought, and I think it must be a simple trick, but I have failed to obtain a proof of this fact. Can somebody help or provide me with a reference? (the only reference I could find was a text by Muroga, which I couldn't procure)</p>\n", 'ViewCount': '59', 'Title': 'Assumption on weights in threshold circuits', 'LastActivityDate': '2012-10-30T14:56:00.480', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6272', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '639', 'Tags': '<complexity-theory><circuits>', 'CreationDate': '2012-10-23T10:38:02.097', 'Id': '6259'}{'Body': '<blockquote>\n  <p>$L_1$ and $L_2$ are two languages defined on the alphabet $\\sum$.\n  $L_1$ is reducible to $L_2$ in polynomial time. Which of the following\n  cannot be true?</p>\n  \n  <ul>\n  <li>$L_1 \\in P$ and $L_2$ is finite</li>\n  <li>$L_1 \\in NP$ and $L_2 \\in P$</li>\n  <li>$L_1$ is undecidable and $L_2$ is decidable</li>\n  <li>$L_1$ is recursively enumerable and $L_2$ is recursive</li>\n  </ul>\n</blockquote>\n\n<p>My reasoning is as follow,</p>\n\n<p>If $A \\le_p B$, and $B \\in P$, then $A$ can be reduced to $B$ in polynomial time and solved in polynomial time making $A \\in P$. Thus I initially figured the 2nd choice as false and thus the right answer.</p>\n\n<p>However using the same argument on mapping reducibility, the 3rd choice seems to be false as well. The fourth choice is the same as the third one.</p>\n\n<p>I was unsuccessful in reasoning anything about the 1st choice.</p>\n\n<p>To put my above arguments in context, I am learning about theory of computation and have just about skimmed the surface of computability and complexity theory. Helo me out.</p>\n', 'ViewCount': '354', 'Title': 'Polynomial time reducibility', 'LastActivityDate': '2012-10-25T08:36:57.790', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '6307', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2980', 'Tags': '<complexity-theory><reductions><complexity-classes>', 'CreationDate': '2012-10-24T13:41:22.653', 'Id': '6291'}{'ViewCount': '194', 'Title': 'Algorithmic consequences of algebraic formula for partition function?', 'LastEditDate': '2012-10-27T11:21:20.700', 'AnswerCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '667', 'FavoriteCount': '2', 'Body': '<p><a href="http://www.aimath.org/news/partition/brunier-ono">Bruinier and Ono</a> have found an algebraic formula for the <a href="http://en.wikipedia.org/wiki/Partition_function_%28number_theory%29#Partition_function">partition function</a>, which was widely reported to be a breakthrough. I am unable to understand the paper, but does it have any algorithmic consequences for fast computation of the partition function?</p>\n', 'Tags': '<algorithms><complexity-theory><number-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-27T15:47:28.097', 'CommentCount': '2', 'AcceptedAnswerId': '6338', 'CreationDate': '2012-10-26T11:33:57.743', 'Id': '6323'}{'Body': '<p>By making use of the fact that sorting $n$ numbers requires \n$\\Omega(n \\log n)$ steps for any optimal algorithm (which uses \'comparison\' for sorting), how can I prove that finding the <a href="http://en.wikipedia.org/wiki/Convex_hull" rel="nofollow">convex-hull</a> of $n$ points is bounded by $\\Omega (n \\log n)$ steps?</p>\n', 'ViewCount': '254', 'Title': 'Lower bound for Convex hull', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-29T18:56:12.077', 'LastEditDate': '2012-10-29T18:56:12.077', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4190', 'Tags': '<complexity-theory><computational-geometry><lower-bounds>', 'CreationDate': '2012-10-29T07:20:12.997', 'Id': '6369'}{'ViewCount': '2657', 'Title': 'Proving DOUBLE-SAT is NP-complete', 'LastEditDate': '2012-10-29T11:12:42.877', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4190', 'FavoriteCount': '0', 'Body': '<p>The well known SAT problem is defined <a href="http://en.wikipedia.org/wiki/Boolean_satisfiability_problem">here</a> for reference sake. </p>\n\n<p>The DOUBLE-SAT problem is defined as</p>\n\n<p>$\\qquad \\mathsf{DOUBLE\\text{-}SAT} = \\{\\langle\\phi\\rangle \\mid \\phi \\text{ has at least two satisfying assignments}\\}$</p>\n\n<p>How do we prove it to be NP-complete? </p>\n\n<p>More than one way to prove will be appreciated. </p>\n', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-29T11:16:44.353', 'CommentCount': '0', 'AcceptedAnswerId': '6373', 'CreationDate': '2012-10-29T09:04:33.973', 'Id': '6371'}{'Body': '<p>We know that the clique problem is NP-complete. Is the restriction of the problem to bipartite graphs or planar graphs still NP-complete?</p>\n', 'ViewCount': '358', 'Title': 'Is the clique problem NP-complete also on bipartite or planar graphs?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-30T00:00:07.960', 'LastEditDate': '2012-10-29T21:57:01.987', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1402', 'Tags': '<complexity-theory><graph-theory><graphs><np-complete>', 'CreationDate': '2012-10-29T21:24:06.577', 'Id': '6375'}{'Body': '<p>Does anybody know a good definition of 2 decision / optimization problems being equivalent? </p>\n\n<p>I am asking since for example allowing polynomial time computations any 2 problems in NP could be considered equivalent.</p>\n', 'ViewCount': '165', 'Title': 'When are 2 decision/optimization problems equivalent?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-31T09:52:13.867', 'LastEditDate': '2012-10-31T09:52:13.867', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '6394', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4404', 'Tags': '<complexity-theory><terminology><undecidability>', 'CreationDate': '2012-10-30T18:42:29.597', 'Id': '6393'}{'ViewCount': '199', 'Title': 'Modification of Hamilton Path', 'LastEditDate': '2012-11-03T04:47:29.347', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4436', 'FavoriteCount': '1', 'Body': '<p>Although I know that the <a href="http://en.wikipedia.org/wiki/Hamiltonian_path_problem" rel="nofollow">Hamilton Path problem</a> is ${\\sf NP}$-complete, I think the following variant can be solved in polynomial time:</p>\n\n<blockquote>\n  <p>Given a planar graph with vertex set $V$, edge set $E$, start node $S$ and target node $F$,\n  our task is to find the Hamiltonian path from $S$ to $F$ or write that the path doesn\'t exist.</p>\n  \n  <p><em>Last condition</em>: In the path, in addition to selecting the directly connected vertices, \n  we can also choose those connected to exactly one neighbor.</p>\n  \n  <p><strong>Edit</strong>: The degree of any vertex is at most four ($\\deg(v_i) \\le 4$).</p>\n</blockquote>\n\n<p>Does anyone have any ideas how to prove that this can be solved in polynomial time? </p>\n\n<p>It can be hard to understand, so I will give an example:  </p>\n\n<p><img src="http://i.stack.imgur.com/meTSp.png" alt="Examples"></p>\n\n<p>In the left example, for $S=1,F=12$, the solution is the path $1, 11, 8, 7, 5, 9, 2, 10, 4, 6, 3, 12$.  </p>\n\n<p>In the right example, for $S=1,F=15$, there is no Hamiltonian path.</p>\n', 'Tags': '<algorithms><complexity-theory><graph-theory><np-hard>', 'LastEditorUserId': '4304', 'LastActivityDate': '2012-11-03T16:06:59.817', 'CommentCount': '9', 'AcceptedAnswerId': '6448', 'CreationDate': '2012-11-02T10:23:44.050', 'Id': '6446'}{'Body': "<p>I ran into the following problem:</p>\n\n<p>Given a directed acyclic graph with real-valued edge weights, and two vertices s and t, compute the minimum s-t cut.</p>\n\n<p>For general graphs this is NP-hard, since one can trivially reduce max-cut to it by simply reversing the edge weights (correct me if I'm wrong).</p>\n\n<p>What is the situation with DAGs? Can min-cut (or max-cut) be solved in polynomial time? Is it NP-hard and, if so, are there any known approximation algorithms?</p>\n\n<p>I tried to find work on this but wasn't able to (maybe I'm just using wrong keywords in my searches), so I was hoping somebody may know (or find) something about this.</p>\n", 'ViewCount': '521', 'Title': 'Minimum s-t cut in weighted directed acyclic graphs with possibly negative weights', 'LastActivityDate': '2012-11-05T21:05:51.660', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '6498', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '691', 'Tags': '<algorithms><complexity-theory><graph-theory><weighted-graphs>', 'CreationDate': '2012-11-04T18:19:49.463', 'Id': '6476'}{'ViewCount': '244', 'Title': 'Reduce the following problem to SAT', 'LastEditDate': '2012-11-07T10:26:52.693', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1718', 'FavoriteCount': '3', 'Body': "<p>Here is the problem. Given $k, n, T_1, \\ldots, T_m$, where each $T_i \\subseteq \\{1, \\ldots, n\\}$. Is there a subset $S \\subseteq \\{1, \\ldots, n\\}$ with size at most $k$ such that $S \\cap T_i \\neq \\emptyset$ for all $i$? I am trying to reduce this problem to SAT. My idea of a solution would be to have a variable $x_i$ for each of 1 to $n$. For each $T_i$, create a clause $(x_{i_1} \\vee \\cdots \\vee x_{i_k})$ if $T_i = \\{i_1, \\ldots, i_k\\}$. Then and all these clauses together. But this clearly isn't a complete solution as it does not represent the constraint that $S$ must have at most $k$ elements. I know that I must create more variables, but I'm simply not sure how. So I have two questions:</p>\n\n<ol>\n<li>Is my idea of solution on the right track?</li>\n<li>How should the new variables be created so that they can be used to represent the cardinality $k$ constraint?</li>\n</ol>\n", 'Tags': '<complexity-theory><reductions><np-hard>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-07T16:44:49.113', 'CommentCount': '1', 'AcceptedAnswerId': '6522', 'CreationDate': '2012-11-07T02:59:38.507', 'Id': '6521'}{'ViewCount': '610', 'Title': 'NP-Completeness - Proof by Restriction', 'LastEditDate': '2012-11-07T21:45:31.310', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4481', 'FavoriteCount': '1', 'Body': '<p>I\'m reading Garey &amp; Johnsons <em>"Computers and Intractability"</em> and I\'m at the part <em>"Some techniques for solving NP-Completeness"</em>. Here\'s the text about Proof by Restriction:</p>\n\n<blockquote>\n  <p>Proof by restriction is the simplest, and perhaps most frequently\n  applicable, of our three proof types. An NP-completeness proof by\n  restriction for a given problem $L \\in NP$ consists simply of showing that\n  $L$ contains a known NP-complete problem $L\'$ as a special case. The heart\n  of such a proof lies in the specification of the additional\n  restrictions to be placed on the instances of $L$ so that the resulting\n  restricted problem will be identical to $L\'$. We do not require that the\n  restricted problem and the known NP-complete problem be exact\n  duplicates of one another, but rather that there be an "obvious"\n  one-to-one correspondence between their instances that preserves "yes"\n  and "no" answers."</p>\n</blockquote>\n\n<p>And I\'m trying to learn this technique by example, but need some help.</p>\n\n<p>(If you have the book, my example is on page 65, 27th printing)</p>\n\n<p>They prove that <em>Multiprocessor Scheduling</em> is NP-complete with the following proof:</p>\n\n<p>(Paraphrasing):</p>\n\n<blockquote>\n  <p>Restrict to PARTITION by allowing only instances in which $m = 2$ and $D$\n  $=$ half the total sum of the "lengths".</p>\n</blockquote>\n\n<p>Here $m$ is the number of processors and $D$ is the maximum allowed sum of "lengths" per processor. </p>\n\n<p>This is obviously a special case of multiprocessor scheduling which is solvable by solving the PARTITION problem, and there\'s no confusion there.</p>\n\n<p>But, I\'m not sure why this proof holds. </p>\n\n<p>Excerpt from above: <em>"The heart of such a proof lies in the specification of additional restrictions to be placed on the instances of $L$ so that the resulting restricted problem will be identical to $L\'$ ".</em></p>\n\n<p>The way I see it that means we have to find the special case, and then find restrictions that show us that this problem can always be reduced to the special case. What we\'re trying to do here is show that Problem $A$ (MS) is at least as hard as Problem $B$ (PARTITION), so why would a simple special case be enough here? Is it because there\'s an obvious way to map to this special case that I\'m missing? Or perhaps because $m = 1$ is trivial and we know that the problem will only get harder with a higher $m$, and that $D$ is always arbitrary, therefore $A$ must be at least as hard as $B$ (I feel like I\'m just guessing now :p)</p>\n\n<p>I hope it is clear where I get lost. </p>\n\n<p><strong>TLDR; Why is it enough to find a special case that is solvable by an NP-Complete problem? Don\'t we need some reduction to complete the proof?</strong></p>\n', 'Tags': '<complexity-theory><np-complete><proof-techniques>', 'LastEditorUserId': '4481', 'LastActivityDate': '2012-11-07T23:54:51.733', 'CommentCount': '2', 'AcceptedAnswerId': '6527', 'CreationDate': '2012-11-07T08:30:41.353', 'Id': '6525'}{'Body': '<p>As the net-evergreen <a href="http://www.snopes.com/holidays/christmas/santa/physics.asp">The Physics of Santa</a> establishes, it is physically impossible for Santa to get a gift to every kid on the planet. Route planning won\'t help much there, but can a good planning algorithm at least make sure that every kid gets a gift once in a while while Santa <em>also</em> serves as many kids as possible each year?</p>\n\n<hr>\n\n<p>Consider a complete graph with real, positive weights and a constant $k$. We want to solve a variant of the Travelling Sales Person problem:</p>\n\n<blockquote>\n  <p>Is there a circular route of length at most $k$ that serves more than $m$ nodes?</p>\n</blockquote>\n\n<p>The optimisation version would be:</p>\n\n<blockquote>\n  <p>Maximise the number of nodes that can be served with a circular route of length at most $k$.</p>\n</blockquote>\n\n<p>This is motivated by real-world limitations on routes: Santa has one night to deliver as many gifts as possible, a sales person has eight hours for one day\'s route, and so on.</p>\n\n<p>The first, but not final question is: how hard is this problem? Let\'s assume we can start at any node, but that should not make too much of a difference.</p>\n\n<p>Now, in order to model fairness, let\'s assume there are $N$ nodes and we can visit at most $M$ with every tour. Ideally, we would want that every node is visited $t\\cdot\\frac{M}{N}$ times across $t$ efficient tours. Since there may be bottleneck nodes that have to be visited more often in order to ensure routes visit many nodes, some will inevitably have to be visited less often. That also excludes the trivial approximation of removing once visited nodes until all have been visited.</p>\n\n<p>So, here is the final question. Let $T$ be the number of tours needed until all nodes have been visited by <em>efficient</em> $k$-tours. How can we algorithmically determine the minimal value of $T$ (and all the necessary routes)? How complex is this problem?</p>\n\n<p>I guess this is really a multi-criterial problem: each tour should visit as many nodes as possible while we want to keep tours as disjoint as possible.</p>\n', 'ViewCount': '179', 'Title': 'Can Santa be both fair and efficient?', 'LastActivityDate': '2012-11-09T03:48:37.460', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><graphs><scheduling>', 'CreationDate': '2012-11-07T11:10:15.287', 'FavoriteCount': '2', 'Id': '6531'}{'Body': '<p>I have encountered the following problem.</p>\n\n<p>We have $N$ points in discrete coordinates,distributed through a plane with vertical axis $[1..Y]$ and horizontal axis $[1..X]$.\nWe can perform the action of removing all points with vertical coordinate $y$, in short removing $y$.</p>\n\n<p><img src="http://i.stack.imgur.com/jcs9u.png" alt="example"></p>\n\n<p>What is the least number of $y$\'$s$ we must remove so that the number of $x$ that have points is less than $X/2$.\nFor example in the graph above removing 1 and 2 leaves points only in 1,3,6,9.</p>\n\n<p>This seems like a NP-complete problem to me so the only solution I have developed is removing all combinations of $y\'$s. I would be grateful if someone experienced in computation-theory could point me to a similar known problem (or maybe a problem this could be reduced to), any suggestion is welcome.</p>\n', 'ViewCount': '164', 'Title': 'Is the following NP-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-09T08:00:56.913', 'LastEditDate': '2012-11-09T08:00:56.913', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '5', 'OwnerDisplayName': 'manix', 'PostTypeId': '1', 'OwnerUserId': '4496', 'Tags': '<complexity-theory><np-complete><computational-geometry>', 'CreationDate': '2012-11-07T17:35:21.283', 'Id': '6542'}{'Body': "<p>I've got two log-space programs $F$ and $G$.</p>\n\n<ul>\n<li>Program $F$ will get input in array $A[1..n]$ and will create the output array $B[1..n]$.</li>\n<li>Program $G$ will get as input $B$ as created by $F$ and create from it the output array $C[1..n]$.</li>\n</ul>\n\n<p>I have to write a proof that there exist a log-space program $H$, which will get input Array $A$ and create from it corresponding array $C$. But I can't find the correct way to write it. How is this done?</p>\n\n<hr>\n\n<p>A log-space program is a program which uses $O(\\log n)$ bits of memory. Here are some conditions you have to keep:</p>\n\n<ol>\n<li><p>You have to use only variables which have simple integer type (for example <code>int</code> in C++, <code>longint</code> in Pascal).</p></li>\n<li><p>Allowed range of integer is defined: if $n$ is the size of the input we can save into variables only values which are polymonial sized based on $n$.</p>\n\n<p>For example: we can have variables which can takes on values in $[-n...n]$, $[-3n^5...3n^5]$ or also values $[-4...7]$, but we can't have variables which will take on values in $[ 0...2^n]$.\nNo other types of variables are allowed, neither are arrays and iterators.</p></li>\n<li><p>Exceptions from the rules about are input and output. Input will be available in special variables (mostly arrays) which your program can only read from, and the output can only be written to other special variables. So you can't read from output, and you can't increase values of input variables etc.</p></li>\n<li><p>Your programs can't use recursion.</p></li>\n</ol>\n\n<p>Example of log-space program written in Pascal (so everyone can understand it) which will find the largest number in the array of integer</p>\n\n<pre><code>    var n: integer;  //input variable the number of elements in A\n    A: array [1..n] of integer; //input variable - the array of integers\n    m: integer;      // output variable, the position of maximum\n    i, j: integer;   //working variables\n    begin\n      j := 1;\n      for i := 2 to n do\n        if A[i] &gt; A[j] then j := i;\n      m := j;\n    end;\n</code></pre>\n\n<p>The only two variables here are <code>j</code> and <code>i</code> and they evidently take values in $[1...n]$. Therefore all conditions are fulfilled and it really is a log-space program.</p>\n", 'ViewCount': '121', 'Title': 'Simulate the concatenation of two log-space programs in log-space', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-21T06:29:00.577', 'LastEditDate': '2012-11-09T07:49:44.290', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'OwnerDisplayName': 'user12392', 'PostTypeId': '1', 'Tags': '<algorithms><complexity-theory><simulation><space-complexity>', 'CreationDate': '2012-11-06T21:30:33.060', 'Id': '6571'}{'Body': '<p>I have difficulties understanding the definition of the class <a href="http://en.wikipedia.org/wiki/SNP_%28complexity%29" rel="nofollow">Max-SNP</a> (optimization variant of <strong>strict NP</strong>), thus I have to following basic question:</p>\n\n<pre><code>If a problem is known to be Max-SNP hard, does this imply NP-hardness of the problem?\n</code></pre>\n', 'ViewCount': '337', 'Title': 'Does Max-SNP hard imply NP-hard', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-10T08:26:30.693', 'LastEditDate': '2012-11-10T08:26:30.693', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6592', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4532', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2012-11-10T01:06:59.770', 'Id': '6589'}{'Body': '<p>I am following <strong>"Introduction to the theory of computation" by Sipser</strong>.</p>\n\n<p>My question is about relationship of different classes which is present in <strong>Chapter 8.2. The Class PSPACE</strong>.</p>\n\n<p>$P \\subseteq NP \\subseteq PSPACE = NPSPACE \\subseteq EXPTIME$</p>\n\n<p>I am trying to understand why the the following part is true $NPSPACE \\subseteq EXPTIME$.</p>\n\n<p>The explanation from the textbook is following: </p>\n\n<p><em>"For $f(x)\\geq n$, a TM that  uses $f(x)$ space can have at most $f(n)2^{O(f(n))}$ different configurations, by a simple generalization of the proof of the Lemma 5.8 on page 194. A TM computation that halts may not repeat a configuration. Therefore a TM that uses space $f(n)$ must run in time $f(n)2^{O(f(n))}$, so $NPSPACE \\subseteq EXPTIME$"</em></p>\n\n<p>I am trying to understand why it\'s true, why TM that uses $f(n)$ space must run in time $f(n)2^{O(f(n))}$. Let\'s try to reverseengeneer the formula: $n$ is the length of the input, 2 is the size of alphabet, $f(n)$ is the space that TM use on the second tape (operational tape) and $f(n) \\geq n$, but how to explain what $O(f(n))$ means. Apparently, $2^{O(f(n))}$ expreses a configuration, so $O(f(n))$ must express union of transition function and alphabet, but actually it seems like I get it wrong. The most intriguing question why, in the end,  $f(n)2^{O(f(n))}$ expressed in the terms of time, the transition from space to time is very vague for me.</p>\n\n<p>I will very appreciate if someone could explain me this relationship.</p>\n', 'ViewCount': '153', 'Title': 'Proving that NPSPACE $\\subseteq$ EXPTIME', 'LastActivityDate': '2012-11-13T19:29:32.513', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6651', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1170', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-11-13T18:43:57.293', 'Id': '6649'}{'ViewCount': '527', 'Title': 'How can P =? NP enhance integer factorization', 'LastEditDate': '2012-11-13T20:01:21.107', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '4365', 'FavoriteCount': '3', 'Body': '<p>If ${\\sf P}$ does in fact equal ${\\sf NP}$, how would this enhance our algorithms to factor integers faster. In other words, what kind of insight would this fact give us in understanding integer factorization better?</p>\n', 'Tags': '<complexity-theory><computability><np-complete><p-vs-np><factoring>', 'LastEditorUserId': '2755', 'LastActivityDate': '2012-11-18T19:44:37.800', 'CommentCount': '0', 'AcceptedAnswerId': '6652', 'CreationDate': '2012-11-13T19:13:56.870', 'Id': '6650'}{'ViewCount': '220', 'Title': 'Intuition behind Relativization', 'LastEditDate': '2012-11-15T09:19:53.543', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1379', 'FavoriteCount': '1', 'Body': '<p>I take course on Computational Complexity. My problem is I don\'t understand <strong>Relativization method</strong>. I tried to find a bit of intuition in many textbooks, unfortunately, so far with no success. I will appreciate if someone could shed the light on this topic so that I will be able to continue by myself.\nFew following sentences are questions and my thoughts about relativization, they will help to navigate the discussion. </p>\n\n<p>Very often relativization comes in comparison with diagonalization, which is a method that helps distinguish between countable set and uncountable set. It somehow comes from relativization that $P$ versus $NP$ question cannot be solved by diagonalization. I don\'t really see the idea why relativization show the useless of diagonalization, and if it\'s useless why is actually useless.</p>\n\n<p>The idea behind oracle Turing machine $M^A$ at first is very clear. However, when it comes to $NP^A$ and $P^A$ the intuition disappears. Oracle is a blackbox that is designed for special language and answers the question whether the string on the input of the oracle is in the language in time 1. As I understood TM that contains an oracle is just make some auxiliary operations and ask the oracle. So the core of the TM is the oracle, everything else is less important. What\'s the difference between $P^A$ and $NP^A$, even thought oracle in both of them works in time 1.</p>\n\n<p>The last  thing is the proving the existence of an oracle $B$ such that $P^B \\neq NP^B$. I found the proof in several textbooks and in all of them the proof seems very vague. I tried to use <strong>"Introduction to complexity" by Sipser, Chapter9. Intractability</strong>, and didn\'t get the idea of construction of a list of all polynomial time oracle TMs $M_i$. </p>\n\n<p>This is more or less everything what I know about relativization, I will appreciate if someonw would decide to share his/her thoughts on the topic.</p>\n\n<p><strong>Addendum</strong>: in one of the textbooks I found example of $NP^B$ language (Computational Complexity: A Modern Approach by Boaz Barak Sanjeev Arora. Theorem 3.7. Page 74). $U_B=\\left \\{ 1^n:some \\space string \\space of  \\space length \\space  n  \\space is \\space  in \\space B\\right \\} $ it\'s unary language. I believe that (1,11,111,1111,...) are all in $U_B$. Author affirms that such a language is in $NP^B$ which is I cannot understand why, hence oracle for B can resolve everything in time 1. Why do we need nondeterministic TM with oracle. If it\'s not good example of $NP^B$ please put yours such that to approve the existence of $NP^B$.</p>\n', 'Tags': '<complexity-theory><np-complete><complexity-classes><relativization><np>', 'LastEditorUserId': '1379', 'LastActivityDate': '2012-11-15T09:19:53.543', 'CommentCount': '6', 'AcceptedAnswerId': '6666', 'CreationDate': '2012-11-14T14:14:35.827', 'Id': '6665'}{'Body': '<p>I would like to ask you some clarification on the following question:\nknow that ${\\sf NP}$ is a subset of ${\\sf IP}$ \nand also ${\\sf coNP}$ it is a subset of ${\\sf IP}$.\nSo ${\\sf IP}$ is a biggest class, but how much it is big?</p>\n\n<p>May i say that ${\\sf PSPACE}$ is a subset of ${\\sf IP}$? or that they may intersect?</p>\n\n<p>Can you give me a easy clarification about it?</p>\n', 'ViewCount': '160', 'Title': 'Relation between interactive proof systems (IP), NP, coNP, PSPACE', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-16T21:07:21.567', 'LastEditDate': '2012-11-16T21:07:21.567', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4488', 'Tags': '<complexity-theory><time-complexity><space-complexity><complexity-classes><interactive-proof-systems>', 'CreationDate': '2012-11-15T13:47:04.607', 'Id': '6679'}{'Body': '<p>I try to understand if someone can apply a <strong>NTM</strong> to recognize <strong>coNP</strong> language.</p>\n\n<p>From the definition we know that:</p>\n\n<p><strong>NP</strong> - set of languages that can be recognized by NTM in polynomial time.</p>\n\n<p><strong>coNP</strong> - set of all languages that are complement to NP language.</p>\n\n<p>as with P versus NP question, we have NP versus coNP question.</p>\n\n<p>Unfortunately, is not defined explicitly if can one recognize coNP language with NTM.</p>\n\n<p>However, if we take a look at few examples from the set of coNP languages, few questions emerge.</p>\n\n<p>TAUTOLOGY = {$\\varphi$:$\\varphi$ is satisfied by every assingment}</p>\n\n<p>$\\bar{SAT}$ = {$\\varphi$: $\\varphi$ is not satisfiable }</p>\n\n<p>These languages are known to be coNP language and intuitively it seems like one can construct NTM to recognize these languages. On the other hand, if one can construct NTM to recognize them why them not in NP class (by definition)? Maybe not all language of coNP can be solved by NTM just few of them, if yes, we will have intersection of NP class and coNP class. And if every language from coNP class cannot be solved by NTM, does it mean that limitation of NTM is located in coNP class. Is NTM is limited at all?</p>\n\n<p>I am a little bit confused, I will appreciate if someone will shed the light on this topic.</p>\n', 'ViewCount': '79', 'Title': 'coNP and limitation of NDTM', 'LastEditorUserId': '1379', 'LastActivityDate': '2012-11-17T23:36:10.440', 'LastEditDate': '2012-11-17T18:56:14.323', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><np-complete><complexity-classes>', 'CreationDate': '2012-11-17T17:37:12.450', 'Id': '6718'}{'Body': '<p>In  the theory of distributed algorithms, there are problems with lower bounds, as $\\Omega(n^2)$, that are "big" (I mean, bigger than $\\Omega(n\\log n)$), and nontrivial.\nI wonder if are there problems with similar bound in the theory of serial algorithm, I mean of order much greater than $\\Omega(n\\log n)$.</p>\n\n<p>With trivial, I mean "obtained just considering that we must read the whole input" and similarly.</p>\n', 'ViewCount': '172', 'Title': 'Is there any nontrivial problem in the theory of serial algorithms with a nontrivial polynomial lower bound of $\\Omega(n^2)$?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-24T08:01:48.460', 'LastEditDate': '2013-05-24T08:01:48.460', 'AnswerCount': '2', 'CommentCount': '8', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1665', 'Tags': '<algorithms><complexity-theory><lower-bounds>', 'CreationDate': '2012-11-18T01:28:50.303', 'FavoriteCount': '1', 'Id': '6732'}{'Body': '<p>Given that the <a href="http://en.wikipedia.org/wiki/Hamiltonian_path_problem" rel="nofollow">Hamiltonian cycle problem</a> is NP-complete, I want to prove that the following problem is NP-complete:</p>\n\n<blockquote>\n  <p>Given an undirected graph $G(V,E)$ and vertices $s,t\\in V$, does there\n  exist a path from $s$ to $t$ with at least $k$ edges such that all vertices\n  in the path are distinct?</p>\n</blockquote>\n\n<p>I thought of assigning a weight of $1$ to every edge and on similar grounds, but I am not able to compensate for the "at least $k$" edges part.</p>\n\n<p>It would be appreciated if somebody could help me with  the approach.</p>\n', 'ViewCount': '211', 'Title': 'Reduction to Hamiltonian cycle', 'LastEditorUserId': '4304', 'LastActivityDate': '2012-11-18T23:50:01.033', 'LastEditDate': '2012-11-18T07:30:57.460', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4635', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2012-11-18T04:09:10.590', 'FavoriteCount': '1', 'Id': '6735'}{'Body': "<p>Could anyone please explain Cantor's diagonalization principle in simple terms?</p>\n", 'ViewCount': '389', 'Title': "Cantor's diagonal method in simple terms?", 'LastEditorUserId': '472', 'LastActivityDate': '2012-11-22T03:35:01.137', 'LastEditDate': '2012-11-22T03:35:01.137', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '6759', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '947', 'Tags': '<complexity-theory><sets><uncountability>', 'CreationDate': '2012-11-19T02:53:30.917', 'Id': '6753'}{'Body': '<p>When I read about NP-completeness for the first time, I really wondered why is the concept of reductions given such high emphasis, after all we have been looking at concepts such as reductions and \'special case of one another problem\' in mathematics since elementary algebra. What I mean by reductions in algebra is the following.</p>\n\n<p>Problem 1: Find value of x such that $x^2+ax+b=0$</p>\n\n<p>Problem 2: Find value of x such that $(x+m/n)^2=0$</p>\n\n<p>We can go on proving both the problems are same and one solution can be translated to another.</p>\n\n<p>My question is that "Is the concept of reductions in computational intractability same as that in above algebraic theory?" If not, how are the reductions in CI theory different?</p>\n', 'ViewCount': '89', 'Title': 'Difference between reductions in algebraic problems versus reductions in computational intractability', 'LastEditorUserId': '472', 'LastActivityDate': '2012-12-04T00:56:09.023', 'LastEditDate': '2012-12-04T00:56:09.023', 'AnswerCount': '3', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4667', 'Tags': '<complexity-theory><np-complete><np-hard>', 'CreationDate': '2012-11-20T12:28:30.580', 'FavoriteCount': '2', 'Id': '6781'}{'Body': "<p>Taking an NP-complete problem like vertex cover if we can find a reduction which is exponential and not polynomial and the reduction we do to a problem can be solved in polynomial time, then what would be it's implications?</p>\n\n<p>Based on Yuval's answer, I wanted to throw this scenario into the place also.</p>\n\n<p>If we have a problem in P which we can reduce in polynomial time to an NP-complete problem for e.g vertex cover, what happens then?</p>\n", 'ViewCount': '201', 'Title': 'What would an exponential reduction from an NP-complete problem to P signify?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:09:52.037', 'LastEditDate': '2013-05-24T03:09:52.037', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '366', 'Tags': '<complexity-theory><np-complete><p-vs-np>', 'CreationDate': '2012-11-20T15:03:43.400', 'Id': '6785'}{'Body': '<p>In this Wikipedia article about the <a href="http://en.wikipedia.org/wiki/Clique_%28graph_theory%29">Clique problem in graph theory</a> it states in the beginning that the problem of finding a clique of size K, in a graph G is NP-complete:</p>\n\n<blockquote>\n  <p>Cliques have also been studied in computer science: finding whether there is a clique of a given size in a graph (the clique problem) is NP-complete, but despite this hardness result many algorithms for finding cliques have been studied.</p>\n</blockquote>\n\n<p>But in this other Wikipedia article about the <a href="http://en.wikipedia.org/wiki/Clique_problem">Clique problem in CS</a>\n it says it is solving the problem for a fixed size k is a problem in P, it can be brute forced in polynomial time.</p>\n\n<blockquote>\n  <p>A brute force algorithm to test whether a graph G contains a k-vertex clique, and to find any such clique that it contains, is to examine each subgraph with at least k vertices and check to see whether it forms a clique. This algorithm takes time O(n^k k^2): there are O(n^k) subgraphs to check, each of which has O(k^2) edges whose presence in G needs to be checked. Thus, the problem may be solved in polynomial time whenever k is a fixed constant. When k is part of the input to the problem, however, the time is exponential.</p>\n</blockquote>\n\n<p>Is there something I am missing here? Maybe a difference in the wording of the problem? And what does the last sentence mean, that "When k is part of the input to the problem, however, the time is exponential."? Why is there a difference when the k is part of the input to the problem?</p>\n\n<p>My idea is that to find a clique of size k in a graph G, is that we first choose a subset of size k of nodes from G, and test wether they are all related to the other k nodes, which can be done in constant time. And repeat this until we have a clique of size k. The number of sets of k nodes we can choose from G is n! / k!*(n-k)!. </p>\n', 'ViewCount': '1742', 'Title': 'Is the k-clique problem NP-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-24T15:19:38.560', 'LastEditDate': '2012-11-24T15:19:38.560', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '6848', 'Score': '8', 'OwnerDisplayName': 'Eivind', 'PostTypeId': '1', 'Tags': '<complexity-theory><graph-theory><np-complete><complexity-classes>', 'CreationDate': '2012-11-22T08:52:36.760', 'Id': '6847'}{'Body': '<p>I am new to "Computational Complexity" and therefore I have enough problems with some exercises like the following one:</p>\n\n<blockquote>\n  <p>Remember: $\\text{PH} := \\bigcup_{i} \\Sigma_i$</p>\n  \n  <p>Show:</p>\n  \n  <p>$\\bullet \\bigcup_{i}(\\Sigma_i \\cup \\Pi_i \\cup \\Delta_i) = \\bigcup_{i}\\Sigma_i = \\bigcup_{i}\\Pi_i = \\bigcup_{i}\\Delta_i$</p>\n  \n  <p>$\\bullet \\forall k \\in \\mathbb{N} (\\Sigma_k = \\Pi_k \\Rightarrow \\text{PH} = \\Sigma_k)$</p>\n</blockquote>\n\n<p>I have tried to make myself familiar with <a href="http://en.wikipedia.org/wiki/Polynomial_hierarchy" rel="nofollow">Polynomial hierarchy</a>, but on the one hand I don\'t understand the meaning of the symbols $\\Delta, \\Sigma, \\Pi$ and on the other hand I don\'t know how to solve the actual exercise.</p>\n\n<p>Can somebody give me some help, please?</p>\n', 'ViewCount': '151', 'Title': 'Notations around the polynomial hierarchy', 'LastEditorUserId': '19', 'LastActivityDate': '2012-11-28T05:10:48.793', 'LastEditDate': '2012-11-24T19:10:26.167', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><terminology><time-complexity>', 'CreationDate': '2012-11-24T11:26:59.523', 'FavoriteCount': '1', 'Id': '6870'}{'Body': '<p>I think the following exercise is to "warm up", but nevertheless it\'s quite difficult for me:</p>\n\n<blockquote>\n  <p>Let $k \\in \\mathbb{N}$ and let $L \\in \\Sigma_k$. Show that also $L^{*} \\in \\Sigma_k$.</p>\n</blockquote>\n\n<p>The following details from my lecture notes seem to be useful:</p>\n\n<p>Notation. Let $n \\in \\mathbb{N}$.</p>\n\n<p>We write $\\exists_n y. \\varphi(y)$ for $\\exists y \\in \\Sigma^{*}.|y| \\le n \\wedge \\varphi(y)$.</p>\n\n<p>We write $\\forall_n y. \\varphi(y)$ for $\\forall y \\in \\Sigma^{*}.|y| \\le n \\Rightarrow \\varphi(y)$.</p>\n\n<p>Theorem.</p>\n\n<p>$L \\in \\Sigma^P_i \\Leftrightarrow$ there is a language $A \\in P$ and a polynomial $p$ so that: $x \\in L \\Leftrightarrow \\exists_{p(|x|)}y_1 \\forall_{p(|x|)}y_2 \\exists_{p(|x|)}y_3 .../\\forall_{p(|x|)}y_i (x,y_1,y_2,...,y_i) \\in A$</p>\n\n<p>Unfortunately I don\'t see the solution of the "puzzle". Can somebody please help me a little bit (despite the fact that it\'s weekend)?</p>\n', 'ViewCount': '76', 'Title': 'Show that a language belongs to the polynomial hierarchy', 'LastActivityDate': '2012-11-24T18:25:10.387', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6875', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-11-24T17:22:31.363', 'Id': '6874'}{'Body': '<blockquote>\n  <p><strong>Subset-sum:</strong> Given a list of numbers, find if a non-empty sublist has sum 0 (there\'s a variation where we want sum=k instead of 0, but 0 is easier for analysis)</p>\n  \n  <p><strong>Partition:</strong> Given a list, can it be partitioned into two non-empty sublists with equal sum?</p>\n</blockquote>\n\n<p>I want to reduce subset-sum to partition. The reductions I found so far are same as <a href="http://cs.stackexchange.com/questions/6111/how-can-i-reduce-subset-sum-to-partition">this one</a> but it has following faults :</p>\n\n<ol>\n<li>For $B=0$, you can always partition $L\'$ into $\\{2S-0\\}$, $\\{S+0\\} U L$.</li>\n<li>It supposes $2S-B$ and $S+B$ have to go to different partitions! You could have both of them in same partition along with elements that sum to $-S$, hence total sum $= 2S$ as needed.</li>\n</ol>\n', 'ViewCount': '284', 'Title': 'reducing subset-sum to partition', 'LastEditorUserId': '4717', 'LastActivityDate': '2012-11-25T05:55:50.390', 'LastEditDate': '2012-11-24T20:21:14.430', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '6882', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4717', 'Tags': '<complexity-theory><np-complete><reductions><partitions>', 'CreationDate': '2012-11-24T20:06:48.693', 'Id': '6877'}{'Body': "<p>The following exercise gives me headaches:</p>\n\n<blockquote>\n  <p>Show: If the polynomial hierarchy is strict (i.e. $\\forall k \\in \\mathbb{N}. \\Sigma_k \\neq \\Sigma_{k+1}$), then there is no $\\text{PH}$-complete problem for polynomial-time reductions (i.e. there is no problem $\\text{P} \\in \\text{PH}$ such that each problem in $\\text{PH}$ can be reduced to $\\text{P}$ through a function $f \\in \\text{FP}$).</p>\n</blockquote>\n\n<p>The exercise describes in detail what has to be shown, but my issue is that I don't know how to show this. Can somebody please help me?</p>\n", 'ViewCount': '66', 'Title': 'Strict polynomial hierarchy and reduction', 'LastActivityDate': '2012-11-26T17:57:15.720', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '6926', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-11-25T13:47:45.003', 'Id': '6885'}{'Body': '<p>We know that counting the number of Hamiltonian paths is in $\\#\\mathsf{P}$.</p>\n\n<p>So, what complexity (counting version) class would the counting the number of Hamiltonian paths that have two or three particular vertexes in a graph be in?</p>\n\n<p>Also, what would be like if counting the number of hampaths that have two or three particular vertexes in particular place - so, for example, calculating the hampath that has vertex 3 as the second place from starting point and so on?</p>\n', 'ViewCount': '27', 'Title': '#P complexity reduction', 'LastActivityDate': '2012-11-25T18:13:36.500', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '0', 'OwnerDisplayName': 'rrut', 'PostTypeId': '1', 'Tags': '<complexity-theory>', 'CreationDate': '2012-10-25T02:41:32.137', 'Id': '6891'}{'Body': '<ol>\n<li><p>Is it always true that a problem which is ${\\sf NP}$-hard but not ${\\sf NP}$-complete is an optimization problem such as <strong>Minimum-Vertex-Cover</strong> and many others.</p></li>\n<li><p>Is it always true that a ${\\sf NP}$-complete problem is always a decision problem such as vertex cover of size $k$, independent set of size $k$ and many others.</p></li>\n</ol>\n', 'ViewCount': '154', 'Title': 'NP-Hard problems which are not NP-Complete', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-27T08:19:00.027', 'LastEditDate': '2012-11-27T08:19:00.027', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2556', 'Tags': '<complexity-theory><terminology><np-complete><np-hard><decision-problem>', 'CreationDate': '2012-11-26T07:02:31.070', 'FavoriteCount': '1', 'Id': '6910'}{'ViewCount': '146', 'Title': 'NP-complete reductions', 'LastEditDate': '2012-11-26T11:49:55.377', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4735', 'FavoriteCount': '1', 'Body': '<p>I\'ve read that "Every problem in NP can be reduced to every NP-complete problem". </p>\n\n<p>My question is on the choice of the word "reduce". If I were to "reduce" a polynomial problem in NP to an exponential problem in NP, I just plain feel weird about using the word "reduce" because I feel like I\'ve increased the problem, not reduced it. So, why do we use the word reduce?</p>\n\n<p>Also, why do we write "reduce A to B" as $A\\le_{p} B$. It seems backwards.</p>\n', 'Tags': '<complexity-theory><terminology><np-complete><reductions>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-05T22:56:51.973', 'CommentCount': '2', 'AcceptedAnswerId': '7200', 'CreationDate': '2012-11-26T08:29:17.163', 'Id': '6912'}{'Body': '<p>The title of the question expresses what I\'m looking for - this is to help me better understand the prerequisites for the <a href="http://en.wikipedia.org/wiki/Time_hierarchy_theorem#Non-deterministic_time_hierarchy_theorem">Non-Deterministic Time Hierarchy Theorem</a></p>\n\n<p>For instance, the Arora-Barak book explains the theorem using $g(n) = n$ and $G(n) = n^{1.5}$ - but, I can see that $n \\in o(n^{1.5})$ as well! So, I\'m trying to better understand what "extra" time is guaranteed by specifying that in order for $\\text{NTIME}(g(n))$ to be a proper subset of $\\text{NTIME}(G(n))$, $g(n + 1) = o(G(n))$, <strong>not</strong> $g(n) = o(G(n))$...  </p>\n', 'ViewCount': '127', 'Title': 'Two functions $g(n)$, $G(n)$ such that $g(n) = o(G(n))$ but $g(n+1) \\neq o(G(n))$', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-27T00:09:41.660', 'LastEditDate': '2012-11-26T22:05:53.567', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '6932', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '476', 'Tags': '<complexity-theory><time-complexity><asymptotics><landau-notation>', 'CreationDate': '2012-11-26T20:16:07.620', 'Id': '6929'}{'ViewCount': '151', 'Title': 'Showing that Independent set of size $k$ can be decided using logarithmic space', 'LastEditDate': '2012-11-27T08:05:39.133', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2329', 'FavoriteCount': '1', 'Body': "<p>An independent set $I$ is a subset of the nodes of a graph $G$ where: no 2 nodes in $I$ are adjacent in $G$. For natural number $k$, the problem $k-\\text{IND}$ asks if there is an independent set of size $k$.</p>\n\n<p>I'd really love your help with showing that $k-\\text{IND} \\in {\\sf L}$, i.e., can be decided using deterministic logarithmic space.</p>\n", 'Tags': '<complexity-theory><graphs><space-complexity>', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-27T18:19:38.020', 'CommentCount': '3', 'AcceptedAnswerId': '6946', 'CreationDate': '2012-11-26T21:58:10.790', 'Id': '6933'}{'Body': '<p>EDITS: corrected $r$ to add edges just like $f$ does in paragraph 8 per the first comment below. Also specified the Clique problem of interest in paragraph 2.</p>\n\n<p>Having received no response to this question on math.SE, I\'m asking it here. Thanks for your help.</p>\n\n<p>In <a href="http://en.wikipedia.org/wiki/Clique_problem" rel="nofollow">the Wikipedia article on the Clique problem</a>, we are told that under the brute-force algorithm, there are potentially exponentially many subgraphs of a given graph that must be checked as possible cliques. The particular Clique problem I\'m interested in is the problem of finding a clique larger than a given size.</p>\n\n<p>Informally, the question here is whether an unknown representation of graphs will also have a possibly exponential number of subgraphs that must be checked as possible cliques under the brute-force algorithm.</p>\n\n<p>I\'ll try to make this more precise by first giving a function to build up normal graphs, and then a new, different function to build up the unknown representation with properties that the new function must satisfy. The whole discussion here is about undirected graphs.</p>\n\n<p>Let\'s start by defining an operation that will build up a normal undirected graph. Let $E$ denote the null graph: $0$ nodes, $0$ edges. Let $f$ be the following operation:</p>\n\n<p>$f(n_1, n_2, G)$</p>\n\n<p>$f$ takes a graph $G$ and returns a graph with the edge from $n_1$ to $n_2$ added to $G$. So while the null graph $E$ is definable without $f$, all other standard graphs in our discussion are built by $f$: $f(n_1, n_2, G)$ where $G$ could equal $E$.</p>\n\n<p>As an example, the expression $f(n_1, n_2, E)$ returns the graph $(\\{n_1, n_2\\}, \\{(n_1, n_2)\\})$.</p>\n\n<p>Now consider an alternate graph representation $H$, built by a function we\'ll call $r$ that adds edges like $f$ does. But $H$ is an unknown representation that must obey the properties below.</p>\n\n<p>First let\'s describe a similarity relation ($\\sim$) between $G$ and $H$:</p>\n\n<p>Case 1. $G \\sim H$ if $G = E$ and $H = E$.<br>\nCase 2. $G \\sim H$ if $G = f(n_1, n_2, G_1)$, $H = r(n_1, n_2, H_1)$, and $G_1 \\sim H_1$.</p>\n\n<p>As before, the null graph $E$ is definable without $r$, but all others in the unknown representation are built by $r$: $r(n_1, n_2, H)$ where $H$ could equal $E$.</p>\n\n<p>The representation $H$ must obey the following properties:</p>\n\n<ol>\n<li>Just as $G$ is built by successive applications of $f$ to the null graph $E$, $H$ is built by successive applications of $r$ to the null graph $E$.</li>\n<li>The order in which the edges of a graph are added doesn\'t matter:\nin ordinary graphs, $f(n_1, n_2, f(n_3, n_4, G)) = f(n_3, n_4, f(n_1, n_2, G))$; in the unknown representation, $r(n_1, n_2, r(n_3, n_4, H)) = r(n_3, n_4, r(n_1, n_2, H))$. </li>\n<li>Since we\'re talking about undirected graphs, the order in which the nodes of an edge are specified doesn\'t matter: in ordinary graphs, $f(n_1, n_2, G) = f(n_2, n_1, G)$; in the alternate representation, $r(n_1, n_2, H) = r(n_2, n_1, H)$.</li>\n<li>Just as for $G$, $H$ has an operation $hasClique(\\{n_1,...,n_k\\}, H)$ which is true exactly when there is a clique among the nodes $\\{n_1,...,n_k\\}$. </li>\n<li>Consider a graph $G$ with nodes $\\{n_1,...,n_m\\}$ and a subset $\\{n_i,...,n_j\\}$ and $G \\sim H$ for some $H$. Then we require that nodes $\\{n_i,...,n_j\\}$ form a clique in $G$ if and only if the nodes $\\{n_i,...,n_j\\}$ form a clique in $H$. What I\'m trying to capture here is that $H$ has a clique wherever $G$ does and vice versa for $G \\sim H$.</li>\n</ol>\n\n<p>Question: Can we conclude that $H$ has potentially exponentially many subgraphs that must be checked as possible cliques under the brute-force algorithm, just as in normal graphs?</p>\n', 'ViewCount': '106', 'Title': 'Cliques in an alternate graph representation', 'LastEditorUserId': '1295', 'LastActivityDate': '2012-11-30T05:58:41.677', 'LastEditDate': '2012-11-28T03:46:37.517', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '7035', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1295', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2012-11-27T05:13:30.250', 'Id': '6942'}{'Body': '<p>I don\'t understand this definition of an "instance" of a problem.  Quoting from the CLRS book on page 1054 on abstract problems (Chapter 34.1):</p>\n\n<blockquote>\n  <p>We define an abstract problem $Q$ to be a binary relation on a set $I$ of problem <strong>instances</strong> and set $S$ of problem <strong>solutions</strong>.</p>\n</blockquote>\n', 'ViewCount': '379', 'Title': 'What is an instance of NP complete problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-29T17:42:14.317', 'LastEditDate': '2012-11-29T16:48:03.150', 'AnswerCount': '4', 'CommentCount': '0', 'AcceptedAnswerId': '7020', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4193', 'Tags': '<complexity-theory><terminology><np-complete>', 'CreationDate': '2012-11-29T02:18:20.670', 'Id': '7005'}{'ViewCount': '444', 'Title': 'Graph 3-colorability is self-reducible', 'LastEditDate': '2012-11-30T19:23:12.183', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4799', 'FavoriteCount': '1', 'Body': '<p>I am interested in self-reducibility of Graph 3-Coloralibity problem.</p>\n\n<p><strong>Definition of Graph 3-Coloralibity problem.</strong></p>\n\n<p>Given an undirected graph $G$ does there exists a way to color the nodes red, green, and blue so that no adjacent nodes have the same color?</p>\n\n<p><strong>Definition of self-reducibility.</strong></p>\n\n<p>A language $L$ is self-reducible if a oracle turing machine TM $T$ exists such that $L=L(T^L)$ and for any input $x$ of length $n$, $T^L(x)$ queries the oracle for words of length at most $n-1$.</p>\n\n<p>I would like to show in very strict and formal way that Graph 3-colorability is self-reducible.</p>\n\n<p>Proof of self-reducibility of SAT can be used as example (<a href="http://cseweb.ucsd.edu/~mihir/cse200/decision-search.pdf" rel="nofollow">self-reducibility of SAT</a>).</p>\n\n<p>In my opinion, the general idea of proof of self-reducibility of Graph 3-colorability is different from proof of SAT self-reducibility in few aspects.</p>\n\n<ul>\n<li>SAT has two choices for every literal (true or false) and Graph 3-colorability has three choices (namely, red green blue).</li>\n<li>Choices of SAT literal are independent on each other and choices of colors of Graph 3 colorability are strictly dependent, any adjacent node must have different color, this property potentially could help to make less iteration among all colors.</li>\n</ul>\n\n<p><strong>The general idea of proof</strong>.</p>\n\n<p>Let\'s denote by $c_{v_i}$  the color of the vertex $v_i$, which can take one of the following values (red,green,blue). Define graph $G\'$ from a given graph $G$ by coloring the arbitrary vertex $v_0$, assign $c_{v_0}$ to \'red\' and put the graph $G\'$ with colored vertex $v_0$ to the input of the oracle. If oracle answers 1, which means that the modified graph is still 3-colorable, save the current assignments and start new iteration, with the different vertex $v_1$ chosen arbitrarily, color vertex $v_1$ according to the colors of the adjacent vertices.\nif oracle answers 0, which means the previous assignment has broken 3 colorability, pick different color from the set of three colors, but still according to colors of adjacent vertices.</p>\n\n<p>The previous proof is not mathematical robust, the question is how to improve it and to make it more formal and mathematical strict. It looks like I need more carefully distinguish the cases when new vertex doesn\'t have any edges with already colored vertices and when the new vertex is adjacent to already colored vertices. </p>\n\n<p>In addition I would like to prove that Graph 3-colorability is downward self-reducible.</p>\n\n<p><strong>Definition of downward self-reducible language.</strong></p>\n\n<p>The language $A$ is said to be downward self-reducible if it is possible to determine in polynomial time if $x \\in A$ using the results of shortest queries. </p>\n\n<p>The idea seems to be simple and intuitive: start with coloring an arbitrary vertex, and on each iteration add one more colored vertex and check by oracle if graph is still 3-colorable, if not reverse previous coloring and check another color.</p>\n\n<p>But how to write the proof in a strict way and more important  how to find an appropriate encoding of a graph.</p>\n\n<p>In short, I would like to show that Graph 3-colorability is self-reducible and downward self-reducible in strict and formal way.</p>\n\n<p>I will appreciate sharing your thoughts with us.</p>\n\n<p><strong>Update:</strong></p>\n\n<p><strong>downward self-reducibility</strong></p>\n\n<p>Downward self-reducibility is applied to decision problem and it\'s oracle answers the same decision problem with shorter input, at the end of the process of downward self-reduction we should have the right color assignments.</p>\n\n<p>Every 3 - colorable graph $G$ with more than three vertices, has two vertices $x,y$ with the same color. Apparently, there is only three colors and more than three vertices so some number of non-adjacent vertices might have the same color. If we merge $x$ and $y$ with the same color as the result we still have 3 - colorable graph, just because, if graph is 3 - colorable, then there are exist right assignment of all vertices that are adjacent to $x$ and $y$ according to the same color of $x, y$, so by merging $x, y$ we don\'t need to change any color of any vertices, we only need to add more edges between already correctly colored vertices (I know it\'s not the best explanation, I will appreciate if someone could explain it better). On every iteration we take two non-adjacent vertices $x,y$ of graph $G$, merge $x$ and $y$ and get graph $G\'$ which is our shorter input to the oracle. Oracle answers if it\'s 3-colorable or not. Now the problem is before setting $G\'$ on the input of oracle I should color the merged vertex and test colorability of $G\'$, if it\'s not 3-colorable change the color, but how to implement it correctly, I need right encoding for it.</p>\n\n<p><strong>self-reducibility</strong></p>\n\n<p>First, we should check if a given graph $G$ is 3-colorable at all, so set it on input of oracle, and oracle will answer if it\'s 3 - colorable, if yes then start the process. Any two nonadjacent vertices can have the same color in 3-colorable graph. The process of self-reducibility we should run in iterations, I think we can start from small subgraph $G\'$ of a given graph $G$ and on every iteration add one more vertices from $G$ to $G\'$. In paralel, we should maintain the assignment of already colored vertices. Unfortunately, I still don\'t get the idea completely. Would appreciate for help and hints. </p>\n', 'Tags': '<complexity-theory><reductions>', 'LastEditorUserId': '4799', 'LastActivityDate': '2012-11-30T19:23:12.183', 'CommentCount': '5', 'AcceptedAnswerId': '7016', 'CreationDate': '2012-11-29T11:10:30.967', 'Id': '7013'}{'Body': '<p>Unfortunately I have no idea how to show this:</p>\n\n<blockquote>\n  <p>Show that the set of ${\\sf P}$-complete languages is not closed under intersection.</p>\n</blockquote>\n\n<p>As far as I understand my lecture notes, ${\\sf P}$-completeness is defined as follows:</p>\n\n<ul>\n<li>$A \\subset \\Sigma^{*}$ is complete for ${\\sf P}$ iff $A \\in \\text{P}$ and $\\forall B \\in {\\sf P}, B \\le_L A$</li>\n<li>$\\le_L$ is ${\\sf LOGSPACE}$-reduction: for $A,B \\subset \\Sigma^{*}$, the relation $A \\le_{L} B$ is defined by\n$$A \\le_{L} B \\quad\\text{iff}\\quad \\exists f \\in {\\sf FLOGSPACE}, (x \\in A \\Leftrightarrow f(x) \\in B)$$</li>\n</ul>\n', 'ViewCount': '224', 'Title': 'Proof for P-complete is not closed under intersection', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-04T12:04:27.640', 'LastEditDate': '2012-11-29T20:54:49.207', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><time-complexity><reductions>', 'CreationDate': '2012-11-29T12:48:39.203', 'Id': '7014'}{'Body': "<p>I don't know exactly how to solve the exercise below.</p>\n\n<blockquote>\n  <p>Show that the multiplication lies in $\\text{FL}$.</p>\n  \n  <p>Hint: A useful approach to a solution is to split the exercise into two parts and to explain that each function lies in $\\text{FL}$. The standard multiplication scheme can be used as an intermediate step. Example:</p>\n  \n  <p>$\\begin{align}\n1001 \\cdot{} 1100 &amp; = \\\\\n 1001000\\\\\n + \\ \\ \\ 100100\\\\\n + \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\\\\n + \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\\\\n\\end{align}$</p>\n  \n  <p>Other useful approaches are certainly also accepted.</p>\n</blockquote>\n\n<p>Useful definitions from our lecture notes:</p>\n\n<hr>\n\n<p>Let $f : \\Sigma^* \\to \\Sigma^*$ be a function, let $t : \\mathbb N \\to \\mathbb N$ be a time bound and let $s : \\mathbb N \\to \\mathbb N$ be a memory space bound.</p>\n\n<p>$\\bullet$ It is $f \\in \\text{FDTIME}(t),$ if there exists a DTM $M$ with an output tape, calculating $f$ and for which $T_M \\in O(t)$ holds.</p>\n\n<p>$\\bullet$ It is $A \\in \\text{FDSPACE}(s),$ if there exists an offline DTM $M$, calculating $f$ and for which $S_M \\in O(s)$ holds. The fields being written on the output band are not considered for the amount of memory space.</p>\n\n<p>$\\text{FP}=\\bigcup_{k \\in \\mathbb N} \\text{FDTIME}(n^k), \\text{FL}=\\text{FDSPACE}(\\log n)$</p>\n\n<hr>\n\n<p>I think the hint wants me to find two functions (one for the multiplication and one for the addition), but I don't see how to find two functions that do the calculation of the example in the appropriate way. Can somebody help me, please?</p>\n", 'ViewCount': '175', 'Title': 'Show that the multiplication lies in FL', 'LastActivityDate': '2013-03-02T08:46:26.067', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-11-29T17:57:19.647', 'Id': '7022'}{'Body': '<p>If an optimization problem is known to be inapproximable up to some precision, does this automatically imply that the problem is apx-hard?</p>\n', 'ViewCount': '103', 'Title': 'Inapproximability result implies apx-hardness?', 'LastActivityDate': '2012-11-30T00:08:10.550', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7030', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4532', 'Tags': '<complexity-theory><approximation>', 'CreationDate': '2012-11-29T23:12:55.417', 'Id': '7029'}{'Body': '<p>$\\newcommand{\\np}{\\mathsf{NP}}\\newcommand{\\cc}{\\textrm{Circuit-SAT}}$I am having difficulty understanding the $\\np$-hardness proof for $\\cc$ in <a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms" rel="nofollow">CLRS</a>.</p>\n\n<blockquote>\n  <p>$\\cc = \\{\\langle C \\rangle : C \\text{ is a satisfiable combinatorial boolean circuit} \\}$</p>\n  \n  <p><strong>Lemma:</strong> The $\\cc$ problem is $\\mathsf{NP}$-hard.</p>\n</blockquote>\n\n<p>Can anyone provide an easy-to-understand proof?</p>\n', 'ViewCount': '265', 'Title': 'Circuit Satisfiability problem is NP-Hard?', 'LastEditorUserId': '19', 'LastActivityDate': '2012-12-01T05:56:51.550', 'LastEditDate': '2012-12-01T05:56:51.550', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '7034', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4193', 'Tags': '<complexity-theory><np-hard><satisfiability><circuits>', 'CreationDate': '2012-11-30T02:16:14.930', 'Id': '7032'}{'Body': '<p>The following exercise is difficult for me:</p>\n\n<blockquote>\n  <p>Show that for each $k \\in \\mathbb{N}$ the question of existence of a $k$-clique within a graph lies in $\\text{L}$.</p>\n  \n  <p>Hint: A $k$-clique denotes $k$ verteces within a graph that are all connected with each other.</p>\n  \n  <p>Annotation: if the question also considers $k$ as parameter, then the problem is $\\text{NP}$-complete.</p>\n</blockquote>\n\n<p>So $\\text{L}$ is "the complexity class containing decision problems which can be solved by a deterministic Turing machine using a logarithmic amount of memory space". Now I\'m wondering if this exercise isn\'t a catchy question, since I\'ve found <a href="http://www.cs.berkeley.edu/~virgi/combclique-ipl-g.pdf" rel="nofollow">this paper</a> and it says "We give an algorithm for $k$-clique that runs in (...) $O(n^{\\varepsilon})$ space, for all $\\varepsilon &gt; 0$, on graphs with $n$ nodes"?</p>\n\n<p>Furthermore, I also don\'t understand the annotation, because how should it be possible to not consider $k$ for the $k$-clique problem?</p>\n', 'ViewCount': '109', 'Title': 'Show that k-clique lies in L', 'LastActivityDate': '2012-11-30T11:43:05.207', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-11-30T10:19:40.617', 'Id': '7039'}{'Body': "<p>To show that a NP problem is NP-complete, we also have to show that $L \\leq_{p} L'$  , where $L$ is proven NP-complete and you have to prove $L'$ also is. The thing I am confused is how in all NP-complete problems in CLRS they just state the reduction algorithm for $L$ to convert to $L'$ is polynomial. How can one prove it's polynomial time, provided an example such a clique or ham cycle kind of problem?</p>\n", 'ViewCount': '110', 'Title': 'How to determine the polynomial runtime of an NP reduction?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-01T14:06:20.573', 'LastEditDate': '2012-12-01T14:06:20.573', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7069', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4193', 'Tags': '<complexity-theory><np-complete><reductions><proof-techniques>', 'CreationDate': '2012-12-01T05:03:35.287', 'Id': '7068'}{'Body': "<p>I am interesting in proving that there is no search problem that is polynomial bounded and  self-reducible, as long as ${\\sf P} \\neq  {\\sf NP} \\cap {\\sf coNP}$.</p>\n\n<p>The problem is I don't know how to approach the proof, below I wrote few ideas with open questions.</p>\n\n<p>We can start by denoting the search problem in set ${\\sf NP} \\cap {\\sf coNP}$ in terms of search problem relations $R_1$ and $R_2$ such that $S = \\left \\{ x:R_1(x) \\neq \\emptyset \\right \\}  = \\left \\{ x:R_2(x) = \\emptyset \\right \\} $. But how to present that the decision problem $S$ is not in ${\\sf P}$. I don't know (but it seems to be crucial to show that $S$ is not in ${\\sf P}$). </p>\n\n<p>Having defined $S$ the next step would be to show that there is a relation $R$ that is self-reducible to $S$, but is not polynomial bounded.</p>\n\n<p>In short, the question is how to define relation $R$ that is self-reducible to $S$. How to prove that $R$ is not polynomial bounded. Actually proving that $R$ is polynomial bounded may be redundant because $S$ is in ${\\sf NP} \\cap {\\sf coNP}$ and it's given that ${\\sf NP} \\cap {\\sf coNP} \\neq {\\sf P} $.</p>\n\n<p><strong>Addendum:</strong> I was given a hint</p>\n\n<p>$R = \\left \\{ (x,1y):(x,y) \\in R_1 \\right \\} \\cup \\left \\{ (x,0y):(x,y) \\in R_2 \\right \\}$</p>\n\n<p>If I will be able to show that search problem relation R is self-reducible to S, than I think the problem is solved.</p>\n", 'ViewCount': '94', 'Title': 'Not self-reducible NP problem', 'LastActivityDate': '2012-12-01T07:19:31.027', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4778', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2012-12-01T07:19:31.027', 'Id': '7072'}{'Body': '<p>I am trying to reduce NOT-ALL-EQUAL SAT to MAX-CUT with weighted edges. </p>\n\n<p>I know that if there are weights to the edges, then I can reduce NOT-ALL-EQUAL SAT to MAX CUT by have a $G$ with $2n$ nodes ($x_i$ and $\\bar{x}_i$) and edges between the nodes based on each clause. And, adding edges between $x_i$ and $\\bar{x}_i$, so on.\nBut, I am not sure how to assign weights if I have to reduce a NOT-ALL-EQUAL SAT to weighted MAX CUT. </p>\n\n<p>How should I go about this problem? </p>\n', 'ViewCount': '272', 'Title': 'NAE SAT reduction to weighted MAX CUT', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-03T18:13:55.633', 'LastEditDate': '2012-12-02T11:40:23.967', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'OwnerDisplayName': 'Pavanred', 'PostTypeId': '1', 'OwnerUserId': '4831', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2012-12-01T22:19:24.880', 'Id': '7097'}{'Body': '<p>It is well-known that 1-in-k SAT is NP-complete for k=3. What about for k > 3?</p>\n', 'ViewCount': '126', 'Title': 'Is 1-in-k SAT NP-complete for k > 3', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-02T11:41:55.400', 'LastEditDate': '2012-12-02T11:41:55.400', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'OwnerDisplayName': 'user12702', 'PostTypeId': '1', 'Tags': '<complexity-theory><reference-request><np-complete>', 'CreationDate': '2012-12-01T00:13:36.670', 'Id': '7098'}{'Body': '<p>What is the best known approximation for the computational complexity of the clique problem? Is it accurate to consider it $O(2^n)$?</p>\n', 'ViewCount': '116', 'Title': 'Computational complexity of the clique problem', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-03T08:10:55.423', 'LastEditDate': '2012-12-03T07:57:07.407', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '7113', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4846', 'Tags': '<complexity-theory><time-complexity><algorithm-analysis>', 'CreationDate': '2012-12-03T00:18:28.903', 'Id': '7112'}{'Body': '<p>Suppose\n$$A = \\left\\{\\langle G, d, s, t\\rangle \\;\\Bigg|\\;\n\\begin{array}{l}\n  \\text{\\(G\\) undirected}, \\\\\n  \\text{\\(s\\) and \\(t\\) are nodes in \\(G\\)}, \\\\\n  \\text{there is a path of length \\(d\\) from \\(s\\) to \\(t\\) and no path of shorter length}\n\\end{array}\\right\\}$$\nI can easily see that this language is in NL, but I am having trouble proving that this is NL-complete.</p>\n', 'ViewCount': '236', 'Title': 'Prove the following problem is NL-complete', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-03T21:04:47.773', 'LastEditDate': '2012-12-03T21:04:47.773', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1718', 'Tags': '<complexity-theory><graphs><space-complexity>', 'CreationDate': '2012-12-03T01:40:51.520', 'Id': '7115'}{'Body': u'<p>The Clique problem takes a graph $G = (V,E)$ and an integer $k$ and asks if $G$ contains a clique of size $k$. (A clique is a set of vertices such that every pair of vertices in the set is adjacent.) The Independent-Set problem takes a graph $G\u2019 = (V\u2019,E\u2019)$ and an integer $k\u2019$ and asks if $G\u2019$ contains an independent set of size $k\u2019$. (An independent set is a set of vertices such that no pair of vertices in the set is adjacent.)</p>\n\n<ol>\n<li><p>Give a polynomial time algorithm that, given a graph $G$ and an integer $k$ produces a graph $G\u2019$ and an integer $k\u2019$ such that $G$ has a clique of size $k$ if and only if $G\u2019$ has an independent set of size $k\u2019$. Justify your answer.</p></li>\n<li><p>Use 1. to prove that the Independent-Set problem is NP-Complete given that the Clique problem is NP-Complete.</p></li>\n</ol>\n', 'ViewCount': '2074', 'Title': 'Reducing Clique to Independent Set', 'LastEditorUserId': '2826', 'LastActivityDate': '2012-12-03T19:13:11.427', 'LastEditDate': '2012-12-03T18:47:25.250', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4828', 'Tags': '<algorithms><complexity-theory><graph-theory><np-complete>', 'CreationDate': '2012-12-03T10:46:11.947', 'Id': '7120'}{'ViewCount': '105', 'Title': 'How is verifying whether an assignment satisfies a boolean formula possible in polynomial time?', 'LastEditDate': '2012-12-03T21:32:10.107', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2860', 'FavoriteCount': '1', 'Body': '<p>How can I prove that I can verify whether a boolean assignment of variables $a$ satisfies some boolean formmula $\\phi$ in polynomial time?</p>\n\n<p>I know that we can just plug the boolean assignment into the formula, but this seems to be a very high-level description, and I am not sure that it is a reliable one since we must simplify the formula.</p>\n', 'Tags': '<complexity-theory><logic><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-03T21:38:26.133', 'CommentCount': '0', 'AcceptedAnswerId': '7135', 'CreationDate': '2012-12-03T21:03:03.350', 'Id': '7134'}{'Body': "<p>I need to know what class of CFL is closed under i.e. what set is complement of CFL.\nI know CFL is not closed under complement, and I know that P is closed under complement. Since CFL $\\subsetneq$ P I can say that complement of CFL is included in P(right?). There is still a question whether complement of CFL is proper subset of P or the whole P. I would appreciate any ideas on how to show that complement of CFL is the whole P(if that's the case of course). </p>\n", 'ViewCount': '1022', 'Title': 'What is complement of Context-free languages?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-05T02:26:08.850', 'LastEditDate': '2012-12-04T16:52:22.483', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7146', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4859', 'Tags': '<complexity-theory><formal-languages><context-free><closure-properties><sets>', 'CreationDate': '2012-12-04T01:48:38.370', 'Id': '7144'}{'Body': "<p>I am really confused about clique problem and clique cover problem. I tried googling it,but I don't see to be able to visualise the clique cover problem.</p>\n", 'ViewCount': '172', 'Title': 'What exactly is a clique cover problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-04T16:59:06.307', 'LastEditDate': '2012-12-04T16:59:06.307', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7157', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4193', 'Tags': '<complexity-theory><terminology><np-complete>', 'CreationDate': '2012-12-04T13:19:51.807', 'Id': '7156'}{'Body': '<p>I read some research that analyzes the hardness of SAT solving in the average case.\nIn fact, for a 3CNF formula if you compute the ratio of clause to variables there is an interval (more or less between 4 and 5) in which solving the formula is hard. But it is easy (between 0 and 4) high probability of satisfiable assignment and high probability of unsatisfiable assignment after ratio 5.</p>\n\n<p>My question is, what about a generic formula that is not in normal form. We can say something about its hardness?</p>\n', 'ViewCount': '121', 'Title': 'Hardness of finding a true or a false assignment into a generic boolean formula?', 'LastEditorUserId': '41', 'LastActivityDate': '2013-02-06T00:32:56.353', 'LastEditDate': '2013-02-06T00:32:56.353', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4887', 'Tags': '<complexity-theory><satisfiability><average-case>', 'CreationDate': '2012-12-05T18:54:17.610', 'Id': '7193'}{'Body': u'<p>I try to figure out linear speed-up of Turing machine.</p>\n\n<p><em>Prove that any problem that can be solved by a two-tape Turing machine that has time complexity t can be solved by another two-tape Turing machine having time complexity $t\u2032$, where $t\u2032(n) = O(n) + (t(n)/2)$.</em></p>\n\n<p>The idea seems to show that what the first machine does within two steps the second machine is capable to do within one step. Time complexity $O(n)$  seems to be complexity of encoding input of first machine to input of second machine.</p>\n\n<p>I have a problem with proving this statement and will appreciate any help.</p>\n\n<p>In addition, why only two-tape Turing machine was mentioned, what about one-tape Turing machine.</p>\n', 'ViewCount': '133', 'Title': 'Speed-up of two-tape Turing machine', 'LastActivityDate': '2012-12-08T11:48:09.560', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7251', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><turing-machines>', 'CreationDate': '2012-12-08T05:35:16.830', 'Id': '7248'}{'Body': '<p>Who was/were the first person/people to introduce the topic of quantum complexity theory and problem classes like BQP and QMA?</p>\n', 'ViewCount': '93', 'Title': 'Origin of quantum complexity theory', 'LastActivityDate': '2012-12-10T17:22:34.170', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7306', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12230', 'Tags': '<complexity-theory><quantum-computing><history>', 'CreationDate': '2012-12-10T07:48:42.793', 'FavoriteCount': '1', 'Id': '7293'}{'Body': '<p>I want to show that reasonable advice can really speed up computation.</p>\n\n<p>Show, that every time-constructible function $t$, there exists a set $S$ in time $\\text{DTIME}(t^2) \\setminus \\text{DTIME}(t)$ that can be decided in linear time using an advice of linear length, $S \\in \\text{DTIME}(l) /  l$ (definition in analogy to $P / \\text{poly}$), where $l(n)=O(n)$.</p>\n\n<p>The problem is that I cannot come up with the structure of set.</p>\n', 'ViewCount': '53', 'Title': 'Advice speeds up computations', 'LastEditorUserId': '683', 'LastActivityDate': '2012-12-10T18:11:09.897', 'LastEditDate': '2012-12-10T18:06:46.360', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7310', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2012-12-10T17:51:28.267', 'Id': '7308'}{'Body': '<p>I am trying to get better in proofs and deep understanding of concept of <strong>computational complexity</strong>. Unfortunately, so far, with no success.</p>\n\n<p>In order to get more intuition, I decided to do more exercises, but most of them are still difficult for me.</p>\n\n<p>I am looking for exercises with solutions in field of computational complexity. Sometimes on course pages there are homeworks with solutions.</p>\n\n<p>I am asking if you aware about any decent course on computational complexity with exercises and solutions on course page, please let me know.</p>\n', 'ViewCount': '190', 'Title': 'execises in computational complexity', 'LastActivityDate': '2012-12-10T19:52:31.313', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '7312', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory>', 'CreationDate': '2012-12-10T18:01:40.410', 'FavoriteCount': '2', 'Id': '7309'}{'Body': '<p>For which values $A,B$ is the problem $\\mathsf{gap\\mathord-VC}\\mathord-[A,B]$ NP-hard? VC is the <a href="http://en.wikipedia.org/wiki/Vertex_cover" rel="nofollow">vertex cover</a> problem. I am given three options: $B=\\frac{3}{4},A=\\frac{1}{2}$ or  $B=\\frac{3}{4},A=\\frac{1}{4}$ or none.</p>\n\n<p>I would to review what I think that I need to do, I\'m not sure that the way I think of it is correct. This is what I think: I need to decide if it NP-hard to approximate the VC to $\\frac{1}{2}$, i.e., can I build an NP Turing machine that would return Yes iff for a given graph, it can guarantee that it has less than $\\frac{1}{4}V$ vertices that cover the whole graph? Maybe even for $\\frac{1}{2}V$ vertices? </p>\n\n<p><sub> This is a question from a past midterm that I\'m solving now in order to prepare myself for my own midterm in a "Computational Complexity Theory" course. </sub></p>\n', 'ViewCount': '67', 'Title': 'For what values of A and B is the gap-VC-[A,B] problem NP-HARD?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-12T20:39:47.017', 'LastEditDate': '2012-12-11T21:29:00.627', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7365', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><graph-theory><approximation>', 'CreationDate': '2012-12-11T19:46:56.387', 'Id': '7332'}{'Body': '<p>The following is an excerpt from <a href="http://www.amazon.ca/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844" rel="nofollow">CLRS</a>:</p>\n\n<blockquote>\n  <p>The definition of $g(n)$ requires that every member $f(n) \\in \\Theta(g(n))$ be asymptotically nonnegative, that is, that $f(n)$ be nonnegative whenever n is sufficiently large. (An asymptotically positive function is one that is positive for all sufficiently large $n$). Consequently, the function $g(n)$ itself must be asymptotically nonnegative, or else the set $g(n)$ is empty. </p>\n</blockquote>\n\n<p>Intuition suggests that having one function with a positive domain while the other with a negative one perverts the purpose of asymptotic analysis (a measure of the order of growth) as the positive function can be an upper asymptotic bound of the negative function simply on merit of it being positive, even in cases where the negative function grows faster.</p>\n\n<p>In cases where <em>both</em> functions have negative domains, asymptotic analysis would still be a valid measure of the order of growth, making the restriction of both functions having to be positive appear useless.</p>\n', 'ViewCount': '58', 'Title': 'Why does every member $f(n) \\in \\Theta(g(n))$, and $g(n)$ have to be asymptotically non-negative?', 'LastActivityDate': '2012-12-11T22:49:01.640', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7343', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4267', 'Tags': '<complexity-theory><asymptotics>', 'CreationDate': '2012-12-11T21:51:09.250', 'Id': '7340'}{'Body': "<p>Show that for $l(n) = \\log \\log n$, it holds that $\\text{DSPACE}(o(l)) = \\text{DSPACE}(O(1))$.</p>\n\n<p>It's well known fact in Space Complexity, but how to show it explicitly?</p>\n", 'ViewCount': '285', 'Title': 'Space complexity below $\\log\\log$', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-13T15:09:01.203', 'LastEditDate': '2012-12-13T15:09:01.203', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7378', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><regular-languages><space-complexity><lower-bounds>', 'CreationDate': '2012-12-13T10:57:13.230', 'Id': '7372'}{'Body': "<p>I'm trying to decide which of the following statements are true:</p>\n\n<ol>\n<li><p>$\\mathsf{NSpace}(\\log \\log n) = \\mathsf{coNSpace}(\\log \\log n )$</p></li>\n<li><p>$\\mathsf{NSpace}(\\lg^2n) = \\mathsf{coNSpace}(\\lg^2n)$</p></li>\n<li><p>$\\mathsf{NSpace}(\\sqrt n) = \\mathsf{coNSpace}(\\sqrt n)$</p></li>\n</ol>\n\n<p>I thought immediately that (1) is correct since $\\lg \\lg n &lt; \\lg n$, and since $\\mathsf{NL} = \\mathsf{coNL}$, I thought that the statement yields from it. I thought that since we don't know if $\\mathsf{P} = \\mathsf{PSPACE}$, we can't say anything about a class which is bigger than $\\lg n$ and a subset of $P$.</p>\n\n<p>But it is exactly the opposite. (1) is not necessarily true while (2) and (3) are necessarily true. Why is that?</p>\n\n<p>The question is from a past midterm that I'm solving now.</p>\n", 'ViewCount': '124', 'Title': 'Equality of NSpace and coNSpace classes', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-14T09:30:50.753', 'LastEditDate': '2012-12-13T21:48:53.410', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7386', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-13T19:16:21.123', 'Id': '7385'}{'Body': '<p>Given a deterministic Turing machine with an input tape and a work tape. The work tape is restricted to $\\log_2 n+100$ cells ($n$ represents the input length) and its tape alphabet is of size $2006$. Moreover, the Turing machine has $27$  states.</p>\n\n<p>I wonder how come the running time of such machine is $O(n^{1+\\log_2 2006}\\cdot \\log_2n)$ (The answer is the correct choice for this multiple choices question out of an exam I practise)</p>\n', 'ViewCount': '68', 'Title': 'How come this turing machine running time is $O(n^{1+\\log_2 2006}\\cdot \\log_2n)$', 'LastEditorUserId': '472', 'LastActivityDate': '2012-12-14T22:12:10.200', 'LastEditDate': '2012-12-14T22:12:10.200', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '7399', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><time-complexity><turing-machines>', 'CreationDate': '2012-12-14T18:55:50.397', 'Id': '7398'}{'Body': '<p>Let $M_U$ be an universal Turing machine which fulfills the following condition:</p>\n\n<blockquote>\n  <p>If $M$ running $x$ takes $f(x)$ space, then $M_U$ running on $\\langle \\langle M\\rangle,x\\rangle$ takes $(f(|x|))^3+2\\cdot|x|+|\\langle M\\rangle|$ space.</p>\n</blockquote>\n\n<p>Why can we conclude from the above that ${\\sf Space}(n^2) \\neq {\\sf Space}(n^7)$?</p>\n', 'ViewCount': '61', 'Title': 'Concluding $SPACE(n^2) \\neq SPACE(n^7)$ from universal turing machine running time', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-15T11:24:06.970', 'LastEditDate': '2012-12-15T11:24:06.970', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7407', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-15T09:49:28.640', 'Id': '7405'}{'Body': '<p>I\'m reviewing for finals and have a sample problem that I <strong>think</strong> I understand, but would like someone to bless my understanding or smack me and tell me why I\'m wrong.</p>\n\n<p>I\'m presented with a problem $\\Pi$  of unknown complexity class.  If I can transform $\\Pi$ to some problem $X$, where $X  \\in {\\sf P}$, what does that tell me about $\\Pi$?</p>\n\n<p>I think allows me to conclude that $\\Pi \\in {\\sf P}$, right? If I can reduce $\\Pi$ to another problem that\'s deterministically solvable in polynomial time, and the transformation itself can be done "easily" in polynomial time, then I can conclude that $\\Pi$ is deterministically solvable in polynomial time, and therefore that $\\Pi \\in {\\sf P}$ correct?</p>\n\n<p>Conversely, given the same input, transforming $X$ to $\\Pi$ in polynomial time allows me to conclude nothing meaningful, since nothing is known about  $\\Pi$ right?</p>\n', 'ViewCount': '110', 'Title': 'Implications of polynomial time reductions', 'LastEditorUserId': '472', 'LastActivityDate': '2012-12-16T19:03:45.837', 'LastEditDate': '2012-12-16T19:03:45.837', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7439', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5084', 'Tags': '<complexity-theory><reductions><complexity-classes><p-vs-np>', 'CreationDate': '2012-12-16T15:28:34.083', 'Id': '7438'}{'Body': '<p>Problems in NP have certificates which can be verified in polynomial time.</p>\n\n<p>It seems conceivable that there could be problems in P which have certificates which can be verified in logarithmic time.  (Such certificates would also have to be logarithmic in size, naturally.)</p>\n\n<p>However, it is also conceivable that there are no such problems.  I\'ve tried to come up with examples, but none of them have worked out so far.</p>\n\n<p>Have problems like this been studied and shown to exist (or not exist)?</p>\n\n<p>I can\'t seem to find a complexity class that would describe them in the <a href="http://complexityzoo.uwaterloo.ca/Complexity_Zoo" rel="nofollow">Complexity Zoo</a>, although it\'s certainly possible that there\'s one there and I\'m just having a hard time identifying it.  (L and LOG usually refer to space, and neither LH nor NLOG looks like it necessarily captures the idea.)</p>\n', 'ViewCount': '69', 'Title': 'Are any problems in P known to have logarithmic-time-verifiable certificates?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-12-23T04:23:58.610', 'LastEditDate': '2012-12-23T04:23:58.610', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '5049', 'Tags': '<complexity-theory><nondeterminism>', 'CreationDate': '2012-12-16T18:10:40.223', 'Id': '7442'}{'ViewCount': '139', 'Title': 'How to find recurrences where Master formula cannot be applied', 'LastEditDate': '2012-12-17T05:27:40.540', 'AnswerCount': '1', 'Score': '3', 'OwnerDisplayName': 'ajmartin', 'PostTypeId': '1', 'OwnerUserId': '4975', 'Body': '<p>Given: $T(n) = T(\\sqrt{n}) + 1$ (base case $T(x) = 1$ for $x&lt;=2$) </p>\n\n<p>How do you solve such a recurrence?</p>\n', 'Tags': '<complexity-theory><algorithms>', 'LastEditorUserId': '4975', 'LastActivityDate': '2012-12-17T05:27:40.540', 'CommentCount': '2', 'AcceptedAnswerId': '7452', 'CreationDate': '2012-12-16T11:49:40.497', 'Id': '7445'}{'Body': '<ol>\n<li><p>How is an arithmetic model defined? </p>\n\n<p>What relations are between it and Turing machine? Are they equivalent in some sense?</p>\n\n<p>Is it true that </p>\n\n<ul>\n<li><p>in the arithmetic model of computation, the basic arithmetic operations (addition, subtraction, multiplication, division, and\ncomparison) take a constant unit time step to perform, regardless of\nthe sizes of the operands.</p></li>\n<li><p>in the Turing machine, the time each operation takes will depends on the storage size of the operands?</p></li>\n</ul>\n\n<p>What is the point of having these two different computational models?</p></li>\n<li><p>Are there other models of computation distinct from the Turing\nmachine and the arithmetic model?</p></li>\n<li><p>There are algorithms which run in polynomial time in the Turing machine model, but not in the arithmetic\nmodel. The\nEuclidean algorithm for computing the greatest common divisor of two\nintegers is one example.</p>\n\n<p>If an algorithm runs in polynomial time in the Turing machine, will\nit run in polynomial time in the arithmetic model?</p></li>\n<li><p>Is an algorithm running in polynomial storage space defined the same under the Turing machine and the arithmetic model?</p></li>\n</ol>\n\n<p>Thanks and regards!</p>\n', 'ViewCount': '458', 'Title': 'Models of computation: the arithmetic model, Turing machine (and ...)', 'LastEditorUserId': '336', 'LastActivityDate': '2012-12-22T00:46:44.670', 'LastEditDate': '2012-12-17T15:39:04.030', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<complexity-theory><computation-models>', 'CreationDate': '2012-12-17T15:08:46.770', 'FavoriteCount': '2', 'Id': '7463'}{'Body': '<p><a href="http://en.wikipedia.org/wiki/Time_complexity#Polynomial_time">Wikipedia</a> defines it to be</p>\n\n<blockquote>\n  <p>An algorithm is said to be of <strong>polynomial time</strong> if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm, i.e., $T(n) = O(n^k)$ for some constant k.</p>\n  \n  <p>The algorithm runs in <strong>strongly polynomial time</strong> if [8]</p>\n  \n  <ul>\n  <li><p>the number of operations in the arithmetic model of computation is bounded by a polynomial in the number of integers in the input\n  instance; and</p></li>\n  <li><p>the space used by the algorithm is bounded by a polynomial in the size of the input.</p></li>\n  </ul>\n</blockquote>\n\n<p>In <a href="http://books.google.com/books?id=8535vmYbLGYC&amp;lpg=PA6&amp;ots=ph1A5hYujO&amp;dq=An%20algorithm%20with%20rational%20input%20is%20said%20to%20run%20in%20polynomial%20time%20if&amp;pg=PA6#v=onepage&amp;q=An%20algorithm%20with%20rational%20input%20is%20said%20to%20run%20in%20polynomial%20time%20if&amp;f=false">Bernhard Korte, Jens Vygen, Combinatorial Optimization</a>:</p>\n\n<blockquote>\n  <p>Definition 1.4. </p>\n  \n  <p>An algorithm with rational input is said to run in <strong>polynomial time</strong> if </p>\n  \n  <ul>\n  <li>there is an integer k such that it runs in $O(n^k)$ time, where n is the input size, and </li>\n  <li>all numbers in intermediate computations can be stored with $O(n^k)$ bits.</li>\n  </ul>\n  \n  <p>An algorithm with arbitrary input is said to run in <strong>strongly\n  polynomial time</strong> if </p>\n  \n  <ul>\n  <li>there is an integer k such that it runs in $O(n^k)$ time for any input consisting of n numbers and </li>\n  <li>it runs in polynomial time for rational input.</li>\n  </ul>\n</blockquote>\n\n<p>Please correct me if I am wrong. Following are the literal differences I noticed:</p>\n\n<ul>\n<li><p>For polynomial time algorithms, Korte and Vygen\'s definition is "the Wikipedia\'s definition + polynomial storage space".</p></li>\n<li><p>For strongly polynomial time algorithms, Korte and Vygen\'s definition and Wikipedia\'s definition both require polynomial time in the input storage size. But K and V\'s additionally requires polynomial time in the number of numbers in any input, while Wikipedia\'s additionally requires polynomial storage space in the input size. </p></li>\n</ul>\n\n<p>So are K and V\'s and Wikipedia\'s definitions for these two concepts equivalent, respectively? What other differences and relations are between them?</p>\n\n<p>Thanks and regards!</p>\n', 'ViewCount': '2080', 'Title': 'Definitions of an algorithm running in polynomial time and in strongly polynomial time', 'LastEditorUserId': '336', 'LastActivityDate': '2012-12-22T03:02:59.167', 'LastEditDate': '2012-12-17T22:12:56.957', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<complexity-theory>', 'CreationDate': '2012-12-17T15:28:13.507', 'FavoriteCount': '1', 'Id': '7464'}{'Body': '<p>From <a href="http://books.google.com/books?id=8535vmYbLGYC&amp;lpg=PA73&amp;dq=instances%20of%20LINEAR%20PROGRAMMING%20are%20vectors%20and%20matrices.%20Since%20no%20strongly%20polynomial-time%20algorithm%20for%20LINEAR%20PROGRAMMING%20is%20known%20we%20have%20to%20restri&amp;pg=PA73#v=onepage&amp;q=instances%20of%20LINEAR%20PROGRAMMING%20are%20vectors%20and%20matrices.%20Since%20no%20strongly%20polynomial-time%20algorithm%20for%20LINEAR%20PROGRAMMING%20is%20known%20we%20have%20to%20restri&amp;f=false" rel="nofollow">Bernhard Korte, Jens Vygen, Combinatorial Optimization,</a></p>\n\n<blockquote>\n  <p>Instances of LINEAR PROGRAMMING are vectors and matrices. Since no\n  <strong>strongly polynomial-time</strong> algorithm for LINEAR PROGRAMMING is known we\n  have to restrict attention to <strong>rational instances</strong> when analyzing the\n  running time of algorithms.</p>\n</blockquote>\n\n<p>I was wondering why does the absence of strongly polynomial time algorithms for linear programming imply restriction to rational instances?</p>\n', 'ViewCount': '91', 'Title': 'Why does absence of strongly polynomial time algorithm for LP imply restriction to rational instances?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-12-17T21:55:38.283', 'LastEditDate': '2012-12-17T19:28:20.687', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<complexity-theory><linear-programming>', 'CreationDate': '2012-12-17T17:14:27.047', 'Id': '7467'}{'Body': '<p>How is asymptotic analysis (big o, little o, big theta, big theta etc.) defined for functions with multiple variables?</p>\n\n<p>I know that the Wikipedia article has a section on it, but it uses a lot of mathematical notation which I am unfamiliar with it. I also found the following paper: <a href="http://people.cis.ksu.edu/~rhowell/asymptotic.pdf">http://people.cis.ksu.edu/~rhowell/asymptotic.pdf</a> However the paper is very long and provides a complete analysis of asymptotic analysis rather than just giving a definition. Again the frequent usage of mathematical notation made it very hard to understand.</p>\n\n<p>Could someone provide a definition of asymptotic analysis <em>without</em> the complex mathematical notation?</p>\n', 'ViewCount': '198', 'Title': 'Asymptotic Analysis for two variables?', 'LastActivityDate': '2012-12-17T23:46:10.497', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7481', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '5105', 'Tags': '<complexity-theory><asymptotics>', 'CreationDate': '2012-12-17T23:13:43.127', 'FavoriteCount': '2', 'Id': '7480'}{'Body': '<p>I try to solve exercise "on the power of double - logarithmic space" from the great textbook <a href="http://books.google.com/books?id=EuguvA-w5OEC&amp;pg=PA176&amp;lpg=PA176&amp;redir_esc=y#v=onepage&amp;q&amp;f=false" rel="nofollow">Computational Complexity by Oded Goldreich. </a>\nThe goal is to show that the given set $S=\\left \\{ w_k \\mid k \\in \\mathbb{N} \\right \\}$, where $w_k$ - concatenation of all $k$-bit long strings separated by *\'s is not regular and yet it is decidable in double-logarithmic space. The exercise contains guidelines, and I would like to shed the light on few sentences from guidelines in order to solve the exercise.</p>\n\n<p>In the guidelines it\'s mentioned that </p>\n\n<blockquote>\n  <p>we can take advantage of of the *\'s (in $w_i$) , the $i$th iteration\n  can be implemented in space $O(\\log i)$</p>\n</blockquote>\n\n<p>The $i$th iteration is verifying whether $x = w_i$, which is really can be decided in $O(\\log i)$ space, where $\\log i$ can be used to note the position in $i$ long string, but the position in $x$ can be included in $O(\\log i)$ or not?</p>\n\n<blockquote>\n  <p>Furthermore, on input $x \\notin S$, we halt and reject after at most\n  $\\log |x|$ iterations.</p>\n</blockquote>\n\n<p>It means only $\\log |x|$ $w$\'s from the set S will be compared to $x$. Why it is actually so?</p>\n\n<blockquote>\n  <p>Actually, it is slightly simpler to handle the related set\n  $\\left \\{w_1**w_2**..**w_k \\right \\}$</p>\n</blockquote>\n\n<p>Why it is actually so, and I would call it set, it is rather concatenated string.</p>\n', 'ViewCount': '91', 'Title': 'Power of Double - Logarithmic Space', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-19T18:01:29.307', 'LastEditDate': '2012-12-19T17:33:42.143', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7515', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-19T17:21:23.247', 'Id': '7511'}{'Body': "<p>Let $L_\\epsilon$ be the language of all $2$-CNF formulas $\\varphi$, such that at least $(\\frac{1}{2}+\\epsilon)$ of $\\varphi$'s clauses can be satisfied.</p>\n\n<p>I need to prove that there exists $\\epsilon'$ s.t $L_\\epsilon$ is $\\mathsf{NP}$-hard for any $\\epsilon&lt;\\epsilon'$.</p>\n\n<p>We know that $\\text{Max}2\\text{Sat}$ can be approximate to $\\frac{55}{56}$ precent of the clauses from a $\\text{Max}3\\text{Sat}$ reduction. How should I solve this one?</p>\n", 'ViewCount': '124', 'Title': "Find $\\epsilon'$ s.t $L_\\epsilon$ is $\\mathsf{NP}$-hard for any $\\epsilon<\\epsilon'$", 'LastEditorUserId': '41', 'LastActivityDate': '2012-12-23T09:24:26.913', 'LastEditDate': '2012-12-23T09:24:26.913', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7528', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '2329', 'Tags': '<complexity-theory><satisfiability><approximation>', 'CreationDate': '2012-12-20T13:11:14.170', 'Id': '7523'}{'Body': u'<p>In [1] <em>strongly-polynomial</em> is defined as either:</p>\n\n<ul>\n<li>The algorithm runs in strongly polynomial time if the algorithm is a polynmomial space algorithm and performs a number of elementary arithmetic operations which is bounded by a polynomial in the number of input numbers.</li>\n<li>A polynomial algorithm is a polynomial space algorithm (in our standard Turing machine model) and polynomial time algorithm in the arithmetic model (see this question for a clarification).</li>\n</ul>\n\n<p>Why do they restrict to polynomial TM space as opposed to polynomial TM time? (this came up <a href="http://cs.stackexchange.com/a/7542/5106">here</a>)</p>\n\n<p>It seems strange for an algorithm that takes a number of TM steps unboundable by a polynomial to still be considered strongly-polynomial (provided it takes polynomial space and a number of arithmetic operations polynomial in the number of numbers in the input). Can it be shown that such an algorithm does not exist? Perhaps based on this argument: the number of arithmetic operations would not be polynomial, since under the arithmetic model every operation is an arithmetic operation (?).</p>\n\n<p>[1] Gr\xf6tschel, Martin; L\xe1szl\xf3 Lov\xe1sz, Alexander Schrijver (1988). "Complexity, Oracles, and Numerical Computation". Geometric Algorithms and Combinatorial Optimization. Springer. ISBN 0-387-13624-X.</p>\n', 'ViewCount': '203', 'Title': 'Are there strongly-polynomial algorithms that take more than polynomial time?', 'LastActivityDate': '2012-12-22T11:18:34.597', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '5106', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2012-12-22T02:53:58.370', 'Id': '7543'}{'Body': '<p>I wrote a function to check equality between integers <code>a</code> and <code>b</code> using bitwise shift operators. Return value of <code>1</code> means both are Equal and <code>0</code> means unequal inputs.</p>\n\n<pre><code>int foo(int a, int b)\n{\n        return ((a&gt;&gt;= b&lt;&lt;= a) ? 1 : 0);\n}\n</code></pre>\n\n<p>How can I prove theoretically that function <code>foo()</code> works for all values in subset of integer range including negative values. If it fails for certain values, can I theoretically find out for what set of values will foo() works correctly.</p>\n', 'ViewCount': '51', 'Title': 'Prove given equality check function works for all subset of integers', 'LastActivityDate': '2012-12-24T01:09:44.367', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'OwnerDisplayName': 'Manav', 'PostTypeId': '1', 'OwnerUserId': '5030', 'Tags': '<complexity-theory><algorithms>', 'CreationDate': '2012-12-19T12:50:26.990', 'Id': '7550'}{'Body': "<p>Prove that the problem of determining if graph is bipartite is computationally equivalent under log-space reductions to $s$-$t$ undirected connectivity. </p>\n\n<p>Problem of $s$-$t$ undirected connectivity is the following given an undirected graph $G = (V, E)$ and two designated vertices, $s$ and $t$, determine whether there is a path from $s$ to $t$ in $G$.</p>\n\n<p>I assume the idea is to consider mapping from graph $G$ to bipartite graph $G'$, there should be a correspondence between edges of $G$ and edges of bipartite graph $G'$, and between edges of $G$ and the edges that violates the bipartite property of graph $G'$. The problem is I cannot come up with such correspondence.</p>\n\n<p>I would appreciate any idea. </p>\n", 'ViewCount': '88', 'Title': 'Bipartite Problem is Log-Space Reducible To $s$-$t$ Undirected Connectivity', 'LastActivityDate': '2012-12-23T20:54:55.873', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2012-12-23T19:35:07.883', 'FavoriteCount': '0', 'Id': '7568'}{'Body': '<p>I received the following assignment:</p>\n\n<p>$\\text{EXACT-TRIPLE} = \\{ \\phi \\mid \\phi \\text{ is a boolean formula that has exactly 3 satisfying assignments} \\}$.</p>\n\n<p>I need to decide whether this problem belongs to NP or not. I assume it does not. How do I prove that?</p>\n', 'ViewCount': '160', 'Title': 'Prove that $\\text{EXACT-TRIPLE}$ is not in NP', 'LastEditorUserId': '472', 'LastActivityDate': '2012-12-25T21:52:14.667', 'LastEditDate': '2012-12-25T21:52:14.667', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '5187', 'Tags': '<complexity-theory><np-complete><satisfiability><np>', 'CreationDate': '2012-12-25T18:00:43.690', 'FavoriteCount': '1', 'Id': '7595'}{'ViewCount': '206', 'Title': 'randomized algorithm for checking the satisfiability of s-formulas, that outputs the correct answer with probability at least $\\frac{2}{3}$', 'LastEditDate': '2013-01-05T20:18:01.783', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1589', 'FavoriteCount': '1', 'Body': "<p>I'm trying to practice myself with random algorithms.</p>\n\n<p>Lets call a CNF formula over n variables s-formula if it is either unsatisable or it has at\nleast $\\frac{2^n}{n^{10}}$ satisfying assignments.</p>\n\n<p>I would like your help with show a randomized algorithm for checking the\nsatisfiability of s-formulas, that outputs the correct answer with probability at\nleast $\\frac{2}{3}$.</p>\n\n<p>I'm not really sure how to prove it. First thing that comes to my head is this thing- let's accept with probability $\\frac{2}{3}$ every input. Then if the input in the language, it was accepted whether in the initial toss($\\frac{2}{3}$) or it was not and then the probability to accept it is $\\frac{1}{3}\\cdot proability -to-accept$ which is bigger than $\\frac{2}{3}$. Is this the way to do that or should I use somehow Chernoff inequality which I'm not sure how.</p>\n", 'Tags': '<complexity-theory><time-complexity><randomized-algorithms>', 'LastEditorUserId': '1589', 'LastActivityDate': '2013-01-05T20:18:01.783', 'CommentCount': '0', 'AcceptedAnswerId': '7748', 'CreationDate': '2012-12-29T09:38:45.680', 'Id': '7641'}{'Body': '<p>3-Coloring problem can be proved NP-Complete making use of the reduction from 3SAT <a href="http://www.ic.unicamp.br/~rezende/ensino/mo417/2010s2/notas/16-nphard.pdf" rel="nofollow">Graph Coloring (from 3SAT)</a>. As a consequence, 4-Coloring problem is NP-Complete using the reduction from 3-Coloring:</p>\n\n<blockquote>\n  <p>Reduction from 3-Coloring instance: adding an extra vertex to the graph of 3-Coloring problem, and making it adjacent to all the original vertices.</p>\n</blockquote>\n\n<p>Following the same reasoning, 5-Coloring, 6-Coloring, and even general $k$-Coloring problem can be proved NP-Complete easily. However, my problem comes out with the underlying mathematical induction:</p>\n\n<blockquote>\n  <p>My Problem: What if the induction goes on to $n-1$-Coloring and $n$-Coloring problem, where $n$ is the number of vertices in the graph? I certainly know that $n$-Coloring problem can be solved trivially. So, is there something wrong with the reasoning? How to understand the reduction from 3-Coloring problem to the general $k$-Coloring one?</p>\n</blockquote>\n\n<p>Thanks for any suggestions.</p>\n', 'ViewCount': '1559', 'Title': 'How to understand the reduction from 3-Coloring problem to general $k$-Coloring problem?', 'LastActivityDate': '2013-01-01T08:24:44.500', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7672', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<complexity-theory><graph-theory><np-complete>', 'CreationDate': '2013-01-01T07:08:05.763', 'Id': '7671'}{'Body': '<p>Is there an undecidable problem which is not NP-hard?</p>\n', 'ViewCount': '162', 'Title': 'Is undecidable(complement of R) a subset of NP-hard?', 'LastActivityDate': '2013-01-01T14:28:59.920', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'OwnerDisplayName': 'cineel', 'PostTypeId': '1', 'Tags': '<complexity-theory><undecidability>', 'CreationDate': '2013-01-01T06:43:12.347', 'Id': '7676'}{'Body': "<p>This is my first post after being a passive user for some time now.\nI wish to ask some questions if I may.  I am not a mathematician but my question relates to the field of maths/computer science.  In particular, the P vs NP problem.  I am aware that this is a problem that elite professionals have not yet been able to solve ... </p>\n\n<p>Regardless, I would like to ask:</p>\n\n<p>If a person who is neither a mathematician nor a programmer were to come up with a flowchart or a series of steps written in basic English that allegedly provides a solution to one of the P vs NP problem, would that be counted as 'proving' that P = NP .. in order to claim the Clays Institute prize :) ? Or is it a must for one to write the solution as mathematical proofs / computer program?</p>\n\n<p>Thank you.</p>\n", 'ViewCount': '1273', 'Title': 'Proving P = NP without mathematical statements / computer program', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-23T18:41:59.157', 'LastEditDate': '2013-01-14T11:33:59.730', 'AnswerCount': '3', 'CommentCount': '4', 'AcceptedAnswerId': '7727', 'Score': '9', 'OwnerDisplayName': 'user5287', 'PostTypeId': '1', 'Tags': '<complexity-theory><p-vs-np>', 'CreationDate': '2013-01-03T10:32:51.870', 'Id': '7726'}{'Body': '<blockquote>\n  <p>Is it $\\mathsf{NP}$-hard to decide whether $\\mathsf{P}=\\mathsf{NP}$ ?</p>\n</blockquote>\n\n<p>If so, what are the implications ? Is there result suggesting that it is the case ?</p>\n', 'ViewCount': '245', 'Title': 'Is it $\\mathsf{NP}$-hard to decide whether $\\mathsf{P}=\\mathsf{NP}$?', 'LastActivityDate': '2013-01-30T07:42:06.680', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '7755', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '4706', 'Tags': '<complexity-theory>', 'CreationDate': '2013-01-03T20:06:03.487', 'FavoriteCount': '1', 'Id': '7737'}{'Body': u'<p>I am struggling in trying to figure out a non-deterministic algorithm for the following problem.</p>\n\n<p>Consider the following problem, called the \ufb01gure-of-eight problem (FOE). An instance is an undirected graph $G = (V,E)$ with vertices $V$ and edges $E$. $G$ is a yes-instance if there is a sequence of vertices $(v_{0},v_{1},...,v_{k+1})\\ (some\\ k \\geq 6)$ such that</p>\n\n<p>\u2022 Each pair $(v_{i},v_{i+1})$ is an edge $(each\\ i &lt; k \u2212 1)$ and $(v_{k\u22121},v_{0})$ is an edge. </p>\n\n<p>\u2022 Every vertex in $V$ occurs at least once in the sequence. </p>\n\n<p>\u2022 There is $j$ with $2 &lt; j &lt; k \u2212 2$ such that $v_{0} = v_{j}$. </p>\n\n<p>\u2022 No other vertex in the sequence is counted twice, i.e. if $v_{s} = v_{t} (any\\ s,t &lt; k)$ then either $s = t$ or ${s,t} = {0,j}$.</p>\n\n<p>If there is no such sequence of vertices then $G$ is a no-instance of FOE.</p>\n\n<p>Thanks</p>\n', 'ViewCount': '106', 'Title': 'Non-deterministic algorithm for solving figure of 8', 'LastActivityDate': '2013-01-04T14:17:12.447', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '7757', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5300', 'Tags': '<algorithms><complexity-theory><graphs><nondeterminism>', 'CreationDate': '2013-01-04T13:03:33.720', 'Id': '7756'}{'Body': "<p>Given some complexity class $\\mathsf{C}$, I want to know if there exists a function (Turing machine) $F:\\mathbb{N} \\to \\mathsf{C}$ such that, if $S$ is any set for which the problem $x \\mapsto x \\in S$ is in $\\mathsf{C}$, then $F(n)$ is a Turing machine which (partially, if $\\mathsf C = \\mathsf{RE}$) decides $x \\in S$ for some $n$.</p>\n\n<p>Note that if $g$ and $h$ are two Turing machines that decide $x \\in S$, then $F$ only needs to enumerate one of them (hopefully this makes the problem easier). Thus the title is a bit wrong, but kept as it is for lack of a better one.</p>\n\n<p>Trivially, if $\\mathsf{C}$ equals something in the Chomsky hierarchy, such machine $F$ exists (enumerating all grammars of the required type). I'm interested in the less obvious classes.</p>\n", 'ViewCount': '88', 'Title': 'Which complexity classes are $\\mathsf{RE}$?', 'LastActivityDate': '2013-01-04T20:40:13.800', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '7765', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '5167', 'Tags': '<complexity-theory><computability>', 'CreationDate': '2013-01-04T18:09:33.833', 'Id': '7764'}{'ViewCount': '298', 'Title': 'Prove or refute: BPP(0.90,0.95) = BPP', 'LastEditDate': '2013-01-07T22:38:45.893', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '1589', 'FavoriteCount': '3', 'Body': '<p>I\'d really like your help with the proving or refuting the following claim: $BPP(0.90,0.95)=BPP$. In computational complexity theory, BPP, which stands for <a href="http://en.wikipedia.org/wiki/BPP_%28complexity%29">bounded-error probabilistic polynomial time</a> is the class of decision problems solvable by a probabilistic Turing machine in polynomial time, with an error probability of at most $\\frac{1}{3}$ for all instances. $BPP=BPP(\\frac{1}{3},\\frac{2}{3})$.</p>\n\n<p>It is not immediate that any of the sets are subset of the other, since if the probability for an error is smaller than $0.9$ it doesn\'t have to be smaller than $\\frac{1}{3}$ and if it is bigger than $\\frac{2}{3}$ it doesn\'t have to be bigger than $0.905$. </p>\n\n<p>I\'m trying to use Chernoff\'s inequality for proving the claim, I\'m not sure exactly how.\nI\'d really like your help. Is there a general claim regarding these relations that I can use?</p>\n', 'Tags': '<complexity-theory><time-complexity><probabilistic-algorithms>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-08T19:20:38.810', 'CommentCount': '4', 'AcceptedAnswerId': '7829', 'CreationDate': '2013-01-07T21:40:43.267', 'Id': '7820'}{'ViewCount': '241', 'Title': 'Concrete understanding of difference between PP and BPP definitions', 'LastEditDate': '2013-02-15T07:31:32.413', 'AnswerCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '5356', 'FavoriteCount': '3', 'Body': '<p>I am confused about how  <strong>PP</strong> and <strong>BPP</strong> are defined. Let us assume $\\chi$ is the characteristic function for a language $\\mathcal{L}$. <em>M</em> be the probabilistic Turing Machine. Are the following definitions correct:<br>\n$BPP =\\{\\mathcal{L} :Pr[\\chi(x) \\ne M(x)] \\geq \\frac{1}{2} + \\epsilon \\quad \\forall x \\in \\mathcal{L},\\ \\epsilon &gt; 0 \\}$<br>\n$PP =\\{\\mathcal{L} :Pr[\\chi(x) \\ne M(x)] &gt; \\frac{1}{2} \\}$  </p>\n\n<p>If the definition are wrong, please try to make minimal change to make them correct (i.e. do not give other equivalent definition which use counting machine or some modified model). I can not properly distinguish the conditions on probability on both the definitions.  </p>\n\n<p>Some concrete examples with clear insight into the subtle points would be very helpful. </p>\n', 'Tags': '<complexity-theory><terminology><randomized-algorithms><complexity-classes>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-15T07:31:32.413', 'CommentCount': '0', 'AcceptedAnswerId': '7849', 'CreationDate': '2013-01-09T11:28:04.633', 'Id': '7848'}{'Body': '<p>Does the proof of the widely believed result P $\\neq$ NP depend on the proof of NP $\\neq$ Co-NP ?</p>\n', 'ViewCount': '201', 'Title': 'If NP $\\neq$ Co-NP then is P $\\neq$ NP', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-12T17:03:17.257', 'LastEditDate': '2013-01-12T17:03:17.257', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'OwnerDisplayName': 'Arjun J Rao', 'PostTypeId': '1', 'OwnerUserId': '5418', 'Tags': '<complexity-theory><complexity-classes><p-vs-np>', 'CreationDate': '2013-01-10T01:36:06.260', 'Id': '7861'}{'Body': "<p>We have a broken stick. For every part, we know it's length. Our task is to connect all parts (glue them), that we will use as small amount of glue as possible. </p>\n\n<p>The amount of glue need to connect two parts equal the maximum from their sizes. We can only glue two parts at one time.Can we solve this problem in the time complexity smaller than $O(n^3)$? I know only the answer, using dynamic table in this complexity</p>\n", 'ViewCount': '136', 'Title': 'Broken stick problem', 'LastActivityDate': '2013-01-11T04:51:06.967', 'AnswerCount': '2', 'CommentCount': '10', 'AcceptedAnswerId': '7882', 'Score': '0', 'OwnerDisplayName': 'Jonny', 'PostTypeId': '1', 'OwnerUserId': '5381', 'Tags': '<complexity-theory><algorithms><dynamic-programming>', 'CreationDate': '2013-01-09T12:40:44.533', 'Id': '7881'}{'Body': '<p>The subset-sum problem is a classic NP-complete problem:</p>\n\n<blockquote>\n  <p>Given a list of numbers $L$ and a target $k$, is there a subset of numbers from $L$ that sums to $k$?</p>\n</blockquote>\n\n<p>A student asked me if this variant of the problem called the "subset product" problem is NP-complete:</p>\n\n<blockquote>\n  <p>Given a list of numbers $L$ and a target $k$, is there a subset of numbers from $L$ whose product is $k$?</p>\n</blockquote>\n\n<p>I did some searching and couldn\'t find any resources that talked about this problem, though perhaps I missed them.</p>\n\n<p>Is the subset product problem NP-complete?</p>\n', 'ViewCount': '722', 'Title': 'Is the "subset product" problem NP-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-14T11:05:59.723', 'LastEditDate': '2013-01-14T11:05:59.723', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2131', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-01-12T18:23:55.230', 'Id': '7907'}{'Body': '<p>Say I have numbers with known factorizations $n = \\prod \\limits _i p_i ^{n_i}$ and  $m = \\prod \\limits _i p_i ^{m_i}$ (where $p_i$ is the $i$th prime).</p>\n\n<p>How hard is it to factorize $m+n$? Is there a more intelligent algorithm than if factorizations of $m$ and $n$ were not known? Assume $n$ and $m$ coprime as it is trivial to make them so.</p>\n\n<p>The fact that $m+n$ will share no factors with $n$ or $m$ seems very helpful for small numbers, but I doubt it offers much for large ones.</p>\n', 'ViewCount': '79', 'Title': 'How hard is it to factorize sum of two numbers', 'LastActivityDate': '2014-03-20T00:45:27.843', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '22836', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '5167', 'Tags': '<complexity-theory><factoring>', 'CreationDate': '2013-01-13T11:05:21.217', 'Id': '7921'}{'Body': u"<p>I was reading a few notes on Proof by Restriction and I am confused:</p>\n\n<p>A Valid Proof by Restriction is the following:</p>\n\n<p>Directed Hamiltonian Cycle Problem is NP Complete because if we look only at <em>instances</em> of DHC where For $G=(V,E)\\quad (u,v)\\in E \\leftrightarrow (v,u) \\in E$ then it reduces to Hamiltonian Cycle which we know is NP complete. </p>\n\n<p>A <em>wrong</em> proof is the following:</p>\n\n<blockquote>\n  <p><strong>Subset Sum problem</strong><br>\n  INSTANCE: Integers $a_1, a_2,\u2026,a_n$ and integer B.</p>\n  \n  <p>QUESTION: Is there a sequence of 0\u2019s and 1\u2019s, $x_1, x_2,\u2026,x_n$ such that:\n  $$\\sum_{i=1}^n a_ix_i \\leq B$$</p>\n</blockquote>\n\n<p>is a special case of </p>\n\n<blockquote>\n  <p><strong>Real Subset Problem</strong>\n  INSTANCE: Integers $a_1, a_2,\u2026,a_n$ and integer B.</p>\n  \n  <p>QUESTION: Is there a sequence of real numbers  $x_1, x_2,\u2026,x_n$  such that:\n  $$\\sum_{i=1}^n a_ix_i \\leq B$$</p>\n</blockquote>\n\n<p>so it is NP Complete. </p>\n\n<p>My notes say that the this proof is wrong since it restricts the question and not the instances but I don't seem to understand the difference. </p>\n\n<p>Further, I can't really understand how Proof by Restriction works; for all I know I could be restricting an NP Complete problem to a trivial case which can be solved in Polynomial time. </p>\n", 'ViewCount': '180', 'Title': 'Proof by restriction: when is it valid to restrict to a special case?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-14T19:50:05.860', 'LastEditDate': '2013-01-14T19:50:05.860', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '7934', 'Score': '3', 'OwnerDisplayName': 'user6422', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><proof-techniques>', 'CreationDate': '2013-01-13T22:00:32.870', 'Id': '7931'}{'ViewCount': '259', 'Title': 'Is there a sometimes-efficient algorithm to solve #SAT?', 'LastEditDate': '2013-01-16T01:27:21.360', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '1786', 'FavoriteCount': '2', 'Body': '<p>Let $B$ be a boolean formula consisting of the usual AND, OR, and NOT operators and some variables.  I would like to count the number of satisfying assignments for $B$. That is, I want to find the number of different assignments of truth values to the variables of $B$ for which $B$ assumes a true value. For example, the formula $a\\lor b$ has three satisfying assignments; $(a\\lor b)\\land(c\\lor\\lnot b)$ has four. This is the <a href="https://en.wikipedia.org/wiki/Sharp-SAT">#SAT problem</a>.</p>\n\n<p>Obviously an efficient solution to this problem would imply an efficient solution to SAT, which is unlikely, and in fact this problem is #P-complete, and so may well be strictly harder than SAT. So I am not expecting a guaranteed-efficient solution.</p>\n\n<p>But it is well-known that there are relatively few really difficult instances of SAT itself. (See for example <a href="http://www.dcs.gla.ac.uk/~pat/cpM/papers/cheeseman91where.pdf">Cheeseman 1991, "Where the <em>really</em> hard problems are"</a>.) Ordinary pruned search, although exponential in the worst case, can solve many instances efficiently; resolution methods, although exponential in the worst case, are even more efficient in practice.  </p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Are any algorithms known which can quickly count the number of satisfying assignments of a typical boolean formula, even if such algorithms require exponential time in the general instance? Is there anything noticeably better than enumerating every possible assignment?</p>\n</blockquote>\n', 'Tags': '<complexity-theory><reference-request><satisfiability>', 'LastEditorUserId': '1786', 'LastActivityDate': '2013-06-25T05:37:04.663', 'CommentCount': '4', 'AcceptedAnswerId': '8953', 'CreationDate': '2013-01-16T00:21:03.510', 'Id': '8952'}{'Body': '<p>For the $n$-th prime number $p_n$ the <em><a href="http://en.wikipedia.org/wiki/Primorial" rel="nofollow">primorial</a></em> $p_n\\#$ is defined as the product of the first $n$ primes.</p>\n\n<blockquote>\nWhat is the complexity of testing if a given number $n$ is a primorial?<br>\nIs it related in some way to the FACTORING problem?<br>\n</blockquote>\n', 'ViewCount': '46', 'Title': 'Complexity of testing if a number is a primorial', 'LastActivityDate': '2013-01-16T09:25:14.040', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '8962', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<complexity-theory><reference-request>', 'CreationDate': '2013-01-16T08:33:30.810', 'Id': '8960'}{'Body': "<p>Consider the following problem:  Given two graphs $G_1 = (V_1, E_1)$ and $G_2 = (V_2, E_2)$ and some non-negative integer $k \\in \\mathbb{N}$, is it possible to delete at most $k$ vertices from $G_1$ to obtain $G_1'$ such that $G_1' \\cong G_2$, i.e. the resulting graph is isomorphic to $G_2$.</p>\n\n<p>I have to show that this problem is NP-complete.</p>\n\n<p>Can somebody help me with this problem? It is school homework and I don't know how to solve it.</p>\n", 'ViewCount': '271', 'Title': 'How to prove this isomorphism-related graph problem is NP-complete?', 'LastEditorUserId': '472', 'LastActivityDate': '2014-01-09T14:38:21.540', 'LastEditDate': '2014-01-09T14:38:21.540', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'OwnerDisplayName': 'Charlie', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-01-16T13:04:17.763', 'FavoriteCount': '1', 'Id': '8970'}{'ViewCount': '162', 'Title': 'Complexity of a subset sum variant', 'LastEditDate': '2013-05-24T03:32:02.207', 'AnswerCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '1', 'Body': "<p>Is this variant of the subset sum problem easy/known?</p>\n\n<blockquote>\nGiven an integer $m$, and a set of positive integers $A = \\{x_1, x_2, ..., x_n\\}$ such that every $x_i$ has at most $k=2$ bits set to $1$ ($x_i = 2^{b_{i_1}}+2^{b_{i_2}},\\;\\; b_{i_1},b_{i_2}\\geq 0$); is there a subset $A' \\subseteq A$ such that the sum of its elements is equal to $m$ ?<br>\n</blockquote>\n\n<p>Is it in $\\sf{P}$? Is it still $\\sf{NP}$-complete?</p>\n\n<p>And if every $x_i$ has at most $k=3$ bits set to $1$? For $k=1$ the problem is trivial.</p>\n", 'Tags': '<complexity-theory><reference-request><decision-problem>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:32:02.207', 'CommentCount': '0', 'AcceptedAnswerId': '9004', 'CreationDate': '2013-01-17T13:23:39.540', 'Id': '8988'}{'Body': "<p>From what I've read, Big O is the absolute worst ever amount of complexity an algorithm will be given an input. On the side, Big Omega is the best possible efficiency, i.e. lowest complexity.</p>\n\n<p>Can it be said then that every algorithm has a complexity of  $O(\\infty)$ since infinite complexity is the worst ever possible?\nBy the same token, can it be said that every algorithm is $\\Omega(1)$ since the absolute lowest complexity an algorithm can be is a constant?</p>\n", 'ViewCount': '208', 'Title': "Is every algorithm's complexity $\\Omega(1)$ and $O(\\infty)$?", 'LastEditorUserId': '55', 'LastActivityDate': '2013-01-18T05:27:12.653', 'LastEditDate': '2013-01-18T05:27:12.653', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9000', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4348', 'Tags': '<complexity-theory><algorithm-analysis><asymptotics>', 'CreationDate': '2013-01-17T18:16:04.023', 'Id': '8998'}{'Body': '<p>Finding Big-O is pretty straightforward for an algorithm where $f(n)$ is</p>\n\n<p>$$f(n) = 3n^4 + 6n^3 + 10n^2 + 5n + 4$$</p>\n\n<p>The lower powers of $n$ simply fall off because in the long run $3n^4$ outpaces all of them. And with $g(n) = 3n^4$ we say $f(n)$ is $O(n^4)$.</p>\n\n<p>But what would Big-O be if instead of 3 we were given a really small constant, for example \n$$f(n) = 0.0000000001n^4 + 6n^3 + 10n^2 + 5n + 4$$</p>\n\n<p>Would we still say $f(n)$ is $O(n^4)$?</p>\n', 'ViewCount': '115', 'Title': 'Big-O complexity when c is a tiny fraction', 'LastActivityDate': '2013-01-18T06:39:20.660', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '9003', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4348', 'Tags': '<complexity-theory><algorithm-analysis>', 'CreationDate': '2013-01-17T21:17:33.200', 'Id': '9002'}{'Body': '<p>This question follows on previous questions <a href="http://cs.stackexchange.com/questions/6562/generalizing-the-comparison-sorting-lower-bound-proof">(1)</a>, <a href="http://cs.stackexchange.com/questions/7349/proofs-based-on-narrowing-down-sets-of-possibilities">(2)</a>, where we define an initial space of possibilities and reason about how a solution is chosen from that.</p>\n\n<p>Consider a problem P where we are given:</p>\n\n<ol>\n<li>the initial space of possibilities is exponential in the size of the input,</li>\n<li>the search space decreases monotonically as we read the input, </li>\n<li>for the algorithm that correctly computes P and has <a href="http://courses.csail.mit.edu/6.841/spring09/scribe/lect16.pdf" rel="nofollow">the minimum worst-case performance</a>, the search space is still exponential in the size of the input even after the final input is read.</li>\n</ol>\n\n<p>Can we conclude that P requires exponential time? If not, what would a polynomial-time counterexample look like?</p>\n', 'ViewCount': '110', 'Title': 'Search spaces and computation time', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-18T15:13:27.137', 'LastEditDate': '2013-01-18T15:13:27.137', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1295', 'Tags': '<complexity-theory><proof-techniques><lower-bounds>', 'CreationDate': '2013-01-18T06:25:20.673', 'Id': '9013'}{'Body': '<p>I try to figure out <strong>a redundant power of two-sided error randomized Karp - reduction.</strong></p>\n\n<p>It\'s well known fact and it is relatively hard to show that <a href="http://en.wikipedia.org/wiki/BPP_(complexity)" rel="nofollow">BPP</a> is reducible by a one-sided error randomized Karp-reduction to coRP (in case of promise problem).</p>\n\n<p>Without delving into details it make sense that the combination of the one - sided error probability of the reduction and the one-sided error probability of coRP leads to two-sided error probability of BPP. Of course the proof of that is not so intuitive.</p>\n\n<p>The question it is possible by two-sided error randomized Karp-reduction to reduce BPP to some constant set in P? In the light of the power of one - sided randomized Karp - reduction, it make sense that two-sided randomized Karp - reduction is strong enough to reduce BPP to constant set, but how to show it formally?</p>\n\n<p><strong>Addendum:</strong></p>\n\n<p><strong>BPP</strong> is the set of the problems that is solvable in polynomial time by two-sided error randomized algorithm, so as a result of two - sided error randomized algorithm we will get some output, them the problem in BPP can be reduced to problem P by two-sided error randomized Karp - reduction in sense that reduction is allowed to make error on both sides. Does it mean that two - sided error randomized reduction will justify the two-sided error that was made by the algorithm in solving the problem in BPP?</p>\n', 'ViewCount': '97', 'Title': 'The Power of Randomized Reduction', 'LastEditorUserId': '1379', 'LastActivityDate': '2013-10-05T07:50:18.583', 'LastEditDate': '2013-01-21T09:54:55.740', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><reductions><randomized-algorithms>', 'CreationDate': '2013-01-19T09:56:05.707', 'Id': '9037'}{'Body': '<p>I\'d like your help with the following question:</p>\n\n<p>Assume we proved that $\\mbox{BPP}\\subseteq \\Pi_2$ -What conclusions can you make?</p>\n\n<p><a href="http://en.wikipedia.org/wiki/BPP_%28complexity%29" rel="nofollow">BPP </a> is  the class of decision problems solvable by a probabilistic Turing machine in polynomial time, with an error probability of at most 1/3 for all instances, </p>\n\n<p>$\\Pi_2$ is the class of all languages $L$ such that there\'s a polynomial algorithm $M$ and a polynom $p$ so that $\\forall x.x\\in L\\Leftrightarrow \\forall u\\in \\{ 0,1 \\}^*.\\exists v \\in \\{ 0,1 \\}^*.M(x,u,v)=1$.</p>\n\n<p>We already know that   $\\mbox{BPP}\\subseteq \\Sigma_2$, so $\\mbox{BPP}\\subseteq \\Pi_2\\cap \\Sigma_2$.</p>\n', 'ViewCount': '78', 'Title': 'Assuming $\\mbox{BPP}\\subseteq \\Pi_2$ -What conclusions can we make?', 'LastActivityDate': '2013-01-20T17:11:01.780', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2329', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-01-19T19:40:47.960', 'Id': '9045'}{'ViewCount': '633', 'Title': 'NP-Hard that is not NP-Complete and not Undecidable', 'LastEditDate': '2013-01-21T10:57:39.683', 'AnswerCount': '2', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '6495', 'FavoriteCount': '3', 'Body': '<p>I\'m wondering if there is a good example for an easy to understand <a href="http://en.wikipedia.org/wiki/NP-hard">NP-Hard</a> problem that is not <a href="http://en.wikipedia.org/wiki/NP-complete">NP-Complete</a> and not undecidable?</p>\n\n<p>For example, the <a href="http://en.wikipedia.org/wiki/Halting_problem">halting problem</a> is NP-Hard, not NP-Complete, but is undecidable.</p>\n\n<p>I believe that this means that it is a problem that a solution for can be verified but not in polynomial time. (Please, correct this statement if this is not the case).</p>\n', 'Tags': '<complexity-theory><np-complete><np-hard>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-18T14:07:47.700', 'CommentCount': '0', 'AcceptedAnswerId': '9064', 'CreationDate': '2013-01-21T01:13:41.927', 'Id': '9063'}{'Body': '<p>The question is: What is the smallest complexity class in which the following problem is contained: Given a graph with $n$ nodes, Is there independent set of size of at least $n-10$? </p>\n\n<p>I have a little difficulty to understand the meaning of being in ${\\sf L}$ and examine problems in a correct way for deciding if they are in ${\\sf NL}$ or ${\\sf L}$ </p>\n\n<p>First I know that for being in ${\\sf NL}$ I need to provide a verifier for a Turing machine which uses only $O(\\log n)$ space on its working tape- So I wonder- I can give as a verifier this set of nodes to be independent set as requested, but how does the checking work? Can it go to all the lists of the pointers to the neighbors of each node , and for every node to check whether all the other nodes in the set given as independent set is not on that list- Is this considered of not using any space and I only need to count the nodes in the list that fulfill the requirement and therefore use only $O(\\log n)$ space? Is this correct? Is there a way to prove that the problem is in ${\\sf L}$?</p>\n', 'ViewCount': '94', 'Title': 'NL- definition and a problem', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-01-21T22:41:27.887', 'LastEditDate': '2013-01-21T20:28:19.350', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2126', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-01-21T18:27:59.220', 'Id': '9075'}{'Body': "<p>I know that $\\sf BPP[2/3,1/3]= BPP[\\alpha,\\beta]$ when $\\alpha\\lt\\beta$, but I read something on Wikipedia which got me confused:</p>\n\n<blockquote>\n  <p>In practice, an error probability of $1/3$ might not be acceptable, however, the choice of $1/3$ in the definition is arbitrary. It can be any constant between $0$ and $1/2$ (exclusive) and the set $\\mathsf{BPP}$ will be unchanged.</p>\n</blockquote>\n\n<p>The reason for my question is the this question that I'm trying to answer:</p>\n\n<p>We define the class $PP_{\\frac{7}{8}}$: $L \\in PP_{\\frac{7}{8}}$. There's a probabilistic Turing machine that  for $x \\in L$ accepts $x$ with probability $&gt;$ than $\\frac{7}{8}$ and for $x \\notin L$ it accepts $x$ with probabilty $\\leq \\frac{7}{8}$.</p>\n\n<p>So by the $\\alpha, \\beta$ first definition I can conclude  that $PP_{\\frac{7}{8}}$ which  equals to $\\sf BPP[7/8,7/8+\\epsilon]$ also equals to $\\sf BPP[2/3,1/3]$ but the I am asked to prove that $\\sf NP \\subseteq  BPP$ which we don't know yet.</p>\n", 'ViewCount': '52', 'Title': 'BPP clarification', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-21T21:48:07.393', 'LastEditDate': '2013-01-21T21:48:07.393', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><time-complexity><probabilistic-algorithms>', 'CreationDate': '2013-01-21T21:06:27.130', 'Id': '9077'}{'Body': "<p>Here's a simple question which made me confused.</p>\n\n<p>Please tell me if my analysis of the problem and my conclusions are correct.</p>\n\n<p>For an optimization problem $\\sf Gap-A[a,b] \\in L$ for $b&gt;a$. I want to discuss what I can know about $\\sf Gap-A[a/2,b/2]$. </p>\n\n<p>$\\sf(i)$ Is it correct to say that $\\sf Gap-A[a/2,b/2]$ is not in $\\sf NP-Hard$ and it is easy only because the realtion $\\frac{a/2}{b/2}=\\frac{a}{b}$ and we already know that it is easy to approximate $A$ with  factor of $a/b$? </p>\n\n<p>$\\sf (ii)$ Is it true that I can't say though that $\\sf Gap-A[a/2,b/2]$ is in $\\sf L$ since there is no intersection between the gaps? In order that gap $B$ would be in the exact class that gap $A$ is in, we have to have $A \\subseteq B$?</p>\n", 'ViewCount': '69', 'Title': 'Gap problems clarifation', 'LastEditorUserId': '1183', 'LastActivityDate': '2013-01-23T06:08:01.450', 'LastEditDate': '2013-01-22T22:25:03.647', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1183', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-01-22T11:53:58.257', 'Id': '9090'}{'Body': '<p>Is it possible to design a Universal Turing Machine in which the simulation time of a given Turing Machine $M$ is bounded by a factor of $\\mathcal{O}(\\log|\\Gamma|+\\log|Q|)$ of the original running-time of $M$, where $\\Gamma$ and $Q$ are the tape alphabet and states of $M$ respectively?</p>\n\n<p>If so, how can this be done?</p>\n', 'ViewCount': '196', 'Title': 'Universal Turing Machine simulation with bounded time overhead', 'LastEditorUserId': '41', 'LastActivityDate': '2013-01-30T04:28:32.270', 'LastEditDate': '2013-01-30T04:28:32.270', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '6522', 'Tags': '<complexity-theory><turing-machines>', 'CreationDate': '2013-01-23T16:10:18.437', 'Id': '9115'}{'ViewCount': '147', 'Title': "Where can I find a short and 'easy' peer reviewed paper on something from computability, decidability or complexity?", 'LastEditDate': '2013-01-26T20:49:07.570', 'AnswerCount': '5', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6572', 'FavoriteCount': '2', 'Body': "<p>It's a homework assignment, we were asked to read, understand, and present to our colleagues a short paper/article (suggested 4-6 pages) for our Computability, Decidability or Complexity class.</p>\n\n<p>The articles I was able to find in the past couple days using google scholar a way over what we were taught, plus, 50-100+ pages is way over the scope of my assignment. In class, we were provided with an introduction to the three topics, complexity classes, relations between them, and (mostly informal) proofs for the most representative problems from each class by modelling them using all kinds of Turing Machines.</p>\n\n<p>Any possible solutions? It's the first time in my life I'm touching anything related to research, I can barely understand even the scope of most papers I find.. I guess any advice would be welcome.</p>\n", 'Tags': '<complexity-theory><computability><turing-machines><research>', 'LastEditorUserId': '6572', 'LastActivityDate': '2013-01-30T15:17:09.530', 'CommentCount': '0', 'AcceptedAnswerId': '9179', 'CreationDate': '2013-01-26T20:36:18.643', 'Id': '9178'}{'Body': '<p>obviously the "Finding an $n/2$ size clique in a directed/ non directed graph" is not $\\sf NL$ but I\'d really like to understand where does it fall in terms of the definition of the $\\sf NL$ definition.</p>\n\n<p>I have to have an input and witness tapes, both of them can be polynomial and a logarithmic size of work stripe. So why can\'t I just guess an $n/2$ clique, each time put 2 vertices on the work tape, check that they share an edge, and count them. The witness tape provides me each time two vertices from left to write, in total $O({\\frac{n}{2}}^2)$. In order to count that I need $O(\\log ({\\frac{n}{2}}^2))$ which is logarithmic. so what\'s lacking or wrong with this attempt?</p>\n', 'ViewCount': '90', 'Title': 'How come finding an $n/2$ size clique in a directed/ non directed graph is not in $\\sf NL$?', 'LastActivityDate': '2013-01-30T03:19:57.180', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2329', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-01-27T07:19:51.583', 'Id': '9198'}{'Body': '<p>SAT [5] can be solved with resolution definitively, i.e. if the formula has a true assignment, resolution can find it, and if it cant be satisfied, resolution can show that no assignment exists (at least in exponential time/space.). [4] </p>\n\n<blockquote>\n  <p>Is there a good fully-self contained description somewhere of solving SAT with resolution?</p>\n</blockquote>\n\n<p>The descriptions on Wikipedia of resolution are focused on a single logical operation, not how to use it in an algorithm to solve SAT, and the Davis Putnam algorithm is described mostly in terms of 1st order logic. I am looking for a description of solving SAT with resolution that does not refer to 1st order logic, just in terms of boolean input variables. Online description is preferred if possible. The connection with DPLL would be helpful also.</p>\n\n<hr>\n\n<p>[1] <a href="http://en.wikipedia.org/wiki/Davis-Putnam_algorithm" rel="nofollow">Davis Putnam algorithm</a>, Wikipedia</p>\n\n<p>[2] <a href="http://en.wikipedia.org/wiki/Resolution_%28logic%29" rel="nofollow">Resolution in logic</a>, Wikipedia</p>\n\n<p>[3] <a href="http://en.wikipedia.org/wiki/DPLL_algorithm" rel="nofollow">Davis Putnam Logemann Loveland algorithm</a>, Wikipedia</p>\n\n<p>[4] <a href="http://cs.stackexchange.com/questions/9095/is-resolution-complete-or-only-refutation-complete">Is resolution complete or only refutation-complete?</a></p>\n\n<p>[5] <a href="http://en.wikipedia.org/wiki/Propositional_satisfiability" rel="nofollow">The boolean satisfiability problem</a></p>\n', 'ViewCount': '118', 'Title': 'Description of resolution algorithm as it applies to SAT', 'LastEditorUserId': '472', 'LastActivityDate': '2013-02-18T22:02:44.297', 'LastEditDate': '2013-02-18T22:02:44.297', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9235', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<algorithms><complexity-theory><reference-request><logic><np-complete>', 'CreationDate': '2013-01-28T01:57:42.843', 'Id': '9233'}{'Body': '<p>I find this a bit difficult to describe, but I am interested in the following idea :</p>\n\n<p>The LZ algorithm factors (verb) an input stream into adjacent factors, these are by definition the maximal prefixes of the piece of text that occur in the previous text (or equivalently the previous concatenation of LZ factors). </p>\n\n<p>I know and believe that in the long term (given infinite input and infinite window) this coding scheme can achieve the Shannon limit, that it will find all repeat patterns that exist. </p>\n\n<p>However in <em>any given finite text</em> (but with an unbounded window) how optimal is this?</p>\n\n<p>Do the choice of factors earlier in the input have potential detrimental effects later on? For instance, could LZ converge to a choice of factors that omits certain larger factors, or factor-choices that would result in a better cover of the input (i.e. a choice of factors that  cover more of the text?). </p>\n\n<p>Or is the optimality of LZ only constrained by the window limit, and the finite nature of a text? Please provide some kind of hand waving or intuitive proof.</p>\n', 'ViewCount': '142', 'Title': 'How optimal is Lempel-Ziv at reaching the Shannon limit?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-31T14:25:17.583', 'LastEditDate': '2013-01-30T21:52:12.133', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '9356', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4602', 'Tags': '<complexity-theory><combinatorics><data-compression><lempel-ziv>', 'CreationDate': '2013-01-30T15:05:50.820', 'Id': '9309'}{'Body': '<p>We say that the language $J \\subseteq \\Sigma^{*}$ is <em>dense</em> if there exists a polynomial $p$ such that $$ |J^c \\cap \\Sigma^n| \\leq p(n)$$ for all $n \\in \\mathbb{N}.$ In other words, for any given lenght $n$ there exist only polynomially many words of length $n$ that are not in $J.$</p>\n\n<p>The problem I am currently studying asks to show the following</p>\n\n<blockquote>\n  <p>If there exist a dense $NP$-complete language then $P = NP$</p>\n</blockquote>\n\n<p>What the text suggest is to consider the polynomial reduction to $3$-$SAT$ and then construct an algorithm that tries to satisfy the given $CNF$ formula while also generating elements in $J^c.$</p>\n\n<p>What I am wondering is</p>\n\n<blockquote>\n  <p>Is there a more direct proof? Is this notion known in a more general setting?</p>\n</blockquote>\n', 'ViewCount': '262', 'Title': 'A dense NP complete language implies P=NP', 'LastActivityDate': '2013-02-05T23:51:20.210', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '9529', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '3092', 'Tags': '<complexity-theory><time-complexity><np-complete><satisfiability>', 'CreationDate': '2013-01-30T20:07:13.607', 'FavoriteCount': '1', 'Id': '9327'}{'ViewCount': '258', 'Title': 'Is it possible to decide if a given algorithm is asymptotically optimal?', 'LastEditDate': '2013-02-02T12:51:15.650', 'AnswerCount': '3', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '6642', 'FavoriteCount': '0', 'Body': '<p>Is there an algorithm for the following problem:</p>\n\n<blockquote>\n  <p>Given a Turing machine $M_1$ that decides a language $L$,<br>\n  Is there a Turing machine $M_2$ deciding $L$ such that\n  $t_2(n) = o(t_1(n))$?</p>\n</blockquote>\n\n<p>The functions $t_1$ and $t_2$ are the worst-case running times of Turing machines $M_1$ and $M_2$ respectively.</p>\n\n<p>What about space complexity?</p>\n', 'Tags': '<complexity-theory><computability><undecidability><decision-problem>', 'LastEditorUserId': '4249', 'LastActivityDate': '2013-02-02T12:51:15.650', 'CommentCount': '1', 'AcceptedAnswerId': '9399', 'CreationDate': '2013-01-31T10:58:26.190', 'Id': '9349'}{'ViewCount': '236', 'Title': 'What is the decision version of independent set?', 'LastEditDate': '2013-02-02T18:48:17.307', 'AnswerCount': '3', 'Score': '4', 'OwnerDisplayName': 'Jose Antonio Martin H', 'PostTypeId': '1', 'OwnerUserId': '6655', 'Body': "<p>I always read that finding an independent set of size $k$ in a graph is $\\mathsf{NP}$-complete. However, this only requires looking for all combinations of $k$ vertices and this is a polynomial procedure of order $k$.</p>\n\n<p>I know that we can reduce directly SAT to independent set, with $k$ the number of clauses.</p>\n\n<p>The problem is that I can't grasp correctly, as in 3-COLORING or 3-SAT, the required format to study the complexity of INDEPENDENT SET.</p>\n\n<p>What is the decision version of independent set? And why isn't $k$-independent set in $\\mathsf P$?</p>\n", 'Tags': '<complexity-theory><terminology><decision-problem>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-02T18:48:17.307', 'CommentCount': '0', 'AcceptedAnswerId': '9365', 'CreationDate': '2013-01-31T17:41:26.847', 'Id': '9363'}{'Body': '<p>I am interested to know the complexity of the NAE-HORN-SAT problem\n(not all equal).  We know that HORNSAT is $\\mathsf{P}$-complete, but\non the other hand, NAE-SAT is $\\mathsf{NP}$-complete.  I want to know\nwhat can we say about NAE-HORN-SAT problem.  Let me define the problem\nformally:</p>\n\n<blockquote>\n  <p>Given: One Boolean formula $\\phi$ is given to us in CNF where each\n  clause has at most one positive literal (HORN-property).<br>\n  Question: Is there any assignment for the input variables of\n  $\\phi$ such that any clause has at least one False and at least one\n  True literal (NAE-property) ?</p>\n</blockquote>\n\n<p>N.B.:</p>\n\n<ul>\n<li>Positive literal: any variable directly,</li>\n<li>Negative literal: negation of any variable.</li>\n<li>True literal: literal is assigned to Boolean True by any assignment,</li>\n<li>False literal: literal is assigned to Boolean False by any assignment.</li>\n</ul>\n\n<p>According to <a href="http://en.wikipedia.org/wiki/Schaefer%27s_dichotomy_theorem" rel="nofollow">Schaefer\'s dichotomy theorem</a>, this problem must be either\nin $\\mathsf{P}$ or $\\mathsf{NP}$-complete.  I can just find one\npolynomial reduction from HORNSAT to this problem, which proves\nactually nothing.  Is there a polynomial time algorithm to solve this\nproblem?</p>\n\n<p>Or, is there any way to prove this problem to be $\\mathsf{NP}$-hard?\nAny thoughts about this ?</p>\n', 'ViewCount': '263', 'Title': 'Is NAE-HORN-SAT in P or NP-hard?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-05T13:20:20.817', 'LastEditDate': '2013-02-05T12:57:19.910', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '6', 'OwnerDisplayName': 'David', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'CreationDate': '2013-02-04T16:04:39.273', 'FavoriteCount': '1', 'Id': '9484'}{'ViewCount': '88', 'Title': 'Does reduction from an NP-complete problem to some problem $X$ imply that $X\\in NP$?', 'LastEditDate': '2013-02-06T14:52:09.737', 'AnswerCount': '2', 'Score': '3', 'OwnerDisplayName': 'user6697', 'PostTypeId': '1', 'OwnerUserId': '6697', 'Body': '<p>I am having problems resolving the following question:</p>\n\n<blockquote>\n  <p>Given some problem $X$. If there exists a polynomial time reduction from (for example) $\\mbox{SAT}$ to $X$, $(\\mbox{SAT} \\leq_{p} X)$ and since we know that $\\mbox{SAT}$ is $\\mbox{NP-complete}$, to show that $X$ is $\\mbox{NP-complete}$ is it necessary to show that $X\\in \\mbox{NP}$ via some third party algorithm?</p>\n</blockquote>\n\n<p>If yes, then why?</p>\n', 'Tags': '<complexity-theory><terminology><reductions><np>', 'LastEditorUserId': '683', 'LastActivityDate': '2013-02-06T14:52:09.737', 'CommentCount': '1', 'AcceptedAnswerId': '9520', 'CreationDate': '2013-02-05T12:34:42.987', 'Id': '9519'}{'ViewCount': '11016', 'Title': 'In basic terms, what is the definition of P, NP, NP-Complete, and NP-Hard?', 'LastEditDate': '2013-06-06T14:06:56.640', 'AnswerCount': '5', 'Score': '56', 'PostTypeId': '1', 'OwnerUserId': '6569', 'FavoriteCount': '54', 'Body': "<p>I'm in a course about computing and complexity, and am unable to understand what these terms mean. All I know is that np is a subset of np complete which is a subset of np hard... but I have no idea what they actually mean. Wikipedia isn't much help either as the explanations are still a bit too high level.</p>\n", 'Tags': '<complexity-theory><terminology><p-vs-np><reference-question>', 'LastEditorUserId': '6716', 'LastActivityDate': '2014-04-16T09:27:50.623', 'CommentCount': '4', 'AcceptedAnswerId': '9566', 'CreationDate': '2013-02-06T20:38:08.297', 'Id': '9556'}{'Body': '<p>I know that maximum independent set on cubic triangle-free graphs is NP-complete. </p>\n\n<p>Is it still NP-complete in case we require the independent set to be of size exactly $|V|/2$?</p>\n\n<p>Basiclly, YES instance of independent set problem on cubic triangle-free graphs problem must have exactly $|V|/2$ nodes. NO instance has an independent set of size less than $|V|/2$.</p>\n', 'ViewCount': '128', 'Title': 'Independent set on cubic triangle-free graphs', 'LastEditorUserId': '96', 'LastActivityDate': '2013-02-08T04:43:21.480', 'LastEditDate': '2013-02-07T17:45:15.193', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '9588', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-02-07T12:16:43.410', 'Id': '9572'}{'Body': u'<p>This is one of my assignments. I am not able to comprehend how to reduce the Turing machine domain to Classical planning domain. My understanding is that we have to essentially perform complexity analysis of classical planning domain. So I have defined these two languages </p>\n\n<p>a)  PLAN-EXISTENCE(D) = {P : P is the statement of a planning problem that has a solution}</p>\n\n<p>b)  PLAN-LENGTH(D) = {(P,n) : P is the statement of a planning problem that has a  solution that contains no more than n actions (length \u2264 n) }</p>\n\n<p>And then I proceed to prove that both these are decidable in classical planning domain. </p>\n\n<p>Is this the correct approach? Please help me  </p>\n', 'ViewCount': '130', 'Title': 'Show that the Turing Machine domain can be viewed as a classical planning domain', 'LastActivityDate': '2013-02-07T19:14:31.263', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '9579', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6754', 'Tags': '<complexity-theory><turing-machines><artificial-intelligence>', 'CreationDate': '2013-02-07T13:18:46.983', 'Id': '9573'}{'ViewCount': '334', 'Title': 'P, NP and specialised Turing Machines', 'LastEditDate': '2013-02-08T08:34:13.790', 'AnswerCount': '3', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '6769', 'FavoriteCount': '2', 'Body': "<p>I'm sort of new, but very interested to the field of computing and complexity theory, and I want to clarify my understanding about how to class problems, and how strongly the problems relate to the machine being used to solve them.</p>\n\n<p><strong>My Understanding</strong></p>\n\n<ul>\n<li>Standard Turing Machine - a Turing Machine which has a finite alphabet, finite number of states and a single right-infinite tape</li>\n<li>Turing-Equivalent Machine - a Turing Machine which, can emulate, and be emulated by, a Standard Turing Machine (quite often with some trade-off between space and time achieved by the emulation)</li>\n<li><code>P</code> - the class of problems which can be solved in polynomial time using a Standard Turing Machine (defined above)</li>\n<li><code>NP</code> - the class of problems which can be verified in polynomial time using a Standard Turing Machine</li>\n<li><code>NP-complete</code> - the hardest problems which are still in <code>NP</code>, which all <code>NP</code> problems can be converted to in polynomial time</li>\n</ul>\n\n<p><strong>My Question</strong></p>\n\n<p>Are the complexity classes (<code>P</code>, <code>NP</code>, <code>NP-complete</code>, etc) related to the algorithm, or the algorithm and the machine?</p>\n\n<p>Said in another way, if you could create a Turing Equivalent Machine (that can solve all the problems that a Standard TM can, but in a different amount of time/space) and this new machine could solve an <code>NP-complete</code> problem in time which grows as a polynomial with respect to the input, would that imply <code>P=NP</code>?</p>\n\n<p>Or must the <code>NP-complete</code> problem be solvable on all possible Turing Machines in polynomial time to be considered in <code>P</code>?</p>\n\n<p>Or do I mis-understand something fundamental above?</p>\n\n<p>I have had a look (maybe not with the correct search terms, I don't know all the jargon quite well) but it seems most lectures/notes etc. focus on standard machines but say that custom machines often have some time/space speed up at the expense of space/time, without saying how that bears on complexity classes. I'm not really familiar enough with the jargon in this field yet to find papers which explain this.</p>\n", 'Tags': '<complexity-theory><computability><terminology><turing-machines><complexity-classes>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-08T20:15:58.060', 'CommentCount': '1', 'AcceptedAnswerId': '9593', 'CreationDate': '2013-02-08T02:06:20.137', 'Id': '9585'}{'Body': "<p>Let $\\mathcal{A}$ be a problem in $\\text{NP} \\cap \\text{co}$-$\\text{NP}$.</p>\n\n<p>Now assume we can reduce another problem $\\mathcal{B}$ to it using Cook reduction.</p>\n\n<p>What conclusions can we draw about $\\mathcal{B}$? Does this question even make sense?</p>\n\n<p>I'm asking because from what I understand Cook reductions differ from Karp reductions (for example, $\\text{NP}$ cannot be distinguished from $\\text{co}$-$\\text{NP}$).\nI'm pretty confused and can't seem to really understand the properties of Cook reductions. Any good reference about the topic would also be appreciated!</p>\n\n<p>I hope this question is not too basic, but I was not able to find anything about it. </p>\n", 'ViewCount': '156', 'Title': 'Problems that are Cook-reducible to a problem in NP $\\cap$ co-NP', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-08T08:30:35.880', 'LastEditDate': '2013-02-08T08:30:35.880', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '9592', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '691', 'Tags': '<complexity-theory><reductions><np>', 'CreationDate': '2013-02-08T03:11:17.540', 'Id': '9586'}{'Body': "<p>It's known that for $f(n) \\geq \\log n$,  $\\mathsf{NSPACE}(f(n)) = \\mathsf{coNSPACE}(f(n))$.</p>\n\n<p>What if $f(n)&lt;\\log n$? Are they also equal?</p>\n", 'ViewCount': '93', 'Title': 'Does $\\mathsf{NSPACE}( f (n)) = \\mathsf{coNSPACE}( f (n))$ hold for $ f(n) < \\log (n) $?', 'LastEditorUserId': '683', 'LastActivityDate': '2013-02-11T00:25:29.670', 'LastEditDate': '2013-02-10T22:58:08.963', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9629', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '4409', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-02-09T21:48:58.417', 'Id': '9625'}{'Body': "<p>I've seen a reduction that's done by adding another vertex to the graph and creating a path through that vertex.</p>\n\n<p>Why do I need to add a vertex? Cant I just remove an edge? Lets say the graph with the HamCycle is G,s,t when removing the edge between s and t dont I get a path the goes through all the vertexes that's qualified as a Hamiltonian path?</p>\n", 'ViewCount': '169', 'Title': 'HamCycle to HamPath reduction', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-11T12:21:48.907', 'LastEditDate': '2013-02-11T12:08:05.400', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9672', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6821', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-02-11T10:46:12.443', 'Id': '9669'}{'Body': "<p>What does a pseudo-polynomial algorithm tell us about the problem it solves? I don't see how running time improves if the algorithm is exponential in the input length and polynomial in the input value; so how do we explain this shift from exponential to polynomial?</p>\n", 'ViewCount': '229', 'Title': 'Weak and strong completeness', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-24T03:24:29.867', 'LastEditDate': '2013-02-12T06:27:18.567', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2499', 'Tags': '<algorithms><complexity-theory><np-complete><pseudo-polynomial>', 'CreationDate': '2013-02-11T18:23:44.420', 'FavoriteCount': '1', 'Id': '9686'}{'Body': '<p>For example, I know that the non-regular language $a^nb^n$ is in $AC^0$. I would like to know more examples like this.</p>\n', 'ViewCount': '148', 'Title': 'Which non-regular languages are in $AC^0$?', 'LastActivityDate': '2013-02-13T00:40:15.447', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '9720', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '6817', 'Tags': '<complexity-theory><regular-languages><circuits>', 'CreationDate': '2013-02-12T12:32:20.147', 'FavoriteCount': '0', 'Id': '9704'}{'ViewCount': '295', 'Title': 'Can we make a problem harder than NP and coNP if they are not equal?', 'LastEditDate': '2013-02-15T16:30:56.863', 'AnswerCount': '2', 'Score': '3', 'OwnerDisplayName': 'Jose Antonio Martin H', 'PostTypeId': '1', 'OwnerUserId': '6655', 'Body': '<p>Let us assume that $\\mathsf{NP} \\neq \\mathsf{coNP}$. Consider the graph 3-colorability problem.</p>\n\n<p>Since $\\mathsf{NP} \\neq \\mathsf{coNP}$ implies $\\mathsf{P} \\neq \\mathsf{NP}$ and 3-coloribility is $\\mathsf{NP}$-complete and its complement is $\\mathsf{coNP}$-complete , we have:</p>\n\n<ol>\n<li>3-coloribility is not in $\\mathsf{P}$, i.e. there are no polynomial-time algorithm for deciding if a given graph is 3-colorable.</li>\n<li>non-3-coloribility is not in $\\mathsf{NP}$, i.e. there are no polynomial-time verifier with polynomial-size certificatesfor non-3-colorability.</li>\n</ol>\n\n<p>However, we know that for many classes of graphs, polynomial algorithms exists for 3-colorability and also they have polynomial-time verifiers with polynomial-size certificates for non-3-colorability. But this is not the case for all graphs since we we assumed that  $\\mathsf{NP} \\neq \\mathsf{coNP}$.</p>\n\n<p>We can define the following problem:</p>\n\n<blockquote>\n  <p>Input: a graph $G$,<br>\n  Task: determine if $G$ is 3-colorable or non-3-colorable and provide a certificate for the answer. The certificate is either a 3-coloring or a non-3-colorability certificate. </p>\n</blockquote>\n\n<p>What is the complexity of this problem?</p>\n\n<p>YES version is in $\\mathsf{NP}$ . And the NO version is in $\\mathsf{coNP}$. Note that the answer is not always YES since $\\mathsf{NP} \\neq \\mathsf{coNP}$.</p>\n', 'Tags': '<complexity-theory><complexity-classes>', 'LastEditorUserId': '41', 'LastActivityDate': '2013-02-16T06:15:30.230', 'CommentCount': '6', 'AcceptedAnswerId': '9735', 'CreationDate': '2013-02-13T00:01:44.327', 'Id': '9734'}{'Body': u'<p>There is a well known definition of <strong>parsimonious reduction</strong>.</p>\n\n<p>The standard definition of parsimonious reduction is very intuitive. It simply means that the two problem have the same number of solutions, when on input of one of them we applied function $f$.</p>\n\n<p>We say there is a parsimonious reduction from #A to #B if there is a polynomial time transformation $f$ such that for all $x$, $|\\{y,(x, y) \\in  A\\}| = |\\{z : (f(x), z) \\in B\\}|$.</p>\n\n<p>I am interested in definition of <strong>strongly parsimonious reduction</strong>.</p>\n\n<p>The only definition I found:</p>\n\n<p>"Strongly parsimonious reduction of $R\'$ to $R$ is a parsimonious reduction $g$ that is coupled with an efficiently computable 1-1 mapping of pairs $(g(x), y) \\in R$ to pairs $(x, h(x, y)) \\in  R\'$ (i.e., $h$ is efficiently computable and $h(x, \xb7)$ is a 1-1 mapping of $R(g(x))$\nto $R\'(x)$). For technical reasons, we also assume that $|g(x)| \u2265 |x|$ for every $x$."</p>\n\n<p>The problem is I simply don\'t understand what this definition means. I tried to separate it to smaller block, but so far with no success. According  to the definition there are two function $g(x)$ and $h(x,y)$ are they are applied simultaneously to two different problem $R$ and $R\'$. How the usages of two function can be explained. What is the difference between two reduction, parsimonious reduction  and strongly parsimonious reduction.</p>\n\n<p>I would appreciate any help in understanding the definition of strongly parsimonious reduction.</p>\n', 'ViewCount': '88', 'Title': 'Definition of Strongly Parsimonious Reduction', 'LastActivityDate': '2013-02-13T22:12:32.960', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9750', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-02-13T12:52:57.913', 'Id': '9744'}{'Body': '<p>I may have missed something in my classes - but with $A\\leq_{P}B$... Does this show that, if $A\\in \\textbf{NP-Complete}$, that $B\\in \\textbf{NP}$ or $B\\in \\textbf{NP-Complete}$?</p>\n\n<p>Or maybe I got things backwards. If $A$ is polynomial-time-reducable to $B$, and $B$ is $\\textbf{NP}$-complete, does that make $A$ $\\textbf{NP}$ or $\\textbf{NP}$-complete?</p>\n', 'ViewCount': '67', 'Title': 'What do time complexity reductions prove?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-24T03:17:52.437', 'LastEditDate': '2013-05-24T03:17:52.437', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '9754', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<complexity-theory><terminology><reductions>', 'CreationDate': '2013-02-13T23:41:37.760', 'Id': '9753'}{'Body': "<p>I'm having a very hard time understanding what's what.</p>\n\n<p>$$L_{1}\\leq_{p}L_{2}$$</p>\n\n<p>If $L_2$ is stated to be in $\\textbf{NP}$, is it necessarily true that $L_1$ is $\\textbf{NP}$-Complete? I need to show the following for an assignment, but I'm having a dispute with a fellow student because he claims that I can't claim that $L_1$ is $\\textbf{NP}$-Complete...</p>\n\n<blockquote>\n  <p>Suppose that $L_1\\leq_p L_2\\leq_p L_3$. Also suppose that $L_3$ is in $\\textbf{NP}$. Explain how to solve $L_1$ deterministically in exponential time.</p>\n</blockquote>\n\n<p>I say (and I could be wrong - and that's a strong possiblity since I have very little understanding of this material) that since $L_3$ is in $\\textbf{NP}$, $L_2$ also has to be in $\\textbf{NP}$, and so therefore $L_1$ has to be in $\\textbf{NP}$. And if that's the case, then $L_1$ can easily be converted to a deterministic algorithm through a breadth first search through the non-deterministic computation tree. Is there something I'm missing?</p>\n", 'ViewCount': '70', 'Title': 'Polynomial time reductions', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-14T06:34:11.407', 'LastEditDate': '2013-02-14T06:34:11.407', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9759', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<complexity-theory><terminology><np-complete><reductions>', 'CreationDate': '2013-02-14T02:24:22.693', 'Id': '9758'}{'Body': '<p>I am asking for help to explain some crucial points of the central lemma and it\'s proof of famous paper <a href="http://www.cs.princeton.edu/courses/archive/fall05/cos528/handouts/NP_is_as.pdf" rel="nofollow">NP is as easy as detecting unique solutions by L.Valiant and V.Vazirani</a>.</p>\n\n<p>The proof can be found in the section <strong>2. The proof</strong> of the paper. </p>\n\n<p><strong>The idea of the lemma</strong>: lemma shows that there is a randomized polynomial - time reduction from SAT to Unique-SAT. Lemma uses GF[2] inner product with polynomial few {0,1} vectors.</p>\n\n<p><strong>Problem in general</strong>: I have some difficulties in understanding the definition of the lemma and in usage of GF[2] for proving the lemma. </p>\n\n<p><strong>Specific questions:</strong></p>\n\n<p>Following is the number of citations from the paper with relevant question to the citation. </p>\n\n<blockquote>\n  <p><strong>Lemma 2.1.</strong> If $f$ is any CNF formula in $x_1,...,x_n$ and $w_1,...,w_k \\in \\{0,1\\}^n$, </p>\n</blockquote>\n\n<p>Q:I think $x_1,...,x_n$ are literals, but what are $w_1,..,w_k$? Are they literals or something else? If yes, why to distinct between them and $x$ literals.</p>\n\n<p>A:$w_1,..,w_k$ are the truth assignments. </p>\n\n<blockquote>\n  <p>then one can construct in linear time a formula $f\'_k$ whose solution $v$ satisfy $f$ and the equations $v\\cdot  w_1=...=v\\cdot w_k=0$. Furthermore, one can construt a polynomial-size CNF formula $f_k$ in variables $x_1,...,x_n,y_1,...y_m$,</p>\n</blockquote>\n\n<p>Q: $x_1,...x_n$ are unknown literals, how can we construct $f_k$ with unknown literals and where $y_1,...,y_m$ came from?</p>\n\n<blockquote>\n  <p>for some $m$ such that there is a bijection between solutions of $f_k$ and $f\'_k$, defined be equality on the $x_1,...,x_n$ values.</p>\n  \n  <p><strong>Proof</strong>: It is sufficient to show the lemma for $k=1$. Then, $f\'_k$ is</p>\n  \n  <p>$f \\wedge (x_{i_1} \\bigoplus x_{i_2} \\bigoplus ... \\bigoplus x_{i_j} \\bigoplus 1)$</p>\n</blockquote>\n\n<p>Q: this is the most vague point, how do we come to the such construction of $f\'_1$ and why showing only $f\'_1$ sufficient for the proof.</p>\n\n<p>I hope you forgive me for my naivety. I will appreciate any hint in accordance to the above questions.</p>\n', 'ViewCount': '106', 'Title': 'Proof of SAT is randomly reducible to UNIQUE-SAT', 'LastEditorUserId': '1379', 'LastActivityDate': '2013-02-14T17:47:28.463', 'LastEditDate': '2013-02-14T17:47:28.463', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><reductions><proof-techniques>', 'CreationDate': '2013-02-14T09:57:05.487', 'Id': '9766'}{'Body': '<p>It is known that $Parity \\notin AC^0$ (nonuniform), but the proof is rather involved and combinatorial. Are there simpler, but weaker lower bounds, say for $NP \\not \\subseteq AC^0$ or $NEXP \\not \\subseteq AC^0$?</p>\n\n<p>For example, can nontrivial simplifications be obtained in the proof of $NEXP \\not \\subseteq ACC^0$ to deal only with the special case of $AC^0$?</p>\n', 'ViewCount': '110', 'Title': 'Simple lower bounds against AC0', 'LastEditorUserId': '41', 'LastActivityDate': '2013-02-14T22:05:44.687', 'LastEditDate': '2013-02-14T21:44:12.463', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9786', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '667', 'Tags': '<complexity-theory><lower-bounds><circuits>', 'CreationDate': '2013-02-14T21:39:13.577', 'Id': '9783'}{'ViewCount': '47', 'Title': '"Definition of NP via relations and quantifiers; not via NTMs"', 'LastEditDate': '2013-02-15T02:34:43.813', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6569', 'FavoriteCount': '1', 'Body': "<p>I have the following question on an assignment, and despite asking my prof, I can't get a grasp on it..</p>\n\n<blockquote>\n  <p>Let $L_1, L_2$ be languages in ${\\sf NP}$. Using the definition of ${\\sf NP}$ via relations and quantifiers (not the non-deterministic Turing machines) prove that the following language is in ${\\sf NP}$:  $L=\\{ x | x \\in L_1 \\text{ or } xx  \\in L_2 \\}$, where $xx$ is two concatenated copies of $x$.</p>\n</blockquote>\n\n<p>Her notes say the following on this:</p>\n\n<blockquote>\n  <p>Let $L\\subseteq\\Sigma^{*}$. We say $L\\in{\\sf NP}$ if there is a two-place predicate $R\\subseteq\\Sigma^{*}\\times\\Sigma^{*}$ such that $R$ is computable in polynomial time, and such that for some $c,d\\in\\mathbb{N}$ we have $\\forall x\\in\\Sigma^{*},x\\in L\\iff\\exists y\\in\\Sigma^{*},|y|\\leq c|x|^d$ and $R(x,y)$.</p>\n</blockquote>\n\n<p>I would imagine that this is a well known definition (though possibly worded differently)... but I don't know where else I can get details on it. My textbook has a somewhat similar definition, but it doesn't talk about this $c,d\\in\\mathbb{N}$ stuff..</p>\n\n<blockquote>\n  <p>A <strong><em>verifier</em></strong> for a language $A$ is an algorithm $V$, where\n  $$A=\\{w\\mid V\\text{ accepts }\\langle w,c\\rangle\\text{ for some string c}\\}.$$\n  We measure the time of a verifier only in terms of the length of $w$, so a <strong><em>polynomial time verifier</em></strong> runs in polynomial time in the length of $w$. A language $A$ is <strong><em>polynomially verifiable</em></strong> if it has a polynomial time verifier.</p>\n</blockquote>\n\n<p>The $y$ in the first definition is supposed to be analogous to $c$ in the second; it is a <strong>certificate</strong> or <strong>witness</strong> used by the verifier. But that's all I can understand between the two.</p>\n\n<p>Now... what I <strong><em>think</em></strong> I know about this question is that $R(x,y)$ is supposed to be a verifier for $L$, while $R_1(x,y_1)$ is a verifier for $L_1$ and $R_2(x,y_2)$ is a verifier for $L_2$. She said something about $y=\\langle y_1, y_2\\rangle$ being an encoding of the two certificates for the verifiers $R_1$ and $R_2$. But from there I'm lost. I have no idea how to answer this question even after asking for help two or three times.</p>\n\n<p>Anybody here able to help? Thanks in advance.</p>\n", 'Tags': '<complexity-theory><closure-properties>', 'LastEditorUserId': '6569', 'LastActivityDate': '2013-02-15T02:53:43.503', 'CommentCount': '0', 'AcceptedAnswerId': '9797', 'CreationDate': '2013-02-14T23:48:53.697', 'Id': '9790'}{'ViewCount': '160', 'Title': 'Is the open question NP=co-NP the same as P=NP?', 'LastEditDate': '2013-02-15T07:34:14.460', 'AnswerCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6569', 'FavoriteCount': '1', 'Body': "<p>I'm wondering this based on several places online that call $\\sf NP=$ co-$\\sf NP$ a major open problem... but I can't find any indication as to whether or not this is the same as $\\sf P=NP$ problem...</p>\n", 'Tags': '<complexity-theory><complexity-classes><p-vs-np>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-15T10:57:56.617', 'CommentCount': '0', 'AcceptedAnswerId': '9798', 'CreationDate': '2013-02-15T01:38:55.790', 'Id': '9795'}{'Body': '<p>I am interested if there exists a following version of the travelling salesman problem:</p>\n\n<blockquote>\n  <p>INSTANCE: A finite set $C = \\{1,2,\\dots,k\\}$ of cities, a positive integer distance $\\delta(i,j)$ for each pair of cities, and two positive integers $d$ and $B$.</p>\n  \n  <p>QUESTION: Is there a tour that visits every city in $C$, includes exactly $d$ detours, and has total length no more then $B$?  In other words, suppose $OPT$ is the optimal permutation of the cities; that is, $OPT(i)$ is the next city after city $i$ in an optimal traveling salesman tour.  Is there an ordering $x(0), \\dots, x(k-1)$ of the cities such that $$\\sum_{i=1}^{k} \\delta(x(i), x((i+1) \\bmod k)) \\leq B$$ and there are exactly $d$ indices $i$ where $x((i+1) \\bmod k) \\ne OPT(x(i))$?</p>\n</blockquote>\n\n<p>The $d$ implies that if my shortest tour is $a\\rightarrow b \\rightarrow c\\rightarrow a$ but $d=1$ then what would be the shortest path if I had to first go to $c$, $ a \\rightarrow c \\rightarrow ...$. So $d$ tells me that I have to make $d$ number of wrong choices but I can choose these choices in any way I want to to minimize the length of the path.</p>\n\n<p>Is this a problem worthwhile describing? Or if it has been described where could I see an example? </p>\n', 'ViewCount': '90', 'Title': 'Travelling salesman problem with detours', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-06T15:05:07.807', 'LastEditDate': '2013-06-06T15:05:07.807', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6697', 'Tags': '<complexity-theory><graph-theory><np-hard><decision-problem><traveling-salesman>', 'CreationDate': '2013-02-15T10:58:21.960', 'Id': '9802'}{'Body': '<p>I have as an assignment question to show that $QuadSat=\\{\\langle\\phi\\rangle\\mid\\phi$ is a satisfiable 3CNF formula with at least 4 satisfying assignments$\\}$ is $\\sf NP$-Complete.</p>\n\n<p>My solution is as follows, which is pretty much copied almost 100% from a textbook example with only an extra requirement for satisfiablity at the end...</p>\n\n<blockquote>\n  <p>$$QuadSat\\leq_{p} Clique$$\n  Let $\\phi$ be a formula with k clauses such as\n  $$\\phi=\\bigwedge_{1}^{k}(a_k\\vee b_k\\vee c_k)$$\n  The reduction $f$ generates the strong $\\langle G,k\\rangle$, where $G$ is an undirected graph defined as follows:</p>\n  \n  <p>The nodes in $G$ are organized into $k$ groups of three nodes each called the \\textbf{triples}, $t_1, \\dots, t_k$. Each triple corresponds to one of the clauses in $\\phi$, and each node in a triple corresponds to a literal in the associated clause. Label each node of $G$ with its corresponding literal in $\\phi$.</p>\n  \n  <p>The edges of $G$ connect all but two types of pairs of nodes in $G$: No edge is present between nodes in the same triple, and no edge is present between two nodes with contradictory labels. $QuadSat$ is satisfiable if and only if the resulting graph $G$ contains four or more $k$-$cliques$. Each unique $k$-$clique$ in $G$ represents a set of satisfying assignments to $QuadSat$.</p>\n  \n  <p>The reduction runs in polynomial time, because the construction of the graph is a polynomial function; one pass through all the triples to create all the vertices for $V$, and one pass through the same triples to create the edges.</p>\n</blockquote>\n\n<p>I feel like my explanation as to why my reduction is polynomial in time is severely weak, possibly bordering on wrong. How can I explain this better?</p>\n\n<p>And something else: I think this only proves that QuadSat is in NP, but not necessarily NP Complete. How can I prove this?</p>\n', 'ViewCount': '117', 'Title': 'How do I explain that a polynomial time reduction is in fact polynomial time?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-16T14:39:23.387', 'LastEditDate': '2013-02-16T14:39:23.387', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9812', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<complexity-theory><np-complete><reductions><proof-techniques>', 'CreationDate': '2013-02-15T13:50:38.367', 'Id': '9806'}{'ViewCount': '90', 'Title': 'Hardness of Approximating 0-1 Integer Programs', 'LastEditDate': '2013-02-18T05:51:25.817', 'AnswerCount': '1', 'Score': '8', 'OwnerDisplayName': 'Jonas Anderson', 'PostTypeId': '1', 'OwnerUserId': '1439', 'Body': '<p>Given a $0,1$ (binary) integer program of the form:\n$$\n\\begin{array}{lll}\n\\text{min} &amp; f(x) &amp; \\\\\n\\text{s.t.} &amp;A\\vec{x} = \\vec{b} &amp; \\quad \\forall i\\\\\n &amp;x_i\\ge 0 &amp; \\quad \\forall i\\\\\n&amp;x_i \\in \\{0,1\\} &amp; \\quad \\forall i\n\\end{array}\n$$</p>\n\n<p>Note: the size of $A$ is not fixed in either dimension.</p>\n\n<p>I believe this problem has been shown to be hard to approximate (strongly ${\\sf NP}$-Complete) <a href="http://dl.acm.org/citation.cfm?id=322090">Garey &amp; Johnson</a>. </p>\n\n<p>If so, is this still the case when $A$, $\\vec{b}$ have binary entries and $f(x)$ is a linear function ( $f(x) = \\sum_i c_i x_i$ )?</p>\n', 'Tags': '<complexity-theory><np-complete><approximation><integer-programming>', 'LastEditorUserId': '683', 'LastActivityDate': '2013-02-18T05:51:25.817', 'CommentCount': '2', 'AcceptedAnswerId': '9887', 'CreationDate': '2013-02-14T01:13:24.667', 'Id': '9810'}{'ViewCount': '1022', 'Title': 'Are there subexponential-time algorithms for NP-complete problems?', 'LastEditDate': '2013-04-04T12:17:10.723', 'AnswerCount': '2', 'Score': '18', 'OwnerDisplayName': 'ksb', 'PostTypeId': '1', 'OwnerUserId': '3134', 'FavoriteCount': '3', 'Body': '<p>Are there NP-complete problems which have proven subexponential-time algorithms? </p>\n\n<p>I am asking for the general case inputs, I am not talking about tractable special cases here. </p>\n\n<p>By sub-exponential, I mean an order of growth above polynomials, but less than exponential, for example $n^{\\log n}$.</p>\n', 'Tags': '<complexity-theory><np-complete><np>', 'LastEditorUserId': '39', 'LastActivityDate': '2014-03-13T11:20:22.313', 'CommentCount': '1', 'AcceptedAnswerId': '9814', 'CreationDate': '2013-02-15T15:42:36.863', 'Id': '9813'}{'ViewCount': '173', 'Title': 'What is the difference between "for infinitely many n" and "for all n"?', 'LastEditDate': '2013-02-17T09:59:19.923', 'AnswerCount': '2', 'Score': '5', 'OwnerDisplayName': 'Jose Antonio Martin H', 'PostTypeId': '1', 'OwnerUserId': '6655', 'Body': '<p>I have read some complexity papers in which "for infinitely many input sizes" is used.</p>\n\n<p>What is the difference in the computational complexity context between "for infinitely many input sizes" and "for all input sizes"?</p>\n', 'Tags': '<complexity-theory><terminology>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-17T23:45:10.537', 'CommentCount': '3', 'AcceptedAnswerId': '9845', 'CreationDate': '2013-02-16T22:06:48.160', 'Id': '9844'}{'Body': "<p>Between my textbook and various online sources (namely wikipedia), I'm very confused... can somebody clear up which words are synonymous and which mean different things?</p>\n\n<ul>\n<li>Many-to-one reduction</li>\n<li>Mapping reduction</li>\n<li>Turing reduction</li>\n<li>Cook reduction</li>\n<li>Karp reduction</li>\n<li>Polynomial-time many-to-one reduction</li>\n<li>Polynomial time turing reduction</li>\n</ul>\n\n<p>I've also seen others, but I can't recall them currently.</p>\n", 'ViewCount': '105', 'Title': 'What is the difference between these terms?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-17T08:53:28.023', 'LastEditDate': '2013-02-17T08:53:28.023', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '9855', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<complexity-theory><computability><terminology><reductions>', 'CreationDate': '2013-02-17T01:30:50.600', 'Id': '9847'}{'ViewCount': '250', 'Title': 'Showing that minimal vertex deletion to a bipartite graph is NP-complete', 'LastEditDate': '2013-02-18T00:25:04.840', 'AnswerCount': '1', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '3092', 'FavoriteCount': '1', 'Body': '<p>Consider the following problem whose input instance is a simple graph $G$ and a natural integer $k$.</p>\n\n<blockquote>\n  <p>Is there a set $S \\subseteq V(G)$ such that $G - S$ is bipartite and $|S| \\leq k$?</p>\n</blockquote>\n\n<p>I would like to show that this problem is $\\rm{NP}$-complete by reducing either 3-SAT, $k$-CLIQUE, $k$-DOMINATING SET or $k$-VERTEX COVER to it.</p>\n\n<p>I believe I can reduce the 3-COLORING problem to it so I would only need to see how to reduce one of the mentioned problems to it.  But since that would be rather messy I am wondering if someone sees an elegant reduction to the aforementioned problems.</p>\n\n<p>Also, is there a name for this decision problem?</p>\n', 'Tags': '<complexity-theory><np-complete><reductions>', 'LastEditorUserId': '4249', 'LastActivityDate': '2013-02-18T10:57:25.470', 'CommentCount': '5', 'AcceptedAnswerId': '9865', 'CreationDate': '2013-02-17T17:54:20.413', 'Id': '9863'}{'Body': '<p>We know that at the end computation should be done by physical systems which follow laws of physics. I know there are some researches that study the <a href="http://en.wikipedia.org/wiki/Phase_transition" rel="nofollow">phase transition</a> phenomenon in physics and try to connect it with some properties in complexity theory (such as P and NP famous problem ). Just a quick review for example the phase transition happens from 2-SAT problem to 3-SAT problem. The first one is in P and the second one is NP-Complete. </p>\n\n<p>My question is that: Is there any study that shows the <strong>mapping of Polynomial Hierarchy</strong> (PH) and <strong>multi-phase systems</strong>? Is there any mapping between PH-Complete problems and real physical system states? If so, are all levels of these hierarchy stable?</p>\n', 'ViewCount': '34', 'Title': 'Polynomial Hierarchy and its Relation to Multi-Phase/States Physical Systems', 'LastActivityDate': '2013-02-17T18:09:44.167', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6550', 'Tags': '<complexity-theory><computability>', 'CreationDate': '2013-02-17T18:09:44.167', 'Id': '9864'}{'Body': '<p>I want to know whether the 2-DNF problem is NP-complete or not? If it is NP-complete, can anyone provide a proof?</p>\n', 'ViewCount': '256', 'Title': 'Is 2-DNF NP-complete?', 'LastEditorUserId': '10228', 'LastActivityDate': '2013-11-07T13:27:21.760', 'LastEditDate': '2013-11-07T13:27:21.760', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '2', 'OwnerDisplayName': 'user13821', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'CreationDate': '2013-02-19T07:28:39.307', 'Id': '9927'}{'Body': '<p>In boolean circuit complexity, a circuit is just defined by a Directed Acyclic Graphs with designated input and output nodes, where the intermediate nodes compute a specific boolean function. A circuit is called a formula if the underlying graph is a tree. i.e., the fan-out of each node is $1$. Is it true that for a formula, (given that its fan-out is already $1$, by defintion) the fan-in is also constant? </p>\n\n<p>In the usual definition of formulas, this is never spelt out(Its always defined as a circuit where all gates have fan-out $1$). But somehow I seem to carry around this intuitively that formulas are always bounded fan-in. (It might be partly due to the fact that poly-sized boolean formulas correspond to $\\mathsf{NC^1}$ which is a complexity class defined by bounded fan-in circuits of logarithmic depth).</p>\n\n<p>So my question is, if you bound the fan-out of the circuit to be $1$, does it imply even the fan-in should be constant for every gate? I tried to use a counting argument, that says that the indegree and outdegree of the graphs must sum to the same, but somehow a water tight proof eludes me. First of all, is my intuition correct?</p>\n', 'ViewCount': '124', 'Title': 'Formulas vs Circuits', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-21T19:09:38.490', 'LastEditDate': '2013-02-20T07:01:24.137', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6954', 'Tags': '<complexity-theory><logic><circuits>', 'CreationDate': '2013-02-19T19:27:27.227', 'Id': '9940'}{'Body': u'<p>In 2009 Doron has published a paper stating "Using 3000 hours of CPU time on a CRAY machine, we settle the notorious P vs. NP problem in the affirmative, by presenting a \u201cpolynomial\u201d time algorithm for the NP-complete subset sum problem.". I\'ve been looking for other people\'s opinions on this but I haven\'t found anything significant. Has this problem been officially settled? is this a correct solution? I am not able to assess the paper because of my limited knowledge. What do you guys think ?</p>\n\n<p>Paper : <a href="http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimPDF/pnp.pdf">http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimPDF/pnp.pdf</a></p>\n', 'ViewCount': '262', 'Title': "Doron ZEILBERGER's P = NP computer proof", 'LastActivityDate': '2013-02-20T19:03:40.157', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '9953', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4365', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-02-20T04:59:33.830', 'Id': '9952'}{'Body': '<p>Many a times if the complexities are having constants such as 3n, we neglect this constant and say O(n) and not O(3n). I am unable to understand how can we neglect such three fold change? Some thing is varying 3 times more rapidly than other! Why do we neglect this fact?  </p>\n', 'ViewCount': '248', 'Title': 'Justification for neglecting constants in Big O', 'LastEditorUserId': '157', 'LastActivityDate': '2013-02-21T05:14:05.497', 'LastEditDate': '2013-02-21T05:14:05.497', 'AnswerCount': '5', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<complexity-theory><asymptotics><landau-notation>', 'CreationDate': '2013-02-20T07:12:59.983', 'FavoriteCount': '2', 'Id': '9957'}{'Body': '<p>I read somewhere that, if $A\\leq_p B$ and $B\\leq_p A$, then it is said that $A\\equiv_p B$. What exactly does this mean? Is it saying that both $A$ and $B$ are the exact same level of complexity?</p>\n', 'ViewCount': '130', 'Title': 'Anti-symmetry of polynomial time reductions', 'LastActivityDate': '2013-02-20T20:30:36.690', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9986', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-02-20T20:12:24.670', 'Id': '9985'}{'Body': '<p>The sum divider game for $n$ starts with the set $M_0 = \\{1,\\dots,n\\}$. Player A chooses a number $m_1$ from $M_0 \\setminus \\{1\\}$ and B has to choose a divider $m_2$ of $m_1$ from $M_1 = M_0 \\setminus \\{m_1\\}$. The players continue to choose a number $m_i$ from $M_{i-1} = M_{i-2} \\setminus \\{m_{i-1}\\}$ alternatingly, where every $m_i$ has to divide $\\sum_{k=1}^{i-1} m_k$. A player wins, if the other player is unable to do so and $M_{i-1} \\neq \\emptyset$, $M_{i-1} = \\emptyset$ is considered a tie.</p>\n\n<p>My questions:</p>\n\n<ul>\n<li>Is there an $n &gt; 2$, for which A has no winning strategy?</li>\n<li>Given some $n$ (in <strike>binary</strike> unary representation), how hard is it to decide whether there is a winning strategy for A\n<ul>\n<li>where A wins in at most $k$ steps ?</li>\n<li>where A chooses no prime numbers ?</li>\n</ul></li>\n</ul>\n', 'ViewCount': '230', 'Title': 'Complexity of deciding whether there is a winning strategy in the following game', 'LastEditorUserId': '41', 'LastActivityDate': '2013-07-20T09:17:09.133', 'LastEditDate': '2013-07-20T09:17:09.133', 'AnswerCount': '0', 'CommentCount': '18', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><time-complexity><game-theory><number-theory>', 'CreationDate': '2013-02-21T14:10:55.227', 'FavoriteCount': '2', 'Id': '10011'}{'Body': '<p>Given the reduction $3\\mathsf{SAT}\\leq_p \\mathsf{IndSet}$ as follows:</p>\n\n<p><img src="http://i.stack.imgur.com/PCe9v.png" alt="enter image description here"></p>\n\n<p>How can I argue that it\'s in polynomial time? I understand how the reduction works, but even though it appears rather trivial, I can\'t explain why it\'s efficient.</p>\n\n<blockquote>\n  <p>To place $\\mathsf{IndSet}$ in $\\mathsf{NP}$-Hard, we will show $3\\mathsf{SAT}\\leq_p \\mathsf{IndSet}$:</p>\n  \n  <p>Given\n  $$\\phi=\\bigwedge_{m=1}^{n}(x_m\\vee y_m\\vee z_m)$$\n  with $m$ clauses, produce the graph $G_\\phi$ that contains a triangle for each clause, with vertices of the triangle labeled by the literals of the clause. Add an edge between any two complementary literals from different triangles. Finally, set $k=m$. In our example, we have triangles on $x,y,\\overline{z}$ and on $\\overline{x},w,z$ plus the edges $(x,\\overline{x})$ and $(\\overline{z},z)$.</p>\n  \n  <p>We need to prove two directions. First, if $\\phi$ is satisfiable, then $G_\\phi$ has an independent set of size at least $k$. Secondly, if $G_\\phi$ has an independent set of size at least $k$, then $\\phi$ is satisfiable. (Note that the latter is the contrapositive of the implication "if $\\phi$ is not satisfiable, then $G_\\phi$ does not have an independent set of size at least k".)</p>\n  \n  <p>For the first direction, consider a satisfying assignment for $\\phi$. Take one true literal from every clause, and put the corresponding graph vertex into a set $S$. Observe that $S$ is an independent set of size $k$ (where $k$ is the number of clauses in $\\phi$).</p>\n  \n  <p>For the other direction, take an independent set $S$ of size $k$ in $G_\\phi$. Observe that $S$ contains exactly one vertex from each triangle (clause) , and that $S$ does not contain any conflicting pair of literals (such as $x$ and $\\overline{x}$, since any such pair of conflicting literals are connected by an edge in $G_\\phi$). Hence, we can assign the value True to all the literals corresponding with the vertices in the set $S$, and thereby satisfy the formula $\\phi$.</p>\n  \n  <p>This reduction is polynomial in time because $\\Huge\\dots?$</p>\n</blockquote>\n\n<p>I\'ve looked at many different examples of how this is done, and everything I find online includes everything in the proof except the argument of why this is polynomial. I presume it\'s being left out because it\'s trivial, but that doesn\'t help me when I\'m trying to learn how to explain such things.</p>\n', 'ViewCount': '94', 'Title': 'How can I argue that $3\\mathsf{SAT}\\leq_p \\mathsf{IndSet}$ is polynomial in time?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-24T16:15:03.743', 'LastEditDate': '2013-02-24T16:15:03.743', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10015', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-02-21T17:41:56.177', 'Id': '10014'}{'Body': "<p>Let Undir-Reachability be the following problem:\ngiven an undirected graph G and two specified vertices s and t in G, is there a path from s to t in G?</p>\n\n<p>I need to prove that the 2-Colourability is in L, by knowing that Undir-Reachability belongs to the complexity class L.</p>\n\n<p>I don't know how to start.</p>\n", 'ViewCount': '55', 'Title': 'Prove that 2-Colourability is in L from Undir-Reachability is in L', 'LastActivityDate': '2013-02-21T23:20:30.173', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10024', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6978', 'Tags': '<complexity-theory><graph-theory><space-complexity><colorings>', 'CreationDate': '2013-02-21T18:32:59.790', 'Id': '10016'}{'Body': '<p>I need to prove that the following problem $0$-$1$ $\\mathsf{ Ineq}$ is $\\mathsf{NL}$-complete.</p>\n\n<p>Given a finite set of variables $V$, a finite set of inequalities of the form $x \\le y$ (where $x, y \\in V$) and a finite set of equalities of the form $x=a$ (where $x \\in V$ and $a \\in \\{0,1\\}$), is there an assignment of values from $\\{0, 1\\}$ to the variables satisfying all the inequalities and all the equalities?</p>\n\n<p>How can I start to resolve the proof?</p>\n', 'ViewCount': '64', 'Title': 'Prove that $0$-$1$ $\\mathsf{ Ineq}$ is $\\mathsf{NL}$-complete', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-02-22T10:06:31.597', 'LastEditDate': '2013-02-22T10:06:31.597', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '10023', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6978', 'Tags': '<complexity-theory><graph-theory><reductions><space-complexity>', 'CreationDate': '2013-02-21T18:41:55.347', 'Id': '10017'}{'Body': '<p>I need a good book which starts from quite beginner to learn about calculating the complexity of Algorithm??</p>\n', 'ViewCount': '480', 'Title': 'Book to learn Algorithm Complexity', 'LastActivityDate': '2013-02-24T10:59:41.620', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '6669', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2013-02-24T06:37:31.737', 'Id': '10042'}{'Body': '<p>To say simply, can PSPACE problems be written as $\\Pi_1$ formula? Or how can these problems be written in terms of (first-order) arithmetic hierarchy?</p>\n\n<p>edit:also currently, by what arithmetic hierarchy formula can P=PSPACE be written?</p>\n\n<p>and what would be the consequence of being able to write P=PSPACE as $\\Pi_1$ formula?</p>\n', 'ViewCount': '236', 'Title': 'Can P=PSPACE and PSPACE problems be formulated as $\\Pi_1$ formula?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-25T17:41:41.727', 'LastEditDate': '2013-02-25T17:04:55.383', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '0', 'OwnerDisplayName': 'mars', 'PostTypeId': '1', 'Tags': '<complexity-theory><logic>', 'CreationDate': '2013-02-25T04:21:24.923', 'Id': '10083'}{'ViewCount': '157', 'Title': 'Why is MAX-2SAT in NP?', 'LastEditDate': '2013-02-26T07:47:05.793', 'AnswerCount': '1', 'Score': '2', 'OwnerDisplayName': 'simplicity', 'PostTypeId': '1', 'FavoriteCount': '1', 'Body': "<blockquote>\n  <p>Max-2-SAT is defined as follows. We are given a 2-CNF formula and a\n  bound k, and asked to find an assignment to the variables that\n  satisfies at least k of the clauses.</p>\n</blockquote>\n\n<p>I can understand the trick used to prove 2-SAT is in P. You use get a contradiction by using unit propagation. But, I was wondering why does MAX 2-SAT escape this.</p>\n\n<p>Also, I find it hard to believe this is NP-complete. Certainly, what is the problem that causes it to blow up.</p>\n\n<p>Why wouldn't an algorithm like this work. Given a 2-SAT expression. Find it's length, which we can do in P. Need to check if there is at least k of the clauses.</p>\n\n<p>So we just check $\\binom n k$ posibilities and run like Horn algorithm on each sub expression of the n 2-SAT expression. Surely, where is the problem as we are just running a P algorithm a polynomial amount of time. </p>\n\n<p>So I'm very confused. Sort of similar problem I have factorization and if that is in P or NP. </p>\n", 'Tags': '<complexity-theory><np-complete><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-26T07:47:05.793', 'CommentCount': '2', 'AcceptedAnswerId': '10099', 'CreationDate': '2013-02-23T11:09:50.640', 'Id': '10098'}{'Body': '<p>When we talk about operators in descriptive complexity, are they something like this: for example, if transitive closure operator $TR$ is available, we can use variable $y$ that we define as $TR(x)$ where $x$ is input? or is it something else? </p>\n\n<p>Also, when we say $FO(t(n))$, what does quantifier block being iterated $t(n)$ times mean?</p>\n', 'ViewCount': '53', 'Title': 'Operators in descriptive complexity', 'LastEditorUserId': '7073', 'LastActivityDate': '2013-02-28T22:34:47.023', 'LastEditDate': '2013-02-28T14:55:57.453', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7073', 'Tags': '<complexity-theory><descriptive-complexity>', 'CreationDate': '2013-02-28T14:47:30.563', 'Id': '10150'}{'Body': '<p>By "number of gates", I am wondering whether these gates include AND/OR gates that can receive several inputs or they just include AND/OR gates that receive two inputs.</p>\n', 'ViewCount': '53', 'Title': 'What does "number of gates" mean in circuit complexity?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-03-01T16:45:55.577', 'LastEditDate': '2013-03-01T16:45:55.577', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7084', 'Tags': '<complexity-theory><circuits>', 'CreationDate': '2013-03-01T00:26:09.313', 'Id': '10159'}{'Body': '<blockquote>\n  <p>Definition<br>\n  A family of circuits $(C_{1}, C_{2}, \\ldots)$ is uniform if some log\n  space transducer $T$ outputs $\\langle C_{n}\\rangle$ where $T$\'s input is $1^{n}$. (from <a href="http://en.wikipedia.org/wiki/Boolean_circuit#Uniform_Boolean_Circuits" rel="nofollow">http://en.wikipedia.org/wiki/Boolean_circuit#Uniform_Boolean_Circuits</a>)</p>\n</blockquote>\n\n<p>Can anyone exlain this? I know what boolean circuits are, so only explanation needed is what  and transducer exactly are.</p>\n', 'ViewCount': '106', 'Title': 'Definition of uniform boolean circuit', 'LastEditorUserId': '1636', 'LastActivityDate': '2013-03-01T04:39:19.890', 'LastEditDate': '2013-03-01T03:49:03.477', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7084', 'Tags': '<complexity-theory><finite-automata><circuits>', 'CreationDate': '2013-03-01T02:09:59.500', 'Id': '10161'}{'Body': u'<p>From <a href="http://rjlipton.wordpress.com/2009/05/27/arithmetic-hierarchy-and-pnp/" rel="nofollow">http://rjlipton.wordpress.com/2009/05/27/arithmetic-hierarchy-and-pnp/</a>,</p>\n\n<blockquote>\n  <p>Define, $M_{[x,c]}$ as the deterministic Turing machine that operates\n  as follows on an input $y$. The machine treats $x$ as a deterministic\n  program, and simulates $x$ on input $y$. At the same time the machine\n  runs a counter that stops its execution after steps $|y|^c$. If the\n  machine accepts before the counter stops, then it accepts; otherwise,\n  it rejects. </p>\n  \n  <p>Let $f(i,c)$ be the smallest natural number so that $M_{[i,c]}$makes a\n  mistake on the input $y$. Then, if $P \\neq NP$ is true, the function\n  $f(i,c)$ is always defined.</p>\n  \n  <p>Theorem: Suppose that there are infinite number of $i$ for which there exists a $c$ so that $$f(i,c) &gt; 2^{2^{|i|+c}}$$ Then, for infinitely many $n$, SAT has circuit size $n^{O(\\log n)}$. </p>\n  \n  <p>Proof: Let $i&gt;1$ and $c$ be so that $$f(i,c) &gt; 2^{2^{|i|+c}}$$ Define\n  $n = 2^{|i|+c-1}$. Note, that $c$ is at most $\\log n$. Then,\n  $M_{[i,c]}$ on all $y$ of length $n$ is correct, since $y \\leq 2^n = 2^{2^{|i|+c-1}} &lt; f(i,c)$.\n  The size of the circuit that simulates this Turing machine on inputs\n  of length $n$ is polynomial in $|i|$, $n$, and the running time of the\n  machine. The machine, by definition, runs in time $|y|^c \\leq n^c \\leq n^{\\log n}$</p>\n</blockquote>\n\n<p>I am not getting this part. Can anyone explain this (to specify, \u201cThe size of the circuit that simulates this Turing machine on inputs of length $n$ is polynomial in $|i|$, $n$, and the running time of the machine\u201d in the quote)? (So the question is how can we relate the running time of Turing machine to the size of the circuit.)</p>\n', 'ViewCount': '60', 'Title': 'How to relate circuit size to the running time of Turing machine', 'LastEditorUserId': '39', 'LastActivityDate': '2013-03-01T22:47:26.920', 'LastEditDate': '2013-03-01T22:47:26.920', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7087', 'Tags': '<complexity-theory><circuits>', 'CreationDate': '2013-03-01T06:53:18.167', 'Id': '10170'}{'Body': '<p>Programmers do sometimes write a program that creates infinite loop if some particular input is passed into the program.</p>\n\n<p>But Simply-typed lambda calculus has to stop - so the question is, can anyone show some "useful" program in Turing-complete language (e.g. untyped lambda calculus) that does not go into infinite loop but cannot be written in (simply-)typed lambda calculus?</p>\n\n<p>from comment section:</p>\n\n<p>"Yes I know all of these and I know that they are more expressive and those - but halting problem would only have meaning if there is an algorithm (program) that typed ones cannot express - otherwise, we can write all programs into typed one and see whether it is well-formed, right? Then we automatically know whether a program halts or not. This is what I am asking."</p>\n', 'ViewCount': '206', 'Title': 'A program that cannot be written in (simply-)typed lambda calculus but only in lambda calculus or Turing-complete language', 'LastEditorUserId': '7103', 'LastActivityDate': '2013-03-02T09:08:56.633', 'LastEditDate': '2013-03-02T09:08:56.633', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7103', 'Tags': '<complexity-theory><computability><programming-languages><lambda-calculus>', 'CreationDate': '2013-03-02T04:49:49.113', 'FavoriteCount': '1', 'Id': '10197'}{'Body': '<p>We know that $\\text{3-SAT}$ problem is NP-complete, but I am not sure what is meant by size of input. Does this mean number of literals, or number of variables?</p>\n', 'ViewCount': '89', 'Title': 'Input size of 3-SAT when analyzing complexity', 'LastActivityDate': '2013-03-03T10:41:33.220', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10225', 'Score': '3', 'OwnerDisplayName': 'user14010', 'PostTypeId': '1', 'Tags': '<complexity-theory>', 'CreationDate': '2013-03-03T03:01:49.470', 'Id': '10224'}{'Body': '<p>I have a undirected graph with no edge costs. A subset of the nodes are labeled $c_1, c_2, ..., c_k$ and one node is labeled $K$. I want to find the minimum cut of the graph with the extra condition that all nodes $c_i$ are in the same half of the cut and the node K is in the other cut.</p>\n\n<p>My idea was to begin by doing a BFS from $K$ to all nodes $c_i$, saving predecessors and then finding all paths from $K$ to a node $c_i$ and finally picking the minimum set of edges from the paths so that at least one edge from each path was chosen. Unfortunately, if I understand this correctly, this is equivalent to the NP-complete <a href="http://en.wikipedia.org/wiki/Set_cover_problem" rel="nofollow">set cover problem</a>.</p>\n\n<p>Is there  anything sane with this approach? Do you have any hints to push me in the right direction?</p>\n\n<p>Note: this is homework so I\'d rather have some hints than a full solution.</p>\n', 'ViewCount': '87', 'Title': 'min-cut with extra condition', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-06T12:10:21.790', 'LastEditDate': '2013-03-05T07:03:20.143', 'AnswerCount': '1', 'CommentCount': '13', 'AcceptedAnswerId': '10316', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7139', 'Tags': '<algorithms><complexity-theory><np-complete>', 'CreationDate': '2013-03-04T10:58:21.523', 'Id': '10255'}{'ViewCount': '141', 'Title': 'How to show that the complement of a language in $\\mathsf P$ is also in $\\mathsf P$?', 'LastEditDate': '2013-03-04T13:30:31.070', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7140', 'Body': u'<p>If $L$ is a binary language (that is, $L \\subseteq \\Sigma = \\{0,1\\}^\u2217$) and $\\overline{L}$ is the complement of $L$:</p>\n\n<p>How can I show that if $L \\in \\mathsf P$, then $\\overline{L} \\in \\mathsf P$ as well?</p>\n', 'ClosedDate': '2013-03-04T19:39:55.200', 'Tags': '<complexity-theory><formal-languages><time-complexity><complexity-classes>', 'LastEditorUserId': '2152', 'LastActivityDate': '2013-03-04T17:31:28.363', 'CommentCount': '2', 'AcceptedAnswerId': '10270', 'CreationDate': '2013-03-04T12:32:28.090', 'Id': '10257'}{'Body': '<p>I asked a question on Rabin-Karp Searching algorithm <a href="http://cs.stackexchange.com/questions/10173/rabin-karp-searching-algorithm">here</a>, which I am reading from the book "<a href="http://rads.stackoverflow.com/amzn/click/0262033844" rel="nofollow">Introduction to Algorithms" 3rd edition Cormen et al.</a>. </p>\n\n<p>After reading few para of the section on Rabin-Karp, I got some more confusions:</p>\n\n<p>In the third paragraph the authors say that the if we could find <strong>p</strong>  (decimal value of pattern P[1....m] )  in  time O(m) <em>and all the <strong>ts</strong> values</em> (i.e decimal value of length-m sub-string T[s+1....s+m], s=0,1,2,,,,n-m) in time O(n-m+1),  then we could determine all valid shifts s in time O(m) + O(n-m+1) by comparing <strong>p</strong> with each of the <strong>ts</strong> values. </p>\n\n<p>How is this possible? O(m) is for finding p, O(n-m+1) is for finding all ts, so total pre-processing time so far is O(m) + O(n-m+1). This is the total pre-processing time; the comparison has yet to start, I have to spend some extra $ for doing comparison of a decimal p with each of the (n-m+1)-ts values. </p>\n\n<p>1-Then why the authors say in the first para that the pre-processing time is O(m)? Why it is not O(m) + O(n-m+1) which include processing time of p and all ts values? </p>\n\n<p>2- Now if we talk about worst case matching time, what should be that? So in the worst my decimal number p (already calculated ) will be compared with <em>each</em> of the another (m-n+1) decimal numbers, which are the values of ts (already calculated, no extra cash needed for doing this job now ). The worst case is when I am most unlucky and I have to compare every value of ts with p. Right? </p>\n\n<p>Based on my understanding,(if I am right) the worst case matching time should be O(m-n+1) and not O((m-n+1)m) as claimed by the authors in the first para. For example let us say my Pattern is P[1...m]=226 and Text is T[1....n]=224225226. so  my p is decimal 226, and ts is decimal value of T[s+1, s+2, s+3], for s=0,1,2...6 as n=9, and m=3. The ts values will be as follows: </p>\n\n<blockquote>\n  <p>s=0 => T[224]=> ts=224     </p>\n  \n  <p>s=1 => T[242]=> ts=242 </p>\n  \n  <p>s=2 => T[422]=> ts=422 </p>\n  \n  <p>s=3 => T[225]=> ts=225 </p>\n  \n  <p>s=4 => T[252]=> ts=252 </p>\n  \n  <p>s=5 => T[522]=> ts=522 </p>\n  \n  <p>s=6 => T[226]=> ts=226</p>\n</blockquote>\n\n<p>Now you will be comparing p=226 with all these values. So are you not making n-m+1=7 comparisons to achieve search for 226 in T, and not (n-m+1)m =7 x3=21? So the worst case time should be O(n-m+1) and not O((n-m+1)m). </p>\n\n<p>In short I understand that:</p>\n\n<blockquote>\n  <p>Total pre-processing time = O(m) + O(n-m+1) (including for both p and\n  all the ts values)</p>\n  \n  <p>Total matching time in worst case = O(n-m+1)</p>\n</blockquote>\n\n<p>Where I am making mistake? </p>\n', 'ViewCount': '877', 'Title': 'Time Complexity of Rabin-Karp matching algorithm', 'LastEditorUserId': '6466', 'LastActivityDate': '2013-03-07T13:53:20.220', 'LastEditDate': '2013-03-04T12:43:50.803', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<algorithms><complexity-theory><time-complexity><search-algorithms>', 'CreationDate': '2013-03-04T12:37:40.083', 'FavoriteCount': '0', 'Id': '10258'}{'Body': '<p>I need to disprove that a <code>PARITY</code> gate can be simulated using a <strong>single</strong> <code>MAJORITY</code> gate, or even a <code>THRESHOLD</code> gate. How do I go about doing this? Some ideas as to how to go about contradiction or otherwise would be helpful.</p>\n\n<p>One possible argument would be monotonicity of <code>MAJORITY</code> and <code>THRESHOLD</code> while <code>PARITY</code> is non-monotone (Page 134 of <a href="http://www.igi.tugraz.at/psfiles/47.pdf" rel="nofollow">this paper</a>). But, I do not find this sufficiently convincing.</p>\n', 'ViewCount': '70', 'Title': 'PARITY using depth one TC0 circuit', 'LastEditorUserId': '2935', 'LastActivityDate': '2013-03-04T15:12:11.170', 'LastEditDate': '2013-03-04T15:12:11.170', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2935', 'Tags': '<complexity-theory><complexity-classes><circuits>', 'CreationDate': '2013-03-04T14:57:01.100', 'Id': '10261'}{'Body': '<blockquote>\n  <p>Given a tree $T = (V , F)$, find an algorithm which finds $u \\in V$, so in the graph $T = (V \\setminus \\{u\\} , F)$ the size of each connected component is $\\lceil |V| / 2 \\rceil$ at most. What is the complexity?</p>\n</blockquote>\n\n<p>Can I please have a hint?</p>\n', 'ViewCount': '211', 'Title': 'Find node that splits tree in half', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-07T02:37:14.300', 'LastEditDate': '2013-03-05T07:06:43.247', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '3', 'OwnerDisplayName': 'user2102697', 'PostTypeId': '1', 'Tags': '<algorithms><complexity-theory><graph-theory><trees>', 'CreationDate': '2013-03-01T15:40:43.320', 'Id': '10262'}{'Body': '<p>What I only got currently from PCP theorem is that it needs at most $O(\\log n)$ randomness and $O(1)$ query of proof to approximate. So how does this result relate to the fact that solution to NP problems are hard to approximate?</p>\n', 'ViewCount': '84', 'Title': 'Why does PCP theorem imply that NP problems are hard to approximate?', 'LastActivityDate': '2013-03-05T19:11:45.947', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10299', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7154', 'Tags': '<complexity-theory><randomized-algorithms>', 'CreationDate': '2013-03-05T12:56:15.360', 'Id': '10289'}{'ViewCount': '60', 'Title': 'What is the Meaning of the Notation', 'LastEditDate': '2013-03-05T16:22:52.133', 'AnswerCount': '1', 'Score': '2', 'OwnerDisplayName': 'Anjali Vijaya', 'PostTypeId': '1', 'OwnerUserId': '6522', 'Body': '<p>What is meant by saying an algorithm runs in time $Poly(|S|,n,\\frac{1}{\\epsilon})$.</p>\n\n<p>Can somebody explain with an example.</p>\n', 'ClosedDate': '2013-03-05T17:49:02.400', 'Tags': '<complexity-theory><machine-learning>', 'LastEditorUserId': '41', 'LastActivityDate': '2013-03-05T16:22:52.133', 'CommentCount': '3', 'AcceptedAnswerId': '10293', 'CreationDate': '2013-03-05T09:00:17.110', 'Id': '10292'}{'Body': '<p>I think half the battle in answering this question lies in formulating it precisely! A search engine doesn\'t turn up much, so I was wondering if this is a well-known or well-studied question.</p>\n\n<p>My thoughts: I think the most straightforward way to formulate this question is as in my title: Given constants $t,s,k \\in \\mathbb{N}$, how many TMs are there that run in $t$ steps or fewer on all inputs of size $k$, and how many TMs are there that use $s$ tape squares or fewer on all inputs of size $k$? This seems like the most direct and simple way to ask the question, but we might want to restate it in a different way -- for example, given a function $p(k)$, how many TMs are there that run in time $p(k)$ on inputs of size $k$ for all $k$ (or how "dense" are these TMs)? This seems harder to me.</p>\n\n<p>We should probably fix a tape alphabet (or a Godel numbering??). We could consider two TMs with different but isomorphic state diagrams to be the same or different, either way.</p>\n\n<p>The immediate problem is that there are an infinite number: Take any TM that satisfies the criteria and add "dead states". I can think of two ways to deal with this. The first (which I don\'t like) is to add an additional parameter: how many TMs whose description has length $\\leq L$ satisfy the criteria? The second (which I prefer) is to consider two TMs <em>equivalent</em> on inputs of size $\\leq k$ if, for all such inputs, the TMs have exactly the same behavior (enter the same states and write/move on the tape identically). Then we would restrict to the minimal TM in each equivalence class, or just ask how many equivalence classes satisfy the criteria.</p>\n\n<p>Edit: As pointed out by Vor in the comments, the problem with the second approach is that it\'s basically the same as a circuit at that point. So how about the first one? Or is there a nicer way to formalize this question?</p>\n\n<p>Any references/literature, thoughts, or answers would be very interesting and appreciated!</p>\n', 'ViewCount': '129', 'Title': 'How many Turing Machines are there that run in time $t$ or in space $s$ on inputs of length $k$?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-07T12:15:33.460', 'LastEditDate': '2013-03-06T07:13:07.320', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4197', 'Tags': '<complexity-theory><reference-request><turing-machines><combinatorics>', 'CreationDate': '2013-03-05T17:46:58.547', 'Id': '10298'}{'Body': '<p>I am currently confused by the following situation: </p>\n\n<p>1) The metric $k$-center problem is inapproximable in polynomial time within $2-\\epsilon$ unless $P=NP$. <br>\n2) The metric $k$-center problem can approximated within $1+\\epsilon$ in time $O(k^{O(k/ \\epsilon)})$</p>\n\n<p>Did I just win a million dollars or why isn\'t this a contradiction?\nI guess my confusion comes from the unprecise statement  "in polynomial time" in 1).</p>\n', 'ViewCount': '151', 'Title': '$1+\\epsilon$ approximation for inapproximable problems', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-05-10T12:15:42.897', 'LastEditDate': '2013-05-10T12:15:42.897', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '10302', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7159', 'Tags': '<complexity-theory><np-complete><approximation><p-vs-np><parametrized-complexity>', 'CreationDate': '2013-03-05T19:27:39.220', 'Id': '10300'}{'ViewCount': '102', 'Title': 'Witness length independent $\\exists$-Operator', 'LastEditDate': '2013-03-07T22:18:25.960', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6716', 'FavoriteCount': '1', 'Body': '<p>Short version:</p>\n\n<p>Is there an operator $\\exists$ (on complexity classes) s.t. $\\exists P = NP$ and $\\exists REC=RE$, i.e. you can use the same operator on multiple interesting classes without explicitly stating a class of functions that limits the length of the witnesses?\nThe construction should not rely on the existence of a definition of the class using any specific computation model (like Turing machines), i.e. it should be defined for any class of languages.</p>\n\n<hr/>\n\n<p>Long Version:</p>\n\n<p>For any complexity class $\\mathcal{C}$, any language $L$ and any class of functions $F\\subseteq\\{f|f:\\mathbb{N}\\rightarrow\\mathbb{N}\\}$ define</p>\n\n<p>$$\\exists^{f,\\#} L =\\{x \\in (\\Sigma\\setminus\\{\\#\\})^*|\\exists w\\in(\\Sigma\\setminus\\{\\#\\})^*: x\\#w \\in L, |w| \\leq f(|x|) \\}$$\n$$\\exists^F \\mathcal{C} =\\{L|\\exists\\#\\exists f\\in F\\exists L\'\\in\\mathcal{C}:L=\\exists^{f,\\#} L\'\\} \\qquad .$$</p>\n\n<p>Note: If $F=\\mathbb{N}^{\\mathbb{N}} = \\{f|f:\\mathbb{N}\\rightarrow\\mathbb{N}\\}$ the length of the witness $w$ becomes unrestricted (set $f(n)$ to be the maximum length of a witness for all inputs of size $n$).</p>\n\n<p>It is well known that $NP=\\exists^pP$, where $p$ is the set of all polynomials (see <a href="http://en.wikipedia.org/wiki/Polynomial_hierarchy" rel="nofollow">WP:Polynomial hierarchy</a>) and $\\exists^{\\mathbb{N}^{\\mathbb{N}}}REC=RE$ (see <a href="http://en.wikipedia.org/wiki/Arithmetical_hierarchy#Relation_to_Turing_machines" rel="nofollow">WP:Arithmetical hierarchy</a>).</p>\n\n<p>Now I\'d like to know, if one could get rid of the class of functions $F$ or define $F$ depending on the class $\\mathcal{C}$ without using a certain way to define the class (Not: If $\\mathcal{C}$ is the class of languages accepted by a TM in $\\mathrm{DTIME}(\\dots)$, then $F:=\\dots$)</p>\n\n<hr/>\n\n<p>Things I\'ve tried so far: </p>\n\n<ol>\n<li>$\\exists\\mathcal{C} = \\exists^F\\mathcal{C} \\text{ where } \\exists^{o(F)}\\mathcal{C} \\subseteq \\mathcal{C} \\text{ and } \\exists^F\\mathcal{C}\\nsubseteq \\mathcal{C}$</li>\n<li>$\\exists\\mathcal{C} = \\exists^{F\'}\\mathcal{C} \\text{ where } F\'=\\{2^f|f\\in F\\} \\text{ and } F \\text{ maximal s.t. } \\exists^{F}\\mathcal{C} \\subseteq \\mathcal{C}$\n<hr/></li>\n<li>(<strong>added:</strong>) $\\exists\\mathcal{C} = \\exists^F\\mathcal{C} \\text{ where } F=\\{f\\,|\\,\\forall L\\forall\\#\\notin\\Sigma(L):\\, \\{\\#^{f(|w|)}w|w\\in L\\} \\in \\mathcal{C} \\Leftrightarrow L \\in \\mathcal{C}\\}$, i.e. those functions s.t. $\\mathcal{C}$ is "invariant" under padding ($\\Sigma(L)=\\{a|\\exists i\\exists w_1,\\dots,w_k \\in L:\\, w_i = a \\}$).</li>\n</ol>\n\n<p>1 and 2 don\'t work for P, I\'m not sure about 3.</p>\n', 'Tags': '<complexity-theory>', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-03-08T22:32:03.673', 'CommentCount': '6', 'AcceptedAnswerId': '10395', 'CreationDate': '2013-03-06T13:39:17.580', 'Id': '10317'}{'Body': '<p>Consider the following variant of the FACTORING problem (given N,M decide whether N has a prime factor less than M):</p>\n\n<blockquote>\nMULTIPLE-FACTORING: Given three integers $1 \\leq K \\leq M \\leq N$ decide if there are at least $K$ prime factors of $N$ less than $M$\n</blockquote>\n\n<p>FACTORING $\\leq_m$ MULTIPLE-FACTORING (just pick $K=1$) and</p>\n\n<p>MULTIPLE-FACTORING $\\leq_T$ FACTORING (find all factors of $N$ using FACTORING, and count if their number is $\\geq K$)</p>\n\n<p>But is MULTIPLE-FACTORING many one reducible to FACTORING?<br>\n(MULTIPLE-FACTORING $\\leq_m^?$ FACTORING)</p>\n', 'ViewCount': '62', 'Title': 'Karp reduction between FACTORING and a variant of it', 'LastEditorUserId': '140', 'LastActivityDate': '2013-03-11T07:46:28.627', 'LastEditDate': '2013-03-11T07:46:28.627', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<complexity-theory><reductions><factoring><np>', 'CreationDate': '2013-03-11T00:00:51.463', 'FavoriteCount': '1', 'Id': '10441'}{'Body': '<p>Suppose that there is some graph, with $n$ vertexes. We wish to find the hamiltonian path, but we make the graph being searched a little different. There is a person A that travels each (undirected) edge that connects one vertex to the other vertex. But after the person crosses the edge, how edges connect pairs of vertexes change. (So, for example, before one crossed(traveled) one edge, there was an edge that connects vertex A to vertex B, but after some edge is crossed, there may no longer be the edge that connects vertex A to vertex B.) How the graph changes depends only on the order of the path being crossed - so, if he is on the third vertex in the path he chose, regardless of what path is, how the graph changes only depend on the fact that it is third vertex. Every change is known and inserted as input. Then we compute hamiltonian path. </p>\n\n<p>We can replace human with machine.</p>\n\n<p>So, what would be the name of finding hampath in such graph? And what complexity class would this be in?</p>\n\n<p>I tried to search this in my complexity textbook, but failed miserably - so I wonder if this even has a name.</p>\n', 'ViewCount': '44', 'Title': 'The name of "finding the path of a graph that is a variant of hamiltonian path"', 'LastActivityDate': '2013-03-12T13:46:05.437', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7243', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-03-12T13:46:05.437', 'Id': '10482'}{'ViewCount': '1328', 'Title': 'Flaw in my NP = CoNP Proof?', 'LastEditDate': '2013-03-13T14:36:43.313', 'AnswerCount': '3', 'Score': '6', 'OwnerDisplayName': 'simpleton', 'PostTypeId': '1', 'OwnerUserId': '7253', 'FavoriteCount': '1', 'Body': '<p>I have this very simple "proof" for NP = CoNP and I think I did something wrongly somewhere, but I cannot find what is wrong. Can someone help me out?</p>\n\n<p>Let A be some problem in NP, and let M be the decider for A. Let B be the complement, i.e. B is in CoNP. Since M is a decider, you can use it to decide B as well (just flip the answer). Doesn\'t that mean that we solve both NP and CoNP problems with the same M?</p>\n\n<p>To put it more concretely.</p>\n\n<p>Let A be some NP-complete problem, and let M be decider for A. Consider any problem B in CoNP. We consider its complement not-B, which is in NP, and then get a polynomial reduction to A. Then we run our decider M and flip our answer. We thus obtain a decider for B. This implies B is in NP as well. </p>\n\n<p>May I know what is wrong with my reasoning?</p>\n', 'Tags': '<complexity-theory><p-vs-np><check-my-proof><np>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-13T14:36:43.313', 'CommentCount': '2', 'CreationDate': '2013-03-12T09:52:11.097', 'Id': '10485'}{'Body': '<p>Given any graph $G$ on $V(G)=\\{1,\\dots,n\\}$ and its adjacency matrix \n$$A(G)=\\left(\\matrix{\nA_{1,1} &amp; A_{1,2} &amp; \\dots &amp; A_{1,n}\\\\\nA_{2,1} &amp; A_{2,2} &amp; \\dots &amp; A_{2,n}\\\\\n&amp;&amp;\\dots&amp;\\\\\nA_{n,1} &amp; A_{n,2} &amp; \\dots &amp; A_{n,n}\n}\\right)$$ any permutation on  $\\{1,\\dots,n\\}$ defines a new isomorphic graph $G\'$. A common approach to canonization is to take the lexicographically  minimal string $A\'_{1,2}A\'_{1,3}\\dots A\'_{n-1,n}$ (i.e. the upper/lower triangular matrix) such that $G$ is isomorphic to $G\'$ with $A\'=A(G\')$.</p>\n\n<p>If you now consider a permutation on $I=\\{(i,j)\\mid 1\\leq i&lt;j\\leq n\\}$ or equivalently  a bijective function $\\pi : \\{1,\\dots,{n \\choose 2}\\} \\rightarrow I$, we can try to minimize $A\'_{\\pi(1)},\\dots,A\'_{\\pi({n\\choose 2})}$ instead, or at least to compute the first $k$ bits of the minimal string.</p>\n\n<p>Observe that the complexity of this task heavily depends on the choice of $\\pi$:</p>\n\n<ol>\n<li>If you stick with default permutation (upper triangular matrix) you can easily compute the first $2n-1$ bits in polynomial time (adjacent vertices with maximal degrees).</li>\n<li>If you choose $\\pi(i)=(i,i+1)$ for the first $\\sqrt[c]{n}$ positions, you can reduce <strong>HamiltonPath</strong> to this in polynomial time.</li>\n</ol>\n\n<p><strong>Now my questions</strong>:</p>\n\n<ol>\n<li>Given a fixed function $k$ and input $(G,\\pi)$ how hard is it to compute the first bits $k(|V(G)|)$ of the minimal string $A\'_{\\pi(1)},\\dots,A\'_{\\pi({n\\choose 2})}$? Is there any (not necessarily strictly) monotonically increasing $k$ for which this is feasible? </li>\n<li>Is there a $\\pi$ s.t. even $\\omega(n)$ bits can be computed in polynomial time?</li>\n<li>Do you know any other reductions to a problem of this kind where $\\pi$ is "fixed" (i.e. only depends on $|V(G)|$) and the input has the form $(G,k)$ or $G$ (i.e. $k$ is "fixed" too)?</li>\n</ol>\n\n<p>Note: Answering (1) is enough to get accepted.</p>\n\n<p>Edit: In the meanwhile there appeared a somewhat connected question: <a href="http://cs.stackexchange.com/questions/10576/is-induced-subgraph-isomorphism-easy-on-an-infinite-subclass">Is induced subgraph isomorphism easy on an infinite subclass?</a></p>\n', 'ViewCount': '58', 'Title': 'Complexity of computing the first bits of a minimal permuted adjacency matrix', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-03-19T17:08:31.693', 'LastEditDate': '2013-03-19T17:08:31.693', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><graph-theory><graph-isomorphism>', 'CreationDate': '2013-03-12T17:46:21.020', 'Id': '10493'}{'Body': '<p>I am wondering in general if it is correct to claim that <strong>if a special case of a problem is NP-Hard, the general case of that problem is NP-\nHard too?</strong></p>\n\n<p>For example: Min Set-Cover is NP-Hard does it imply without having to prove that Min Set-k-Cover where each element needs to be covered k times is NP-Hard too? </p>\n', 'ViewCount': '77', 'Title': 'Does hardness of a special case imply hardness of a general case?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-18T20:50:52.970', 'LastEditDate': '2013-03-14T07:39:17.577', 'AnswerCount': '3', 'CommentCount': '5', 'Score': '2', 'OwnerDisplayName': 'user14178', 'PostTypeId': '1', 'Tags': '<complexity-theory><terminology><np-hard>', 'CreationDate': '2013-03-13T14:11:38.093', 'Id': '10514'}{'Body': u'<p>I want to prove that $E \\subsetneq EXP$ and i would like to do so using the Time Hierarchy Theorem </p>\n\n<p>I need to choose $f(n)$, i think $2^{cn}$ is a good choice, so here is my Proof:</p>\n\n<ul>\n<li>$E\\subseteq TIME(2^{cn})$</li>\n<li>$TIME(2^{cn}) \\subsetneq TIME(n^2 \\cdot (2^{cn})^2)$ Time Hierarchy Theorem</li>\n<li>$E \\subsetneq EXP$</li>\n</ul>\n\n<p>Is this correct ?</p>\n\n<hr>\n\n<p>I have done something similar with $P\\subsetneq EXP$: <br> <strong>PROOF IDEA</strong>:</p>\n\n<ul>\n<li>$P\\subseteq TIME(2^n)$</li>\n<li>$TIME(2^n)\\subsetneq TIME(n^2\\cdot (2^n)^2) \\ \\text{Time Hierarchy Theorem}$</li>\n<li>$TIME(n^2\\cdot (2^n)^2)\\subseteq EXP$</li>\n<li>$P\\subsetneq EXP$</li>\n</ul>\n\n<hr>\n\n<blockquote>\n  <p><strong>Complexity class E:</strong> $E=\\bigcup_{c\\ge 0}TIME(2^{cn})$ <br>\n  <strong>Complexity Class EXPTIME:</strong> $EXP=\\bigcup_{c\\ge 0}TIME(2^{n^c})$ <br>\n  <strong>Time Hierarchy Theorem:</strong> $TIME(f(n)) \\subsetneq TIME(n\xb2\\cdot (fn)\xb2)$</p>\n</blockquote>\n\n<p>The <strong><em>Time Hierarchy Theorem</em></strong> shows that allowing Turing Machines more computation time strictly increases the class of languages that they can decide. Recall that a function $f : N \u2192 N$ is a time-constructible function if there is a Turing machine that, given the input $1^n$ , writes down $1^{f(n)}$ on its\ntape in $O(f (n))$ time. </p>\n', 'ViewCount': '115', 'Title': 'How to Prove E $\\subsetneq$ EXP?', 'LastEditorUserId': '6672', 'LastActivityDate': '2013-03-17T13:20:00.520', 'LastEditDate': '2013-03-16T16:16:54.643', 'AnswerCount': '2', 'CommentCount': '10', 'AcceptedAnswerId': '10560', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6672', 'Tags': '<complexity-theory><time-complexity><complexity-classes>', 'CreationDate': '2013-03-16T14:04:12.593', 'Id': '10551'}{'Body': '<p>Does the difficulty of a strongly NP-hard or NP-complete problem (as e.g. defined <a href="http://en.wikipedia.org/wiki/Strongly_NP-complete" rel="nofollow">here</a>) change when its input is unary instead of binary encoded?</p>\n\n<p>What difference does it make if the input of a strongly NP-hard problem is unary encoded? I mean, if I take for instance the weakly NP-complete Knapsack problem, it is NP-complete when binary encoded but can be solved in polynomial time by dynamic programming when unary encoded. Maybe it has some implications for hardness of higher levels of the polynomial time heirarchy?</p>\n\n<p>Does the notion of strongly ...-hard also hold for other complexity classes, e.g. higher classes of the polynomial time hierarchy?</p>\n\n<p>I previously asked this <a href="http://stackoverflow.com/q/15454532/1708806">question at stackoverflow.com</a> but it was pointed out that it is more appropriate here. </p>\n', 'ViewCount': '233', 'Title': 'Does the complexity of strongly NP-hard or -complete problems change when their input is unary encoded?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-17T18:18:32.653', 'LastEditDate': '2013-03-17T18:12:21.403', 'AnswerCount': '4', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '7309', 'Tags': '<complexity-theory><time-complexity><np-complete>', 'CreationDate': '2013-03-16T22:59:58.783', 'Id': '10563'}{'Body': '<p>An undirected graph is a near clique if adding an additional edge would make it a clique. Formally, a graph $G = (V,E)$ contains a near clique of size $k$ where $k$ is a positive integer in $G$ if there exists $S \\subseteq V$ where $|S| = k$ and $u,v \\in S$ where $(u,v) \\not\\in E$, and $S$ forms a clique in $(V,E \\cup \\{(u,v)\\})$. How can I show finding a near clique of size $k$ in $G$ is NP-complete? </p>\n', 'ViewCount': '173', 'Title': 'Prove finding a near clique is NP-complete', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-17T18:21:40.813', 'LastEditDate': '2013-03-17T18:21:40.813', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '10583', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6723', 'Tags': '<complexity-theory><graph-theory><np-complete>', 'CreationDate': '2013-03-17T07:07:50.377', 'Id': '10573'}{'Body': '<p>Is there a sequence of undirected graphs $\\{C_n\\}_{n\\in \\mathbb N}$, where each $C_n$ has exactly $n$ vertices and the problem </p>\n\n<blockquote>\n  <p>Given $n$ and a graph $G$, is $C_n$ an induced subgraph of $G$?</p>\n</blockquote>\n\n<p>is known to be in class $\\mathsf{P}$?</p>\n', 'ViewCount': '183', 'Title': 'Is induced subgraph isomorphism easy on an infinite subclass?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-05T10:06:27.850', 'LastEditDate': '2013-03-18T07:35:29.710', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '11032', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '667', 'Tags': '<complexity-theory><graphs>', 'CreationDate': '2013-03-17T12:13:37.153', 'Id': '10576'}{'Body': "<p>This is a Data structures &amp; Algorithms question. For instance I have the following grades of functions: $O(1), O(2^n), O(n \\log n), O(e^n), O(n^3), O(n^{1/3})$ and $O(\\log \\log n)$  </p>\n\n<p>I need to show and proof to which of these function grades does the function: $n^7$ belong to. \nI didn't get a chance to ask my professor on this topic so I'm not sure how to solve this problem.</p>\n", 'ViewCount': '54', 'ClosedDate': '2013-03-18T10:24:46.367', 'Title': 'Show that a function belongs to grade of incline', 'LastEditorUserId': '157', 'LastActivityDate': '2013-03-18T10:14:45.007', 'LastEditDate': '2013-03-17T21:26:38.540', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'OwnerDisplayName': 'user1125177', 'PostTypeId': '1', 'Tags': '<complexity-theory><asymptotics><landau-notation>', 'CreationDate': '2013-03-17T20:11:18.047', 'Id': '10588'}{'Body': '<p>Consider the following problem. Given a $m \\times n$ integer matrix $A$ and a $p \\times q$ integer matrix $B$, do there exist one-to-one functions \n$$r:\\{1,2,...,m\\} \\rightarrow \\{1,2,...,p\\}$$\n$$c:\\{1,2,...,n\\} \\rightarrow \\{1,2,...,q\\}$$\nwhere for all $1 \\leq i \\leq m$ and $1 \\leq j \\leq n$, $A[i,j] \\leq B[r(i),c(j)]$? </p>\n\n<p>What is the best way to show this problem is NP-complete? I am currently considering reducing the clique problem to this problem.  </p>\n', 'ViewCount': '71', 'Title': 'Prove Matrix Correspondence is NP-complete', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-18T07:36:52.923', 'LastEditDate': '2013-03-18T07:36:52.923', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10596', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6723', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-03-18T02:57:18.987', 'Id': '10595'}{'Body': '<p>Unfortunately my background in computational complexity is still weak, but I am working on it.</p>\n\n<p>As I understand, the question of existence of one-way functions is very important in the field.</p>\n\n<p>Assume there are one way-functions, how it can be shown that there exist one-way functions which are length preserving?</p>\n', 'ViewCount': '200', 'Title': 'Length-preserving one-way functions', 'LastEditorUserId': '157', 'LastActivityDate': '2013-03-21T10:21:10.180', 'LastEditDate': '2013-03-20T16:22:22.640', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><cryptography><one-way-functions>', 'CreationDate': '2013-03-20T08:46:30.130', 'Id': '10639'}{'ViewCount': '169', 'Title': 'How hard is a variant of Sudoku puzzle?', 'LastEditDate': '2013-03-21T02:23:06.343', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '96', 'FavoriteCount': '1', 'Body': '<p>Sudoku is well known puzzle which is known to be NP-complete and it is a special case of more general problem known as Latin squares. A correct solution of the $N \\times N$ square consists of filling every row and every column with numbers from $1$ to $N$ under the condition that every number appears exactly once in any row or any column.</p>\n\n<p>I define a new problem. The input is a correct solution of $N \\times N$ Sudoku puzzle (more generally Latin square problem). I would like to decide whether there is permutation of rows and permutation of columns such that no row and no column contains consecutive triples. </p>\n\n<p>An examples for a row without consecutive triple is 9 5 6 2 3 8 4 7 1. An example for a row with consecutive triple is 8 9 5 2 3 4 7 6 1. The triple is 2 3 4.</p>\n\n<p>I suspect the problem is NP-hard but I was not able to find a reduction.</p>\n\n<p>How hard is solving this variant of Sudoku puzzle? Is it NP-complete?</p>\n\n<p><strong>EDIT</strong> : To clarify, the same permutation must be applied to the columns and the rows.</p>\n', 'Tags': '<complexity-theory><np-complete>', 'LastEditorUserId': '96', 'LastActivityDate': '2013-03-21T03:50:34.153', 'CommentCount': '9', 'AcceptedAnswerId': '10671', 'CreationDate': '2013-03-20T13:41:08.940', 'Id': '10646'}{'ViewCount': '218', 'Title': 'Is detecting "doubly" arithmetic progressions 3SUM-hard?', 'LastEditDate': '2013-03-21T10:36:09.113', 'AnswerCount': '1', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '7362', 'FavoriteCount': '2', 'Body': '<p>This is inspired by an <a href="http://www.careercup.com/question?id=15877680">interview question</a>.</p>\n\n<p>We are given an array of integers $a_1, \\dots, a_n$ and have to determine if there are distinct $i \\lt j \\lt k$ such that</p>\n\n<ul>\n<li>$a_k - a_j = a_j - a_i$</li>\n<li>$k - j = j - i$</li>\n</ul>\n\n<p>i.e, the sequences $\\{a_i, a_j, a_k\\}$ and $\\{i,j,k\\}$ are both in arithmetic progression.</p>\n\n<p>There is an easy $O(n^2)$ algorithm for this, but finding a sub-quadratic algorithm seems elusive.</p>\n\n<p>Is this a known problem? Can we prove 3SUM-hardness of this? (or maybe provide a sub-quadratic algorithm?)</p>\n\n<p>If you like, you can assume $0 \\lt a_1 \\lt a_2 \\lt ... \\lt a_n$ and that $a_{r+1} - a_{r} \\le K$ for some known constant $K &gt; 2$. (In the interview problem, $K = 9$).</p>\n', 'Tags': '<algorithms><complexity-theory><lower-bounds>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-24T03:39:07.830', 'CommentCount': '0', 'AcceptedAnswerId': '10725', 'CreationDate': '2013-03-21T07:56:00.003', 'Id': '10681'}{'Body': "<p>Define the problem $W$:</p>\n\n<blockquote>\n  <p><strong>Input:</strong> A multi-set of numbers $S$, and a number $t$.</p>\n  \n  <p><strong>Question:</strong> What is the smallest subset $s \\subseteq S$ so that $\\sum_{k \\in s} k = t$, if there is one? (If not, return <code>none</code>.)</p>\n</blockquote>\n\n<p>I am trying to find some polytime equivalent decision problem $D$ and provide a polytime algorithm for the non-decision problem $W$ assuming the existence of a polytime algorithm for $D$.</p>\n\n<p>Here is my attempt at a related decision problem:</p>\n\n<blockquote>\n  <p>$\\mathrm{MIN\\text{-}W}$:</p>\n  \n  <p><strong>Input:</strong> A multi-set of numbers $S$, two numbers $t$ and $k$.</p>\n  \n  <p><strong>Question:</strong> Is there a subset $s \\subseteq S$ so that $\\sum_{k \\in s} k = t$ and $|s| \\leq k$?</p>\n</blockquote>\n\n<p>Proof of polytime equivalence:</p>\n\n<p>Assume $W \\in \\mathsf{P}$.</p>\n\n<pre><code>solveMIN-W(S, t, k):\n1. S = sort(S)\n2. Q = {}\n3. for i=1 to k:\n4.     Q.add(S_i)\n5.     res = solveW(Q, t)\n6.     if res != none and res = t: return Yes\n7. return No\n</code></pre>\n\n<p>I'm not sure about this algorithm though. Can anyone help please?</p>\n", 'ViewCount': '89', 'Title': 'How to prove polynomial time equivalence?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-22T13:44:52.263', 'LastEditDate': '2013-03-22T13:44:52.263', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10692', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<complexity-theory><reductions><p-vs-np>', 'CreationDate': '2013-03-22T04:50:15.547', 'Id': '10690'}{'Body': '<p>So I\'m trying to understand P/NPC problems. The one I\'m trying to tackle now is subset sum (we have a collection of integers $S$ and a $k$ param: is there a subset of $S$ that sum of all it\'s elements is equal to $k$?) problem and the proof that ss is an NPC problem by reduction from 3SAT. </p>\n\n<p>I\'ve found two PDF\'s that attempt to solve that, but the problem is, I don\'t have the foggiest idea how to \'explain in in my own words\'. </p>\n\n<p>Okay, some links ahead and questions related to them: </p>\n\n<p><a href="http://people.clarkson.edu/~alexis/PCMI/Notes/lectureB07.pdf" rel="nofollow">Here</a>, on page 4th, there\'s a logic table for 3SAT clause that apparently proves why ss is NPC, but I don\'t get it - what exactly are those s and t values, and how does that table proves NPC\'ness? And how k is computed in that table? It\'s simply not clear to me :(</p>\n\n<p><a href="http://valis.cs.uiuc.edu/~sariel/teach/2004/b/webpage/lec/10_npc_notes.pdf" rel="nofollow">Another link</a>\non pages 5 and 6 there are another tables that appear out of nowhere with no explanation that I could understand.</p>\n\n<p>So, if anybody knows what I\'m talking about and could help me, please answer :). Or, if it\'s possible, can anybode give me a simple and straightforward proof why subset sum is NPC?</p>\n', 'ViewCount': '812', 'Title': 'Proving NP Completeness of a subset-sum problem - how?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-23T15:55:25.050', 'LastEditDate': '2013-03-23T15:55:25.050', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'OwnerDisplayName': 'user67311', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-03-18T16:01:15.190', 'Id': '10702'}{'ViewCount': '368', 'Title': 'How to prove NP-hardness of a longest-path problem?', 'LastEditDate': '2013-11-13T17:56:10.210', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7168', 'FavoriteCount': '1', 'Body': "<p>I have this question:</p>\n\n<pre><code>Input: \nG(V, E) = an undirected graph, V={v1, v2, ..., vn} (V = set of nodes, E = set of edges)\nwhere there is a path connecting from v1 to vn.\n\nQuestion: \nWhat is the maximum number of nodes you can visit when starting from v1 and ending at vn. \n(including v1 and vn) \nEach node can only be visited at most once.\n</code></pre>\n\n<p>I want to prove that this is NP-hard by reducing it from a known NP-complete problem, such as undirected Hamiltonian path or subset-sum.</p>\n\n<p>However I don't know exactly how to do this and this is where I need help.</p>\n\n<p>Can anyone help please?</p>\n", 'Tags': '<complexity-theory><reductions><proof-techniques><np-hard>', 'LastEditorUserId': '755', 'LastActivityDate': '2013-11-13T17:56:10.210', 'CommentCount': '1', 'AcceptedAnswerId': '10734', 'CreationDate': '2013-03-24T03:02:15.400', 'Id': '10732'}{'Body': "<p>I have this problem which is described as follows:</p>\n\n<p>Input:\n    You are given a multi-set $M$ (a set that can contain duplicates), and two numbers $P$ and $T$.\n    $M = {(x_1,y_1), (x_2,y_2), ..., (x_n,y_n)}$.\n    Each $x$ and $y$ is an integer $&gt;= 0$.\n    $P$ in an integer $&gt;= 0$.\n    $T$ is an integer $&gt; 0$.</p>\n\n<p>Question:\n    Is there a subset $G$ of $M$, such that the sum of every $x$ value of $G$ is $&gt; P$ and the sum of every $y$ value of $G$ is $&lt; T$?\n    (Note: You are basically taking from $M$. For example: if $M$ has two $(1,1)$'s then $G$ can contain at most two $(1, 1)$'s)</p>\n\n<p>I want to reduce it to from the subset sum problem, but I am not sure how because there's two conditions to solve for...</p>\n\n<p>Can anyone help with this problem?</p>\n", 'ViewCount': '144', 'Title': 'How to reduce from subset-sum problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-25T12:06:45.403', 'LastEditDate': '2013-03-25T12:06:45.403', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '10748', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2013-03-24T17:43:29.840', 'Id': '10747'}{'Body': '<p>Suppose I have a graph $G$ with $M(G)$ the (unknown) set of perfect matchings of $G$. Suppose this set is non-empty, then how difficult is it to sample uniformly at random from $M(G)$? What if I am okay with a distribution that is close to uniform, but not quite uniform, then is there an efficient algorithm?</p>\n', 'ViewCount': '113', 'Title': 'Sampling perfect matching uniformly at random', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-26T10:12:47.543', 'LastEditDate': '2013-03-26T10:12:47.543', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '10758', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '55', 'Tags': '<algorithms><complexity-theory><matching><sampling>', 'CreationDate': '2013-03-24T21:22:33.253', 'Id': '10756'}{'Body': '<p>I have a question have to answer, so that, if anyone have the answer, please help me.</p>\n\n<p>The problem is: Give a self-contained proof that $\\mathsf{L} \\neq \\mathsf{PSPACE}$\nwhere: </p>\n\n<p>$\\qquad \\mathsf{L}      = \\{ L \\mid L \\text{ is a language decidable in logarithmic space} \\}$ and</p>\n\n<p>$\\qquad  \\mathsf{PSPACE} = \\{ L \\mid L \\text{ is a language decidable in polynomial space}\\}$.</p>\n', 'ViewCount': '111', 'Title': 'Relationship between L and PSPACE', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-25T10:39:03.237', 'LastEditDate': '2013-03-25T10:39:03.237', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'OwnerDisplayName': 'user14332', 'PostTypeId': '1', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-03-25T06:42:58.217', 'Id': '10764'}{'Body': "<p>There are many NP-complete decision problems that ask the question whether it holds for the optimal value that OPT=m (say bin packing asking whether all items of given sizes can fit into m bins of a given size).\nNow, I am interested in the problem whether OPT>m. Is this a decision problem or an optimization problem? It seems to be that it lies in NP (a NTM can guess a solution and it can be verified in polynomial time that the bound is met). Is it also NP-complete?</p>\n\n<p>I would have said yes, because having a polynomial algorithm, we could find a solution in polynomial time for the original problem (asking whether OPT=m) by using binary search and repeatedly using the polynomial algorithm to test if OPT larger than some bound.</p>\n\n<p>However when I try to construct a proper solution, I always see the complication that the oracle (that asks whether OPT>m') would need to be queried more than once, and this is forbidden in the polynomial time Karp reduction.</p>\n\n<p>Any solutions or remarks?\nWould it make a difference if I ask whether OPT>=m?</p>\n\n<p>Thanks in advance</p>\n", 'ViewCount': '136', 'Title': 'Polynomial time reductions using binary search', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-26T11:07:26.827', 'LastEditDate': '2013-03-25T15:20:47.793', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7309', 'Tags': '<complexity-theory><terminology><np-complete><optimization><decision-problem>', 'CreationDate': '2013-03-25T14:08:42.207', 'Id': '10774'}{'Body': "<p>I have a problem where I am supposed to analyze the <code>Steiner tree problem</code> by doing the following 3 steps.</p>\n\n<p>1) Look up what the Steiner tree problem is.</p>\n\n<p>2) Find a polynomial time reduction to it from one of these 8 known NP-complete problems:</p>\n\n<ul>\n<li>3-col </li>\n<li>subset-sum </li>\n<li>clique </li>\n<li>hampath </li>\n<li>Uhampath </li>\n<li>sat </li>\n<li>3-sat </li>\n<li>vertex-cover.</li>\n</ul>\n\n<p>3) Prove that it is NP-complete.</p>\n\n<hr>\n\n<p>My first problem is that I don't understand what the Steiner tree problem is. I can't find the problem anywhere. Wikipedia has  a page on it, but doesn't really describe it in simple terms.</p>\n\n<p>Can anyone help me out on this, and also give me hints for number 1, 2 and 3?</p>\n", 'ViewCount': '202', 'Title': 'How to analyze the Steiner tree problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-26T11:23:15.850', 'LastEditDate': '2013-03-26T11:23:15.850', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<complexity-theory><graph-theory><np-complete><reductions><trees>', 'CreationDate': '2013-03-26T00:09:08.733', 'FavoriteCount': '2', 'Id': '10790'}{'ViewCount': '192', 'Title': 'Job scheduling with a bottleneck problem', 'LastEditDate': '2013-03-29T08:50:28.533', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '3', 'Body': '<p>Given $n$ jobs $J_1,J_2,...,J_n$, each job requires $T_i &gt; 0, T_i \\in N$ time to complete.</p>\n\n<p>Each job must be pre-processed and post-processed by a single machine M that can handle only <em>1 job at a time</em> and both phases require 1 unit of time. After being pre-processed, job $J_i$ is sent to a machine with unlimited power (that can handle in parallel an unlimited number of jobs) and it will be ready in time $T_i$, then it must be sent (<strong>immediately</strong>) to machine M again for post-processing. </p>\n\n<p><img src="http://i.stack.imgur.com/Y3BVv.png" alt="enter image description here"></p>\n\n<p>The associated decision problem is:</p>\n\n<p><em>Input:</em> the processing times $T_i &gt;0, T_i \\in \\mathbb{N}$ of $N$ jobs, an integer $K\\geq 2N$<br>\n<em>Question:</em> can we process all the jobs in time $\\leq K$ using the above "bottleneck" model ?</p>\n\n<blockquote>\nHas this problem a name?<br>\nWhat is its complexity? (is it in $\\sf{P}$ or is it $\\sf{NP}$-complete?)\n</blockquote>\n\n<p><strong>UPDATE 29 March:</strong><br>\nAs correctly noticed by M.Cafaro in his answer, the problem is similar to the \n<em>Unconstrained Minimum Finish Time Problem (UMFT)</em> (see Chapter 17 of \n<a href="http://books.google.it/books?id=MAY1ZstmGPkC">Handbook of Scheduling Algorithms</a>) which is $\\sf{NP}$-hard (proved in\n W. Kern and W. Nawijn, "Scheduling multi-operation jobs with time lags on a single machine", University of Twente, 1993). As I can see, there are some differences because in my model:</p>\n\n<ul>\n<li>the pre/post processing time is constant (1 unit of time)</li>\n<li>as soon as the job is completed it must immediately be post-processed (the UMFT model allows delays)</li>\n</ul>\n\n<p>I didn\'t found the Kern &amp; Nawijn proof online, so I still don\'t know if the above restrictions change the difficulty of the problem.</p>\n\n<p>Finally you can think the whole process like a single <em>cook robot</em> with a big oven; the robot can prepare different types of foods one at a time (all require the same time of preparation), put them in the oven, and as soon as they are cooked it must remove them from the oven and add some cold ingredients ... the "<em>cook robot problem</em>" :-)</p>\n', 'Tags': '<complexity-theory><reference-request><scheduling>', 'LastEditorUserId': '140', 'LastActivityDate': '2013-06-21T18:54:32.070', 'CommentCount': '11', 'AcceptedAnswerId': '12822', 'CreationDate': '2013-03-28T11:49:30.607', 'Id': '10869'}{'Body': '<p>I have a hard time understanding the following lines from our lecture notes:</p>\n\n<hr>\n\n<p>$f \\in \\text{FP}$ iff there is a transducer T that computes $f$ and there exists a polynomial $p$ such that $TIME(T(x)) \\leq p(|x|).$</p>\n\n<p>Note: If $f \\in \\text{FP},$ then $|f(x)| \\leq p(|x|)$ holds for a fixed polynomial $p.$</p>\n\n<p>Examples:</p>\n\n<p>$f(x) = x^2$ ($x$ is a binary number)</p>\n\n<p>$f(x) = $ Table of the shortest paths from a start node s in a directed graph $G,$ where $G$ and $s$ are coded as $x.$</p>\n\n<p>$f(x) = 2^x$ is not in $\\text{FP}.$</p>\n\n<hr>\n\n<p>Can somebody please explain the examples in a dummy-friendly way?</p>\n', 'ViewCount': '61', 'Title': 'The complexity class FP', 'LastActivityDate': '2013-03-29T16:38:31.633', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10888', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4713', 'Tags': '<complexity-theory>', 'CreationDate': '2013-03-29T08:57:23.470', 'Id': '10886'}{'Body': '<p>Do you know of any kind of decomposition of graphs that involves centers, especially in the context of parametrized complexity? If so, please provide some reference. If not, do you see any reason (other than the potentially large size of centers) why such a notion isn\'t fruitful (e.g. subsumed by other notion)?</p>\n\n<p>I\'m looking for something similar to this:</p>\n\n<p>Let $G=(V,E)$ be an undirected graph. Its <em>central decomposition</em> is</p>\n\n<ul>\n<li>If $G$ is not connected: the set of central decompositions of its connected components.</li>\n<li>If $G$ is self-centered (radius equals diameter): $G$</li>\n<li>If $G$ is connected and not self-centered and its center is $C$: the pair $(I,O)$ where $I$ is the central decomposition of $G[C]$ and $O$ is the central decomposition of $G[V\\setminus C]$ (induced subgraphs of center and its complement)</li>\n</ul>\n\n<p>Its <em>central width</em> shall be the size of largest self-centered graph which appears in its central decomposition.</p>\n\n<p>The notion may also use other concepts (like complements, trees etc.), but it should use centers recursively. There is no need for uniqueness.</p>\n\n<p>I\'m <strong>not looking for</strong> e.g. <em>path distance decompositions</em> (see <a href="http://igitur-archive.library.uu.nl/math/2007-0104-200209/bodlaender_97_isomorphism.pdf" rel="nofollow">here</a>) where the root is the center, i.e. a map $d$ of a path $\\{p_0,\\dots,p_k\\}$ to $V$ where $d(p_i)=\\{v\\in V\\mid \\min_{c \\in C}\\mathrm{dist}(v,c) = i\\}$ ($C$ being the center of $G$).</p>\n', 'ViewCount': '58', 'Title': 'Decomposition of graphs that uses centers', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-04-03T15:31:28.617', 'LastEditDate': '2013-04-03T15:31:28.617', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><graph-theory><reference-request><parametrized-complexity>', 'CreationDate': '2013-03-29T21:09:20.307', 'Id': '10903'}{'ViewCount': '296', 'Title': 'Subset Sum: reduce special to general case', 'LastEditDate': '2013-04-02T22:46:23.867', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '7549', 'FavoriteCount': '2', 'Body': '<p><a href="http://en.wikipedia.org/wiki/Subset_sum_problem">Wikipedia</a> states the subset sum problem as finding a subset of a given set of integers, whose sum is zero. Further it describes it as equivalent to finding a subset with sum $s$ for any given $s$.</p>\n\n<p>So I believe as they are equivalent, there must be a reduction in either side. The one from $s$ to zero is trivial by setting $s = 0$. But I had no luck finding a reduction from zero to $s$, i.e. given a set of integers $A$, construct a set of integers $B$ containing a subset with sum $s$ (for any $s$), if and only if there is as subset of $A$ with sum zero.</p>\n\n<p>Can you give me some pointers?</p>\n', 'Tags': '<complexity-theory><reductions><np-hard>', 'LastEditorUserId': '268', 'LastActivityDate': '2013-04-03T06:52:39.257', 'CommentCount': '0', 'AcceptedAnswerId': '10987', 'CreationDate': '2013-04-02T22:06:48.883', 'Id': '10981'}{'Body': '<p>I was learning about algorithms with polynomial time complexity. I found the following algorithms interesting.</p>\n\n<ul>\n<li><p>Linear Search - with time complexity $O(n)$</p></li>\n<li><p>Matrix Addition - with time complexity $O(n^2)$</p></li>\n<li><p>Matrix Multiplication - with time complexity  $O(n^3)$</p></li>\n</ul>\n\n<p>Is there any algorithm with a higher complexity like $n^4$, $n^5$ etc? I would like to know about practical algorithms with polynomial time complexity only.</p>\n\n<p>(I am familiar with algorithms having exponential complexity and class NP algorithms. My doubt is not about them.)</p>\n', 'ViewCount': '568', 'Title': 'Algorithms with polynomial time complexity of higher order', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-03T21:05:45.970', 'LastEditDate': '2013-04-03T21:05:45.970', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '11002', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7363', 'Tags': '<algorithms><complexity-theory><asymptotics>', 'CreationDate': '2013-04-03T18:10:35.997', 'Id': '10997'}{'ViewCount': '29', 'Title': 'Why are optimization problems always NP-hard and not NP-complete and what does this mean for other levels of the polynomial time hierarchy?', 'LastEditDate': '2013-04-03T20:22:50.270', 'AnswerCount': '0', 'Score': '2', 'OwnerDisplayName': 'user2145167', 'PostTypeId': '1', 'OwnerUserId': '7309', 'Body': '<p>I have read that optimization problems cannot be $\\mathcal{NP}$-complete, but are always classified as $\\mathcal{NP}$-hard. When a problem is NP-complete, I know it is contained in $\\mathcal{NP}$P. This implies in particular that it is not hard for the second level of the polynomial time hierarchy, e.g. for $\\Sigma_2^P$ or $\\Pi_2^P$. But since optimization problems are only NP-hard, I have no such knowledge. Or are optimization problems usually also $\\Sigma_2^P$-hard or $\\Pi_2^P$-hard, or just some of them?</p>\n\n<p>Are there any interesting problems from combinatorial optimization that are harder than $\\mathcal{NP}$-hard, e.g. hard for the second level of the polynomial time hierarchy?</p>\n\n<p>I am in particular interested in problems from combinatorial optimization, e.g. BP (bin packing), TSP and CVRP (capacitated vehicle routing problem). They are all classified as $\\mathcal{NP}$-hard, but CVRP is a generalization of both TSP and BP, so it should be harder? Bin packing should be easier, are there any results showing this?\nDoes anyone know, if there are hardness results for any of these problems that imply more difficult than $\\mathcal{NP}$-hard?</p>\n\n<p>I know there are many versions of CVRP and TSP and unfortunately I know not a lot about them.</p>\n', 'ClosedDate': '2013-04-05T08:15:21.540', 'Tags': '<complexity-theory><terminology><optimization><integer-programming>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-03T20:22:50.270', 'CommentCount': '3', 'CreationDate': '2013-03-21T09:30:40.023', 'Id': '11001'}{'ViewCount': '357', 'Title': 'Do any decision problems exist outside NP and NP-Hard?', 'LastEditDate': '2013-04-04T07:16:45.770', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7572', 'FavoriteCount': '1', 'Body': '<p><a href="http://cs.stackexchange.com/questions/9063/np-hard-that-is-not-np-complete-and-not-undecidable">This question</a> asks about NP-hard problems that are not NP-complete. I\'m wondering if there exist any decision problems that are neither NP <em>nor</em> NP-hard.</p>\n\n<p>In order to be in NP, problems have to have a verifier that runs in polynomial time on a deterministic Turing machine. Obviously, all problems in P meet that criteria, but what about the problems with sub-exponential complexity? They do not belong to P and it\'s not obvious to me that they all have efficient deciders. And they certainly don\'t qualify for NP-complete.</p>\n\n<p>I\'m willing to believe that all decision problems are either NP or NP-hard or both, but nobody has actually <em>said</em> that (that I can find). I\'m also willing to believe that such problems do exist, even if they are very contrived. Maybe someone more knowledgeable can put this issue to rest for me. Thanks.</p>\n\n<p><strong>Edit</strong></p>\n\n<p>I abused the term \'subexponential\' in my question. In my mind it meant some problem with a complexity between exponential and polynomial like L-notation in <a href="http://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions" rel="nofollow">this table</a>. See the links in Raphael\'s answer for more details.</p>\n', 'Tags': '<complexity-theory><np-complete><np-hard><decision-problem><complexity-classes>', 'LastEditorUserId': '7572', 'LastActivityDate': '2013-04-04T13:33:02.737', 'CommentCount': '4', 'AcceptedAnswerId': '11012', 'CreationDate': '2013-04-04T04:53:18.070', 'Id': '11009'}{'Body': '<p>I was thinking about how nature can efficiently compute ridiculous (i.e. NP) problems with ease. For example, a quantum system requires a $2^n$ element vector to represent the state, where $n$ is just the number of particles. Nature doesn\'t need any extra time despite the exponential nature of "solving" this $n$-particle system.</p>\n\n<p>This may not be a wholly valid assumption, but the action principle in physics makes me think that nature always wants to do things the easiest way. If that\'s not true, then this question is probably moot.</p>\n\n<p>If we found that nature was NOT capable of solving some problems efficiently, does this mean we are doomed in terms of being able to solve NP problems in polynomial time? Are the laws of physics a strong enough weapon for tackling P vs. NP? Is the converse of the first question/assertion also true (if nature can do it, then there must be a way for us to as well)?</p>\n', 'ViewCount': '358', 'Title': "What is the relation between P vs. NP and Nature's ability to solve NP problems efficiently?", 'LastActivityDate': '2013-04-05T03:52:33.673', 'AnswerCount': '3', 'CommentCount': '5', 'AcceptedAnswerId': '11027', 'Score': '4', 'OwnerDisplayName': 'anon', 'PostTypeId': '1', 'Tags': '<complexity-theory><quantum-computing>', 'CreationDate': '2013-03-30T19:28:37.943', 'FavoriteCount': '2', 'Id': '11026'}{'Body': '<p>A simple question:</p>\n\n<p>What would be the complexity of finding whether a hampath of length $k$ exists in a graph with $n$ vertexes where $k &lt; n$?</p>\n\n<p>Would this be in NP-complete or just NP?</p>\n', 'ViewCount': '44', 'Title': 'complexity of finding the hampath of length $k$ in a graph with $n$ vertexes where $k < n$', 'LastActivityDate': '2013-04-05T03:35:16.630', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7585', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-04-05T01:05:09.547', 'Id': '11034'}{'Body': "<p>Prove if a oracle machine $K$ is given with $\\mathsf{P^k}=\\mathsf{NP}$ then $\\mathsf{NP}=\\mathsf{co\\text{-}NP}$.</p>\n\n<hr>\n\n<p>Lets assume that $\\mathsf{P^k}=\\mathsf{NP}$ then $\\mathsf{co\\text{-}P^k}=\\mathsf{co\\text{-}NP}$.  I am stuck here, I don't know how to prove this. Can someone help?</p>\n\n<p>I know that $\\mathsf{P}=\\mathsf{co\\text{-}P}$ but can I also say $\\mathsf{P^k}=\\mathsf{co\\text{-}P^k}$ or do I have to prove it ?</p>\n", 'ViewCount': '85', 'Title': 'Prove that if $\\mathsf{P^k}=\\mathsf{NP}$ then $\\mathsf{NP}=\\mathsf{co\\text{-}NP}$', 'LastEditorUserId': '472', 'LastActivityDate': '2013-04-06T04:17:56.190', 'LastEditDate': '2013-04-05T21:03:56.313', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '11071', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6672', 'Tags': '<complexity-theory><turing-machines><np>', 'CreationDate': '2013-04-05T20:59:08.920', 'Id': '11066'}{'ViewCount': '476', 'Title': 'Negligible Function in Cryptography', 'LastEditDate': '2013-04-06T12:01:29.477', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4799', 'FavoriteCount': '1', 'Body': '<p>In the field of Cryptography and Computation Complexity there is a notion of negligible function.</p>\n\n<p>I have some difficulties in understanding intuition behind this notion. The following are some definitions from Chapter 9. Cryptography from the textbook Computation Complexity. A modern approach by Arora and Barak with extensive use of negligible function. There my question after every definition about negligible function.</p>\n\n<blockquote>\n  <p>Before proceeding further, we make a simple definition that will greatly  simplify notation throughout this chapter.</p>\n  \n  <p><strong>Definition of negligible function</strong>. a function $\\epsilon : \\mathbb{N} \\rightarrow [0,1]$ is called negligible if $\\epsilon(n)=n^{-\\omega(1)}$. </p>\n  \n  <p>Because negligible functions tend to zero very fast as their input grows, events that happen with negligible probability can be safely ignored in most practical and theoretical settings.</p>\n</blockquote>\n\n<p>So far so good, it\'s just the definition of negligible function, the only point is why do we need to care about this function if it <em>"can be safely ignored".</em></p>\n\n<blockquote>\n  <p><strong>The notion of computational secure function</strong>.$k \\in_R \\{0,1\\}^n, x \\in_R \\{0,1\\}^m, Pr [A(E_k(x))=(i,b) s.t. x_i=b] \\leq \\frac{1}{2}+\\epsilon(n)$.</p>\n</blockquote>\n\n<p>Less intuitive usage of negligible function. As I understood, in general, $A$ can with probability 0.5 guess uniformly distributed $x_i$, therefore it makes sence to expected lower bound of success to be $\\leq \\frac{1}{2}$, however it\'s $\\leq \\frac{1}{2} + \\epsilon(n)$, it we can "safely ignore" $\\epsilon(n)$ why to mention it, and the second point is it possible to run $A$ some fixed finite number of times to get probability infinitely close to 1?</p>\n\n<blockquote>\n  <p><strong>Definition of one-way function</strong>. $x\\in_R\\{0,1\\}^n, y=f(x), Pr[A(y)=x\' s.t. f(x\')=y] &lt; \\epsilon(n)$</p>\n</blockquote>\n\n<p>In this case, the usage of negligible function is very intuitive, the success probability is upper bounded by negligible function $\\epsilon(n)$. I am not sure how it\'s correlated with existence of computationally secure encryption scheme (of course =0 is preferable by encryption scheme), however if $\\epsilon(n)$ can be safely ignored than it\'s ok.</p>\n\n<p>The problem is I am not quite understand why do we need negligible function. By mentioning few definition I tried to be more specific about what exactly I don\'t understand. </p>\n\n<p>I would appreciate if anyone can shed the light on the usage of negligible function</p>\n', 'Tags': '<complexity-theory><probability-theory><cryptography>', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-04-07T13:22:40.707', 'CommentCount': '0', 'AcceptedAnswerId': '11074', 'CreationDate': '2013-04-06T09:45:34.340', 'Id': '11073'}{'ViewCount': '115', 'Title': 'Why does a polynomial-time language have a polynomial-sized circuit?', 'LastEditDate': '2013-04-08T14:41:49.757', 'AnswerCount': '2', 'Score': '2', 'OwnerDisplayName': 'John Smith', 'PostTypeId': '1', 'OwnerUserId': '4631', 'Body': '<p>I wish to understand why P is a subset of PSCPACE, that is why a polynomial-time langauge does have a polynomial-sized circuit. I read many proofs like <a href="http://www.stanford.edu/~rrwill/week3.pdf" rel="nofollow">this one here on page 2-3</a>, but all the proofs use the same technique used in the Cook-Levin theorem to convert the computation of M on an n-bit input x to a polynomial sized circuit. </p>\n\n<p>What I don\'t understand is that the resulting circuit is dependent on the input x, because what is being converted into a circuit is the computation of M on the specific input x. By definition of PSIZE, the same circuit must work for all the inputs in a fixed length, and thus is not dependent on one specific input. </p>\n\n<p>So how is the process of creating a poly-sized circuit family for a poly-time deterministic Turing machine works exactly?</p>\n', 'Tags': '<complexity-theory><time-complexity><space-complexity><complexity-classes><polynomial-time>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:41:49.757', 'CommentCount': '1', 'AcceptedAnswerId': '11121', 'CreationDate': '2013-04-07T21:22:54.587', 'Id': '11117'}{'Body': '<p>I\'m a bit confused about the definition of BPP. The way BPP is defined in typical text books (Arora/Barak for example) is that if M(x) is a Probabilistic Turing Machine (PTM) that recognizes a language $L(x)$, then $Pr[M(x)=L(x)]&gt; 2/3$. My question is, what is the probability taken over? Arora/Barak remark (<a href="http://www.cs.princeton.edu/theory/complexity/bppchap.pdf" rel="nofollow">7.2</a>) that the probability is taken over internal coin tosses of $M(x)$, i.e., fix a value of $x$, and run all possible $2^{T(|x|)}$ experiments of internal coin tosses, and compute the majority of accept state. But if this is true, then Amplification theorem cannot hold because by definition if the probability is computed by executing all $2^{T(|x|)}$ possible coin-flips, then no matter how many times I run the algorithm, the probability is not going to change. (For example, if I have a bag with 2 red balls and 1 blue ball, then no matter how many times I pick a ball from the bag (and return it), the probability of picking a red ball is going to remain 2/3.)</p>\n\n<p>Basically, a PTM is a random process in two variables: The input string $x \\in \\{0,1\\}^*$ and random coin tosses $ r \\in \\{0,1\\}^{T(|x|)}$. For the amplification theorem to hold, I think one needs to fix a value of $r$ and run the machine on all values of $x$, and compute $Pr[M(x) = L(x)]$. Then for a fixed $x$, running $M(x)$ multiple times will have amplification effect, but if the probability is computed over internal coin tosses, then the Amplification theorem cannot hold.</p>\n\n<p>What am I misunderstanding here?</p>\n', 'ViewCount': '94', 'Title': 'Accurate definition of BPP', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:39:16.167', 'LastEditDate': '2013-04-08T14:39:16.167', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '3', 'OwnerDisplayName': 'MachPortMassenger', 'PostTypeId': '1', 'Tags': '<complexity-theory><terminology><complexity-classes><randomness>', 'CreationDate': '2013-04-07T03:51:38.153', 'FavoriteCount': '1', 'Id': '11119'}{'Body': u'<p>In the paper <a href="http://link.springer.com/content/pdf/10.1007/BF01300131">Complexity of the Frobenius Problem</a> by Ram\xedrez-Alfons\xedn, a problem was proved to be NP-complete using Turing reductions.\nIs that possible? How exactly? I thought this was only possible by a polynomial time many one reduction. Are there any references about this?</p>\n\n<p>Are there two different notions of NP-hardness, even NP-completeness? But then I am confused, because from a practical viewpoint, if I want to show that my problem is NP-hard, which do I use?</p>\n\n<p>They started the description as follows:</p>\n\n<blockquote>\n  <p>A  polynomial  time  Turing  reduction from  a problem $P_1$  to  another problem $P_2$  is  an  algorithm  A  which  solves  $P_1$  by  using  a  hypothetical  subroutine A\'  for  solving  $P_2$  such  that,  if  A\' were  a  polynomial  time  algorithm  for  $P_2$  then  A would  be  a  polynomial  time  algorithm  for  $P_1$.  We  say  that  $P_1$  can  be  Turing  reduced to  $P_2$. </p>\n  \n  <p>A  problem  $P_1$  is  called  (Turing)  NP-hard  if  there  is  an  NP-complete  decision \n  problem $P_2$  such  that  $P_2$  can  be  Turing  reduced  to  $P_1$.</p>\n</blockquote>\n\n<p>And then they use such a Turing reduction from an NP-complete problem to show NP-completeness of some other problem.</p>\n', 'ViewCount': '355', 'Title': 'Can one show NP-hardness by Turing reductions?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:48:09.817', 'LastEditDate': '2013-04-08T14:48:09.817', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '7309', 'Tags': '<complexity-theory><time-complexity><np-complete><reductions>', 'CreationDate': '2013-04-08T00:05:59.537', 'FavoriteCount': '1', 'Id': '11120'}{'ViewCount': '216', 'Title': 'Average length of s-t (simple) paths in a directed graph', 'LastEditDate': '2013-04-08T19:10:43.587', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '7644', 'FavoriteCount': '3', 'Body': '<p>Given the fact that $s$-$t$ path enumeration is a #P-complete problem, could there be efficient methods that compute (or at least approximate) the average length of $s$-$t$ path without enumerating them? <strike>What if paths are allowed to revisit vertices?</strike> </p>\n\n<p>Relevant results on special graphs could also be helpful.</p>\n', 'Tags': '<algorithms><complexity-theory><graphs><approximation><enumeration>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-10T04:41:12.817', 'CommentCount': '5', 'AcceptedAnswerId': '11184', 'CreationDate': '2013-04-08T18:28:42.923', 'Id': '11146'}{'Body': '<p>When Savitch\'s famous theorem is stated, one often sees the requirement that $S(n)$ be space constructible (interestingly, it is omitted in Wikipedia). My simple question is: Why do we need this? I understand the requirement for $S(n)$ being in $\\Omega(\\log n)$, which is clear from the proof. But no proof I have seen so far explicitly uses that $S(n)$ is space constructable.</p>\n\n<p>My explanation: in order to call the procedure REACH (or PATH or whatever you like to call it), the last parameter needs to be "spelled out", and in order not to leave our space bounds of S(n) for one call, we must not need more than $S(n)$ space to write it down. </p>\n', 'ViewCount': '106', 'Title': "Why is one often requiring space constructibility in Savitch's theorem?", 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-11T06:54:59.833', 'LastEditDate': '2013-04-10T13:33:01.197', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '11217', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<complexity-theory><space-complexity><complexity-classes><nondeterminism>', 'CreationDate': '2013-04-09T18:45:00.597', 'Id': '11168'}{'Body': "<p>I have to solve the following problem:</p>\n\n<blockquote>\n  <p>Consider the problem Connected:</p>\n  \n  <p><strong>Input:</strong> An unweighted, undirected graph $G$.</p>\n  \n  <p><strong>Output:</strong> True if and only if $G$ is connected.</p>\n  \n  <p>Show that Connected can be decided in polynomial time.</p>\n</blockquote>\n\n<p>I have been at this for hours, and I can't seem to find a way to prove this.\nAny hints?</p>\n", 'ViewCount': '384', 'Title': 'How to check whether a graph is connected in polynomial time?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-20T10:18:03.417', 'LastEditDate': '2013-04-10T08:49:17.583', 'AnswerCount': '3', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7643', 'Tags': '<algorithms><complexity-theory><graph-theory><polynomial-time>', 'CreationDate': '2013-04-10T00:08:01.310', 'Id': '11177'}{'Body': '<p>In computability and complexity theory (and maybe other fields), reductions are ubiquitous. There are many kinds, but the principle remains the same: show that one problem $L_1$ is at least as hard as some other problem $L_2$ by mapping instances from $L_2$ to solution-equivalent ones in $L_1$. Essentially, we show that any solver for $L_1$ can also solve $L_2$ if we allow it to use the reduction function as preprocessor.</p>\n\n<p>I have performed my share of reductions over the years, and something keeps bugging me. While every new reduction requires a (more or less) creative construction, the task can feel repetitive. Is there a pool of canonical methods?</p>\n\n<p>What are techniques, patterns and tricks one can regularly employ for constructing reduction functions?</p>\n\n<p><sup>This is supposed to become a <a href="http://meta.cs.stackexchange.com/questions/599/reference-questions">reference question</a>. Therefore, please take care to give general, didactically presented answers that are illustrated by at least one example but nonetheless cover many situations. Thanks!</sup></p>\n', 'ViewCount': '548', 'LastEditorDisplayName': 'user742', 'Title': 'What are common techniques for reducing problems to each other?', 'LastActivityDate': '2014-01-17T18:09:43.470', 'LastEditDate': '2013-05-15T10:15:37.360', 'AnswerCount': '4', 'CommentCount': '0', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><computability><reductions><proof-techniques><reference-question>', 'CreationDate': '2013-04-10T21:31:03.203', 'FavoriteCount': '10', 'Id': '11209'}{'Body': '<p>The Kolmogorov complexity of a string $x$ is the size of the smallest Turing machine $M$ that started on empty tape produces $x$. To make it computable, we can add a bound on the time used by $M$ to produce $x$: </p>\n\n<p>$C^{t}(x) = \\min \\{|M| : U(M) = x$ in less than $t(n)$ steps $ n = |x| \\}$ </p>\n\n<p>And for a nice function $f(n) &lt; n$ we can define:</p>\n\n<p>$C[f(n),t(n)] = \\{x : C^t(x) \\leq f(n), n = |x| \\}$</p>\n\n<p>i.e. the set of compressible strings $x$ (whose compressed program has size less than $f(n)$) and that can be generated in time $t(n)$.</p>\n\n<p>For example, for unbounded $f$, we have $C[f(n),n^k] \\subseteq C[f(n),n^{k+1}] \\subset C[f(n),\\infty]$</p>\n\n<blockquote>\n<ul><li>Is the first inclusion tight?</li>\n<li>What is known about the *size* of $C[f(n), n^{k+1}] \\setminus C[f(n), n^{k}]$ ?</li>\n<li>Are there known results for particular classes like $C[n/2,n^k]$?</li>\n</ul>\n</blockquote>\n', 'ViewCount': '51', 'Title': 'Interval density of time bounded Kolmogorov complexity', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-11T07:34:56.750', 'LastEditDate': '2013-04-11T07:34:56.750', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '140', 'Tags': '<complexity-theory><reference-request><descriptive-complexity><kolmogorov-complexity>', 'CreationDate': '2013-04-10T22:52:05.313', 'Id': '11214'}{'Body': '<p>I have a problem which I suspect is NP-complete. It is easy to prove that it is NP. My current train of thought revolves around using a reduction from knapsack but it would result in instances of 0-1-Knapsack with the value of every item being equal to its weight.</p>\n\n<p>Is this still NP-complete? Or am I missing something?</p>\n', 'ViewCount': '367', 'Title': 'Is the 0-1 Knapsack problem where value equals weight NP-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-14T10:40:18.413', 'LastEditDate': '2013-04-14T10:40:18.413', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11245', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7139', 'Tags': '<complexity-theory><np-complete><decision-problem><packing>', 'CreationDate': '2013-04-11T22:41:16.210', 'Id': '11243'}{'Body': '<p>In an exercise I have to show that minimizing a multivariate polynomial with $n$ variables over the hyper-cube $H = \\{ (x_1, \\ldots, x_n) : 0 \\leq x_i \\leq 1 \\}$ is NP-Hard. Formally, given $p(x_1, \\ldots, x_n)$ and $\\alpha$, does $\\min_{0 \\leq x_i \\leq 1} p(x_1, \\ldots, x_n) \\leq \\alpha$?</p>\n\n<p>My idea is to reduce it to MAX-SAT as follows. Suppose I am given the formula:</p>\n\n<p>$(x_1 \\vee \\overline{x_2} \\vee x_3) \\wedge (\\overline{x_1} \\vee \\overline{x_3}) \\wedge (\\overline{x_1} \\vee x_2 \\vee \\overline{x_3})$</p>\n\n<p>Then I consider:</p>\n\n<p>$p(y_1, y_2, y_3) = y_1 (1 - y_2) y_3 + (1 - y_1) (1 - y_3) + (1 - y_1) y_2 (1 - y_3)$</p>\n\n<p>If $p$ reaches a minimum at a corner of $H$ then the assignment:\n$$x_i = \\textit{true} \\ \\text{if} \\ y_i = 0 \\ \\text{and} \\ x_i = \\textit{false} \\ \\text{if} \\ y_i = 1$$\nis a solution for MAX-SAT value for the corresponding formula and since MAX-SAT is NP-Hard we are done. However, how do I proceed if $p$ reaches its minimum at an interior point? Or is it the case that it will always be a corner?</p>\n', 'ViewCount': '118', 'Title': 'Minimizing a multivariate polynomial over the hyper-cube is NP-Hard', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-12T03:01:45.210', 'LastEditDate': '2013-04-11T23:39:17.320', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'OwnerDisplayName': 'fran.aubry', 'PostTypeId': '1', 'OwnerUserId': '7697', 'Tags': '<complexity-theory><reductions><optimization><np-hard>', 'CreationDate': '2013-04-11T15:42:38.420', 'Id': '11246'}{'Body': '<p>So in what complexity class would all decision problems in that class can be transformed into a problem (by many-one reduction) that its solution only involves basic arithmetic operation of multiplication, division, addition and subtraction? </p>\n\n<p>So, like this: for every problem, there is input and output (we consider only those that halt) and my question is that is there any complexity class that all problems in the class can be transformed into a problem that involves only elementary arithmetic of the form of arithmetic function involving only arithmetic like $2^x+x^5/4-4x+2$ where $x$ is input coded as natural number.</p>\n', 'ViewCount': '92', 'Title': 'What complexity class decision problems can be solved by only addition, multiplication, division and subtraction?', 'LastEditorUserId': '7707', 'LastActivityDate': '2013-04-13T15:52:08.703', 'LastEditDate': '2013-04-13T00:52:09.240', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7707', 'Tags': '<complexity-theory>', 'CreationDate': '2013-04-12T17:01:02.027', 'Id': '11271'}{'Body': '<p>I have a little problem to understand the proof of the Time Hierarchy Theorem (Hennie and Stearns, 1966) that ensures the existence of a language acceptable in $U(n)$ but not acceptable in $T(n)$ for any functions $T(n),U(n)$, such that $U(n)$ is time-constructible and</p>\n\n<p>$$n \\leq T(n) = o\\left(\\frac{U(n)}{\\log T(n)}\\right).$$</p>\n\n<p>This proof is based on the existence of the Universal Turing machine simulating any Turing machine with time complexity $T(n)$ in time $T(n) \\log T(n)$.</p>\n\n<p>I understand (and believe) the proof that every $k$-tape Turing machine can be simulated by a two-tape Turing machine with a logarithmic overhead. However, I understand this construction only if the simulated Turing machine is fixed, not in the case of the Universal TM simulation.</p>\n\n<p>I see one "problem" in the reasoning given in the cited paper (and also in several standard books on computational complexity) related to the construction of the Universal machine. This "problem" is that in the Universal machine simulation, one computational step of a simulated machine is supposed to be executed in constant time by the Universal machine. In other words, the length of the description of the simulated machine is supposed to be constant.</p>\n\n<p>But is this OK? Since in the proof of the Time Hierarchy Theorem, the input given to the simulated Turing machine is exactly this description, and thus, the description is somehow dependent of $n$. I am aware of that the description can be lengthened by a sequence of leading bits, but this does not seem to solve this problem. </p>\n\n<p>That is, I cannot figure out why the computation step of a simulated machine can be supposed to be executed in a constant time by the Universal machine. The paper of Hennie and Stearns does not pay much attention to this, it merely states that this time is something that is implicitly assumed to be a constant. Similarly in the textbooks I have read on the topic.</p>\n\n<p>I simply cannot figure out why the time complexity of the simulation is $T(n)\\log T(n)$, and not $n T(n) \\log T(n)$.</p>\n\n<p>I am almost sure that I am missing something. However, I am trying to understand this for a relatively long time and somehow I cannot figure this out.</p>\n', 'ViewCount': '382', 'Title': 'Time Complexity of Universal Turing Machine Simulations and the Time Hierarchy Theorem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-14T10:35:19.797', 'LastEditDate': '2013-04-14T10:35:19.797', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11284', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2091', 'Tags': '<complexity-theory><turing-machines><simulation>', 'CreationDate': '2013-04-13T09:50:42.470', 'Id': '11280'}{'ViewCount': '226', 'Title': 'If A is poly-time reducible to B, is B poly-time reducible to A?', 'LastEditDate': '2013-04-14T11:11:21.183', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7715', 'FavoriteCount': '1', 'Body': '<p>Basically, is the following statement true?</p>\n\n<blockquote>\n  <p>$A \\leq_p B$ $\\rightarrow$ $B \\leq_p A$</p>\n</blockquote>\n', 'Tags': '<complexity-theory><reductions><polynomial-time>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-15T08:23:29.080', 'CommentCount': '3', 'AcceptedAnswerId': '11294', 'CreationDate': '2013-04-13T21:49:36.997', 'Id': '11292'}{'Body': '<p>There is the complexity class <a href="https://en.wikipedia.org/wiki/Elementary_recursive" rel="nofollow">ELEMENTARY</a> that captures all problems that can be solved by using elementary recursive function only. So if algorithms for solving problems in some complexity class (e.g. NP or P) are converted to elementary recursive function form, would they retain time complexity of the complexity class? </p>\n\n<p>For example, in complexity class P, we know that problems take deterministic polynomial time to solve. Would an elementary recursive form of a solving algorithm retain this complexity?</p>\n\n<p>By converting into elementary recursive form, I mean:</p>\n\n<p>Yes, it is true that NP is in elementary, that is there is an elementary recursive algorithm that can solve NP problems, but what I ask is "will such algorithm retain its time complexity?" For example, complexity P has problems that can be solved in polynomial time complexity; however, it is not clear whether it will retain polynomial time complexity if the algorithm has to be in elementary recursive form.</p>\n\n<p>By my understanding, elementary recursive algorithm would be the one that does not necessarily use "if and else".</p>\n\n<p>Modification to the question: Let us say that for all decision problems we consider, there exist function problems that have same time complexity as their decision problem counterparts. For example, for 3-SAT problem with some input $x$, one satisfying assignment to the variables is treated as output. The reason why some people think this question is not valuable may be because for all decision problems, output is always either zero or one. So let us consider the function version of decision problems (that keeps time complexity).</p>\n', 'ViewCount': '122', 'ClosedDate': '2013-04-20T20:27:22.187', 'Title': 'Does converting algorithms into elementary recursive form preserve runtime bounds?', 'LastEditorUserId': '7743', 'LastActivityDate': '2013-04-18T08:30:59.960', 'LastEditDate': '2013-04-16T15:12:54.647', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7720', 'Tags': '<complexity-theory><time-complexity><arithmetic>', 'CreationDate': '2013-04-14T06:57:39.190', 'Id': '11302'}{'ViewCount': '211', 'Title': 'Is Hidoku NP complete?', 'LastEditDate': '2013-05-06T22:36:24.267', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '7549', 'FavoriteCount': '2', 'Body': u'<p>A Hidoku is a $n \\times n$ grid with some pre-filled integers from 1 to $n^2$. The goal is to find a path of successive integers (from 1 to $n^2$) in the grid. More concrete, each cell of the grid must contain a different integer from 1 to $n^2$ and each cell with value $z \u2260 n^{2}$ must have a neighbor cell with value $z + 1$ (can also be diagonally).</p>\n\n<p>Is it NP hard to decide whether a given Hidoku is solvable? What reduction could be used?</p>\n\n<p>Edit: according to the comments, I give a little clarification. Given is a grid of cells, some of them already contain values (integers from 1 to n\xb2). We must fill all remaining cells with integers from 1 to $n^2$, such that no two cells have the same value and that every cell with value $z \u2260 n\xb2$ has a neighbor with value $z + 1$. That is, after filling out the cells, we must find the path $1, 2, 3,\\cdots, n^2$. In the grid, which logically visits each cell.</p>\n\n<p>An example of a Hidoku woud be <a href="http://www.janko.at/Raetsel/Hidoku/018.c.gif" rel="nofollow">http://www.janko.at/Raetsel/Hidoku/018.c.gif</a>.\nAn already solved Hidoku is <a href="http://diepresse.com/images/uploads/3/f/7/586743/spectrumsommerraetsel_7august_hidoku_schwer_loesung20100810172340.gif" rel="nofollow">http://diepresse.com/images/uploads/3/f/7/586743/spectrumsommerraetsel_7august_hidoku_schwer_loesung20100810172340.gif</a>, where you can see the path I was refering to.</p>\n', 'Tags': '<complexity-theory><reductions><np-hard>', 'LastEditorUserId': '7492', 'LastActivityDate': '2013-05-06T22:36:24.267', 'CommentCount': '8', 'AcceptedAnswerId': '11336', 'CreationDate': '2013-04-15T12:51:57.417', 'Id': '11330'}{'Body': '<p>I have difficulties in understanding the notion of density for distribution.</p>\n\n<p><strong>Notion of density for distribution</strong>. A distribution $H$ over $\\{0,1\\}^n$ has density $\\sigma$ if for every $x \\in \\{0,1\\}^{n}$, $Pr[H=x] \\leq \\frac{1}{2^n\\sigma}$.</p>\n\n<p>The following is my desperate tries to understand the notion.\nif $H$ is uniform distribution over $\\{0,1\\}^n$ then  for every $x \\in \\{0,1\\}^n$, $Pr[H=x]=\\frac{1}{2^n}$.</p>\n\n<p>if a distribution $H$ has density $\\sigma = 1$ then $P[H=x]\\leq\\frac{1}{2^n}$, so distribution $H$ is upper bounded by the uniform distribution.</p>\n\n<p>if a distribution $H$ has density $\\sigma = \\frac{1}{2}$ then $P[H=x]\\leq\\frac{1}{2^{n-1}}$, so distribution $H$ is upper bounded by the uniform distribution over $\\{0,1\\}^{n-1}$.</p>\n\n<p>if a a distribution $H$ has density $\\sigma = \\frac{1}{2^n}$ then $P[H=x]\\leq 1$.</p>\n\n<p>So density $\\sigma$ might determine the part of distribution over $2^n$ where the actual "probabilistic weight" should be placed? However it\'s always upper bounded, therefore we can always say something about the upper bound?</p>\n\n<p>As you see I don\'t have intuition behind this notion and I would appreciate any help.</p>\n', 'ViewCount': '42', 'Title': 'The notion of density of distribution', 'LastEditorUserId': '1379', 'LastActivityDate': '2013-04-17T09:22:50.767', 'LastEditDate': '2013-04-17T06:58:12.263', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '11363', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><probability-theory>', 'CreationDate': '2013-04-16T13:38:56.990', 'Id': '11354'}{'Body': '<p>I encountered the following optimization problem. Let $ S = \\lbrace 1, 2, \\ldots, n \\rbrace $ be a set of items. Each item $ i \\in S $ has a non-negative benefit $ b_i \\in \\mathbb R^+ $, non-negative weight $ w_i \\in \\mathbb R^+ $ and a non-negative cost $ c_i \\in R^+ $. The objective is to select $ A \\subseteq S $ that maximizes the function $ \\frac{\\sum_{i \\in A} b_i w_i}{\\sum_{i \\in A} w_i} - \\frac{\\sum_{i \\in A} c_i \\sqrt{w_i} }{\\sqrt{\\sum_{i \\in A} w_i}} $. In addition, there is an optional cardinality contraint $ |A| \\leq K $ for a given $ K \\in \\mathbb Z^+ $.</p>\n\n<p>The problem can be viewed as a fractional combinatorial optimization problem. However the difficulty stems from the second term where the denominator is not linear.</p>\n\n<ol>\n<li>If the second term is omitted, the problem becomes solvable in polynomial time (Hansen et al.,  1991). </li>\n<li>If the second term had instead a linear denominator which is different from the denominator of the first term, the problem becomes NP-hard (Prokopyev et al., 2004)</li>\n</ol>\n\n<p>The problem can also be viewed as a set function optimization problem. When the set function $F$ is submodular (i.e. $ F(A) + F(B) &gt;= F(A \\cup B) + F(A \\cap B), \\forall A, B \\subseteq S $), maximization is NP-hard. </p>\n\n<p>The objective function exhibits submodularity for some values of $b_i$, $w_i$, $c_i$ but not for all cases.</p>\n\n<p>Are there problems with similar objective functions? Is the problem solvable in polynomial time or NP-hard?</p>\n\n<p>The decision version of the problem can be stated as: is there $ A \\subseteq S $ such that $ \\frac{\\sum_{i \\in A} b_i w_i}{\\sum_{i \\in A} w_i} - \\frac{\\sum_{i \\in A} c_i \\sqrt{w_i} }{\\sqrt{\\sum_{i \\in A} w_i}} \\geq M $ for some $ M $?</p>\n', 'ViewCount': '60', 'Title': 'Complexity of Set Optimization with Sum of Rational Functions Objective', 'LastActivityDate': '2013-04-16T14:39:01.653', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7751', 'Tags': '<complexity-theory>', 'CreationDate': '2013-04-16T14:39:01.653', 'Id': '11355'}{'Body': '<p>I try to get the intuition behind the notion of <em>strong one way function</em> and <em>weak one way function</em> by reading the scribe <a href="http://www.cs.cornell.edu/courses/cs6830/2011fa/scribes/lecture3.pdf" rel="nofollow">One-Way Functions</a>. Particularly, I am interested in examples and definitions of the weak and strong one way function. I known it\'s very broad notion, therefore I will be as specific as possible in my questions.</p>\n\n<p><strong>Strong one way function</strong>. $\\forall$ nonuniform PPT $A$, $\\exists \\epsilon s.t. \\forall n \\in N, Pr_{x\\in\\{0,1\\}^n}[A(1^n, f(x)) \\in f^{-1}(f(x))] \\leq \\epsilon(n)$</p>\n\n<blockquote>\n  <p>Q:$1^n$ as the first parameter of the PPT $A$ represent the length of the initial input, the usage of it is justified as <em>"this ensures that the output of A doesn\'t shrink the size if its too must as in the f(x)=|x| example".</em> Unfortunately I didn\'t get the previous explanation (may be because the lost the sign, which takes an additional bit). In my opinion putting in A the size of $x$ might help $A$ get the right output $x$.</p>\n  \n  <p>Q: in the lecture it mentioned that $f(x)=|x|$ is hard, <em>"because it will take $2^c$ time to write a valid inverse of something such that $f(x)=c$"</em>. It happens because we cannot find $x$ with probability with negligible more than 0.5,  but it\'s due to another problem not a computational but rather information theory problem, by running the function we lost the information about the sign of the input $x$, if it\'s a correct reasoning, why actually it would take $2^c$ time?  In addition for  me it looks like the great discover to find the strong one way function, however do have more assumption of hard function like $f(x)=|x|$?</p>\n</blockquote>\n\n<p><strong>Definition of weak one way function</strong>.$\\exists$ $q(x)$, $\\forall$ nonunoform PPT A, $\\forall$ n $\\in$ N,\n$Pr_{x \\in \\{0,1\\}^n}[A(1^n,f(x)) \\in f^{-1}(f(x))] \\leq 1-\\frac{1}{q(n)}$</p>\n\n<blockquote>\n  <p>Q: in the lecture there was an assumption that the multiplication is weak one function, how we can actually show that the multiplication is weak one way function, and do we have more assumptions of examples of weak one way functions?</p>\n</blockquote>\n\n<p>I am very sorry for being naive, even though I will appreciate any help.</p>\n', 'ViewCount': '87', 'Title': 'Assumptions of One Way Functions', 'LastEditorUserId': '157', 'LastActivityDate': '2013-05-18T07:11:24.310', 'LastEditDate': '2013-04-18T06:04:27.470', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory><cryptography><one-way-functions>', 'CreationDate': '2013-04-17T19:40:32.080', 'Id': '11369'}{'Body': u'<p>In a directed graph, the indegree of a node is the number of incoming edges and\nthe outdegree is the number of outgoing edges. Show that the following problem\nis NP-complete. Given an undirected graph G and a designated subset C of G\u2019s\nnodes, is it possible to convert G to a directed graph by assigning directions to each\nof its edges so that every node in C has indegree 0 or outdegree 0, and every other\nnode in G has indegree at least 1?</p>\n\n<p>I need an idea how to prove it</p>\n', 'ViewCount': '339', 'Title': 'Can the edges of a graph be assigned directions such that all nodes in a given subset have in- or outdegree 0, and every other node indegree > 0?', 'LastEditorUserId': '917', 'LastActivityDate': '2013-10-08T10:57:13.280', 'LastEditDate': '2013-10-08T10:57:13.280', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7783', 'Tags': '<complexity-theory><graph-theory><np-complete><np-hard>', 'CreationDate': '2013-04-19T06:22:19.890', 'FavoriteCount': '1', 'Id': '11398'}{'Body': "<p>I'm looking for a good book that explains these subjects in a readable way.\nAny suggestions ?</p>\n\n<p>I currently pursuing my BSC in computer science, and I just failed to pass the course introduction to thr theory of computation and complexity.\nI would like to have more reference and sources of knowledge so I can understand the subject better. Examples and solutions for various problems like proving undecidability, many to one reductions, etc can help me alot.</p>\n", 'ViewCount': '214', 'Title': 'Introduction to complexity and computability', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T14:20:11.200', 'LastEditDate': '2013-04-21T14:20:11.200', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5187', 'Tags': '<complexity-theory><computability><reference-request><books>', 'CreationDate': '2013-04-19T06:54:25.990', 'FavoriteCount': '1', 'Id': '11399'}{'Body': "<blockquote>\n  <p>Meeting rooms on university campuses may or may not contain coffee machines. We would\n  like to ensure that every meeting room either has a coffee machine or is close enough to a\n  meeting room that does have a coffee machine. (For any two meeting rooms, the architect\n  has told us whether or not they are close enough.) Our problem is to determine among all the\n  meeting rooms of any university campus, which ones should have coffee machines so that we\n  use as few coffee machines as possible. Specify this problem as an optimization problem on a\n  graph. Formulate the corresponding Coffee-machine Decision Problem (abbreviated Coffee).\n  Prove that the Coffee Machine Decision Problem is NP-complete.</p>\n  \n  <p>Hint: You could use Vertex Cover. For every edge, add two more edges and one more vertex.</p>\n</blockquote>\n\n<p>I'm confused at the hint given and why this problem isn't just a straight reduction from Vertex Cover.  What's the point of adding two more edges and a vertex for every edge?</p>\n", 'ViewCount': '126', 'Title': 'How does the problem of having a coffee-machine close relate to vertex cover?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T15:23:25.990', 'LastEditDate': '2013-04-21T15:23:25.990', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7787', 'Tags': '<complexity-theory><np-complete><reductions><decision-problem>', 'CreationDate': '2013-04-19T09:11:08.353', 'Id': '11402'}{'Body': '<p>A set is sparse if it contains polynomially bounded number of strings of any given string length $n$ otherwise it is dense. All known NP-complete sets are dense. It was proven that P=NP if and only if there is a sparse NP-complete set (under Karp reduction).</p>\n\n<p>I would like to find the density of uniquely satisfiable 3SAT formulas. Is it super-polynomially dense or exponentially dense? What is known about the asymptotic lower bound on the number of 3SAT formulas with unique solutions?</p>\n', 'ViewCount': '84', 'Title': 'Asymptotic bounds on number of 3SAT formulas with unique solutions', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-01T23:30:50.850', 'LastEditDate': '2013-04-21T14:12:11.020', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11745', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><reference-request><np-complete><satisfiability>', 'CreationDate': '2013-04-19T12:56:38.680', 'Id': '11408'}{'ViewCount': '98', 'Title': 'Time Complexity of a selection problem', 'LastEditDate': '2013-04-21T14:42:44.753', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2449', 'FavoriteCount': '1', 'Body': "<p>I wonder what's the time complexity of the following selection problem I found while thinking of a string-matching problem.</p>\n\n<p>[Assuming operations on integers take $O(1)$ time]</p>\n\n<p>We are Given $m$ sets, with $n$ integer numbers each. We want to select exactly one integer from each set, to make a set S, such that $~ l = \\max(S) - \\min(S)~$ is minimized.</p>\n\n<p>For example, n = 4, m = 3:</p>\n\n<p>$S_1 = \\{1, 43, 71, 101\\}$</p>\n\n<p>$S_2 = \\{18, 53, 80, 107\\}$</p>\n\n<p>$S_3 = \\{3, 16, 51, 208\\}$</p>\n\n<p>Now</p>\n\n<p>$~S = \\{43, 53, 51\\}$</p>\n\n<p>has one number from each set and </p>\n\n<p>$~l = \\max(S) - \\min(S) = 53 - 43 = 10 ~$ </p>\n\n<p>wich is the minimum possible value of $l$ (I think).</p>\n\n<p>First thing I tried was a reduction to the set cover problem, but I wasn't able to find one.</p>\n", 'Tags': '<complexity-theory><time-complexity><set-cover>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T14:42:44.753', 'CommentCount': '0', 'AcceptedAnswerId': '11430', 'CreationDate': '2013-04-20T12:51:15.197', 'Id': '11424'}{'Body': "<p>Let's say I have a decision problem  $P$ on graphs for which I know that it is NP-hard on graphs with maximum degree $d$. Does this then imply that it is NP-hard on $d$-regular graphs? Although it might seem obviously true, maybe it is inherent in the reduction to show that $P$ is hard, that some vertices have degree less than $d$.</p>\n", 'ViewCount': '71', 'Title': 'NP hardness through Restriction', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T14:43:50.053', 'LastEditDate': '2013-04-21T14:43:50.053', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '11456', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7816', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2013-04-21T02:47:17.720', 'Id': '11453'}{'ViewCount': '66', 'Title': 'Prove NP-completeness of deciding whether there is an edge-tour of at most a given length', 'LastEditDate': '2013-04-21T15:43:16.887', 'AnswerCount': '1', 'Score': '1', 'OwnerDisplayName': 'Mariska', 'PostTypeId': '1', 'OwnerUserId': '7799', 'Body': "<p>We are given a graph G, integer b &lt; |E|, and subset F in E. The problem is to detect whether there is a cycle in the graph with length at most b and includes each edge in F. Prove that this is NP Complete. </p>\n\n<p>I'm thinking of reducing from Hamiltonian Path, but still can't think of the appropriate transformation function. </p>\n", 'Tags': '<complexity-theory><np-complete><reductions>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T15:43:16.887', 'CommentCount': '1', 'AcceptedAnswerId': '11464', 'CreationDate': '2013-04-21T13:16:30.233', 'Id': '11463'}{'Body': '<p>As I understand, the <a href="http://en.wikipedia.org/wiki/Assignment_problem" rel="nofollow">assignment problem</a> is in P as the Hungarian algorithm can solve it in polynomial time - O(n<sup>3</sup>). I also understand that the assignment problem is an <a href="http://en.wikipedia.org/wiki/Integer_programming" rel="nofollow">integer linear programming</a> problem, but the Wikipedia page states that this is NP-Hard. To me, this implies the assignment problem is in NP-Hard.</p>\n\n<p>But surely the assignment problem can\'t be in both P and NP-Hard, otherwise P would equal NP? Does the Wikipedia page simply mean that the general algorithm for solving all ILP problems is NP-Hard? A few other sources state that ILP is NP-Hard so this is really confusing my understanding of complexity classes in general.</p>\n', 'ViewCount': '1180', 'Title': 'Are all Integer Linear Programming problems NP-Hard?', 'LastActivityDate': '2013-07-22T11:05:12.550', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '11476', 'Score': '2', 'OwnerDisplayName': 'Matt', 'PostTypeId': '1', 'OwnerUserId': '1554', 'Tags': '<complexity-theory><complexity-classes><linear-programming><integer-programming>', 'CreationDate': '2013-04-21T19:27:20.410', 'Id': '11475'}{'Body': '<p>Can you help me with this problem ?</p>\n\n<blockquote>\n  <p>Given an undirected graph $G$ and an integer $n$, prove that determining whether the graph has wheel on $n$ vertices $W_{n}$ (a wheel $W_{i}$ is such that $i$ nodes form a cycle and a $i+1$st node is connected to all other nodes, resulting in $2i$ edges) is NP-complete.</p>\n</blockquote>\n', 'ViewCount': '187', 'Title': 'Proving that finding wheel subgraphs is NP-complete', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-24T06:56:08.333', 'LastEditDate': '2013-04-24T06:50:24.760', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '11508', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7336', 'Tags': '<complexity-theory><graphs><np-complete>', 'CreationDate': '2013-04-23T01:42:26.310', 'Id': '11505'}{'Body': "<p>For the following question:</p>\n\n<p>If B is an element of PSPACE and A is an element of PSPACE-Complete, and A polynomial reduces to B, then B is an element of PSPACE-Complete.</p>\n\n<p>I am trying to prove this, but I don't understand how to get started. Can anyone help please?</p>\n", 'ViewCount': '45', 'Title': 'Showing transitivity of PSPACE?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-23T09:10:18.867', 'LastEditDate': '2013-04-23T09:10:18.867', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7168', 'Tags': '<complexity-theory><reductions><proof-techniques><space-complexity>', 'CreationDate': '2013-04-23T02:15:09.323', 'Id': '11506'}{'ViewCount': '248', 'Title': 'Does our PC work as Turing Machine?', 'LastEditDate': '2013-04-23T12:28:36.693', 'AnswerCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7384', 'FavoriteCount': '2', 'Body': u'<p>Does our PC work as Turing Machine?  The model of a Turing Machine consists of infinite memory tape, which means infinite states. But suppose if our PC has 128 MB memory and 30GB disk it would have 256^30128000000 states and thus, it has finite states.</p>\n\n<p>I know that we can write a type of program that, if during execution we run out of memory, will request to swap memory disk with empty memory disk and resume execution.</p>\n\n<p><strong>But what if we don\u2019t swap memory disk, in this case is it right to consider PC as FA</strong>?  </p>\n', 'Tags': '<complexity-theory><computability><turing-machines><automata>', 'LastEditorUserId': '1861', 'LastActivityDate': '2013-04-23T15:53:04.873', 'CommentCount': '1', 'AcceptedAnswerId': '11516', 'CreationDate': '2013-04-23T11:46:49.043', 'Id': '11514'}{'Body': "<p>I have a question, i was trying to reduce 3-SAT to a particular graph problem and i'm not quite sure about a thing i used in the reduction.\nIn fact the reduction build a bipartite graph, the edge $(x_1,c_1)$ exist if the variable $x_1$ is in the clause number 1, the costs on that edge are dependent on the truthfulness of the variable $x_1$, cost 1 if $x_1$ is true and 0 elsewhere. My question :is it permitted in a reduction or should i have the entire graph instance independent from values taken by the variables ?</p>\n\n<p>Thank you all!</p>\n", 'ViewCount': '110', 'Title': 'Reduction from 3-SAT to a graphe problem', 'LastEditorUserId': '7934', 'LastActivityDate': '2013-04-28T00:16:23.053', 'LastEditDate': '2013-04-28T00:16:23.053', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '11544', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7880', 'Tags': '<complexity-theory><graphs><np-complete><reductions><3-sat>', 'CreationDate': '2013-04-24T22:56:55.940', 'Id': '11541'}{'ViewCount': '451', 'Title': 'Prove NP-completeness of deciding satisfiability of monotone boolean formula', 'LastEditDate': '2013-04-26T09:54:06.637', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7901', 'FavoriteCount': '1', 'Body': "<p>I am trying to solve this problem and I am really struggling.</p>\n\n<p>A <em>monotone boolean formula</em> is a formula in propositional logic where all the literals are positive. For example, </p>\n\n<p>$\\qquad (x_1 \\lor x_2) \\land (x_1 \\lor x_3) \\land (x_3 \\lor x_4 \\lor x_5)$ </p>\n\n<p>is a monotone boolean function. On the other hand, something like</p>\n\n<p>$\\qquad (x_1 \\lor x_2 \\lor x_3) \\land (\\neg x_1 \\lor x_3) \\land (\\neg x_1 \\lor x_5)$ </p>\n\n<p>is not a monotone boolean function.</p>\n\n<p>How can I prove NP-completeness for this problem: </p>\n\n<blockquote>\n  <p>Determine whether a monotone boolean function is satisfiable if $k$ variables or fewer are set to $1$? </p>\n</blockquote>\n\n<p>Clearly, all the variables could just be set to be positive, and that's trivial, so that is why there is the restraint of $k$ positively set variables.</p>\n\n<p>I have tried a reduction from SAT to monotone boolean formula. One thing I have tried is to substitute a dummy variable in for every negative literal. For example, I tried replacing $\\neg x_1$ with $z_1$, and then I tried forcing $x_1$ and $z_1$ to be different values. I haven't quite been able to get this to work though.</p>\n", 'Tags': '<complexity-theory><np-complete><satisfiability>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-26T09:54:06.637', 'CommentCount': '1', 'AcceptedAnswerId': '11559', 'CreationDate': '2013-04-25T23:58:57.687', 'Id': '11558'}{'Body': '<p>Suppose you are given a polynomial-time algorithm for the following problem related to INDEPENDENT SET:</p>\n\n<p>INDEPENDENT SET VALUE</p>\n\n<p>Input: An undirected graph G.</p>\n\n<p>Output:The size of the largest independent set in G (but not the set itself).</p>\n\n<p>Show how you can use this algorithm to solve the INDEPENDENT SET problem in polynomial time: given a graph G, return an independent set which is as large as possible.</p>\n\n<p>Any help would be really appreciated. I am pretty lost in this question</p>\n', 'ViewCount': '132', 'Title': 'How to reduce INDEPENDENT SET to INDEPENDENT SET SIZE?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-26T09:48:23.050', 'LastEditDate': '2013-04-26T09:48:23.050', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7909', 'Tags': '<complexity-theory><graph-theory><np-complete><reductions>', 'CreationDate': '2013-04-26T08:16:10.927', 'FavoriteCount': '1', 'Id': '11570'}{'Body': u'<p>Famous PPAD class of problems is  formally defined by specifying one of its complete problems, known as <a href="http://en.wikipedia.org/wiki/PPAD_%28complexity%29" rel="nofollow">End-Of-The-Line</a>:</p>\n\n<p><strong>End-Of-The-Line Problem:</strong>\n$G$ is a (possibly exponentially large) directed graph with no isolated vertices, and with every vertex having at most one predecessor and one successor. $G$ is specified  by giving a polynomial-time computable function $f(v)$ (polynomial in the size of $v$) that returns the predecessor and successor (if they exist) of the vertex $v$. Given a vertex $s$ in $G$ with no predecessor, find a vertex $t\u2260s$ with no predecessor or no successor. (The input to the problem is the source vertex s and the function $f(v)$). In other words, we want any source or sink of the directed graph other than $s$.</p>\n\n<p>Let\'s consider the slightly augmented version of End-Of-The-Line problem.</p>\n\n<p><strong>End-Of-The-Line Augmented Problem:</strong> The definition is same as for End-Of-The-Line expect that it\'s required to find not a vertex $t\u2260s$ with no predecessor or no successor, but the exact end of the path of the given source vertex $s$.</p>\n\n<p>Intuitively, it seems like <strong>End-Of-The-Line Augmented Problem</strong> is not more in PPAD, just because it requires something more stronger than <strong>End-Of-The-Line Problem</strong>. How to show that <strong>End-Of-The-Line Augmented Problem</strong> is NP-hard?</p>\n', 'ViewCount': '49', 'Title': 'End-Of-The-Line Augmented Problem of PPAD', 'LastEditorUserId': '4778', 'LastActivityDate': '2013-04-28T05:38:26.623', 'LastEditDate': '2013-04-28T05:38:26.623', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4778', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-04-27T15:20:01.477', 'Id': '11604'}{'Body': '<p>I was looking over <a href="http://stackoverflow.com/q/352203/2327689">this question</a> requesting an algorithm to generate all permutations of a given string. A comment in the answer caught my eye:</p>\n\n<p><em>It might seem that it can take O(n) time per permutation, but if you think about it more carefully, you can prove that it takes only O(n log n) time for all permutations in total, so only O(1) -- constant time -- per permutation.</em></p>\n\n<p>This seemed strange to me because the best method I was aware of to generate all permutations of a string is in O(2^n) time. Looking through the other results, I came across a <a href="http://stackoverflow.com/a/7140205/2327689">response to a similar question</a> which states: <em>While it technically produces the desired output, you\'re solving something that could be O(n lg n) in O(n^n)</em></p>\n\n<p>I am aware of an algorithm to unrank permutations in O(n log n) time, but these responses seem to imply that all permutations in total can be generated in time O(n log n). Am I misunderstanding these responses?</p>\n', 'ViewCount': '1009', 'Title': 'Can all permutations of a set or string be generated in O(n log n) time?', 'LastActivityDate': '2013-04-28T05:47:47.137', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '11626', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7938', 'Tags': '<algorithms><complexity-theory><time-complexity>', 'CreationDate': '2013-04-27T20:47:12.143', 'Id': '11611'}{'Body': '<p>Is there any way to find out how to replace for/if for elementary recursive algorithms? I know that primitive recursive functions cannot basically eliminate "for", but for elementary recursive functions, there must be a way to convert the program into ones that do not have for/if/while and so on (which is elementary recursive).</p>\n', 'ViewCount': '76', 'Title': "How to eliminate for/if/while from algorithms when it's possible", 'LastActivityDate': '2013-04-28T01:40:46.220', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7941', 'Tags': '<complexity-theory><computability><programming-languages>', 'CreationDate': '2013-04-28T01:40:46.220', 'FavoriteCount': '1', 'Id': '11618'}{'Body': '<p>How do I show that TQBF $\\notin$ SPACE$((\\log{n})^4)$?  I know that TQBF is PSPACE complete, but is this the right approach?</p>\n', 'ViewCount': '171', 'Title': 'Show that TQBF $\\notin$ SPACE$((\\log{n})^4)$?', 'LastActivityDate': '2013-04-29T03:53:45.987', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7220', 'Tags': '<complexity-theory>', 'CreationDate': '2013-04-29T02:21:06.957', 'Id': '11648'}{'Body': '<p>I need to determine which complexity class this problem belongs to:</p>\n\n<blockquote>\n  <p>Given a graph $G(V, E)$, two vertices $u$ and $v$ and a natural number $k$, does a path of length $k$ exist between thesee two vertices?</p>\n</blockquote>\n\n<p>How can I approach this problem to solve it?</p>\n', 'ViewCount': '131', 'Title': 'k-path problem - P, NP or NPC?', 'LastEditorUserId': '903', 'LastActivityDate': '2013-05-31T17:08:03.723', 'LastEditDate': '2013-05-01T01:25:11.237', 'AnswerCount': '3', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7981', 'Tags': '<complexity-theory><graph-theory><np-complete><np>', 'CreationDate': '2013-04-30T18:55:29.343', 'Id': '11680'}{'Body': "<p>I was working on proving this one and I've solve one direction as follows :<br>\nto prove that $P \\subseteq PCP(0,logn)$ I said :<br>\nlet $M$ be deterministic polynomial TM that accepts $L \\in P$ ,we want to show that we can there exists a proof system which consists of prover and deterministic polynomial verifier that have access to an oracle and make at most $O(log(n))$ queries and $\\forall x \\in L$ $\\exists \\pi _x $suchthat the verifier always(i.e. probability =1) accepts and $\\forall x \\notin L$ always reject what ever the proof was.<br>\nthe prover and the verifier will be the machine $M$ (since no randomness required) and $\\pi _x$ will be: run M and obtain solution denoted by : $ANS$ send it to the verifier then the verifier checks if $ANS$ is the same and rejects or accepts accordingly ... this proves that: $P \\subseteq PCP(0,O(1)) \\subseteq PCP(0,O(log(n)) $ </p>\n", 'ViewCount': '135', 'Title': 'proving $P \\subseteq PCP(0,O(log(n))$', 'LastActivityDate': '2013-05-01T20:31:12.117', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '11691', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Tags': '<complexity-theory><approximation>', 'CreationDate': '2013-05-01T00:18:29.293', 'Id': '11683'}{'ViewCount': '106', 'Title': 'Is linear-time reduction symmetric?', 'LastEditDate': '2013-05-01T10:12:30.693', 'AnswerCount': '1', 'Score': '2', 'OwnerDisplayName': 'Bruce', 'PostTypeId': '1', 'OwnerUserId': '7984', 'Body': '<p>By reduction I mean the following:</p>\n\n<blockquote>\n  <p>Problem X linear reduces to problem Y if X can be solved with:<br>\n  a) Linear number of standard computational steps.<br>\n  b) Constant calls to subroutine for Y.  </p>\n</blockquote>\n\n<p>If a problem X reduces to a problem Y, is the opposite reduction also possible? Say</p>\n\n<p>X = Given an array tell if all elements are distinct<br>\nY = Sort an array using comparison sort  </p>\n\n<p>Now, X reduces to Y in linear time i.e. if I can solve Y, I can solve X in linear time. Is the reverse always true? Can I solve Y, given I can solve X? If so, how?</p>\n', 'Tags': '<complexity-theory><reductions>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-05-01T10:12:30.693', 'CommentCount': '0', 'AcceptedAnswerId': '11688', 'CreationDate': '2013-04-30T20:30:10.923', 'Id': '11687'}{'Body': "<p>I know that the CVAL problem is P-complete.\nIn the CVAL problem the input is a Boolean circuit together with an input to this circuit, and the answer is the evaluation of the given circuit on the given input.</p>\n\n<p>I wish to know if the problem of evaluating a Boolean formula on a given assignment is also P-complete. From one hand, it seems that a Boolean circuit and a Boolean formula are very similar objects. Also, the proof of that CVAL is P-complete results from the Cook-Levin problem, the same theorem that actually shows that SAT is NP-Complete, so I don't see a reason why this problem won't be P-Complete.\nFrom the other hand, it seems pretty easy to evaluate a Boolean formula in logarithmic space, so if this problem is indeed P-complete I think it would imply L = P which is unknown. </p>\n\n<p>So I think I'm missing something.. any ideas people? </p>\n", 'ViewCount': '89', 'Title': 'Is the problem of evaluating a boolean formula on a given assignment P-complete?', 'LastActivityDate': '2013-05-01T17:23:20.530', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '11705', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4631', 'Tags': '<complexity-theory><time-complexity><complexity-classes>', 'CreationDate': '2013-05-01T15:23:31.873', 'Id': '11697'}{'Body': '<p>I use the following scribe to study  <a href="http://people.seas.harvard.edu/~salil/pseudorandomness/prgs.pdf" rel="nofollow">Pseudorandom Generators</a>.</p>\n\n<p>The most intriguing question for me is how exactly PRG can be used in order to simulate BPP.</p>\n\n<p>Let $A(x,r) \\in BPP$, where $x$ is primary input and $r$ - randomness provided by BPP. Instead of $r$ we can provide $A$ with pseudorandom input $G(U_{d(n^c)})$ and according to the <strong>Claim 7.6</strong> from the scribe. $A$ with pseudorandom input differs from $A$ with random $r$ in less than half of running cases. The proof of Lemma shows that if it\'s so, that there is a distinguisher that distinguishes $U_{d(n^c)}$ from $U_{n^c}$ with advantage at least $\\frac{1}{2} - \\frac{1}{3} &gt; \\frac{1}{8}$ which is contradicts to the definition of PRG.</p>\n\n<p>Q: Where this advantage comes from? I simply don\'t understand what these numbers mean.</p>\n\n<p>Q: Construction question. Why do need to run over all seeds of length $d(n^c)$ there are $2^{(d(n^c))}$ such string. For me it sounds like a strengthening of randomness because after that we use the majority as a result. But actually why do need that, why we cannot use single seed of length $d(n^c)$.</p>\n\n<p>Q:Philosophical question. Why do we need PRG to be non-uniformly strong? Why we cannot use uniformly indistinguishable PRG? I saw the idea that the primary input $x$ to the $A$ can be used as advice, but I still don\'t understand why do we need it.</p>\n', 'ViewCount': '40', 'Title': 'Simulation BPP by Pseudorandom Generator', 'LastActivityDate': '2013-05-02T04:16:45.680', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11716', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1379', 'Tags': '<complexity-theory>', 'CreationDate': '2013-05-01T20:31:33.670', 'Id': '11712'}{'Body': '<p>How should I show that ${\\sf P}$ is contained in ${\\sf NP} \\cap {\\sf CoNP}$?</p>\n\n<p>I.e., all polynomial time solvable problems and their complements are verifiable in polynomial time.</p>\n', 'ViewCount': '205', 'Title': u'P is contained in NP \u2229 Co-NP?', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-05-21T16:58:00.003', 'LastEditDate': '2013-05-21T16:58:00.003', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '0', 'OwnerDisplayName': 'user15870', 'PostTypeId': '1', 'Tags': '<complexity-theory><np><polynomial-time>', 'CreationDate': '2013-05-02T08:25:55.583', 'Id': '11725'}{'Body': '<p>I am given an oracle $A$ that takes input samples from two distributions $\\chi_1$  and $\\chi_2$.</p>\n\n<p>Suppose we have $Pr_{x \\sim \\chi_1}[A(x) = 1] = p_1$ and $Pr_{x \\sim \\chi_2}[A(x) = 1] = p_2$, where $p_1 \\neq p_2$.</p>\n\n<p>In general, how can we use $A$ to construct a distinguisher to determine whether the input samples are from $\\chi_1$ or $\\chi_2$? And how good is the running time of such distinguisher?</p>\n\n<p>Thank you very much! :)</p>\n', 'ViewCount': '87', 'Title': 'How to distinguish whether a sample is from distribution $\\chi_1$ or $\\chi_2$?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-06-06T11:33:38.173', 'LastEditDate': '2013-05-07T11:07:54.823', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8051', 'Tags': '<complexity-theory><probability-theory>', 'CreationDate': '2013-05-05T03:57:06.787', 'Id': '11795'}{'Body': "<p>I'm doing some research regarding NFAs and inclusion problems with them. I know that in general, the inclusion problems, and converting to an unambiguous NFA, are both PSPACE-complete.</p>\n\n<p>I'm wondering, are there any sub-classes of NFA for which these can be decided efficiently? In particular, the NFAs I'm looking at accept finite language where all words have the same Parikh vector.</p>\n", 'ViewCount': '107', 'Title': 'Classes of NFAs which allow efficient subset testing or unambiguity conversions', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-06-13T16:33:18.830', 'LastEditDate': '2013-05-06T23:38:41.717', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2253', 'Tags': '<complexity-theory><formal-languages><automata><finite-automata><nondeterminism>', 'CreationDate': '2013-05-06T22:26:42.443', 'FavoriteCount': '1', 'Id': '11841'}{'Body': '<p>For every integer $t$, is there a problem whose solutions can be verified in $O(n^{s})$ time but cannot be found in $O(n^{st})$ time?</p>\n\n<p>By verifying, I mean that given a candidate solution $y$, we can judge whether $y$ is correct or not in time $O(n^s)$.</p>\n', 'ViewCount': '401', 'Title': 'A Problem on Time Complexity of Algorithms', 'LastEditorUserId': '72', 'LastActivityDate': '2013-05-09T22:53:07.350', 'LastEditDate': '2013-05-09T14:35:06.697', 'AnswerCount': '2', 'CommentCount': '8', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8074', 'Tags': '<complexity-theory><time-complexity><asymptotics><complexity-classes><lower-bounds>', 'CreationDate': '2013-05-07T01:48:11.327', 'Id': '11844'}{'Body': '<p>Assume we fix a degree $d$ polynomials $f$ of $k$ variables. (If it helps, let $t$ be the number of terms in $f$ and $g$).\nConsider a list of real numbers $a_1,\\ldots,a_n$, does there exist a permutation $\\pi$, such that for all $i\\leq n-k$\n$$ f(a_{\\pi(i)},a_{\\pi(i+1)},\\ldots,a_{\\pi(i+k-1)}) \\geq 0$$</p>\n\n<p>How hard is this problem?</p>\n', 'ViewCount': '70', 'Title': 'Rearrange a sequence of real numbers to satisfy polynomial inequalities', 'LastEditorUserId': '220', 'LastActivityDate': '2013-05-08T23:48:14.477', 'LastEditDate': '2013-05-08T17:21:52.910', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '11879', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<complexity-theory><real-numbers>', 'CreationDate': '2013-05-07T23:06:04.543', 'Id': '11869'}{'Body': "<p>My task is to give proof, the Vertex-Cover problem is NP-complete, assuming it's already shown that the Stable-Set problem is NP-complete, too.</p>\n\n<p>My approach: i know, Stable-Set is NP-complete, and all Problems that are NP-complete can be reduced to each other. If i could solve one NP-complete problem, i might be able to solve all NP-complete problems. It should be possible to create a function with polynomial complexity to reduce Vertex-Cover to Stable-Set. At least, this was, what my Professor told.</p>\n\n<p>Now all i have to do, is to find this polynomial function, in order to Show that Vertex-Cover is NP-complete. But here is where i am stuck.. so i need some advice how to build such functions.</p>\n", 'ViewCount': '415', 'Title': 'Show that Vertex-Cover is NP-complete, using Stable-Set', 'LastActivityDate': '2013-05-11T21:05:26.027', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11955', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6828', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-05-11T20:04:02.480', 'Id': '11954'}{'Body': '<p>Is it known whether the implication $\\mathsf{NEXP} = \\Sigma_2 \\implies \\mathsf{NEXP} = \\mathsf{MA}$ holds?</p>\n\n<p>(The question is inspired by well-known $\\mathsf{NEXP} \\subseteq \\mathsf{P/poly} \\Leftrightarrow \\mathsf{NEXP} = \\mathsf{MA}$.)</p>\n', 'ViewCount': '126', 'Title': '$NEXP = \\Sigma_2 \\implies NEXP = MA$?', 'LastActivityDate': '2013-05-12T17:37:41.307', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '667', 'Tags': '<complexity-theory>', 'CreationDate': '2013-05-12T17:37:41.307', 'Id': '11973'}{'Body': '<p>So, Google Code Jam round 1C has just wrapped up, and one of its problems seems rather elusive to me:  <a href="https://code.google.com/codejam/contest/2437488/dashboard#s=p2" rel="nofollow">https://code.google.com/codejam/contest/2437488/dashboard#s=p2</a></p>\n\n<p>A quick summary of the problem is thus:</p>\n\n<p>The Great Wall of China starts out as an infinite line, where the height at all locations is $0$.</p>\n\n<p>Some number of tribes $N$, $N \\le 1000$, will attack the wall the wall according to the following parameters - a start day, $D$, a start strength $S$, a start west-coordinate, $W$, and a start east-coordinate, $E$.  This first attack occurs on day $D$, on range $[W,E]$, at strength $S$.  If there is any portion of the Great Wall within $[W,E]$ that has height $&lt; S$, the attack is successful, and at the end of the day, the wall will be built up such that any segment of it within $[W,E]$ of height $&lt; S$ would then be at height $S$ (or greater, if some other attack that day hit upon the same segment with strength $S\' &gt; S$)</p>\n\n<p>Each tribe will perform up to $1000$ attacks before retreating, and each attack will be determined iteratively from the one before it.  Every tribe has some $\\delta_D$, $\\delta_X$, and $\\delta_S$ that determines their sequence of attacks:  The will wait $\\delta_D \\ge 1$ days between attacks, they will move their attack range $\\delta_X$ units for each attack (negative = west, positive = east), though the size of the range will stay the same, and their strength will also increase/decrease by a constant value after each attack.</p>\n\n<p>The goal of the problem is, given a complete description of the attacking tribes, determine how many of their attacks will be successful.</p>\n\n<p>I managed to code a solution that does work, running in about 20 seconds:  I believe the solution I implemented takes $O(A\\log A + (A+X)\\log X)$ time, where $A =$ the total number of attacks in a simulation (max $1000000$), and $X =$ the total number of unique edge points on attack ranges (max $2000000$).</p>\n\n<p>At a high level, my solution:</p>\n\n<ul>\n<li>Reads in all the Tribe information</li>\n<li>Calculates all the unique $X$-coordinates for attack ranges - $O(A)$</li>\n<li>Represents the Wall as a lazily-updated binary tree over the $X$ ranges that tracks minimum height values.  A leaf is the span of two $X$ coordinates with nothing in-between, and all parent nodes represent the continuous interval covered by their children. - $O(X \\log X)$</li>\n<li>Generates all the Attacks every Tribe will perform, and sorts them by day - $O(A \\log A)$</li>\n<li>For each attack, see if it would be successful ($\\log X$ query time).  When the day changes, loop through all unprocessed successful attacks and update the wall accordingly ($\\log X$ update time for each attack). - $O(A\\log X)$</li>\n</ul>\n\n<p>My question is this:  Is there a way to do better than $O(A\\log A + (A+X)\\log X)$?  Perhaps, is there some strategic way to take advantage of the linear nature of Tribes\' successive attacks?  20 seconds feels too long for an intended solution (Although Java might be to blame for that)</p>\n\n<p>-- Edit --</p>\n\n<p>Looking over other discussions and successful solutions seems to indicate that the solution I\'ve described is pretty much the expected algorithm.  The slow-down in my solution is possibly just due to lazy use of auto-boxing and a pointer-based tree structure, rather than an array-based one - so I suspect that, if a solution does exist, it\'s probably not a whole lot better than what\'s here.  We shall see if anything crops up though</p>\n\n<p>-- Edit2 --</p>\n\n<p>The solution has been posted at last: <a href="https://code.google.com/codejam/contest/2437488/dashboard#s=a&amp;a=2" rel="nofollow">https://code.google.com/codejam/contest/2437488/dashboard#s=a&amp;a=2</a><br>\nIt\'s very much the same as what I have posted here; so I am much more inclined to believe that a more efficient solution does not exist.</p>\n', 'ViewCount': '344', 'Title': 'Google Code Jam Great Wall Problem', 'LastEditorUserId': '7678', 'LastActivityDate': '2013-07-14T05:43:02.910', 'LastEditDate': '2013-07-14T05:43:02.910', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '7614', 'Tags': '<complexity-theory><data-structures><binary-trees>', 'CreationDate': '2013-05-15T15:26:19.040', 'FavoriteCount': '2', 'Id': '12040'}{'Body': '<p>I am trying to (intuitively) understand the two terms "decidability" and "verifiability".</p>\n\n<p>I have done a reasonable amount of searching and going through the various texts I can put my hands on. However, their intuitive understanding seems to escape me, specially for the second one.</p>\n\n<p>Out of the many definitions found, the following one found in <a href="http://kilby.stanford.edu/~rvg/154/handouts/decidability.html" rel="nofollow">this page</a>, clearly explained decidability to me.</p>\n\n<blockquote>\n  <p>A language is called decidable if there exists a method - any method\n  at all - to determine whether a given word belongs to that language or\n  not.</p>\n</blockquote>\n\n<p>However, I fail to find a parallel definition for verifiability.</p>\n\n<p>In the <a href="http://rads.stackoverflow.com/amzn/click/0534950973" rel="nofollow">Theory of Computation book by Sipser</a>, we find,</p>\n\n<blockquote>\n  <p>P = the class of languages for which membership can be <em>decided</em>\n  quickly. </p>\n  \n  <p>NP = the class of languages for which membership can be\n  <em>verified</em> quickly.</p>\n</blockquote>\n\n<p>In light of the above, I want to understand verifiability. </p>\n\n<p>Please provide as many examples as you can, at one moment, I try catch the meaning, in the next one, I get confused again.</p>\n', 'ViewCount': '154', 'Title': 'Please explain "decidability" and "verifiability"', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-17T18:15:56.733', 'LastEditDate': '2013-05-17T06:41:56.163', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '12079', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7200', 'Tags': '<complexity-theory><formal-languages><terminology><computability>', 'CreationDate': '2013-05-16T13:44:06.820', 'Id': '12068'}{'Body': "<p>What i actually want to do is to turn a math problem ,i have to solve,to a Boolean Satisfiability problem and solve it using a SAT Solver.\nI wonder if someone knows any manual,guide or anything that will help me to make my problem solve using a SAT Solver.From what i found so far,SAT Solver's do not have any good documentations..  </p>\n", 'ViewCount': '40', 'ClosedDate': '2013-05-19T02:06:13.393', 'Title': 'Start using SAT Solvers', 'LastActivityDate': '2013-05-18T10:50:31.373', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'OwnerDisplayName': 'Dchris', 'PostTypeId': '1', 'OwnerUserId': '7443', 'Tags': '<complexity-theory><logic>', 'CreationDate': '2013-05-17T15:03:13.950', 'Id': '12108'}{'Body': "<p>I have a question about the structure of the complexity class $APX$. Obviously, unless $P=NP$, no problem in the class $PTAS$ can be $APX$-complete (under the AP-reduction). However, what about the rest of problems in $APX$? Are there any problems known that are in $APX$, do not have a $PTAS$ (unless $P=NP$) and at the same time are provably not $APX$-complete (unless $P=NP$)?</p>\n\n<p>For the class $NP$, Ladner's Theorem guarantees the existence of problems in $NP - P$ that are not $NP$-complete (unless $P=NP$) - the so-called $NP$-intermediate problems. I am curious if any similar result has been proved for $APX - PTAS$ with respect to approximation preserving reductions.</p>\n\n<p>It is possible that the answer to this question is trivial - to be honest, the only $APX$-complete problem I know is MAX-3-SAT. However, I wonder how hard it is with respect to other problems in $APX - PTAS$.</p>\n", 'ViewCount': '92', 'Title': 'Are there any problems in $APX - PTAS$ that are not $APX$-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-19T15:01:57.763', 'LastEditDate': '2013-05-19T15:01:57.763', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12132', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2091', 'Tags': '<complexity-theory><approximation><complexity-classes>', 'CreationDate': '2013-05-18T13:53:24.377', 'Id': '12112'}{'ViewCount': '189', 'Title': 'Modeling the problem of finding all stable sets of an argumentation framework as SAT', 'LastEditDate': '2013-05-20T14:48:10.623', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7443', 'FavoriteCount': '2', 'Body': '<p>As a continuation of my previous <a href="http://cs.stackexchange.com/questions/12087/converting-math-problems-to-sat-instances?noredirect=1#comment25370_12087">question</a> i will try to explain my problem and how i am trying to convert my algorithm to a problem that can be expressed in a CNF form.</p>\n\n<p>Problem: Find all stable sets of an <a href="http://en.wikipedia.org/wiki/Argumentation_framework" rel="nofollow">argumentation framework</a> according to <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.4129" rel="nofollow">Dung\'s proposed framework</a>.</p>\n\n<p>Brief theory: Having an argumentation framework AF, with A the set of all arguments and R the set of the relations, a stable set is a set which attacks all arguments not in their set and there is no attack relation between arguments in the stable set.\nExample:</p>\n\n<p>Let\'s say we have an argumentation framework AF ,A={1,2,3,4}(arguments of AF) and attack relations R{1,3} and R{2,4}.\nIt\'s obvious that the set {1,2} is a stable extension of the framework because:</p>\n\n<p>a)it attacks all arguments not in their set (3 and 4)</p>\n\n<p>b)it\'s conflict free(no attacks between arguments in the set) because argument 1 does not attack argument 2 and the opposite </p>\n\n<p>My exhaustive abstract algorithm:</p>\n\n<pre><code>argnum=number of arguments;\n\nAi[argnum-1]=relation "attacks" ,where 1&lt;=i&lt;=argnum\n\nP[2^argnum-1]=all possible relations that can be generated from all the arguments\n\nS[2^argnum-1]=empty; where S are all the stable sets\n\nj=0; //counter for while\nk=1; //counter for counting stable sets\nwhile j&lt;2^argnum-1\n    if P[j] attacks all arguments not in P[j](check using Ai[])\n        if all arguments in P[j] are conlfict-free\n            S[k++]=P[j];\n        end if\n    end if \n    j++;\nend while\n</code></pre>\n\n<p>I want to solve the above problem either by transforming the above algorithm to CNF or by using a different algorithm and finally use a SAT Solver(or anything similar if exists) give CNF as input and get stable sets as output.</p>\n\n<p>I wonder if someone can give me any feedback of how i can transform any algorithm like the above to CNF in order to be used into a SAT Solver.</p>\n\n<p>I decided to use <a href="http://fmv.jku.at/precosat/" rel="nofollow">precosat</a>.</p>\n', 'Tags': '<algorithms><complexity-theory><time-complexity><np-complete><satisfiability>', 'LastEditorUserId': '7443', 'LastActivityDate': '2013-05-26T00:33:46.807', 'CommentCount': '7', 'AcceptedAnswerId': '12176', 'CreationDate': '2013-05-19T15:50:58.177', 'Id': '12135'}{'Body': '<p>If A many-one reduces to B, does the complement of A many-one reduce to the complement of B? My gut says no but I am having a hard time finding a counterexample.</p>\n', 'ViewCount': '115', 'Title': 'If A many-one reduces to B, does the complement of A many-one reduce to the complement of B?', 'LastEditorUserId': '683', 'LastActivityDate': '2013-06-20T02:38:20.557', 'LastEditDate': '2013-05-21T01:57:38.250', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8273', 'Tags': '<complexity-theory><formal-languages><reductions>', 'CreationDate': '2013-05-20T20:07:12.047', 'Id': '12168'}{'Body': "<p>i'm going to use the Christofides heuristic algorithm in order to solve a TSP for about 80 edges. Eventually i should have a solution, that is within the factor 1.5 of the optimum.</p>\n\n<p>But when i'm finished, i'd like to check my solution but i don't know how. So i thought about using a computer-program to find the optimal solution to see, if my solution is within the 3/2-range.</p>\n\n<p>i am not quite sure, if this is really possible or how long it might take. if it would take less than a month, i think, it would be worth a try.</p>\n", 'ViewCount': '63', 'Title': 'Is there a program to solve a metric TSP for 80 edges at optimum?', 'LastActivityDate': '2013-05-21T13:33:49.650', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12190', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6828', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-05-21T12:39:05.100', 'Id': '12184'}{'Body': '<p>I am new in complexity theory and this question is a part of a homework that I have and I am stuck on it.</p>\n\n<blockquote>\n  <p>Let ${\\sf coNP}$ be the class of languages $\\{\\overline{L}: L \\in {\\sf NP} \\}$.</p>\n  \n  <p>Show that if ${\\sf NP} \\neq {\\sf coNP}$, then ${\\sf P}\\neq  {\\sf NP}$.</p>\n</blockquote>\n', 'ViewCount': '729', 'Title': 'Proving that if coNP $\\neq$ NP then P $\\neq$ NP', 'LastEditorUserId': '4249', 'LastActivityDate': '2013-05-21T18:53:59.637', 'LastEditDate': '2013-05-21T18:53:59.637', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'OwnerDisplayName': 'user16111', 'PostTypeId': '1', 'Tags': '<complexity-theory><complexity-classes><np><p-vs-np>', 'CreationDate': '2013-05-21T09:05:11.783', 'Id': '12195'}{'Body': "<p>Given a set of rectangles, $D = \\{ (a_1, b_1), (a_2, b_2) \\dots , (a_n, b_n) \\}$, where in each pair $(a_i, b_i)$, $a_i$ represents the height of the rectangle and $b_i$ the width, and given another pair $(w, h)$ representing the width and height of a container $C$, does exist a way that taking some of the squares in $D$, the <strong>whole</strong> container C is perfectly filled? Here, $a_i, b_i, w, h \\in \\mathbb N$.</p>\n\n<p>I am trying to reduce it from Subset Sum, but can't find the way... Hope you guys can give me a hint over it!</p>\n", 'ViewCount': '38', 'Title': 'Showing filling a container with rectangles is hard by reducing from SUBSET-SUM', 'LastEditorUserId': '472', 'LastActivityDate': '2013-05-30T23:52:12.767', 'LastEditDate': '2013-05-30T23:52:12.767', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '12205', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8287', 'Tags': '<complexity-theory><np-complete><reductions><np><polynomial-time>', 'CreationDate': '2013-05-21T21:33:02.157', 'Id': '12202'}{'Body': "<p>May be it's a stupid question (sorry if it's the case).</p>\n\n<p>What is the complexity the decision problem:</p>\n\n<p>Input: $A\\in\\mathcal{M}_{n,m}(\\mathbb{Z})$</p>\n\n<p>does there exists $x\\in\\mathbb{N}^n,x&gt;0$ such that $Ax\\geq 0$?</p>\n\n<p>Where $x\\geq 0$ means for all $x_i\\geq 0$ and $x&gt;0$ means there exists $x_j&gt;0$.</p>\n\n<p>I know that integer linear programming is NP-complete but it's expressed has $Ax\\leq b$ and I failed to reduce $Ax\\leq b$ to $Ax\\geq0$ ... </p>\n", 'ViewCount': '50', 'Title': 'Complexity of $Ax\\geq 0$', 'LastActivityDate': '2013-05-23T18:34:30.377', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12234', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7240', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-05-23T16:37:27.763', 'Id': '12232'}{'Body': '<p>This was a question at SO, and I think it\'s very interesting, I thought about it, but I could not provide any efficient algorithm neither showing the NP-Hardness:</p>\n\n<blockquote>\n  <p>Find the length of the longest non-decreasing sequence through\n  adjacent, non-repeating cells (including diagonals). For example, in the\n  following grid, one legal path (though not the longest) that could be\n  traced is 0->3->7->9 and its length would be 4.</p>\n  \n  <p>8 2 4 </p>\n  \n  <p>0 7 1 </p>\n  \n  <p>3 7 9 </p>\n  \n  <p>The path can only connect adjacent locations (you could not connect 8 ->\n  9). The longest possible sequence for this example would be of length\n  6 by tracing the path 0->2->4->7->7->9 or 1->2->4->7->7->8.</p>\n</blockquote>\n\n<p>For first attempts and possible misinterpretations is not bad to see <a href="http://stackoverflow.com/questions/15553218/technical-interview-longest-non-decreasing-subsequence-in-mxn-matrix/15554014#15554014">this</a> answer at SO.</p>\n\n<p>My question: above problem is in $P$?</p>\n', 'ViewCount': '365', 'LastEditorDisplayName': 'user742', 'Title': 'Longest path in grid like graph', 'LastActivityDate': '2013-05-24T02:46:31.383', 'LastEditDate': '2013-05-23T23:29:03.860', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'OwnerDisplayName': 'user742', 'PostTypeId': '1', 'Tags': '<algorithms><complexity-theory><graph-theory>', 'CreationDate': '2013-05-23T23:20:39.770', 'FavoriteCount': '1', 'Id': '12239'}{'Body': '<p>It is clear that any language in $\\mathsf{EXP}^{\\mathsf{EXP}}$ can be computed in <a href="https://en.wikipedia.org/wiki/2-EXPTIME" rel="nofollow">$\\mathsf{2EXP} = \\mathsf{DTime}(2^{2^{\\mathsf{poly}(n)}})$</a>.</p>\n\n<p>My question is whether the converse is true: is $\\mathsf{2EXP} \\subseteq \\mathsf{EXP}^{\\mathsf{EXP}}$?</p>\n', 'ViewCount': '72', 'Title': '$\\mathsf{2EXP} = \\mathsf{EXP}^{\\mathsf{EXP}}$?', 'LastActivityDate': '2013-05-24T18:11:41.933', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'OwnerDisplayName': 'user16109', 'PostTypeId': '1', 'Tags': '<complexity-theory><complexity-classes>', 'CreationDate': '2013-05-21T05:35:01.390', 'FavoriteCount': '1', 'Id': '12248'}{'Body': '<blockquote>\n  <p><strong>Input</strong>: A set of $n$ Users $U=\\{u_1, ..., u_n\\}$ and a set of $m$ products $I=\\{i_1, ..., i_m\\}$. Associated with each pair $u \\in U$ and $i \\in I$  is the probability $p_{u,i}$ of $u$ purchasing the product $i$.<br/>\n  <strong>Task</strong>: Assign each user exactly $k$ products so that the following objective function is maximized:<br/>\n  $$\\sum_{i \\in I(U)} ({1-\\prod_{u\\in U(i)}{(1-p_{u,i})}})$$<br/>\n  Where $I(U)\\subseteq I$ is the set of products assigned to some user, and $U(i) \\subseteq U$ is the set of users to whom a product $i$ is assigned.</p>\n</blockquote>\n\n<p>Question: Is this problem NP-Hard?</p>\n', 'ViewCount': '56', 'Title': 'Hardness of a special case of maximum matching', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-28T07:27:34.407', 'LastEditDate': '2013-05-28T07:27:34.407', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8344', 'Tags': '<complexity-theory><reductions><np-hard><matching>', 'CreationDate': '2013-05-25T02:15:10.840', 'Id': '12260'}{'Body': '<p>I\'m studying the <a href="http://en.wikipedia.org/wiki/PCP_theorem" rel="nofollow">PCP theorem</a>. </p>\n\n<p>While it is easy to prove that $\\mathsf{P}=\\text{PCP}(O(\\log n),0)$ , proving that $\\text{PCP}(O(\\log n),1)\\subseteq \\mathsf{P}$  i.e. PCP that uses $O(\\log n)$ random bits and read 1 bit of the proof is less obvious, what I tried to do is to take some proof $\\pi$ of length $n^{O(1)}$ (because effectively the message sent by the prover is bounded by $2^{r(n)}q(n)=2^{O(\\log n)}=n^{O(1)}$) then try all the coin tosses each time the verifier read some bit of the message so if the proof is not correct we flip the bit in the proof!   </p>\n', 'ViewCount': '109', 'Title': 'Proving that $\\text{PCP}(O(\\log n),1)\\subseteq \\mathsf{P}$', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-03T06:59:43.993', 'LastEditDate': '2014-03-03T06:59:43.993', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '12282', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Tags': '<complexity-theory><randomness>', 'CreationDate': '2013-05-25T20:05:31.100', 'Id': '12276'}{'Body': '<p>Reachability is defined as follows:\na digraph $G = (V, E)$ and two vertices $v,w \\in V$. Is there a directed path from $v$ to $w$ in $G$?</p>\n\n<p>Is it possible to write a polynomial time algorithm for it?</p>\n\n<p>I asked this question on mathematics and got no answer by far.</p>\n', 'ViewCount': '109', 'Title': 'Does reachability belong to P?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-06T07:39:49.460', 'LastEditDate': '2013-05-28T07:11:56.720', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '21360', 'Score': '-3', 'PostTypeId': '1', 'OwnerUserId': '51', 'Tags': '<complexity-theory><graph-theory><time-complexity>', 'CreationDate': '2013-05-26T05:57:18.243', 'Id': '12288'}{'Body': '<p>Hello for a homework I have to show that deciding whether a regex over $\\Sigma = \\{0,1\\}$ descibes $\\Sigma^*$ is $\\mathsf{coNP}$ complete (this is irrelevant for the question though).</p>\n\n<p>The thing which irrs me is that I think this problem is in $\\mathsf{P}$.</p>\n\n<p>Here is my argumentation:</p>\n\n<p>Let $R$ be a regex, then we have $$L(R) = \\{0,1\\}^* \\Leftrightarrow \\overline{L(R)} = \\varnothing$$</p>\n\n<p>Given $R$ we can consruct an NFA with $\\epsilon$ moves for $L(R)$ in poly. time; eliminating the $\\epsilon$ moves (again poly. time: $O(|Q| \\cdot |\\delta| \\cdot |\\Sigma|)$) we obtain an NFA $M$.</p>\n\n<p>By toggling the accepting states of $M$ we can construct an NFA which accepts $\\overline {L(R)}$, whose emptiness we can check with a BFS (again in poly. time).</p>\n\n<p>$\\leadsto \\mathsf{RegExpEq_{*}} \\in \\mathsf{P}$</p>\n\n<p>Where does my argumentation shatter? If both my argumentation and the question is correct, then $\\mathsf{P} = \\mathsf{coNP}$ which seems highly doubtful.</p>\n', 'ViewCount': '64', 'Title': "$\\mathsf{RegExpEq_*} \\in \\mathsf{coNPC}$ but why isn't in $\\mathsf{P}$", 'LastEditorUserId': '8368', 'LastActivityDate': '2013-06-23T12:02:53.363', 'LastEditDate': '2013-05-26T14:56:26.050', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12297', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8368', 'Tags': '<complexity-theory><formal-languages>', 'CreationDate': '2013-05-26T14:49:42.683', 'Id': '12296'}{'ViewCount': '100', 'Title': 'Assuming NP $\\neq$ P, are there NPI languages only P languages reduce to?', 'LastEditDate': '2013-05-28T07:01:25.540', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7934', 'FavoriteCount': '1', 'Body': '<p>let $L_c$ be the class of all languages that have a polynomial reduction to some language L, for example if $L=SAT$ then $SAT_c=NP$.</p>\n\n<p>Assuming know that $NP\\neq P$ we know that there exist languages that are not NP-hard and not in P, i.e. those in NPI. My question is there a language L in NPI such that $L_c \\setminus \\{L\\}=P$?   </p>\n', 'Tags': '<complexity-theory><complexity-classes>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-28T07:01:25.540', 'CommentCount': '2', 'AcceptedAnswerId': '12307', 'CreationDate': '2013-05-27T03:59:29.337', 'Id': '12300'}{'Body': "<p>So we know that there exists a Turing Machine $M$ and a polynomial $T$ such that:</p>\n\n<ul>\n<li>$M$ halts on all inputs within at most $T(|x|)$ steps</li>\n<li>If $x$ is in $L$ then $M$ accepts $x$</li>\n<li>If $x$ is not in $L$ then $M$ rejects $x$</li>\n</ul>\n\n<p>We need to show that for any other problem $L'$, there exists a polynomial time computable function $f$ such that for all $x$, $f(x)$ is in $L'$ if and only if $x$ is in $L$.</p>\n\n<p>I imagine the answer is simple but I'm stumped.</p>\n", 'ViewCount': '90', 'Title': u"Prove that if a problem L can be decided in polynomial time, then L \u2264p L' for any other problem L'", 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-28T17:44:24.253', 'LastEditDate': '2013-05-28T17:44:24.253', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8402', 'Tags': '<complexity-theory><reductions><decision-problem><polynomial-time>', 'CreationDate': '2013-05-28T09:11:53.633', 'Id': '12329'}{'Body': '<p>So, there are multiple possible definitions of "np-complete", two of which being:  </p>\n\n<ol>\n<li><p>A decision problem $L$ is np-complete if and only if:  $L \\in \\text{NP}$  and  $\\forall L\' \\in \\text{NP}: L\' \\preceq_{p} L$</p></li>\n<li><p>A decision problem $L$ is np-complete if and only if:  $L \\in \\text{NP}$  and  there exists a np-complete problem $L \\in \\text{NP}$ such that: $L\' \\preceq_{p} L$</p></li>\n</ol>\n\n<p>My question is, why are those two definitions equivalent, or put differently, (why) is np-complete an equivalence class? </p>\n\n<p>If it is an equivalence class I can understand equivalence of the above two definitions, but I fail to see why this is the case, since the (one-to-many) poly-time reduction $\\preceq_{p}$ is not symmetric... :-/</p>\n', 'ViewCount': '90', 'Title': 'Is np-complete an equivalence class?', 'LastActivityDate': '2013-05-28T23:29:25.010', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12347', 'Score': '3', 'OwnerDisplayName': 'user2429385', 'PostTypeId': '1', 'OwnerUserId': '8426', 'Tags': '<complexity-theory><complexity-classes><reductions><np><np-complete>', 'CreationDate': '2013-05-28T17:09:44.347', 'Id': '12346'}{'Body': '<p>I am interested in the following version of TSP:</p>\n\n<p><strong>Assumption:</strong> TSP where the distances are non-negative. We know the algorithm A which computes the optional solution for such instances of TSP.<br>\n<strong>Task:</strong> State an algorithm that uses the algorithm A and computes an optimal solition for instances where negative distances are allowed. </p>\n', 'ViewCount': '173', 'Title': 'Traveling salesman problem - negative distances allowed', 'LastEditorUserId': '39', 'LastActivityDate': '2013-10-10T14:04:07.183', 'LastEditDate': '2013-06-06T15:04:59.887', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '12388', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8072', 'Tags': '<complexity-theory><np-complete><traveling-salesman>', 'CreationDate': '2013-05-30T23:58:46.050', 'Id': '12387'}{'Body': "<p>I'm trying to find complexity class of finding winning strategy for first player in following game:</p>\n\n<p>Intance of 'Stones' game is:</p>\n\n<ul>\n<li>finite set $X$</li>\n<li>relation $R \\subseteq X^3$</li>\n<li>set $Y \\subseteq X$ and node $f \\in X$</li>\n</ul>\n\n<p>At the beggining we place stone in every element of $Y$. \nEvery player in his turn can move stone from $x$ to $z$ iff. $\\exists y.R(x, y, z) \\wedge y\\ has\\ stone\\ placed\\ in\\ it$.\nPlayer who places stone in $f$ wins.</p>\n\n<p>I think it's $PSPACE-complete$, but I was trying to proove this for some time, and I run out of ideas.</p>\n\n<p>I won't lie, it's homework assignment for my complexity class. Any help will be highly appreciated.</p>\n", 'ViewCount': '54', 'Title': "'Stones' game complexity", 'LastActivityDate': '2013-06-01T03:24:19.843', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8469', 'Tags': '<complexity-theory><space-complexity><complexity-classes><game-theory>', 'CreationDate': '2013-06-01T03:24:19.843', 'FavoriteCount': '1', 'Id': '12407'}{'Body': "<p>Do you know the name of the following problem and can you give a reference for its complexity (especially the relation to $\\mathsf{GraphIsomorphism}$ and/or other isomorphism/homomorphism problems)?</p>\n\n<blockquote>\n  <p>Given two metrics $d_1$ and $d_2: V^2 \\to \\mathbb{N}$. Does there exist a  permutation $\\pi$ on $V$ such that $d': V^2\\to \\mathbb{N}$ with \n  $$d'(u,v)=\\min \\{d_1(u,v),d_2(\\pi(u),\\pi(v))\\}$$\n  is a metric?</p>\n</blockquote>\n\n<p>Motivation: Think of two fishing nets. If you try to fasten every knot of one net to every knot of the other net, the maximal distance between two knots is determined by the length of the shorter thread in the two nets.</p>\n", 'ViewCount': '17', 'Title': 'Name and complexity of a problem concerning metrics', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-02T13:29:27.023', 'LastEditDate': '2013-06-02T13:29:27.023', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><reference-request><graph-isomorphism>', 'CreationDate': '2013-06-02T13:16:10.880', 'Id': '12431'}{'Body': '<p>How can I compute the search space complexity of a directional semantic network (i.e. a network where each semantics consist of two nodes and a directional link stands for their semantic relation)?</p>\n\n<p>Edit: For example, each semantics would be something like <code>lion ~&gt; IsA ~&gt; animal</code>, <code>animal ~&gt; IsInstanceOf ~&gt; living</code> etc...</p>\n', 'ViewCount': '39', 'Title': 'Search space complexity of directional semantic network', 'LastEditorUserId': '6899', 'LastActivityDate': '2013-06-04T18:56:16.000', 'LastEditDate': '2013-06-04T18:56:16.000', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6899', 'Tags': '<complexity-theory><knowledge-representation><searching><semantic-networks>', 'CreationDate': '2013-06-03T08:12:17.507', 'Id': '12440'}{'Body': '<p>There are $n$ bins and $m$ type of balls.\nThe $i$th bin has labels $a_{i,j}$ for $1\\leq j\\leq m$, it is the expected number of balls of type $j$.</p>\n\n<p>You start with $b_j$ balls of type $j$. Each ball of type $j$ has weight $w_j$, and want to put the balls into the bins such that bin $i$ has weight $c_i$. A distribution of balls such that previous condition holds is called a feasible solution.</p>\n\n<p>Consider a feasible solution with $x_{i,j}$ balls of type $j$ in bin $i$, then the cost is $\\sum_{i=1}^n \\sum_{j=1}^m |a_{i,j}-x_{i,j}|$. We want to find a minimum cost feasible solution.</p>\n\n<p>This problem is clearly NP-hard if there is no restriction on $\\{w_j\\}$. The subset sum problem reduces to the existence of a feasible solution. </p>\n\n<p>However, if we add the condition that $w_j$ divides $w_{j+1}$ for every $j$, then the subset sum reduction no longer works, so it\'s not clear whether the resulting problem remains NP-hard. Checking for the existence of a feasible solution takes only $O(nm)$ time(attached at the end of the question), but this does not give us the minimum-cost feasible solution. </p>\n\n<p>The problem has a equivalent integer program formulation:\nGiven $a_{i,j},c_i,b_j,w_j$ for $1\\leq i\\leq n,1\\leq j\\leq m$. \n\\begin{align*}\n\\text{Minimize:} &amp; \\sum_{i=1}^n \\sum_{j=1}^m |a_{i,j}-x_{i,j}| \\\\\n\\text{subject to:} &amp; \\sum_{j=1}^m x_{i,j}w_j = c_i \\text{ for all } 1\\leq i\\leq n\\\\\n&amp; \\sum_{i=1}^n x_{i,j} \\leq b_j \\text{ for all } 1\\leq j \\leq m\\\\\n&amp; x_{i,j}\\geq 0 \\text{ for all } 1 \\leq i\\leq n, 1\\leq j \\leq m\\\\\n\\end{align*}</p>\n\n<p>My question is, </p>\n\n<blockquote>\n  <p>Is the above integer program NP-hard when $w_j$ divides $w_{j+1}$ for all\n  $j$?</p>\n</blockquote>\n\n<p>It\'s not obvious how to solve this even when $n=1$ and $w_j=2^j$, namely\n\\begin{align*}\n\\text{Minimize:} &amp; \\sum_{j=1}^m |a_j-x_j| \\\\\n\\text{subject to:} &amp; \\sum_{j=1}^m 2^j x_j = c\\\\\n&amp; 0 \\leq x_j \\leq b_j \\text{ for all } 1\\leq j \\leq m\\\\\n\\end{align*}</p>\n\n<p><strong>An algorithm to decide if there is a feasible solution in $O(nm)$ time</strong>:</p>\n\n<p>Define $w_{m+1}=w_m(\\max_{j} c_j + 1)$ and $d_j = w_{j+1}/w_j$. Let $a\\%b$ be the remained of $a$ divides $b$.</p>\n\n<ol>\n<li>If there exist a $c_i$ that\'s not divisible by $w_1$, return "no feasible solution". (the invariant $c_i$ divides $w_j$ will always be maintained in the following loop)</li>\n<li><p>for $j$ from $1$ to $m$:</p>\n\n<ol>\n<li>$k \\gets \\sum_{i=1}^n (c_i/w_j)\\%d_j$. (the minimum of balls of weight $w_j$ required)</li>\n<li>If $b_j&lt;k$, return "no feasible solution".</li>\n<li>$c_i \\gets c_i - ((c_i/w_j)\\% d_j)$ for all $i$. (remove the minimum number of required balls of weight $w_j$)</li>\n<li>$b_{j+1} \\gets \\lfloor (b_j-k)/d_j \\rfloor$. (group smaller balls into a larger ball)</li>\n</ol></li>\n<li>return "there is a feasible solution".</li>\n</ol>\n', 'ViewCount': '578', 'Title': 'Is it NP-hard to fill up bins with minimum moves?', 'LastEditorUserId': '220', 'LastActivityDate': '2014-04-17T20:15:43.023', 'LastEditDate': '2014-04-17T20:15:43.023', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<complexity-theory><np-hard><integer-programming>', 'CreationDate': '2013-06-03T08:38:00.137', 'FavoriteCount': '3', 'Id': '12441'}{'Body': '<p>I have an exercise which I can\'t solve.</p>\n\n<p><strong>Exercise.</strong> Consider a game where the players have $2$ pure strategies each and assume that the graph $G$ is a tree with maximum degree $3$. Give a polynomial time algorithm to decide if such a game has a pure Nash equilibrium.</p>\n\n<p>The idea seems pretty obvious, every vertex of the tree and corresponding neighbouring vertices represent a "mini" game  which can be represent in normal form with size at most $2^4$. This "mini" game can decided efficiently in polynomial time.</p>\n\n<p>The problem is we have $n$ such a neighbouring areas (as a number of players), therefore we need somehow iteratively going over every area and decide where we have equilibrium and if not going back to the previous neighbouring areas change actions and check the existence. On the worst case it is going to take $2^{4n}$.</p>\n\n<p>But how to decide it in polynomial time?</p>\n', 'ViewCount': '47', 'Title': 'Nash Equilibrium in Tree of Bounded Degree', 'LastActivityDate': '2013-06-04T15:26:43.427', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4778', 'Tags': '<complexity-theory><trees><game-theory><polynomial-time>', 'CreationDate': '2013-06-04T15:26:43.427', 'Id': '12460'}{'ViewCount': '216', 'Title': 'Using software to calculate the complexity of an algorithm', 'LastEditDate': '2013-06-05T21:42:55.220', 'AnswerCount': '1', 'Score': '1', 'OwnerDisplayName': 'rafiki', 'PostTypeId': '1', 'OwnerUserId': '8537', 'FavoriteCount': '1', 'Body': '<p>I am somewhat a beginner, and I have often seen complexity being calculated for various algorithms but they never actually gave me a very clear idea about how it is done. Can someone please point some resources where I can learn to calculate the complexity of an algorithm?</p>\n\n<p>Secondly, is there some software that calculates the space and time complexity for an algorithm? I have seen that <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity" rel="nofollow">cyclomatic complexity</a> can be calculated by software.</p>\n', 'Tags': '<time-complexity><complexity-theory>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-06-05T21:42:55.220', 'CommentCount': '1', 'CreationDate': '2013-05-20T11:28:55.373', 'Id': '12475'}{'Body': '<p>Let  consider a general version of <a href="http://en.wikipedia.org/wiki/Two_Generals%27_Problem" rel="nofollow">Two Generals\' Problem</a>, when there are $n$ generals located on the arbitrary graph and they should agree on exactly the same value whether to attack or not to attack. </p>\n\n<p>It\'s well known  that Two Generals\' Problem represents a version of the <a href="http://en.wikipedia.org/wiki/Consensus_%28computer_science%29" rel="nofollow">Consensus Problem</a> with unlimited number of the stopping failures, I think this is the only reason why Two Generals\' Problem and Generals\' Problem (with $n$ generals) don\'t have solution.</p>\n\n<p>There is a proof of lacking solution for Two Generals\' Problem (can be found in the textbook of Lynch).</p>\n\n<p>The following is the exercise from the textbook of Lynch, that I have not solved so far.</p>\n\n<p>Show that a solution to the (deterministic) coordinated attack problem (Generals\' Problem) for any nontrivial connected graph implies a solution for the simple graph consisting of two processes connected by one edge. (Therefore, this problem is unsolvable in any nontrivial graph.)</p>\n\n<p>Apparently, there is a reduction from an edge case to graph. But how to show it mathematically rigorous?</p>\n\n<p><strong>Addendum:</strong></p>\n\n<p>Can I say something like this?\nWhen we are given the primary problem of Two Generals and they initial values $a_i$ (inclination whether to attack or not), we in arbitrarily add more dummy generals with the only requirement if $a_1=a_0=a$ for primary problem set all dummy\'s general input to $a$, otherwise set arbitrary input value $b \\in \\{0,1\\}$. Find the solution on the graph, the solution on the graph is the solution for the primary problem. </p>\n', 'ViewCount': '157', 'LastEditorDisplayName': 'user742', 'Title': 'Coordinated Attack Problem On The Arbitrary Graph', 'LastActivityDate': '2013-09-20T17:48:32.680', 'LastEditDate': '2013-09-20T09:33:24.167', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4778', 'Tags': '<algorithms><complexity-theory><graph-theory><reductions><distributed-systems>', 'CreationDate': '2013-06-07T13:49:01.323', 'Id': '12508'}{'Body': '<p>Motivated by <a href="http://cs.stackexchange.com/a/12510/6716">Max-Flow: Detect if a given edge is found in some Min-Cut, </a> I\'d like to ask the following questions:</p>\n\n<ol>\n<li>Given a multiset of real numbers $B$, how hard is it to compute the minimal positive difference $\\delta_\\min$\n$$\\delta(B_1,B_2)=\\left|\\sum_{b\\in B_1}b-\\sum_{b\\in B_2}b\\right|$$\ntaken over all partitions $B_1\\cup B_2=B$ of $B$ <strong>such that  $\\bf\\delta(B_1,B_2)&gt;0$</strong>?</li>\n<li>How hard is it to find a lower bound $\\delta_- &gt;0$ for $\\delta_\\min$?</li>\n</ol>\n\n<p>Observe that (2) is easy for rational numbers, as you can compute the least common denominator $d$ and every positive difference is a multiple of $\\frac{1}{d}$.</p>\n\n<p>Assume that all $b\\in B$ are from some subset (closed under addition and symmetric difference) of $\\mathbb{R}$ for which we do have a representation by finite strings and all basic operations are performable in at most polynomial time.</p>\n', 'ViewCount': '69', 'Title': 'Minimal positive difference of a mulitset of real numbers', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-08T20:38:22.673', 'LastEditDate': '2013-06-08T15:19:10.773', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6716', 'Tags': '<complexity-theory><real-numbers>', 'CreationDate': '2013-06-07T15:10:13.000', 'Id': '12511'}{'Body': '<blockquote>\n  <p><strong>Problem</strong>&nbsp;&nbsp;Given a Turing machine $M$ which has known runtime ${O}(g(n))$ with respect to input length $n$, is the runtime of $M \\in {O}(f(n))$?</p>\n</blockquote>\n\n<p>Is the above problem decidable for some nontrivial pairs of $g$ and $f$?A solution is trivial if $g(n) \\in O(f(n))$.</p>\n\n<p>This is related to the problem <a href="http://cstheory.stackexchange.com/questions/5004/are-runtime-bounds-in-p-decidable-answer-no">Are runtime bounds in P decidable? (answer: no)</a>. One can derive from <a href="http://cstheory.stackexchange.com/a/5006/314">Viola\'s answer</a> that if $f(n)\\not \\in o(n)$ and $f(n)\\not \\in O(g(n))$ then the problem is undecidable. </p>\n\n<p>The requirement that $f(n)\\not \\in o(n)$ is because the $M\'$ in Viola\'s proof need $O(n)$ time to find its input size. Thus Viola\'s proof could not work when $f(n)=1$.</p>\n\n<p>It would be interesting if we can decide on the run time of sublinear time algorithms. A special case is when we have arbitrary $g(n)$ and $f(n)=1$. </p>\n', 'ViewCount': '88', 'Title': 'Are runtime bounds decidable for anything nontrivial?', 'LastEditorUserId': '220', 'LastActivityDate': '2013-06-09T02:48:20.960', 'LastEditDate': '2013-06-07T21:14:42.577', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-06-07T20:41:57.460', 'FavoriteCount': '1', 'Id': '12518'}{'Body': '<p>The notion of <a href="http://en.wikipedia.org/wiki/Polynomial-time_reduction" rel="nofollow">polynomial time Turing reductions</a> (Cook reductions) is an abstraction of a very intuitive concept: efficiently solving a problem by using another algorithm as a subroutine. </p>\n\n<p>For example, by stating "$A$ is polynomial time Turing reduced to $B$", we indicate that we can solve the problem $A$ in a polynomial number of steps by making use of an algorithm which can solve the problem $B$.</p>\n\n<p>Then if $B$ is in $\\mathsf{NP}$, why not $A$?</p>\n', 'ViewCount': '314', 'Title': 'Why NP is not closed under Turing reduction', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-08T20:38:39.947', 'LastEditDate': '2013-06-08T20:38:39.947', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '1', 'OwnerDisplayName': 'Zhong Yantao', 'PostTypeId': '1', 'Tags': '<complexity-theory><reductions><closure-properties><np>', 'CreationDate': '2013-06-08T09:08:33.743', 'Id': '12541'}{'ViewCount': '151', 'Title': 'Use minimum number of swaps so each bin contains balls of the same color', 'LastEditDate': '2013-06-12T02:25:54.510', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '220', 'FavoriteCount': '3', 'Body': '<p>There are $n$ bins, the $i$th bin contain $a_i$ balls. The balls has $n$ colors, there are $a_i$ balls of color $i$. Let $m=\\sum_{i=1}^n a_i$.</p>\n\n<p>A swap is take a ball from one bin and swap with a ball from another bin. We want minimum number of swaps such that each bin only contain balls with the same color. </p>\n\n<p>I know a easy special cases $a_i\\leq 2$ for all $i$. (If $a_i=2$ for all $i$, then you can even do it by swapping each ball at most once.)</p>\n\n<p><strong>Edit</strong>: This is wrong because finding $c(D)$ is NP-hard.</p>\n\n<p><del>If we know which color goes to which bin, the problem is easy.</del></p>\n\n<p><del>Consider a multi-digraph $D=(V,A)$, $V=\\{v_1,\\ldots,v_n\\}$. If we know color $i$ goes to bin $b(i)$, then there are $k$ parallel arcs $(j,b(i))$ in $A$ iff bin $j$ contains $k$ balls of color $i$. Each component of the graph is Eulerian. \nThe minimum number of swaps required is $m-c(D)$, where $c(D)$ is the number of arc disjoint cycles that covers $A$. \nWe can swap by "following" a Eulerian circuit. (a swap using an arc of a minimal cycle can change it to a smaller minimal cycle and a self loop). Once the entire graph is set of self loops, we have made all the necessary swaps. </del></p>\n\n<p>How hard is this problem in general?  </p>\n', 'Tags': '<algorithms><complexity-theory>', 'LastEditorUserId': '220', 'LastActivityDate': '2013-06-12T02:25:54.510', 'CommentCount': '0', 'AcceptedAnswerId': '12630', 'CreationDate': '2013-06-09T10:31:21.867', 'Id': '12560'}{'Body': '<p>In Graph-Theory there are many ways for efficient approximation-algorithms to solve the Metric TSP. The best solution seems to be the Christofides Heuristic with a factor of 1.5 to the optimal solution. My Teacher said, there would be the so called $\\frac{4}{3}$-conjecture, which states: there might be a approximation solution for the metric tsp, that has only a $\\frac{4}{3}$-factor.</p>\n\n<p>But i cannot find any literature or further information about this assumption. Maybe you can?</p>\n', 'ViewCount': '54', 'Title': 'Where can i find literature about the $\\frac{4}{3}$-conjecture for approximation of the Metric TSP?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-10T14:49:29.627', 'LastEditDate': '2013-06-10T14:49:29.627', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '12594', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6828', 'Tags': '<complexity-theory><reference-request><np-complete><approximation><traveling-salesman>', 'CreationDate': '2013-06-10T10:33:26.633', 'Id': '12593'}{'Body': "<p>Assuming $P \\neq NP$ Is the following langauge in $P$ or $NPC$:<br>\n$L=\\{\\langle\\phi\\rangle\\mid\\phi$ is a 3CNF formula with an assignment satisfying at least half of the clauses$\\}$</p>\n\n<p>The first thing I tried to do is to find a 3CNF formula $\\phi$ such that  $\\phi \\notin L$ and I haven't managed to do so. Is it possible that simply all 3CNF formulas have such an assignment (and so the problem is in $P$) or am I missing something ?</p>\n", 'ViewCount': '55', 'Title': 'Is the following langauge in $P$ or $NPC$', 'LastActivityDate': '2013-06-14T23:01:55.957', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12680', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7068', 'Tags': '<complexity-theory><time-complexity><np-complete><satisfiability><3-sat>', 'CreationDate': '2013-06-14T22:05:23.980', 'Id': '12678'}{'ViewCount': '409', 'Title': 'Why is NFA minimization a hard problem when DFA minimization is not?', 'LastEditDate': '2013-06-15T18:22:30.120', 'AnswerCount': '3', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '8184', 'FavoriteCount': '1', 'Body': "<p>I know that we can minimize DFAs by finding and merging equivalent states, but why can't we do the same with NFAs?  I'm not looking for a proof or anything like that--unless a proof is simpler to understand.  I just want to understand intuitively why NFA minimization is so hard when DFA minimization is not.</p>\n", 'Tags': '<complexity-theory><finite-automata><nondeterminism>', 'LastEditorUserId': '31', 'LastActivityDate': '2013-06-18T03:28:02.137', 'CommentCount': '0', 'AcceptedAnswerId': '12712', 'CreationDate': '2013-06-15T17:57:35.147', 'Id': '12693'}{'Body': "<p>In the book on complexity by Arora and Barak, there is an exercise to show $Space(n)\\neq NP$, the proof of which goes by showing that $NP$ is closed under Karp reductions, while $Space(n)$ isn't.</p>\n\n<p>To show that $Space(n)$ isn't closed under Karp reductions, the suggested technique (both in the solutions given at my place of study as well as those given at many other universities) is to assume we have a TM that decides language $L$ in $Space(n^2)$. Now take an encoding $enc(x)$ of some $x$ in $L$ with $|enc(x)| = n$ and blow it up (in quadratic, thus polynomial time) to an encoding $enc'(x)$ of $x$ with $|enc'(x)| = n^2$ by padding the smaller encoding with $n^2-n$ padding symbols. Now we take the same TM, and it can decide $L$ in space linear in $enc'(x)$ by ignoring the padding stuff and just operating on $enc(x)$. This implies that $Space(n^2) \\subseteq Space(n)$, which contradicts the space hierarchy theorem, so $Space(n)$ can't be closed under Karp reductions.</p>\n\n<p>My problem here is that while I realize that we can easily show that $NP$ is closed under Karp reductions, it somewhat confuses me regarding what this says about $NTime(s(n))$. It seems to me that this approach will also work to show that $NTime(s(n))$ isn't closed under Karp reductions for any time-constructible function s(n) using the time hierarchy theorem, or am I mistaken here?</p>\n", 'ViewCount': '95', 'Title': 'Space(n) not closed under Karp reductions - what about NTime(n)?', 'LastEditorUserId': '6689', 'LastActivityDate': '2013-06-16T23:04:50.010', 'LastEditDate': '2013-06-16T19:32:14.977', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '12704', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6689', 'Tags': '<complexity-theory><reductions><closure-properties>', 'CreationDate': '2013-06-16T18:31:07.150', 'Id': '12702'}{'Body': '<p>Let $B=\\{b_1=g_1,\\cdots,b_n=g_n\\}$ be a set of binary variables $b_i$ and their corresponding values $g_i \\in \\{0,1\\}$. Let $M=\\{\\sum_{e \\in A}e \\;:\\; A \\subset B\\}$, i.e., $M$ is the set of all possible linear combinations of the equations in $B$.</p>\n\n<p>Given $S_i \\subset B$ for $i=1,\\cdots,m$, is that possible to compute, in polynomial time, a\n$K \\subset M$ with minimum size such that $S_i \\cup K$ is a full rank system of equations (i.e., the values of all of the variables can be obtained by solving $S_i \\cup K$)?</p>\n\n<p>An example: Let $B=\\{b_1=1,b_2=0,b_3=1\\}$, $S_1=\\{b_1=1,b_2=0\\}$, and $S_2=\\{b_2=0,b_3=1\\}$. \n$K=\\{b_1+b_3=0\\}$ is the solution because both $S_1\\cup K$ and $S_2 \\cup K$ can be solved uniquely and $K$ has the minimum size 1.</p>\n', 'ViewCount': '25', 'Title': 'Is this problem in P: Finding a common key for a collection of systems of equations?', 'LastActivityDate': '2013-06-20T02:54:32.613', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1672', 'Tags': '<complexity-theory><time-complexity><np-hard><polynomial-time><linear-algebra>', 'CreationDate': '2013-06-20T02:54:32.613', 'Id': '12776'}{'ViewCount': '217', 'LastEditorDisplayName': 'user742', 'Title': 'Find which vertices to delete from graph to get smallest largest component', 'LastEditDate': '2013-09-20T09:28:39.900', 'AnswerCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '8770', 'FavoriteCount': '1', 'Body': '<p>Given a graph $G = (V, E)$, find $k$ vertices $\\{v^*_1,\\dots,v^*_k\\}$, which removal would result in a graph with smallest largest component.  </p>\n\n<p>I assume for large $n = |V|$ and large $k$ the problem is difficult (NP-hard), but I am interested in small values of $k$ ($k \\in \\{1, 2, 3, 4\\}$).</p>\n\n<p>For $k = 1$, I think it is possible to find best vertex $\\{v^*_1\\}$ to remove by performing single depth-first-search of the graph (i.e., checking articulation points).</p>\n\n<p>For $k = 2$, it would be possible to find best vertices $\\{v^*_1, v^*_2\\}$ by performing $n$ depth-first searches (each of them for graph $G_i = G / \\{v_i\\}$). A similar approach could be applied in the case $k &gt; 2$.</p>\n\n<p>I wonder if there is any better solution than that.</p>\n\n<p>(Related: <a href="http://cs.stackexchange.com/questions/12783/find-min-no-of-vertices-to-remove-to-make-graph-max-component-k">counting the minimum number of vertices without necessarily enumerating them</a>)</p>\n', 'Tags': '<algorithms><complexity-theory><graph-theory><parametrized-complexity>', 'LastActivityDate': '2014-03-30T17:24:55.313', 'CommentCount': '4', 'AcceptedAnswerId': '12809', 'CreationDate': '2013-06-20T14:40:37.167', 'Id': '12789'}{'ViewCount': '49', 'Title': 'Why/how does the definition of PCP use randomness?', 'LastEditDate': '2013-06-21T06:18:14.120', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4778', 'FavoriteCount': '1', 'Body': '<p>I am confused by the definition of probabilistic checkable proofs. </p>\n\n<p>Language $L$ has an $(r(n),q(n))$ - PCP verifier, if there is a PPA V satisfying:</p>\n\n<p><strong>Efficiency</strong>: $V$ uses at most $r(n)$ random coins and makes at most $q(n)$ nonadaptive queries to location of $\\pi$.</p>\n\n<p><strong>Completeness</strong>: $x \\in L, \\exists \\pi \\in \\{0,1\\}^*, Pr[V^{\\pi}(x)=1]=1$</p>\n\n<p><strong>Soundness</strong>: $x \\notin L, \\forall \\pi \\in \\{0,1\\}^*, Pr[V^{\\pi}(x)=1]\\leq\\frac{1}{2}$</p>\n\n<p>The main question:</p>\n\n<ul>\n<li>Why does PCP need randomness? </li>\n<li>How exactly are random coins  used in the PCP? </li>\n<li>And what happens when these random coins are actually deterministic?</li>\n<li>Where does the effective proof length bound of $2^{r(n)}q(n)$ come from?</li>\n</ul>\n', 'Tags': '<complexity-theory><terminology>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-21T06:41:07.980', 'CommentCount': '2', 'AcceptedAnswerId': '12807', 'CreationDate': '2013-06-21T04:44:20.143', 'Id': '12805'}{'Body': '<p>Is there any general technique for proving a problem NOT being NP-Complete?</p>\n\n<p>I got this question on the exam that asked me to show whether some problem (see below) is NP-Complete. I could not think of any real solution, and just proved it was in P. Obviously this is not a real answer.</p>\n\n<p>NP-Complete is defined as the set of problems which are in NP, and all the NP problems can be reduced to it. So any proof should contradict at least one of these two conditions. This specific problem, is indeed in P (and thus in NP). So I am stuck with proving that there is some problem in NP that can\'t be reduced to this problem. How on the earth can this be proven??</p>\n\n<p>Here is the specific problem I was given on exam:</p>\n\n<blockquote>\n  <p>Let $DNF$ be the set of strings in <a href="http://en.wikipedia.org/wiki/Disjunctive_normal_form">disjunctive normal form</a>.\n  Let $DNFSAT$ be the language of strings from $DNF$ that are satisfiable by some assignment of variables. Show whether or not $DNFSAT$ is in NP-Complete.</p>\n</blockquote>\n', 'ViewCount': '991', 'Title': 'How to prove a problem is NOT NP-Complete?', 'LastActivityDate': '2013-06-22T22:24:31.567', 'AnswerCount': '5', 'CommentCount': '5', 'AcceptedAnswerId': '12813', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '7410', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-06-21T10:51:14.073', 'FavoriteCount': '2', 'Id': '12812'}{'Body': '<p>I know that Hamiltonian cycle problem in 3-regular triangle-free graphs is NP-complete. I would like to know how far we can stretch this result. Observing that a triangle is just $C_3$ cycle, What is the longest cycle $C_n$ such that deciding the existence of Hamiltonian cycle in 3-regular $C_n$-free graphs is still NP-complete?</p>\n', 'ViewCount': '34', 'Title': 'Existence of Hamiltonian cycle in a 3-regular $C_n$-free graph', 'LastActivityDate': '2013-06-24T12:08:02.523', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-06-24T12:08:02.523', 'Id': '12862'}{'Body': "<p>Suppose that $S \\in PCP(r(n),q(n))$, colclude that $S \\in NTIME(2^r \\cdot poly) \\cap DTIME(2^{2^r q+r} \\cdot poly)$</p>\n\n<p>The idea of a nondeterminstic simulation of the $V$ on input $x$ is simple, guess a proof, check every string $y$ of the length $2^r$, and this simulation should take nondeterministic time $2^r \\cdot poly$ because $V$ works in time $poly$ and there are $2^r$ string to check.</p>\n\n<p>In case of deterministic simulation the same intuition is applied, the maximum length of the proof is $2^r \\cdot q$ with non-adaptive queries, hence $2^{2^rq}$ number of proofs  should be checked by deterministic emulation, therefore the total time is $2^{2^r \\cdot q} \\cdot poly$, not exactly what's required.</p>\n\n<p>The problem is to show that $S \\in NTIME(2^r \\cdot poly) \\cap DTIME(2^{2^r q+r} \\cdot poly)$</p>\n", 'ViewCount': '32', 'Title': 'PCP deterministic emulation', 'LastEditorUserId': '8473', 'LastActivityDate': '2013-06-25T17:04:30.100', 'LastEditDate': '2013-06-25T08:33:27.527', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12893', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8473', 'Tags': '<complexity-theory>', 'CreationDate': '2013-06-25T07:52:57.893', 'Id': '12888'}{'Body': "<p>I'm working on old multiple choice exams and would like to know if the following statements are true or false:</p>\n\n<p>a) $L_1 \\le_p L_2 \\le_p L_3 \\Rightarrow L_1 \\le_p L_3$</p>\n\n<p>b) If $L \\in \\mathsf{NP}$ and $U \\le_p L$ holds for all languages $U \\in \\mathsf{PSPACE}$ then $\\mathsf{NP} = \\mathsf{PSPACE}$</p>\n\n<p>c) $L \\in P \\Leftrightarrow L \\le_p \\{a\\}^*$</p>\n\n<p>Statement a) was part of the lecture, Statesments b) and c): I don't know.</p>\n", 'ViewCount': '80', 'Title': 'Properties of polynomial time many-one reductions', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-25T14:41:00.997', 'LastEditDate': '2013-06-25T14:31:06.470', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '8862', 'Tags': '<complexity-theory><reductions><polynomial-time>', 'CreationDate': '2013-06-25T13:12:53.783', 'FavoriteCount': '1', 'Id': '12889'}{'Body': '<p>I\'ve read that quantum computers can solve \'certain problems\' exponentially better than classical computers.  As I think I understand it, it\'s NOT the same to say that quantum computers take any problems that are EXPTIME-complete, 2-EXPTIME,... and convert them to linear time or constant-time.</p>\n\n<p>I would like to know something more about this matter:</p>\n\n<ul>\n<li>Why can/can\'t a quantum computer solve exponential problems in sub-exponential time?</li>\n<li>Is it at least theoretically possible to imagine a computer (quantum or otherwise) able to solve EXPTIME-complete problems in constant time? Or does this lead to a contradiction?</li>\n</ul>\n\n<p><strong>EDIT</strong>  a third related item:</p>\n\n<ul>\n<li>Can quantum computers do parallel computing?</li>\n</ul>\n\n<p>Now that the subject came up from comments, the idea about parallel computing, that\'s the usual/pop vision about quantum computers, like if quantum computers were able to compute "all posibilities at once" of any given problem (I think if that were the case, wouldn\'t be necesary to call great Peter Shor to invent a factoring algorithm!). Then "why" question about quantum computers can/cannot do parallel computing is half a computer science and a physics question.</p>\n\n<p>Here a source of confusion: <a href="http://physics.about.com/od/physicsqtot/g/quantumparallel.htm" rel="nofollow">http://physics.about.com/od/physicsqtot/g/quantumparallel.htm</a></p>\n', 'ViewCount': '250', 'Title': 'Quantum computers, parallel computing and exponential time', 'LastEditorUserId': '1396', 'LastActivityDate': '2013-06-25T18:57:45.420', 'LastEditDate': '2013-06-25T18:36:11.587', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1396', 'Tags': '<complexity-theory><time-complexity><quantum-computing>', 'CreationDate': '2013-06-25T15:36:04.140', 'FavoriteCount': '2', 'Id': '12892'}{'Body': '<p>The PCP theorem implies (with other results) that there is no polynomial time algorithm for MAX 3SAT to find an assignment satisfying $7/8+ \\epsilon$ clauses of a satisfiable 3SAT formula unless $P = NP$.</p>\n\n<p>There is a trivial polynomial time algorithm that satisfies $7/8$ of the clauses. How hard is it to find an assignment that satsfies at least $7/8$ of the clauses but no more than $7/8 +\\epsilon $ for some $\\epsilon \\gt 0$? Is this task still $NP$-hard?</p>\n', 'ViewCount': '93', 'Title': 'How hard is finding restricted assignment of 3-SAT satisfying $7/8$ of the clauses?', 'LastEditorUserId': '96', 'LastActivityDate': '2013-06-26T16:13:46.583', 'LastEditDate': '2013-06-26T14:34:49.270', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2013-06-26T14:29:27.607', 'FavoriteCount': '2', 'Id': '12908'}{'Body': "<p>I am studying now for a test in my complexity course. When I solved previous exams I saw the following question : Prove that the language $L$ of all directed graphs on $n$ vertices that contain exactly $10\\sqrt(n)$ strongly connected components is in $NL$. </p>\n\n<p>We saw in class that checking whether a directed graph contains exactly $C$ strongly connected components is in $NL$ for any fixed $C$, but I thought about this question the whole day and I absolutely have no idea how to do it in $NL$ when then number of SCC required is $10\\sqrt(n)$. In the test this question was worth 20 points, so it shouldn't be too hard so I thought that maybe I am missing something important.<br>\nAny ideas people?</p>\n", 'ViewCount': '145', 'Title': 'Checking whether a directed graph on n vertices contains exactly 10*sqrt(n) strongly connected components is in non-deterministic logspace', 'LastActivityDate': '2013-06-28T05:07:36.833', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12942', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4631', 'Tags': '<complexity-theory><space-complexity><nondeterminism>', 'CreationDate': '2013-06-27T22:34:14.210', 'Id': '12932'}{'Body': '<p>I am interested in showing connection between CSP (Constraint Satisfaction Problems) as it\'s defined in <a href="https://www.cs.duke.edu/courses/fall10/cps270/csp.pdf" rel="nofollow">CSP</a> (definition with Constraint graph, sometimes called binary CSP) and 3SAT problem, when domain of CSP contains of 7 values. </p>\n\n<p>The specific requirement is to show reduction from 3SAT to GAP CSP, when domain of CSP contains of 7 values.</p>\n\n<p>Let try to reduce 3SAT to CSP, every clause of 3SAT can be represent as a vertex of CSP, and edges connect two clauses (vertices) when these clauses have at least one common variable. Set the values (assignments) from the domain of 7 values to every nodes such that to ensure the consistency (each variable get the same value in all clauses). </p>\n\n<p>The problem is I cannot get what is so special about 7 values, apparently, we should have 8 different assignments to the vertices, how can I show that 7 values is enough?</p>\n\n<p>In addition, I still don\'t have a good intuition about the constraints, for me constraints represented by the edge of the graph, and they ensure the consistency of the assignment (each variable get the same value in all assignments).</p>\n\n<p>Having codded 3SAT as CSP how can we show the reduction to GAP CSP?</p>\n', 'ViewCount': '84', 'Title': 'Connection CSP and 3SAT', 'LastEditorUserId': '1636', 'LastActivityDate': '2013-06-28T11:03:56.603', 'LastEditDate': '2013-06-28T11:03:56.603', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4799', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-06-28T07:01:20.957', 'Id': '12945'}{'Body': "<p>Pardon me if i'm missing something which is very obvious here but i cant seem to figure it out. </p>\n\n<p>$E=\\{ \\langle M, w \\rangle \\mid \\text{ Turing Machine encoded by $M$ accepts input $w$ after at most $ 2^{|w|}$ steps}\\}$</p>\n\n<p>We have to prove $E\\notin P$</p>\n\n<p>The book (Papadimitrou, Elements of the ToC) assumes $E\\in P$ and it constructs another language (a diagonal one) </p>\n\n<p>$E_1=\\{\\langle M\\rangle \\mid \\text{ Turing Machine encoded by $M$ accepts input $M$ after at most $  2^{|M|}$ steps}\\}$</p>\n\n<p>and takes its complement language $E_1'$ and it follows that with the assumption $E\\in P$ , it is true that $E_1' \\in P$</p>\n\n<p>The question it then asks is the following: Say the polynomially bounded turing machine to decide $E_1'$ is $M^*$ then what happens when $M^*$ is presented with $M^*$ as an input?\nNow I understand it cant give an yes because that results in a contradiction. My doubt is where is the contradiction if the answer is no?</p>\n", 'ViewCount': '108', 'Title': 'Proving that a language is not in P using diagonalization', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-06-29T07:03:24.240', 'LastEditDate': '2013-06-29T07:03:24.240', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12955', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '8912', 'Tags': '<complexity-theory><polynomial-time><check-my-proof>', 'CreationDate': '2013-06-28T15:45:59.360', 'Id': '12953'}{'Body': "<p>I want to show that the following problems are in NP (NP-completeness is irrelevant) by textually describing a non-deterministic Turing machine which runs in polynomial time. The assumptions are that addition, multiplication, tests for divisibility can be done in polynomial time and natural numbers are represented in binary.</p>\n\n<p>a) $\\{n \\in \\mathrm{N} \\ | \\ n \\ $is not a prime number$\\}$</p>\n\n<p>b) $\\{x_1, ..., x_n, y \\in \\mathrm{N} \\ | \\exists M \\subseteq \\{1, ..., n\\} : \\sum_{m \\in M}x_m = y \\ \\}$</p>\n\n<p>For a) it's clear that there must be a non-trivial divisor if $n$ isn't a prime, but how does it exactly work? How can I reject invalid and verify valid inputs?</p>\n", 'ViewCount': '396', 'Title': 'How to show that problems are in NP?', 'LastEditorUserId': '41', 'LastActivityDate': '2013-06-30T05:21:11.320', 'LastEditDate': '2013-06-30T05:21:11.320', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8480', 'Tags': '<complexity-theory><np>', 'CreationDate': '2013-06-29T20:31:05.000', 'Id': '12969'}{'Body': '<p>In <a href="http://cs.stackexchange.com/questions/909/knapsack-problem-np-complete-despite-dynamic-programming-solution">a different post</a> it came up that \n(using the Turing machine model of computation), \nit is not even safe to say that $N$ numbers can be read in $O(N)$ time.\nTo me this is boggling since \nit\'s something I take for granted in the RAM model of computation, \nand I admittedly only have a cursory understanding of Turing machines.</p>\n\n<p>However, the more boggling part is that \nthe same person claimed that in the Turing machine model \nwe cannot read $N$ numbers even in exponential time,\nBUT that we can read the input for Knapsack and fill a table of size $N$ by $w$ in exponential time.</p>\n\n<p>How can filling a two-dimensional $N$ by $w$ array take less time than \nan $N$ by $1$ array?</p>\n', 'ViewCount': '164', 'Title': 'Can we read N numbers in O(N) time?', 'LastEditorUserId': '41', 'LastActivityDate': '2013-06-30T07:07:41.653', 'LastEditDate': '2013-06-30T07:07:41.653', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8932', 'Tags': '<complexity-theory><turing-machines>', 'CreationDate': '2013-06-30T05:49:35.830', 'FavoriteCount': '1', 'Id': '12981'}{'Body': '<p>Partition problem is a well known NP-complete problem. In the definitions I have seen, the input is assumed to be a multiset of integers and we want to decide the existance of a partition into two sets that have the same sum.</p>\n\n<blockquote>\n  <p>Is the partition problem still NP-complete if all input integers are distinct (no integer is repeated)?</p>\n</blockquote>\n', 'ViewCount': '82', 'Title': 'Partition problem with distinct integers', 'LastActivityDate': '2013-07-02T06:10:49.613', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13032', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete><partition>', 'CreationDate': '2013-07-02T05:03:25.180', 'Id': '13030'}{'Body': "<p>I'd like to reduce 3 colorability to SAT. I've stuffed up somewhere because I've shown it's equivalent to 2 SAT.</p>\n\n<p>Given some graph $G = (V,E)$ and three colors, red, blue, green. For every vertex $i$, let the boolean variable $i_r$ tell you whether the $i$-th vertex is red (or more precisely, that the $i$-th vertex is red when $i_r = 1$). Similarly, define $i_b$ and $i_g$.</p>\n\n<p>Suppose two vertices $i$ and $j$ were connected by an edge $e$. Consider the clause\n        \\begin{align}\n   (\\bar i_r \\vee \\bar j_r)\n  \\end{align}\n        If we demand the clause is true, it means that the vertices cannot both be red at the same time. Now consider the bigger clause $\\phi_e$\n        \\begin{align}\n   (\\bar i_r \\vee \\bar j_r)\\wedge(\\bar i_b \\vee \\bar j_b)\\wedge(\\bar i_g \\vee \\bar j_g)\n  \\end{align}\n        which, if true, demands that the vertices $i$ and $j$ aren't both the same color. By itself, this clause is in 2-SAT.</p>\n\n<p>For every edge $e \\in E$, I now make a clause $\\phi_e$ of the above form and put them all together using $\\wedge$'s\n          \\begin{align}\n              \\phi = \\wedge_{e \\in E} \\phi_e\n           \\end{align}\nThus, for the entire graph, I've come up with a 2SAT formula which is equivalent to 3 coloring.</p>\n\n<p>This is obviously wrong, but I can't tell where I've screwed up.</p>\n", 'ViewCount': '83', 'Title': '3 Colorability reduction to SAT', 'LastActivityDate': '2013-07-04T12:00:36.670', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '13083', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9015', 'Tags': '<complexity-theory>', 'CreationDate': '2013-07-04T11:30:14.863', 'Id': '13082'}{'Body': '<p>The running time of knapsack is $O(n*W)$, but we always specify that this is only pseudo-polynomial. I was wondering if somebody could tell me if I understand the notion of pseudo-polynomial time correctly. </p>\n\n<p>My current understanding is that pseudo polynomial time means polynomial in the magnitude of the input, and polynomial time is polynomial in the number of bits it takes to represent the input. Thus, looking through each element of an array is $O(n)$ in the magnitude of its length (pseudo-polynomial), but it is exponential in the number of bits in the length of the array. In the same way, binary search is $O(log_2 n)$ in the magnitude of the length of $n$, but is linear in the number of bits in $n$ making it "pseudo-logarithmic". </p>\n\n<p>If I am correct, why do we never specify that binary search is linear in the number of bits, but we always specify that knapsack is exponential in the number of bits?</p>\n', 'ViewCount': '596', 'Title': 'Do I understand pseudo polynomial time correctly?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-06T13:36:01.240', 'LastEditDate': '2013-07-06T13:36:01.240', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '4', 'OwnerDisplayName': 'Maksim', 'PostTypeId': '1', 'Tags': '<algorithms><complexity-theory><terminology><pseudo-polynomial>', 'CreationDate': '2013-07-05T19:56:54.220', 'Id': '13104'}{'Body': '<p>I have a complete $n$-partite graph, where each partite set has $n$ vertices (yes it\'s also $n$), so the graph has $n^2$ vertices in total.  My problem is to find a minimum weight $n$-clique in the graph.  I would like to know whether the problem can be solved in polynomial time. </p>\n\n<p>More details of the terms: </p>\n\n<p><strong>Complete $n$-partite graph</strong>: a graph in which vertices are adjacent if and only if they belong to different partitions (<a href="http://en.wikipedia.org/wiki/Glossary_of_graph_theory" rel="nofollow">wikipedia</a>).  There are $n$ partitions in the graph.  (In my case, each partition contains exactly $n$ vertices.)</p>\n\n<p><strong>Minimum weight clique</strong>:  Every edge in the graph has a weight.  The weight of a clique is the sum of the weights of all edges in the clique.  The goal is to find a clique with the minimum weight.</p>\n\n<p>Note that the size of the required clique is $n$, which is the largest clique size in a complete $n$-partite graph, and it is always attainable. </p>\n\n<p>I have searched for hours and there seems no research tackling the exact problem.  Any suggestions?</p>\n', 'ViewCount': '107', 'Title': 'Is this NP-hard: min-weight n-clique in a complete n-partite graph', 'LastEditorUserId': '755', 'LastActivityDate': '2013-07-08T04:47:58.273', 'LastEditDate': '2013-07-08T00:19:34.617', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13154', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8732', 'Tags': '<complexity-theory><optimization><np-hard>', 'CreationDate': '2013-07-07T16:38:18.347', 'Id': '13135'}{'ViewCount': '576', 'Title': 'Decision problems in $\\mathsf{P}$ without fast algorithms', 'LastEditDate': '2013-07-12T05:17:37.383', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '472', 'FavoriteCount': '4', 'Body': u'<p>What are some examples of difficult decision problems that can be solved in polynomial time? I\'m looking for problems for which the optimal algorithm is "slow", or problems for which the fastest known algorithm is "slow".</p>\n\n<p>Here are two examples:</p>\n\n<ul>\n<li><p><strong>Recognition of perfect graphs.</strong> In their FOCS\'03 paper [1] Cornu\xe9jols, Liu and Vuskovic gave an $O(n^{10})$ time algorithm for the problem, where $n$ is the number of vertices. I\'m not sure if this bound has been improved upon, but as I understand it, more or less a breakthrough is needed to obtain a faster algorithm.</p></li>\n<li><p><strong>Recognition of map graphs.</strong> Thorup [2] gave a rather complex algorithm with the exponent being (about?) $120$. Perhaps this has been even dramatically improved upon, but I don\'t have a good reference.</p></li>\n</ul>\n\n<p>I\'m especially interested in problems that have practical importance, and obtaining a "fast" (or even a practical) algorithm has been open for several years.</p>\n\n<hr>\n\n<p>[1] Cornu\xe9jols, G\xe9rard, Xinming Liu, and Kristina Vuskovic. "A polynomial algorithm for recognizing perfect graphs." Foundations of Computer Science, 2003. Proceedings. 44th Annual IEEE Symposium on. IEEE, 2003.</p>\n\n<p>[2] Thorup, Mikkel. "Map graphs in polynomial time." Foundations of Computer Science, 1998. Proceedings. 39th Annual Symposium on. IEEE, 1998.</p>\n', 'Tags': '<algorithms><complexity-theory><reference-request>', 'LastEditorUserId': '41', 'LastActivityDate': '2014-04-04T20:09:25.113', 'CommentCount': '6', 'AcceptedAnswerId': '13227', 'CreationDate': '2013-07-10T15:22:02.280', 'Id': '13202'}{'Body': '<p>During my involvement in a course on dealing with NP-hard problems I have encountered the PCP theorem, stating</p>\n\n<p>$\\qquad\\displaystyle \\mathsf{NP} = \\mathsf{PCP}(\\log n, 1)$. </p>\n\n<p>I understand the technical definition of a PCP verifier, so I know in principle what kind of algorithm has to exist for every NP problem: a randomised algorithm that checks $O(1)$ bits of the given certificate for the given input using $O(\\log n)$ random bits, so that this algorithm is essentially a one-sided error Monte-Carlo verifier.</p>\n\n<p>However, I have trouble imagining how such an algorithm can deal with an NP-complete problem. Short of reading the proof of the PCP theorem, are there concrete examples for such algorithms?</p>\n\n<p>I skimmed the relevant sections of <a href="http://www.cs.princeton.edu/theory/complexity/" rel="nofollow">Computational Complexity: A Modern Approach</a> by Arora and Barak (2009) but did not find any.</p>\n\n<p>An example using a $\\mathsf{PCP}(\\_,\\ll n)$ algorithm would be fine.</p>\n', 'ViewCount': '220', 'Title': 'Example for a non-trivial PCP verifier for an NP-complete problem', 'LastActivityDate': '2013-07-19T09:24:04.750', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<algorithms><complexity-theory><np-complete><approximation><randomized-algorithms>', 'CreationDate': '2013-07-12T11:10:36.380', 'Id': '13246'}{'Body': '<p>I am trying to understand <a href="https://en.wikipedia.org/wiki/Interactive_proof_system" rel="nofollow">interactive proof systems</a> and tried the following problem as an exercise. We know that $PH \\subseteq PSPACE$ and $IP=PSPACE$, so come up with (easy to understand) interactive proof systems for $PH$?</p>\n\n<p>An interactive proof system for $NP$ is trivial, but I failed to get an interactive proof system even for $coNP$. Do you know of an explicit interactive proof system (by explicit I mean without going through the $IP=PSPACE$ route) for $coNP$?</p>\n', 'ViewCount': '93', 'Title': 'Interactive Proofs for coNP', 'LastEditorUserId': '41', 'LastActivityDate': '2013-07-17T08:03:41.293', 'LastEditDate': '2013-07-17T08:03:41.293', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '984', 'Tags': '<complexity-theory><interactive-proof-systems>', 'CreationDate': '2013-07-15T14:49:51.387', 'Id': '13286'}{'Body': "<p>does $BPP\\subseteq P^{NP}$ ? it seems reasonable but I don't know if there is a proof of this!could any one post a proof or any material that discusses the statement or something that look like this .  </p>\n", 'ViewCount': '54', 'Title': 'BPP upper bound', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-17T05:48:37.233', 'LastEditDate': '2013-07-17T05:48:37.233', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13301', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8570', 'Tags': '<complexity-theory><complexity-classes><randomized-algorithms><oracle-machines>', 'CreationDate': '2013-07-16T12:50:19.600', 'Id': '13300'}{'Body': '<p>Given a linear system of the form:</p>\n\n<p>$$\\begin{array}{c}\nx_r = a \\quad x_j = b \\\\\nc_1x_1 + c_2x_2 + \\ldots + c_nx_n = N \\\\\nx_1+x_2 + x_3 + \\ldots + x_n = k\\\\\n0 \\le a,b,x_1,x_2,x_3...x_n \\le 1\\\\\nk \\ge 0\n\\end{array}$$</p>\n\n<p>How quickly can the feasibility of the system be checked? To clarify: $x_r,x_j$ are members of $x_1,x_2...x_n$. Would it be $O(n^{3.5})$ since I believe that is the general complexity for running a linear program or would it be less? Can one use gaussian elimination to quickly reduce the first 4 equations in $O(n^3)$ and after that systematically move through the equations starting from the terms with largest coefficient and moving to terms with smallest coefficient assigning values that bring the equations as close to satisfactory as possible?</p>\n\n<p>Additional info:</p>\n\n<p>I am assuming that the number of variables scales linearly. $n \\ne N$ (I think that was clear though). </p>\n', 'ViewCount': '439', 'Title': 'Checking Feasibility of Linear Program in Polynomial Time', 'LastEditorUserId': '7678', 'LastActivityDate': '2013-07-22T06:23:52.420', 'LastEditDate': '2013-07-22T06:23:52.420', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '13371', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9271', 'Tags': '<complexity-theory><time-complexity><computational-geometry><linear-programming><linear-algebra>', 'CreationDate': '2013-07-20T23:16:43.717', 'Id': '13370'}{'Body': '<p>I am trying to solve the question 6.12 in Arora-Barak (Computational Complexity: A modern approach). The question asks you to show that the\n$\\mathsf{PATH}$ problem (decide whether a graph $G$ has a path from a given node $s$ to another given node $t$) which is complete for $\\mathbf{NL}$ is also contained in $\\mathbf{NC}$ (this is easy). The question then also makes a remark that this implies that $\\mathbf{NL} \\subseteq \\mathbf{NC}$ which is not obvious to me.</p>\n\n<p>I think in order to show this, one has to show that $\\mathbf{NC}$ is closed under logspace reductions, i.e</p>\n\n<p>$$(1): B \\in \\mathbf{NC} \\hbox{ and } A \\le_l B \\Longrightarrow A \\in \\mathbf{NC}$$ </p>\n\n<p>where $\\le_l$ is the logspace reduction defined as</p>\n\n<p>$$A \\le_l B :\\Longleftrightarrow (\\exists M \\hbox{ TM}, \\forall x)[x \\in A \\Longleftrightarrow M(x) \\in B]$$</p>\n\n<p>($M$ is a TM which runs in logarithmic space).</p>\n\n<p>I would appreciate if someone could give a tip for proving the statement $(1)$.</p>\n', 'ViewCount': '105', 'Title': '$\\mathbf{NC}$ is closed under logspace reductions', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-22T15:25:58.423', 'LastEditDate': '2013-07-22T14:17:00.753', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13390', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9293', 'Tags': '<complexity-theory><reductions><closure-properties><complexity-classes><parallel-computing>', 'CreationDate': '2013-07-22T12:55:57.660', 'Id': '13387'}{'Body': "<p>I need to know if the following problem is $NP$-complete.</p>\n\n<p>The data are as follows :</p>\n\n<ul>\n<li>$n$, number of items</li>\n<li>$\\{s_{i}\\}_{i \\in \\{1, \\dots n\\}}$, item sizes, sorted by ascending values.</li>\n<li>$S$ knapsack capacity.</li>\n<li>$T$ a lower bound on the value to be attained. </li>\n</ul>\n\n<p>Now, for each $i \\in \\{1, \\dots n\\}, c_i = \\log i $ is the value of item $i$. \nThe same item may be picked any number of times.</p>\n\n<p>The question is : if we note for each $i \\in \\{1, \\dots n\\}$, $x_i \\in \\mathbb{N}$, the number of times item $i$ is picked, does a set of values for all $x_i$ exist such that :\n$$\n\\forall i \\in \\{1, \\dots n\\}, x_i \\in \\mathbb{N},\n$$</p>\n\n<p>$$\n\\sum_{i=1}^{n} s_ix_i \\leq S\n$$<br>\nand \n$$\n\\sum_{i=1}^{n} \\log i \\cdot x_i \\geq T\n$$\n?</p>\n\n<p>A reduction from the subset sum problem doesn't look straightforward.</p>\n", 'ViewCount': '52', 'Title': 'Complexity of a particular integer knapsack version', 'LastActivityDate': '2013-07-24T07:14:06.143', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8326', 'Tags': '<complexity-theory>', 'CreationDate': '2013-07-24T07:14:06.143', 'Id': '13413'}{'Body': '<p>In the web draft of Arora and Barak, "Computational Complexity: A Modern Approach", the way I understand their definition of a round of interaction is that it consists of either the verifier or the prover sending a message. In other sources on the matter, it seems to me that a round consists of both the verifier and the prover sending a message. Could someone clarify which of the definitions is the one that is usually used?</p>\n', 'ViewCount': '86', 'Title': 'Number of rounds in interactive proofs - Arora & Barak', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-28T16:36:25.773', 'LastEditDate': '2013-07-29T08:07:58.093', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13469', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6689', 'Tags': '<complexity-theory><interactive-proof-systems>', 'CreationDate': '2013-07-26T14:18:50.917', 'Id': '13452'}{'Body': "<p>I'm wondering, what is the time-complexity of determining emptiness for 2-way DFAs? That is, finite automata which can move backwards on their read-only input tape.</p>\n\n<p>According to Wikipedia, they are equivalent to DFAs, though the equivalent DFA might be exponentially larger. I've found state complexity for their complements and intersections, but not for their emptiness-testing.</p>\n\n<p>Does anyone know of a paper where I could find this?</p>\n", 'ViewCount': '135', 'Title': 'What is the complexity of the emptiness problem for 2-way DFAs?', 'LastActivityDate': '2013-07-30T14:30:26.037', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13482', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2253', 'Tags': '<complexity-theory><formal-languages><reference-request><automata><finite-automata>', 'CreationDate': '2013-07-26T22:35:28.517', 'Id': '13456'}{'Body': '<p>In these notes about <a href="http://www.scottaaronson.com/democritus/lec10.html" rel="nofollow">quantum computation</a> by Scott Aronson, he explains that the computation classes $\\mathsf{BPP}$ is contained in $\\mathsf{BQP}$, but that they are not equal, and</p>\n\n<blockquote>\n  <p>So, the bottom line is that we get a problem -- Simon\'s problem -- that quantum computers can provably solve exponentially faster than classical computers. Admittedly, this problem is rather contrived, relying as it does on a mythical "black box" for computing a function f with a certain global symmetry. Because of its black-box formulation, Simon\'s problem certainly doesn\'t prove that $\\mathsf{BPP} \\neq \\mathsf{BQP}$. What it does prove that there exists an oracle relative to which $\\mathsf{BPP} \\neq \\mathsf{BQP}$. This is what I meant by formal evidence that quantum computers are more powerful than classical ones.</p>\n</blockquote>\n\n<p>What does he mean by an <em>oracle</em> separation?</p>\n\n<p>My understanding of an oracle for a Turing machine is one that solves the halting problem. Surely that can\'t be the case here?</p>\n', 'ViewCount': '234', 'Title': 'What is meant by an oracle separation between classes $\\mathsf{BPP}$ and $\\mathsf{BQP}$?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-07-31T16:02:03.220', 'LastEditDate': '2013-07-31T16:02:03.220', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '4', 'OwnerDisplayName': 'Mozibur Ullah', 'PostTypeId': '1', 'Tags': '<complexity-theory><quantum-computing><oracle-machines>', 'CreationDate': '2013-07-30T23:54:56.503', 'FavoriteCount': '1', 'Id': '13528'}{'Body': '<p>Are there classes of problems that cannot be solved by an oracle machine? If so, are there specific problem examples of that class of problems?</p>\n\n<p>Even the Omega number, at least the first N digits, could be computed as the Oracle could just return TRUE or FALSE for each {0,1}-digits...</p>\n', 'ViewCount': '125', 'Title': 'Problems unsolvable by an oracle machine?', 'LastActivityDate': '2013-08-05T04:57:29.613', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9508', 'Tags': '<complexity-theory><oracle-machines>', 'CreationDate': '2013-08-04T13:47:08.617', 'FavoriteCount': '0', 'Id': '13596'}{'Body': "<p>Suppose I have a decision problem $D$ and I encode it to a language $L \\subset \\{0,1\\}^*$. Now, I can also encode it to a different language $L'$.</p>\n\n<p>Is there any theorem relating the time complexity of $L$ and $L'$?</p>\n\n<p>How does the time complexity of a problem change with different encodings of the same problem?</p>\n", 'ViewCount': '211', 'Title': 'Does the time complexity of a problem change with encoding of the problem?', 'LastEditorUserId': '683', 'LastActivityDate': '2013-08-07T19:01:09.883', 'LastEditDate': '2013-08-07T18:59:31.140', 'AnswerCount': '4', 'CommentCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '180', 'Tags': '<complexity-theory><terminology><time-complexity>', 'CreationDate': '2013-08-07T02:49:58.497', 'Id': '13640'}{'Body': '<p>I\'m curious about two things.</p>\n\n<ol>\n<li><p>When we define the class called "probabilistic polynomial-time algorithm" in computer science, does it include polynomial-time algorithm with exponential space? \nFor example, when algorithm is considered to be given a input from domain $\\{0,1\\}^n$, \nwhat if the algorithm internally queries its exponential sized table (ex. $0^n\\to0,0^{n-1}1\\to1$ and so on..) and outputs the result? Does it still polynomial-time algorithm?</p></li>\n<li><p>In theoretical cryptography, one-way function $f:\\{0,1\\}^*\\to\\{0,1\\}^*$ has a requirement, which is related with <em>hard-to-invert</em> property, as following block.\nIf the answer to above question is yes, is it possible to construct algorithm $A\'$ to simulate exactly same as $f$ for every value in $\\{0,1\\}^n$ using exponential table as described in above question? If then, it implies that it\'s impossible to design one-way function which is definitely not true. So what have i missed?</p>\n\n<blockquote>\n  <p>For every probabilistic polynomial-time algorithm $A\'$, every positive polynomial $p(\\cdot)$, and all sufficiently large $n$\'s, </p>\n  \n  <p>$Pr[A\'(f(U_n),1^n)\\in f^{-1}(f(U_n))]&lt;\\frac{1}{p(n)}$</p>\n  \n  <p>where $U_n$ is random variable uniformly distributed over $\\{0,1\\}^n$ </p>\n</blockquote></li>\n</ol>\n', 'ViewCount': '195', 'Title': 'Polynomial-time algorithm with exponential space is eligible?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-08T10:42:59.150', 'LastEditDate': '2013-08-08T10:42:59.150', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '13668', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9565', 'Tags': '<complexity-theory><terminology><polynomial-time><one-way-functions>', 'CreationDate': '2013-08-07T10:09:41.700', 'Id': '13655'}{'Body': '<p>It seems that on this site, people will often correct others for confusing "algorithms" and "problems." What are the difference between these? How do I know when I should be considering algorithms and considering problems? And how do these relate to the concept of a language in formal language theory?</p>\n', 'ViewCount': '453', 'Title': 'What is the difference between an algorithm, a language and a problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-15T20:11:23.283', 'LastEditDate': '2013-08-08T10:47:58.127', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '2253', 'Tags': '<algorithms><complexity-theory><formal-languages><terminology><reference-question>', 'CreationDate': '2013-08-08T06:10:27.963', 'FavoriteCount': '6', 'Id': '13669'}{'Body': "<p>While reading a cryptography textbook, i find the definition of a function that is hard on the average.(More precisely, it is 'hard on the average but easy with auxiliary input', but i omit latter for simplicity.)</p>\n\n<blockquote>\n  <p><strong>Definition : Hard on the average</strong> : </p>\n  \n  <p>$h:\\{0,1\\}^*\\to \\{0,1\\}^* $ is hard on the average if <strong>there exists</strong> a probabilistic polynomial-time algorithm $G$ such that<br>\n  for every probabilistic polynomial-time algorithm $A'$ every positive polynomial $p(\\cdot)$, and all sufficiently large $n$'s,  Pr$[A'(X_n)=h(X_n)]&lt;\\frac{1}{p(n)}$  </p>\n  \n  <p>where $X_n := G(1^n)$ is a random variable assigned the output of $G$.</p>\n</blockquote>\n\n<p>My question is why the statement of the existence of qualified algorithm G is sufficient? </p>\n\n<p>In other words, why the above definition gives a formal definition of 'hardness on the average' instead of following definition, which is more intuitive(?) to understand and more strict.\nWhy is the above definition sufficient? </p>\n\n<p>( Now I'm thinking that problem might occur when $G$ has only polynomial number of possible outputs, but if so, let's replace 'for any $G$' with 'for any $G$ which have exponentially many possible outputs' in following definition.)</p>\n\n<blockquote>\n  <p><strong>(strong?) Def : Hard on the average</strong> : </p>\n  \n  <p>$h:\\{0,1\\}^*\\to \\{0,1\\}^* $ is hard on the average if <strong>for any</strong> probabilistic polynomial-time algorithm $G$ and for every probabilistic polynomial-time algorithm $A'$ every positive polynomial $p(\\cdot)$, and all sufficiently large $n$'s,  Pr$[A'(X_n)=h(X_n)]&lt;\\frac{1}{p(n)}$  </p>\n  \n  <p>where $X_n := G(1^n)$ is a random variable assigned the output of $G$.</p>\n</blockquote>\n\n<p>Another question is that whether a following simpler definition is equivalent to original definition or not?</p>\n\n<blockquote>\n  <p><strong>(simple) Def : Hard on the average</strong> : </p>\n  \n  <p>$h:\\{0,1\\}^*\\to \\{0,1\\}^* $ is hard on the average if for every probabilistic polynomial-time algorithm $A'$ every positive polynomial $p(\\cdot)$, and all sufficiently large $n$'s,  Pr$[A'(U_n)=h(U_n)]&lt;\\frac{1}{p(n)}$  </p>\n  \n  <p>where $U_n$ is a random variable uniformly distributed over $\\{0,1\\}^n$.</p>\n</blockquote>\n", 'ViewCount': '64', 'Title': "Completeness of formal definition of 'hardness on the average'", 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-09T07:02:13.240', 'LastEditDate': '2013-08-09T07:02:13.240', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13678', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9565', 'Tags': '<complexity-theory><terminology><cryptography><randomized-algorithms><average-case>', 'CreationDate': '2013-08-08T12:43:21.820', 'Id': '13674'}{'ViewCount': '162', 'LastEditorDisplayName': 'user742', 'Title': 'Why are all problems in FPTAS also in FPT?', 'LastEditDate': '2013-09-08T10:00:18.023', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2131', 'FavoriteCount': '1', 'Body': '<p>According to <a href="https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme" rel="nofollow">the Wikipedia article on polynomial-time approximation schemes</a>:</p>\n\n<blockquote>\n  <p>All problems in FPTAS are fixed-parameter tractable.</p>\n</blockquote>\n\n<p>This result surprises me - these classes seem to be totally different from one another.  FPTAS characterizes problems by how easy they are to approximate, while FPT characterizes problems by their difficulty relative to some parameter.  Unfortunately, Wikipedia (as of the time I\'m asking this question) doesn\'t provide a citation for this.</p>\n\n<p>Is there a standard proof of this result?  Or is there a source I could consult to learn more about this connection?</p>\n', 'Tags': '<complexity-theory><reference-request><approximation><parametrized-complexity>', 'LastActivityDate': '2013-09-08T10:00:18.023', 'CommentCount': '5', 'AcceptedAnswerId': '13681', 'CreationDate': '2013-08-08T21:07:15.470', 'Id': '13679'}{'Body': '<p>I have a problem $\\Pi_1$ that I want to show that is NP-hard. I know that I must find an NP-hard problem $\\Pi_2$ and a polynomial time reduction $f()$ from instances of $\\Pi_2$ to $\\Pi_1$ such that $I_2$ is an Yes-instance of $\\Pi_2$ iff $I_1=f(I_2)$ is an Yes-instance of $\\Pi_1$.</p>\n\n<p>What if I find a (constant sized) family of reductions $f_i()$ such that $I_2$ is an Yes-instance of $\\Pi_2$ iff at least one $f_i(I_2)$ is an Yes-instance of $\\Pi_1$? Is this enough? Is there a way of translating this one in the "classical" definition? How to formalize this?</p>\n\n<p>I know that in the second situation I can say that I can\'t solve $\\Pi_1$ in polynomial time unless P=NP, but I\'m no sure that is equivalent of saying that $\\Pi_1$ is NP-hard.</p>\n', 'ViewCount': '99', 'Title': 'NP-Hardness reduction', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-12T18:55:32.767', 'LastEditDate': '2013-08-11T13:21:08.910', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1373', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2013-08-09T23:22:09.297', 'Id': '13698'}{'Body': "<p>I need to prove that this language is in co-NPC:\n$\\{ \\langle M,x,1^n \\rangle \\mid M $ is a TM and for all $c \\in \\Sigma^*$ , $M$ accepts in $ $$n$ steps when given $(x,c)$ as input $\\}$.</p>\n\n<p>I tried to do so by showing that the complement is in NPC, that is $\\{ \\langle M,x,1^n \\rangle \\mid M $ is a TM and there exists  $c \\in \\Sigma^*$ , s.t $M$ doesn't accepts in $n$ steps when given $(x,c)$ as input $\\}$.</p>\n\n<p>I can prove that it's in NP by giving a polynomial non-deterministic algorithm, but I get stuck in the reduction part and don't know from which language in NPC to do a polynomial reduction and how. Does anybody know how do deal with such reduction?</p>\n", 'ViewCount': '54', 'Title': 'Showing a language is in co-NPC', 'LastEditorUserId': '472', 'LastActivityDate': '2013-08-18T13:57:00.253', 'LastEditDate': '2013-08-18T13:57:00.253', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9713', 'Tags': '<complexity-theory><turing-machines><np-complete>', 'CreationDate': '2013-08-17T18:24:44.037', 'Id': '13792'}{'Body': '<p>The following question is related to the <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCwQFjAA&amp;url=http://en.wikipedia.org/wiki/Maximum_cut&amp;ei=wMQTUuXxLuny4QS55oHgAw&amp;usg=AFQjCNF7PelNFUITFjPfjyXHqig7ivCgvw&amp;sig2=JVB560isHX3-zBpX2khJTQ&amp;bvm=bv.50952593,d.bGE" rel="nofollow">max cut problem</a> in <em>cubic graphs</em>. In <a href="http://www.cs.armstrong.edu/greenlaw/research/cubic.ps" rel="nofollow">this</a> survey paper Theorem 6.5 states</p>\n\n<blockquote>\n  <p>A maximal cut of a cubic graph can be computed in polynomial time</p>\n</blockquote>\n\n<p>Browsing through some other related results (for example <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCwQFjAA&amp;url=http://www.cs.tau.ac.il/~zwick/papers/cubic-MAXCUT-SODA.pdf&amp;ei=ycUTUvvrH6fV4gT25IHQBA&amp;usg=AFQjCNG6njoPJo3VO7GHk9dQvdiN23WOTA&amp;sig2=z706i_jNpl-wljwko3W6QQ&amp;bvm=bv.50952593,d.bGE" rel="nofollow">this</a> SODA paper) one gets the impression that this problem is actually NP complete even for cubic instances. In particular, the last paper states that this is indeed so if the graph is subcubic.</p>\n\n<p>That makes me wonder.. What\'s going on? Is the survey paper (and the result cited therein) faulty or is there some point that I am missing?</p>\n', 'ViewCount': '49', 'Title': 'Max cut in cubic graphs', 'LastActivityDate': '2013-08-20T21:01:07.307', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13848', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '3092', 'Tags': '<complexity-theory><graph-theory><graphs><np-complete><np>', 'CreationDate': '2013-08-20T19:42:20.570', 'Id': '13845'}{'Body': "<p>I'm interested in a slight variant of tiling, the 'jigsaw' puzzle: each edge of a (square) tile is labeled with a symbol from $\\{1\\ldots n, \\bar{1}\\ldots\\bar{n}\\}$, and two tiles can be placed adjacent to each other iff the symbol on one tile's facing edge is $k$ and the symbol on the other tile's facing edge is $\\bar{k}$, for some $k\\in\\{1\\ldots n\\}$.  Then, given a set of $m^2$ tiles, can they be placed into an $m\\times m$ square (rotating but not flipping the tiles) with all edges matching correctly?  (There's also a variant on this problem in which four $1\\times m$ 'framing' edges are provided and the pieces must fit correctly into that frame).</p>\n\n<p>I know this problem is NP-complete for sufficiently large $n$, but the bounds that I've seen on $n$ seem to be fairly large; I'm interested in the problem for small values of $n$ and in particular for $n=1$, the 'zero-one' case (where every edge is labeled either $0$ or $1$ and edges with a $0$ must be matched to edges with a $1$).  Here there are (with rotational symmetry) just six tile types (the all-zeroes tile, the all-ones tile, the tile with three zeroes and a one, the tile with three ones and a zero, and two distinct tiles with two zeroes and two ones, '0011' and '0101'), so a problem instance is just a specification of $m$ and a set of five numbers $T_{0000}$, $T_{0001}$, $T_{0011}$, $T_{0101}$, $T_{0111}$ and $T_{1111}$ (representing the count of each type of tile) with $T_{0000}+T_{0001}+T_{0011}+T_{0101}+T_{0111}+T_{1111}=m^2$.  The problem is obviously in NP (with $m$ given in unary) since a solution can simply be exhibited and then checked in polynomial (in $m$) time, but is it known to be NP-complete, or is there some dynamic programming algorithm that can be applied here?  What about the 'framed' case where the problem specification also includes the four edges of the square that are to be matched?  (Obviously if the unframed case is NP-complete the framed case almost certainly is as well)</p>\n", 'ViewCount': '173', 'Title': "Are 'zero-one' jigsaw puzzles NP-complete?", 'LastActivityDate': '2013-08-21T19:26:52.600', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '242', 'Tags': '<complexity-theory><np-complete><tiling>', 'CreationDate': '2013-08-20T21:39:23.030', 'FavoriteCount': '2', 'Id': '13849'}{'Body': "<p>One possible motivation for studying computational complexity classes is to understand the power of different kinds of computational resources (randomness, non-determinism, quantum effects, etc.).  If we look at it from this perspective, then it seems like we can obtain one plausible axiom for any attempt at characterizing which computations are feasible in some model:</p>\n\n<ul>\n<li>Any feasible computation can always invoke another feasible computation as a subroutine.  In other words, suppose the programs $P,Q$ are considered feasible to execute.  Then if we construct a new program by hooking $P$ and $Q$ up, so that $P$ makes subroutine calls to $Q$, then this new program is also feasible.</li>\n</ul>\n\n<p>Translated into the language of complexity classes, this axiom amounts to the following requirement:</p>\n\n<ul>\n<li>If $C$ is a complexity class intended to capture which computations are feasible in some model, then we must have $C^C = C$.</li>\n</ul>\n\n<p>(Here $C^C$ represents computations in $C$ that can invoke an oracle from $C$; that's an oracle complexity class.)  So, let's call a complexity class $C$ <em>plausible</em> if it satisfies $C^C=C$.</p>\n\n<p>My question: <em>What complexity classes do we know of, that are plausible (by this definition of plausible)?</em></p>\n\n<p>For instance, $P$ is plausible, since $P^P=P$.  Do we have $BPP^{BPP} = BPP$?  What about $BQP^{BQP} = BQP$?  What are some other complexity classes that meet this criterion?</p>\n\n<p>I suspect that $NP^{NP} \\ne NP$ (or at least, that would be our best guess, even if we cannot prove it).  Is there a complexity class that captures non-deterministic computation and that is plausible, under this definition?  If we let $C$ denote the smallest complexity class such that $NP \\subseteq C$ and $C^C \\subseteq C$, is there any clean characterization of this $C$?</p>\n", 'ViewCount': '95', 'Title': 'Complexity classes where $C^C = C$', 'LastActivityDate': '2013-08-24T00:30:01.770', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<complexity-theory><oracle-machines>', 'CreationDate': '2013-08-22T20:52:25.900', 'Id': '13876'}{'ViewCount': '176', 'Title': 'Complexity of deciding if a formula has exactly 1 satisfying assignment', 'LastEditDate': '2013-08-23T23:03:31.500', 'AnswerCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '667', 'FavoriteCount': '4', 'Body': '<p>The decision problem</p>\n\n<blockquote>\n  <p>Given a Boolean formula $\\phi$, does $\\phi$ have exactly one satisfying assignment?</p>\n</blockquote>\n\n<p>can be seen to be in $\\Delta_2$, $\\mathsf{UP}$-hard and $\\mathsf{coNP}$-hard. Is anything more known about its complexity?</p>\n', 'Tags': '<complexity-theory><complexity-classes><satisfiability>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-08-25T18:38:59.147', 'CommentCount': '0', 'AcceptedAnswerId': '13888', 'CreationDate': '2013-08-23T13:09:52.587', 'Id': '13887'}{'Body': "<p>I found something in my notes I don't really understand, maybe you could help.</p>\n\n<p>Let $A$ = Independent Set and $B$ = Clique. Then, we clearly have</p>\n\n<ul>\n<li>$A \\in \\mathsf{NPC}$ and</li>\n<li>$B \\in \\mathsf{NP}$.</li>\n</ul>\n\n<p>Now, the claim is that $A \\setminus B \\notin \\mathsf{NP}$ with the following explanation. If it was in $\\mathsf{NP}$ then $\\mathsf{NP} = \\mathsf{NPC}$.</p>\n\n<p>Can you explain why this argument is true?</p>\n", 'ViewCount': '129', 'Title': 'Why is the difference of two NP-complete languages not in NP?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-28T05:15:34.103', 'LastEditDate': '2013-08-27T10:45:45.470', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '13980', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9844', 'Tags': '<complexity-theory><np-complete><np>', 'CreationDate': '2013-08-27T06:59:58.437', 'Id': '13955'}{'Body': "<p>By a vanilla Turing machine, I mean a Turing machine with one tape (no special input or output tapes).</p>\n\n<p>The problem is as follows: the tape is initially empty, other than a string of $n$ $1$s and $0$s terminated by an end-of-string character. The tape head starts at the beginning of the string. The goal is for the tape to contain the original string in reverse order, terminated by an end-of-string character, with the tape head returned to the beginning of the string when the Turing machine finally halts.</p>\n\n<p>The Turing machine can use as large an alphabet as we like (so long as it contains $0$, $1$, and an end-of-string character), and can have as many states as we like. Is there a fixed Turing machine that can complete this task in time $o(n^2)$?</p>\n\n<p>It's easy to do this in time $O(n^2)$ using just a few states and symbols. It seems intuitively clear that something prevents us from doing it more than a constant factor faster, but I've never been able to prove it, and I often worry late into the night about miraculous applications of network coding or voodoo magic that somehow get a logarithmic speedup...</p>\n", 'ViewCount': '392', 'Title': 'Can you do an in-place reversal of a string on a vanilla turing machine in time $o(n^2)$?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-28T21:23:11.410', 'LastEditDate': '2013-08-28T09:35:04.997', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '13996', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9868', 'Tags': '<complexity-theory><time-complexity><turing-machines>', 'CreationDate': '2013-08-28T06:19:06.700', 'Id': '13988'}{'Body': u"<p>Given $n$ nodes in the plane, connect the nodes by a spanning tree.\nFor each node $v$ we construct a disk centered at $v$ with radius equal to the distance to $v$\u2019s furthest neighbor in the spanning tree. The <strong>interference</strong> of a node $v$ is then de\ufb01ned as the number of such disks that include the node $v$.</p>\n\n<p>The problem I'm interested is to find a spanning tree that <strong>minimizes the maximum interference</strong>.</p>\n\n<p>What is known about the problem in terms of computational complexity? Is it NP-hard? Can it be solved efficiently? What is its inapproximability threshold?</p>\n\n<p>Apparently this problem is still not understood well. I do not know the complexity of the problem (solvable optimally in polynomial time, or NP-complete), and as far as I know it is unknown whether efficient approximation algorithms exist.</p>\n", 'ViewCount': '124', 'Title': 'Complexity of finding a spanning tree that minimizes the maximum interference', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-08T11:04:52.237', 'LastEditDate': '2013-08-29T12:17:16.040', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14202', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9665', 'Tags': '<complexity-theory><graph-theory><computational-geometry>', 'CreationDate': '2013-08-28T19:48:05.097', 'Id': '13999'}{'Body': '<p>The problem can be formulated as:</p>\n\n<p>$\\min f(\\textbf{x})=\\sum_{i=1}^{n} \\prod_{j \\in N(i)}(1-F(x_i))$ s.t. $\\sum_{i=1}^n x_i \\leq B$ </p>\n\n<p>$N(i)$ is a set of i. And $F_{x_i}$ can be any function with range between [0,1].</p>\n\n<p>if $F(x_i)$ is a convex function and $\\prod_{j \\in N(i)}(1-x_i)$ is concave, the objective function is a concave function.</p>\n\n<p>Is this an NP-hard problem? Is there any possible ways so that I can get the approximation?</p>\n', 'ViewCount': '70', 'Title': 'Minimizing concave function with a linear constraint', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T09:46:45.970', 'LastEditDate': '2013-09-02T09:46:45.970', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9898', 'Tags': '<complexity-theory><optimization>', 'CreationDate': '2013-08-30T10:14:48.120', 'FavoriteCount': '1', 'Id': '14035'}{'Body': '<p>I want to prove that\n$\\textbf{REACH} \\leq_{\\textbf{L}} \\textbf{CIRCUIT-VALUE}$</p>\n\n<p>$\\textbf{REACH}$ is the well-known reachability problem: checking whether there is a connection from vertex $\\textbf{a}$ to vertex $\\textbf{b}$ in a graph $\\textbf{G}$.</p>\n\n<p>$\\textbf{CIRCUIT-VALUE}$ is the well-known CVP problem: checking whether a boolean circuit with gates outputs $\\textbf{TRUE}$.</p>\n\n<p>The reduction I\'m interested in is the "Mapping-Reduction".\nI\'ve considered, converting a given Graph to be used as input for the $\\textbf{CIRCUIT-VALUE}$-Problem. This conversion must be logarithmic.</p>\n', 'ViewCount': '94', 'ClosedDate': '2013-11-11T13:49:59.257', 'Title': 'Prove that REACH can be logarithmically reduced to CIRCUIT-VALUE', 'LastEditorUserId': '39', 'LastActivityDate': '2013-10-10T07:54:52.697', 'LastEditDate': '2013-09-06T15:04:46.460', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9978', 'Tags': '<complexity-theory><turing-machines><reductions>', 'CreationDate': '2013-09-04T09:07:34.980', 'Id': '14123'}{'ViewCount': '76', 'Title': 'Can anyone give a plain English explanation of the SAT problem?', 'LastEditDate': '2013-09-05T14:16:45.330', 'AnswerCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9987', 'FavoriteCount': '1', 'Body': "<p>I am new to algorithms. I Recently found the SAT problem. I tried to understand the Wikipedia article on it, but I couldn't understand much. Could someone explain what the problem is, and what is the significance of it without technical jargon?</p>\n", 'ClosedDate': '2013-09-05T12:06:40.997', 'Tags': '<complexity-theory><np>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-05T14:16:45.330', 'CommentCount': '2', 'AcceptedAnswerId': '14149', 'CreationDate': '2013-09-05T06:59:27.560', 'Id': '14139'}{'Body': '<p>Given complex number $C=a+ib$, I want to find two complex numbers $C_1=x+iy$ and $C_2=z+iw$ such that $C=C_1*C_2$ (a,b,x,y, z and w are all non zero integers). This problem is at least as hard as Integer factoring. Prime complex number has one as its only factor.</p>\n\n<p>Does this problem reduce to integer factoring? Is it NP-hard?</p>\n', 'ViewCount': '128', 'Title': 'How hard is factoring a complex number?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-06T15:28:15.030', 'LastEditDate': '2013-09-06T15:28:15.030', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '14160', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><number-theory><factoring>', 'CreationDate': '2013-09-05T21:54:52.927', 'Id': '14158'}{'ViewCount': '179', 'Title': 'Showing NP-hardness of HALF-SAT', 'LastEditDate': '2013-09-06T16:05:06.570', 'AnswerCount': '2', 'Score': '0', 'OwnerDisplayName': 'Sebastian', 'PostTypeId': '1', 'OwnerUserId': '10048', 'Body': '<p>Yesterday I wrote my undergraduate exam in complexity theory. I had to leave off one question, which bugs me since then. Consider:\n$$ HALF-SAT = \\{ \\varphi \\mid \\varphi \\text{ is a formula which is satisfied by at least half of all assignments }\\} $$\nI\'d like to know how I can prove NP-hardness.</p>\n\n<p>FWIW, here\'s what I figured out:</p>\n\n<ol>\n<li>HALF-SAT is <em>probably</em> not $\\in$ NP, at least in no verifiable way I can think of (not really relevant to the question)</li>\n<li>SAT $\\preceq$ HALF-SAT doesn\'t work, at least not by just adding clauses with new variables, doesn\'t change satisfiable-assignments/arbitrary-assignments ratio</li>\n<li>TAUT $\\preceq$ HALF-SAT via $\\varphi \\mapsto \\varphi \\wedge x_{new}$, but that\'s coNP-hardness (together with NP-hardness this further lets me assume 1., intuitively)</li>\n</ol>\n\n<p>And no, this has nothing to do with the problem you find via googling "HALF-SAT".</p>\n', 'Tags': '<complexity-theory><reductions><np-hard>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-06T16:05:06.570', 'CommentCount': '2', 'AcceptedAnswerId': '14166', 'CreationDate': '2013-09-03T16:46:25.667', 'Id': '14165'}{'Body': '<ol>\n<li><p>Apart from $2SAT$, what versions of SAT problem is complete for the class NL?</p></li>\n<li><p>Is there dynamic programming algorithm to solve the $2SAT$ Problem?</p></li>\n</ol>\n', 'ViewCount': '120', 'Title': 'Are there more easy SAT Problems?', 'LastEditorUserId': '9736', 'LastActivityDate': '2013-09-09T12:13:05.067', 'LastEditDate': '2013-09-09T10:54:07.480', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9736', 'Tags': '<complexity-theory><satisfiability>', 'CreationDate': '2013-09-06T23:11:12.620', 'Id': '14179'}{'Body': '<p>Quantified Boolean formulae are the prime examples of problems that are hard for the polynomial hierarchy, i.e., for the $\\Pi$ and $\\Sigma$ versions of it. However, there is also the $\\Delta$ version, defined as $\\Delta_{i+1}^{\\rm P} := {\\rm P}^{\\Sigma_i^{\\rm P}}$. In particular, $\\Delta_2^{\\rm P} = {\\rm P}^{\\rm NP}$.</p>\n\n<p>What are typical hard problems for this part of the hierarchy?</p>\n\n<p>I failed to search the Web for this; especially, you cannot use Google to find much about "P^NP".</p>\n', 'ViewCount': '138', 'Title': 'Which problems are hard for P^NP?', 'LastActivityDate': '2013-09-10T22:07:50.093', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '14258', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '10063', 'Tags': '<complexity-theory><oracle-machines>', 'CreationDate': '2013-09-10T16:56:25.643', 'Id': '14251'}{'ViewCount': '121', 'Title': '$\\mathsf{co\\text{-}NP}$ and Cook reductions', 'LastEditDate': '2013-09-16T07:26:19.233', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8942', 'FavoriteCount': '1', 'Body': '<p>Can someone help me understand the steps in this argument? There is a decision problem that is in $\\mathsf{co\\text{-}NP}$ (under standard Karp reductions) and is $\\mathsf{NP}$-hard with respect to Cook reductions. Does this imply that if it is in $\\mathsf{NP}$ then $\\mathsf{NP} = \\mathsf{co\\text{-}NP}$ and if so, why?</p>\n', 'Tags': '<complexity-theory><reductions><np-hard>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-16T07:26:19.233', 'CommentCount': '0', 'AcceptedAnswerId': '14286', 'CreationDate': '2013-09-12T08:36:22.790', 'Id': '14278'}{'Body': "<p>So I'm reading Introductions to Algorithms and sometimes I wish it would be a little bit more friendly with how it explains topics. One of these topics is proving big-theta. </p>\n\n<p>I understand that the definition of $\\Theta$ is as follows: </p>\n\n<blockquote>\n  <p>$\\Theta(g(n)) = f(n)$ if there exists positive constants $c_1$, $c_2$, and $n_0$ such that $0 \\le c_1 g(n) \\le f(n) \\le c_2 g(n)$ for all $n \\ge n_0$.</p>\n</blockquote>\n\n<p>In other words, for $f(n)$ and $g(n)$, $f(n)$ can be bounded by $c_2 g(n)$ from above and bounded below by $c_1 g(n)$. </p>\n\n<p>So the example in the book goes: </p>\n\n<blockquote>\n  <p>Show that $\\frac{1}{2} n^2 - 3 n = \\Theta(n^2)$.</p>\n</blockquote>\n\n<p>From the definition of big theta: </p>\n\n<p>$$ c_1 n^2 \\le \\frac{1}{2} n^2 - 3 n \\le c_2 n^2$$</p>\n\n<p>CLRS begins by dividing by the largest order term of $n$ which is $n^2$ to get </p>\n\n<p>$$ c_1 \\le \\frac{1}{2} - \\frac{3}{n} \\le c_2 $$</p>\n\n<p>From here we split the problem into two parts, the right-hand inequality and the left-hand inequality. </p>\n\n<p>On the right hand side: CLRS chooses $c_2 \\ge \\frac{1}{2}$ because for $n \\gt 1$, $\\frac{1}{2} - \\frac{3}{n}$ can never be less than $\\frac{1}{2}$ since $\\frac{3}{n}$ goes to $0$ as $n$ goes to infinity. (I'm assuming they choose $n \\gt 1$ here because if $n=0$ then we would be dividing by $0$.)</p>\n\n<p><em>Now this is where I start to get lost.</em> </p>\n\n<p>On the left hand side: CLRS chooses  $c_1 = \\frac{1}{14}$ (not sure why) and $n \\ge 7$. I'm not sure what the significance of these choices is. At $n \\le 6$, $\\frac{1}{2}-\\frac{3}{n}$ becomes negative. But why $\\frac{1}{14}$ for $c_2$? I'm just not sure how they arrived at solving the left hand side and the book doesn't really explain it well for me.   </p>\n", 'ViewCount': '145', 'Title': 'Trouble understanding how to pick constants to prove big theta', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-15T10:08:13.853', 'LastEditDate': '2013-09-15T10:04:36.650', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '14327', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10152', 'Tags': '<complexity-theory><asymptotics>', 'CreationDate': '2013-09-15T08:14:47.893', 'Id': '14326'}{'Body': '<p>It seems that factoring a number known to be composite is in its own interesting little complexity class, e.g. polynomial time using quantum computing even though no one has proved $\\mathsf{P} = \\mathsf{NP}$ for quantum computing. </p>\n\n<p>Are there interesting, non-obvious examples of problems with polynomial-time verifiability for solutions, which have been shown to be polynomial-time equivalent to factoring a composite number into primes, under the classical non-quantum computational model?   </p>\n', 'ViewCount': '83', 'Title': 'Are there problems that are polynomial-time equivalent to factoring composites?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-17T08:13:13.480', 'LastEditDate': '2013-09-17T08:13:13.480', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '14368', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<complexity-theory><complexity-classes><factoring>', 'CreationDate': '2013-09-16T17:55:59.850', 'Id': '14359'}{'ViewCount': '57', 'Title': 'Post-selection and complexity theory', 'LastEditDate': '2013-09-17T08:32:43.633', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Body': "<p>I read about post-selection and didn't understand the meaning behind this thing. I didn't understand the Wikipedia article well, so what is a simple but understandable explanation of post-selection and how to use it in complexity?   </p>\n", 'ClosedDate': '2013-09-30T07:56:33.610', 'Tags': '<complexity-theory><terminology><probability-theory>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-17T16:55:42.447', 'CommentCount': '3', 'AcceptedAnswerId': '14371', 'CreationDate': '2013-09-16T20:53:29.813', 'Id': '14364'}{'Body': '<p>Given $x\\in\\Bbb N$, I would like to find $x\\bmod N$, where $N$ is composite. For example $N=35$, $x=53$ and $x\\bmod N=18$. Is this operation considered monotone in circuit/algebraic complexity language? I also want to have consider $x_1+x_2\\bmod N = x_1\\bmod N+x_2\\bmod N$ and $x_1x_2\\bmod N = (x_1\\bmod N)(x_2\\bmod N)$.</p>\n', 'ViewCount': '77', 'Title': 'Modulo operation in monotone complexity', 'LastEditorUserId': '9753', 'LastActivityDate': '2013-09-18T10:44:49.497', 'LastEditDate': '2013-09-18T10:44:49.497', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14383', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory><circuits>', 'CreationDate': '2013-09-17T14:13:55.767', 'Id': '14379'}{'Body': '<p>As the question states, how do we prove that $\\textbf{NTIME}(f(n)) \\subseteq \\textbf{DSPACE}(f(n))$?</p>\n\n<p>Can anyone point me to a proof or outline it here? Thanks!</p>\n', 'ViewCount': '105', 'Title': 'NTIME(f) subset of DSPACE(f)', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-09T02:19:16.840', 'LastEditDate': '2013-09-20T17:45:09.420', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10237', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2013-09-20T16:26:15.297', 'Id': '14475'}{'Body': "<p>I've read that MAJSAT is PP-complete.  Under what type of reduction is this true? What kind of reductions are usually used in order to prove PP-completeness?  </p>\n", 'ViewCount': '62', 'Title': 'What kind of reductions are usually used in order to prove PP-completeness?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-09-24T07:20:32.133', 'LastEditDate': '2013-09-24T07:20:32.133', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '14564', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7934', 'Tags': '<complexity-theory>', 'CreationDate': '2013-09-22T22:39:49.190', 'Id': '14528'}{'Body': '<p>Consider a bipartite graph with vertex set partitioned into $X=\\{u_1,u_2,u_3\\}$ and $Y=\\{v_1,v_2,v_3\\}$. Consider the graph has the following edges: $\\{u_1,v_1\\}$, $\\{u_2,v_2\\}$, $\\{u_2,v_3\\}$, $\\{u_3,v_2\\}$ and $\\{u_3,v_3\\}$. The perfect matchings are $\\{\\{u_1,v_1\\}$, $\\{u_2,v_2\\}$, $\\{u_3,v_3\\}\\}$ and $\\{\\{u_1,v_1\\}$, $\\{u_2,v_3\\}$, $\\{u_3,v_2\\}\\}$. The total number of such matchings is $2$.</p>\n\n<p>However I do not want the same edge to occur in two different sets. Here edge $\\{u_1,v_1\\}$ occurs in both the sets. So I can pick one of the two possible matchings for a total of $1$.</p>\n\n<p>Is there any counting strategy for the new matching problem? Note that permanent counts perfect matchings in the base case. </p>\n\n<p>Is there an approximation algorithm?</p>\n', 'ViewCount': '52', 'Title': 'Counting modified perfect matchings', 'LastEditorUserId': '9753', 'LastActivityDate': '2013-09-25T20:33:54.460', 'LastEditDate': '2013-09-25T20:33:54.460', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-09-23T04:08:20.910', 'Id': '14544'}{'Body': '<p>A question on the interesting result in <a href="http://arxiv.org/pdf/1110.6126v1.pdf">http://arxiv.org/pdf/1110.6126v1.pdf</a></p>\n\n<p>It is shown $\\Pi_2^P \\not\\subset P^{NP}$. But <a href="http://en.wikipedia.org/wiki/Polynomial_hierarchy">http://en.wikipedia.org/wiki/Polynomial_hierarchy</a> says $\\Pi_2^P = CoNP^{NP}$.</p>\n\n<p>Does this mean an oracle in NP under which $P$ is not $CoNP$ has been shown?</p>\n\n<p>Could someone elaborate?</p>\n', 'ViewCount': '38', 'Title': 'A containment result in complexity', 'LastActivityDate': '2013-09-27T21:52:38.670', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14648', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory>', 'CreationDate': '2013-09-27T21:32:57.727', 'FavoriteCount': '1', 'Id': '14646'}{'Body': '<p>Wiki (<a href="http://en.wikipedia.org/wiki/Sharp-P" rel="nofollow">http://en.wikipedia.org/wiki/Sharp-P</a>) says \'In computational complexity theory, the complexity class #P (pronounced "number P" or, sometimes "sharp P" or "hash P") is the set of the counting problems associated with the decision problems in the set NP\'.</p>\n\n<p>Is there a counting version for CoNP problems? </p>\n', 'ViewCount': '85', 'Title': 'A simple question on #P', 'LastEditorUserId': '9550', 'LastActivityDate': '2013-09-28T00:29:30.567', 'LastEditDate': '2013-09-28T00:29:30.567', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '14650', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory>', 'CreationDate': '2013-09-27T22:18:43.710', 'Id': '14649'}{'Body': "<p>Let $S$ be a convex polygon on $n$ points. Given two points $A$ and $B$, where $A$ is left of $S$, and $B$ is right of $S$, what's an algorithm to find the shortest path from $A$ to $B$, that avoids the interior of $S$? What about the longest path?</p>\n", 'ViewCount': '114', 'Title': 'Finding both the longest and shortest path in a convex polygon', 'LastEditorUserId': '9665', 'LastActivityDate': '2013-10-31T17:09:25.687', 'LastEditDate': '2013-10-01T16:38:51.820', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9665', 'Tags': '<algorithms><complexity-theory><algorithm-analysis><computational-geometry>', 'CreationDate': '2013-10-01T16:03:11.983', 'FavoriteCount': '1', 'Id': '14736'}{'ViewCount': '38', 'Title': 'On approximations and reductions', 'LastEditDate': '2013-10-01T23:30:34.090', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9753', 'FavoriteCount': '1', 'Body': '<p>This may be a naive question but I am a bit clueless. I was under the opinion that given two NP complete problems, $P1$ and $P2$, if $P2 \\in APX$ and $P1 \\notin APX$, then we cannot have a direct reduction $P2\\leq P1$ but we can have a reduction $P1\\leq P2$.</p>\n\n<p>In this paper on page 165 <a href="http://www.lancaster.ac.uk/staff/letchfoa/articles/cut-projection.pdf" rel="nofollow">http://www.lancaster.ac.uk/staff/letchfoa/articles/cut-projection.pdf</a>, there is a reduction $MAXCUT \\leq STABLESET$. That is, given an instance of <em>STABLESET</em>, I can find an instance of <em>MAXCUT</em>. Why cant I use the approximate solution for <em>MAXCUT</em> to find an approximate solution to <em>STABLESET</em>?</p>\n', 'Tags': '<complexity-theory><reductions>', 'LastEditorUserId': '9753', 'LastActivityDate': '2013-10-02T06:55:41.410', 'CommentCount': '0', 'AcceptedAnswerId': '14746', 'CreationDate': '2013-10-01T22:53:24.303', 'Id': '14741'}{'Body': '<p>The CLIQUE problem -- problem of finding the maximum clique in a graph -- is NP-complete. That is, CLIQUE is</p>\n\n<ol>\n<li>in NP and </li>\n<li>there is an NP complete problem, 3-SAT for one, that reduces to CLIQUE in polynomial time.</li>\n</ol>\n\n<p>Part 2. above is fine -- all over in every resource and very well explained. For Part 1., from what I know, we need to have the following: Given a specific solution instance, we need to show that it can be verified, in polynomial time, that that solution is an answer to this problem. So for instance, given a specific graph and a subgraph of it, we should be able to check whether that subgraph is a clique of maximum size in that graph.</p>\n\n<p>The resources I\'ve read so far are phrasing this Part 1. here as "easy, straightforward, etc" or "it can be shown in $O(n^2)$ time that the given subgraph is a clique/not". However, the verification here is not just whether it\'s a clique, but also is whether it is a maximum clique in the graph. How can this be decided in polynomial time?</p>\n\n<p>What am I missing here?</p>\n', 'ViewCount': '186', 'Title': 'Showing that CLIQUE can be verified in polynomial time', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-04T06:43:02.090', 'LastEditDate': '2013-10-04T06:43:02.090', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10464', 'Tags': '<complexity-theory><decision-problem><np>', 'CreationDate': '2013-10-02T23:33:58.783', 'Id': '14765'}{'ViewCount': '103', 'Title': 'One $O(n^k)$ algorithm requiring only one $O(2^n)$ computation (for all n instances) is P or NP', 'LastEditDate': '2013-10-04T12:27:09.820', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10499', 'FavoriteCount': '3', 'Body': '<p>Let $a$ one decision problem and $A$ one algorithm solving it in $O(n^k)$.</p>\n\n<p>But, to construct $A_n$ we need to compute certain thing (strategy path, magic numbers, ...), we can compute that using certain general algorithm $R$ in $O(2^n)$.</p>\n\n<p>Obiously, $A$ is polynomial (then, all $A_n$ are in <strong>P</strong>) and $R$ is exponential.</p>\n\n<p>We <strong>can not</strong> solve big instances because $R$ is not practical.</p>\n\n<p>But, in practice, we will can solve big instances after a big effort computing $A_n = R(n)$.</p>\n\n<p>My question is twofold:</p>\n\n<ul>\n<li><p>How are such problems considered in theory?\nHave they been studied explicitly? Is there a particular case? some literature to read?</p></li>\n<li><p>How are such problems solved in practice?\nHave they been studied in general? Is there is a particular case? some literature to read?</p></li>\n</ul>\n', 'Tags': '<complexity-theory><decision-problem><np>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-10-04T14:37:03.027', 'CommentCount': '4', 'AcceptedAnswerId': '14811', 'CreationDate': '2013-10-04T09:50:35.823', 'Id': '14810'}{'Body': u'<p>Suppose we are given an M\xd7N matrix, with some elements are zero, some non-zero. We know the co-ordinates of non-zero elements. Now, if I am allowed to multiply a whole row or a whole column by zero one at a time what will be minimum number of operations (i.e multiplications) I will need. For example, for the matrix</p>\n\n<p>$\\begin{pmatrix}\n    0 &amp; 1 &amp; 0 \\\\\n    0 &amp; 0 &amp; 0 \\\\\n    1 &amp; 0 &amp; 1\n  \\end{pmatrix}$</p>\n\n<p>the answer is two. For this example</p>\n\n<p>$\\begin{pmatrix}\n    1 &amp; 1 &amp; 1 \\\\\n    0 &amp; 0 &amp; 1 \\\\\n    0 &amp; 0 &amp; 1\n  \\end{pmatrix}$</p>\n\n<p>the answer is two not three.</p>\n\n<p>Any help to go for head start is appreciated.</p>\n', 'ViewCount': '65', 'Title': 'What will be minimum no of operation to make whole matrix zero if one is allowed to multiply a row or column by zero?', 'LastEditorUserId': '6665', 'LastActivityDate': '2013-10-06T16:53:54.620', 'LastEditDate': '2013-10-06T16:53:54.620', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10516', 'Tags': '<algorithms><complexity-theory><graph-theory><data-structures><discrete-mathematics>', 'CreationDate': '2013-10-05T18:23:42.310', 'FavoriteCount': '1', 'Id': '14831'}{'Body': '<p>I know that Stable set cannot be approximated to constant factor. I saw a simple proof using OR product sometime back. I am unable to recall it. If anyone here knows what I am talking about could help fill my memory, that will be helpful.</p>\n\n<p>Is there a graph product $\\cdot$ such that $\\alpha(G\\cdot G)=\\alpha(G)^2$ for all  graphs $G$ and $G\\cdot G$ the product of $G$ with itself?</p>\n\n<p>I only need an answer to inapproximability to constant factor and I believe there is a one step proof for this.</p>\n\n<p>If we had such a product, then we have $\\alpha(G\\cdot G\\cdot\\cdots \\cdot G\\cdot G)=\\alpha(G)^k$. If $\\alpha(G\\cdot G\\cdot\\cdots \\cdot G\\cdot G)$ can be approximated to constant factor $\\sigma&gt;0$, then $\\alpha(G\\cdot G\\cdot\\cdots \\cdot G\\cdot G)=\\sigma\\hat\\alpha(G\\cdot G\\cdot\\cdots \\cdot G\\cdot G)=\\alpha(G)^k$ and since $0&lt;\\sqrt[k]{\\sigma}&lt;\\sigma$, we can get an approximation of $\\alpha(G)$ that is better than $\\sigma$ by $\\sqrt[k]{\\sigma\\hat\\alpha(G\\cdot G\\cdot\\cdots \\cdot G\\cdot G)}=\\alpha(G)$.</p>\n', 'ViewCount': '53', 'Title': 'Is there a graph product that is multiplicative in independence number?', 'LastEditorUserId': '9753', 'LastActivityDate': '2013-12-07T10:56:41.340', 'LastEditDate': '2013-10-06T13:53:35.667', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '14860', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-10-05T19:42:26.987', 'Id': '14833'}{'Body': '<p>Can a problem be both <em>NP-Hard</em> and <em>CoNP</em>?</p>\n\n<p>Can a problem be both <em>NP</em> and <em>CoNP-Hard</em>?</p>\n', 'ViewCount': '103', 'Title': 'CoNP and NPhard intersection', 'LastActivityDate': '2013-10-06T03:16:14.600', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '14848', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory>', 'CreationDate': '2013-10-06T03:01:49.877', 'Id': '14847'}{'Body': '<p>I have N by N symmetrical matrix with each side having the same items.</p>\n\n<pre><code>     A    B    C    D\nA    0\nB    4    0\nC    8    3    0\nD    3    1    8    0\n</code></pre>\n\n<p>In reality this would be much larger (100 x 100)</p>\n\n<p>I am trying to find a subset of a fixed size in this matrix with the highest score. For example the selection ABC would be:</p>\n\n<pre><code>  AB = 4;\n  AC = 8;\n  BC = 3;\nTotal  15\n</code></pre>\n\n<p>It is kinda like traveling salesman problem, but with the final distance only determined by the final selection. </p>\n', 'ViewCount': '82', 'Title': 'What kind of NP problem would this be', 'LastEditorUserId': '10548', 'LastActivityDate': '2013-10-08T22:44:44.390', 'LastEditDate': '2013-10-07T15:44:02.447', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10548', 'Tags': '<complexity-theory><np>', 'CreationDate': '2013-10-07T15:04:18.977', 'Id': '14886'}{'Body': '<p>A deterministic computation can only be run backward in time, if all transitions are one-to-one. This restriction is absent for non-deterministic computations. Hence it seems to me that non-deterministic computations be can run both forward and backward in time. But because the output becomes the input for the reversed computation, and the only output for a decision problem is "yes"/"no", this time reversal symmetry seems pretty useless for decision problems.</p>\n\n<p>Now I wonder whether there is some class of computational problems for which this fact would translate into a corresponding useful property. Something like the fact that "P = co-P", which is a useful property of decision problems for deterministic computations.</p>\n\n<blockquote>\n  <p>Is there a computational problem type for which the time reversal symmetry of non-deterministic computations turns into a useful property for certain problem classes?</p>\n</blockquote>\n\n<p>The computational problem types I have in mind here are the different types of requested output like</p>\n\n<ul>\n<li>decision problem</li>\n<li>optimization problem</li>\n<li>search problem</li>\n<li>counting problem</li>\n<li>function problem</li>\n</ul>\n\n<p>because the different types of expected input (that come to my mind) like</p>\n\n<ul>\n<li>offline/online problem</li>\n<li>(non-)promise problem</li>\n</ul>\n\n<p>seem to be closely tied to the computational problem itself, so that they are probably not helpful for general symmetry considerations.</p>\n', 'ViewCount': '40', 'Title': 'Is the time reversal symmetry of non-deterministic computations important?', 'LastEditorUserId': '1557', 'LastActivityDate': '2013-10-10T10:42:31.497', 'LastEditDate': '2013-10-10T10:42:31.497', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1557', 'Tags': '<complexity-theory>', 'CreationDate': '2013-10-09T00:02:34.310', 'Id': '14932'}{'Body': "<p>I can't seem to find this stated explicitly anywhere, which makes me wonder if I have it all wrong.</p>\n\n<p>So first, let's say we view problems in NP as degenerate problems in FNP, where the codomain of the binary relation is the set {true, false}.</p>\n\n<p>Second, FSAT is known to be FNP-complete, meaning that everything in FNP can be reduced to it in polynomial time. Also, FSAT is polynomial-time reducible to SAT, which is NP-complete, and then a SAT problem can be changed to anything else in NP-complete in polynomial time. So this shows that everything in FNP-complete can be changed to something in NP-complete in polynomial time.</p>\n\n<p>So the first thing shows that NP-complete $\\subset$ FNP-complete, but then the second thing shows that FNP-complete $\\subset$ NP-complete, which means that NP-complete = FNP-complete.</p>\n\n<p>So given that, it seems like everything in FNP can be reduced to any NP-complete problem in polynomial-time.</p>\n\n<p>Am I going somewhere wrong here, or do I have this all right?</p>\n", 'ViewCount': '67', 'Title': 'Does FNP-complete = NP-complete?', 'LastActivityDate': '2013-10-09T00:41:48.237', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10594', 'Tags': '<complexity-theory><np-complete><decision-problem><search-problem>', 'CreationDate': '2013-10-09T00:41:48.237', 'Id': '14937'}{'ViewCount': '192', 'Title': 'How can you bound the error of an approximation without knowing the optimal solution?', 'LastEditDate': '2013-10-11T07:28:50.080', 'AnswerCount': '1', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '10572', 'FavoriteCount': '1', 'Body': '<p>I been looking at this <a href="http://www.math.uwaterloo.ca/tsp/world/countries.html">site</a> and it says that people found solutions for TSP tours that are just 0.031% higher than the optimal tour is. Without finding the optimal tour how does they know what length it is supposed to be?</p>\n', 'Tags': '<complexity-theory><approximation>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-17T15:01:09.993', 'CommentCount': '3', 'AcceptedAnswerId': '15003', 'CreationDate': '2013-10-09T12:03:45.390', 'Id': '14945'}{'Body': '<p>It is known that HORN-3SAT is complete for $P$ under Logspace many-one reductions ($&lt;_L^m$). </p>\n\n<p>This implies that $\\bar{A} &lt;_L^m A$ for any $P$-complete problem $A$, where $\\bar{A}$ means the complement of $A$. This immediately follows from that fact that $P$ is closed under complement and the $P$-hardness of $A$. </p>\n\n<p>My question is to find such Logspace many-one reduction $\\bar{A} &lt;_L^m A$ for any $P$-complete problem $A$ (such as HORN-3SAT). The reduction must show the mapping between short certificates of $A$ and $\\bar{A}$. </p>\n\n<p>EDIT: As David stated in his comment on the case of HORN-3SAT problem,  we know that Logspace function exists but it seems that it is hard to find explicitly.</p>\n', 'ViewCount': '144', 'Title': '$P$-complete problems and Logspace reductions', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-11T07:29:59.773', 'LastEditDate': '2013-10-11T07:29:59.773', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-10-09T12:54:01.173', 'FavoriteCount': '0', 'Id': '14947'}{'ViewCount': '1579', 'Title': u'Traveling Salesman - Held\u2013Karp algorithm - BIG improvement', 'LastEditDate': '2013-10-17T22:35:11.870', 'AnswerCount': '1', 'Score': '-9', 'PostTypeId': '1', 'OwnerUserId': '10572', 'FavoriteCount': '1', 'Body': u'<p>I think that I found a polynomial solution to TSP problem. How ever in order to prove the "think" there are many questions need to be answered. I hope you be able to help me.</p>\n\n<ul>\n<li><a href="http://cs.stackexchange.com/questions/14998/traveling-salesman-heldkarp-algorithm-improvement">Part 0</a> - The first question that I asked about it, comes with <a href="https://drive.google.com/folderview?id=0B1ttIJPHEPWFTUVfSFBYb185V1k&amp;usp=sharing" rel="nofollow">sample source code</a>.</li>\n<li><strong>Part 1</strong> - The fundamentals, the basic theory of my algorithm.</li>\n<li><a href="http://cs.stackexchange.com/questions/16165/traveling-salesman-using-the-shorter-path-in-order-to-find-1">Part 2</a> - Stop condition number 1: Using the shorter path in order to find 1 </li>\n<li><a href="http://cs.stackexchange.com/questions/16166/traveling-salesman-intersections">part 3</a> - Stop condition number 2: Intersections</li>\n<li><a href="http://cs.stackexchange.com/questions/16175/traveling-salesman-intersections-looping">Part 4</a> - Stop condition number 3: Intersections Looping</li>\n<li><a href="http://cs.stackexchange.com/questions/16177/traveling-salesman-exact-algorithm">final part</a> - Exact solution</li>\n</ul>\n\n<h2>Base assumption:</h2>\n\n<p><strong>If we found the shortest route for a given input of $N$ cities (let it be called main route), so each sub route between any 2 cities on the "main route" will be also the shortest route.</strong></p>\n\n<p>This assumption is easy to prove. Lets say we found a shorter route between two cities on the "Main route". So now we can improve our main route and make him shorter, how ever this is not possible as the main route is the shortest rout by definition.</p>\n\n<p>Also I want to show you the definition of sub route,(you can skip this if you think it\'s to obvious) I will show it by example. If I have the next route: A,C,E,F,H,K so sub route between C and F is: A,C,E,F when I want to find a shorter route for this given sub route, I can only change the places of the cities C, and E, there could be only 2 options for sub routes between A, and F.</p>\n\n<p>Now I will try to show you my implementation, and I want you tell me if I made any bad assumptions or having bad calculations.</p>\n\n<p>Lets say you been given the next input of Cities: A,B,C,D,E,F,H. In order to find the shortest path you will need to perform 720 tests($(7-1)!$). I want to show you how you can cut half of those tests. </p>\n\n<p>When you will start to calculate, this is how your first tests will look like:</p>\n\n<ul>\n<li>A->B->C->D->E->F->G</li>\n<li>A-><strong>C</strong>-><strong>B</strong>->D->E->F->G</li>\n<li>A-><strong>C</strong>-><strong>B</strong>->D->E-><strong>G</strong>-><strong>F</strong></li>\n<li>A->B->C->D->E-><strong>G</strong>-><strong>F</strong> </li>\n<li>A->B->C->D->F-><strong>E</strong>-><strong>G</strong></li>\n<li>A-><strong>C</strong>-><strong>B</strong>->D-><strong>F</strong>-><strong>E</strong>->G</li>\n</ul>\n\n<p>When you start calculating test 1, you should stop when reaching city D. Stop and calculate what would be the shortest path, starting at A, finishing at D and going thru B,C. Latter you can assume that any path starting with A, going thru C,B and finished in D no matter how it would continue, if it will not start with the shortest path that you found, it will not be the shortest path. So now you can skip all the tests that start with A,B,C,D or A,C,B,D, depending on which of those paths is shorter.</p>\n\n<p>Now in order to save more than just $\\frac{(N-1)!}{2}$ calculation I will create a longer sub routes and calculate the shortest path between them, dropping all other options. The only problem with that, is I may repeatedly calculate the same sub routes, as I may find them in different parts of the main route. For example: for the given route: A,B,C,D,E,F,G,H lets say that I found the shortest route between B to E thru C,D. But that was just from my first test of: A,B,C,D,E,F,G,H. Later I will come in to testing: A,F,G,H,B,D,C,E as eventually I will have to test all the options. So again in order to drop part of those options I will try to find what will be the shortest path between B to E thru D,C(Remember I can can drop calculation from any part of the route) and will have to calculate it again. To avoid that I will store all the sub routes calculation in to maps.</p>\n\n<p>So lets see how long it will take me to create all the maps with K cities length. First I need to select the starting city, got N options for that, now select the last city, got $N -1$ options for that, and now select all the cities in between order is not metter and without repetition. I will use <a href="http://www.mathsisfun.com/combinatorics/combinations-permutations-calculator.html" rel="nofollow">this</a> formula for that: </p>\n\n<blockquote>\n  <p>$\\frac{N!}{ (N - R)!R!}$</p>\n</blockquote>\n\n<p>In our case $N$ is $N-2$ and $R$ is $K - 2$ so we will get:</p>\n\n<blockquote>\n  <p><strong>$\\frac{N!} {(N - K)!(K - 2)!}$</strong> The number of $K$ cities length maps from $N$ cities.</p>\n</blockquote>\n\n<p>Now lets assume that we created all the $K$ length maps and we want to create $2K - 1$ length maps. We do not need to start from 0, we can use our $K$ length maps to help us. Like this:</p>\n\n<p>Lets say we want to create the next map of 7 cities and we already created a map of 4 cities. So the cities are: A,B,C,D,E,F,H. Our first test will be: A,B,C,D,E,F,H. We can save us lots of time if we split it in two maps of 4 cities. \n - Map 1: From A to D thru B,C\n - Map 2: From D to H thru E,F</p>\n\n<p>Lets see how many maps like this could be: There are 5 options for the common city in the middle and there are $2C4$ options for the first two cities( 2 choice 4, selecting 2 cities out of 4. Order is not important, repetition is not allowed) and the last 2 cities is just what reminds. After summing it up we will have get 30 options to create 1 map of 7 cities.\nLets say it in more general way: To create all the maps for K length cities(assuming that we already created all the $\\frac{(K + 1)}{2}$ length cities maps) will be: $K - 2$ options for the common city at the middle. And $\\frac{(K - 3)} {2}C(K - 3)$ options for the cities that belongs to Map 1. Summing all together we will get:</p>\n\n<blockquote>\n  <p>$\\frac{(k - 2)!}{(\\frac{K - 3}{2}!)^2}$ The number of calculation need to be done to create $K$ cities length map when we already created $\\frac{K + 1}{2}$ cities length map.</p>\n</blockquote>\n\n<p>Now in order to find the shortest path for $N$ cities length we need to create all the maps with $\\frac{N + 1}{2}$ length and just one map with $N$ length. In cases when $N$ is not belong to $f(x) = f(x - 1)  * 2 - 1$; we will still need to create the biggest maps length group possible but we will have more than 1 city in common when we will split the problem in 2 maps. For example when N = 10. We will create all the 4 length maps, and all the 7 length maps. Lets give a sample: For the given cities A,B,C,D,E,F,G,H,I,A find the shortest path. We will split it in two maps of 7.</p>\n\n<ul>\n<li>Map 1: From A to G thru B,C,D,E,F</li>\n<li>Map 2: From D to A thru E,F,G,H,I</li>\n</ul>\n\n<p>For map 1 we will choose who is going to be the last city, we have 8 options to that.\nAnd we have $5C8$ options for the cities of the map 1, and the rest is going to map 2. You may ask yourself now how could it be that map 1 will actually have the exact common cities with map 2, isn\'t there a chance that they be ordered in some other way. Well according to my base assumption there isn\'t. so if we will sum it all together we will get: 448 options for that. Now lets say it in general way: To find the shortest path for input of $N$ cities, we will first need to find all the maps with $length &lt; N$ that belongs to $f(x) = f(x - 1)  * 2 - 1; F(0) = 4$. Lets say that the longest map of all those maps is G length and $f^{-1}(G) = G\'$( sorry for not knowing how to express $G$ with $N$). So we will have $N - 2$ options for the last city of map 1 and $(G - 2)C(N - 2)$ summing it up will give:</p>\n\n<blockquote>\n  <p>$\\frac{(N - 2)!} {(N - G)!(G - 2)!}$</p>\n</blockquote>\n\n<p>So the efficiency of finding the shortest path for N cities will be(Also added the time it will take to create the first 4 length maps) </p>\n\n<blockquote>\n  <p>$(\\frac{N(N-1)(N-2)(N-3)}{2}) + (\\sum_{i}^{G\'}\\frac{(f(i) - 2)!}{(\\frac{f(i) - 3}{2}!)^2})+ (\\frac{(N - 2)!} {(N - G)!(G - 2)!})$</p>\n  \n  <p>Using $f(x)=f(x\u22121)\u22172\u22121;F(0)=4$</p>\n</blockquote>\n\n<p>I think its better than $O(2^N)$</p>\n\n<p>Please help me to do the math, and tell me if I have any mistakes in my math or conclusions. Also please avoid writing an answers without fully understanding what I stated you are welcome to ask me more in <a href="http://chat.stackexchange.com/rooms/11065/tsp-chat">chat</a>.</p>\n', 'ClosedDate': '2014-02-02T11:24:39.057', 'Tags': '<complexity-theory><np-complete><np-hard><traveling-salesman>', 'LastEditorUserId': '10572', 'LastActivityDate': '2013-10-18T07:59:35.663', 'CommentCount': '12', 'CreationDate': '2013-10-14T14:53:59.097', 'Id': '16076'}{'Body': "<p>I've got this problem:</p>\n\n<blockquote>\n  <ul>\n  <li><p>Write down a definition of P-completeness analogous to the definition of\n  NP-completeness, i.e., using polynomial-time reductions.</p></li>\n  <li><p>Which problems are P-complete in this sense, and why?</p></li>\n  <li>Thus, what is the problem, i.e., what must be changed if the goal is to come\n  up with a more interesting notion of P-completeness?</li>\n  </ul>\n</blockquote>\n\n<p>I have an idea about the first part, but I don't have any idea about the second and third part. The first part is like the NP-Complete, and small change for P-Complete, which is wrong I know, but I want it that way!</p>\n", 'ViewCount': '129', 'Title': 'Definition P-Completeness', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-28T07:43:43.407', 'LastEditDate': '2013-10-28T07:43:43.407', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10795', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-10-16T14:33:48.637', 'FavoriteCount': '1', 'Id': '16138'}{'Body': '<p>In the text book, Introduction to Algorithm, 3rd Edition.</p>\n\n<p>In the chapter, <strong>Approximation Algorithms</strong> and for the problem <strong>Travelling Salesman Problem</strong>, the author says: </p>\n\n<p><img src="http://i.stack.imgur.com/99jYL.png" alt="enter image description here"></p>\n\n<p>I am wondering how triangle inequality gives rise to this assertion? It seems that this property is not that important, as I searched through the rest of this section, it does not appear.</p>\n', 'ViewCount': '143', 'Title': 'without triangle inequality, finding good approximate tours for TSP in polynomial time is impossible unless P=NP?', 'LastActivityDate': '2013-10-18T00:46:42.290', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4662', 'Tags': '<algorithms><complexity-theory><traveling-salesman><approximation-algorithms>', 'CreationDate': '2013-10-16T17:31:49.740', 'Id': '16143'}{'Body': u'<p>Both <a href="http://en.wikipedia.org/wiki/2-satisfiability" rel="nofollow" title="this text appears when you mouse over">wikipedia</a> and my lecturer explained how the 2 satisfiability problem work. However, I am finding it really hard understanding how this formula:</p>\n\n<pre><code>xvy\u2261 \xacx--&gt;y \u2261 \xacy --&gt;x\n</code></pre>\n\n<p>Then breaks down the following conjectures :</p>\n\n<pre><code>(\xacx v y) &amp; (\xacy v z) &amp; (\xacz v w) &amp; (\xacw v \xacx) &amp; \n(x v \xacy) &amp; (y v \xacz) &amp; (z v \xacw) &amp; (w v x)\n</code></pre>\n\n<p>is converted to an implcation graph.</p>\n\n<p>Heres my attempt:</p>\n\n<pre><code> (\xacx v y) = (\xacy--&gt;x)\n\n          = (\xacx--&gt;y)\n</code></pre>\n\n<p>but this cannot be right, as they have diffrent truth tables:</p>\n\n<pre><code>(\xacy--&gt;x)\n</code></pre>\n\n<p>1 0 <strong>0</strong> 0</p>\n\n<p>1 0   <strong>1</strong>  1</p>\n\n<p>0 1   <strong>1</strong>   0</p>\n\n<p>0 1   <strong>1</strong>   1</p>\n\n<pre><code>(\xac x--&gt;y)\n</code></pre>\n\n<p>1 0 <strong>0</strong> 0</p>\n\n<p>0 1 <strong>1</strong> 1</p>\n\n<p>1 0 <strong>0</strong> 0</p>\n\n<p>0 1 <strong>1</strong> 1</p>\n\n<p>I understand once you have the conjectures converted to implication, how to construct the implication graph and find out if its not satisfiable (bad loops).</p>\n\n<p>Could someone please explain clearly how to break down the conjectures to implications?</p>\n', 'ViewCount': '219', 'Title': 'Converting a 2-SAT formula into an implication graph', 'LastEditorUserId': '472', 'LastActivityDate': '2013-10-21T12:57:30.320', 'LastEditDate': '2013-10-18T21:04:10.513', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '16200', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7173', 'Tags': '<complexity-theory><satisfiability>', 'CreationDate': '2013-10-17T14:06:14.303', 'Id': '16159'}{'Body': "<p>Problem Statement:\nSuppose we a thousands of words and we need to maintain these words in a data structure in such a way that we should be able to find all anagrams for a given string.\nI tried to achieve this with O(1) complexity.</p>\n\n<p>I am looking for a algorithm to implement above scenario. I implemented this problem with below algo, but i feel that we can improve its complexity. Any suggestion will be helpful.</p>\n\n<p>Algorithms:</p>\n\n<p>Here is trick to utilize hash code, we can also use character histogram.</p>\n\n<p>Step 1:Create an array of prime numbers.</p>\n\n<pre><code>   int primes[] = {2, 3, 5, 7, ...};\n\n   We are using prime number to avoid false collisions.\n</code></pre>\n\n<p>Step 2:Create a method to calculate hash code of a word\\string.</p>\n\n<pre><code>   int getHashCode(String str){\n     int hash = 31;\n     for(i =0 to length of str){\n        hash = hash*primes['a' - str.charAt[i]];\n     }\n     return hash;\n   }\n</code></pre>\n\n<p>Step 3: Now store all words in a HashMap.</p>\n\n<p>void loadDictionary(String[] words){</p>\n\n<pre><code>  for( word from words for i = 0 to length of words)   {\n     int hash  = getHashCode(word);\n     List&lt;String&gt; anagrams = dictionary.get(hash);\n     if(anagrams ! = null){\n         anagrams.add(word);\n     } else\n        List&lt;String&gt; newAnagrams = new ArrayList&lt;String&gt;();\n        newAnagrams.add(word);\n        dictionary.put(hash, newAnagrams);\n     }\n }\n}\n</code></pre>\n\n<p>Step 4: Now here is the approach to find anagrams:</p>\n\n<pre><code>   int findNumberOfAnagrams(String str){\n\n   List&lt;String&gt; anagrams = dictionary.get(getHashCode(str));\n      return anagrams.size();\n\n   }\n</code></pre>\n", 'ViewCount': '635', 'Title': 'Algorithm to write a dictionary using thousands of words to find all anagrams for a given string with O(1) complexity', 'LastEditorUserId': '6665', 'LastActivityDate': '2013-10-19T14:15:13.607', 'LastEditDate': '2013-10-19T11:43:38.863', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10848', 'Tags': '<algorithms><complexity-theory><time-complexity><strings>', 'CreationDate': '2013-10-19T07:27:25.860', 'FavoriteCount': '1', 'Id': '16221'}{'Body': '<p>Given a procedure/function </p>\n\n<p>$Select(S,r)$ - which selects element of rank r from set S\nwhich uses at most $|S|. constant$ comparisons</p>\n\n<p>We design another function $Multiselect(S,R)$\nwith $R =\\{r_1&lt;r_2&lt;...&lt;r_k\\}$<br>\nreturns $X =\\{x_1&lt;x_2&lt;...&lt;x_k\\}$  such that rank of $x_i$ is $r_i$</p>\n\n<p>What is the minimum no of comparisons for this function?</p>\n\n<p>From Wikipedia I found the upper bound for it -\n<img src="http://i.stack.imgur.com/Nmfem.png" alt="upper bound"></p>\n\n<p>But while utilising this for deriving the answer I got it totally messed up!<br>\nI tried using algorithm to utilise Select(S,r) repeatedly each time<br>\neach time decreasing the search space by logn  ... but I guess the answer could be found<br>\nin a more concise mathematical way.</p>\n\n<p>By the way, answer given was - $constant.|S|(1+logR)$  </p>\n', 'ViewCount': '44', 'Title': 'Selection of K elements of given ranks', 'LastEditorUserId': '8514', 'LastActivityDate': '2013-10-21T20:13:13.250', 'LastEditDate': '2013-10-21T20:13:13.250', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '16243', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8514', 'Tags': '<complexity-theory><algorithm-analysis>', 'CreationDate': '2013-10-19T21:20:45.603', 'Id': '16239'}{'Body': '<p>I need to prove that $n^4+2n = \\Omega (n^2)$</p>\n\n<p>Which means I need to point two constants $c_1,c_2$ that from $n_0$:\n$$ c_1 \\leq \\frac{\\log(n^4+2n)}{\\log(n^2)} \\leq c_2$$</p>\n\n<p>Now I know that:\n$\\lim_{n \\to \\infty } \\frac{\\log(n^4+2n)}{\\log(n^2)} = 2$ so I can choose $c_1 = 0.5$ and $c_2 = 3$ but how do I do I calculate the $n_0$ that this sentence become true to?</p>\n', 'ViewCount': '51', 'Title': 'Proving $f = \\Omega (h)$', 'LastActivityDate': '2013-10-20T13:35:13.730', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '16258', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10875', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-10-20T12:49:45.960', 'Id': '16255'}{'Body': '<p>How do we prove $M$ that is a deterministic random access machine that decides a problem $A$ for an input $i$, and $u_M(i)$ is the set of addresses of those registers that occur at least once with $s$ steps and a configuration of $C_0,\\dots,C_s$ where each configuration is of the form $C_i=(k_i,R_i)$, were $k_i$ is the program counter and a mapping $R_i$ runs in polynomial time if it runs in logarithmic space.</p>\n', 'ViewCount': '81', 'Title': 'Deterministic Random access machine and polynomial time', 'LastEditorUserId': '7269', 'LastActivityDate': '2013-10-21T02:10:25.430', 'LastEditDate': '2013-10-20T13:24:18.860', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '7269', 'Tags': '<complexity-theory><polynomial-time>', 'CreationDate': '2013-10-20T13:13:09.723', 'Id': '16256'}{'Body': "<p>I have this question I'm struggling with. </p>\n\n<p>Let $A=\\{&lt;i,n&gt;|\\;n \\in \\phi ^{(i)}\\}$. In other words, $A$ is the language defined by the set of all pairs $&lt;i,n&gt;$ such that $n$ is $\\leq_m$ to the $i$th Turing jump.\nA is definitely not an arithmetically definable language, and you can prove this by contradiction. </p>\n\n<p>I have to find a language, let's say $B$, that is more complex than $A$ $i.e.$ $B\\nleq_T A$. I thought about $B=\\{&lt;i,n&gt;|\\;n \\not\\in \\phi ^{(i)}\\}$, but I'm not sure about my reasoning, I think an oracle turing machine with an oracle $A$ couldn't reduce to $B$..</p>\n\n<p>And one last thing, do you think there exists a language that is more complex than any other (it doesn't reduce to anything)?</p>\n\n<p>If you have any hints that could help me solve those two questions I would be really grateful! </p>\n", 'ViewCount': '62', 'Title': 'What would be a not arithmetically definable language that is not Turing reducible to another given not arithmetically definable language?', 'LastActivityDate': '2013-10-24T16:13:26.107', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '16405', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10888', 'Tags': '<complexity-theory><computability><reductions><arithmetic>', 'CreationDate': '2013-10-21T00:29:52.033', 'Id': '16271'}{'Body': u'<p>I am trying to convert the following 2-sat clauses to implications and then draw the implication graph.</p>\n\n<p>The clauses are: <code>{\xacxvy}, {\xacyvz}, {\xaczvw} ,{\xacwvu},{\xacuv\xacx},{xvw},{\xacwvx}</code></p>\n\n<p>I converted the boolean literals into implications so I could construct the implication graph:</p>\n\n<p><code>{\xacxvy}</code>: I have <code>x--&gt;y</code> and <code>\xacx --&gt;\xacy</code></p>\n\n<p><code>{\xacyvz}</code> : I have <code>y--&gt;z</code> and <code>\xacy--&gt;\xacz</code></p>\n\n<p><code>{\xaczvw}</code> : I have <code>z--&gt;w</code> and <code>\xacz--&gt;\xacw</code></p>\n\n<p><code>{\xacwvu}</code> : I have <code>w--&gt;u</code> and <code>\xacw---&gt;\xacu</code></p>\n\n<p><code>{\xacuv\xacx}</code> : I have <code>u--&gt;\xacx</code> and <code>\xacx--&gt;\xacu</code> </p>\n\n<p><code>{xvw}</code> : I have <code>\xacx--&gt;w</code> and <code>\xacw--&gt;x</code></p>\n\n<p><code>{\xacwvx}</code> : I have <code>w--&gt;x</code> and <code>\xacw--&gt;\xacx</code></p>\n\n<p>Am I doing this right? If so, I have constructed this implication graph to prove it is not satisfiable.</p>\n\n<p><img src="http://i.stack.imgur.com/tdXrm.png" alt="enter image description here"></p>\n\n<p>I would argue that these literals are not satisfiable because of the infinite loops you can have from \xacw \xacx \xacy \xacz \xacw and w x y z w. Is this a sufficient enough explanation?</p>\n\n<p>Thanks in advance!</p>\n', 'ViewCount': '190', 'Title': 'Drawing an implication graph for 2-SAT clauses', 'LastEditorUserId': '472', 'LastActivityDate': '2013-10-22T10:01:51.437', 'LastEditDate': '2013-10-22T10:01:51.437', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '16318', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7173', 'Tags': '<complexity-theory><logic><satisfiability>', 'CreationDate': '2013-10-21T18:35:42.693', 'Id': '16311'}{'ViewCount': '92', 'Title': "Courcelle's Theorem: Looking for papers", 'LastEditDate': '2013-10-22T09:51:25.143', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1382', 'FavoriteCount': '1', 'Body': '<p>I am looking for an easy and introductory paper on the proof of <a href="http://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle\'s Theorem</a>. I am also interested in its connection to <a href="http://en.wikipedia.org/wiki/Parameterized_complexity">parameterized complexity</a> regarding the <a href="http://en.wikipedia.org/wiki/Treewidth">treewidth</a>.</p>\n\n<p>I am only a beginner in this field.</p>\n\n<p>Any suggestions?</p>\n', 'Tags': '<complexity-theory><graph-theory><reference-request><discrete-mathematics><parametrized-complexity>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-12T21:25:05.823', 'CommentCount': '0', 'AcceptedAnswerId': '16326', 'CreationDate': '2013-10-22T09:20:33.627', 'Id': '16324'}{'ViewCount': '102', 'Title': 'Direct reduction from Near-Clique to Clique', 'LastEditDate': '2013-10-22T13:16:24.780', 'AnswerCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10913', 'FavoriteCount': '2', 'Body': '<p>An undirected graph is a Near-Clique if adding one more edge would make it a clique. Formally, a graph $G=(V,E)$ contains a near-clique of size&nbsp;$k$ if there exists $S\\subseteq V$ and $u,v\\in S$ where $|S|=k$, $(u,v)\\notin E$, and $S$&nbsp;forms a clique in $(V,E\\cup\\{(u,v)\\})$. How can I show a direct reduction from Near-Clique to Clique?</p>\n', 'Tags': '<complexity-theory><graph-theory><reductions><np>', 'LastEditorUserId': '9550', 'LastActivityDate': '2013-10-23T03:08:34.873', 'CommentCount': '1', 'AcceptedAnswerId': '16349', 'CreationDate': '2013-10-22T09:31:12.100', 'Id': '16325'}{'ViewCount': '254', 'Title': 'Does coNP-completeness imply NP-hardness?', 'LastEditDate': '2013-10-23T21:26:48.343', 'AnswerCount': '2', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '8877', 'FavoriteCount': '1', 'Body': '<p>Does coNP-completeness imply NP-hardness? In particular, I have a problem that I have shown to be coNP-complete. Can I claim that it is NP-hard? I realize that I can claim coNP-hardness, but I am not sure if that terminology is standard.</p>\n\n<p>I am comfortable with the claim that if an NP-complete problem belonged to coNP, then NP=coNP. However, <a href="http://www.csie.ntu.edu.tw/~lyuu/complexity/2004/c_20041117.pdf" rel="nofollow">these lecture notes</a> state that if an NP-hard problem belongs to coNP, then NP=coNP. This would then suggest that I cannot claim that my problem is NP-hard (or that I have proven coNP=NP, which I highly doubt).</p>\n\n<p>Perhaps, there is something wrong with my thinking. My thought is that a coNP-complete problem is NP-hard because:</p>\n\n<ol>\n<li>every problem in NP can be reduced to its complement, which will belong to coNP.</li>\n<li>the complement problem in coNP reduces to my coNP-complete problem.</li>\n<li>thus we have a reduction from every problem in NP to my coNP-complete, so my problem is NP-hard.</li>\n</ol>\n', 'Tags': '<complexity-theory><np-hard>', 'LastEditorUserId': '8877', 'LastActivityDate': '2013-10-24T14:03:18.837', 'CommentCount': '1', 'AcceptedAnswerId': '16376', 'CreationDate': '2013-10-23T19:46:17.283', 'Id': '16371'}{'Body': '<p>I have graphs $G_k$ and $H_k$ with $|\\mathcal{V}(G_k)|=|\\mathcal{V}(H_k)|^{2k}=n^{2k}$ with $k\\in\\Bbb N$ that pass sanity checks such as no-homomorphism lemma. Are there free and easy to use tools to test graph homomorphism from $G$ to $H$?</p>\n', 'ViewCount': '167', 'Title': 'Software for testing graph homomorphism', 'LastEditorUserId': '472', 'LastActivityDate': '2013-10-25T19:08:17.933', 'LastEditDate': '2013-10-24T13:29:06.540', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-10-23T21:36:20.043', 'FavoriteCount': '0', 'Id': '16375'}{'Body': "<p>I'm having trouble understanding why it's easy to detect negative-weight cycles (Bellman Ford) but hard to find the maximum weight cycle in an undirected graph. </p>\n\n<p>If we negate the weight of each edge, we can easily find if there are any cycles with total weight > 0. However it must not be easy to find if there are any cycles with weight > 1 or else we could repeat with 2, 3, 4 etc until the answer is no.</p>\n\n<p>Is this correct? Why is it so much harder to detect if there exists a cycle with weight > 1 then to find if there is a cycle with weight > 0?</p>\n", 'ViewCount': '97', 'Title': 'Negative weight cycle vs maximum weight cycle', 'LastActivityDate': '2013-11-07T21:20:02.610', 'AnswerCount': '4', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '10987', 'Tags': '<complexity-theory><graph-theory>', 'CreationDate': '2013-10-26T13:13:26.430', 'Id': '16442'}{'Body': "<p>I am unclear about finding the memory complexity of an algorithm.</p>\n\n<p>Some places refer memory complexity as what container would be carrying for instance:</p>\n\n<pre><code>for i = 1 to n-1\n     if d[i] == d[i + 1]\n           d[i] = (d[i] + 5) mod 13\n</code></pre>\n\n<p>Is considered as having $\\theta(N)$ memory complexity.</p>\n\n<p>At some other places how much data we write to a container is a complexity for instance:</p>\n\n<pre><code>reverse_list(n)\n\n    Stack res\n    while (n != NULL)\n         res push n\n         n = n-&gt;next\n    while (res != null) \n         a = pop res\n         print a\n</code></pre>\n\n<p>Is considered as having a memory complexity of $\\theta(N)$ too. Moreover:</p>\n\n<p>Such thing is considered having $\\theta(1)$ memory complexity</p>\n\n<pre><code>reverse_list(head)\n    last = NULL;\n    while(last != head)\n        current = head\n        while(current-&gt;next != last)\n            current = current-&gt;next\n        print current\n        last = current\n</code></pre>\n\n<p>I know how these algorithms work and what they do, but I don't understand how are we meant to be analysing their memory complexity. Could someone explain that please?</p>\n", 'ViewCount': '472', 'Title': 'Memory complexity?', 'LastEditorUserId': '8849', 'LastActivityDate': '2013-10-28T15:14:42.793', 'LastEditDate': '2013-10-28T15:14:42.793', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '16464', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8849', 'Tags': '<complexity-theory><algorithm-analysis><asymptotics><space-complexity>', 'CreationDate': '2013-10-27T04:26:35.907', 'Id': '16461'}{'Body': '<p>In Theoretical Computer Science, which one is more important? Computability of a problem or Complexity of a problem?</p>\n', 'ViewCount': '72', 'ClosedDate': '2013-10-27T15:58:25.267', 'Title': 'Computability vs Complexity?', 'LastActivityDate': '2013-10-27T14:05:27.103', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '16471', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10700', 'Tags': '<algorithms><complexity-theory><computability>', 'CreationDate': '2013-10-27T10:35:47.770', 'Id': '16466'}{'ViewCount': '111', 'Title': 'Complexity of deciding the satisfiability of a quasi-monotone CNF formula', 'LastEditDate': '2013-11-01T22:52:30.737', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '10228', 'FavoriteCount': '2', 'Body': '<p>A <em>quasi-monotone CNF formula</em> is a formula where each variable appears at most once as a positive literal (and any number of times as a negative literal). </p>\n\n<p>What is the complexity of deciding its satisfiability?</p>\n', 'Tags': '<complexity-theory><np-complete><satisfiability><decision-problem>', 'LastEditorUserId': '10228', 'LastActivityDate': '2013-11-01T22:52:30.737', 'CommentCount': '0', 'AcceptedAnswerId': '16492', 'CreationDate': '2013-10-28T00:04:09.943', 'Id': '16483'}{'Body': '<p>The TWICE-3SAT is defined as \n$$TWICE-3SAT=\\{(\\varphi) | \\varphi \\text{ has at least two different satisfying assignments } \\}$$ \nHow do we prove it is in NP-complete?</p>\n', 'ViewCount': '134', 'ClosedDate': '2013-11-11T13:48:09.013', 'Title': 'Proving TWICE-3SAT is NP-complete', 'LastActivityDate': '2013-10-28T14:15:23.030', 'AnswerCount': '2', 'CommentCount': '8', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '7269', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'CreationDate': '2013-10-28T10:45:48.040', 'Id': '16493'}{'Body': "<p>Consider $\\Pi$ to be the problem to decide if there is a subset of numbers that sum to $0$ in the given list of integers. </p>\n\n<p>How does one construct a promise problem equivalent to $xSAT$ from this? $xSAT$ is in $NP\\cap coNP$. </p>\n\n<p>How is it possible that the original problem was NP complete and the transformed problem is in coNP? </p>\n\n<p>Doesn't this mean NO instances also have short certificates for the original problem $\\Pi$?</p>\n", 'ViewCount': '64', 'Title': 'Promise problems', 'LastEditorUserId': '9753', 'LastActivityDate': '2013-10-28T16:32:29.723', 'LastEditDate': '2013-10-28T16:32:29.723', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2013-10-28T15:56:10.873', 'Id': '16505'}{'Body': '<p>To continue this <a href="http://cs.stackexchange.com/questions/16483/complexity-of-deciding-the-satisfiability-of-a-quasi-monotone-cnf-formula">post</a>, let us define the Monotone$(+, 2^-)$-SAT problem: </p>\n\n<p>Given a monotone CNF formula $F^+$, where each variable appears exactly once (as a positive literal), and a monotone 2-CNF formula $F_2^-$ defined on the same variables as $F^+$, where all variables are negated. Is $F^+ \\land F_2^-$ satisfiable ?</p>\n\n<p>Is this problem NP-complete?</p>\n', 'ViewCount': '128', 'Title': 'Complexity of Monotone (+,2) SAT problem?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-05T16:22:04.540', 'LastEditDate': '2013-11-05T16:22:04.540', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '10228', 'Tags': '<complexity-theory><np-complete><decision-problem><complexity-classes>', 'CreationDate': '2013-11-01T22:56:57.180', 'FavoriteCount': '1', 'Id': '16634'}{'Body': '<p>Let $\\phi$ be a 3-CNF formula over variables $x_1,x_2,\\ldots,x_n$. Every variable $x_i$, $i \\in [n]$, occurs equally many times as a positive literal and as a negative literal in $\\phi$. </p>\n\n<p>Is it NP-complete to decide the satisfiability of such a formula? Assuming it is, I would be interested in knowing if it has a special name. Has it perhaps also been investigated somewhere?</p>\n', 'ViewCount': '182', 'Title': '3-SAT where variables occur equally many times as a positive literal and as a negative literal', 'LastActivityDate': '2013-11-06T11:50:13.120', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '16765', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<complexity-theory><np-complete><satisfiability><decision-problem>', 'CreationDate': '2013-11-03T14:27:40.600', 'Id': '16672'}{'Body': "<p>I'm trying to prove that every language that is not the empty set or {0,1}* is complete for NL (nondeterministic logarithmic space) under polynomial-time Karp reductions.</p>\n\n<p>I'm really not sure how to even approach this problem or what languages are being discussed if you exclude both the empty set and {0,1}*. Any suggestions to get me going in the right direction? Thanks!</p>\n\n<p><strong>Edit:</strong></p>\n\n<p>I feel like I may still be understanding the problem incorrectly. I seem to be finding that polynomial-time reductions can't be used to define NL completeness, but that's what I feel this question is asking. What am I thinking about wrongly here? Thanks.</p>\n", 'ViewCount': '95', 'Title': 'Proving languages are complete on NL?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-03T22:52:22.417', 'LastEditDate': '2013-11-03T22:52:22.417', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11153', 'Tags': '<complexity-theory><reductions><polynomial-time>', 'CreationDate': '2013-11-03T18:01:48.380', 'Id': '16677'}{'ViewCount': '82', 'Title': 'Is MIN or MAX-True-2-XOR-SAT NP-hard?', 'LastEditDate': '2013-11-04T19:22:00.093', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2755', 'FavoriteCount': '1', 'Body': '<p><strong>Is there a proof or reference that $\\left\\{\\text{MAX},\\text{MIN}\\right\\}\\text{-True-2-XOR-SAT}$ is $NP$-hard, or that it (the decision version) is in $P$?</strong></p>\n\n<p>Let:</p>\n\n<p>$$\\Phi\\left(\\mathbf x\\right)={\\huge\\wedge}_{i}^{n}C_i,\\\\\n\\forall_{C_i} \\left.C_i=(p \\oplus q)\\right|_{\\left(p\\in \\mathbf x \\vee\\neg p\\in\\mathbf x\\right),\\left(q\\in \\mathbf x \\vee\\neg q\\in\\mathbf x\\right)}\n$$</p>\n\n<p>The $\\text{2-XOR-SAT}$ problem is to find a satisfying assignment of $\\mathbf x$ that would make $\\Phi\\left(\\mathbf x\\right)=T$. This is in $P$, as it can be encoded in a set of linear equations mod $2$.</p>\n\n<p>The $\\left\\{\\text{MAX},\\text{MIN}\\right\\}\\text{-True-2-XOR-SAT}$ problems are to maximize or minimize the number of true values in $\\mathbf x$, respectively, subject to the constraint that $\\Phi\\left(\\mathbf x\\right)=T$.</p>\n', 'Tags': '<complexity-theory><np-hard><satisfiability>', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-11-04T19:22:00.093', 'CommentCount': '5', 'AcceptedAnswerId': '16689', 'CreationDate': '2013-11-03T23:08:22.110', 'Id': '16682'}{'Body': u"<p>I'm trying to prove that the language SPACE TMSAT (where SPACE TMSAT = {\u27e8$M$, $w$, $1^n$\u27e9 : DTM $M$ accepts $w$ in space $n$}) is PSPACE-complete.</p>\n\n<p>My solution is as follows:<br>\nSPACE TMSAT $= \\{&lt;M,w,1^{n}&gt; :$ DTM $M$ accepts $w$ in space $n\\}$ can only be computed by running machine $M$ on $w$. As this forces the allowance of the computation of any PSPACE language, SPACE TMSAT is PSPACE-complete.</p>\n\n<p>Does this solution make sense? Am I being too hand wavy? Any other suggestions or critiques? Thanks!</p>\n", 'ViewCount': '100', 'ClosedDate': '2013-11-10T16:59:53.130', 'Title': 'Proving that the language SPACE TMSAT is PSPACE-complete?', 'LastActivityDate': '2013-11-06T08:49:32.537', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11153', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-11-04T02:38:41.303', 'Id': '16690'}{'Body': '<p>What is the complexity of MIN-2-XOR-SAT and MAX_2-XOR-SAT?  Are they in P?  Are they NP-hard?</p>\n\n<p>To formalize this more precisely, let</p>\n\n<p>$$\\Phi\\left(\\mathbf x\\right)={\\huge\\wedge}_{i}^{n}C_i,$$</p>\n\n<p>where $\\mathbf{x} = (x_1,\\dots,x_m)$ and each clause $C_i$ is of the form $(x_i \\oplus x_j)$ or $(x_i \\oplus \\neg x_j)$.</p>\n\n<p>The $\\text{2-XOR-SAT}$ problem is to find an assignment to $\\mathbf{x}$ that satisfies $\\Phi$.  This problem is in $P$, as it corresponds to a system of linear equations mod $2$.</p>\n\n<p>The $\\text{MAX-2-XOR-SAT}$ problem is to find an assignment to $\\mathbf{x}$ that maximizes the number of clauses that are satisfied.  The $\\text{MIN-2-XOR-SAT}$ problem is to find an assignment to $\\mathbf{x}$ that minimizes the number of clauses that are satisfied.  What are the complexities of these problems?</p>\n\n<p>Inspired by <a href="http://cs.stackexchange.com/q/16682/755">Is MIN or MAX-True-2-XOR-SAT NP-hard?</a></p>\n', 'ViewCount': '108', 'Title': 'MIN-2-XOR-SAT and MAX-2-XOR-SAT: are they NP-hard?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-04T19:19:55.910', 'LastEditDate': '2013-11-04T19:19:55.910', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<complexity-theory><optimization><np-hard><satisfiability>', 'CreationDate': '2013-11-04T03:28:01.333', 'Id': '16691'}{'Body': '<p>It is well known that any CNF formula can be transform in polynomial time into a 3-CNF formula  by using new variables (<a href="http://en.wikipedia.org/wiki/Boolean_satisfiability_problem#3-satisfiability" rel="nofollow">see here</a>). If using new variables is not allowed, it is not always possible (take for instance the single clause formula : $(x_1 \\lor x_2 \\lor x_3 \\lor x_4)$). </p>\n\n<p>Let define the (SAT to 3-SAT) problem : Given $F$, a CNF formula. Is it possible to transform $F$ into an equivalent 3-CNF defined <em>on the same variables</em> as $F$ ? - where "equivalent" means with the same set of models.</p>\n\n<p>What is the complexity of this problem ?</p>\n\n<p><strong>Edit</strong> : It has been shown <a href="http://cstheory.stackexchange.com/questions/19821/transform-a-cnf-into-an-equivalent-3-cnf-defined-on-the-same-variables">on cstheory</a> that the problem is co-NP hard.</p>\n', 'ViewCount': '184', 'Title': 'Complexity of (SAT to 3-SAT) Problem?', 'LastEditorUserId': '10228', 'LastActivityDate': '2013-12-24T00:47:22.790', 'LastEditDate': '2013-12-23T22:53:00.603', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '10228', 'Tags': '<complexity-theory><satisfiability><decision-problem><complexity-classes>', 'CreationDate': '2013-11-05T15:46:40.127', 'FavoriteCount': '1', 'Id': '16741'}{'Body': "<p>I'm studing P and NP complexity classes. I like know, why is SAT not in P? Is it because I can not determine if any Boolean expression is satisfiable?</p>\n", 'ViewCount': '54', 'ClosedDate': '2013-11-08T13:17:52.880', 'Title': 'Why is SAT not in P?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-08T13:16:31.463', 'LastEditDate': '2013-11-08T13:16:31.463', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '11241', 'Tags': '<complexity-theory><satisfiability><p-vs-np>', 'CreationDate': '2013-11-07T23:50:44.720', 'Id': '16807'}{'Body': u'<p>Consider the following 3-SAT variant defined over the variables $x_1,\\ldots,x_n$. In the $k$P$k$N-3SAT problem each variable $x_j$, $j \\in [n]$, occurs exactly $k$ times as a positive literal in $\\phi$, and exactly $k$ times as a negative literal in $\\phi$, where $\\phi$\xa0is a 3-CNF formula. The problem is then to decide if such a formula has a satisfying assignment.</p>\n\n<blockquote>\n  <p>Is the $k$P$k$N-3SAT problem NP-complete?</p>\n</blockquote>\n\n<p>In the $m$P$n$N-SAT problem each positive literal occurs exactly $m$ times in $\\phi$, and each negative literal occurs exactly $m$ times in $\\phi$, where $\\phi$ is a CNF formula. It was shown in [1] that $2$P$1$N-SAT is NP-complete. This hints that the $k$P$k$N-3SAT problem is hard as well. </p>\n\n<p>The $1$P$1$N-SAT is apparently easy, see a related question and answer <a href="http://cs.stackexchange.com/a/16765/472">here</a>. Is $k$P$k$N-3SAT perhaps hard already for $k \\geq 2$?</p>\n\n<hr>\n\n<p>[1] Yoshinaka, Ryo. "Higher-order matching in the linear lambda calculus in the absence of constants is NP-complete." Term Rewriting and Applications. Springer Berlin Heidelberg, 2005. 235-249.</p>\n', 'ViewCount': '138', 'Title': 'Is the $k$P$k$N-3SAT problem NP-complete?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-13T13:37:40.000', 'LastEditDate': '2013-11-08T11:27:14.390', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '16822', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '472', 'Tags': '<complexity-theory><np-complete><satisfiability><decision-problem>', 'CreationDate': '2013-11-08T11:13:22.193', 'Id': '16817'}{'ViewCount': '638', 'Title': 'Is Dominosa NP-Hard?', 'LastEditDate': '2013-11-12T22:26:57.560', 'AnswerCount': '2', 'Score': '20', 'OwnerDisplayName': 'user987415', 'PostTypeId': '1', 'OwnerUserId': '10573', 'FavoriteCount': '4', 'Body': '<p>Dominosa is a relatively new puzzle game. It is played on an $(n+1)\\times(n+2)$\n  grid. Before the game begins, the domino bones  $\\left(0,0\\right),\\left(0,1\\right),\\ldots,\\left(n,n\\right)$\n  are placed on the grid (constituting a perfect tiling). In the next step, the domino bones are hidden, leaving only the numbers revealed. The purpose of the game is to recover the original arrangement of the domino bones.\nYou can play the game here: <a href="http://www.puzzle-dominosa.com/">http://www.puzzle-dominosa.com/</a>:</p>\n\n<p>Rules:</p>\n\n<blockquote>\n  <p>The rules are simple. You have to find the location of all the dominoes on the grid. A domino is a pair of numbers. You can only have one of each pair.</p>\n</blockquote>\n\n<p>I have some polynomial algorithms that solve a relatively small part of the puzzle. I could also show that typical Dominosa grids have at least $2^{\\frac{n}{2}+o\\left(n\\right)}$ solutions.</p>\n\n<p>Is Dominosa NP-Hard? </p>\n', 'Tags': '<complexity-theory><np-hard><board-games><tiling>', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-12-10T15:02:32.800', 'CommentCount': '9', 'CreationDate': '2013-09-12T12:18:43.740', 'Id': '16850'}{'Body': '<p>I would like to show that Quadratic Programming is NP-hard.</p>\n\n<p>I am currently reading a couple of papers which state that QP is NP-Hard and prove it by transforming SAT to QP, however I am finding the diction quite tough since I am just a beginner in the field. Would anyone happen to know the answer to this question who can maybe explain it to me in simpler terms?</p>\n', 'ViewCount': '66', 'Title': 'Transforming SAT to Quadratic Programming in polynomial time', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-12T16:52:50.120', 'LastEditDate': '2013-11-12T16:52:50.120', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '17952', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '11330', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2013-11-12T06:44:40.763', 'Id': '17946'}{'Body': '<p>For a homework question I need to show an explicit reduction from independent set (of size k) to CNF-SAT. I don\'t have anything formal written out so I will just give an idea of what I think needs to be done, any feedback or hint/help would be greatly appreciated:</p>\n\n<p>So I figure that given my a graph $G$ (it doesn\'t state in the question but I am guessing it is undirected graph) and an integer $G$ my variables for the boolean formula that I will need to define composes of the following:</p>\n\n<p>$var(\\phi) = \\{s_{ij}\\ | 1\\leq i \\leq k, j\\in{V}\\}$ where $s_{ij}$ is the $i$-th element of the independent set $S$ is $j$, which is node in the graph $G$. Now I want to convert this into a series of clauses that will be a series of conjunctions so I have these in mind:</p>\n\n<p>Have one series of conjunctions that will be every "not pair" of elements, i.e. $(\\overline{s_{ia}}\\vee \\overline{s_{ib}})$, that will indicate that no two nodes are the same in the $i$-th spot in the independent set S. Another series of conjunctions that will consists of every 2,3,4, all the way to k pairs of elements such that no elements in the clause share an edge. Then we take the conjunctions of these two major groups and that will be my Boolean formula. Like I said any feedback or if you want me to clarify something would be great!</p>\n', 'ViewCount': '79', 'ClosedDate': '2013-11-13T22:06:09.400', 'Title': 'Giving an explicit reduction for IND-SET $\\leq_{p}$ CNF-SAT', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-13T22:05:35.303', 'LastEditDate': '2013-11-13T22:05:35.303', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10880', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2013-11-12T22:18:12.250', 'Id': '17972'}{'Body': "<p>I'm a little stuck on this question, any help would be appreciated!</p>\n\n<p>Given that the Hamiltonian Path (HP) and the Hamiltonian Circuit/Cycles (HC) problems are known to be NP-complete, show that HCE is NP-complete.</p>\n\n<p>HCE: Given an undirected graph G and an edge e of G, does G have a Hamiltonian circuit/cycle that uses e?</p>\n\n<p>I've tried to approach this by showing that HC $\\leq$ HCE, but I'm wondering if my approach is too convoluted.</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>I think I have a solution.\nConsider a graph $G=(V,E)$ where $V$ is the set of vertices in $G$,\nand $E$ is the set of edges in $G$. Let $f(G)=G'=(V',E')$ where</p>\n\n<p>\\begin{alignat*}{1}\nV'= &amp; V\\cup\\{v_{\\alpha},v_{\\beta},v_{\\gamma}\\},v_{\\alpha},v_{\\beta},v_{\\gamma}\\notin V\\\\\nE'= &amp; E\\cup\\{(v_{\\alpha},v_{\\beta}),(v_{\\beta},v_{\\gamma})\\}\\cup\\{\\bigcup_{i\\in\\{\\alpha,\\gamma\\},v\\in V}(v,v_{i})\\}\n\\end{alignat*}</p>\n\n<p>Let the edge $e=(v_{\\alpha},v_{\\beta})$.</p>\n\n<p>$G'$is the graph $G$ with three additional vertices. $v_{\\alpha}$\nand $v_{\\gamma}$ are connected to all the vertices in $G$ and $v_{\\beta}$.\n$v_{\\beta}$ has a degree of 2, and is only connected to $v_{\\alpha}$and\n$v_{\\gamma}$. $f$ can be computed in p-time.</p>\n\n<p>Consider some $G$ that has a HP along vertices $v_{1},v_{2},...,v_{n}$.\nThen $G'$ will also have a path $v_{1},v_{2},...,v_{n}$ with each\nvertex only appearing once in the path. In order to turn this path\ninto a HC, the three additional vertices will have to be included.\nIn order to do so, the path has to be extended in either $v_{n},v_{\\alpha},v_{\\beta},v_{\\gamma},v_{1}$\nor $v_{n},v_{\\gamma},v_{\\beta},v_{\\alpha},v_{1}$. $G'$ thus have\na HC that will always include the edge $e$.</p>\n\n<p>$\\therefore$ G $\\in$ HP $\\implies$$f(G)=G'\\in$ HCE</p>\n\n<p>Consider some $G'$ with a HCE along some path $v_{1},v_{2},...,v_{n},v_{\\alpha},v_{\\beta},v_{\\gamma},v_{1}$.\nSince $G$ has vertices $V=V'\\backslash{v_{\\alpha},v_{\\beta},v_{\\gamma}}$,\n$G$ has a HP along vertices $v_{1},v_{2},...,v_{n}$. </p>\n\n<p>$\\therefore$ $G'\\in$ HCE $\\implies G\\in$ HP</p>\n\n<p>And thus $G\\in$ HP iff $f(G)=G'\\in$ HCE. Since $f$ can run in p-time,\nHP $\\leq$ HCE.</p>\n\n<p>$\\therefore$ HCE is NP-complete.</p>\n", 'ViewCount': '284', 'Title': 'Proof that Hamiltonian cycle/circuit with a specified edge is NP-complete', 'LastEditorUserId': '11365', 'LastActivityDate': '2014-04-15T16:57:15.503', 'LastEditDate': '2013-11-14T23:44:18.807', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '11365', 'Tags': '<complexity-theory><np-complete><hamiltonian-path>', 'CreationDate': '2013-11-14T01:51:37.303', 'Id': '17999'}{'Body': '<p>The following is my proof for $P$ being closed under union. I wish to know if my proof is correct in addition to what it means for the union of two problems.</p>\n\n<p>Proof:</p>\n\n<p>Let $p_1, p_2 \\in P$ Then by definition of $P$ $p_1$ is solvable in $O(n^k)$ for some $k\\in\\mathbb{N}$. Similarly $p_2$ is solvable in $O(n^{k_2}$) for some $k_2\\in\\mathbb{N}$.</p>\n\n<p>Then to solve $p_1 \\cup p_2$, we solve $p_1$ and $p_2$. So the total running time would be $O(n^k) + O(n^{k_2}) = O(n^{\\max(k, k_2)})$</p>\n\n<ol>\n<li>What does it mean to solve $p_1 \\cup p_2$? </li>\n<li>Is my proof correct or on the right track?</li>\n</ol>\n', 'ViewCount': '155', 'Title': 'Proving that the complexity class $P$ is closed under union', 'LastEditorUserId': '6815', 'LastActivityDate': '2013-11-19T13:40:09.620', 'LastEditDate': '2013-11-17T16:20:04.710', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '6815', 'Tags': '<complexity-theory><time-complexity><polynomial-time>', 'CreationDate': '2013-11-14T04:39:04.420', 'Id': '18004'}{'Body': u'<p>Are there problems that are in NP class but not in #P class? \nAccording to Wiki definition: </p>\n\n<blockquote>\n  <p>More formally, #P is the class of function problems of the form "compute \u0192(x)," where \u0192 is the number of accepting paths of a nondeterministic Turing machine running in polynomial time"</p>\n</blockquote>\n\n<p>So I am thinking, if you already have a poly nondeterministic Turing machine that can accept correct paths, then you can just use this to count in poly time.\nIs there something I am missing here?</p>\n', 'ViewCount': '118', 'Title': 'Problems in NP but not in #P', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-17T18:16:09.373', 'LastEditDate': '2013-11-15T18:30:47.287', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '11383', 'Tags': '<complexity-theory><complexity-classes><np>', 'CreationDate': '2013-11-14T17:17:08.513', 'Id': '18026'}{'Body': "<p>Show that if 3SAT is polynomial-time reducible to $complement of 3SAT$ then $PH = NP$.</p>\n\n<p>Above problem is Exercise problem from Arora and Barak,</p>\n\n<p>i don't know how to solve this problem,if anybody knows how to solve please post the solution </p>\n\n<p>Thanks for help!!</p>\n", 'ViewCount': '71', 'ClosedDate': '2013-11-16T15:29:29.187', 'Title': 'Proving $PH = NP$', 'LastActivityDate': '2013-11-15T13:09:15.560', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '10145', 'Tags': '<complexity-theory><np-complete><complexity-classes><nondeterminism><polynomial-time>', 'CreationDate': '2013-11-15T09:28:14.230', 'Id': '18043'}{'Body': '<p>This came up while I was trying to answer this question on  <a href="http://cs.stackexchange.com/questions/18041/wiring-length-minimization">Wiring Length Minimization</a>.  I was going to call this the "polygamous marriage" problem, but the internet, so kittens.  Yay!</p>\n\n<p>Suppose we have $M$ kittens that need to be adopted by $N$ people, $M &gt; N$.  For each kitten, $i$ and each person $j$ there is a cost $c_{ij}$.  We would like to minimize the total cost of getting all the kittens adopted.  There is also a set of constraints: each person $j$ is able to adopt no more than $u_j$ kittens.</p>\n\n<p>Without the constraints the problem is easy; each kitten $i$ goes with the person $j$ for which $c_{ij}$ is minimal.  With the constraints is there an efficient algorithm for this problem or is it NP-hard?</p>\n', 'ViewCount': '160', 'Title': 'Complexity of the Kitten Adoption problem', 'LastActivityDate': '2013-11-16T08:03:23.087', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '18065', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '7459', 'Tags': '<algorithms><complexity-theory>', 'CreationDate': '2013-11-15T15:27:48.693', 'FavoriteCount': '4', 'Id': '18051'}{'Body': '<p>Consider a certicate for 3SAT that lists an assignment for each occurrence of a variable in the order\nof appearence,e.g. 100000 for ($x\\bigvee$$y\\bigvee$z)$\\bigwedge$($\\neg(w)$$\\bigvee$$y\\bigvee$z). This certicate is of polynomial length and can\nbe read once to check the satisability of the given formula. Does this prove that SAT is in NL?</p>\n', 'ViewCount': '42', 'Title': 'Is SAT is in NL?( under certain conditions)', 'LastEditorUserId': '10145', 'LastActivityDate': '2013-11-16T06:45:03.890', 'LastEditDate': '2013-11-16T02:49:02.610', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10145', 'Tags': '<complexity-theory><np-complete><complexity-classes>', 'CreationDate': '2013-11-16T02:34:40.960', 'Id': '18061'}{'Body': '<p>Sipser example 9.29</p>\n\n<p>He says: "one way to do so (compute the parity function with O(n) gates. One way to do so is build a binary tree that computes the XOR function, where the XOR function is the same as parity on 2 variables, and then implement each XOR gate with two NOTs and two ANDs, and one OR. ... Let A be the language of strings that contain an odd number of 1\'s. Then A has circuit complexity O(n)."</p>\n\n<p>I\'m not seeing the steps that lead to saying that A has circuit complexity of O(n). Why can we say that if we implement a binary tree of XORs we can compute the parity with O(n) gates?</p>\n', 'ViewCount': '57', 'Title': 'Computing parity function on n variables with O(n) gates', 'LastActivityDate': '2013-11-16T19:45:19.503', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18080', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10599', 'Tags': '<complexity-theory><circuits>', 'CreationDate': '2013-11-16T19:33:32.610', 'Id': '18079'}{'Body': '<p>What makes neuromorphic architectures more efficient (less heat and power consumption) than von Neumann architecture for complex tasks? Except inspiration from biological systems, what are some formal results on this?\nAny reference to books or articles is appreciated as well. </p>\n', 'ViewCount': '89', 'Title': 'What makes neuromorphic computing architecture more efficient than von Neumann', 'LastActivityDate': '2013-11-16T21:11:49.633', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11368', 'Tags': '<complexity-theory><machine-learning><parallel-computing>', 'CreationDate': '2013-11-16T21:11:49.633', 'FavoriteCount': '2', 'Id': '18081'}{'Body': u'<p>A natural number n represents the initial position in the game. When it is a players turn he/she is allowed to </p>\n\n<pre><code>I)  Subtract 2 from n\nII) Subtract 3 from n\nIII)    Subtract 5 from n\n</code></pre>\n\n<p>We call the player who begin the game Adam and the other player Berta. The players alternate by applying on of the three rules to the number 0 or a negative number his/her opponent. If a player manages to produce the number 0 or a negative number he/she wins the game.</p>\n\n<p>Here is an example of a game played by Adam and Berta (for n=15)</p>\n\n<pre><code>15 is given to Adam. He decides to subtract 5 leaving 15-5 = 10 to Berta\n10 is given to Berta. She decides to subtract 3 leaving 11-3=8 to Beta\n8 is given to Adam. He decides to subtract 2 leaving 8-2=6 to Berta\n6 is given to Berta. She decides to subtract 2 leaving 6-2=4 to Adam\n4 is given to Adam. He decides to subtract 5 producing -1 a negative number, Adam wins!\n</code></pre>\n\n<p>b) we define a one dimensional array X(1), X(2),X(3),..,X(n)</p>\n\n<pre><code>i)  X(j) =1 if Adam has a method to win when given the number j\nii) X(j)=0 if Adam has no method that guarantees that he wins when the given the number k\n</code></pre>\n\n<p>Calculate X(1),X(2),X(3)\u2026.,X(23),X(25)</p>\n\n<p>What is X(8), X(13) and X(24)?     Answer should be of the form\nboolean boolean boolean  so if X(8)=0 , X(13)=1 and X(24)=1 the correct answer is 011\nThus the correct answer is one of the following 000 001 010 011 100 101 110 111</p>\n\n<p>My attempt is </p>\n\n<pre><code>n=8\nAdam: 8-5=3\nBerta: 3-3 =0\nBerta wins  0\n\nn=13 \nAdam=13-5=8\nBerta: 8-3=5\nAdam 5- 5\nAdam wins 1\n\nI get really stuck with 24, so far I have 01 \n</code></pre>\n\n<p>Is there a method for this type of problem, i have been stuck on it for ages now. \nThanks in advance</p>\n', 'ViewCount': '176', 'Title': 'Applying dynamic programming to a simple two-person game of perfect information', 'LastEditorUserId': '755', 'LastActivityDate': '2014-02-16T08:01:39.513', 'LastEditDate': '2014-02-16T08:01:39.513', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7173', 'Tags': '<algorithms><complexity-theory>', 'CreationDate': '2013-11-16T21:17:32.187', 'Id': '18082'}{'Body': "<p>I have basic background (at the level of Sipser's book),\nbut am looking to brush it up and get to the more advanced part via self-study.\nI have two Computational Complexity books (Arora and Barak and Papadimitriou's).</p>\n\n<p>I am looking for good lectures (online), exercises etc., possibly coursera style, \nfor a faster progress with the material.\nAny recommendations would be greatly appreciated.</p>\n\n<p>Thanks</p>\n", 'ViewCount': '78', 'ClosedDate': '2013-11-28T21:02:25.930', 'Title': 'Computational complexity lecture/videos/exercise', 'LastActivityDate': '2013-11-19T14:26:23.947', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11105', 'Tags': '<complexity-theory>', 'CreationDate': '2013-11-19T13:36:38.463', 'Id': '18154'}{'Body': '<p>This question is a follow up to the question: <a href="http://cs.stackexchange.com/questions/16321/proving-equivalence-of-1-dimensional-cellular-automaton-and-turing-machines">Proving Equivalence of 1-dimensional Cellular Automaton and Turing Machines</a>.</p>\n\n<p>To simulate a CA with a TM, I used a construction which placed a marker on the ends of the input, and modeled each "step" with the transition function. Assuming that $\\rho(\\text{\'\'blank\'\'}, \\text{\'\'blank\'\'}, \\text{\'\'blank\'\'}) = \\text{\'\'blank\'\'}$, what is the time complexity of simulating a CA? I\'m only concerned with the upper bound. </p>\n\n<p>I\'m really stuck, any hints would be really appreciated.</p>\n\n<p>Edit: As recommended, I am adding a better description of the algorithm:</p>\n\n<p>On input $w = w_1 w_2 \\dots w_n$, have the TM place unique begin and end characters on each side of the input. We model a single timestamp in the CA by multiple steps of the TM. The head sweeps through the taps, replacing its contents with the contents of the CA tape in the next timestamp. We write each character one place to teh right of where it would have been in the CA. Formally, this is: </p>\n\n<blockquote>\n  <p>there are states $q_{a,b}$ for all pairs of CA states, with transitions in the form:\n  $$ q_{a,b} \\to^{c \\to \\rho(a, b, c), R} q_{b,c}$$</p>\n</blockquote>\n\n<p>after completing a single sweep, return the head to the start of the tape and repeat. Continue unless an accept character is written, in which case, enter the TM accept state.</p>\n', 'ViewCount': '77', 'Title': 'Time Complexity of Simulating CA with TM', 'LastEditorUserId': '10448', 'LastActivityDate': '2013-11-20T04:00:24.680', 'LastEditDate': '2013-11-20T04:00:24.680', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10448', 'Tags': '<complexity-theory><turing-machines><cellular-automata>', 'CreationDate': '2013-11-19T19:37:42.877', 'FavoriteCount': '1', 'Id': '18168'}{'Body': "<p>I am trying to prove:</p>\n\n<blockquote>\n  <p>Let there be a constructible function $t: ~\\mathcal{N} \\to \\mathcal{N}$. Then there exists a language $L$ where $L$ is decidable by an LBA in $O(t(n))$ time, but not $o\\left(\\frac{t(n)}{\\log t(n)}\\right)$ time. You may assume that LBAs have a fixed tape alphabet and have unique symbols marking the start and end of the input.</p>\n</blockquote>\n\n<p>I've read through Sipser's version of the proof (Theorem 9.10) several times, but am not sure how to apply it to LBAs. Hints only please.</p>\n", 'ViewCount': '74', 'Title': 'Extension of Time Hierarchy Theorem to LBAs', 'LastActivityDate': '2013-11-19T21:36:29.687', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18171', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10596', 'Tags': '<complexity-theory><automata>', 'CreationDate': '2013-11-19T19:51:28.933', 'Id': '18169'}{'Body': '<p>If we consider polynomial-time (or log-space) computable reductions $&lt;_p^m$ as  transformations between computational problems, then the following definitions of known complexity classes suggest the conservation of information under "efficient" transformations. Assuming $P\\ne NP$, it seems that information flows only from easy problems to hard problems thorough efficient reductions.</p>\n\n<p>$P=\\{L| L&lt;_p Horn3SAT, \\bar L &lt;_p Horn3SAT \\}$ </p>\n\n<p>$NP=\\{L| L&lt;_p 3SAT \\}$</p>\n\n<p>$CoNP=\\{L| \\bar L&lt;_p 3SAT \\}$</p>\n\n<p>$NPC=\\{L| L&lt;_p 3SAT, 3SAT&lt;_p L \\}$</p>\n\n<p>$PC=\\{L| L&lt;_p Horn3SAT, Horn3SAT&lt;_p L \\}$</p>\n\n<blockquote>\n  <p>Is there a notion of computational hardness in terms of information flow that explains this apparent asymmetry of information flow between natural computational problems?</p>\n</blockquote>\n\n<p>I am aware of the theorem that $P=NP$ if and only if a sparse set is $NP$-complete. I\'m looking for notions different than set sparsity.</p>\n', 'ViewCount': '47', 'Title': 'Notions of computational hardness in terms of information flow?', 'LastEditorUserId': '96', 'LastActivityDate': '2013-11-20T11:10:22.187', 'LastEditDate': '2013-11-20T11:10:22.187', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><information-theory>', 'CreationDate': '2013-11-20T10:48:22.983', 'Id': '18195'}{'Body': '<p>It is well known that in Descriptive Complexity Theory FO is equivalent to AC0.</p>\n\n<p>However, this accepts a couple of a theory and a string <code>&lt;T,s&gt;</code> iff the interpretation of s as a query is satisfied by the theory T.</p>\n\n<p>My question now is if there is an interpretation of which is stronger than AC0. For example, is there an interpretation of s as a theory so that the formalism accepts if s is a theory that is logically entailed by T. This problem is undecidable, but maybe it is possible to express problems in it which are stronger than AC0. (Reachability would be an interesting example if anyone could make this work)</p>\n', 'ViewCount': '61', 'Title': 'On the Turing Completeness of First Order Logic', 'LastActivityDate': '2013-11-20T11:53:17.923', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '11502', 'Tags': '<complexity-theory><logic><turing-completeness><first-order-logic>', 'CreationDate': '2013-11-20T11:53:17.923', 'FavoriteCount': '1', 'Id': '18197'}{'Body': "<p>Consider assigning a single object to $n$ potential receivers. It can only be assigned to one person.</p>\n\n<p>For each receiver $k$, there is a value of profit $v_k$ and a probability $p_k$.\n Fix an ordering of the receivers, then for the $i$th receiver he accept the object with probability $p_i$, if he does, we gain a value $v_i$; if he doesn't, consider the next person in the ordering.</p>\n\n<p>Then the expected value we gain is</p>\n\n<p>$E(V)=p_1v_1+(1-p_1)p_2v_2+\\cdots +(1-p_1)(1-p_2)\\cdots (1-p_{n-1})p_nv_n$</p>\n\n<p>It can be easily seen: to maximize the expected value we gain, the ordering should be in the decrease of the $v$.</p>\n\n<p>But since passing through the potential receivers the object defects the value of it, the $i$th receiver has a parameter $w_i$ where $w_1&gt;w_2&gt;\\cdots&gt;w_n$.</p>\n\n<p>$v_k$ is assigned to each person $k$, and $w_i$ is assigned to the $i$th person in the ordering. For example if the $3$rd person in the ordering is person $5$, then he has $v_5$ and $w_3$.</p>\n\n<p>so the expected value changes to</p>\n\n<p>$E(v)=p_1w_1v_1+(1-p_1)p_2w_2v_2+\\cdots+(1-p_1)(1-p_2)\\cdots(1-p_{n-1})p_nw_nv_n$</p>\n\n<p>Is there a polynomial algorithm to give an optimal ordering that maximizes the expected value? Or should this be NP-Complete?</p>\n\n<p>Any hint is appreciated. Thanks in advance.</p>\n", 'ViewCount': '72', 'Title': 'Prove or disprove NP-Completeness: An optimal ordering problem', 'LastActivityDate': '2013-11-25T02:01:51.750', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11589', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-11-24T10:44:47.610', 'Id': '18296'}{'ViewCount': '188', 'Title': '$O(n^{k-1}$) algorithm for K-clique problem', 'LastEditDate': '2013-11-25T15:38:33.530', 'AnswerCount': '1', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '96', 'FavoriteCount': '1', 'Body': "<p>Clique problem is a well known $NP$-complete problem where the size of the required clique is part of the input. However, k-clique problem has a trivial polynomial time algorithm ($O(n^k)$ when $k$ is constant). I'm interested in the best known upper bounds when k is constant. </p>\n\n<blockquote>\n  <p>Is there an algorithm with run time $O(n^{k-1})$? A $o(n^k)$-time algorithm is also acceptable. Also, Is there any complexity-theoretic consequence for the existence of such algorithms?</p>\n</blockquote>\n", 'Tags': '<complexity-theory><graph-theory>', 'LastEditorUserId': '96', 'LastActivityDate': '2014-01-20T16:12:20.110', 'CommentCount': '0', 'AcceptedAnswerId': '18331', 'CreationDate': '2013-11-25T15:32:53.833', 'Id': '18330'}{'Body': "<p>Considering two sets $A, B$ containing some $p$-dimensional points $x \\in \\mathbb{R}^p$. Let $d_x^S = \\min_{x' \\in S \\setminus \\{x\\}} \\lVert \\mathbf{x} - \\mathbf{x'} \\rVert$ denote the Euclidean distance from $x$ to its nearest point in $S$. We have a very simple algorithm:</p>\n\n<ol>\n<li>$\\forall x \\in A$, if $d_x^A &gt; d_x^B$ then move $x$ from $A$ to\n$B$.</li>\n<li>$\\forall x \\in B$, if $d_x^A &lt; d_x^B$ then move $x$ from $B$ to\n$A$.</li>\n<li>Repeat (1) and (2) until convergence</li>\n</ol>\n\n<p>Convergence is when there is no more $x \\in A$ such that $d_x^A &gt; d_x^B$, and there is no more $x \\in B$ such that $d_x^A &lt; d_x^B$.</p>\n\n<p>How could I figure out which function does this algorithm minimize or maximize at each iteration ? The function $\\Phi(A)+\\Phi(B) = \\sum_{x \\in A} d_x^A + \\sum_{x \\in B} d_x^B$ does not seem to decrease at each iteration.</p>\n\n<p>Note: another version of this algorithm is when we define $d_x^S$ as the mean distance from $x$ to its $k$ nearest points in $S$, instead of the distance to its nearest point in $S$. I don't know if $k &gt; 1$ would make the proof more complicated or not.</p>\n", 'ViewCount': '87', 'Title': 'Which potential function does this algorithm minimize or maximize?', 'LastEditorUserId': '2895', 'LastActivityDate': '2013-11-26T16:29:35.140', 'LastEditDate': '2013-11-26T16:29:35.140', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2895', 'Tags': '<algorithms><complexity-theory><algorithm-analysis><optimization>', 'CreationDate': '2013-11-25T20:40:26.780', 'FavoriteCount': '2', 'Id': '18333'}{'Body': '<p>I Know that determining Hamiltonian cycle in a graph is NP complete. For the sake of my clarification, I just want to know that whether the problem remains NP complete with following restrictions ? </p>\n\n<p>1) Graph is undirected , and  every node has degree two.</p>\n\n<p>Any help will be appreciated. Thanks.</p>\n', 'ViewCount': '27', 'Title': 'Complexity class of Determining Hamiltonian cycle', 'LastActivityDate': '2013-11-26T04:54:16.490', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11629', 'Tags': '<complexity-theory><graph-theory><p-vs-np>', 'CreationDate': '2013-11-26T04:17:18.607', 'Id': '18352'}{'Body': "<p>So given an input of lets say 10 strings, what way can we input these so we get the best or worst case for these two given sorts?</p>\n\n<pre><code>Heap sort:\nbest case - nlogn\nworst case - nlogn\n\nQuick sort:\nbest case - nlogn\nworst case - n^2\n</code></pre>\n\n<p>Where I get confused on these two is:</p>\n\n<ul>\n<li><strong>heap</strong>- Since the best and worst case are the same does it not matter\nthe input order? The number of comparisons and assignments will\nalways be the same? I imagine in a heap sort it may be the same since\nthe real work is done in the insertion, but the sorting only uses the\nremoval of the max/min heap? Is that why?</li>\n<li><strong>quick sort</strong>- This one I don't know for sure. I'm not sure what the\nbest case and worst case situations are for this. If its a already\nsorted list of 10 strings for example wouldn't we always have to\nchoose the same amount of pivots to get complete the recursive\nalgorithm? Any help on this explanation would really help.</li>\n</ul>\n", 'ViewCount': '416', 'Title': 'Best and worse case inputs for heap sort and quick sort?', 'LastEditorUserId': '9550', 'LastActivityDate': '2013-11-26T21:03:49.457', 'LastEditDate': '2013-11-26T18:52:40.720', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11638', 'Tags': '<algorithms><complexity-theory><sorting><heaps>', 'CreationDate': '2013-11-26T17:43:11.983', 'Id': '18391'}{'ViewCount': '230', 'Title': 'Easy way to prove that this algorithm eventually terminates', 'LastEditDate': '2013-11-26T19:24:53.680', 'AnswerCount': '1', 'Score': '10', 'OwnerDisplayName': 'user995434', 'PostTypeId': '1', 'OwnerUserId': '2895', 'FavoriteCount': '3', 'Body': '<h2>Introduction and notations:</h2>\n\n<p>Here is a new and simple version of my algorithm which seems to terminates (according to my experiments), and now I would like to prove that.</p>\n\n<p>Let the notation $x_i \\in \\mathbb{R}^p$ refer to a $p$ dimensional data point (a vector). I have three sets A, B and C, such that $|A| = n$, $|B| = m$, $|C| = l$:\n$$A = \\{x_i | i = 1, .., n\\}$$\n$$B = \\{x_j | j = n+1, .., n+m\\}$$\n$$C = \\{x_u | u = n+m+1, .., n+m+l\\}$$</p>\n\n<p>Given $k \\in \\mathbb{N^*}$, let $d_{x_i}^A$ denote the mean Euclidean distance from $x_i$ to its $k$ nearest points in $A$; and $d_{x_i}^C$ denote the mean Euclidean distance from $x_i$ to its $k$ nearest points in $C$.</p>\n\n<h2>Algorithm:</h2>\n\n<p>I have the following algorithm which iteratively modifies the sets A and B by moving some selected elements from A to B and vis versa, and C remains always the same (do not change). To make it simple: the purpose of the algorithm is to better separate the sets $A$ and $B$ such that "the points of $B$ are more similar to those of a known fixed set $C$" and "the points of $A$ are finally self-similar and farther from those of $C$ and the final set $B$":</p>\n\n<ul>\n<li>$A\' = \\{ x_i \\in A \\mid d_{x_i}^A &gt; d_{x_i}^C \\}$ ... (1)</li>\n<li>$A = A \\setminus A\'$; $B = B \\cup A\'$ ... (2)</li>\n<li>$B\' = \\{ x_i \\in B \\mid d_{x_i}^A &lt; d_{x_i}^C$ } ... (3)</li>\n<li>$B = B \\setminus B\'$; $A = A \\cup B\'$ ... (4)</li>\n<li>Repeat (1), (2), (3), and (4) until: (no element moves from $A$ to $B$ or from $B$ to $A$, that is A\' and B\' become empty) or ($|A| \\leq k$ or $|B| \\leq k$)</li>\n</ul>\n\n<p>The algorithm terminates in two cases:</p>\n\n<ul>\n<li>when $|A|$ or $|B|$ becomes less than or equals to $k$</li>\n<li>or the most standard case, when $A\' = B\' = \\emptyset$, which means that no more elements moves between A and B.</li>\n</ul>\n\n<h2>Question:</h2>\n\n<p>How to prove that this algorithm eventually terminates ? I didn\'t found a convenient potential function which can be strictly minimized or maximized by the algorithm.\nI have unsuccessfully tried some functions: the function $\\sum_{x \\in A} d_x^C + \\sum_{x \\in B} d_x^A$ but it is not increasing at each iteration. The function $\\sum_{x \\in A} d_x^A + \\sum_{x \\in B} d_x^C$ but it is not decreasing at each iteration. The function $\\sum_{x \\in A} d_x^A + \\sum_{x \\in B} d_x^B$ seems not to be decreasing at each iteration. The function $\\sum_{x \\in A} d_x^B + \\sum_{x \\in B} d_x^A$ seems not to be increasing at each iteration. So what is the convenient potential function which can be show to either increase or decrease at each iteration ? Or should we show that the function decreases but not at each iteration (after some iterations rather) ? How ?</p>\n\n<h2>Notes:</h2>\n\n<ul>\n<li>The $k$ nearest points to $x$ in a set $S$, means: the $k$ points\n(others than $x$) in $S$, having the smallest Euclidean distance to\n$x$. You can just take $k = 1$ to simplify the analysis.</li>\n<li>I don\'t know if this may help or not, but I have the following\nproperty for my initial sets $A, B, C$: initially $\\forall x_i \\in B,\n   x_j \\in A$, if $x_b \\in C$ is the nearest point to $x_i$ and $x_a \\in\n   C$ is the nearest point to $x_j$ then always $distance(x_i, x_b) &lt;\n   distance(x_j, x_a)$. This intuitively means that points in $B$ are\ncloser to $C$ than points in $A$.</li>\n<li>If that makes the analysis easier: it is totally possible to consider a slightly different version of the Algorithm where as soon as a point from $A$ should be moved to $B$, it is moved from $A$ to $B$ (without passing by $A\'$), and vis versa for $B$.</li>\n</ul>\n', 'Tags': '<algorithms><complexity-theory><algorithm-analysis><optimization>', 'LastEditorUserId': '2895', 'LastActivityDate': '2013-11-27T22:36:33.060', 'CommentCount': '11', 'CreationDate': '2013-11-22T10:53:45.843', 'Id': '18393'}{'Body': "<p>I'm asked to prove that, if P=NP, that 0*1* is NP-complete, but I'm having trouble going about doing it. I know it's fairly easy to prove it's NP by creating a TM to verify an input (which can be done in O(n) time, and that's polynomial). </p>\n\n<p>But then I now have to reduce an NP-complete problem to 0*1* in order to prove that 0*1* is NP-complete. I'm thinking reducing SAT to it, but I have no idea how to do that, since in SAT all you can use is and, or, and negate, and there's no way to tell if a 1 came before a 0 in an input by doing that (at least, as far as I can tell).</p>\n\n<p>Thanks</p>\n", 'ViewCount': '212', 'Title': 'Having trouble proving a language is NP-complete', 'LastActivityDate': '2014-01-03T00:14:15.713', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '18400', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11300', 'Tags': '<complexity-theory><np-complete><np-hard><np>', 'CreationDate': '2013-11-27T00:07:47.700', 'FavoriteCount': '1', 'Id': '18399'}{'Body': "<p>The question (Prove L is NP-hard) was about proving that the following language is NP-hard:\n$$ L = \\{ \\langle D_1, D_2, ... ,D_K \\rangle : k \\in {N}\\text{, the } D_i \\text{ are DFAs and } {\\bigcap}_{i=1}^k L(D_i) = \\emptyset \\} $$</p>\n\n<p>That got me thinking about the related problem:</p>\n\n<p>$$ L' = \\{ \\langle D_1, D_2, ... ,D_K \\rangle : k \\in {N}\\text{, the } D_i \\text{ are DFAs and } {\\bigcap}_{i=1}^k L(D_i) \\neq \\emptyset \\} $$</p>\n\n<p>I would imagine that $L'$ is also NP-hard, but I couldn't think of any reductions.. am I missing something obvious? </p>\n", 'ViewCount': '70', 'Title': 'Proving $ \\{ \\langle D_1, ... ,D_K \\rangle : \\text{ where } D_i \\text{ are DFAs and } {\\bigcap}_{i=1}^k L(D_i) = \\emptyset \\} $ is NP-Hard', 'LastActivityDate': '2013-11-27T05:25:17.433', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18405', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10448', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2013-11-27T04:01:13.527', 'Id': '18402'}{'Body': '<p>I would like some hints on how to approach this problem, I know for instance that $TQBF$ is $PSPACE$-$Complete$, so it can solved in poly space and any other $PSPACE$-$Complete$ problems can be log spaced reduced to $TQBF$. I believe that I need to employ the space hierarchy theorem in some way but I am not sure how, this is a homework question so I just want a hints. Thank you! </p>\n', 'ViewCount': '117', 'Title': 'Prove that $TQBF \\notin SPACE(n^{\\frac{1}{3}})$', 'LastActivityDate': '2013-12-11T08:44:59.787', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '18870', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10880', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-11-27T22:03:52.387', 'Id': '18426'}{'Body': '<p>It is NP-hard to approximate <a href="http://link.springer.com/chapter/10.1007/3-540-44849-7_21" rel="nofollow">maximum 3D matching problem</a> even if each element occurs exactly in two triples. I\'m interested in the following decision version of 3D matching. </p>\n\n<p>Informally, Given a set of triples $F$ of elements such that each element occurs exactly in two triples, Is there a subset of $F$ such that each element occurs in exactly one triple?</p>\n\n<blockquote>\n  <p>Is this decision problem solvable in polynomial time? Is it $NP$-complete?</p>\n</blockquote>\n', 'ViewCount': '30', 'Title': 'Bounded occurrence 3D matching problem', 'LastActivityDate': '2013-11-28T20:25:59.877', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<algorithms><complexity-theory>', 'CreationDate': '2013-11-28T20:25:59.877', 'Id': '18455'}{'Body': '<p>I am a physicist, with little formal training in computer science - please don\'t assume I know even obvious things about computer science! </p>\n\n<p>Within the context of data analysis, I was interested in identifying clusters within a $d$-dimensional list of $n$ data-points, for which the dimensionality $d$ could be $\\sim100$, whilst the number of data-points could be $\\sim 1,000,000$, or perhaps more.</p>\n\n<p>I wanted the points with a cluster to be close together, with distance measured in the Euclidean manner,\n$$\nd(\\vec x,\\vec y) = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2} \n$$ \nAs long as the clustering was reasonably accurate, I wasn\'t bothered if the exactly correct result was obtained. i.e. if of my $\\sim1,000,000$, $\\sim1,000$ points were wrongly categorized, it wouldn\'t matter much.</p>\n\n<p>I have written a short algorithm that can perform typically at $\\mathcal{O}(n)$ (from trials of up to $n\\sim5,000,000$ and some theoretical analysis) and worst-case $\\mathcal{O}(n^2)$ (from my theoretical evaluation of the algorithm). The nature of the algorithm sometimes (but not always) avoids the so-called chaining problem in clustering, where dissimilar clusters are chained together because they have a few data-points that are close.</p>\n\n<p>The complexity is, however, sensitive to the <em>a priori</em> unknown number of clusters in the data-set. The typical complexity is, in fact, $\\mathcal{O}(n\\times c)$, with $c$ the number of clusters. </p>\n\n<p>Is that better than currently published algorithms? I know naively it is a  $\\mathcal{O}(n^3)$ problem. I have read of SLINK, that optimizes the complexitiy to $\\mathcal{O}(n^2)$. If so, is my algorithm useful? Or do the major uses of clustering algorithms require exact solutions?</p>\n\n<p>In real applications is $c\\propto n$?, such that my algorithm has no advantage. My naive feeling is that for real problems, the number of "interesting" clusters (i.e. not including noise) is a property of the physical system/situation being investigated, and is in fact a constant, with no significant dependence on $n$, in which case my algorithm looks useful.</p>\n', 'ViewCount': '83', 'Title': 'Is an $\\mathcal{O}(n\\times \\text{Number of clusters})$ clustering algorithm useful?', 'LastEditorUserId': '11757', 'LastActivityDate': '2013-12-06T00:49:12.167', 'LastEditDate': '2013-12-05T13:11:18.563', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '18668', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11757', 'Tags': '<algorithms><complexity-theory><cluster>', 'CreationDate': '2013-12-02T11:38:24.923', 'Id': '18534'}{'Body': "<p>I need to describing a Turing machine that computes $\\lceil\\log_{2}(n)\\rceil$ I know that:</p>\n\n<p>n = 1, 2, 3, 4, 5, 6, 7, 8, ... <br>\nf(n) = 0, 1, 2, 2, 3, 3, 3, 3, ...</p>\n\n<p>So I'm thinking of putting $n$ on the tape. Then keeping a count of how many times I multiply 2*2 until it is greater than than $n$. For example for n=5, 2*2*2=8, number of two's is 3 so then $f(n)$ is 3. I don't know how to translate this to the ticker tape of the Turing machine.</p>\n\n<p>But would something like this work? Put $n$ 1's on the tape followed by a 0. Compute 1^(2^1), then check if 1's on the left of the 0 on the tape is less than or equal to the 1's on the right of the 0. If its not then repeat it for 1^(2^(1)). It keeps doing this until the left side has less than or equal number of 1's.</p>\n", 'ViewCount': '98', 'Title': 'Describing a Turing machine that computes $\\lceil\\log_{2}(n)\\rceil$', 'LastEditorUserId': '472', 'LastActivityDate': '2013-12-02T19:09:53.377', 'LastEditDate': '2013-12-02T19:09:53.377', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '18541', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '11155', 'Tags': '<complexity-theory><turing-machines><automata>', 'CreationDate': '2013-12-02T17:04:15.713', 'Id': '18537'}{'Body': "<p>Please correct my statement.\nAssuming $L\\in NP$, and algorithm A can determine L in poly-time in a nondeterministic machine, we have algorithm $A'$ and the complement of $L$ -- $L'$. $x$ is the input of $A'$</p>\n\n<pre><code>A'(x)\n{\n   if(A(x) is true)\n      return false\n   else\n      return true\n}\n</code></pre>\n\n<p>In this code, it seems like $A'$ can also run in a nondeterministic machine in poly-time. Can I just say $co-NP=NP$??</p>\n\n<p>Or my flaw is that the input $x\\in L'$ but $x\\notin L$?</p>\n\n<p>Could you please give me a specific example?? </p>\n", 'ViewCount': '27', 'ClosedDate': '2013-12-03T08:12:08.397', 'Title': 'Why NP is not closed under complement?', 'LastActivityDate': '2013-12-03T01:10:20.433', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11773', 'Tags': '<complexity-theory><computability><np-complete><decision-problem>', 'CreationDate': '2013-12-03T01:10:20.433', 'Id': '18553'}{'Body': '<p>I read <a href="http://blog.computationalcomplexity.org/2011/10/if-you-find-mistake-in-someone-elses.html" rel="nofollow">on a blog</a> that there are mistakes in Karp\'s paper where he proved that 0-1 programming is NP-Complete, but I couldn\'t find it, can anyone explain? And I doubt that there are also mistakes where he proved Steiner Tree Problem is NP-Compelete but not sure.</p>\n\n<p>The blog post a little old and I thought asking the writer of the blog may not receive answer quickly enough. I didn\'t find any referrence in other places so I thought this question may worth asking. </p>\n', 'ViewCount': '89', 'Title': "Mistake in Karp's paper on NP-Complete problems?", 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-03T08:53:58.347', 'LastEditDate': '2013-12-03T08:49:56.580', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '18566', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11589', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-12-03T06:48:29.323', 'Id': '18559'}{'ViewCount': '92', 'Title': '"Unusual" coupling between a decision problem and a corresponding optimization problem', 'LastEditDate': '2013-12-04T18:21:05.133', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '2', 'Body': '<p>There seems to usually be a tight connection between <a href="http://en.wikipedia.org/wiki/Decision_problem" rel="nofollow">decision problems</a> and (corresponding) <a href="http://en.wikipedia.org/wiki/Optimization_problem" rel="nofollow">optimization problems</a> in general. However, is this always the case? </p>\n\n<blockquote>\n  <p>Are there examples where the typical "tight coupling" between a decision problem and the correponding optimization problem breaks down or behaves in an unusual way, e.g. have significantly different complexity?</p>\n</blockquote>\n\n<p>Or, maybe there is a case where there is a cluster of problems that are all closely related, but the "best" or "definitive" version is not obvious or apparent? Also, I am looking for any survey or broad overview or discussion of this apparent basic connection between decision and optimization problems.</p>\n\n<p>A similar question was asked <a href="http://cs.stackexchange.com/questions/939/optimization-version-of-decision-problems">here</a>, but the answers were highly theoretical and it did not seem to yield any specific or tangible examples.</p>\n', 'Tags': '<complexity-theory><reference-request><optimization><decision-problem>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-12-04T18:21:05.133', 'CommentCount': '5', 'AcceptedAnswerId': '18608', 'CreationDate': '2013-12-03T17:10:07.033', 'Id': '18575'}{'Body': '<p>On one hand, <a href="http://en.wikipedia.org/wiki/Horn-satisfiability" rel="nofollow">Horn-SAT</a> is known to be tractable in linear time - where Horn-SAT is the problem of deciding whether a given set of propositional Horn clauses (with at most one positive literal) is satisfiable or not.\nOn the other hand, Double-SAT is NP-complete (see this post : <a href="http://cs.stackexchange.com/questions/6371/proving-double-sat-is-np-complete">Proving Double-SAT is NP-complete</a>) - where Double-SAT is the problem of deciding whether a given set of propositionnal clauses has at least two models.</p>\n\n<p>Let Double-Horn-SAT be the problem of deciding whether a given set of propositional Horn clauses has at least two models.</p>\n\n<p>What is the complexity of Double-Horn-SAT ?</p>\n', 'ViewCount': '41', 'Title': 'Complexity of Double-Horn-SAT?', 'LastActivityDate': '2013-12-03T22:13:38.727', 'AnswerCount': '1', 'CommentCount': '8', 'AcceptedAnswerId': '18585', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10228', 'Tags': '<complexity-theory><np-complete><satisfiability><complexity-classes>', 'CreationDate': '2013-12-03T20:28:43.277', 'Id': '18581'}{'Body': '<p>When I was studying Comp Sci, we had <a href="http://rads.stackoverflow.com/amzn/click/0716710455" rel="nofollow">Garey &amp; Johnson</a> as a course textbook, with a large collection of NP-Complete problems. But by that time you could also have a look at the <a href="http://www.ensta-paristech.fr/~diam/ro/online/viggo_wwwcompendium/wwwcompendium.html" rel="nofollow">Compendium of NP Optimization Problems</a>, online.</p>\n\n<p>However, it seems the \'Compendium\' site has not seen any updates in several years. Is that indeed the case? Is there a more up-to-date compendium (perhaps in print) which accounts for further research and contains more problems in more domains?</p>\n', 'ViewCount': '45', 'Title': "Is there a more up-to-date / wider-scope version of the 'Compendium of NP Optimization Problems'", 'LastEditorUserId': '11796', 'LastActivityDate': '2013-12-14T12:47:16.403', 'LastEditDate': '2013-12-14T12:47:16.403', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '11796', 'Tags': '<complexity-theory><time-complexity><optimization><np>', 'CreationDate': '2013-12-03T22:00:16.900', 'FavoriteCount': '1', 'Id': '18584'}{'Body': '<p>It is known that <a href="http://en.wikipedia.org/wiki/3-satisfiability#3-satisfiability" rel="nofollow">3-SAT</a> belong to - <a href="http://en.wikipedia.org/wiki/NP-complete" rel="nofollow">NP-Complete</a> complexity problems, while <a href="http://en.wikipedia.org/wiki/2-satisfiability" rel="nofollow">2-SAT</a> belong to <a href="http://en.wikipedia.org/wiki/P_%28complexity%29" rel="nofollow">P</a> as there is known polynomial solution to it.</p>\n\n<p>So you can state that there is no such reduction from <strong>3-SAT</strong> to <strong>2-SAT</strong> unless $P=NP$.</p>\n\n<p>I am looking for strong proof for this state, regardless NP belong to P or not.</p>\n', 'ViewCount': '381', 'Title': '3-sat to 2-sat reduction', 'LastActivityDate': '2013-12-05T19:52:06.330', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '-3', 'PostTypeId': '1', 'OwnerUserId': '10572', 'Tags': '<complexity-theory><np-complete><satisfiability><np>', 'CreationDate': '2013-12-05T14:55:37.870', 'FavoriteCount': '3', 'Id': '18643'}{'Body': '<p>Can we solve an EXPTIME-complete problem  in polynomial time given 2^N processors?(N is the size of input).</p>\n', 'ViewCount': '41', 'Title': 'EXPTIME and parallel computing', 'LastActivityDate': '2013-12-06T07:40:16.823', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11867', 'Tags': '<complexity-theory><parallel-computing>', 'CreationDate': '2013-12-06T07:40:16.823', 'Id': '18674'}{'Body': "<p>I'm reading a definition of PSPACE and say: are the decision problems solvable in polynomial space on a Deterministic Turing Machine. My question is: Why NP is in PSPACE?. I have a doubt beccause for example a SAT problem is solvable in Non-Deterministic Turing Machine and SAT $\\in NP$ and not in $P$.</p>\n", 'ViewCount': '48', 'Title': 'PSPACE and NP complexity', 'LastActivityDate': '2013-12-06T12:24:10.787', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18679', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11241', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-06T11:53:17.897', 'Id': '18678'}{'Body': '<p>Is it possible to represent the <a href="http://pt.wikipedia.org/wiki/Computador_de_DNA#A_solu.C3.A7.C3.A3o_do_problema" rel="nofollow">algorithm proposed by Adleman</a> to solve the Hamiltonian problem in a probabilistic Turing Machine?</p>\n\n<p>See also <a href="http://www.usc.edu/dept/molecular-science/papers/fp-sciam98.pdf" rel="nofollow">Computing with DNA</a></p>\n', 'ViewCount': '60', 'Title': 'DNA Computing Algorithm to solve the Hamiltonian problem', 'LastEditorUserId': '10572', 'LastActivityDate': '2013-12-08T19:39:36.043', 'LastEditDate': '2013-12-08T19:39:36.043', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11241', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-06T21:28:30.037', 'Id': '18695'}{'Body': '<p>Let $\\phi$ be a 3-CNF of $m$ clauses and $n$ variables, and $\\langle G, k\\rangle$ be the \nVertex Cover instance  obtained from $\\phi$ through the reduction\nfrom 3-SAT to Vertex Cover. Assume that $\\phi$ has a unique satisfying assignment.</p>\n\n<p>Then does $G$ have a <strong>unique</strong> vertex cover of size $k$?</p>\n', 'ViewCount': '62', 'ClosedDate': '2013-12-26T09:48:59.383', 'Title': 'Does graph have unique vertex cover of given size?', 'LastActivityDate': '2013-12-08T13:49:00.393', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11304', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-07T03:41:44.153', 'Id': '18705'}{'ViewCount': '123', 'Title': 'Hard computational problem on special class of bipartite graphs', 'LastEditDate': '2013-12-09T18:52:36.190', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '96', 'FavoriteCount': '1', 'Body': '<p>I am interested in the properties of a class of bipartite graphs $G(X \\cup Y, E)$ where all nodes in $X$ are 3-regular, all nodes in $Y$ are 2-regular, and $|X|=|2Y/3|$. First, Is this a well known class of graphs? Secondly,</p>\n\n<blockquote>\n  <p>Is there an example of intractable computational problem restricted to this class of bipartite graphs?</p>\n</blockquote>\n', 'Tags': '<complexity-theory><graph-theory>', 'LastEditorUserId': '96', 'LastActivityDate': '2013-12-09T20:22:37.543', 'CommentCount': '0', 'AcceptedAnswerId': '18787', 'CreationDate': '2013-12-08T17:59:53.053', 'Id': '18754'}{'Body': '<p>I understand and know how to show that a language B is NP-Complete.</p>\n\n<ol>\n<li>Show that $B\\in NP$</li>\n<li>Show that every language $A\\in NP$ is polynomial time reducible to $B$</li>\n</ol>\n\n<p>For step 2, it is sufficient to give a polynomial time reduction from a language that is already known to be NP-Complete. I am reading Sipser\'s "Theory of Computation" textbook, and the main method he gives is a reduction from $3SAT$. I would agree that $3SAT$ is probably the simplest reduction choice, unless the problem is a trivial modification of an NP-Complete problem that you already know of.</p>\n\n<p>What I am struggling with is, finding reductions from $3SAT$ or any NP-Complete language to the new language $B$. The other tip that Sipser gives is the notion of variable and clause "gadgets" which refer to the structures in the new language which correspond to the variables and clauses in $3SAT$. I tried the Undirected Hamiltonian Path problem for a few hours but could not get anywhere useful in finding sufficient "gadgets" so that I could solve the problem. Looking at the $k$-clique problem and the $k$-vertex-cover problem, the "gadgets" that Sipser uses are not something that I would think of...</p>\n\n<ol>\n<li>How can I begin to find these "gadgets"?</li>\n<li>Specifically with a reduction from $3SAT$, what are the common techniques?</li>\n</ol>\n\n<p>This is a fascinating theory! Please help!</p>\n', 'ViewCount': '74', 'ClosedDate': '2013-12-09T16:36:34.470', 'Title': 'Tips for showing a language is NP-Complete', 'LastEditorUserId': '6815', 'LastActivityDate': '2013-12-09T16:38:34.207', 'LastEditDate': '2013-12-09T16:38:34.207', 'AnswerCount': '0', 'CommentCount': '13', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6815', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-12-09T03:19:15.097', 'Id': '18769'}{'Body': "<p>I know that the set partitioning problem defined like this:</p>\n\n<p>Given $S = \\left\\{ x_1, \\ldots x_n \\right\\}$, find $S_1$ and $S_2$ such that $S_1 \\cap S_2 = \\emptyset$, $S_1 \\cup S_2 = S$ and $\\sum_{x_i \\in S_1} x_i=\\sum_{x_i \\in S_2} x_i.$</p>\n\n<p>is NP-complete. But I don't understand why (or am not even sure if) the following problem is NP-complete:</p>\n\n<p>Given $S = \\left\\{ x_1, \\ldots x_n \\right\\}$, find $S_1$ and $S_2$ such that $S_1 \\cap S_2 = \\emptyset$, $S_1 \\cup S_2 = S$ and $\\vert \\sum_{x_i \\in S_1} x_i-\\sum_{x_i \\in S_2} x_i \\rvert$ is minimized.</p>\n\n<p>The paper 'The Differencing Method of Set Partitioning' by Karp and Karmarkar and some others say that it is NP-complete. But, if I have a sample solution to this problem, I can not tell whether it is an optimal solution (unlike in the first problem) and therefore I feel it NP-hard. If this is not true, how can I conclude that it is NP-complete? Thanks! </p>\n", 'ViewCount': '123', 'Title': 'Is the set partitioning problem NP complete?', 'LastActivityDate': '2013-12-09T18:45:42.057', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11962', 'Tags': '<complexity-theory><polynomial-time><partition-problem>', 'CreationDate': '2013-12-09T18:10:13.013', 'Id': '18782'}{'ViewCount': '61', 'Title': 'CNF SAT conversions', 'LastEditDate': '2013-12-10T00:58:52.430', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8508', 'FavoriteCount': '1', 'Body': '<p>I am interested in reductions from 3-CNF boolean expressions to similar restricted forms. For example, I am interested in knowing how to reduce a 3-CNF formula to another 3-CNF formula where each variable appears in at most $b$ clauses. I observed this is used in MAX-SAT so I am interested in knowing such reductions. Is there a paper/book that contains descriptions of such forms and their properties?</p>\n', 'Tags': '<complexity-theory><reductions><satisfiability>', 'LastEditorUserId': '8508', 'LastActivityDate': '2013-12-10T01:07:49.217', 'CommentCount': '0', 'AcceptedAnswerId': '18805', 'CreationDate': '2013-12-09T22:05:24.017', 'Id': '18793'}{'Body': "<p>There's an <code>f(n)</code> such that <code>f(n) != O(f(n/2))</code></p>\n\n<p>so by the definition of big O notation:<br>\nfor <code>f(n) = n^2</code> the statement is false, because there is a constant c such that <code>n^2 = c*(n^2/2)</code></p>\n\n<p>Which f(n) will work?<br>\nMy guess is f(n) = 2. is that correct?  </p>\n", 'ViewCount': '49', 'Title': 'Big O Notation - Find a Function That Represents the Statement', 'LastActivityDate': '2013-12-09T22:33:40.627', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18795', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '11957', 'Tags': '<complexity-theory><asymptotics>', 'CreationDate': '2013-12-09T22:12:00.927', 'Id': '18794'}{'Body': "<p>I have a question asking about a language L with the property: there is a TM that decides L in time O(n^2013 / (log(n))^2012), and if there is a TM that decides L in time O(n^2012.9).</p>\n\n<p>My confusion comes from the first big O given, from what I understand the numerator would dominate as the TM grows towards infinity, so it would end up being O(n^2013), which would grow faster then O(n^2012.9), so there could not be a TM that decides L in time O)n^2012.9). But I'm not sure how to go about proving this. Is there some theorem that let's you compare O(n^2/log(n)) with O(n) or something to that extent?</p>\n", 'ViewCount': '42', 'ClosedDate': '2013-12-10T09:00:33.683', 'Title': 'Big O confusion', 'LastActivityDate': '2013-12-10T03:30:33.863', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11300', 'Tags': '<complexity-theory><time-complexity><landau-notation>', 'CreationDate': '2013-12-10T01:44:42.587', 'FavoriteCount': '1', 'Id': '18808'}{'Body': "<p>I am having an extremely tough time with this homework question, wondering if anyone could help me (for all you theory aficionados, this one's for you).</p>\n\n<p><em>There is a language $L$ with the following property: There is a Turing machine that decides $L$ in time $O(n^{2013}/\\log^{2012} n)$, but there is no Turing machine that decides $L$ in time $O(n^{2012.9})$.</em> Is this statement TRUE or FALSE?</p>\n\n<p>My notion/idea is to use this Corollary that stems from the Time Hierarchy Theorem: <em>For any two real numbers $1 \\le e_1 &lt; e_2$, we have $\\mathrm{TIME}(n^{e_1}) \\subsetneq \\mathrm{TIME}(n^{e_2})$</em>. I think I am on the right track but I need some help with this proof.</p>\n", 'ViewCount': '141', 'Title': 'Are there problems with complexity between $O(n^c/\\log^b n)$ and $O(n^{c - \\varepsilon})$?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-10T09:37:20.407', 'LastEditDate': '2013-12-10T07:58:18.613', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '18816', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11979', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2013-12-10T03:12:31.800', 'Id': '18810'}{'Body': "<p>Let Two-Solutions-SAT be the language of Boolean formulas that have exactly two distinct satisfying assignments. Show Two-Solutions-SAT is co-NP-hard.</p>\n\n<p>I know how to show that the complement of Two-Solutions-SAT is in NP, it's relatively easy to create a nondeterministic polynomial time TM that decides it.</p>\n\n<p>My problem comes with reducing from SAT to the complement of Two-Solutions-SAT. I understand how to reduce from SAT to 3SAT, but in the case of 3SAT you will always have CNF's with 3 variables. With the complement of Two-Solutions-SAT, you have to somehow reduce to the case where you have 0 or 1 or >= 3 distinct satisfying assignments, and I'm not sure how to go about reducing to that.</p>\n\n<p>Thanks</p>\n", 'ViewCount': '260', 'Title': 'Question on SAT reduction', 'LastActivityDate': '2013-12-12T02:56:18.300', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '18909', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11300', 'Tags': '<complexity-theory><np-complete><reductions><np-hard>', 'CreationDate': '2013-12-10T05:24:42.023', 'FavoriteCount': '1', 'Id': '18815'}{'Body': '<p>Recently, I am reading papers about <em>dichotomy</em>. I do not understant what condition can be called as a <em>dichotomy</em>? What is the meaning of "a question is either in <strong>P</strong> or in <strong>NP</strong>-<em>complete</em>"? (assume <strong>P</strong> $\\neq$ <strong>NP</strong>)</p>\n\n<p>For example, I\'ve known the Schaefer\'s dichotomy theorem, in which a dichotomy about "whether a class of SAT is in <strong>P</strong>" is given. In this theorem, the dichotomy contains six conditions, one of them is "2-SAT". </p>\n\n<p>So my question is that, whether "2-SAT" itself can be called as a <em>dichotomy</em> or a trivial <em>dichotomy</em>, because 2-SAT is in <strong>P</strong> but 3-SAT is <strong>NP</strong>-<em>complete</em>? In another words, I wonder that "if a special class of an <strong>NP</strong>-<em>complete</em> problem is in <strong>P</strong>, then this class is a dichotomy? or a trivial dichotomy?"</p>\n', 'ViewCount': '123', 'Title': 'What is a dichotomy? Whether 2-SAT itself is a dichotomy of SAT?', 'LastActivityDate': '2013-12-11T11:02:42.043', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '18868', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '12018', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'CreationDate': '2013-12-11T07:52:17.700', 'Id': '18865'}{'Body': "<p>I have a question on my homework causing some confusion.  </p>\n\n<blockquote>\n  <p>If L is a strict subset of L', and L' is a member of Co-NP, is L a member of Co-NP? True of False</p>\n</blockquote>\n\n<p>Now I understand what belonging to Co-NP. Essentially means instead of deciding a yes instance we're deciding a no instance of the decidable problem.  I'm stuck on interpreting L' and what it is.</p>\n\n<p>My guess at this point is that L is a member of Co-NP since it's a subset of L' which we're given is in Co-NP.</p>\n", 'ViewCount': '125', 'Title': 'Is Co-NP closed under taking subset?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-12T10:52:15.023', 'LastEditDate': '2013-12-11T16:14:03.290', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10773', 'Tags': '<complexity-theory><closure-properties><np>', 'CreationDate': '2013-12-11T16:01:15.793', 'Id': '18880'}{'Body': u"<p>Are NP or P closed under subtraction? Im having a hard time deciding whether they are or aren't.\n<em>Question was edited</em></p>\n\n<p><strong>Original question</strong>:\nIm having some hard time figuring out what languages are closed under subtraction.\nSay you have 2 languages A, B \u2208 NP. Is A\\B \u2208 NP? what about P?</p>\n\n<p><strong>Commenters</strong>:\nMy original question was extremely not accurate so i rephrased :)</p>\n\n<p>Thanks!</p>\n", 'ViewCount': '97', 'Title': 'Complexity classes that are closed under subtraction', 'LastEditorUserId': '12040', 'LastActivityDate': '2013-12-11T23:21:43.957', 'LastEditDate': '2013-12-11T23:17:20.347', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '18903', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12040', 'Tags': '<complexity-theory><closure-properties><np>', 'CreationDate': '2013-12-11T20:57:30.853', 'Id': '18897'}{'Body': '<p>I have little background with SAT sovers and theoretical computer science.</p>\n\n<p>How can I describe the complexity of calculating all models of a propositional formula versus just the usual SAT problem of finding just one model?</p>\n\n<p>I am writing a paper, in an area where finding a single of a model of a type of propositional formula is considered "easy", but for my reasearch I need to calculated all models. (I am using Picosat that can calculate all models of a logic formula.) Is there a way to describe how "hard" or "complex" finding all models is compared to finding a single model?</p>\n', 'ViewCount': '20', 'Title': 'Complexity of calculating a single model versus all models of a propositional formula with a SAT solver', 'LastActivityDate': '2013-12-12T09:02:45.050', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18918', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1829', 'Tags': '<complexity-theory><np-complete><satisfiability><sat>', 'CreationDate': '2013-12-12T07:19:46.190', 'FavoriteCount': '1', 'Id': '18912'}{'Body': u'<p>I\'m learning about asymptotic analysis, and have seen some exotic looking complexities living between other common ones. For instance "log log n" is strictly between 1 and log n. It makes me wonder if one can always find complexities between any other two.</p>\n\n<p>Specifically, for any functions f and g with O(f) \u2282 O(g) does there always exist an h such that O(f) \u2282 O(h) \u2282 O(g)?</p>\n\n<p>This isn\'t homework or anything. I\'m just curious if anyone knows.</p>\n', 'ViewCount': '106', 'Title': 'Is there always a Big Oh complexity strictly between any two others?', 'LastActivityDate': '2013-12-14T20:58:16.143', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '18994', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '12119', 'Tags': '<complexity-theory><time-complexity><asymptotics>', 'CreationDate': '2013-12-14T20:02:02.963', 'FavoriteCount': '1', 'Id': '18993'}{'Body': '<p>Consider the following variation (let us call it Q) on the Vertex Cover problem: Given a Graph G and a number K, we are asked if there is a k-cover of G so that it is the minimum cover.\nMy question is: How may one prove that Q can be reduced to the general Vertex Cover problem?\nAnd, more generally, what is the approach to solve such a reduction, from "is there a k..." to\n"is k the minimum/maximum?"? I have a hunch on the methodology but am not sure and would appreciate a wiser opinion than that of myself on the subject.</p>\n\n<p>My hunch is the following: First of all, we take into consideration the following fact:\nif there is a k-1 cover of G, then we will surely have a k cover of G, just by adding a random node to the k-1 cover ( the cover property holds if we add nodes ). Thus, We can reformulate Q this way: Is there a k-cover of G, so that there is no (k-1)-cover of the graph? From this reformulation it is clear that an instance of Q reduces to 2 instances of the original decision version of the Vertex Cover.</p>\n', 'ViewCount': '46', 'Title': 'Reduce variant of Vertex Cover to original decision-version Vertex cover problem', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-10T08:48:36.473', 'LastEditDate': '2014-02-10T08:48:36.473', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18999', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12121', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2013-12-14T21:34:34.557', 'Id': '18997'}{'ViewCount': '142', 'Title': 'Problems that are NP but polynomial on graphs of bounded treewidth', 'LastEditDate': '2013-12-16T12:50:01.927', 'AnswerCount': '4', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '4598', 'FavoriteCount': '1', 'Body': '<p>I <em>heard</em> <a href="http://www.youtube.com/watch?v=cQwhYtTfZCs&amp;list=PLawkBQ15NDElkyLbJBKwZCgA5jxsKRlK-&amp;index=22" rel="nofollow">here</a> that the Hamiltonian cycle problem is polynomial on graphs of bounded treewidth.</p>\n\n<p>I am interested in examples/references to different problems which is essentially hard but having polynomial complexity on graphs of bounded treewidth. </p>\n', 'Tags': '<complexity-theory><graph-theory><reference-request><np><polynomial-time>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-05T14:13:58.150', 'CommentCount': '0', 'AcceptedAnswerId': '19036', 'CreationDate': '2013-12-15T20:00:48.920', 'Id': '19019'}{'Body': '<p>Given two NP NP-hard functional problems, A and B, one can find a reduction of A to B. Is it possible to find a reduction that would honour approximations? That is, if you have an approximation algorithm for B that yield approximate solutions within accuracy $\\delta$, is it possible to reduce A to B in such a way that one would be able to derive an approximate solution of A within accuracy $\\epsilon = \\epsilon(\\delta)$?</p>\n', 'ViewCount': '85', 'Title': 'Approximation algorithms for NP-complete problems', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-19T05:48:21.523', 'LastEditDate': '2013-12-16T20:06:37.607', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10447', 'Tags': '<complexity-theory><reductions><approximation-algorithms>', 'CreationDate': '2013-12-16T18:26:00.343', 'Id': '19050'}{'Body': '<p>The theory of NP-completeness was initially built on Cook (polynomial-time Turing) reductions. Later, Karp introduced polynomial-time many-to-one reductions. A Cook reduction is more powerful than a Karp reduction since there is no restriction on the number of calls to the oracle. So, I am interested in NP-complete graph problem that does not have a known Karp reduction from a NP-complete problem. </p>\n\n<blockquote>\n  <p>Is there a natural graph problem known to be $NP$-complete only under Cook reduction, but not known to be NP-complete under Karp reductions?</p>\n</blockquote>\n', 'ViewCount': '129', 'Title': 'Graph problem known to be $NP$-complete only under Cook reduction', 'LastEditorUserId': '755', 'LastActivityDate': '2013-12-18T08:06:32.597', 'LastEditDate': '2013-12-18T08:06:32.597', 'AnswerCount': '0', 'CommentCount': '8', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2013-12-17T20:00:33.290', 'FavoriteCount': '1', 'Id': '19069'}{'Body': '<p><strong>Background:</strong> The <code>Exact-3D-Matching</code> problem is defined as follows (The definition is from Jeff\'s lecture note: <a href="http://www.cs.uiuc.edu/~jeffe/teaching/algorithms/notes/29-nphard.pdf" rel="nofollow">Lecture 29: NP-Hard Problems</a>. You can also refer to <a href="https://en.wikipedia.org/wiki/3-dimensional_matching" rel="nofollow">3-dimensional matching</a>):</p>\n\n<blockquote>\n  <p><em>Exact-3D-Matching:</em> Given a set $S$ and a collection of three-element subsets of $S$, called <em>triples</em>, is there a sub-collection of disjoint triples that exactly cover $S$?</p>\n</blockquote>\n\n<p>The <code>3-Partition</code> problem is defined as (It is also from <a href="http://www.cs.uiuc.edu/~jeffe/teaching/algorithms/notes/29-nphard.pdf" rel="nofollow">Lecture 29: NP-Hard Problems</a>. You can also refer to <a href="https://en.wikipedia.org/wiki/3-partition_problem" rel="nofollow">3-partition problem</a>.):</p>\n\n<blockquote>\n  <p>Given a set $S$ of $3n$ integers, can it be partitioned into $n$ disjoint three-element subsets, such that every subsets has exactly the same sum?</p>\n</blockquote>\n\n<p>It is known that the <code>3-Partition</code> problem can be proved to be NP-complete by reducing the NP-complete <code>Exact-3D-Matching</code> problem to it. And the NP-completeness of the <code>Exact-3D-Matching</code> problem is proved by reducing the <code>3SAT</code> problem to it (both are given in the book <a href="https://en.wikipedia.org/wiki/Computers_and_Intractability" rel="nofollow">Computers and Intractability: A Guide to the Theory of NP-Completeness</a>).</p>\n\n<p><strong>Problem:</strong> \nMy problem is:</p>\n\n<blockquote>\n  <p>How to prove the NP-completeness of the <code>Exact-3D-Matching</code> problem by reducing the <code>3-Partition</code> problem to it?</p>\n</blockquote>\n\n<p>I have found neither papers nor lecture notes on it.</p>\n', 'ViewCount': '131', 'Title': 'How to prove the NP-completeness of the ``Exact-3D-Matching`` problem by reducing the ``3-Partition`` problem to it?', 'LastEditorUserId': '4911', 'LastActivityDate': '2013-12-19T14:18:21.653', 'LastEditDate': '2013-12-19T11:13:30.527', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '19095', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<complexity-theory><np-complete><np-hard>', 'CreationDate': '2013-12-18T09:41:58.583', 'Id': '19092'}{'Body': '<p>I came across an interesting procedure that ranks (sorts) a set of tuples, <em>not</em> by comparisons between tuples, but by the proximity between <em>next</em> tuple(s) and the set of tuples already ranked.</p>\n\n<p>Specifically, consider the ranking procedure as follows,</p>\n\n<p>Input: $D=\\{p_i\\mid p_i \\in \\mathbb{R}^2, i=1, 2,\\ldots,n\\}$, $i_{start} \\in \\{1, 2,\\ldots, n\\}$, and distance metric $f: 2^D \\times D \\mapsto \\mathbb{R}_{\\ge 0}$<br>\nOutput: $\\Pi = \\left[ i_1, i_2, \\ldots, i_n\\right]$</p>\n\n<ol>\n<li>$\\Pi \\gets \\left[~ \\right]$; // empty sequence</li>\n<li>$A \\gets \\emptyset$;  </li>\n<li>$i_{next} \\gets i_{start}$;  </li>\n<li>while $D \\neq \\emptyset$  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$\\Pi \\gets \\Pi \\oplus i_{next} $ // append $i_{next}$ to sequence</li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$A \\gets A \\bigcup \\left\\{ p_{i_{next}} \\right\\}$; // $p_{i_{next}}$ is a tuple from $D$ identified by subscript ${i_{next}}$  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$D \\gets D \\setminus \\left\\{p_{i_{next}}\\right\\}$;  // same $p_{i_{next}}$ as in line 6  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;${i_{next}} \\gets \\min \\bigl\\{\\arg_j\\,\\min_{p_j\\in D}\\,f(A, p_j) \\bigr\\}$; // not defined when $D = \\emptyset$   </li>\n</ol>\n\n<p>An example of the distance metric $f(A, p)$ is, say, the distance between 2D point $p$ and the centroid of 2D points in set $A$. As such, the procedure is literally the expansion of a cluster of 2D points, starting from a given point $p_{start}$, until all $n$ points from $D$ have been included. And the sequence $\\Pi$ records the order by which points from $D$ are included in the cluster.</p>\n\n<p>Could anyone shed some light on the literature, background, or well-known examples, of such ranking procedures? In particular, are there any previous results on the complexity bounds of such a procedure perhaps under different types of distance metrics?</p>\n', 'ViewCount': '93', 'Title': 'On ranking (sorting) by a varying distance metric', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-23T13:08:49.810', 'LastEditDate': '2013-12-23T13:08:49.810', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7644', 'Tags': '<algorithms><complexity-theory><reference-request><sorting><ranking>', 'CreationDate': '2013-12-19T18:41:36.297', 'FavoriteCount': '1', 'Id': '19128'}{'Body': '<p>I got stuck in Ladner\'s Proof while reading "Computational Complexity: A Modern Approach" by Sanjeev Arora and Boaz Barak. Pardon me if I\'m missing something really obvious here but the authors do the following:</p>\n\n<p>For every function $H\\colon\\mathbb{N}\\to\\mathbb{N}$ define</p>\n\n<p>$$SAT_H=\\{\\psi01^{n^{H(n)}}: \\psi \\in SAT \\ and \\ n=|\\psi|\\}$$</p>\n\n<p>Now $H$ is defined as follows:</p>\n\n<p>$H(n)$ is the smallest number $i&lt;\\log \\log n$ such that for every $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$, $M_i$ (TM encoded by binary representation of $i$) outputs $SAT_H (x)$ within $i|x|^i$ steps. If there is no such number $i$ then $H(n)=\\log \\log n$.</p>\n\n<p>$M_i$ outputs $SAT_H (x)$ is equivalent to the statement that: The machine $M_i$ on an input $x$ outputs a 1 $\\iff$ $x \\in SAT_H$.</p>\n\n<p>My question is:\nBy definition of $SAT_H$, every string in it will have length exactly $n+1+n^{H(n)}$. </p>\n\n<p>For every string $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$, we note that $|x|&lt;n+1+n^{H(n)}$. So there does not exist any string $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$ and $x \\in SAT_H$. </p>\n\n<p>This would mean that the machine $M_i$ should trivially output 0 for every string $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$. But then how would such an argument be used for a proof? Where exactly am I going wrong?</p>\n', 'ViewCount': '67', 'Title': "A doubt in Ladner's Proof", 'LastEditorUserId': '683', 'LastActivityDate': '2013-12-23T09:34:11.867', 'LastEditDate': '2013-12-23T09:25:00.680', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19206', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8912', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-23T08:00:38.603', 'Id': '19205'}{'Body': '<p>Is the complexity class $P$ closed under rotation, where rotation is defined as $\\text{rot}(L) = \\{ wv \\mid vw \\in L \\}$?  How would we prove it?</p>\n', 'ViewCount': '87', 'Title': 'Class P is closed under rotation?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-12-24T00:43:16.683', 'LastEditDate': '2013-12-24T00:43:16.683', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '19223', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12323', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-23T19:49:22.403', 'Id': '19220'}{'Body': '<p>As I understand, to show that a certain problem $P$ is NP-hard we can reduce a known NP-hard problem $Q$ to a problem in $P$. This reduction, say $f$, has to be polynomial time. </p>\n\n<p>Could someone please explain is it necessary that $f$  maps each instance of $q\\in Q$ to $P$ or can we map a selected  subset of $\\tilde Q \\in Q$ to $P$? i.e. does pre-image of $f$ has to be be all of $Q$ or can it be a subset of $Q$?</p>\n\n<p>Thanks</p>\n', 'ViewCount': '112', 'Title': 'NP-hard proof: Polynomial time reduction', 'LastActivityDate': '2013-12-24T13:40:34.447', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '19248', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-24T03:43:33.370', 'Id': '19228'}{'Body': '<p>When we say a problem is NP-hard is that a property of a set of problems or is it a property of a instance of the set of problems?</p>\n', 'ViewCount': '50', 'Title': 'NP-hard: an instance or a set?', 'LastActivityDate': '2013-12-24T14:35:21.543', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-24T03:53:04.950', 'Id': '19229'}{'Body': '<p>Suppose a parameter $\\hat{k}$ is larger than another parameter $k$, assume that $k$ is bounded \nby a function $f$ of $\\hat{k}$. </p>\n\n<p>How can we prove that if a problem is FPT with respect to $k$ implies it is FPT w.r.to $\\hat{k}$.</p>\n', 'ViewCount': '39', 'Title': 'Fixed Parameter Algorithms', 'LastActivityDate': '2013-12-24T10:15:26.153', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '6522', 'Tags': '<algorithms><complexity-theory>', 'CreationDate': '2013-12-24T05:19:04.430', 'Id': '19233'}{'Body': u"<p>Algorithms for the finding of an MST in a graph can be applied for both maximum and minimum spanning trees.</p>\n\n<p>It is well known, however, that the finding of a max-cut in a graph is an NP-hard problem while the min-cut problem can be easily solved in polynomial time.</p>\n\n<p>Why aren't the two equivalent? </p>\n\n<p>What is the restriction that I\u2019m missing here? </p>\n\n<p>Thanks!</p>\n", 'ViewCount': '49', 'Title': 'Reduction from max-cut to min-cut', 'LastActivityDate': '2013-12-25T00:43:05.643', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19265', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12356', 'Tags': '<complexity-theory><graph-theory><np-complete>', 'CreationDate': '2013-12-24T22:17:23.767', 'Id': '19263'}{'Body': "<p>Lets assume $P = NP$. Can we say if every language $L \\in P$, then $L \\in NPC$?</p>\n\n<p>I read $P \\subseteq NP$, which means that $L\\in NP$. So I know for example, that a language can be $NP \\text{ hard}$, but it doesn't have to be in $NP$, e.g. $HALT$.</p>\n\n<p>But what about the case above. Is the language also $NPC$?</p>\n", 'ViewCount': '141', 'Title': 'P vs NP: Assuming P = NP', 'LastEditorUserId': '11941', 'LastActivityDate': '2013-12-28T00:21:54.187', 'LastEditDate': '2013-12-27T17:43:11.793', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11941', 'Tags': '<complexity-theory><np-complete><np-hard><np><polynomial-time>', 'CreationDate': '2013-12-27T17:37:27.420', 'Id': '19328'}{'Body': '<p>Given integers $n,m$, I want to find a $m \\times n$ binary matrix $X$ such that there does not exist any non-zero vector $y \\in \\{-1,0,1\\}^n$ with $Xy=0$ (all operations performed over $\\mathbb{Z}$).  What algorithm could I use for this?</p>\n\n<hr>\n\n<p>In more detail: We are given parameters $n$ and $m$.  The problem is to determine if there exists $x$ such that $x_{i,j} \\in \\{0,1\\}$, and there does not exist $y\\ne (0,0,\\dots,0)$ where $y_j \\in \\{-1,0,1\\}$ for all $j$ and for all $1 \\leq i \\leq m$,</p>\n\n<p>$$\\sum_{1 \\leq j \\leq n} x_{i,j} y_j = 0.$$</p>\n\n<p>(Notice that we require that at least one of the  $y_j \\ne 0$ to avoid the trivial solution.)</p>\n\n<p>For example, consider $m=3,n=4$.  Then, expressing $x_{i,j}$ as a matrix $X$,</p>\n\n<p>$$\nX=\\begin{pmatrix}\n0 &amp; 1 &amp; 1 &amp; 0 \\\\\n1 &amp; 0 &amp; 1 &amp; 1 \\\\\n0 &amp; 1 &amp; 0 &amp; 1 \\\\\n\\end{pmatrix}\n$$</p>\n\n<p>is a valid solution for $m=3$ and $n=4$.</p>\n\n<p>What algorithm can I use to solve this problem?  Can I formulate this as an integer linear programming problem or maybe as a constraint programming problem?</p>\n', 'ViewCount': '205', 'Title': 'Find a binary matrix so that no vector from {-1,0,1}^n is in its kernel', 'LastEditorUserId': '8942', 'LastActivityDate': '2014-01-03T13:18:40.517', 'LastEditDate': '2014-01-03T13:13:21.270', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '8942', 'Tags': '<complexity-theory><linear-programming><linear-algebra><constraint-programming><integer-programming>', 'CreationDate': '2013-12-27T20:07:50.993', 'FavoriteCount': '1', 'Id': '19333'}{'Body': '<p>I have a problem $A$ which was shown to be PSPACE-complete by reduction from planning. \nHowever, $A$ can also be transformed into reachability problem which is NL-complete. </p>\n\n<p>I know that $NL=NSPACE(log \\ n)$ and $PSPACE=NSPACE$.  </p>\n\n<p>Does this mean $A$ is also NL-complete? IF yes, does it make any difference in this context to say whether $A$ is PSPACE-complete or NL-complete ?</p>\n', 'ViewCount': '40', 'Title': 'If a problem is PSPACE-complete what do we know about NL-completeness', 'LastEditorUserId': '4598', 'LastActivityDate': '2013-12-30T11:18:50.060', 'LastEditDate': '2013-12-30T10:57:07.170', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19374', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4598', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2013-12-30T10:46:46.743', 'Id': '19373'}{'Body': '<p><a href="http://en.wikipedia.org/wiki/Karp%27s_21_NP-complete_problems" rel="nofollow">Karp\'s 21 NP-complete problems</a> show that 0-1 integer linear programming is NP-hard. That is, an integer linear program with binary variables.</p>\n\n<p>If we set the $c^T$ vector of the objective $\\text {maximize } c^Tx$ to all one (unweighted, i.e., $c^T=(1,1,\\dots,1)$) is the problem still NP-hard?</p>\n', 'ViewCount': '95', 'Title': 'Is 0-1 integer linear programming NP-hard when $c^T$ is the all-ones vector?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-12-31T06:22:31.170', 'LastEditDate': '2013-12-31T06:21:22.400', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19379', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory><np-hard><linear-programming>', 'CreationDate': '2013-12-30T16:49:35.700', 'Id': '19378'}{'Body': "<p>We know that P=NP implies NP=coNP. Does the reverse implication hold?\nDoes NP equal coNP imply that P equals NP?\nIf not why not?</p>\n\n<p>I googled but didn't find the answer.</p>\n", 'ViewCount': '92', 'Title': 'Does NP=coNP imply P=NP?', 'LastActivityDate': '2013-12-30T22:18:10.463', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '12473', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-30T21:54:51.407', 'FavoriteCount': '1', 'Id': '19389'}{'Body': '<p>A problem is in NP if a correct answer to it can be verified to be so in polynomial time.  </p>\n\n<p>A problem is in co-NP if an incorrect answer to it can be verified to be so in polynomial time.  </p>\n\n<p>P is a subset of the intersection of the sets NP and co-NP.</p>\n\n<p>My question is: what is a <strong>specific</strong> problem that is in the intersection of co-NP &amp; NP, but is not in P?</p>\n', 'ViewCount': '127', 'Title': 'Is there a specific problem that is in both NP and co-NP but not in P?', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-01-11T02:03:35.730', 'LastEditDate': '2014-01-11T02:03:35.730', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '4700', 'Tags': '<complexity-theory><np>', 'CreationDate': '2013-12-31T09:28:09.233', 'FavoriteCount': '1', 'Id': '19399'}{'Body': '<p>It is well known that the maximization problem of Knapsack if NP-hard. How about just finding a feasible solution i.e. objective is set to zero? </p>\n\n<p>And also if we set the <a href="http://en.wikipedia.org/wiki/Knapsack_problem" rel="nofollow">values</a> to all one (not the weights) in the objective of the Knapsack problem is it still NP-hard i.e. $\\max v^Tx$ where $v=(1,1,1..,1)$?</p>\n', 'ViewCount': '36', 'Title': 'Is Knapsack Feasibility and Knapsack with Unit Values NP-Hard?', 'LastEditorUserId': '12321', 'LastActivityDate': '2013-12-31T19:40:12.600', 'LastEditDate': '2013-12-31T14:47:47.303', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '19420', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory>', 'CreationDate': '2013-12-31T14:30:50.637', 'Id': '19409'}{'Body': '<p>Given two languages $L_1$ and $L_2$ that are in $\\mathsf{P}$, can it be proven that there is a polynomial time reduction from $L_1$ to $L_2$ and vice versa? If so, how?</p>\n\n<p>I noticed that if $L_1$ is the empty language, and $L_2$ is the "full language" $\\{ 0,1 \\}^*$, there does not seem to be a reduction from $L_2$ to $L_1$, but this is not clear to me. I know how a reduction works, so that is not a problem for me.</p>\n', 'ViewCount': '97', 'Title': 'Does two languages being in P imply reduction to each other?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-03T14:04:01.493', 'LastEditDate': '2014-01-03T14:04:01.493', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '19428', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12504', 'Tags': '<complexity-theory><reductions><polynomial-time>', 'CreationDate': '2013-12-31T22:04:51.200', 'Id': '19427'}{'Body': '<p>In the theory of NP-completeness, researchers refer to the concept of combinatorial  explosion. Some researchers use it as justification for intractability or NP-completeness. Others use it to refer to the exponential growth of possible solutions of an intractable problem while others use to refer to the apparent exponential time required to solve NP-complete problems. I am interested in formal connection to combinatorics.</p>\n\n<blockquote>\n  <p>Is there combinatorial basis that captures and explains the phenomena of combinatorial explosion?</p>\n</blockquote>\n', 'ViewCount': '295', 'Title': 'What is combinatorial explosion?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-03T06:40:58.943', 'LastEditDate': '2014-01-03T06:40:58.943', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><terminology><combinatorics>', 'CreationDate': '2014-01-02T17:49:02.183', 'FavoriteCount': '2', 'Id': '19459'}{'Body': u'<p>The following array occupies 10000 slots in memory:</p>\n\n<pre><code>a = [0,1,2,3,4,5,6,7,8,9,10,...,10000]\n</code></pre>\n\n<p>But one could easily represent the same array as:</p>\n\n<pre><code>a = {len:10000, get: \u03bb idx -&gt; idx}\n</code></pre>\n\n<p>Which is much more compact. Similarly, there are several arrays that can be represented compactly:</p>\n\n<pre><code>a = {a:1000, get: \u03bb idx -&gt; idx * 2}\nIs a description for [0,2,4,6,8,10,...,2000]\n\na = {a:1000, get \u03bb idx -&gt; idx ^ 2}\nIs a description for [0,1,2,4,9,...1000000]\n\nAnd so on...\n</code></pre>\n\n<p>Providing so many arrays can be represented in much shorter ways than storing each element on memory, I ask:</p>\n\n<ol>\n<li>Is there a name for this phenomena?</li>\n<li>Is there a way to find the minimal representation for a specific array?</li>\n<li>Considering this probably depends on the language of description (in this case, I used an imaginary programming language with functions, objects and math operators). Is there a specific language that is optimal for finding that kind of minimal description for objects?</li>\n</ol>\n', 'ViewCount': '91', 'Title': 'How to find the minimal description for an array?', 'LastActivityDate': '2014-01-28T15:05:22.407', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '11547', 'Tags': '<algorithms><complexity-theory><formal-languages><programming-languages><data-compression>', 'CreationDate': '2014-01-04T23:53:15.990', 'Id': '19501'}{'Body': '<p>In <a href="http://www.dece.nctu.edu.tw/files/writing/7180_8835b76e.pdf" rel="nofollow">this</a> paper (page 3 Theorem 1) the authors want to prove that their problem is NP-complete. Their method is as follows. Let their problem be known as $P$. They show that their problem can be written as a $0\\text{-}1$ integer program. Then they claim that $0\\text{-}1$ integer programs are NP-complete and therefore their problem $P$ is NP-complete.</p>\n\n<p>I find this proof hard to believe. For the problem $P$ to be NP-hard I think one has to reduce the $0\\text{-}1$ integer program into an instance of problem $P$ and not the other way around.</p>\n\n<p>Please can someone explain if this proof in the paper is acceptable? </p>\n', 'ViewCount': '129', 'Title': 'Can one reduce a problem of unknown complexity to a hard problem to show hardness?', 'LastEditorUserId': '472', 'LastActivityDate': '2014-01-07T14:09:03.943', 'LastEditDate': '2014-01-06T22:02:58.273', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '19555', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2014-01-06T19:50:00.527', 'Id': '19541'}{'ViewCount': '108', 'Title': 'Existence of NP problems with complexity intermediate between P and NP-hard', 'LastEditDate': '2014-01-07T08:03:04.937', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10447', 'FavoriteCount': '0', 'Body': "<p>Assuming P!=NP, there is a result that there are decision problems intermediate between P and NP-complete. That is, the class NP cannot be a union of two disjoint subsets: P and NP-complete.</p>\n\n<p>I could never quite understand the proof of the above result. The proof I saw in a textbook was starting with the assumption that one can enumerate all P and NP-hard problems, and then proceeding with a construction of a function that didn't fit in either. However, this construction seemed a bit fishy to me; in particular, the assumption that one can start with enumerated set of problems in a particular class, the NP.</p>\n\n<p>Could you refer me to a clear self-contained proof of the statement in the 1st paragraph? More generally, what would be a good reference for proofs of such results?</p>\n", 'Tags': '<complexity-theory><reference-request><np><p-vs-np>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-07T21:14:35.700', 'CommentCount': '0', 'AcceptedAnswerId': '19566', 'CreationDate': '2014-01-06T20:23:25.287', 'Id': '19543'}{'Body': '<p>Consider the 3-SAT problem where the formula is in conjunctive normal form and we restrict the Boolean formulas such that the number of clauses in the formula is equal to the number of variables. Is this problem still NP-hard?</p>\n\n<p>For example, this formula has $3$ variables and has $3$ clauses $(\\lnot x_1 \\vee \\lnot x_2 \\vee \\lnot x_3 ) \\wedge (\\lnot x_1 \\vee \\lnot x_3) \\wedge (\\lnot x_2 \\vee \\lnot x_3)$,</p>\n\n<p>and the following formula has three variables but has only two clauses $(\\lnot x_1 \\vee \\lnot x_2 \\vee \\lnot x_3  ) \\wedge (\\lnot x_2 \\vee \\lnot x_3)$.</p>\n', 'ViewCount': '96', 'Title': '3-SAT problem with number of clauses equal to number of variables', 'LastEditorUserId': '472', 'LastActivityDate': '2014-01-09T09:28:49.803', 'LastEditDate': '2014-01-08T19:18:32.590', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19584', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory><np-hard><satisfiability>', 'CreationDate': '2014-01-08T16:54:27.993', 'Id': '19582'}{'Body': "<p>What's the name of a complexity class of optimization problems that have BPP approximations? That is, I'm looking for a class of problems that relates to APX as BPP relates to P.</p>\n", 'ViewCount': '66', 'Title': 'Almost always almost right', 'LastActivityDate': '2014-01-08T17:01:23.883', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '10447', 'Tags': '<complexity-theory>', 'CreationDate': '2014-01-08T17:01:23.883', 'Id': '19583'}{'Body': '<p><a href="https://github.com/gurgeh/CodeSpace">This Github repo</a> hosts a very cool project where the creator is able to, give an integer sequence, predict the most likely next values by searching the smallest/simplest programs that output that integer sequence. I was trying to approach the same idea using lambda-calculus instead of a stack-based language, but I was stuck on the enumeration of valid programs on LC\'s grammar.</p>\n\n<p>Anyway, what is the field studying that kind of idea and how can I grasp the current state-of-art?</p>\n', 'ViewCount': '94', 'Title': 'What is the field studying the search and generation of computer programs?', 'LastActivityDate': '2014-01-12T11:12:54.350', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '11547', 'Tags': '<algorithms><complexity-theory><formal-languages><computability><regular-languages>', 'CreationDate': '2014-01-09T20:37:06.207', 'Id': '19605'}{'Body': "<p>I'm aware some ints have higher or lower Kolmogorov Complexities. For example, the number <code>5.41126806512</code> has a very low complexity as it can be expressed by <code>17/pi</code>. I'm also aware that, though the KC varies depending on the expression language, it is always the same up to a given constant. So, I ask: is there a way to calculate an <strong>approximation</strong> of the KC for the first N ints?</p>\n", 'ViewCount': '87', 'Title': 'What is an estimation of the Kolmogorov Complexity for the first N integers?', 'LastActivityDate': '2014-01-12T23:58:08.803', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '11547', 'Tags': '<complexity-theory><kolmogorov-complexity>', 'CreationDate': '2014-01-10T03:59:57.223', 'Id': '19615'}{'Body': '<p>For example, how is it proven that any NP problem can reduce to subset sum, circuit satisfiability, etc.? Or could you link to a proof?</p>\n', 'ViewCount': '54', 'ClosedDate': '2014-01-10T09:06:55.770', 'Title': 'How do we know that all NP problems reduce to NP-hard problems?', 'LastActivityDate': '2014-01-13T03:08:58.583', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '19617', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12725', 'Tags': '<complexity-theory><np-complete><np-hard>', 'CreationDate': '2014-01-10T05:38:10.027', 'Id': '19616'}{'Body': '<p>As seen in <a href="http://xkcd.com/1313/">this recent XKCD strip</a> and <a href="http://nbviewer.ipython.org/url/norvig.com/ipython/xkcd1313.ipynb">this recent blog post</a> from Peter Norvig (and a Slashdot story featuring the latter), "regex golf" (which might better be called the regular expression separation problem) is the puzzle of defining the shortest possible regular expression that accepts every word in set A and no word in set B.  Norvig\'s post includes an algorithm for generating a reasonably short candidate, and he notes that his approach involves solving an NP-complete Set Cover problem, but he\'s also careful to point out that his approach doesn\'t consider every possible regular expression, and of course his isn\'t necessarily the only algorithm, so his solutions aren\'t guaranteed to be optimal, and it\'s also possible that some other assuredly polynomial-time algorithm could find equivalent or better solutions.</p>\n\n<p>For concreteness\' sake and to avoid having to solve the optimization question, I think the most natural formulation of Regular Expression Separation would be:</p>\n\n<blockquote>\n  <p>Given two (finite) sets $A$ and $B$ of strings over some alphabet $\\Sigma$, is there a regular expression of length $\\leq k$ that accepts every string in $A$ and rejects every string in $B$?</p>\n</blockquote>\n\n<p>Is anything known about the complexity of this particular separation problem?  (Note that since I\'ve specified $A$ and $B$ as finite sets of strings, the natural notion of size for the problem is the total lengths of all strings in $A$ and $B$; this swamps any contribution from $k$). It seems highly likely to me that it <em>is</em> NP-complete (and in fact, I would expect the reduction to be to some sort of cover problem) but a few searches haven\'t turned up anything particularly useful.</p>\n', 'ViewCount': '286', 'Title': 'Is regex golf NP-Complete?', 'LastEditorUserId': '242', 'LastActivityDate': '2014-01-22T00:39:07.057', 'LastEditDate': '2014-01-14T17:52:01.430', 'AnswerCount': '1', 'CommentCount': '17', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '242', 'Tags': '<complexity-theory><np-complete><regular-expressions>', 'CreationDate': '2014-01-13T09:26:28.640', 'FavoriteCount': '2', 'Id': '19686'}{'Body': '<p><strong>So we have two problems:</strong></p>\n\n<p>Problem A: Given a list of <strong>positive</strong> integers, decide whether the list contains a subset adding to a given number t.</p>\n\n<p>Problem B: Given a list of integers, decide whether the list contains a subset adding to 0.</p>\n\n<p>I have to prove that A can be reduced to B in polynomial time. And a really simple reduction came into mind. Here goes my proof.</p>\n\n<p>So let L be the list of positive integers from the problem A, I just create L\' add -t to the it, and pass L\' to B, this is the reduction.</p>\n\n<p>To prove this is a reduction, let\'s see that, <strong>L is a positive instance of A if and only if L\' is a positive instance of B</strong>. Am I doing it right?</p>\n\n<p>So first:</p>\n\n<p>=>) It\'s just obvious to prove that, given a list of integers which contains a subset adding up to t, this list, along with -t adds up to 0.</p>\n\n<p>&lt;=) Let S be the subset of L\' that adds up to 0. Given that, by construction, all integers in L\' are positive but one, which is -t, -t must be in S. If S contains the only negative number -t, and S adds up to 0, S{-t}, adds up to t. Then S{-t} is a subset of S{-t} = L that adds up to t. </p>\n\n<p><strong>Question:</strong> </p>\n\n<ul>\n<li><p>Is my proof correct? </p></li>\n<li><p>Is there any obvious mistake which makes it invalid? </p></li>\n<li><p>Are there any minor mistakes which could be fixed to "improve" it?</p></li>\n</ul>\n\n<p><strong>Extra question:</strong></p>\n\n<p>And also, I would like to ask a more generic question. Consider the problem A, but removing the "positive" part, so L can now contain both positive and negative numbers on it. I know A\' (the new A) is still reductible to B, because they both belong to the NP-complete problem class. So my other question is:</p>\n\n<ul>\n<li>How can I reduce A\' to B?</li>\n</ul>\n', 'ViewCount': '38', 'ClosedDate': '2014-01-13T16:03:11.043', 'Title': 'Is this reduction done correctly?', 'LastEditorUserId': '12801', 'LastActivityDate': '2014-01-13T17:32:17.800', 'LastEditDate': '2014-01-13T17:32:17.800', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12801', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2014-01-13T13:52:50.153', 'Id': '19692'}{'Body': u"<p>The following definitions are from Li, M., &amp; Vit\xe1nyi, P. (1997). An introduction to Kolmogorov complexity and its applications (2nd ed.), pg. 38.</p>\n\n<blockquote>\n  <p>A language $A$ is called <em>polynomial time Turing-reducible</em> to a language $B$, denoted as $A\\leq_T^P B$, if given $B$ as an <em>oracle</em>, there is a deterministic Turing machine that accepts $A$ in polynomial time. That is, we can accept $A$ in polynomial time given answers to membership of $B$ for free.</p>\n  \n  <p>A language $A$ is called <em>polynomial time many-to-one reducible</em> to a language $B$, denoted as $A\\leq_m^P B$, if there is a function $r$ that is a polynomial time computable, and for every $a$, $a\\in A$ iff $r(a)\\in B$. In both cases, if $B\\in P$, then so is $A$.</p>\n</blockquote>\n\n<p>Aren't the two definitions equivalent? What's the difference?</p>\n", 'ViewCount': '41', 'ClosedDate': '2014-02-07T06:13:16.147', 'Title': 'What\'s the difference between "polynomial time Turing-reducible" and "polynomial time many-to-one reducible"?', 'LastActivityDate': '2014-01-13T15:49:05.680', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1474', 'Tags': '<complexity-theory><time-complexity><polynomial-time>', 'CreationDate': '2014-01-13T15:22:35.997', 'Id': '19694'}{'Body': "<p>Is there a lower bound on the running time for solving 3-SAT if P = NP.  For instance, is it known that 3-SAT can't be solved in linear time?  What about quadratic?</p>\n", 'ViewCount': '112', 'Title': 'Lower bound on running time for solving 3-SAT if P = NP', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-16T13:38:40.363', 'LastEditDate': '2014-01-15T23:06:52.207', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19759', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8526', 'Tags': '<complexity-theory><satisfiability><lower-bounds>', 'CreationDate': '2014-01-15T21:59:30.103', 'Id': '19756'}{'ViewCount': '96', 'Title': 'Is DSPACE properly contained in NSPACE?', 'LastEditDate': '2014-01-17T22:20:45.957', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12901', 'FavoriteCount': '0', 'Body': '<p>It may be a dumb question, but is $\\mathsf{DSPACE}(f(n)) \\subset \\mathsf{NSPACE}(f(n))$ or is $\\mathsf{DSPACE}(f(n)) \\subseteq \\mathsf{NSPACE}(f(n))$?  In other words, is the containment relation proper or not?  Wikipedia says the first one, while the ComplexityZoo says the other one.</p>\n', 'Tags': '<complexity-theory><complexity-classes><space-complexity>', 'LastEditorUserId': '755', 'LastActivityDate': '2014-01-18T14:14:48.173', 'CommentCount': '1', 'AcceptedAnswerId': '19797', 'CreationDate': '2014-01-17T20:15:15.043', 'Id': '19794'}{'Body': '<p>As in title. Does $NSPACE(n) \\subseteq DTIME(2^n)$ ?</p>\n', 'ViewCount': '49', 'ClosedDate': '2014-01-21T12:59:56.790', 'Title': 'Does $DTIME(2^n)$ contain $NSPACE(n)$ ?', 'LastActivityDate': '2014-01-21T11:10:30.410', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12901', 'Tags': '<complexity-theory><complexity-classes>', 'CreationDate': '2014-01-21T10:04:02.517', 'Id': '19865'}{'Body': '<p>I have recently summarized several algorithms for the <a href="https://en.wikipedia.org/wiki/Maximum_disjoint_set" rel="nofollow">maximum disjoint set</a> problem. This problem is NP-hard, but it has both PTAS and sub-exponential algorithms. These algorithms seem to me closely related. The details vary, but the general idea is:</p>\n\n<ul>\n<li>For a PTAS: remove a small fraction of the input set (e.g. $O(\\sqrt{n})$ shapes). Partition the remaining input set to two subsets. Recursively find an approximate maximum set on each subset, and return the union of these two sets as the approximate solution.</li>\n<li>For a sub-exponential algorithm: instead of removing those $O(\\sqrt{n})$ shapes, check all possible subsets of them. For each subset, do the recursive step as in the PTAS. Return the best solution found. The runtime is dominated by the number of all possible subsets, which is $O(2^\\sqrt{n})$.</li>\n</ul>\n\n<p>Initially I thought that maybe every problem with a PTAS has a sub-exponential exact algorithm, but I haven\'t found such a relation so I assume it is not true. My questions are therefore:</p>\n\n<ul>\n<li>Are there problems with PTAS but provably no subexponential algorithms (no algorithms with runtime $O(2^{n^e})$ with $e&lt;1$)?</li>\n<li>Are there problems with subexponential algorithms but provably no PTAS?</li>\n</ul>\n', 'ViewCount': '27', 'Title': 'PTAS vs. exact-time sub-exponential algorithms', 'LastActivityDate': '2014-01-21T17:05:37.750', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<complexity-theory><time-complexity><np-complete>', 'CreationDate': '2014-01-21T17:05:37.750', 'Id': '19871'}{'Body': '<p>I have the following problem.</p>\n\n<blockquote>\n  <p>Maximize $\\sum\\limits_{m=1}^M\\sum\\limits_{n=1}^N x_{mn}$</p>\n  \n  <p>subject to: $\\sum\\limits_{\\substack{m^\\prime=1\\\\ m^\\prime \\neq m}}^M\\sum\\limits_{\\substack{n^\\prime=1\\\\ n^\\prime \\neq n}}^N \\alpha_{mn^\\prime}x_{m^\\prime n^\\prime} \\leq \\alpha_{mn},~~ \\forall~ m\\in\\{1, 2, \\cdots, M\\}, \\forall~ n\\in\\{1, 2, \\cdots, N\\} .$</p>\n  \n  <p>where, $x_{mn} \\in \\{0, 1\\}$, and $\\alpha_{mn} \\in \\mathbb{R} ~\\forall~ m\\in\\{1, 2, \\cdots, M\\}, \\forall~ n\\in\\{1, 2, \\cdots, N\\}$ </p>\n</blockquote>\n\n<p>Please can I say that this is a knapsack problem? \nIs there a way to find a reduction from knapsack problem? In the <a href="http://en.wikipedia.org/wiki/List_of_knapsack_problems" rel="nofollow">most basic form of knapsack problem</a>, if the weights are all equal 1 the optimal solution is easy to solve.</p>\n', 'ViewCount': '61', 'Title': 'Is this problem a knapsack problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-22T21:40:49.310', 'LastEditDate': '2014-01-22T21:40:49.310', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12683', 'Tags': '<complexity-theory><optimization><np-hard><knapsack-problems><integer-programming>', 'CreationDate': '2014-01-22T18:58:47.070', 'Id': '19897'}{'Body': '<p>I am writing a sprite sheet generator tool in adobe AIR, and I have to force with the question: How to pack a collection of 2D rectangles to smallest possible 2D rectangle with power of two. (like 1024x444).</p>\n\n<p>I think that this question is NP-Hard. I found good answer for it <a href="http://stackoverflow.com/a/4264497/1129332">here</a>.</p>\n\n<p>I thought about another option. What if I cut my rectangles to smaller rectangles. Will this make my life easier?</p>\n\n<p>My XML data will be more complicated, and I am not sure how this will effect the performance of the application that will use the cut sprite sheet.</p>\n\n<p>How ever the difficulty of such problem is probably belongs to P.</p>\n\n<p>Do you think it\'s possible? What am I missing here?</p>\n', 'ViewCount': '49', 'Title': 'Packing rectangles to generate a sprite sheet', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-23T18:11:51.577', 'LastEditDate': '2014-01-23T18:11:51.577', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10572', 'Tags': '<complexity-theory><tiling>', 'CreationDate': '2014-01-23T16:02:05.563', 'Id': '19915'}{'Body': '<p>Recently i\'ve been dealing with a problem that led me to the following questions:</p>\n\n<ul>\n<li>Is there a good algorithm to enumerate all maximum/perfect matchings in a general graph?</li>\n<li>Is there a good algorithm for finding all maximum/perfect matchings in a general graph?</li>\n<li>Are these two problems equivalent in their complexity?</li>\n</ul>\n\n<p>I\'ve stumbled upon the following references:</p>\n\n<ul>\n<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.8179&amp;rep=rep1&amp;type=pdf" rel="nofollow">Algorithms for Enumerating All Perfect Maximum and Maximal Matchings In Bipartite Graphs</a>- Suggesting an algorithm for enumerating all maximum matchings in a bipartite graph.</li>\n<li><a href="http://www.sciencedirect.com/science/article/pii/0893965994900450" rel="nofollow">Finding All the Perfect Matchings\nin Bipartite Graphs</a>- Suggesting an algorithm for finding all perfect matchings in bipartite graphs</li>\n</ul>\n\n<p>Both algorithms\' complexity depend on the number of perfect matchings in the graph (meaning exponential running time in the worst case).</p>\n\n<p>Moreover, both articles deal with bipartite graphs, I couldn\'t find similar articles dealing with the same problem in general graphs.</p>\n\n<p>I\'d appreciate information and references about the above problems.</p>\n', 'ViewCount': '131', 'Title': 'Counting and finding all perfect/maximum matchings in general graphs', 'LastEditorUserId': '10438', 'LastActivityDate': '2014-01-24T19:06:05.883', 'LastEditDate': '2014-01-24T16:12:01.350', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19926', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10438', 'Tags': '<algorithms><complexity-theory><graph-theory><reference-request><matching>', 'CreationDate': '2014-01-23T21:28:38.760', 'Id': '19924'}{'ViewCount': '60', 'Title': 'Is it possible to encode an arbitrary computation as a series of NP complete problem instances?', 'LastEditDate': '2014-01-25T16:40:32.763', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '13118', 'Body': '<p>For example, can I make a compiler that transforms a C program (Turing complete language) into a bunch of SAT instances.</p>\n\n<p>This encoding would be motivated as a way for specifying a problem piecemeal, where work on each piece could be verified in polynomial time.</p>\n', 'ClosedDate': '2014-02-02T11:29:06.923', 'Tags': '<complexity-theory><computability><np-complete>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-25T18:14:48.120', 'CommentCount': '6', 'AcceptedAnswerId': '19964', 'CreationDate': '2014-01-25T03:49:36.860', 'Id': '19960'}{'Body': '<p>We have had <a href="http://cs.stackexchange.com/search?q=cook+reduction+is%3Aquestion">several questions about the relation of Cook and Karp reductions</a>. It\'s clear that Cook reductions (polynomial-time Turing reductions) do not define the same notion of NP-completeness as Karp reductions (polynomial-time many-one reductions), which are usually used. In particular, Cook reductions can not separate NP from co-NP even if P $\\neq$ NP. So we should not use Cook reductions in typical reduction proofs. </p>\n\n<p>Now, students found a peer-reviewed work [1] that uses a Cook-reduction for showing that a problem is NP-hard. I did not give them full score for the reduction they took from there, but I wonder.</p>\n\n<p>Since Cook reductions <em>do</em> define a similar notion of hardness as Karp reductions, I feel they <em>should</em> be able to separate P from NPC resp. co-NPC, assuming P $\\neq$ NP. In particular, (something like) the following should be true:</p>\n\n<p>$\\qquad\\displaystyle L_1 \\in \\mathrm{NP}, L_2 \\in \\mathrm{NPC}_{\\mathrm{Karp}}, L_2 \\leq_{\\mathrm{Cook}} L_1 \\implies L_1 \\in \\mathrm{NPC}_{\\mathrm{Karp}}$.</p>\n\n<p>The important nugget is that $L_1 \\in \\mathrm{NP}$ so above noted insensitivity is circumvented. We now "know" -- by definition of NPC -- that $L_2 \\leq_{\\mathrm{Karp}} L_1$.</p>\n\n<p>As has been <a href="http://chat.stackexchange.com/transcript/message/13483686#13483686">noted by Vor</a>, it\'s not that easy (notation adapted):</p>\n\n<blockquote>\n  <p>Suppose that $L_1 \\in \\mathrm{NPC}_{\\mathrm{Cook}}$, then by definition, for all languages $L_2 \\in \\mathrm{NPC}_{\\mathrm{Karp}} \\subseteq \\mathrm{NP}$ we have $L_2 \\leq_{\\mathrm{Cook}} L_1$; and if the above implication is true then $L_1 \\in \\mathrm{NPC}_{\\mathrm{Karp}}$ and thus $\\mathrm{NPC}_{\\mathrm{Karp}} = \\mathrm{NPC}_{\\mathrm{Cook}}$ which is still an open question.</p>\n</blockquote>\n\n<p>There may be other differences between the two NPCs but co-NP.</p>\n\n<p>Failing that, are there any known (non-trivial) criteria for when having a Cook-reduction implies Karp-NP-hardness, i.e. do we know predicates $P$ with</p>\n\n<p>$\\qquad\\displaystyle L_2 \\in \\mathrm{NPC}_{\\mathrm{Karp}}, L_2 \\leq_{\\mathrm{Cook}} L_1, P(L_1,L_2) \\implies L_1 \\in \\mathrm{NPC}_{\\mathrm{Karp}}$?</p>\n\n<hr>\n\n<ol>\n<li><a href="http://dx.doi.org/10.1089/cmb.1994.1.337" rel="nofollow">On the Complexity of Multiple Sequence Alignment</a> by L. Wang and T. Jiang (1994)</li>\n</ol>\n', 'ViewCount': '71', 'Title': 'Can we construct a Karp reduction from a Cook reduction between NP problems?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-05T07:56:44.503', 'LastEditDate': '2014-02-05T07:56:44.503', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><reference-request><np-complete><reductions>', 'CreationDate': '2014-01-29T18:33:16.763', 'FavoriteCount': '1', 'Id': '20074'}{'Body': u"<p>I am trying to create a polynomial time algorithm for a problem defined as follows:</p>\n\n<blockquote>\n  <h3>c-ZPath(cZP)</h3>\n  \n  <p>$c$ is an integer constant $\\geq 1$ </p>\n  \n  <p><strong>Input:</strong> An undirected graph $G=(V,E)$. </p>\n  \n  <p><strong>Question:</strong> Can the vertices in $G$ be colored with two colors such that</p>\n  \n  <ol>\n  <li><p>no edge\u2019s endpoint vertices have the same color and</p></li>\n  <li><p>there is a path in this colored version of $G$ with $\\geq c$ edges in which no vertex or edge repeats and the vertex-colors alternate for the entire length of the path? </p></li>\n  </ol>\n</blockquote>\n\n<p>I understand that the coloring can be checked by a simple breadth first search in polynomial time. </p>\n\n<p>My problem is with the path of length $c$. My professor stated that the reason that this is not NP-complete and analogous to the longest path problem is because $c$ is a constant. I fail to see why this restriction causes it to differ from longest path. If anyone could clarify this for me I'd be really greatful. </p>\n", 'ViewCount': '22', 'Title': 'Restricting longest path with 2-coloring to paths of at most constant length', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-29T20:34:41.350', 'LastEditDate': '2014-01-29T20:34:41.350', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '20082', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13230', 'Tags': '<complexity-theory><time-complexity><np-complete>', 'CreationDate': '2014-01-29T19:57:44.057', 'Id': '20081'}{'Body': "<p>I'm a novice to the topic of provability so bear with me... </p>\n\n<p>During a discussion with a friend, the question came up whether it could be possible that proving that $NP \\neq P$ (or $NP = P$) is an unprovable statement. My friend opposed that, if indeed it was unprovable, then this would imply that there cannot be a polynomial time algorithm for NP-hard problems (as the existence of such proves the statement), thus implying $NP \\neq P$. This seems to be imply that the statement cannot be unprovable or am I missing something?</p>\n", 'ViewCount': '82', 'Title': 'Provability of NP /= P?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-30T15:17:53.247', 'LastEditDate': '2014-01-30T15:17:53.247', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '13244', 'Tags': '<complexity-theory><np><p-vs-np>', 'CreationDate': '2014-01-30T13:57:04.927', 'FavoriteCount': '1', 'Id': '20106'}{'Body': "<p>I have an example for a reduction of 3CNF to Clique, there is one thing I don't get about it, hopefully you could clarify it.  The reduction works like this:</p>\n\n<blockquote>\n  <p>Construct a graph G = (V, E) as follows:</p>\n  \n  <p>Vertices: Each literal corresponds to a vertex.</p>\n  \n  <p>Edges: All vertices are connected with an edge except the vertices of\n  the same clause and vertices with negated literals.</p>\n</blockquote>\n\n<p>Why is it important that that negated literals will not be connected? How would that effect the reduction?</p>\n", 'ViewCount': '42', 'Title': 'Reducing 3CNF to Clique: Why do we omit negated literals?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-31T08:16:45.470', 'LastEditDate': '2014-01-31T08:16:45.470', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '20133', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9851', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2014-01-30T18:38:25.957', 'Id': '20127'}{'Body': '<p><a href="http://en.wikipedia.org/wiki/Petersen%27s_theorem" rel="nofollow">Petersen\'s Theorem</a> states that every cubic, bridgeless graph $G(V, E)$ contains a 2-factor $F$ (and therefore a perfect matching $E-F$). Alternatively, 2-factor is a set of vertex disjoint cycles that cover $V$. I\'m interested in the computational properties of 2-factors in connected bridgeless cubic graphs. I conjecture that every non-trivial property of two-factors in connected bridgeless cubic graphs is intractable.</p>\n\n<p>There are two parameters of two-factor: the number of disjoint cycles and the size of each cycle. So, it seems that restricting cycles sizes and/or the number of cycles in the 2-factor would make the decision problem of deciding the existence of restricted 2-factor is $NP$-complete. For instance, I conjecture the following decision problem is NP-complete: Given connected bridgeless cubic graph, decide whether it contains 2-factor such that sizes of each cycle are between two integers $n$ and $m$.</p>\n\n<p><strong>Non-trivial property</strong> in this context means a restriction on the parameters of  2-factor (in connected bridgeless cubic graph ) which partitions the class of connected bridgeless cubic graphs into two infinite sets. Therefore, there is infinite set of connected bridgeless cubic graphs with their 2-factor satisfying the property and infinite set not satisfying the property. I am aware of several $NP$-complete properties of 2-factors in connected bridgeless cubic graphs. For instance, Deciding the existence of connected 2-factor, even 2-factor, and odd 2-factor are all $NP$-complete problems.</p>\n\n<blockquote>\n  <p>When does such non-trivial property of 2-factor become $NP-complete? When does it become polynomial-time decidable?</p>\n</blockquote>\n\n<p>This is an improved version of a post originally posted on TCS SE.</p>\n', 'ViewCount': '97', 'Title': 'Intractable properties of Two-factor in connected bridgeless cubic graphs', 'LastEditorUserId': '96', 'LastActivityDate': '2014-02-06T21:01:54.387', 'LastEditDate': '2014-02-02T03:11:02.460', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '96', 'Tags': '<complexity-theory><graph-theory><np-complete>', 'CreationDate': '2014-02-02T02:08:18.210', 'FavoriteCount': '0', 'Id': '20203'}{'Body': u"<p>The optimization version of TSP asks for the length of the shortest tour. Unlike the decision version of TSP, there's no obvious way to verify a proposed solution of the optimization problem in polynomial time. But is there a proof of whether or not it can be verified in polynomial time assuming P \u2260 NP?</p>\n", 'ViewCount': '56', 'Title': u'Has it been proven that the optimization TSP is (or is not) polynomial-time verifiable if P \u2260 NP?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-02T13:42:30.540', 'LastEditDate': '2014-02-02T13:42:30.540', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '20209', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '836', 'Tags': '<complexity-theory><optimization><np><traveling-salesman>', 'CreationDate': '2014-02-02T05:46:32.140', 'Id': '20204'}{'ViewCount': '24', 'Title': "Blum's speedup theorem in big-O format?", 'LastEditDate': '2014-02-06T08:36:39.950', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>Is there a way to state <a href="http://en.wikipedia.org/wiki/Blum%27s_speedup_theorem" rel="nofollow">Blum\'s speedup theorem</a> in terms of <a href="http://en.wikipedia.org/wiki/Landau_notation" rel="nofollow">Big-O (Landau) notation</a>?</p>\n', 'Tags': '<complexity-theory><asymptotics>', 'LastEditorUserId': '472', 'LastActivityDate': '2014-02-06T08:36:39.950', 'CommentCount': '1', 'AcceptedAnswerId': '21343', 'CreationDate': '2014-02-06T01:45:42.293', 'Id': '21342'}{'Body': '<p>Do any of <a href="http://en.wikipedia.org/wiki/Blum%27s_speedup_theorem" rel="nofollow">Blum\'s theorems</a> prove that there exist decidable languages that are unclassifiable anywhere in the <a href="http://en.wikipedia.org/wiki/Time_hierarchy" rel="nofollow">time hierarchy</a>? In other words, asserting they (mentioned in the proofs) are computable within any time $O(f(n))$ for some <a href="http://en.wikipedia.org/wiki/Time_constructible" rel="nofollow">time-constructable</a> function $f(n)$ leads to a contradiction?</p>\n', 'ViewCount': '19', 'Title': "Blum's speedup theorem showing unclassifiable complexity languages?", 'LastEditorUserId': '472', 'LastActivityDate': '2014-02-06T08:36:16.793', 'LastEditDate': '2014-02-06T08:36:16.793', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<complexity-theory>', 'CreationDate': '2014-02-06T02:00:37.930', 'Id': '21344'}{'Body': '<p>Consider this example: a problem of dimension $n$ and $m$ ($m,n$: any given integers).\nhas a search space of size $O(n^n * m^n)$. \nIt is clear that this problem is exponential in $n$,\nwhatsoever $m$ may be.\nMy question: is this same problem polynomial in $m$? \nwhat are the assumptions if we can say that?\nis this way of complexity analysis correct? </p>\n', 'ViewCount': '26', 'Title': 'How to analyse the complexity of a problem with two or more size measures', 'LastEditorUserId': '13107', 'LastActivityDate': '2014-02-07T23:26:10.240', 'LastEditDate': '2014-02-07T23:26:10.240', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14490', 'Tags': '<complexity-theory><time-complexity><asymptotics>', 'CreationDate': '2014-02-07T22:47:41.883', 'FavoriteCount': '1', 'Id': '21435'}{'Body': u'<p>I can\'t understand or imagine some fact about NP-hard problems. If I understand it correctly there is only one polynomial-time algorithm needed &ndash; for whichever NP-complete problem &ndash; to prove that P = NP.</p>\n\n<p>Let\'s take the subset sum problem, which is NP-complete. It says that given a set such as $\\{-7, -3, -2, 5, 8\\}$, we\'re able to find out if there exists a subset of this set summing to zero, within exponential time (and obviously check a solution, for instance $\\{-3, -2, 5\\}$ within polynomial time).</p>\n\n<p>So if someone finds an polynomial-time algorithm for this task, he\'ll show that P = NP, right?</p>\n\n<p>EDIT: I removed:</p>\n\n<blockquote>\n  <p>Assuming, that opinions whether P = NP or P \u2260 NP amongst computer scientists are about 1:1 (<a href="http://www.win.tue.nl/~gwoegi/P-versus-NP.htmh9zmHrJjx7Gfw&amp;bvm=bv.60983673,d.Yms" rel="nofollow">this site</a> claims that they\'re ~ 52% and ~44% respectively)...</p>\n</blockquote>\n\n<p>As the guys noticed in comments, it\'s wrong. I should say the proven cases are like 1:1.</p>\n\n<p>Okay, so it gets more intuitive now. I mean, P \u2260 NP actually seems to be \'more likely now\':</p>\n\n<p>However, assuming that there are still, say, 5-10% of formally educated people who believes that P = NP and the cited problem is not, say, the most complex one, how is that even possible that no one  of them had found a polynomial-time algorithm yet OR (maybe more likely?) no one of their opponents proved that there\'s no such an algorithm? Or, does it also mean that (in terms of those people\'s opinions, again) the \'chances\' of there being  such an algorithm are like 1:1, too?</p>\n\n<p>From my (maybe naive) point of view, the subset sum problem seems so simple to crack &ndash; at least for advanced computer scientists.</p>\n\n<p>As you\'re probably aware of, searching in the Net would not help me much as I just can\'t deeper into this problem. I\'ve got no such mathematical knowledge to even comprehend it more.</p>\n', 'ViewCount': '93', 'ClosedDate': '2014-02-10T08:25:27.573', 'Title': u'What makes it so difficult to prove P =/\u2260 NP? \u2014 The subset sum issue', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-10T08:24:17.317', 'LastEditDate': '2014-02-10T08:24:17.317', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14531', 'Tags': '<complexity-theory><np-complete><p-vs-np>', 'CreationDate': '2014-02-09T23:35:04.740', 'Id': '21478'}{'Body': '<p>What is an upper bound on formula size when converting 3-SAT to UNIQUE 3-SAT?</p>\n\n<p>We can use the <a href="http://en.wikipedia.org/wiki/Valiant%E2%80%93Vazirani_theorem" rel="nofollow">Valiant Vazirani Therom</a>, also found <a href="http://people.csail.mit.edu/madhu/ST07/scribe/lect12.pdf" rel="nofollow">here (in more detail)</a>.</p>\n\n<p>Essentially, it is a randomized algorithm that converts a SAT formula into another SAT formula that has only 1 satisfying variable assignment (called UNIQUE-SAT) with high probability.</p>\n\n<p>I\'m wondering what the upper bounds are on the size of the formula.  The information I have proves that it is polynomial, but I hope we can get more specific.  Can anyone find a more exact upper bounds?</p>\n', 'ViewCount': '43', 'Title': 'What is an upper bound on formula size when converting 3-SAT to UNIQUE 3-SAT?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-10T18:09:47.103', 'LastEditDate': '2014-02-10T18:09:47.103', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1667', 'Tags': '<complexity-theory><reductions><3-sat>', 'CreationDate': '2014-02-10T17:08:04.963', 'Id': '21497'}{'Body': "<blockquote>\n  <p><strong>The problem:</strong></p>\n  \n  <p><em>Input</em>: An $n \\times n$ matrix of 0's and 1's, and a position <em>pos</em> of this matrix (i.e. a pair of integers $i,j$ with $1 \\leq i,j \\leq n$)</p>\n  \n  <p><em>Output</em>:</p>\n  \n  <p>YES if there exists a path through <strong>adjacent</strong> matrix entries $\\dagger$, starting at <em>pos</em>, covering each matrix entry with a 1 <strong>exactly once</strong>, and not covering the matrix entries with a 0.</p>\n  \n  <p>NO otherwise.</p>\n</blockquote>\n\n<p>$\\dagger$ a matrix entry is adjacent to the one immediately to its left, to the one immediately to its right, to the one immediately upwards and the one immediately below.</p>\n\n<hr>\n\n<p>Informally, the matrix can be seen as a labyrinth where the 0's are walls, you start somewhere, and you have to walk through the whole maze without repeating any position.</p>\n\n<p>Example input:</p>\n\n<pre><code>1100\n1100\n0000\n0001\nPos: (1,1)\n</code></pre>\n\n<p>Corresponding output:</p>\n\n<pre><code>No (because you can't reach the position (4,4))\n</code></pre>\n\n<hr>\n\n<p>Is this problem NP-complete? If it is, what other NP-complete problem has been reduced to it? If it isn't, what approach can I use to design an efficient algorithm?</p>\n\n<p>I think this is a particular case of the hamiltonian path problem (except that you have a fixed starting point). The graph can be constructed by taking the matrix entries with 1's as vertices. 2 vertices are adjacent iff their corresponding matrix entries are adjacent. So I think that reducing this problem to the hamiltonian path problem should be easy. Of course, to prove it is NP-complete, we would have to do the reduction backwards.</p>\n", 'ViewCount': '67', 'Title': 'Is this path finding problem in a 01-matrix NP-complete?', 'LastEditorUserId': '14555', 'LastActivityDate': '2014-02-11T20:50:59.417', 'LastEditDate': '2014-02-11T20:50:59.417', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '21511', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14555', 'Tags': '<complexity-theory><np-complete><reductions><np>', 'CreationDate': '2014-02-10T23:14:29.853', 'Id': '21510'}{'ViewCount': '70', 'Title': "Why can't you write the 2-paths problem as a max-flow problem?", 'LastEditDate': '2014-02-12T19:55:24.250', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '8877', 'FavoriteCount': '1', 'Body': '<p>This is a follow-up question to <a href="http://cstheory.stackexchange.com/questions/20989/graph-problems-which-are-np-complete-on-directed-graphs-but-polynomial-on-undire/20991#comment55620_20991">this</a>. Consider the 2-paths problem:</p>\n\n<blockquote>\n  <p>Given a directed graph $D=(V,A)$ and pairs of vertices $(s_1,t_1)$ and $(s_2,t_2)$, are there paths $P_1 = (s_1,\\dots, t_1)$ and $P_2=(s_2,\\dots,t_2)$ such that $P_1$ and $P_2$ are vertex-disjoint?</p>\n</blockquote>\n\n<p>This problem has been shown to be NP-complete (references <a href="http://cstheory.stackexchange.com/questions/20989/graph-problems-which-are-np-complete-on-directed-graphs-but-polynomial-on-undire/20991#comment55620_20991">here</a>). \nThis struck me as unusual, because there seems to be a natural way to formulate this as a max flow problem: </p>\n\n<ul>\n<li>Add new vertices $s$ and $t$ to $D$.</li>\n<li>Add arcs $(s,s_1),(s,s_2),(t_1,t),(t_2,t)$.</li>\n<li>Let all vertices have capacity one (besides $s$ and $t$).</li>\n</ul>\n\n<p>It seems to me that the max $s-t$ flow of this new graph (call it $D\'$) should be two iff $D$ has those desired paths $P_1$ and $P_2$. Surely there must be some mistake here, because this seems to imply that an NP-complete problem can be solved in polytime. Where is the mistake?</p>\n', 'Tags': '<complexity-theory><graphs><network-flow>', 'LastEditorUserId': '8877', 'LastActivityDate': '2014-02-12T22:50:32.903', 'CommentCount': '2', 'AcceptedAnswerId': '21577', 'CreationDate': '2014-02-12T18:35:27.667', 'Id': '21574'}{'Body': '<p>If any problem P is NP complete then if there is a polynomial time reduction of P to another problem R then what can we say about R.Is it NP-hard or NP complete ?<br>\nFrom Theory of computation of Hopcroft,Ullman theorem 10.4 it says it would be NP complete but there some times when i see that it is NP-Hard in some other reference . is there any condition when it is NP Hard or NP Complete .Or i misunderstood the theorem .</p>\n', 'ViewCount': '33', 'Title': 'NP hard relation with NP complete', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-02-13T20:29:01.697', 'LastEditDate': '2014-02-13T19:17:11.720', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14647', 'Tags': '<complexity-theory><np-complete><np-hard>', 'CreationDate': '2014-02-13T18:43:05.647', 'Id': '21604'}{'Body': u'<p>I read several times that it is not possible to flip the answer of a NDTM efficiently. However, I don\u2019t understand why. For instance, given a NDTM $M$ that runs in $O(n)$, <a href="http://www.cs.princeton.edu/theory/complexity/diagchap.pdf" rel="nofollow">this text</a> (section 3.3) states that it is unclear how another NDTM $T$ can determine in $O(n^{100})$ time how to flip $M$\u2019s answer.</p>\n\n<p>My Problem is as follows: A NDTM outputs $1$ iff there exists a sequence of non-deterministic choices that leads to the accepting state. Furthermore, there exists a universal NDTM $NU$ that can simulate every NDTM with only a small (logarithmic) overhead. So why can\u2019t we construct T as follows: First, simulate M with the universal NDTM which should be possible in time $O(n\\log n)$. Then output 1 \u2013 M\u2019s answer. This would mean that we can flip the answer of any linear NDTM in time $O(n\\log n)$.</p>\n', 'ViewCount': '233', 'Title': "Why can't we flip the answer of a NDTM efficiently?", 'LastActivityDate': '2014-02-14T05:39:42.170', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '21618', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '14654', 'Tags': '<complexity-theory><turing-machines>', 'CreationDate': '2014-02-13T22:06:33.487', 'FavoriteCount': '1', 'Id': '21613'}{'Body': "<p>It seems to me to be incorrect to say that lexicographic DFS is P-complete, since it isn't a decision problem. There is a corresponding decision problem, first DFS ordering, which is known to be P-complete. However, I want to talk about complexity of DFS, not it's decision problem. What complexity class should I say DFS belongs to?</p>\n", 'ViewCount': '36', 'Title': 'lexicographic depth-first search complexity class', 'LastEditorUserId': '39', 'LastActivityDate': '2014-02-24T19:24:05.510', 'LastEditDate': '2014-02-24T19:24:05.510', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'OwnerDisplayName': 'Adam Kurkiewicz', 'PostTypeId': '1', 'OwnerUserId': '11718', 'Tags': '<complexity-theory><search-algorithms>', 'CreationDate': '2014-02-13T14:39:10.070', 'Id': '21620'}{'ViewCount': '163', 'Title': 'Why is this function computable in $O(n^{1.5})$ time?', 'LastEditDate': '2014-02-15T02:13:40.423', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '14654', 'FavoriteCount': '0', 'Body': '<p>My textbook says: "We define the function $f\\colon \\mathbb{N}\\to\\mathbb{N}$ as follows: $f(1)=2$ and $f(i+1)=2^{f(i)^{1.2}}$. Note that given $n$, we can easily find in $O(n^{1.5})$ time the number $i$ such that $n$ is sandwiched between $f(i)$ and $f(i+1)$."</p>\n\n<p>How can I convince myself that we can in fact easily find $i$ in $O(n^{1.5})$ time? As $f$ is defined recursively, I think we have to compute $f(1),f(2),f(3)\\dots f(j)$ until $f(j)\\geq n$. In order to find out the time that these computations take, I think we have to find a suitable upper bound for $i$ dependent on $n$ and we have to find an upper bound on the execution time of the function $x\\to2^{x^{1.2}}$. In the end, we can hopefully show the quoted proposition. Unfortunately, I don\'t see neither one thing nor the other.</p>\n\n<p>I forgot to mention: Please note that we are in a nondeterministic context. So $f$ is claimed to be computable in $O(n^{1.5})$ by a nondeterministic Turing machine.</p>\n\n<hr>\n\n<p>As quite a few people have already read this question, with some of them finding it useful and interesting too, but nobody answered so far, I want to provide some more information on the context: The quoted claim is an integral part of the proof of the nondeterministic time hierarchy theorem. The proof (with the claim) can be found e. g. in the <a href="http://www.cs.princeton.edu/theory/complexity/diagchap.pdf" rel="nofollow">book by Arora and Barak</a>, but I have found quite a few other resources on the Web too which present the same proof. Each of those calls the claim easy or trivial and does not elaborate on how to find $i$ in $O(n^{1.5})$ time. So either all these resources just copied from Arora and Barak or the claim is in fact not so difficult.</p>\n', 'Tags': '<complexity-theory><algorithm-analysis><nondeterminism>', 'LastEditorUserId': '683', 'LastActivityDate': '2014-02-15T02:25:32.873', 'CommentCount': '2', 'AcceptedAnswerId': '21654', 'CreationDate': '2014-02-14T14:31:23.487', 'Id': '21636'}{'Body': '<p>As we all know the million dollar question in Computer Science P=NP or not. I was trying to understand it and got some doubts please tell me whether I\'m right or wrong</p>\n\n<p>N=NP in two cases </p>\n\n<blockquote>\n  <p>Case 1: We have found an algorithm which can solve a NP-Complete problem in P-Time. This implies that P=NP=NP-Complete. But still we can not say anything about the NP-HARD Problems.</p>\n  \n  <p><img src="http://i.stack.imgur.com/w7ghQ.png" alt="http://s30.postimg.org/k721ni0j5/image.png"></p>\n  \n  <p>Case 2: We have found an algorithm which can solve a NP-Hard problem in P-Time. This implies that P=NP=NP-Complete=NP-Hard.</p>\n  \n  <p><img src="http://i.stack.imgur.com/UY3ry.png" alt="http://s15.postimg.org/3po7i4kcr/image.png"></p>\n</blockquote>\n\n<p>Am I right or I\'m missing some point.</p>\n', 'ViewCount': '105', 'Title': '2 cases for P = NP', 'LastEditorUserId': '31', 'LastActivityDate': '2014-02-16T18:24:59.603', 'LastEditDate': '2014-02-15T12:22:54.387', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14481', 'Tags': '<complexity-theory>', 'CreationDate': '2014-02-15T10:40:36.970', 'Id': '21659'}{'Body': "<p>I know that:</p>\n\n<p>If $f(n) = O(g(n))$ , then there are constants $M$ and $x_0$ , such that </p>\n\n<p>$f(n) &lt;= M*g(n), \\forall n &gt; n_0$</p>\n\n<p>The other, plain English way of defining it is,</p>\n\n<p>If $f(n)=O(g(n))$ then for large $n$ , $f(n)$ would <em>grow</em> as fast as $g(n)$.</p>\n\n<p>I got confused when comparing $2^n$ with $2^{2n}$. Here , $f(n) = 2^n$ and $g(n) = 2^{2n}$. Clearly , $f(n)$ is smaller than $g(n)$ by a factor of $2^n$. So there will be constants $A$ and $x_0$ such that the first definition above is met.</p>\n\n<p>However, for large $n$ , $2^{2n}$ would grow much faster than $2^n$, leaving $2^n$ far behind. That is $2^{2n}$  won't be an asymptotic/tight bound for $2^n$ .</p>\n\n<p>So, is $2^n = O(2^{2n})$ or not? (or did I just create a confusing situation out of nothing)</p>\n", 'ViewCount': '69', 'Title': 'Big O relation between $2^n$ and $2^{2n}$', 'LastActivityDate': '2014-02-16T03:48:30.417', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '21688', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11837', 'Tags': '<complexity-theory><algorithm-analysis><asymptotics><landau-notation>', 'CreationDate': '2014-02-15T17:49:54.007', 'Id': '21675'}{'Body': '<p>Suppose I wanted to find all valid <a href="http://en.wikipedia.org/wiki/Net_%28polyhedron%29" rel="nofollow">nets</a> of a polyhedron. Is this kind of problem NP-Hard?</p>\n\n<p>My guess is that it is. If you were to increase the "complexity" of the polyhedron (maybe this is the number of faces?), there is no "shortcut" to discovering all the nets; you would have to enumerate all combinations. This sort of "listing all combinations" without any shortcuts seems to be similar to other kind of NP problems I\'ve seen. Is my thinking correct? Can someone else explain their thought process that helps them decide whether this problem is NP-Hard or not?</p>\n\n<p>If this problem is not NP-Hard, how do you classify this and why?</p>\n', 'ViewCount': '68', 'Title': 'Is finding all valid nets of a polyhedron NP-hard?', 'LastEditorUserId': '472', 'LastActivityDate': '2014-02-17T09:40:02.893', 'LastEditDate': '2014-02-17T09:40:02.893', 'AnswerCount': '0', 'CommentCount': '8', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14728', 'Tags': '<complexity-theory><computational-geometry><np-hard>', 'CreationDate': '2014-02-16T21:54:30.863', 'Id': '21708'}{'ViewCount': '130', 'Title': 'Asymptotic lower bound on the number of comparisons needed to find the intersection of unsorted arrays', 'LastEditDate': '2014-02-17T18:28:17.103', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14740', 'FavoriteCount': '1', 'Body': u"<p>A homework problem in my current CS class asks us to produce a <em>comparison-based</em> procedure for taking (essentially\u2014there are some poorly-specified rules about duplicates) the set intersection of $k$ unsorted arrays of at most $n$ elements each. For full credit, we are supposed to do this in $O((k-1)n)$ comparisons. (Specifically, we are given a Java array of arrays of Comparable elements.)</p>\n\n<p>I'm pretty thoroughly convinced that this is impossible, and that the best worst-case comparison bound for such a procedure is $\\Theta(N\\log n_0)$, where $N$ is the sum of the lengths of the arrays and $n_0$ is the length of the shortest array. I don't, however, know how to <em>prove</em> this is the best.</p>\n\n<p>Since producing such an algorithm is current homework, please adhere to the following restriction in your answers/comments: if I am <em>wrong</em>, and it <em>is</em> possible to do better, do not reveal the algorithm unless it is very difficult (in which case a link to a relevant paper would be appreciated).</p>\n\n<h3>What I've tried so far</h3>\n\n<p>The shortest array has $2^{n_0}$ subsets. This gives an immediate information-theoretic lower bound of $\\Omega(\\log_2(2^{n_0}))$. Unfortunately, this is just $\\Omega(n_0)$, and $O(n_0)$ obviously can't be obtained.</p>\n\n<h3>Edit</h3>\n\n<p>I missed a line in the (rather long) assignment. It looks like what he's looking for is actually a lot less interesting than what I thought he wanted. However, I'm still curious about how to prove a lower bound of $\\Omega(N \\log n_0)$, if that is the lower bound.</p>\n", 'Tags': '<algorithms><complexity-theory><sets>', 'LastEditorUserId': '14740', 'LastActivityDate': '2014-02-17T18:28:17.103', 'CommentCount': '16', 'AcceptedAnswerId': '21717', 'CreationDate': '2014-02-17T03:29:15.263', 'Id': '21714'}{'Body': '<p><strong>EDIT</strong></p>\n\n<p>As requested, a single question </p>\n\n<p><strong>Why can\'t arbitrary base conversion be done as fast as converting from base $b$ to base $b^k$ ?</strong> </p>\n\n<p>There is a big time complexity difference, so I am also interested in <em>further reading material about it</em>.</p>\n\n<hr>\n\n<p><strong>Old. Original question</strong></p>\n\n<p>Conversion between power-2-radix can be done faster than between non-power-of-2 radix, they can be even done in parallel, as every digit (or some groups of them) can be decoded independently of the rest.</p>\n\n<p>For example the binary number <code>00101001</code> can be converted to hexadecimal <code>0x29</code> nibble by nibble (<code>0010</code> and <code>1001</code>), and vice versa (i.e. every hex-digit can be parsed to 4 bits independently of the rest), but doing that conversion from to decimal (or any other non-power-of-2 radix) it\'s not so easy because digits affects each other.</p>\n\n<p>I\'ve seen time complexity of math operations in <a href="http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Arithmetic_functions" rel="nofollow">wikipedia</a>, and there is also a related question in <a href="http://stackoverflow.com/questions/17649524/time-complexity-to-convert-a-decimal-to-another-base">stackoverflow</a> saying time complexity of conversions of arbitrary digit length to be $\\mathcal{O}(M(n) log(n))$</p>\n\n<p>I\'m not interested in a "general time complexity bounds for any base conversion" but I would like to know more about the big differences in time complexity between power-of-2 conversions vs any other base conversions. </p>\n\n<p>It\'s could be a general fact about conversions that can be done faster if they are done between numbers where its bases are power among themselves, not only for 2, but the same to a base 10 to base 100.</p>\n\n<p>Is there any known proof or materials around this ?</p>\n', 'ViewCount': '185', 'Title': 'Time complexity of base conversion', 'LastEditorUserId': '1396', 'LastActivityDate': '2014-04-18T19:19:26.113', 'LastEditDate': '2014-02-21T12:31:12.923', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1396', 'Tags': '<complexity-theory><reference-request><time-complexity><binary-arithmetic>', 'CreationDate': '2014-02-17T13:58:42.143', 'FavoriteCount': '1', 'Id': '21736'}{'Body': '<p>I\'m styding this article:\n<a href="http://www.dcs.warwick.ac.uk/~mju/Papers/JPZ08-SIAMJComp.pdf" rel="nofollow">http://www.dcs.warwick.ac.uk/~mju/Papers/JPZ08-SIAMJComp.pdf</a>\nand there is a step not clear for me.</p>\n\n<p>In particular :</p>\n\n<p><img src="http://i.stack.imgur.com/NYhdM.jpg" alt="enter image description here"> </p>\n\n<p>Can anyone help me to understand what is the underlined number?</p>\n\n<p>many thx</p>\n', 'ViewCount': '31', 'ClosedDate': '2014-03-21T00:06:06.443', 'Title': 'Deterministic subexponential algorithm for parity game', 'LastActivityDate': '2014-03-20T03:49:17.097', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'OwnerDisplayName': 'andy young', 'PostTypeId': '1', 'Tags': '<complexity-theory>', 'CreationDate': '2014-02-17T14:06:05.603', 'Id': '21748'}{'Body': "<p>The Triangle Cover Graph problem is this:</p>\n\n<blockquote>\n  <p>Given a graph $G = (V,E)$ and an integer $k$, does there exist a set of at most $k$ vertices of $G$ such that every triangle contained in $G$ also contains a vertex of the set?</p>\n</blockquote>\n\n<p>This problem is obviously in $NP$ as its verifier is just the set which you can easily check.  However, what's the reduction to be able to show that this is NP Complete?</p>\n\n<p>I recognize the fact that a good reduction for this problem would be for 3-SAT as you could easily take a 3-sat instance and make a 3-vertex triangle in the graph corresponding to the variables which are in each clause.  However, I wasn't able to come up with a way to connect the different triangles together to ensure that the assignment of vertices would be a satisfiable truth assignment.</p>\n", 'ViewCount': '58', 'Title': 'Reducing 3SAT to Triangle Cover Graph', 'LastEditorUserId': '683', 'LastActivityDate': '2014-02-19T14:58:51.107', 'LastEditDate': '2014-02-19T14:58:51.107', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14824', 'Tags': '<complexity-theory><graph-theory><np-complete><reductions>', 'CreationDate': '2014-02-19T00:19:18.737', 'FavoriteCount': '1', 'Id': '21792'}{'Body': "<p>I've seen a lot of text concerning the first NP-Complete problem, Boolean Satisfiability. I guess I'm confused concerning the language. </p>\n\n<p>It sounds to me as though the problem could be difficult to compute (hence the NP-complete), however it still might be satisfiable. As in, there <em>exists</em> a satisfying mapping of literals. We can't necessarily compute it easily, but it's out there.</p>\n\n<p>In fact, I would guess that the two adjectives really have no relation to each other. But, when working with problems, I am often asked to see whether a set of clauses is satisfiable. Does that mean, <em>Can we compute a satisfying mapping?</em> And by extension, does NP-complete imply that a given CNF setup is unsatisfiable?</p>\n", 'ViewCount': '103', 'Title': 'Does NP-Complete imply non-satisfiability?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-21T10:30:36.100', 'LastEditDate': '2014-02-21T10:30:36.100', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '21874', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12971', 'Tags': '<complexity-theory><terminology><np-complete><satisfiability>', 'CreationDate': '2014-02-21T01:53:02.537', 'Id': '21871'}{'Body': '<p>I hope I named this CNF Boolean sentence the correct way. The way I see it, a 2P2N is where each literal appears twice (or at most twice, but we can say twice without loss of generality). </p>\n\n<p>I am trying to prove it is Satisfiable. How do I do this? Do I need to try to reduce it to 3-SAT (might need some help doing that as well). Or is there another method of proving satisfiability?</p>\n', 'ViewCount': '62', 'Title': 'Proving 2P2N SAT is NP-Complete', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-21T20:38:37.950', 'LastEditDate': '2014-02-21T11:52:24.113', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '21907', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12971', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'CreationDate': '2014-02-21T02:34:05.097', 'Id': '21873'}{'Body': '<p>It is known that a nondeterministic universal turing machine (UTM) can simulate another nondeterministic TM with running time $t(n)$ in time $c t(n)$, where $c$ is a constant. It is also known that a deterministic UTM can simulate another deterministic TM with running time $t(n)$ in time $ t(n)\\log(t(n))$. </p>\n\n<p>My question is: why is there a $\\log(t(n))$ slowdown in the simulation of a deterministic TM by a UTM, as opposed to a constant factor slowdown in the nondeterministic case?</p>\n', 'ViewCount': '164', 'Title': 'Difference between deterministic and nondeterministic universal turing machine', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-23T20:36:58.043', 'LastEditDate': '2014-02-23T20:36:58.043', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14961', 'Tags': '<complexity-theory><turing-machines><time-complexity><simulation>', 'CreationDate': '2014-02-23T17:58:30.433', 'Id': '21949'}{'Body': "<p>My question here is dealing with the residual that I get. We are trying to prove $T(n) = 3T(n/3) + n$ is $O(n*\\log n)$. So where I get is $T(n) \\le cn[\\log n - \\log 3] + n$. So my residual is $-cn\\log 3 +  n$. So if I minus it I get $-(cn\\log 3 -n) \\ge 0$ right? How do I figure out what values of c &amp; n are? Do I use the base case? And as long as my negative residual is greater than 0 then my desire is correct because as n grows large then the residual doesn't matter? </p>\n", 'ViewCount': '81', 'ClosedDate': '2014-04-01T22:01:50.313', 'Title': 'Recurrence Problem $T(n) = 3T(n/3) + n$', 'LastActivityDate': '2014-02-24T14:02:24.873', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '21967', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '14960', 'Tags': '<complexity-theory><recurrence-relation>', 'CreationDate': '2014-02-23T19:00:59.080', 'Id': '21952'}{'Body': "<p>I read that determining the size of the maximum independent set (and also a clique of maximum size) is in P. The versions that find the actual solution are known to be NP-hard. </p>\n\n<p>With respect to finding clique size, you can sort the node degrees, decrement $i$ from $|V|$ to $0$, and each time check if you have $i$ elements of node degree $i$, pick the power set of those $\\geq i$ elements and verify the clique. However, picking the power set is exponential, and this algorithm would give you the solution itself. I have a hard time figuring out how you can construct an algorithm that decides the presence of a clique (or independent set) of a certain size in polytime, but doesn't give you the solution.</p>\n", 'ViewCount': '101', 'Title': 'Why is determining the size of a maximum independent set or a clique in P?', 'LastEditorUserId': '472', 'LastActivityDate': '2014-02-27T07:22:20.957', 'LastEditDate': '2014-02-27T07:22:20.957', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '22083', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4748', 'Tags': '<algorithms><complexity-theory><graph-theory><graphs><time-complexity>', 'CreationDate': '2014-02-27T05:41:09.613', 'Id': '22080'}{'Body': '<p>I want to prove that a problem $P_1$ is NP-complete. Let say that I want to do a reduction from SAT problem.</p>\n\n<p>If the instance of problem $P_1$ depends on $M$ and $N$, can I specify the sturcture of the instance of the SAT problem? </p>\n\n<p>More precisely, can I say that, for example, the instance of SAT problem is composed of $M\\times N +1$ clauses and every clause has $M+N$ literals ? </p>\n\n<p>Based on this structure of the instance of SAT problem, I construct an instance of $P_1$. Is this proof correct?</p>\n', 'ViewCount': '87', 'Title': 'Is this NP-completeness proof correct?', 'LastEditorUserId': '472', 'LastActivityDate': '2014-03-04T19:45:18.393', 'LastEditDate': '2014-03-04T19:45:18.393', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22105', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12683', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'CreationDate': '2014-02-27T17:04:17.090', 'Id': '22097'}{'Body': '<p>I\'m looking for some clarification on some concepts/facts I came across while studying for a class.</p>\n\n<p>I was reading the following wikipedia article. The below specific section and statement intrigued me when looking it over.</p>\n\n<p><a href="http://en.wikipedia.org/wiki/Computational_complexity_theory#Important_complexity_classes" rel="nofollow">http://en.wikipedia.org/wiki/Computational_complexity_theory#Important_complexity_classes</a>\n"It turns out that PSPACE = NPSPACE and EXPSPACE = NEXPSPACE by Savitch\'s theorem"</p>\n\n<p>I also read that NTMs can be simulated by DTMs but that the shortest accepting computation of the DTM is exponential with respect to the shortest accepting computation of the target NTM.</p>\n\n<p><strong>My questions are:</strong></p>\n\n<p>1.) Are PSPACE and NPSPACE the set of all problems that require at least polynomial space to be solved on Deterministic and Non-deterministic Turing machines respectively?</p>\n\n<p>2.) If so, is the actual size of the polynomial space required dependent on the size of the input?</p>\n\n<p>3.) For P and NP, they are each the sets of problems that require at least polynomial time to be solved on DTMs and NTMs respectively correct?</p>\n\n<p>4.) Is the reason that the shortest accepting computation of a DTM simulating a target NTM is exponential with respect to the shortest accepting computation of an NTM due to the exponential explosion of the number of configurations that an NTM supports as input grows for a given problem?</p>\n\n<p>5.) My last and overarching question is: Are the differences in the set of problems that can be solved in polynomial time on DTMs versus NTMs related to time/space tradeoffs where DTMs can\'t run some polynomial NTM algorithms in polynomial time because they don\'t have the same "space" that an NTM has available to it?</p>\n\n<p>I\'d also appreciate any reading you can suggest to me on time/space tradeoffs and NTMs versus DTMs.</p>\n', 'ViewCount': '109', 'Title': 'Relation of Space and Time in Complexity?', 'LastActivityDate': '2014-02-28T04:20:01.920', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '22110', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '14819', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2014-02-27T20:46:01.303', 'FavoriteCount': '2', 'Id': '22109'}{'Body': "<p>I am trying to teach myself complexity. I am trying to come up with a reduction from minimum set cover\n(given a set of items I, and a set S of subsets of I and an integer k, is there a subset S' of S Euch that |S'|&lt;=k and union(S')=I)\n to weighted Steiner tree \n(given a graph G=(V, E) and weight function w, and a subset V' of V and integer k>0, is there a subtree G' of G such that the sum of the weight of the edges in G'&lt;=k and V' is contained in G'?) \n, but have gotten a bit stuck. I believe I am on the right path. </p>\n\n<p>Here's what I have so far. Given an instance of minimum set cover, define a root node r, For every subset in Si in S, define a node Si and connect it by an edge to r with weight one. For every element in Si, define a node and connect them to Si via an edge of weight 0. This creates a tree. I believe something like this should work, but I cannot figure out how to define G' for the constructed instance of STG such that there is an answer yes if there is a minimum set cover. </p>\n\n<p>Any help would be greatly appreciated, thanks</p>\n", 'ViewCount': '84', 'Title': 'Reduction from Steiner tree to minimum set cover', 'LastEditorUserId': '13230', 'LastActivityDate': '2014-02-28T15:27:51.023', 'LastEditDate': '2014-02-28T15:27:51.023', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '13230', 'Tags': '<complexity-theory><time-complexity><complexity>', 'CreationDate': '2014-02-27T22:53:13.110', 'Id': '22114'}{'ViewCount': '97', 'Title': 'Bin packing problem or not?', 'LastEditDate': '2014-03-01T16:16:32.943', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12683', 'FavoriteCount': '1', 'Body': '<p>Suppose I have $N$ bins and $M$ items as depicted in the figure below (3 bins and 3 items):</p>\n\n<p>Suppose that every bin has unit capacity and the weights of the items depend on the bins used. I want to maximize the number of items in the bins subject to:</p>\n\n<ul>\n<li>One bin contains at most one item.</li>\n<li>If item $i$ is on bin $j$ then $g_{ij}\\geq1$ must hold now if all other bins are empty.</li>\n<li>If item $i$ is on bin $j$ (so $g_{ij}\\geq1$ must hold now) and item $i^\\prime$ is on bin $j^\\prime$, then $g_{ij}\\geq g_{ij^\\prime}$ and $g_{i^\\prime j^\\prime}\\geq g_{i^\\prime j}$ must both hold now.</li>\n<li>If item $i$ is on bin $j$ (so $g_{ij}\\geq1$ must hold now) and item $i^\\prime$ is on bin $j^\\prime$ (so $g_{ij}\\geq g_{ij^\\prime}$ and $g_{i^\\prime j^\\prime}\\geq g_{i^\\prime j}$ must both hold now) and item $i^{\\prime\\prime}$ is on bin $j^{\\prime\\prime}$, then $g_{ij}\\geq g_{ij^\\prime}+g_{ij^{\\prime\\prime}}$ and $g_{i^\\prime j^\\prime}\\geq g_{i^\\prime j}+g_{i^\\prime j^{\\prime\\prime}}$ and $g_{i^{\\prime\\prime} j^{\\prime\\prime}}\\geq g_{i^{\\prime\\prime} j}+g_{i^{\\prime\\prime} j^{\\prime}}$ must all hold now.</li>\n<li>And so on and so forth.</li>\n<li>In general I will have the following constraint: $g_{ij}x_{ij}\\geq\\sum\\limits_{i^\\prime=1,\\;i^\\prime \\neq i}^{M}\\sum\\limits_{j^\\prime=1,\\;j^\\prime \\neq j}^{N}g_{ij^\\prime}x_{i^\\prime j^\\prime}$, where $x_{ij}$ equals $1$ if item $i$ is in bin $j$ and equals $0$ otherwise.</li>\n</ul>\n\n<p>Finally, I have the following problem:</p>\n\n<p>Maximize $\\sum\\limits_{i=1}^{M}\\sum\\limits_{j=1}^{N}x_{ij}$</p>\n\n<p>subject to</p>\n\n<ul>\n<li><p>$\\frac{g_{ij}x_{ij}}{\\sum\\limits_{i^\\prime=1,\\;i^\\prime \\neq i}^{M}\\sum\\limits_{j^\\prime=1,\\;j^\\prime \\neq j}^{N}g_{ij^\\prime}x_{i^\\prime j^\\prime}}\\geq x_{ij},\\; \\forall i, j,$ (C1)</p></li>\n<li><p>$\\sum\\limits_{j=1}^{N}x_{ij}\\leq1,\\; \\forall i,$ (C2)</p></li>\n<li><p>$\\sum\\limits_{i=1}^{M}x_{ij}\\leq1,\\; \\forall j,$ (C3)</p></li>\n</ul>\n\n<p>and $x_{ij}\\in\\{0, 1\\},\\; \\forall i, j,$ (C4)</p>\n\n<p>The input of the problem is $M$, $N$, and $g_{ij},\\;\\forall i,j$. The right hand side of constraint (C1) is to say that when item $i$ is not in bin $j$ (i.e., $x_{ij}=0$) then (C1) is not violated. (C2) and (C3) say that one item goes to one bin and one bin contains one item, respectively. Finally, (C4) is the variable of the problem which is a binary variable.</p>\n\n<p>My question is: Can I say that this problem is a bin packing problem and it is therefore NP-hard? If not, Can you suggest a reduction idea from an NP-complete problem?</p>\n\n<p>Thank you for your help.</p>\n\n<p><img src="http://i.stack.imgur.com/xL94M.jpg" alt="enter image description here"></p>\n', 'Tags': '<complexity-theory><np-complete><optimization><np-hard>', 'LastEditorUserId': '12683', 'LastActivityDate': '2014-03-01T18:23:05.530', 'CommentCount': '5', 'AcceptedAnswerId': '22157', 'CreationDate': '2014-02-28T18:42:52.333', 'Id': '22136'}{'Body': '<p>This is probably a very basic question but do the polynomials in "polynomial time" have integer, real or complex coefficients?</p>\n\n<p>Everywhere I looked it just says "polynomial expression". I am guessing the polynomial must have integer coefficients?</p>\n', 'ViewCount': '52', 'Title': 'Do the polynomials in "polynomial time" have integer, real or complex coefficients?', 'LastActivityDate': '2014-03-02T02:43:10.087', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '22179', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15183', 'Tags': '<complexity-theory>', 'CreationDate': '2014-03-02T01:48:28.130', 'Id': '22178'}{'ViewCount': '90', 'Title': 'Hardness of mixed 3-SAT and 2-SAT formula', 'LastEditDate': '2014-03-04T09:12:17.513', 'AnswerCount': '2', 'Score': '3', 'OwnerDisplayName': 'Paramar', 'PostTypeId': '1', 'OwnerUserId': '12201', 'Body': '<p>It is well known that 3-SAT is $\\sf NP$-complete , but 2-SAT is in $\\sf P$. Let there be a formula with $n-1$ clauses with 2 literals each and only 1 clause with 3 literals.    </p>\n\n<p>We can solve this case in polynomial time, separating and solving in a brute force manner the 3 literal clause and then for each satisfying assignment try to solve the rest $n-1$ 2-literal clauses. This method can work till $O(\\log n)$ clauses with 3 literals. \nIf we consider a more general case with e.g $\\frac{n}{2}$ clauses with 2 literals and  $\\frac{n}{2}$ clauses with 3 literals does the problem remain $\\sf NP$-complete? </p>\n\n<p>It is a bit confusing because we have a subproblem approximately the same size, implying it is difficult and another one roughly the same size implying it is easy. Is there probably a better method than the one I proposed?</p>\n', 'Tags': '<complexity-theory><np-complete><satisfiability>', 'LastEditorUserId': '472', 'LastActivityDate': '2014-03-04T09:12:17.513', 'CommentCount': '0', 'AcceptedAnswerId': '22235', 'CreationDate': '2014-03-03T16:23:28.160', 'Id': '22233'}{'Body': '<p>I want to show that some problem $P_1$ is NP-hard. I have a problem $P_2$ that is NP-complete. From an instance of $P_2$ I created in polynomial time an instance of the problem $P_1$.</p>\n\n<p>My question is: Should I verify both direction ($\\Leftrightarrow$) or only one direction ($\\Rightarrow$)? More precisely, which one to show from these two:</p>\n\n<ul>\n<li>Solve $P_1\\;\\Leftrightarrow$ solve  $P_2$</li>\n<li>Solve $P_1\\;\\Rightarrow$ solve  $P_2$</li>\n</ul>\n', 'ViewCount': '24', 'Title': 'There is equivalence in an NP-hardness proof or not?', 'LastActivityDate': '2014-03-03T22:03:14.687', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22240', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12683', 'Tags': '<complexity-theory><np-complete><reductions><np-hard>', 'CreationDate': '2014-03-03T21:51:46.457', 'Id': '22239'}{'Body': '<p>Given a graph $G=(V,E)$ and a set of colors $k&lt;V$. Find a assignment of colors to vertices that minimizes the number of adjacent vertices in conflict. (Two adjacent vertices are in conflict if they have the same color.)</p>\n\n<p>I want to prove the above problem is NP-complete. Call the above problem P1.</p>\n\n<p>Answer: I am trying to reduce the k-coloring problem.</p>\n\n<p>P2: Given a graph $G=(V,E)$ and set of colors $k&lt;V$ is the graph k-colorable (zero conflicts)?</p>\n\n<p>P2 is feasible iff P1 has optimal value is exactly $0$. Therefore if P1 is solved we know solution to P2.</p>\n\n<p>Is this solution correct? Is it what is suggested by the first comment of user G.Bach in <a href="http://cs.stackexchange.com/questions/21431/a-variation-of-the-graph-coloring-problem">A variation of the graph coloring problem</a> ?</p>\n', 'ViewCount': '99', 'Title': 'Proving NP-completeness of a graph coloring problem', 'LastEditorUserId': '472', 'LastActivityDate': '2014-03-04T09:15:10.200', 'LastEditDate': '2014-03-04T09:15:10.200', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '22259', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory><graph-theory><np-complete><reductions>', 'CreationDate': '2014-03-03T23:56:50.917', 'Id': '22246'}{'Body': '<p>Consider a set of $N$ nodes. There is a $N\\times N$ non-negative valued matrix $D$ where the $(i,j)$th element $d_{ij}$ gives the "positive metric" between node $i$ and $j$, where $i,j\\in [N]$. Thus the diagonal entries of $D$ are all zero and $d_{ij}=d_{ji}$ so $D$ is symmetric. </p>\n\n<p>Then there is a set of  $k$ colors. I want to assign these colors to the $N$ nodes such that the minimum  metric of a common color between any pair of nodes is maximized. So if $c(i)$ is the color assigned to $i\\in [N]$ by the assignment $a\\in A$, where $A$ is the set of all possible color assignments, we are looking for $$\\max_{a\\in A} \\min_{i,j} \\{d_{ij}:c(i)=c(j)\\}.$$</p>\n\n<p>Is this problem NP-hard?  If it is, cwhat sort of reduction can be used to show that this problem is NP-hard?</p>\n', 'ViewCount': '98', 'Title': 'Relaxed graph coloring, with penalties for assigning adjacent vertices the same color', 'LastEditorUserId': '755', 'LastActivityDate': '2014-03-14T15:39:13.670', 'LastEditDate': '2014-03-14T15:39:13.670', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '22257', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12321', 'Tags': '<complexity-theory><reductions><np-hard>', 'CreationDate': '2014-03-04T03:42:40.617', 'Id': '22256'}{'Body': '<p>I read in these two papers <a href="http://www.ccs.neu.edu/home/lieber/courses/csg260/f06/materials/papers/max-sat/p216-schaefer.pdf" rel="nofollow">http://www.ccs.neu.edu/home/lieber/courses/csg260/f06/materials/papers/max-sat/p216-schaefer.pdf</a> and <a href="http://people.csail.mit.edu/madhu/papers/noneed/fullbook.ps" rel="nofollow">http://people.csail.mit.edu/madhu/papers/noneed/fullbook.ps</a> that if we have a boolean formula that is $0-valid$ then (of course) SAT problem is in $\\mathcal{P}$ but finding a solution with maximum true literals is $\\mathcal{NP}-$hard. </p>\n\n<p>N.B. As defined in the previous papers, a $0-valid$ boolean formula $f$ is a boolean formula $f: \\{0, 1\\}^n\\rightarrow\\{0, 1\\}$ that satisfies $f(0, \\dotsc, 0)=1$.</p>\n\n<p>My question is:</p>\n\n<p>Can I represent a general $0-valid$ boolean formula on the variables $x=\\left(x_1, \\dotsc, x_n\\right)$ by the following one:</p>\n\n<p>$f(x)=\\bigwedge\\limits_{i=1}^{L}\\bigvee\\limits_{i\\in\\mathcal{S}_l}\\neg\\;x_i$?</p>\n\n<p>Where $L$ is the number of clauses and $\\mathcal{S}_l\\;\\forall\\;l\\in\\{1,\\dotsc, L\\}$ is a subset of $\\{1, \\dotsc, n\\}$.</p>\n', 'ViewCount': '44', 'Title': 'How to represent a 0-valid boolean formula?', 'LastEditorUserId': '12683', 'LastActivityDate': '2014-03-06T01:26:33.697', 'LastEditDate': '2014-03-05T18:34:01.957', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '22308', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12683', 'Tags': '<complexity-theory><satisfiability>', 'CreationDate': '2014-03-05T17:06:49.690', 'Id': '22307'}{'Body': '<p>The complexity class $\\Sigma_{k}^{p}$ is recursively defined as follows:\n\\begin{align}\n\\Sigma_{0}^{p} &amp; := P, \\\\\n\\Sigma_{k+1}^{p} &amp; := P^{\\Sigma_{k}^{p}}.\n\\end{align}</p>\n\n<p>Why is every language that is reducible to a language in $\\Sigma_i^p$ also in $\\Sigma_i^p$?</p>\n\n<p>This comes in the proof of the theorem: If there is a PH-complete problem, then PH (the <a href="http://en.wikipedia.org/wiki/Polynomial_hierarchy" rel="nofollow">polynomial hierarchy</a>) collapses.</p>\n', 'ViewCount': '76', 'Title': 'Every language that is reducible to a language in $\\Sigma_i^p$ is also in $\\Sigma_i^p$ . How?', 'LastEditorUserId': '39', 'LastActivityDate': '2014-03-07T17:01:02.787', 'LastEditDate': '2014-03-07T17:01:02.787', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15338', 'Tags': '<complexity-theory><reductions>', 'CreationDate': '2014-03-06T11:28:06.663', 'Id': '22337'}{'Body': "<p>Most books assume that this is obvious, but I can't see how each $\\Sigma_k=NP^{\\Sigma_{k-1}}$ level in the polynomial hierarchy is closed under polynomial-time reductions. Is there something that I'm missing?</p>\n", 'ViewCount': '10', 'ClosedDate': '2014-03-07T18:51:58.633', 'Title': 'Show polynomial hierarchy levels closed under reduction', 'LastActivityDate': '2014-03-07T09:25:11.540', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15383', 'Tags': '<complexity-theory><time-complexity><reductions><complexity-classes>', 'CreationDate': '2014-03-07T09:25:11.540', 'Id': '22369'}{'Body': '<p><a href="https://en.wikipedia.org/wiki/3-partition_problem" rel="nofollow">The 3-Partition problem (wiki)</a> is a $\\text{NP}$-complete problem which is to decide whether a given multiset of integers can be partitioned into triples that all have the same sum. It is well-known that the <a href="https://en.wikipedia.org/wiki/3SAT#3-satisfiability" rel="nofollow">3SAT problem</a> has a plenty of variants. Are there some variants of the 3-Partition problem discussed in the literature?</p>\n', 'ViewCount': '18', 'Title': 'Variants of the 3-Partition problem', 'LastActivityDate': '2014-03-08T13:03:42.250', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4911', 'Tags': '<complexity-theory><reference-request><np-complete>', 'CreationDate': '2014-03-08T13:03:42.250', 'Id': '22396'}{'Body': '<p>In case of algorithm analysis we assume a generic one processor Random Access Machine(RAM). As I know RAM is machine which is no more efficient than the Turing machine.All algorithms can be implemented in the Turing machine.So my question is if Turing machine is equally efficient as RAM, then why we are not assuming Turing machine for algorithm analysis.What is the difference between RAM and TM. </p>\n', 'ViewCount': '55', 'Title': 'What is the difference between RAM and TM', 'LastActivityDate': '2014-03-09T05:55:07.097', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22419', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '13053', 'Tags': '<complexity-theory><turing-machines><automata>', 'CreationDate': '2014-03-09T05:42:40.073', 'FavoriteCount': '2', 'Id': '22418'}{'Body': '<p>I need to reduce the vertex cover problem to a SAT problem, or rather tell whether a vertex cover of size k exists for a given graph, after solving with a SAT solver. I know how to reduce a 3-SAT problem to vertex cover problem, by constructing the subgraphs for each variable (x, !x) and for each clause (a triable). But I am not getting,how to do other way round?</p>\n\n<p>I was thinking of first forming a DNF ,with electing k vertices at first and then convert it to a CNF, by enumerating all clauses. Is there any other method?</p>\n', 'ViewCount': '164', 'Title': 'Reduce Vertex cover to SAT', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-03-12T17:03:09.430', 'LastEditDate': '2014-03-09T19:50:54.783', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '22441', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '13302', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2014-03-09T12:43:04.730', 'Id': '22426'}{'Body': "<p>I'm wondering why the following argument doesn't work for showing that the existence of a Las Vegas algorithm also implies the existence of a deterministic algorithm:</p>\n\n<p>Suppose that there is a Las Vegas algorithm $A$ that solves some graph problem $P$, i.e., $A$ takes an $n$-node input graph $G$ as input (I'm assuming the number of edges is $\\le n$) and eventually yields a correct output, while terminating within time $T(G)$ with some nonzero probability.</p>\n\n<p>Suppose that there is no deterministic algorithm that solves $P$. Let $A^\\rho$ be the deterministic algorithm that is given by running the Las Vegas algorithm $A$ with a fixed bit string $\\rho$ as its random string. \nLet $k=k(n)$ be the number of $n$-node input graphs (with $\\le n$ edges).\nSince there is no deterministic algorithm for $P$, it follows that, for any $\\rho$, the deterministic algorithm $A^\\rho$ fails on at least one of the $k$ input graphs. Returning to the Las Vegas algorithm $A$, this means that $A$ has a probability of failure of $\\ge 1/k$, a contradiction to $A$ being Las Vegas. </p>\n", 'ViewCount': '194', 'Title': 'Relationship between Las Vegas algorithms and deterministic algorithms', 'LastActivityDate': '2014-03-10T21:34:04.607', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15471', 'Tags': '<algorithms><complexity-theory><randomized-algorithms>', 'CreationDate': '2014-03-10T02:22:57.270', 'Id': '22448'}{'Body': "<p>I'm having a lot of trouble solving problems in my Comp Theory class. I just have no idea how to formulate arguments for certain things like proving the concatenation of two non reg langs can have reg languages, or whatever. I know it sounds cliche and really corny, but I don't want to just google the answers. It may be fine for doing well on an assignment, but I know for a fact that I'm not getting the benefits of actually failing over and over again, and then solving the problem. However, most of the time I don't even know how to fail. I just can't even approach a problem. I just look at it, and have no idea on how to approach it.</p>\n\n<p>For those who have taken this class and were just as lost as I am, how did you get through it?</p>\n", 'ViewCount': '47', 'ClosedDate': '2014-03-11T00:19:15.673', 'Title': 'How to do well in Computational theory courses?', 'LastActivityDate': '2014-03-10T18:37:50.927', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15507', 'Tags': '<complexity-theory>', 'CreationDate': '2014-03-10T18:37:50.927', 'Id': '22479'}{'Body': '<p>Let f be a polynomial-time reduction of a decision problem A to a decision\nproblem B. We know that, if B $\\in$ P then A $\\in$ P. Similarly, if B $\\in$ NP then\nA $\\in$ NP. However, what about the other direction? Assume that A $\\in$ NP and\nconsider the following non-deterministic algorithms to decide whether y $\\in$ B:</p>\n\n<ol>\n<li>"Guess" non-deterministically some x.</li>\n<li>Verify that f(x) = y by computing f(x) in polynomial time and comparing\nit with y. If f(x)$\\neq$y, reject.</li>\n<li>Check (using the polynomial-time nRAM for A) whether x $\\in$ A and return\nthe answer.</li>\n</ol>\n\n<p>Why does this not qualify as a proof that B $\\in$ NP?</p>\n', 'ViewCount': '82', 'Title': 'Does a polynomial-time reduction from A to B imply that B is in NP if A is?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-11T11:40:48.993', 'LastEditDate': '2014-03-11T11:25:21.833', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15531', 'Tags': '<complexity-theory><reductions><np>', 'CreationDate': '2014-03-11T09:52:00.990', 'Id': '22495'}{'Body': '<p>Assume $P\\neq NP$.</p>\n\n<p>What can we say about the runtime bounds of all NP-complete problems?</p>\n\n<p>i.e. what are the tightest functions $L,U:\\mathbb{N}\\to\\mathbb{N}$ for which we can guarantee that an optimal algorithm for <strong>any</strong> NP-complete problem runs in time of at least $\\omega(L(n))$ and at most $o(U(n))$ on a input of length $n$?</p>\n\n<p>Obviously, $\\forall c:L(n)=\\Omega(n^c)$.\nAlso, $U(n) = O(2^{n^{\\omega(1)}})$.</p>\n\n<h2>Without assuming $QP\\neq NP$, $ETH$, or any other assumption which is not implied by $P\\neq NP$, can we give any better bounds on $L,U$?</h2>\n\n<p><strong>EDIT:</strong> </p>\n\n<p>Note that at least one of $L,U$ has to be far from the bounds I gave here, since being NPC problems, these problems has poly time reduction between each other, meaning that if some NPC problem has an optimal algorithm of time $f(n)$, then all problems has an algorithm (optimal or not) of runtime $O(f(n^{O(1)}))$.</p>\n', 'ViewCount': '152', 'Title': u'Runtime bounds on algorithms of NP complete problems assuming P\u2260NP', 'LastEditorUserId': '12969', 'LastActivityDate': '2014-03-16T16:00:29.563', 'LastEditDate': '2014-03-16T16:00:29.563', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '12969', 'Tags': '<complexity-theory><time-complexity><np-complete><p-vs-np>', 'CreationDate': '2014-03-11T20:05:43.997', 'FavoriteCount': '1', 'Id': '22511'}{'Body': "<p>Is there already a worst case time complexity proof for the sum of all elements in a power set? I would assume, naively, you have to just add everything, which would run in about 2^n, where n is the size of the set.</p>\n\n<p>For example: A = {1,2,3} Powerset(A) = {{}, {1}, {2}, {1, 2}, {3}, {1, 3}, {2, 3}, {1, 2, 3} } Sum(Powerset(A)) = {{} + {1} + {2} + {1 + 2} + {3} + {1 + 3} + {2 + 3} + {1 + 2 + 3} }</p>\n\n<p>I'm defining addition between sets as: A = {1}, B = {2,3}, A + B = {1} + {2 + 3} = 6</p>\n", 'ViewCount': '37', 'Title': 'Proof of sum of powerset?', 'LastActivityDate': '2014-03-12T03:02:16.443', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15579', 'Tags': '<complexity-theory><time-complexity>', 'CreationDate': '2014-03-12T02:20:44.307', 'Id': '22523'}{'Body': '<p>I\'m curious to know if this problem is NP-Hard / NP-Complete, which I believe would mean I\'m unlikely to find a polynomial-time algorithm to solve it.</p>\n\n<p>I have written a program which randomly generates a tournament fixture, and I call it many times to try to pack the matches into the smallest number of rounds.</p>\n\n<p>When it comes to complexity theory I am still a novice, so laymen\'s terms would be appreciated.</p>\n\n<p><strong>Inputs:</strong></p>\n\n<ul>\n<li>a set of countries, each of which may enter one or more entrants to the tournament (e.g. Australia might enter two entrants, UK might enter three entrants, and South Africa might enter one entrant)</li>\n</ul>\n\n<p><strong>Constraints:</strong></p>\n\n<ul>\n<li>each match consists of two entrants playing against each other</li>\n<li>during a round, an entrant can only play in a single match</li>\n<li>no entrant wants to compete in a match against another entrant from the same country</li>\n<li>no entrant wants to compete against another entrant more than once in the tournament</li>\n<li>each entrant must play the exact same number of matches overall</li>\n<li>the number of matches each entrant must play is determined by MIN(for each entrant, total number of possible matches that satisfy the other constraints)</li>\n</ul>\n\n<p>For example, say we have the following entrants:</p>\n\n<ul>\n<li>AU #1 and #2</li>\n<li>UK #1, #2 and #3</li>\n<li>SA #1</li>\n</ul>\n\n<p>The possible matches in this (artificially small) case are:</p>\n\n<pre><code>AU1 v. UK1   AU1 v. UK2   AU1 v. UK3   AU1 v. SA\nAU2 v. UK1   AU2 v. UK2   AU2 v. UK3   AU2 v. SA\nUK1 v. SA    UK2 v. SA    UK3 v. SA\n</code></pre>\n\n<p>Since we want each entrant to play the exact same number of games, the maximum number of games per entrant is three (this can be derived from the total number of entrants (6) less the number of entrants from the largest country (3)).</p>\n\n<p>Since there are six entrants in total, and there are two entrants to each match, the maximum number of courts we can utilise in a round is 3.</p>\n\n<p>A sample fixture is:</p>\n\n<pre><code>          Court 1      Court 2      Court 3\nRound 1   AU1 v. UK1   AU2 v. UK2   UK3 v. SA\nRound 2   AU1 v. UK2   AU2 v. UK3   UK1 v. SA\nRound 3   AU1 v. UK3   AU2 v. UK1   UK2 v. SA\n</code></pre>\n\n<p>This is a nice example because it\'s easy to find a solution where each entrant has played exactly 3 games each, and they all pack perfectly into 3 rounds across 3 courts. Two of the possible 11 matches have not been played, but we don\'t care. We sum the results from each entrant\'s 3 games to determine an overall ranking, which is then used to generate the finals matches.</p>\n\n<p>I have other scenarios where there are more entrants and I have been unable to pack them so neatly, but by running my program many times it almost always finds a near-optimal packing where the number of rounds and unused courts is minimised.</p>\n\n<p><strong>Output</strong></p>\n\n<p>The first problem is if there is a polynomial-time algorithm to generate an optimal fixture.</p>\n\n<p>The optimal fixture is defined by:</p>\n\n<ul>\n<li>minimum number of unused courts (which implies minimising the number of rounds)</li>\n</ul>\n\n<p>The second problem is, given a fixture "A", how to determine if it is an optimal solution, i.e. is it possible to prove that there can exist no better packings for a given set of entrants. If "A" involves no unused courts in any round, then the answer for that one is clearly "Yes" - but if there are any unused courts in any round, the answer is, I think, difficult to derive.</p>\n', 'ViewCount': '159', 'Title': 'Is building this tournament fixture an NP-Hard / NP-Complete problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T11:36:17.767', 'LastEditDate': '2014-03-15T11:32:25.760', 'AnswerCount': '1', 'CommentCount': '8', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '15583', 'Tags': '<complexity-theory><np-hard>', 'CreationDate': '2014-03-12T05:36:53.410', 'FavoriteCount': '2', 'Id': '22530'}{'Body': '<p>Can there be any relations regarding the number of nodes available in a digraph so that to qualify it as NP-Complete problem. \nIf we consider this problem for instance:<br/>\nInput: A digraph $G=(V,E)$ and two nodes $u,v \\in V$ <br/>\nQuestion: Is there a path in $G$ from $u$ to $v$? <br/>\nCan we say this problem is NP-Complete problem since the digraph have only two nodes that they have a path from one another and this makes it be a Hamiltonian Path.<br/> Hints are appreciated! </p>\n', 'ViewCount': '46', 'Title': 'Relation between digraph and NP-Complete problem', 'LastEditorUserId': '7269', 'LastActivityDate': '2014-03-13T14:55:06.787', 'LastEditDate': '2014-03-13T14:28:48.627', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '22588', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7269', 'Tags': '<complexity-theory><graph-theory><np-complete><hamiltonian-path>', 'CreationDate': '2014-03-13T13:45:05.770', 'Id': '22586'}{'Body': '<p>I am trying to either prove or refute the claim mentioned in the title.\nAny ideas ?</p>\n', 'ViewCount': '64', 'ClosedDate': '2014-03-15T11:24:37.173', 'Title': 'Assume that $\\mathsf{NP} \\subseteq \\mathsf{P}/\\text{log(n)}$, does it imply that $\\mathsf{P} = \\mathsf{NP}$?', 'LastActivityDate': '2014-03-14T23:45:11.077', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'OwnerDisplayName': 'Robert777', 'PostTypeId': '1', 'OwnerUserId': '7068', 'Tags': '<complexity-theory><p-vs-np>', 'CreationDate': '2014-03-14T21:05:23.827', 'Id': '22635'}{'Body': '<p>I am reading the proof of PCP theorem in <a href="http://people.csail.mit.edu/madhu/papers/1992/almss-conf.pdf" rel="nofollow">Proof Verication and Hardness of Approximation Problems</a>. The following paragraph appears in section 3 (page 4), <em>"Outline of the Proof of the Main Theorem"</em>.</p>\n\n<blockquote>\n  <p>The results of these sections show that $NP \\subset OPT (poly(n), 1)$ (Theorem 5) and $NP \\subset OPT (\\log n, poly \\log n)$ (Theorem 8). Theorems 9 and 10 show that the recursion idea applies to these proof systems, and in particular shows the following:</p>\n  \n  <ol>\n  <li>$OPT (f (n), g(n)) \\subset OPT (f (n) + O(\\log g(n)), (\\log g(n))^{O(1)} )$ and</li>\n  <li>$OPT (f (n), g(n)) \\subset OPT (f (n) + (g(n))^{O(1)} , 1)$.</li>\n  </ol>\n  \n  <p>This allows us to conclude that $NP \\subset OPT (\\log n, poly \\log \\log n)$ (<strong>by composing</strong> two $OPT (\\log n, poly \\log n)$ proof systems) and then <strong>by composing</strong> this system with the $OPT (poly(n), 1)$ proof system we obtain $OPT (\\log n, 1)$ proof system for $NP$.</p>\n</blockquote>\n\n<p><strong>Edit.</strong> Composition of verifiers is defined in <a href="http://www.cs.umd.edu/~gasarch/pcp/AS.pdf" rel="nofollow">Probabilistic Checking of Proofs: A New Characterization of NP</a>  section 3 (page 13) <em>"Normal Form Verifiers and Their Use in Composition"</em>.</p>\n\n<blockquote>\n  <p>Let $r, q, s, t$ be any functions defined on the natural integers. Suppose there is a normal-form verifier $V_2$ that is $(r(n), s(n), q(n), t(n))$-constrained. Then, for all functions $R, Q, S, T$, $$RPCP(R(n), S(n), Q(n), T(n)) \\subseteq \\\\RPCP(R(n) + r(\\tau), s(\\tau), Q(n) + q(\\tau), Q(n)t(\\tau))$$ where $\\tau$ is a shorthand for $O((T(n))^2)$.</p>\n</blockquote>\n\n<p>Where $RPCP(r, s, q, t)$ is a $PCP(r, s \\cdot q)$ which takes $t$ time to accept of reject <em>after</em> reading the $s \\cdot q$ bits.</p>\n\n<p>I still don\'t see how this composition works. Is $OPT(r, q) = RPCP(r, q, 1, q)$ and a normal form verifier? In that case it seems to work, but then just composing $OPT(poly(n), 1)$ with $OPT(\\log n, poly \\log n)$ is enough, so why bother with $OPT(\\log n, poly \\log \\log n)$ or relations $1.$ and $2.$?</p>\n', 'ViewCount': '83', 'Title': 'Proof of PCP theorem', 'LastEditorUserId': '5167', 'LastActivityDate': '2014-03-23T10:41:07.547', 'LastEditDate': '2014-03-23T10:41:07.547', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '5167', 'Tags': '<complexity-theory><proof-techniques><probabilistic-algorithms>', 'CreationDate': '2014-03-15T07:51:32.813', 'Id': '22644'}{'Body': "<p>I know these relations :  </p>\n\n<p>\\begin{gather}\n\\mathrm{NC}^1 \\subseteq \\mathrm{NC}^2 \\subseteq \\dots \\subseteq \\mathrm{NC}^i \\subseteq \\dots \\subseteq \\mathrm{NC} \\\\\n\\mathrm{NC}^i \\subseteq \\mathrm{AC}^i \\subseteq \\mathrm{NC}^{i+1} \\\\\n\\mathrm{NC}^1 \\subseteq \\mathrm{L} \\subseteq \\mathrm{NL} \\subseteq \\mathrm{AC}^1 \\subseteq \\mathrm{NC}^2 \\subseteq \\mathrm{P}\n\\end{gather}</p>\n\n<p>But I don't know how to compare an algorithm with time complexity of $\\mathrm{NC}^i$ to an algorithm with Polynomial complexity? </p>\n\n<p>For example, Topological sort $\\mathrm{NC}^2$ with BFS $\\mathcal{O}(|V| + |E|)$ </p>\n", 'ViewCount': '84', 'Title': 'How to compare algorithms in class NC time complexity with other classes?', 'LastEditorUserId': '15050', 'LastActivityDate': '2014-04-02T06:07:46.287', 'LastEditDate': '2014-04-02T06:07:46.287', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '15050', 'Tags': '<complexity-theory><time-complexity><parallel-computing>', 'CreationDate': '2014-03-17T13:29:30.280', 'FavoriteCount': '1', 'Id': '22709'}{'Body': u'<p>In "Introduction to the Theory of Computation" by Sipser, Savitch\'s theorem is explained as an improvement to a naive storage scheme for simulating non-deterministic Turing machines (NTM). I am going to quote the text verbatim, because quite frankly I don\'t fully understand it (which is why I was unable to really ask my question in enough detail):</p>\n\n<blockquote>\n  <p>We need to simulate an $f(n)$ space NTM deterministically. A naive\n  approach is to proceed by trying all the branches of the NTM\u2019s\n  computation, one by one. The simulation needs to keep track of which\n  branch it is currently trying so that it is able to go on to the next\n  one. But a branch that uses $f(n)$ space may run for $2^{O(f(n))}$\n  steps and each step may be a nondeterministic choice. Exploring the\n  branches sequentially would require recording all the choices used on\n  a particular branch in order to be able to find the next branch.\n  Therefore, this approach may use $2^{O(f(n))}$ space, exceeding our\n  goal of $O(f^2(n))$ space. (Sipser, "Introduction to the Theory of Computation" 334)</p>\n</blockquote>\n\n<p>He goes on to describe Savitch\'s use of a subroutine called $CANYIELD$, a TM that decides whether some configuration $c_2$ is reachable from some other configuration $c_1$ in $t$ steps. It is recursively defined, so that $CANYIELD(c_1, c_n, t)$ results in two recursive calls $CANYIELD(c_1, c_m, t/2)$ and $CANYIELD(c_m, c_n, t/2)$, and so on until the "distance" between configurations is $0$ or $1$, or it is deemed unreachable. I think this can also be described as $STCON$ on a configuration graph of the TM in question.</p>\n\n<p>So, there are two questions I have.</p>\n\n<ol>\n<li>I understand how the size of each level and the depth of $CANYIELD$ results in no more than $O(f^2(n))$ use of space, but I don\'t understand how the intermediate configuration $c_m$ is found. Is this just not important given that all we care about is space? How do we know that the space used to obtain $c_m$ is negligible?</li>\n<li>I don\'t understand why we need $2^{O(f(n))}$ space in the naive approach. Why can\'t we "forget" about branches we\'ve executed, so that we are still using at most the space required to go all the way down one branch?</li>\n</ol>\n', 'ViewCount': '90', 'Title': "The crux of Savitch's Theorem", 'LastEditorUserId': '15660', 'LastActivityDate': '2014-03-24T13:36:21.720', 'LastEditDate': '2014-03-22T21:32:55.710', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15660', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2014-03-18T04:32:50.640', 'Id': '22745'}{'Body': '<p>If $P = NP$ would this imply that polynomial time reduction from an $NP$- to a $P$-problem would be possible? And if $P\\neq NP$ does it imply that a polynomial time reduction from an $NP$- to a $P$-problem would be impossible?</p>\n', 'ViewCount': '50', 'Title': 'P, NP and polynomial time reduction?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-19T00:04:25.510', 'LastEditDate': '2014-03-19T00:04:25.510', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '22770', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14819', 'Tags': '<complexity-theory><np-complete><reductions>', 'CreationDate': '2014-03-18T20:12:32.437', 'Id': '22769'}{'ViewCount': '66', 'Title': 'what are the basic/typical/common mistakes in P=NP claims?', 'LastEditDate': '2014-03-19T08:20:32.237', 'AnswerCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>the P vs NP problem attracts a lot of attention, not all of it desirable, for a wide variety of reasons. there are many P=NP claims eg on this widely cited list maintained by mathematician Woegeorgi, <a href="http://www.win.tue.nl/~gwoegi/P-versus-NP.htm" rel="nofollow">P vs NP page</a>. also, intermittently there are hot questions on SE sites related to P vs NP (eg recently [2],[3]) below, &amp; there is even a <code>p-vs-np</code> tag on both cs.se (<a href="/questions/tagged/p-vs-np" class="post-tag" title="show questions tagged &#39;p-vs-np&#39;" rel="tag">p-vs-np</a>) &amp; <a href="http://cstheory.stackexchange.com/questions/tagged/p-vs-np">tcs.se</a> sites. the following is intended somewhat as a reference question.</p>\n\n<blockquote>\n  <p>what are the basic/typical/common mistakes in P=NP claims?</p>\n</blockquote>\n\n<p>[1] <a href="http://cs.stackexchange.com/questions/1877/how-not-to-solve-p-np">How not to solve P=NP?</a>, cs.se<br>\n[2] <a href="http://codegolf.stackexchange.com/questions/24401/so-obviously-p-np">P vs NP code exercise, codegolf.se</a><br>\n[3] <a href="http://mathoverflow.net/questions/160265/analogues-of-p-vs-np-in-the-history-of-mathematics">Analogs of P vs NP in the history of mathematics</a> MO.se</p>\n', 'ClosedDate': '2014-03-20T00:00:45.987', 'Tags': '<complexity-theory><p-vs-np>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-19T08:20:32.237', 'CommentCount': '3', 'AcceptedAnswerId': '22794', 'CreationDate': '2014-03-19T03:57:10.470', 'Id': '22792'}{'Body': '<p>I want to show that $CO-2Col \\le_L USTCON$ (Log-Space reduction)</p>\n\n<h2>$USTCON$</h2>\n\n<blockquote>\n  <p>The $s-t$ connectivity problem for <strong>undirected</strong> graphs is\n  called $USTCON$.</p>\n  \n  <p>[Input]: An undirected graph $G=(V,E)$, $s,t \\in V$.</p>\n  \n  <p>[Output]: 1 iff $s$ is connected to $t$ in $G$.</p>\n</blockquote>\n\n<hr>\n\n<h2>$CO-2Col$</h2>\n\n<blockquote>\n  <p>A graph is $2$-colorable if there is a way to color the vertices\n  of $G$ with $2$ colors, such that for every edge the two vertices\n  on the edge are colored differently. $CO-2Col$ is the following\n  problem:</p>\n  \n  <p>[Input]: An undirected graph $G$.</p>\n  \n  <p>[Output]: 1 iff $G$ is NOT $2$-colorable.</p>\n</blockquote>\n\n<hr>\n\n<p>My <strong>solution</strong> is for an input graph $G$ the reduction outputs $(G\',s,t)$ where\n $s$ an arbitrary vertex of $G$, $t$ is one of its neighbours and\n$G\'=G^2$ namely an edge $(u,v)\\in E(G\')$,iff there is $w \\in V (w \\ne u,v)$\nsuch that $(u,w)\\in E(G)$ and $(w,v)\\in E(G)$. </p>\n\n<p>$G$ is bipartite \niff $G\'$ is not connected (and $s$ and $t$ belongs to different\nparts).</p>\n\n<p>But this only works when the input graph $G$ is <strong>connected</strong>.</p>\n\n<p>A counter example: (if we choose s,t to be A,B)</p>\n\n<p><img src="http://i.stack.imgur.com/JYLSD.jpg" alt="Counter example"></p>\n\n<p>How can I improve my reduction that it will work at the unconnected case? or maybe a new reduction is needed?</p>\n\n<p>Thanks!</p>\n', 'ViewCount': '89', 'Title': 'Log-Space Reduction $CO-2Col \\le_L USTCON$', 'LastActivityDate': '2014-03-20T20:01:06.013', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22829', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15890', 'Tags': '<complexity-theory><reductions><space-complexity>', 'CreationDate': '2014-03-19T21:19:01.533', 'Id': '22826'}{'Body': '<p>Given a language $L\\subseteq \\Sigma^*$ in $P$, is the language</p>\n\n<p>$subwords(L) = \\{v\\in\\Sigma^* : \\text{there exist } u,w\\in \\Sigma^* \\text{ with } uvw\\in L\\}$  </p>\n\n<p>that consists of all subwords of words in $L$ also guaranteed to lie in $P$?</p>\n', 'ViewCount': '29', 'ClosedDate': '2014-03-21T21:13:56.350', 'Title': 'Is P closed under subwords?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-21T21:13:15.440', 'LastEditDate': '2014-03-21T21:13:15.440', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15970', 'Tags': '<complexity-theory><closure-properties><polynomial-time>', 'CreationDate': '2014-03-21T12:41:15.233', 'Id': '22902'}{'Body': "<p>Define the complexity class $C$ to be the class of all languages that can be verified by a TM that has:</p>\n\n<ul>\n<li>Input tape: Read only, move in both directions.</li>\n<li>Witness tape: Read only, move only in one direction.</li>\n<li>Work tape: Read-Write, move in both directions.</li>\n</ul>\n\n<p>The machine itself is deterministic (the guesses are the value of the witness tape). The space complexity is the size of the work tape, and is polynomial. We say the machine\naccepts an input if and only if there exists a setting for the witness tape, with which the\nmachine accepts.</p>\n\n<p>Prove: $C = \\mathrm{PSPACE}$</p>\n\n<p>Well, it's obvious that $\\mathrm{PSPACE} \\subset C$ since any TM $M$ can be converted into a TM $M'$ that simply ignores its witness tape and runs in the same space complexity as $M$.</p>\n\n<p>However, I'm struggling with the other direction. The problem is that the witness can be exponential in the input and I can't see how we can enumerate over all witnesses using only polynomial space.</p>\n\n<p>edit: I had a mistake, the witness tape can only be read in one direction.</p>\n", 'ViewCount': '36', 'Title': 'Polynomial space complexity with exponential size witnesses', 'LastEditorUserId': '7068', 'LastActivityDate': '2014-03-22T18:32:45.640', 'LastEditDate': '2014-03-22T18:32:45.640', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22912', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7068', 'Tags': '<complexity-theory><space-complexity><complexity-classes>', 'CreationDate': '2014-03-21T17:49:32.217', 'Id': '22907'}{'ViewCount': '394', 'Title': 'If I solve hard instance, therefore I prove NP=P?', 'LastEditDate': '2014-03-25T13:53:27.870', 'AnswerCount': '1', 'Score': '-4', 'PostTypeId': '1', 'OwnerUserId': '15913', 'Body': '<p>If someone (off-topic) asks a question (on-topic) like this:</p>\n\n<p>Suppose that he claims that $\\mathcal{P=NP}$. Suppose that someone else (on-topic) gives him an instance of an NP-complete problem that cannot be solved by any computer optimally, i.e., to get the optimal solution, one must run an algorithm for very long time (the age of the universe for example).</p>\n\n<p>If this someone (off-topic) solves this instance very fast optimally. Because the problem is NP-complete, we know that it can be easily verified.  </p>\n\n<p>Can we verify easily that it is the optimal solution or we can only verify that it is just a solution?</p>\n\n<p>In the other hand, if this someone (off-topic) solves every instance (hard instances) of an NP-hard problem very fast. Can we claim that he proved that $\\mathcal{P=NP}$?</p>\n\n<p>I want an answer, not a vote up/down or on/off-topic. </p>\n', 'ClosedDate': '2014-03-22T23:04:55.900', 'Tags': '<complexity-theory><p-vs-np>', 'LastEditorUserId': '-1', 'LastActivityDate': '2014-03-25T13:53:27.870', 'CommentCount': '4', 'AcceptedAnswerId': '22944', 'CreationDate': '2014-03-22T16:10:59.560', 'Id': '22939'}{'Body': '<p><a href="http://en.wikipedia.org/wiki/NP_%28complexity%29#Formal_definition" rel="nofollow">Wikipedia\'s formal definition of NP based on deterministic verifiers</a> states: </p>\n\n<blockquote>\n  <p>A language L is in NP if and only if there exist polynomials p and q,\n  and a deterministic Turing machine M, such that</p>\n  \n  <ul>\n  <li>For all x and y, the machine M runs in time p(|x|) on input (x,y)</li>\n  <li>For all x in L, there exists a string y of length q(|x|) such that M(x,y) = 1</li>\n  <li>For all x not in L and all strings y of length q(|x|), M(x,y) = 0</li>\n  </ul>\n</blockquote>\n\n<p>I\'m not an expert in the field but the first bullet point leads me to think that M must run in time p(|x|) regardless of the size of y, which doesn\'t seem to be true, at least if M gets to read y completely. What if |y| > p(|x|)? </p>\n\n<p>Is the first bullet point of the definition correct? Shouldn\'t it be </p>\n\n<blockquote>\n  <p>For all x and y, the machine M runs in time p(|x|+|y|) on input (x,y)</p>\n</blockquote>\n\n<p>Can you point me to an authoritative source with the original definition of NP based on deterministic verifiers?</p>\n', 'ViewCount': '105', 'Title': "Is Wikipedia's formal definition of NP correct?", 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-23T13:12:55.713', 'LastEditDate': '2014-03-23T13:12:55.713', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16003', 'Tags': '<complexity-theory><terminology><np>', 'CreationDate': '2014-03-22T23:44:44.197', 'Id': '22952'}{'Body': '<p>I was just reading something about NP-hard problems and cryptosystems. </p>\n\n<p>I was thinking: Every NP-complete problem can be reduced to another and every NP-complete problem has an equivalent (NP-hard) optimisation problem. A successful attack on one such NP-hard cryptosystem $A$ would mean that every other NP-hard cryptosystem $B$ would be vulnerable to that same attack; just reduce $B$ to $A$ and use the available attack. </p>\n\n<p>That would actually mean that we would be able to extend Information Set Decoding attack of Code-based systems to any NP-hard based cryptosystem.</p>\n\n<p>Is this consideration correct?</p>\n', 'ViewCount': '124', 'Title': 'Can all NP-complete cryptosystems be broken if one is broken?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-01T17:35:50.940', 'LastEditDate': '2014-03-24T22:51:15.960', 'AnswerCount': '4', 'CommentCount': '5', 'Score': '5', 'OwnerDisplayName': 'user3313119', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-hard><cryptography>', 'CreationDate': '2014-03-22T22:34:35.087', 'FavoriteCount': '1', 'Id': '23000'}{'ViewCount': '46', 'Title': u'Assume that SAT \u2208 PSIZE, does it imply that NP = coNP?', 'LastEditDate': '2014-03-24T22:45:55.480', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7068', 'FavoriteCount': '1', 'Body': "<p>Assume that $\\mathrm{SAT} \\in \\mathrm{PSIZE}$, does it imply that $\\mathrm{NP} = \\mathrm{coNP}$ ?</p>\n\n<p>I think that I've managed to show that if $\\mathrm{SAT} \\in \\mathrm{PSIZE}$, then both $\\mathrm{NP}$ and $\\mathrm{coNP}$ are contained in $\\mathrm{PSIZE}$, but I can't see how does help me. Any ideas ?</p>\n", 'Tags': '<complexity-theory><time-complexity><complexity-classes><circuits>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-24T22:45:55.480', 'CommentCount': '8', 'AcceptedAnswerId': '23019', 'CreationDate': '2014-03-24T21:11:49.613', 'Id': '23018'}{'Body': '<p>I have a found a small article [1] saying (the first paragraph of the introduction) that the minimum-weight independent dominating set is NP-complete in chordal graphs, but at the same time, seems to contradict that exact statement.</p>\n\n<p>Moreover, I have found another reference [2] saying that in chordal graphs, it is polynomial time solvable. So which one is it?</p>\n\n<p>Note: I am just trying to reference this result in a project of mine. No need for a proof.</p>\n\n<p>Edit: I am referring to this piece of the introduction: "Domination and most of its variations are NP-complete for chordal graphs (even for the subclass of split graphs) with the exception of independence domination (see [3]). On the other hand, an unpublished proof for the NP-completeness of the weighted independent domination in chordal graphs by the author 20 years ago..." Then in my reference [2], it also states that the weighted version is polynomial time solvable, yet here they say that there is an NP-completeness proof. Am I missing something fundamental?</p>\n\n<hr>\n\n<ol>\n<li><a href="http://dx.doi.org/10.1016/j.dam.2003.05.004" rel="nofollow">The weighted independent domination problem is NP-complete for chordal graphs</a> by G. J. Chang (2004)</li>\n<li>Fundamentals of Domination in Graphs by T. W. Haynes, S. Hedetniemi and P. Slater (1998)</li>\n</ol>\n', 'ViewCount': '26', 'Title': 'Is the minimum weight independent dominating set np-complete in chordal graphs?', 'LastEditorUserId': '4734', 'LastActivityDate': '2014-03-25T00:53:34.463', 'LastEditDate': '2014-03-25T00:52:30.127', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4734', 'Tags': '<complexity-theory><graphs><np-complete>', 'CreationDate': '2014-03-25T00:30:21.693', 'Id': '23025'}{'Body': "<p>I have been attempting to learn parameterized complexity on my own, and decided to go through all of the FPT race problems, and defining easy FPT algorithms for them, using concepts such as bounded search tree. I am stuck on figuring out an FPT algorithm for edge dominating set, defined as follows:</p>\n\n<p><strong>EdgeDominatingSet</strong></p>\n\n<p>Instance: A graph $G=(V,E)$; a positive integer $k$. </p>\n\n<p>Question: Is there a subset $D\\subseteq E$ with $|D|\\leq k$ such that for each $e\\in E$, either $e\\in D$ or $e$ shares an endpoint with an $e'\\in D$. </p>\n\n<p>Parameter: $k$</p>\n\n<p>I'm not looking to define anything fancy, just a simple FPT result. Any help would be great! </p>\n", 'ViewCount': '40', 'Title': 'FPT algorithm for edge dominating set', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-25T08:46:17.463', 'LastEditDate': '2014-03-25T08:46:17.463', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '16086', 'Tags': '<algorithms><complexity-theory><parametrized-complexity>', 'CreationDate': '2014-03-25T04:47:51.053', 'Id': '23028'}{'Body': '<p>I am reading the reduction given by Sipser in his textbook "Introduction to the Theory of Computation," on page 303. The reduction is:</p>\n\n<p>\\begin{equation} 3SAT \\leq_p KCLIQUE \\end{equation}</p>\n\n<p>I am really trying to understand everything formally -- putting everything in a strict logical notation helps me learn Math. To clarify, the content of this proof, has not helped me give other reductions because I don\'t understand one direction of the $\\iff$ in the logic of reductions.</p>\n\n<p>In this reduction, $f$ must be s.t:\n\\begin{equation} w\\in 3SAT \\iff f(w) \\in KCLIQUE \\end{equation}\nand $f$ computes within a polynomial number of steps of the input size. The polynomial part is easy for me to understand, so no problem here!</p>\n\n<p>I see that the above logical statement is equivalent to:\n\\begin{equation} w\\in 3SAT \\implies f(w) \\in KCLIQUE \\land w\\not\\in 3SAT \\implies f(w) \\not\\in KCLIQUE\\end{equation}\nThe above just says yes-instances map to yes-instances and no-instances map to no-instances.</p>\n\n<p>It appears that Sipser shows us:\n\\begin{equation} w\\in 3SAT \\implies f(w) \\in KCLIQUE \\land f(w) \\in KCLIQUE \\implies w\\in 3SAT\\end{equation}</p>\n\n<p>Which is also equivalent to the above by taking the contrapositive of the second implication.</p>\n\n<p>Here is my understanding of the $\\implies$ direction. Given a yes-instance of $3SAT$, show that the reduction $f$ gives us a yes-instance for $KCLIQUE$. This seems completely natural.</p>\n\n<p><strong>I don\'t really understand the other direction</strong> -- namely, given a yes-instance of KCLIQUE we are supposed to show that we get a yes-instance of $3SAT$. However since the reduction goes from $3SAT$ to $KCLIQUE$ i.e. the domain is the language $3SAT$ and the Codomain is the language $KCLIQUE$, I don\'t understand <strong>how</strong> we show this. </p>\n\n<p>It appears that the argument is; Our reduction has provided us this graph, from which we can create a satisfying assignment from?</p>\n\n<p>Please help me understand the other direction, and thanks for your time.</p>\n', 'ViewCount': '40', 'Title': 'Polynomial Reduction 3SAT to K-Clique', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-25T10:07:17.047', 'LastEditDate': '2014-03-25T08:48:36.160', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6815', 'Tags': '<complexity-theory><np-complete><reductions><proof-techniques>', 'CreationDate': '2014-03-25T06:23:45.563', 'Id': '23030'}{'ViewCount': '52', 'Title': 'Complexity of calculating independence number of a hypergraph', 'LastEditDate': '2014-03-25T21:38:30.027', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '16119', 'FavoriteCount': '1', 'Body': '<p>Let $G$ be a "hypergraph", a collection of vertices $V=\\{v_1,v_2,\\ldots,v_n\\}$ and a collection of "hyperedges" $E=\\{e_1,e_2,\\ldots,e_m\\}$, where $e_i\\subseteq V$ and unlike normal edges, an edge may contain more than two vertices.</p>\n\n<p>An "independent set" (<a href="http://en.wikipedia.org/wiki/Independent_set_(graph_theory)" rel="nofollow">http://en.wikipedia.org/wiki/Independent_set_(graph_theory)</a>) is a collection of vertices, $U$, that does not fully contain any of the hyperedges:  $e_i\\not\\subseteq U$.  The "independence number" or "maximum independent set size" is the size of the largest independent set in the graph $G$.</p>\n\n<p>I know that finding if there is an independent set of size $k\\in\\mathbb{N}$ in some normal graph $G$ is NP-Complete.  If I am not mistaken, this holds for hypergraphs as well.  However calculating the independence number is not proven to be NP.  Even approximating it is not proven in NP.</p>\n\n<p>First, is there a more specific complexity class for calculating the independence number than NP-Hard?</p>\n\n<p>Second, how much harder is it for a hypergraph?  Again, is there a complexity class more specific?</p>\n\n<p>For related questions, a recent dissertation has been helpful to me: <a href="https://escholarship.org/uc/item/79t9b162" rel="nofollow">https://escholarship.org/uc/item/79t9b162</a>.</p>\n\n<p>Thanks!</p>\n', 'Tags': '<complexity-theory><graph-theory>', 'LastEditorUserId': '16119', 'LastActivityDate': '2014-03-26T01:07:40.823', 'CommentCount': '15', 'AcceptedAnswerId': '23051', 'CreationDate': '2014-03-25T20:15:07.680', 'Id': '23044'}{'ViewCount': '155', 'Title': 'Which NPC problems are NP Hard', 'LastEditDate': '2014-03-26T15:55:51.197', 'AnswerCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '947', 'Body': '<p>I have read that TSP and Subset Sum problems are NPC problems which are also NP Hard. There are also problems like Halting Problem which is NP Hard, but not NP Complete</p>\n\n<p>And Wikipedia defines this as</p>\n\n<blockquote>\n  <p>A problem $H$ is NP-hard if and only if there is an NP-complete problem\n  $L$ that is polynomial time Turing-reducible to $H$.</p>\n</blockquote>\n\n<p>Like NP Complete problem is there any problem considered to be the first NP Hard problem?</p>\n\n<p>To show one problem to be NP Hard we need just to reduce one NPC problem to it?</p>\n\n<p>Whether all NPC problems are NP Hard?</p>\n\n<p>If no, why not?</p>\n', 'ClosedDate': '2014-03-26T18:02:38.240', 'Tags': '<complexity-theory><np-complete><np-hard>', 'LastEditorUserId': '947', 'LastActivityDate': '2014-03-26T16:07:14.477', 'CommentCount': '0', 'AcceptedAnswerId': '23085', 'CreationDate': '2014-03-26T15:28:18.103', 'Id': '23081'}{'Body': "<p>I've read that subset sum is NP-complete. What happens when I change the decision problem to look for a  constant number? So the decision problem would look like this:</p>\n\n<blockquote>\n  <p>Input:\n  A collection of nonnegative integers A and a nonnegative integer b, </p>\n  \n  <p>Output:\n  Boolean value indicating whether some subset of \n  the collection sums to <strong>10</strong></p>\n</blockquote>\n\n<p>Would this still be NP-complete? I don't believe you would be able to reduce every other NP-complete problem to it.</p>\n", 'ViewCount': '73', 'Title': 'Is subset sum with a fixed target sum NP-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-29T11:51:34.573', 'LastEditDate': '2014-03-29T11:51:34.573', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15375', 'Tags': '<complexity-theory><np-complete><decision-problem>', 'CreationDate': '2014-03-28T23:01:39.577', 'Id': '23198'}{'Body': '<p>Consider, for example, the definition for $\\Sigma_2^p$ complexity class.</p>\n\n<p>$$ x \\in L \\Leftrightarrow \\exists u_1 \\forall u_2 \\;M(x, u_1, u_2) = 1, $$</p>\n\n<p>where $u_1, u_2 \\in \\{0,1\\}^{p(|x|)}$, for some polynomial $p$. Here, $M$ must be polynomial time. But polynomial in the size of what exactly? For example, if we choose (guess) some $u_1$, do I consider it to be fixed size when talking about time complexity of $M$? More precisely, should $M$ be polynomial only in the size of $x$? </p>\n\n<p>An example. Consider the problem whether, given a graph $A$, there exists a graph\n$B$ such that $B$ is subgraph isomorphic to $A$.</p>\n\n<p>$$A \\in L \\Leftrightarrow \\exists B \\; \\text{SubGraphIsomorphic}(A, B) = 1 $$</p>\n\n<p>Now, subgraph isomorphism is NP-complete. If $B$ is fixed, then there is a TM\nthat implements $\\text{SubGraphIsomorphic}$ in deterministic polynomial time. If $B$ is not fixed, then I cannot claim such a thing unless I know $\\sf P=NP$. Is this problem in $\\Sigma_{1}^{p}$, i.e. $\\sf NP$? (Ok, this problem has trivial solutions, but I hope it helps to pinpoint my confusion.)</p>\n\n<p>My confusion generalizes for all $\\Sigma_{i}^p$. </p>\n', 'ViewCount': '35', 'Title': 'Polynomial Hierarchy --- polynomial time TM', 'LastEditorUserId': '472', 'LastActivityDate': '2014-03-29T20:09:59.553', 'LastEditDate': '2014-03-29T20:09:59.553', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23207', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8508', 'Tags': '<complexity-theory><time-complexity><complexity-classes><polynomial-time>', 'CreationDate': '2014-03-29T01:14:37.587', 'Id': '23204'}{'Body': '<p>While familiarizing myself with polynomial hierarchy, I have come across a problem\nof showing $NP^{\\Sigma_{k}^{p} \\cap \\Pi_{k}^{p}} \\subseteq \\Sigma_{k}^{p}$. By looking at the proof for $NP^{SAT} \\subseteq \\Sigma_{2}^{p}$, I got the concept\nwhere we can guess the choices of the NTM and answers to SAT call and then encode\nthe correctness of these answers. However, while I understand encoding correctness of answers for SAT calls, I have a problem of doing the same for the oracle $\\Sigma_{k}^{p} \\cap \\Pi_{k}^{p}$, which has no known complete problems. It seems to me there is a cookbook way of proving this that I am missing?</p>\n', 'ViewCount': '24', 'Title': 'Polynomial hierarchy intersection', 'LastActivityDate': '2014-03-30T04:15:53.713', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '23245', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8508', 'Tags': '<complexity-theory><time-complexity><polynomial-time>', 'CreationDate': '2014-03-30T02:34:29.467', 'Id': '23243'}{'Body': "<p>I am trying to figure out a reduction to prove $W[1]$-hardness for this, but I am having significant trouble. Here is the problem:</p>\n\n<p><strong>Bag Automaton</strong>: \nA non deterministic finite state automaton $M=(Q,I,s,F,d)$. $Q$ is the set of states, $I$ is the set of items, $s\\in Q$ is the start state, $F\\subseteq Q$ is the set of accepting states, $d\\subseteq Q\\times 2^I\\times Q\\times 2^I$ is the set of transitions, where $2^I$ is the set of all subsets of $I$. \nA computation of a Bag Automaton starts in $s$, with given item set $I' \\subseteq I$. At each step the bag automaton in state $q$ and associated item set  $I^* \\subseteq I$ does a state transition $(q,A,q',B)$, $A\\subseteq I^*$, which sets the state to $q'$ and the bag automaton's item set to $(I'-A) \\cup B $. $M$ accepts if there is a sequence of transitions from $s$ to an $f \\in F$.</p>\n\n<p><strong>Bag Automaton Computation</strong>\nInput: A Bag Automaton $M=(Q,I,s,F,d)$, a set $I' \\subseteq I$ and a positive integer $k$.</p>\n\n<p>Parameters: $k$</p>\n\n<p>Question: Can $M$ accept on $I'$ by executing at most $k$ transitions?</p>\n\n<p>I am almost certain a reduction from clique where the initial bag contains all vertices will work, but I cannot figure out how to formalize it.</p>\n", 'ViewCount': '51', 'Title': 'Reduction from clique to bag automata', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-04-01T15:00:21.597', 'LastEditDate': '2014-04-01T15:00:21.597', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '16079', 'Tags': '<complexity-theory><automata><reductions><parametrized-complexity>', 'CreationDate': '2014-03-31T00:46:42.120', 'Id': '23276'}{'Body': "<p>Let's suppose I have an NP-complete problem A.  </p>\n\n<p>Can there be $A_1$, $A_2$ such that $A_1$ and $A_2$ are disjoint, $A = A_1 \\cup A_2$, and $A_1$ and $A_2$ are NP-complete?</p>\n\n<p>My guess would be yes.  For example, just partition SAT into formulas with an even number of variables and formulas with an odd number.</p>\n\n<p>Follow up:  Can I partition $A$ into infinitely many such $A_i$? (I suppose yes: take formulas with $2^n$ variables, $3^n$, $5^n$, $7^n$, $11^n$, or something like that)</p>\n", 'ViewCount': '59', 'Title': 'Partitioning NP-complete problems', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T02:09:36.470', 'LastEditDate': '2014-03-31T08:18:58.903', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'OwnerDisplayName': 'user22235', 'PostTypeId': '1', 'Tags': '<complexity-theory><np-complete>', 'CreationDate': '2014-03-28T17:47:21.313', 'Id': '23282'}{'Body': "<p>I have a homework question about the properties (decidability, Turing-recognizability, etc.) of the language </p>\n\n<p>$$ L = \\{ \\langle M \\rangle | \\text{$M$ is a TM and $M$ accepts some string $w$ which has 101 as a prefix} \\}. $$</p>\n\n<p>I have made an attempt at showing decidability of $L$:</p>\n\n<p>On input $\\langle M, w\\rangle$ (where $M$ is a TM and $w \\in \\sigma^*$):</p>\n\n<ol>\n<li>Simulate $M$ on $w$.</li>\n<li>If $M$ rejects and halts, reject. If $M$ accepts and halts, accept.</li>\n</ol>\n\n<p>However, I'm not sure about moving forward after this. I do not want a solution, but I want some ideas/techniques as to what else I can prove about $L$. </p>\n", 'ViewCount': '85', 'Title': 'The language of TMs accepting some word starting with 101', 'LastEditorUserId': '683', 'LastActivityDate': '2014-03-31T23:14:21.683', 'LastEditDate': '2014-03-31T22:38:24.807', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16332', 'Tags': '<complexity-theory><formal-languages><turing-machines><automata>', 'CreationDate': '2014-03-31T21:27:37.883', 'Id': '23300'}{'Body': "<p>I was wondering how I could go about creating an algorithm that gets all the cliques in a graph in PSPACE</p>\n\n<p>So far, based on some of the readings I've done, I am considering to use bit-strings (that have a length equal to the number of vertices in the graph). Then, for every possible subset of the vertices, a turing machine writes bit-strings in order and checks if the subset is a clique. On the side there will also be a counter that counts the number of cliques </p>\n\n<p>This is where I am stuck so far. Can anyone help me improve my solution (or tell me whats wrong with it)? Thanks very much</p>\n", 'ViewCount': '48', 'ClosedDate': '2014-04-02T06:20:16.330', 'Title': 'Clique and PSPACE', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-02T06:20:01.417', 'LastEditDate': '2014-04-02T06:20:01.417', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16368', 'Tags': '<complexity-theory><graphs><space-complexity><enumeration>', 'CreationDate': '2014-04-02T01:55:22.447', 'Id': '23331'}{'Body': '<p><em>The following may contain errors. It is precisely because I am not\nsure I understand the topic that I am asking questions. I do not have\nbooks about it and could not find an adequate reference on the web.</em></p>\n\n<p>I am discussing a problem regarding an enumeration of strings that\nshould be in <strong>amortized constant delay</strong>. From what I understood (but\nunderstanding that is part of my question), this means that the average\ntime taken for each answer should be independent of the size of the\nanswer, so that the total cost is $O(n)$ where $n$ is the number of\nanswers.</p>\n\n<p>My discussion partner went on to assert (I believe) that amortized\nconstant delay is possible for enumerating the strings accepted by a\ntrie, but not for enumerating the paths of a DAG. And I am at loss to\nsee a significant difference, since proper use of a stack should let\nme explore the DAG as if it had been exploded into a trie (by\nduplicating whatever is below a merge vertex).</p>\n\n<p>The only real difference I can see is that the accepting nodes of a\ntrie can be labeled with a single symbol identifier characterizing the accepted word (turning the trie\ninto a Moore machine) so that the total cost is only a traversal of\nthe trie, with single step output of the symbol label when traversing an\naccepting node.</p>\n\n<p>Such labeling identification is not possible for a DFA structured as a DAG, since an\naccepting node can correspond to different paths. The only way to name\npaths is to describe them in extenso (or nearly so: enough to disambiguate merges), so that the cost\nof the output by itself is already something like $O(n\\times s)$ where\n$s$ is the size of the longest path, thus entailing the same time cost\njust for doing the output.</p>\n\n<p>Where do I err, and what is the accepted wisdom and knowledge on this topic?\nPointers to web references are useful too.</p>\n', 'ViewCount': '31', 'Title': 'What is hiding behind amortized constant delay enumeration?', 'LastActivityDate': '2014-04-02T10:58:09.810', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8321', 'Tags': '<complexity-theory><graphs><strings><amortized-analysis><enumeration>', 'CreationDate': '2014-04-02T10:58:09.810', 'Id': '23337'}{'Body': u'<p>What is the proof of  P \u2286 NP? I cannot happen to find a good explanation for it. I read that the <code>verifier</code> will just ignore the proof and accept any proof if the solution is YES and reject all proofs if the answer is NO. I\'m also unclear about verifier.</p>\n\n<p>Definition of P and NP I follow:</p>\n\n<p>P: a problem \'Q\' is said to be in P if there exists an efficient (polynomial worst-case time) algorithm for solving the problem. E.g.- "is a given natural number \'x\' even?".</p>\n\n<p>NP: a problem \'Q\' is said to be in NP if there exists efficient verifiers (an algorithm for verifying if a given proof is correct).</p>\n', 'ViewCount': '58', 'ClosedDate': '2014-04-02T15:13:50.323', 'Title': u'Proof of P \u2286 NP', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-02T15:12:09.783', 'LastEditDate': '2014-04-02T15:12:09.783', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16381', 'Tags': '<complexity-theory><decision-problem><complexity-classes>', 'CreationDate': '2014-04-02T13:10:01.710', 'Id': '23340'}{'ViewCount': '69', 'Title': 'Why is SAT in NP?', 'LastEditDate': '2014-04-02T20:50:53.243', 'AnswerCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14436', 'FavoriteCount': '1', 'Body': "<p>I know that CNF SAT is in NP (and also NP-complete), because SAT is in NP and NP-complete. But what I don't understand is why? Is there anyone that can explain this?</p>\n", 'Tags': '<complexity-theory><satisfiability><decision-problem><np>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-02T20:50:53.243', 'CommentCount': '1', 'AcceptedAnswerId': '23362', 'CreationDate': '2014-04-02T17:25:08.017', 'Id': '23353'}{'Body': '<p>There is a basic result in circuit complexity that says:</p>\n\n<blockquote>\n  <p>There exists a language that cannot be solved with circuits of size $o(\\frac{2^n}{n})$.</p>\n</blockquote>\n\n<p>The argument is a simple counting argument on the number of boolean functions and the number of distinct circuits.  See, for example, <a href="http://theory.stanford.edu/~trevisan/cs254-14/lecture03.pdf">these lecture notes</a>.</p>\n\n<p>I believe it is unknown whether or not this bound is tight.  That is, we don\'t know if the following statement is true:</p>\n\n<blockquote>\n  <p>Every language can be solved with circuits of size $O(\\frac{2^n}{n})$.</p>\n</blockquote>\n\n<p>If this statement were true, would it have any interesting implications for complexity theory?</p>\n', 'ViewCount': '33', 'Title': 'Implications of the $\\Omega(\\frac{2^n}{n})$ circuit lower bound being tight', 'LastActivityDate': '2014-04-02T21:09:54.020', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23369', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '16172', 'Tags': '<complexity-theory><lower-bounds><circuits>', 'CreationDate': '2014-04-02T20:16:50.513', 'FavoriteCount': '1', 'Id': '23365'}{'Body': '<p>Many of us are familiar with the $P$ class. Counting solutions is believed to be a difficult task and that is why we usually end up approximating the number of solutions (we relax the accuracy of the counting). I want to ask, if relaxing the quality of the solutions counted has been addressed as a problem. Is there for example, any algorithms able to answer the question: How many vertex covers there are, with 3 times the cardinality of the minimum vertex cover? Is the problem $P-$ complete?  </p>\n', 'ViewCount': '30', 'Title': 'Counting approximate solutions', 'LastEditorUserId': '2499', 'LastActivityDate': '2014-04-04T04:29:07.460', 'LastEditDate': '2014-04-04T03:04:32.083', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '23411', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '12201', 'Tags': '<complexity-theory><complexity-classes>', 'CreationDate': '2014-04-04T02:44:13.297', 'Id': '23409'}{'Body': "<p>Consider two sets: the set of validities of propositional logic and the set of validities of monadic predicate logic. Call the first set $VP$ and the second set $VQM$. Both of these sets are decidable, so there are Turing machines that recognize both them and their complements. </p>\n\n<p>I'm interested in how the decidability of these two sets translates into grammars for them, along the lines of the Chomsky hierarchy. I have three questions:</p>\n\n<p>(1) Are there context-sensitive grammars that generate $VP$ and $VQM$? The answer would be yes if the Turing machines that recognized these sets were linearly bounded, but I don't think they are. </p>\n\n<p>(2) If these languages <em>aren't</em> context-sensitive, can <em>anything</em> be said about a grammar that generates them? </p>\n\n<p>I would have a better grasp of the second question if I understood something about grammars <em>between</em> the top two levels of the Chomsky hierarchy, context-sensitive and unrestricted. </p>\n\n<p>(3) There is a natural class of automata between linear-bounded Turing machines and unrestricted Turing machines: polynomially bounded TMs, exponentially bounded TMs, etc. Do these classes of TM track anything on the grammar side of the Chomsky hierarchy? If not, is there <em>any</em> structure to the gap between context-sensitive grammars and full-on unrestricted grammars?</p>\n\n<p>(Just to be clear: I'm <em>not</em> talking about a grammar for propositional logic, but a grammar for its validities.) </p>\n\n<p>EDIT: I thought I'd add a comment about why I'm interested in these questions. I know there is an unrestricted grammar that generates the (recursively enumerable but not recursive) set of validities of (full-on, polyadic) predicate logic. But since $VP$ and $VQM$ are not just recursively enumerable but recursive, I was wondering if the grammars that generate them might have more structure, in the Chomsky-hierarchy sense, than the grammar that generates the validities of all of predicate logic. <strong>In other words, I'm wondering if there is a <em>grammatical</em> way of detecting the difference between sets of validities that are recursive (as in the case of propositional and monadic predicate logic) and sets of validities that are merely recursively enumerable.</strong> What can be said about grammars of recursive but not recursively enumerable languages? Most references on the Chomsky hierarchy say nothing about this gap, but I don't know if that means there's nothing to be said.</p>\n", 'ViewCount': '35', 'Title': 'grammatical complexity of propositional and monadic predicate validities? (and grammars for recursive but not context-sensitive languages?)', 'LastEditorUserId': '16445', 'LastActivityDate': '2014-04-04T22:33:44.240', 'LastEditDate': '2014-04-04T22:33:44.240', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '16445', 'Tags': '<complexity-theory><formal-languages><formal-grammars><logic>', 'CreationDate': '2014-04-04T14:53:25.143', 'FavoriteCount': '1', 'Id': '23423'}{'ViewCount': '27', 'Title': 'What is the Unique Games Conjecture?', 'LastEditDate': '2014-04-07T11:58:09.610', 'AnswerCount': '0', 'Score': '-1', 'OwnerDisplayName': 'zighalo', 'PostTypeId': '1', 'OwnerUserId': '16535', 'Body': '<p>What is the unique game conjecture in relatively simple words? What are the consequences of proving it or disproving it? Does it has any relation to game theory? Why is there "game" in the name?</p>\n', 'ClosedDate': '2014-04-07T14:07:00.723', 'Tags': '<complexity-theory><np-hard><approximation>', 'LastEditorUserId': '472', 'LastActivityDate': '2014-04-07T11:58:09.610', 'CommentCount': '4', 'CreationDate': '2014-04-04T21:43:52.677', 'Id': '23508'}{'Body': '<p>Given a DAG\n$G$\nand a vertex\n$v$\n, consider the following \ngame:\nWe can place a pebble on a vertex\n$u$\nif all its predecessors have pebbles on them.\nWe can remove a pebble from a vertex any time.\nThe goal is to place a pebble on the vertex\n$v$\n. THE goal is to reduce the number of pebbles\nneeded to pebble the vertex\n$v$\n. Consider the following language:\n{\n($G; v; p$)\n|\nthere is a pebbling strategy that uses at most\n$p$\npebbles and places a pebble on\n$v$\n}\nwhere\n$G$\nis a DAG. Show that the language is\nDSPACE\n(\n$O\n(\nn^2\n)$), where\n$n$\nis the\nnumber of vertices of\nG</p>\n', 'ViewCount': '17', 'ClosedDate': '2014-04-07T14:04:37.933', 'Title': 'pebbling is DSPACE($O(n^2)$)', 'LastActivityDate': '2014-04-07T11:50:54.337', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '-1', 'OwnerDisplayName': 'user3505352', 'PostTypeId': '1', 'OwnerUserId': '16533', 'Tags': '<complexity-theory><space-complexity>', 'CreationDate': '2014-04-07T05:34:47.737', 'Id': '23512'}{'Body': "<p>I am trying to prove that 3SAT is polynome time reducable to CNF-SAT, but I don't know how to do this. A formula F is in 3SAT iff f(F) is in KNFSAT, but since 3SAT is a part of KNFSAT, every formula that is in 3SAT will automatically be in CNF-SAT. Is my conclusion correct? And how do I actually show this in a correct manner? </p>\n", 'ViewCount': '26', 'Title': '3SAT to CNF-SAT reduction', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-07T14:09:36.477', 'LastEditDate': '2014-04-07T14:09:36.477', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23514', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '14436', 'Tags': '<complexity-theory><reductions><satisfiability><3-sat>', 'CreationDate': '2014-04-07T13:16:48.117', 'Id': '23513'}{'Body': '<p>Let me preface this question by giving some helpful <a href="http://lcm.csa.iisc.ernet.in/dsa/node187.html" rel="nofollow">background material</a>. </p>\n\n<p>I\'m trying to solve the traveling salesman problem using branch and bound. Concretely, for a partial solution, I\'m using the solution the algorithm would attain by making greedy choices as an upper bound, and comparing this bound to the current best solution. If the bound attained using this heuristic is better than the cost of the best known solution, we continue exploring the partial solution. Otherwise, we prune and discard. Note that the greedy solution attained is always valid.</p>\n\n<p>The above link mentions a method for finding a global lower bound. This is fairly intuitive: for each node, we add to the bound the sum of the two minimum cost edges to other nodes (representing the cheapest in/out edges, if you will) and divide by two to avoid double counting. The solution implied by this global bound is almost never a valid solution but instead gives a hard limit on the lowest cost we could ever hope to attain. </p>\n\n<p>Here\'s how I\'m currently trying to calculate a local lower bound (a lower bound for a partial solution) with cost $C(S)$.</p>\n\n<ul>\n<li>Set <code>bound</code> to the current accumulated cost, $C(S)$</li>\n<li>For each unvisited node, add to <code>bound</code> the sum of the two least cost edges, making sure that the edges selected don\'t lead to a node already visited</li>\n<li>return <code>bound/2</code></li>\n</ul>\n\n<p>Here\'s my question: How is the above solution different from the greedy bound? Maybe a better lower bound would be to add to <code>bound</code> the sum of the two least cost edges, paying <strong>no attention to whether these edges lead to nodes already visited</strong>. Also, how do I actually use this bound to prune the search space? Do I compare the local lower bound computed for a partial solution with the global lower bound, pruning if $L(S) &lt; GL$ or if $L(S) &gt; C(B)$, or if $L(S) &gt; L(B)$? (here $GL$ corresponds to the global lower bound; $L(S)$ computes the local lower bound on a partial solution; $C(B)$ represents the trip cost on the best known solution; $L(B)$ is the lower bound on the best solution). Also, how will $L(S)$ ever be less than the global lower bound (i.e. an infeasible solution) if we only ever use (valid) edges to cities we haven\'t yet visited? </p>\n\n<p>Comments and suggestions on using this lower bound as well as its efficacy would be very much appreciated. Thank you. </p>\n', 'ViewCount': '70', 'Title': 'Traveling Salesman: how to use a lower bound?', 'LastEditorUserId': '16389', 'LastActivityDate': '2014-04-08T08:07:23.937', 'LastEditDate': '2014-04-08T03:01:07.293', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16389', 'Tags': '<complexity-theory><optimization><lower-bounds><traveling-salesman><branch-and-bound>', 'CreationDate': '2014-04-07T17:34:38.440', 'Id': '23520'}{'ViewCount': '140', 'Title': 'If $\\log xy=\\log x+\\log y$ then why multiplication is harder than addition?', 'LastEditDate': '2014-04-08T17:51:22.997', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '16535', 'FavoriteCount': '1', 'Body': "<p>Someone told me that the $\\log$ function was introduced to make the calculation easier. If we have to calculate $xy$, we can calculate instead $\\log x+\\log y$ since $\\log xy=\\log x+\\log y$. How this can make the calculation easier? Maybe from a mathematician point of view but what about a computer scientist's point of view?</p>\n\n<p>If it makes the calcualtion easier then why people do not use it to simplify the complexity of the multiplication algorithms?</p>\n\n<p>From my own thinking, this transformation makes the calculation more difficult. How can we calculate the $\\log x$ and $\\exp x$ functions in a computer?</p>\n\n<p>Am I right? Any suggestions please? Thank you for your time.</p>\n", 'Tags': '<algorithms><complexity-theory><reference-request><education>', 'LastEditorUserId': '16535', 'LastActivityDate': '2014-04-08T20:37:30.863', 'CommentCount': '2', 'AcceptedAnswerId': '23564', 'CreationDate': '2014-04-08T16:13:52.080', 'Id': '23554'}{'Body': '<p>Just wondering, if it were possible to have n = poly(m) and then would m = Omega(n) be valid?</p>\n', 'ViewCount': '16', 'ClosedDate': '2014-04-09T22:52:47.323', 'Title': 'Is it possible for n = poly(Omega(n))?', 'LastActivityDate': '2014-04-09T22:13:06.473', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16601', 'Tags': '<complexity-theory>', 'CreationDate': '2014-04-09T22:13:06.473', 'FavoriteCount': '1', 'Id': '23610'}{'Body': u'<p>So in complexity theory, I\'ve run across different definitions for NP problems -- </p>\n\n<ul>\n<li>Decision problems where a solution can be <em>verified</em> by a <strong>DFA</strong> in polynomial time</li>\n<li>Decision problems where a solution can be <em>found</em> by an <strong>NFA</strong> in polynomial time</li>\n</ul>\n\n<p>Is there one of the above that is generally more accepted as the "go-to" definition in the academic community? If so, is there a reason? (If these "definitions" are incorrect \u2013 please feel free to correct me).</p>\n\n<p>To me, the second definition makes more sense intuitively.</p>\n', 'ViewCount': '36', 'Title': u'NP Problem definition \u2013 verifiable on DFA vs. solvable on NFA', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-10T15:39:52.327', 'LastEditDate': '2014-04-10T15:39:52.327', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23644', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12906', 'Tags': '<complexity-theory><np>', 'CreationDate': '2014-04-10T15:25:02.277', 'Id': '23643'}{'Body': u'<p>I\'m trying to understand/show that DNF VALID is coNP-hard. I have given an algorithm for the complement of DNF VALID and shown that this is in NP (since the complement of a language in NP is in coNP), but I\'m really struggling to show that DNF VALID is coNP-hard. </p>\n\n<blockquote>\n  <p>The complement of DNF VALID = {\u03d5 | \u03d5 is not in DNF OR \u03d5 is falsifiable}</p>\n</blockquote>\n\n<p>A simple algorithm for the complement of DNF VALID:</p>\n\n<pre><code>On a non-deterministic TM M: "on input \u03d5 (boolean formula):\n 1. Scan through \u03d5 and check whether \u03d5 is on DNF. \n      If it is, accept, \n      if not, continue to step 2. \n 2. Non-deterministically choose a valuation for \u03d5\n 3. If \u03d5 is falsifiable accept, if not, reject\n</code></pre>\n\n<p>To show that DNF VALID is coNP-hard I think that I need to show that a language that is NP-complete can be reduced in polynomial time to the complement of DNF VALID, but I\'m not sure with which language to choose, and I could really use some help on how to go forth with the reduction. </p>\n', 'ViewCount': '45', 'Title': 'Showing that DNF VALID is coNP-hard', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-11T06:47:22.733', 'LastEditDate': '2014-04-11T06:47:22.733', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '23666', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16655', 'Tags': '<complexity-theory><reductions><co-np>', 'CreationDate': '2014-04-10T18:09:27.833', 'Id': '23654'}{'ViewCount': '52', 'Title': 'Application of Combinatorics, Logic and computability theory in physical science: Tiling of Wang Tile with proportionality', 'LastEditDate': '2014-04-11T12:23:29.707', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14553', 'FavoriteCount': '1', 'Body': '<p>The original problem of Domino Tiling and Wang Tile has great theoretical interest on computability theory... However, the great emerging problem on application of Wang Tile in material science and physics requires the tiling to satisfy one more condition:</p>\n\n<p>The tiling should satisfy some proportionality, say, Tile 1 should appear with frequency 1/16, Tile 2 with frequency 9/16, Tile 3 with 6/16, Tile 4 with frequency 0...</p>\n\n<p>The most important decision problem is the following:\nCould a given set of Tile tile a grid of size NxN satisfying the frequency constraint within a error of +-epsilon.</p>\n\n<p>For example: could the set {Tile 1, Tile 2, Tile 3, Tile 4} tile the NxN grid with frequency 1/16+-0.01, 9/16+-0.01, 6/16+-0.01, 0+-0.01 respectively....</p>\n\n<p>From one of my previous post:</p>\n\n<p><a href="http://mathoverflow.net/questions/161731/practical-algorithms-for-np-complete-problems">Algorithms for NP complete problem</a></p>\n\n<p>I realize the decision problem of tiling without such constraint could be modeled by SAT... With this constraint the problem becomes ridiculously difficult and I eagerly seek for solutions towards this finite decidable problem.... (we could forget epsilon for a moment if the problem with epsilon is too hard)...</p>\n\n<p>So here is the question: how do we model this problem in MIP or SAT or any other optimization algorithm?</p>\n\n<p>For more detail why this problem is practical in material science and physics, see my previous post:</p>\n\n<p><a href="http://mathoverflow.net/questions/147374/coloring-in-lattice">coloring in lattice</a></p>\n\n<p><a href="http://mathoverflow.net/questions/149565/reference-for-wang-tile">reference for wang tile</a></p>\n\n<p><a href="http://mathoverflow.net/questions/157239/computational-approach-deciding-whether-a-set-of-wang-tile-could-tile-the-space">Computational approach deciding whether a set of Wang Tile could tile the space up to some size</a></p>\n\n<p>P.S. this is a bounty question from mathoverflow without yet a applicable solution...</p>\n\n<p><a href="http://mathoverflow.net/questions/162248/application-of-combinatorics-logic-and-computability-theory-in-physical-science">Application of Combinatorics, Logic and computability theory in physical science: Tiling of Wang Tile with proportionality</a></p>\n', 'ClosedDate': '2014-04-11T06:41:13.197', 'Tags': '<complexity-theory><optimization><logic><satisfiability>', 'LastEditorUserId': '14553', 'LastActivityDate': '2014-04-11T12:23:29.707', 'CommentCount': '6', 'AcceptedAnswerId': '23664', 'CreationDate': '2014-04-10T23:23:56.653', 'Id': '23662'}{'Body': '<p>Say we have a set of numbers $A=\\{a_1, a_2, \\dots, a_n\\}$, and we wish to sum over all possible combinations of $k$ terms to compute</p>\n\n<p>$$\n\\sum_{\\substack{C \\subseteq \\{1,2,\\dots,n\\} \\\\ |C|=k}} \\prod_{c \\in C} a_c\n$$</p>\n\n<p>Naively this requires $O(k\\binom{n}{k})$ operations.</p>\n\n<p>This is different from from computing the permanent where there are permutations. </p>\n\n<p>Is this problem known to be NP-hard when $n=2k$ or other conditions such as $n=\\Theta(k^2)$? </p>\n', 'ViewCount': '49', 'Title': 'Is summing over all possible $k$-combinations NP-hard?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-12T07:34:46.677', 'LastEditDate': '2014-04-12T07:34:46.677', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '23687', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '404', 'Tags': '<complexity-theory><time-complexity><np-hard>', 'CreationDate': '2014-04-11T23:17:54.563', 'Id': '23683'}{'Body': '<p>I have a problem which essentially reduces to this:</p>\n\n<ol>\n<li>You have a black-box function that accepts inputs of length $n$.</li>\n<li>You can measure the amount of time the function takes to return the answer, but you can\'t see exactly how it was calculated.</li>\n<li>You have to determine whether the time-complexity of this function is polynomial or exponential.</li>\n</ol>\n\n<p>The way I did this was by running thousands of random sample inputs of varying lengths through the function, then plotting them on a scatter plot with times on the y-axis and input length on the x-axis.</p>\n\n<p>What are some metrics and methods I can use to determine if these points best fit to a polynomial curve or to an exponential curve?</p>\n\n<p>(Similar question asking how to draw polynomial/exponential best fit lines in Python on Stack Overflow: <a href="https://stackoverflow.com/questions/23026267/how-to-determine-if-a-black-box-is-polynomial-or-exponential">https://stackoverflow.com/questions/23026267/how-to-determine-if-a-black-box-is-polynomial-or-exponential</a>)</p>\n', 'ViewCount': '272', 'Title': 'How to determine if a black-box is polynomial or exponential', 'LastEditorUserId': '16701', 'LastActivityDate': '2014-04-12T16:26:22.670', 'LastEditDate': '2014-04-12T06:40:45.627', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '23688', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '16701', 'Tags': '<complexity-theory><time-complexity><polynomial-time><statistics>', 'CreationDate': '2014-04-12T04:54:14.143', 'Id': '23686'}{'Body': '<p>Trying to understand the concept of NP-completeness, I came across this pearl on Wikipedia:</p>\n\n<blockquote>\n  <p>From <a href="http://en.wikipedia.org/wiki/NP-complete" rel="nofollow">NP-complete</a>:</p>\n  \n  <p>A decision problem L is <strong>NP-complete</strong> if it is in the set of NP problems\n  and also in the set of <strong>NP-hard</strong> problems.</p>\n  \n  <p>From <a href="http://en.wikipedia.org/wiki/NP-hard" rel="nofollow">NP-hard</a>:</p>\n  \n  <p>A problem H is <strong>NP-hard</strong> if and only if there is an <strong>NP-complete</strong> problem\n  L that is polynomial time Turing-reducible to H [...].</p>\n</blockquote>\n\n<p>So it appears that the definition of NP-completeness depends on the definition of NP-hardness, and vice versa.</p>\n\n<p>What is going on here? How can I untangle these concepts?</p>\n', 'ViewCount': '20', 'ClosedDate': '2014-04-12T13:26:52.730', 'Title': 'Cyclic definition of NP-completeness', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-12T13:26:43.133', 'LastEditDate': '2014-04-12T13:26:43.133', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16709', 'Tags': '<complexity-theory><terminology><np-complete><np-hard>', 'CreationDate': '2014-04-12T11:23:20.347', 'Id': '23700'}{'Body': '<p>I\'m trying to find reduction from 3-SAT to Max-2-SAT, so far no luck.<br>\nLet me first describe it.  </p>\n\n<blockquote>\n  <p><strong>3-SAT</strong>: Given a CNF formula $\\varphi$, where every clause in $\\varphi$ has <em>exactly</em> 3 literals in it, one should determine if there exist an assignment that satisfies it.  </p>\n  \n  <p><strong>Max-2-SAT</strong>: Given a CNF formula, where every clause in $\\phi$ has <em>exactly</em> 2 literals in it, and a positive number $k$, one should determine if there exist an assignment that satisfies <em>at least</em> $k$ clauses.</p>\n</blockquote>\n\n<p>Let me first show what I have tried so far.<br>\nGiven $\\varphi=\\wedge _{i=1}^{n}C_i$ where: $C_i=(l_{i_1}\\vee l_{i_2} \\vee l_{i_3})$,<br>\nI set: $\\phi=\\wedge _{j=1}^{3n}D_i$, where: $D_i=(l_{i_1}\\vee l_{i_2})\\wedge(l_{i_1}\\vee l_{i_3})\\wedge(l_{i_2}\\vee l_{i_3})$ and $k=2n$.<br>\nIt\'s quite easy to see that this will not work...<br>\nAlthough, if there exist an assignment which satisfies $\\varphi$ it means there exist an assignment that satisfies $k=2n$ clauses in $\\phi$, the second direction is not true.<br>\nI found several reductions online (such as <a href="http://www.stanford.edu/~rrwill/williams-max2sat-encyc.pdf" rel="nofollow">this</a>, for example), but none of them were useful since in my problem, each clause in $\\phi$ must have <strong>exactly</strong> two literals, where in the link above, the formula can also contain 1-length clause in it.</p>\n\n<p>I could really use some help here.</p>\n', 'ViewCount': '68', 'Title': '3-SAT to Max-2-SAT Reduction', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-13T23:39:21.800', 'LastEditDate': '2014-04-12T13:39:18.530', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11972', 'Tags': '<complexity-theory><reductions><np-hard><satisfiability>', 'CreationDate': '2014-04-12T11:58:23.407', 'FavoriteCount': '0', 'Id': '23702'}{'Body': '<p>In my computation book by Sipser, he says that since every language that can be decided in time $o(n \\log n)$ is regular, then that can be used to show $TIME(n \\log (\\log n))\\setminus TIME(n)$ must be the empty set. Can anyone show me why this is?</p>\n\n<p>both $TIME(n\\log(\\log n))$ and $TIME(n)$ are regular. I think that only means we can subtract the two sets and the result will still be regular. I just dont understand how its possible to subtract the collection of $O(n\\log(\\log n))$ time TM decidable languages from the collection of $O(n)$ time TM decidable languages and get the empty set. These two collections are not equal so I feel like there will be something left over</p>\n', 'ViewCount': '100', 'Title': u'Why is TIME(n log (log n)) \\ TIME(n) = \u2205?', 'LastEditorUserId': '31', 'LastActivityDate': '2014-04-13T15:30:31.163', 'LastEditDate': '2014-04-13T15:30:31.163', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '23726', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14864', 'Tags': '<complexity-theory><regular-languages><time-complexity><complexity-classes>', 'CreationDate': '2014-04-13T01:15:28.793', 'Id': '23721'}{'Body': "<p>I understand this is a slightly vague question, but there are results for P vs. NP, such as the question cannot be easily resolved using oracles. Are there any results like this which have been shown for P vs. NP but have not been shown for P vs PSPACE, so that there is hope that certain proof techniques might resolve P vs PSPACE even though they cannot resolve P vs NP? And are there any non-trivial results that say that if P = PSPACE then there are implications that do not necessarily hold under P = NP? Or anything else non-trivial in the literature that suggests it's easier to prove P != PSPACE than it is to prove P != NP?</p>\n", 'ViewCount': '96', 'Title': 'Has there been any more progress on P vs. PSPACE compared to P vs. NP?', 'LastActivityDate': '2014-04-13T22:02:49.173', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<complexity-theory><time-complexity><space-complexity>', 'CreationDate': '2014-04-13T18:27:42.120', 'FavoriteCount': '1', 'Id': '23745'}{'Body': '<p>Subset sum is given by this question:\n"The problem is this: given a set (or multiset) of integers, is there a non-empty subset whose sum is zero?"</p>\n\n<p>My question is: If the numbers in the set are functions of other numbers, is that still subset sum? For example\nThe set {1,2,3} where the first number is X, the second is X+1, third is X+2 and so on. So it is a general set.</p>\n\n<p>Is this allowed? </p>\n', 'ViewCount': '42', 'ClosedDate': '2014-04-15T23:45:05.803', 'Title': 'Constraints on subset sum problem', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T07:44:52.180', 'LastEditDate': '2014-04-14T07:44:52.180', 'AnswerCount': '3', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15579', 'Tags': '<complexity-theory><decision-problem>', 'CreationDate': '2014-04-13T23:01:49.100', 'Id': '23757'}{'Body': '<p>I\'m just starting to get into the theory of computation, which studies what can be computed, how quickly, using how much memory and with which computational model.</p>\n\n<p>I have a pretty basic question, but am really hoping some of you guys can help me understand the concept behind it:</p>\n\n<blockquote>\n  <p>Why is everything centered around the notion and definition of\n  LANGUAGES (i.e. regular languages and context free languages)? And how\n  do these relate and describe the complexity of an algorithm and the\n  possible computational models for solving them?</p>\n</blockquote>\n\n<p>I read these sort of related questions:</p>\n\n<ul>\n<li><a href="http://cstheory.stackexchange.com/questions/14811/what-is-the-enlightenment-im-supposed-to-attain-after-studying-finite-automata">What is the enlightenment I&#39;m supposed to attain after studying finite automata?</a></li>\n<li><a href="http://cstheory.stackexchange.com/questions/8539/how-practical-is-automata-theory">How practical is Automata Theory?</a></li>\n</ul>\n\n<p>but still don\'t have an answer to my doubts, since they provide a practical justification of why they are important (which I do understand) but don\'t help me understand why complexity theory is based upon them.</p>\n', 'ViewCount': '674', 'Title': 'Why use languages in Complexity theory', 'LastActivityDate': '2014-04-15T00:26:26.867', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '9', 'OwnerDisplayName': 'Matteo', 'PostTypeId': '1', 'OwnerUserId': '16764', 'Tags': '<complexity-theory><formal-languages>', 'CreationDate': '2014-04-14T16:34:19.947', 'FavoriteCount': '2', 'Id': '23787'}{'Body': '<p>I was reading a paper of Buhrman and Homer "Superpolynomial Circuits, Almost Sparse Oracles and the Exponential Hierarchy" (<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.2228&amp;rep=rep1&amp;type=pdf" rel="nofollow">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.2228&amp;rep=rep1&amp;type=pdf</a>).</p>\n\n<p>On the bottom of page 2 they remark that the results of Kannan imply that $NEXPTIME^{NP}$ does not have polynomial size circuits. I know that in the exponential time hierarchy, $NEXPTIME^{NP}$ is just $\\Sigma_2EXP$, and I also know that Kannan\'s result is that $\\forall c\\mbox{   }\\exists L\\in\\Sigma_2P$ such that $L \\not\\in Size(n^c)$. Of course, Kannan\'s theorem is NOT saying $\\Sigma_2P \\not\\subset P/poly$ (in order for that to be the case we would need to show that $\\exists L\\in\\Sigma_2P$ such that $\\forall c$, $L \\not\\in Size(n^c)$. However, I don\'t see how Kannan\'s result implies that $NEXPTIME^{NP} \\not\\subset P/poly$?</p>\n', 'ViewCount': '7', 'ClosedDate': '2014-04-18T15:13:43.597', 'Title': "Question about Kannan's theorem", 'LastActivityDate': '2014-04-18T14:10:27.167', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16883', 'Tags': '<complexity-theory><circuits><oracle-machines>', 'CreationDate': '2014-04-18T14:10:27.167', 'Id': '23914'}{'Body': "<p>A polynomial map is equal to another polynomial map iff they take on the same values at each point.  So this is different from formal polynomials.   So since in $\\Bbb{Z}_p$, $x^{p-1} = 1$ for all $x \\neq 0$, and is $0$ on $0$, we have that there are a finite number of polynomial maps in $\\Bbb{Z}_p[x_1, \\dots, x_k]$.  For now let's work in $\\Bbb{Z}_2$ for simplicity.</p>\n\n<p>The coefficients are arbitrarily chosen $c_i \\in \\Bbb{Z}_2$, and polynomials are in $\\Bbb{Z}_2[x_1, \\dots, x_k]$.  Then </p>\n\n<p>$c_0 + c_1x_1$ obviously has complexity $2$ (2 operations explicitly required).</p>\n\n<p>$c_0 + c_1x_1 + c_2 x_2$ needs $4$ ops.</p>\n\n<p>$c_0 + c_1x_1 + (c_2+ c_3 x_1) x_2$ needs $6$ ops max.</p>\n\n<p>$c_0 + c_1x_1 + c_2 x_2 + c_3 x_3 + c_4 x_1 x_2 + c_5 x_1 x_3 + c_6 x_2 x_3 + c_7 x_1 x_2 x_3 = \\\\ c_0 + x_1(c_1 + x_2 (c_4 + c_7 x_3) + c_5 x_3) + x_2 (c_2 + c_6 x_3) + c_3 x_3$ </p>\n\n<p>needs $14$ ops.  The pattern seems to be</p>\n\n<p>$1 + (k + (k-1) + \\dots + 1) + ((k-2) + (k-1) + \\dots + 1) + \\dots + 1$ which is $O(k^3)$, so is polynomial complexity polynomial?</p>\n\n<p>Where did I make any mistake?  Thanks.</p>\n\n<p>This doesn't make sense as there are about $p^k$ coefficients, and each one must be visited.</p>\n\n<p>$* + x_1(* + x_2(* + x_3(* + *x_4) + *x_3 + *x_4)) + x_2 (* + x_3(* + *x_4) + *x_4) + x_3(* + *x_4) + *x_4$</p>\n", 'ViewCount': '28', 'Title': 'Complexity of general polynomial map evaluation is polynomial?', 'LastEditorUserId': '12373', 'LastActivityDate': '2014-04-20T23:51:52.963', 'LastEditDate': '2014-04-19T20:31:32.287', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23943', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12373', 'Tags': '<algorithms><complexity-theory><polynomial-time><polynomials>', 'CreationDate': '2014-04-19T20:08:43.153', 'Id': '23941'}{'Body': '<p>My textbook says: "The Boolean hierarchy is contained in the class $P^{NP}\\subseteq\\Sigma^P_2\\cap\\Pi^P_2$." However, it provides neither a proof nor a proof sketch nor some hint. How can I convince myself that the claim is true?</p>\n', 'ViewCount': '55', 'Title': 'Why is the Boolean hierarchy contained in the class $P^{NP}$?', 'LastActivityDate': '2014-04-21T14:15:30.400', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23987', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14654', 'Tags': '<complexity-theory><complexity-classes><oracle-machines>', 'CreationDate': '2014-04-20T19:06:08.477', 'Id': '23955'}{'Body': '<p>Given $n$ points $x_1, x_2, ..., x_n \\in \\mathbb{R}^k$, where $\\mathbb{R}^k$ can be high dimensional. Is it possible to devise a fast algorithm </p>\n\n<p>(1) Preparation: first take the n points as an input, do whatever preprocessing necessary. </p>\n\n<p>(2) Query: for each query $f_i = w^\\top x$ being a hyperplane and a constant $b$, find the subset of points $\\{x_i | w^\\top x_i \\geq b\\}$.</p>\n\n<p>such that the asymptotic complexity for the query is less than $\\Theta(k \\cdot n)$ ?</p>\n', 'ViewCount': '40', 'Title': 'Fast algorithm to find points on one side of hyperplane?', 'LastActivityDate': '2014-04-21T19:33:24.670', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '24003', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<algorithms><complexity-theory><computational-geometry>', 'CreationDate': '2014-04-20T20:49:00.997', 'FavoriteCount': '1', 'Id': '23961'}{'Body': "<p>We know that $BPP \\subseteq BQP$ but we have no proof $BPP \\subset BQP$\n(Though we have the proof that BQP $!=$ BPP with an oracle)</p>\n\n<p>Since Simon's problem (as factoring) it's easily solvable by a quantum computer, and in exponential time complexity solvable by a classical computer, that's a hint of the separation between BQP and BPP and therefore this can be a pure NP problem. \nAm I right?</p>\n", 'ViewCount': '26', 'Title': "Is Simon's problem a good NP-intermediate candidate?", 'LastActivityDate': '2014-04-21T14:52:08.960', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '23989', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7955', 'Tags': '<complexity-theory><complexity-classes><quantum-computing>', 'CreationDate': '2014-04-21T12:57:28.700', 'Id': '23985'}{'Body': "<p>Let the following datatype be defined:</p>\n\n<pre><code> data T = A | B T | C T T\n</code></pre>\n\n<p>That is, <code>B, B T, B (B T), C A A, C (B T) A</code> and so on all are members of T. Now, suppose we define two functions that operate on that type:</p>\n\n<pre><code>f :: T -&gt; T\nf A = A\nf (B x) = B (B (f x))\n\ng :: T -&gt; T\ng A = A\ng (B x) = B (B (B (g x)))\n</code></pre>\n\n<p>There are restrictions on the definition of <code>f</code> and <code>g</code>: first, recursive calls can only be applied directly to a subterm of one of the inputs (guaranteeing termination), and second, they can't use any datatype other than T on their bodies (consider T is the only existing type). In this case, we know that the following function:</p>\n\n<pre><code>h :: T -&gt; T\nh A = A\nh (B x) = B (B (B (B (B (B (h x))))))\n</code></pre>\n\n<p>works as the composition <code>f . g</code>. My question is, is it possible/decidable to find the composition of <code>f</code> and <code>g</code> in this form - that is, without any reference to <code>f</code> and <code>g</code> themselves? What is the name of the problem I am trying to solve?</p>\n", 'ViewCount': '48', 'Title': 'Is there a decidable algorithm to compose two well-behaved recursive functions that work on a recursive tree datatype?', 'LastEditorUserId': '16949', 'LastActivityDate': '2014-04-21T19:21:04.403', 'LastEditDate': '2014-04-21T15:45:57.793', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16949', 'Tags': '<algorithms><complexity-theory><computability><programming-languages>', 'CreationDate': '2014-04-21T15:36:19.557', 'Id': '23992'}{'Body': '<p>Consider a Turing Machine $M$ that decides the following language: $$A_{\\text{NFA}} = \\{ \\langle N,w \\rangle  | N\\text{ is an NFA and }N\\text{ accepts }w \\}.$$\nBased on its input size, if $M$ wants to accept a string, it should accept it within a limited number of steps else it would reject it. What is this bound/limit? </p>\n', 'ViewCount': '28', 'ClosedDate': '2014-04-23T16:49:56.880', 'Title': 'Maximum number of configurations on a TM that decides the language $A_\\text{NFA}$', 'LastActivityDate': '2014-04-22T14:01:44.283', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '0', 'OwnerDisplayName': 'user292139', 'PostTypeId': '1', 'OwnerUserId': '14412', 'Tags': '<complexity-theory><turing-machines>', 'CreationDate': '2014-04-22T00:30:56.160', 'Id': '24024'}{'Body': "<p>Is it more plausible that $NP\\subseteq TIME[O(n^{\\log n})]$ than $NP\\subseteq P$? I don't see this mentioned much and is there a reason why? If this question doesn't make sense, explain why.</p>\n", 'ViewCount': '52', 'Title': '$NP\\subseteq TIME[O(n^{\\log n})]$', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-22T22:07:30.020', 'LastEditDate': '2014-04-22T22:07:30.020', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '24034', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '16999', 'Tags': '<complexity-theory><time-complexity><complexity-classes><np>', 'CreationDate': '2014-04-22T20:20:35.647', 'Id': '24033'}{'Body': "<p>Is there any class of NP problems that have one unique solution?\nI'm asking that, because when I was studying cryptography I read about the knapsack and I found very interesting the idea.</p>\n", 'ViewCount': '106', 'Title': 'NP Problems with unique solution', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-23T14:33:23.040', 'LastEditDate': '2014-04-23T14:32:38.843', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '7', 'OwnerDisplayName': 'user3513151', 'PostTypeId': '1', 'OwnerUserId': '17026', 'Tags': '<complexity-theory><decision-problem><np><cryptography>', 'CreationDate': '2014-04-23T01:24:04.347', 'Id': '24043'}{'Body': "<p>Let us consider  where G is an undirected weighted graph G = is an undirected graph. f &lt;=|V| is an integer and d>=0 is a real number. Is it possible to select f vertices of G as token locations, such that the length of the shortest path between any vertex and its nearest tokens is at most d. </p>\n\n<p><strong>token placement belongs to NP:</strong> the certificate is a weighted directed graph, with f token locations and the value d. Given the certificate, we can verify in polynomial time that the path from any vertex to its closest token location is at most d. Given that there are n vertices within the graph, this will take us polynomial time. </p>\n\n<p><strong>Reduction:</strong> I want to select the shortest path between any vertex and its nearest token. Thus reminds me of subset sum \nreduce from subset sum, I have 1 set S and a target value t. \nLet me construct a graph made of one vertex with k edges, k being the number of elements in the set S. the k edges are k self loops on the vertex v.  each element within S is assigned to the weight of one self loops. Reduction takes polynomial time, given that I have n elements in a set S, I have to draw a graph with n self loops. this takes polynomial time. </p>\n\n<p>Proof of correctness:\n1) if subset Sum has a solution, this means that there is a set S' such that the sum of all the elements within S' equal the target value t. Thus, there must be a set of edges within the graph whose sum of weights equals t. Given that the number of elements within the subset S' equals the number of edges whose weights sum up to t. This means, that considering graph G made of e edges, each edge's weight being one element within the set S,this means that there is a set f of edges such that f= the size of S' whose values are at most equal to d, where d equals the target value t. all of the elements within S' correspond to one or more edge weights flowing into the single vertex of the graph. Thus, given the target value t and the set of token locations f. There must be an edge between any vertex and its closest token locations such that it is less than or equal to the target value. f is the number of times the same  node v is visited. </p>\n\n<p>2) If the token problem has a solution, this means that there is a set f of token locations, , number of times v is visited and the edge weight of any edge e in the graph is at most d.  Let us sum up f edge weights within G. Thus, we have a subset of weights whose sum equals to the value d. Since, all of the edges flow into the vertex. Thus, given f token locations, a value d and a graph G, the path from any vertex to its closest token location(which is itself given self loops) is at most d, where d could be the weight of one edge if f=1 or the sum of the weights of many edges if f>1. given f token locations which refer to f edge weights, the sum of all the f edge weights equals the value d. \nThe edges weights of the f edges traversed included in the subset K, their sum is d. The subset K is equivalent to the subset S' in the subset sum problem and the weight d is equivalent to the target value in the subset problem. </p>\n\n<p>Conclusion: token placement has a solution iff subset sum has a solution. </p>\n\n<p>this means that there are f token locations surrounding vertex v, such that the length of any </p>\n", 'ViewCount': '42', 'ClosedDate': '2014-04-25T06:56:07.297', 'Title': "what's wrong with this NP completeness proof", 'LastEditorUserId': '17053', 'LastActivityDate': '2014-04-25T16:01:41.893', 'LastEditDate': '2014-04-25T16:01:41.893', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17053', 'Tags': '<complexity-theory><np-complete><reductions><np>', 'CreationDate': '2014-04-24T23:35:04.413', 'Id': '24091'}{'Body': '<p>So both the 0/1 subset sum problem (find a subset of given numbers that add up to a target sum) and the subset sum problem with "multiplicities" (find non-negative integer coefficients for the set elements so that the linear combination of set elements equals a target sum) are NP-complete. Is there some fairly easy reduction from 0/1 subset-sum to subset sum with multiplicities? This seems perhaps non-trivial, because just because there is a solution with multiplicities doesn\'t mean there is a 0/1 solution.</p>\n\n<p>Some ideas I had that don\'t seem to work: For element $s$, solve the subset sum with multiplicity problem both for total sum $S$ and $S-s$ with element $s$ removed from the set. Then try to argue that $s$ either is or is not included in the 0/1 solution depending on the answer.</p>\n', 'ViewCount': '22', 'Title': 'Is it possible to easily reduce 0/1 subset sum to subset sum with multiplicities?', 'LastEditorUserId': '9584', 'LastActivityDate': '2014-04-26T17:40:13.273', 'LastEditDate': '2014-04-25T21:25:14.210', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '24135', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9584', 'Tags': '<complexity-theory><combinatorics>', 'CreationDate': '2014-04-25T20:29:34.413', 'Id': '24117'}{'Body': "<p>A problem is NP-complete if:</p>\n\n<ol>\n<li>It is in NP.</li>\n<li>All problems in NP can reduce to it.</li>\n</ol>\n\n<p>It's number 2 that I'm concerned with here. I would be highly surprised if we knew  <em>every</em> problem in NP. Based on that assumption, how do we know for sure that any problem is NP-complete? For example, how do we know that there's not some problem we don't know of that will reduce to the Boolean Satisfiability problem, but not the Clique problem? Or would such a problem be NP-Intermediate and therefore need P != NP to exist?</p>\n", 'ViewCount': '416', 'Title': "How do we know any problem is in NP-complete if we don't know all problems in NP?", 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-27T11:34:57.367', 'LastEditDate': '2014-04-27T11:34:57.367', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '4849', 'Tags': '<complexity-theory><np-complete><np>', 'CreationDate': '2014-04-26T21:03:39.997', 'FavoriteCount': '4', 'Id': '24141'}{'Body': '<p>While I was studying SAT problem and its different instances, in Algorithms for the Satisfiability (SAT) Problem: A Survey by J. Gu et. al <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a326042.pdf" rel="nofollow">PDF</a>, I came up with this variant (not mentioned there, but I though of it) and searched, but could not find anything useful.</p>\n\n<p>Consider this variant:</p>\n\n<blockquote>\n  <p>Suppose $f$ is a boolean function in $n$ boolean variables, but with this extra property, that $f$ is increasing. I have thought of $n$ boolean variables, $X_1, \\ldots, x_n$ as representation of subsets of a set with $n$ elements, and if some  subset like $X$ satisfies $f$, then all $Y$ s.t. $X \\subseteq Y$ satisfy $f$, too. <em>What I want is finding the <strong>collection</strong> of all minimal $X$ where $f$ satisfies each of them, but not any $Z$ where $Z \\subsetneq X$?</em></p>\n</blockquote>\n\n<p>Is this problem still hard?</p>\n\n<p>If I consider the $x_1, \\ldots, x_n$ as a number, then increasing property of $f$ helps solving it in polynomial time, just a binary search suffices! So, I made it a little bit harder.</p>\n\n<p>Any help, even offers of search terms is appreciated.</p>\n', 'ViewCount': '48', 'Title': 'How can I identify that a restricted variant of Boolean SAT remains hard or not?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-27T19:21:15.063', 'LastEditDate': '2014-04-27T13:42:27.983', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '24155', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4425', 'Tags': '<complexity-theory><np-hard><satisfiability>', 'CreationDate': '2014-04-27T04:42:23.223', 'Id': '24149'}{'ViewCount': '28', 'Title': 'How does one figure out where a class of languages falls under some complexity class?', 'LastEditDate': '2014-04-30T17:33:52.967', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16742', 'Body': '<p><img src="http://i.imgur.com/fKkk9Aq.png" alt="enter image description here"></p>\n\n<p>I was wondering how can someone prove that one class of languages is of a certain complexity? For example, how could I show the Turing-recognizable languages are in P?</p>\n\n<p>Would I have to come up with an algorithm that runs in deterministic polynomial time?</p>\n', 'ClosedDate': '2014-05-02T12:48:31.513', 'Tags': '<complexity-theory><formal-languages><proof-techniques>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-30T17:33:52.967', 'CommentCount': '1', 'AcceptedAnswerId': '24257', 'CreationDate': '2014-04-30T14:20:55.117', 'Id': '24256'}{'Body': "<p>Is the class $\\sf NP$ closed under complement or is it unknown? I have looked online, but I couldn't find anything. </p>\n", 'ViewCount': '55', 'Title': 'Is the class NP closed under complement?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-30T17:43:47.400', 'LastEditDate': '2014-04-30T17:17:57.027', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '24265', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16742', 'Tags': '<complexity-theory><closure-properties><complexity-classes><np>', 'CreationDate': '2014-04-30T16:23:40.070', 'Id': '24261'}{'Body': "<p>I have tried looking online, but I couldn't find any definitive statements. It would make sense to me that Union and Intersection of two NPC languages would produce a language not necessarily in NPC. Is it also true that NPC languages are not closed under the complement, concatenation, and kleene star operations?</p>\n", 'ViewCount': '78', 'Title': 'are NP Complete languages closed under any regular operations?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-30T22:26:53.000', 'LastEditDate': '2014-04-30T17:19:07.863', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '24271', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '16742', 'Tags': '<complexity-theory><np-complete><closure-properties>', 'CreationDate': '2014-04-30T16:34:39.267', 'Id': '24264'}{'Body': '<p>I understand Partition Problem is NP-complete.</p>\n\n<p>Given we have a magic black box that can answer Yes or No for the partition problem. I was wondering how to come up with a polynomial time algorithm to find the actual set using this black box. </p>\n\n<p>Thank you. </p>\n', 'ViewCount': '12', 'Title': 'How to find partition set of a Partition Problem using its decision problem', 'LastActivityDate': '2014-05-01T00:50:48.473', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24280', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17233', 'Tags': '<complexity-theory><np-complete><partition-problem>', 'CreationDate': '2014-05-01T00:39:31.503', 'Id': '24279'}{'Body': "<p>Problem: Input is an integer number $x$ that we know factors as $p_{i_1}\\cdot p_{i_2}\\ldots p_{i_n}$, where the $p_{i_j}$'s are distinct prime numbers. Output is the above factorization of $x$.</p>\n\n<p>Do you know any results/references for the time complexity of this factoring problem? </p>\n\n<p>Note: If the $p_{i_j}$'s are not assumed distinct, then the problem is just integer factorization. This is a very special case.</p>\n", 'ViewCount': '18', 'Title': 'Complexity of factoring products of distinct prime numbers', 'LastActivityDate': '2014-05-02T20:00:41.800', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6610', 'Tags': '<complexity-theory><reference-request><time-complexity><factoring>', 'CreationDate': '2014-05-02T16:15:36.450', 'Id': '24319'}{'ViewCount': '11', 'Title': 'Is it possible to do reductions with non-decision problems?', 'LastEditDate': '2014-05-02T21:48:04.360', 'AnswerCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16780', 'FavoriteCount': '1', 'Body': "<p>I've recently begun studying reductions in my algorithms class. All the reductions I've seen have been from decision problem $\\to$ decision problem.</p>\n\n<p>Is it possible to do reductions with non-decision problems? \nCan NP-hardness be shown in that way?</p>\n", 'ClosedDate': '2014-05-02T21:57:12.900', 'Tags': '<complexity-theory><reductions><optimization>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-05-02T21:48:04.360', 'CommentCount': '3', 'CreationDate': '2014-05-02T20:58:15.810', 'Id': '24327'}{'Body': '<p>The question is in the title, I suppose. I am studying complexity classes, and I understand that NP-Hard is the set of problems that are at least as hard as the hardest problems in NP. Therefore, it will naturally contain PSPACE problems.</p>\n\n<p>However, I was specifically wondering if there were any PSPACE problems that were not in NP-Hard? (from my understanding, implying that they are <em>easier</em> than the hardest problems in NP).</p>\n', 'ViewCount': '67', 'Title': "Are there any PSPACE problems that don't exist in NP-Hard?", 'LastEditorUserId': '98', 'LastActivityDate': '2014-05-03T09:36:05.037', 'LastEditDate': '2014-05-03T09:36:05.037', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24338', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17290', 'Tags': '<complexity-theory><np-hard><complexity-classes>', 'CreationDate': '2014-05-03T02:37:37.397', 'Id': '24336'}{'Body': '<p>This <a href="http://en.wikipedia.org/wiki/Max-flow_min-cut_theorem#Example" rel="nofollow">Wikipedia</a> example is very confusing. Its saying the max flow = min cut. But I see the max flow = 9 and the min cut = 7. If not, how does the capacity =min cut here? Which is the max flow min cut theorem. </p>\n\n<p><img src="http://i.stack.imgur.com/HOUJi.png" alt="http://en.wikipedia.org/wiki/Max-flow_min-cut_theorem#Example"></p>\n\n<p>Thanks in advance</p>\n', 'ViewCount': '14', 'Title': 'Max-Flow, minimum cut', 'LastActivityDate': '2014-05-03T08:17:56.363', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7173', 'Tags': '<algorithms><complexity-theory>', 'CreationDate': '2014-05-03T08:15:38.933', 'Id': '24346'}