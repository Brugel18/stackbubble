{'Body': '<p>A source provides a stream of items $x_1, x_2,\\dots$ . At each step $n$ we want to save a random sample $S_n \\subseteq \\{ (x_i, i)|1 \\le i \\le n\\}$ of size $k$, i.e. $S_n$ should be a uniformly chosen sample from all $\\tbinom{n}{k}$ possible samples consisting of seen items. So at each step $n \\ge k$ we must decide whether to add the next item to $S$ or not. If so we must also decide which of the current items to remove from $S$ .</p>\n\n<p>State an algorithm for the problem. Prove its correctness.</p>\n', 'ViewCount': '158', 'Title': 'Online generation of uniform samples', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-03T01:02:26.967', 'LastEditDate': '2012-05-19T15:31:20.837', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '1931', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1393', 'Tags': '<algorithms><probability-theory><randomized-algorithms><randomness><online-algorithms>', 'CreationDate': '2012-05-19T14:38:52.510', 'Id': '1923''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I need to recover a data block from a repeated stream of data. I'm looking to see what algorithms may already exist for this as it does not feel like a novel situation.</p>\n\n<p>Here are the specifics:</p>\n\n<ol>\n<li>There is an N-length block of data contained in a stream</li>\n<li>The block is repeated many times in the stream</li>\n<li>the data is highly corrupted, some bytes could just be wrong, where as others can be detected as missing (erasures)</li>\n<li>There is a function <code>F(data)</code> which can say if a block represents valid data (the probability of a false positive is virtually zero)</li>\n<li><code>F</code> can also provide a probability value that even if the block is not valid data whether the block itself is valid (but just has too much corruption to be recovered)</li>\n<li>The chance of corrupted data is very low compared to missing data</li>\n</ol>\n\n<p>For example, say I have this data stream and wish to recover the 10 length sequence <code>1234567890</code>. The data is just a rough visual example (I can't guarantee recovery is actually possible from this bit). A <code>.</code> represents a missing byte, and <code>&lt;break&gt;</code> indicates an unknown block of data (no data  and not length known). Note also the <code>Q</code>s as an example of corrupt data.</p>\n\n<p><code>23.5678901.3456789&lt;break&gt;2345678..1..4567QQ012345678..3456</code></p>\n\n<p>How can I take such a stream of data and recovery probably blocks of N data? As the actual data includes forward error recovery the block recovery need not be perfect. All it needs to do is give probable reconstructed blocks of data and the <code>F</code> function will attempt to do error recovery.  Thus I expect <code>F</code> fill have to be called several times. </p>\n\n<p>I'd like to find something better than simply calling <code>F</code> at each point in the stream since the error rate could be high enough that no single run block of N can be recovered -- the repetitions in the stream must be used somehow.</p>\n", 'ViewCount': '41', 'Title': 'Block detection in repeated stream', 'LastEditorUserId': '1642', 'LastActivityDate': '2012-05-25T11:53:58.550', 'LastEditDate': '2012-05-25T11:53:58.550', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2072', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1642', 'Tags': '<algorithms><online-algorithms><communication-protocols>', 'CreationDate': '2012-05-25T04:33:48.567', 'Id': '2064''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '597', 'Title': 'Determine missing number in data stream', 'LastEditDate': '2012-05-26T03:55:57.317', 'AnswerCount': '3', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '1402', 'FavoriteCount': '2', 'Body': '<p>We receive a stream of $n-1$ pairwise different numbers from the set $\\left\\{1,\\dots,n\\right\\}$.</p>\n\n<p>How can I determine the missing number with an algorithm that reads the stream once and uses a memory of only $O(\\log_2 n)$ bits?</p>\n', 'Tags': '<algorithms><integers><online-algorithms>', 'LastEditorUserId': '157', 'LastActivityDate': '2012-05-28T17:15:07.057', 'CommentCount': '4', 'AcceptedAnswerId': '2090', 'CreationDate': '2012-05-25T17:40:04.097', 'Id': '2079''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I want to implement efficiently "streaming Knapsack" problem in java.</p>\n\n<p>The problem is I have a stream input of integer data coming continuously for example -1, 2, 9, 5, 5, 11, 1 -3,...</p>\n\n<p>The question is to find the first "k" elements in which their sum is "n>0". for example k=3 and n=12, \nthen the solution is: ...,2,...,5, 5.</p>\n\n<p>I found an answer in <a href="http://programmingpraxis.com/2012/05/15/streaming-knapsack/2/" rel="nofollow">http://programmingpraxis.com/2012/05/15/streaming-knapsack/2/</a> \nas: (It is mainly for positive Integer Values)</p>\n\n<p>But looking for simpler one! Any Ideas?</p>\n', 'ViewCount': '200', 'Title': 'Streaming Knapsack Problem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-07T11:30:04.040', 'LastEditDate': '2013-01-26T17:50:18.787', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6550', 'Tags': '<algorithms><optimization><streaming-algorithm><online-algorithms>', 'CreationDate': '2013-01-25T18:37:58.193', 'FavoriteCount': '1', 'Id': '9155''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '251', 'Title': 'Computing inverse matrix when an element changes', 'LastEditDate': '2013-02-18T03:19:37.600', 'AnswerCount': '2', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '867', 'FavoriteCount': '1', 'Body': "<p>Given an $n \\times n$ matrix $\\mathbf{A}$. Let the inverse matrix of $\\mathbf{A}$ be $\\mathbf{A}^{-1}$ (that is, $\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}$). Assume that one element in $\\mathbf{A}$ is changed (let's say $a _{ij}$ to $a' _{ij}$). The objective is to find $\\mathbf{A}^{-1}$ after this change. Is there a method to find this objective that is more efficient than re-calculating the inverse matrix from scratch. </p>\n", 'Tags': '<algorithms><numerical-analysis><online-algorithms>', 'LastEditorUserId': '683', 'LastActivityDate': '2013-02-18T14:24:30.640', 'CommentCount': '3', 'AcceptedAnswerId': '9881', 'CreationDate': '2013-02-18T01:04:51.930', 'Id': '9875''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '271', 'Title': 'Weighted sum of last N numbers', 'LastEditDate': '2013-03-21T03:56:56.377', 'AnswerCount': '1', 'Score': '16', 'PostTypeId': '1', 'OwnerUserId': '4213', 'FavoriteCount': '2', 'Body': u"<p>Suppose we're receiving numbers in a stream. After each number is received, a weighted sum of the last $N$ numbers needs to be calculated, where the weights are always the same, but arbitrary. </p>\n\n<p>How efficiently can this done if we are allowed to keep a data structure to help with the computation? Can we do any better than $\\Theta(N)$, i.e. recomputing the sum each time a number is received?</p>\n\n<p>For example:\nSuppose the weights are $W= \\langle w_1, w_2, w_3, w_4\\rangle$. At one point we have the list of last $N$ numbers $L_1= \\langle a, b, c, d \\rangle&gt;$, and the weighted sum $S_1=w_1*a+w_2*b+w_3*c+w_4*d$. </p>\n\n<p>When another number, $e$, is received, we update the list to get $L_2= \\langle b,c,d,e\\rangle$ and we need to compute $S_2=w_1*b+w_2*c+w_3*d+w_4*e$.</p>\n\n<p><strong>Consideration using FFT</strong>\nA special case of this problem appears to be solvable efficiently by employing the Fast Fourier Transform. Here, we compute the weighed sums $S$ in multiples of $N$. In other words, we receive $N$ numbers and only then can we compute the corresponding $N$ weighed sums. To do this, we need $N-1$ past numbers (for which sums have already been computed), and $N$ new numbers, in total $2N-1$ numbers. </p>\n\n<p>If this vector of input numbers and the weight vector $W$ define the coefficients of the polynomials $P(x)$ and $Q(x)$, with coefficients in $Q$ reversed, we see that the product $P(x)\\times Q(x)$ is a polynomial whose coefficients in front of $x^{N-1}$ up to $x^{2N-2}$ are exactly the weighted sums we seek. These can be computed using FFT in $\\Theta(N*\\log (N))$ time, which gives us an average of $\u0398(\\log (N))$ time per input number.</p>\n\n<p>This is however not a solution the the problem as stated, because it is required that the weighted sum is computed efficiently <em>each</em> time a new number is received - we cannot delay the computation.</p>\n", 'Tags': '<algorithms><data-structures><online-algorithms>', 'LastEditorUserId': '683', 'LastActivityDate': '2013-03-21T18:20:56.223', 'CommentCount': '4', 'AcceptedAnswerId': '10670', 'CreationDate': '2013-03-19T05:24:49.463', 'Id': '10612''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>The usual statement of the <a href="http://en.wikipedia.org/wiki/Fair_division" rel="nofollow">fair cake-cutting problem</a> assumes that all $n$ players get their share at the same time. However, in many cases the players arrive incrementally. For example, we may divide a cake over $n$ players, but then a new player arrives and wants a share.</p>\n\n<p>Usually, fair cake division requires a lot of effort (for example, requires the players to answer many queries), especially when the number of players is large.</p>\n\n<p>Is it possible to use the existing division of the cake over $n$ players, in order to create a new division of the cake to $n+1$ players, with minimal additional effort (i.e. substantially less effort than re-distributing the cake from scratch)?</p>\n', 'ViewCount': '204', 'Title': 'Fair cake-cutting when players join late', 'LastEditorUserId': '1342', 'LastActivityDate': '2014-01-19T02:03:22.010', 'LastEditDate': '2013-04-12T11:28:27.013', 'AnswerCount': '2', 'CommentCount': '7', 'AcceptedAnswerId': '11204', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<algorithms><game-theory><online-algorithms>', 'CreationDate': '2013-04-06T18:40:39.860', 'Id': '11077''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I get values $x_t$ in an online fashion and want to buy "good" ones, where "good" means that some measure $P(x_t) &gt;T$. Consider the following simple algorithm.</p>\n\n<pre><code>T = 0.7\nN = 100 // or any value N &gt; B\nB = 20 // or any value 1 &lt; B &lt; N\n\nl = 0\n\nfor t from 1 to N:\n    input a new observation x_t\n    let P(x_t) the probability associated to x_t\n\n    if P(x_t) &gt; T:\n        l = l + 1\n        pay 1 dollar to buy y_t the label of x_t\n        output immediately the label y_t\n</code></pre>\n\n<p>If the condition $P(x_t) &gt; T$ is used then we get about $l = 100-70 = 30$, this is ok since the value of $T$ is set to $0.7$.</p>\n\n<p>Now if I want to add a constraint which is: additionally to the fact that elements $x_t$ for which the label $y_t$ is purchased are those for which $P(x_t) &gt; T$, I want also that we do not buy more than $B=20$ labels (for example because we only have 20 dollars as budget).</p>\n\n<p>But the problem is that, if I replace the the condition ($P(x_t) &gt; T$) by ($P(x_t) &gt; T \\wedge l &lt; B$), then the elements $x_t$ for which we buy a label are more likely to be among the first elements $t$ that we browse (that is, for an element $x_{95}$ for $t = 95$ for example we will never have a chance to buy its label even if its probability was $P(x_{95}) \\gg T$). But I want that all the elements from $t = 1$ to $N$ will have equal chance to buy their label (not advantaging only the first elements).</p>\n\n<p>Note: the condition that $P(x_t) &gt; T$ for buying the label of a new observation $x_t$, should not be removed from my code. This is important for me: only labels of observations for which $P(x_t)$ was higher than $T$ at time $t$, are possibly purchased; and we should not purchase more than our budget $B$. Note also that a purchased label should immediately be output after we buy it, we should not wait until the end to decide if we buy it or not.</p>\n\n<p>Also, note that we do not have the N elements beforehand; at each time $t$ we see just one new observation $x_t$. And note that you pay 1 dollar when you select a given $x_t$ to ask for its label and that you should output answer (label of selected $x_t$) immediately; so you can not select some $B$ elements then replace them with new selected other elements, because your budget $B$ will already be finished.</p>\n', 'ViewCount': '64', 'Title': 'How to sample uniformly from a stream of elements, some of which are unsuited?', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-04-18T19:57:32.787', 'LastEditDate': '2013-04-18T17:53:54.317', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2895', 'Tags': '<probabilistic-algorithms><online-algorithms><sampling>', 'CreationDate': '2013-04-17T22:07:38.767', 'Id': '11370''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I have recently learned about various randomized algorithms for load balancing. The model is always that there are $m$ balls and $n$ bins and the balls arrive one at a time. The task is to minimize the maximum load of any bin.  However there is something I don't understand.</p>\n\n<p>Why not just keep a priority queue of the loads of the bins and allocate any new ball to the bin with the lowest current load?  This seems to give you the optimal load without any complications.</p>\n", 'ViewCount': '227', 'Title': 'Load balancing. Why not use priority queues?', 'LastActivityDate': '2013-05-20T20:16:53.273', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '12169', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8271', 'Tags': '<priority-queues><online-algorithms>', 'CreationDate': '2013-05-20T19:39:14.903', 'Id': '12165''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I would like to build an online web-based machine learning system, where users can continuously add classified samples, and have the model updated online. I would like to use a perceptron or a similar online-learning algorithm. </p>\n\n<p>But, users may make mistakes and insert irrelevant examples. In that case, I would like to have the option to delete a specific example, without re-training the perceptron on the entire set of examples (which may be very large).</p>\n\n<p>Is this possible?</p>\n', 'ViewCount': '143', 'Title': 'Can a perceptron forget?', 'LastActivityDate': '2013-05-31T03:11:27.920', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '12389', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<machine-learning><online-algorithms>', 'CreationDate': '2013-05-27T11:12:29.320', 'FavoriteCount': '2', 'Id': '12306''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Let <code>S</code> be a system whose state can be altered by performing actions. Each action has two possible outcomes, and each outcome brings to a specific system state. A state is never visited two times, i.e., the state graph is a DAG (a tree, more specifically, where the root corresponds to the initial system state and each edge corresponds to an action). The probability of obtaining either one of the outcomes is known.</p>\n\n<p>Notice that just <code>B</code> actions can be performed, and the pool of actions contains <code>N</code> different actions.</p>\n\n<p>My objective is to devise an <strong>online optimal</strong> algorithm which identifies the best path to be taken, i.e., the path which guarantees the minimum cost. With the term "online" I am referencing to the following behavior:</p>\n\n<ol>\n<li>An action is chosen</li>\n<li>The system state is consequently modified</li>\n<li>A new action is chosen (taking into account the system state modification performed ad 2.)</li>\n<li>The system state is again modified according to the selected action</li>\n<li>...</li>\n</ol>\n\n<p>My first idea was the one of using A* in the following way:</p>\n\n<ol>\n<li>I ask A* to find the best sequence <code>S</code> of <code>B</code> actions to be performed</li>\n<li>I perform just the first action contained in <code>S</code>, and I modify the system state consequently (according to the outcome of the action)</li>\n<li>I ask A* to find the best sequence <code>S\'</code> of <code>(B-1)</code> actions to be performed</li>\n<li>I perform just the first action contained in <code>S\'</code> and I modify the system state consequently</li>\n</ol>\n\n<p>The problem is that I don\'t know whether this solution is optimal (I didn\'t succeed in finding an optimality proof), and an optimal solution would be required in my case.</p>\n\n<p>May you suggest another online algorithm (or, alternatively, a way of proving the optimality of the method I propose) to find an optimal solution for the problem?</p>\n\n<p><strong>EDIT</strong>: maybe something from game theory can be used instead (<a href="http://en.wikipedia.org/wiki/Extensive-form_game#Imperfect_information" rel="nofollow">extensive form games with imperfect information</a>). I am the player I that chooses the actions, while the player II is a dummy player that chooses the action "first-outcome" or "second-outcome", where "first-outcome" and "second-outcome" are my actions\' possible outcomes.</p>\n\n<p><strong>NOTE:</strong> I posted a similar question <a href="http://stackoverflow.com/questions/17149113/gain-maximization-on-trees">here</a>, although in my previous question an <em>offline</em> version was required, i.e., the modifications of the actions were not taken into account at each iteration.</p>\n\n<p>Thanks in advance.</p>\n', 'ViewCount': '51', 'Title': 'Online algorithm for planning', 'LastEditorUserId': '8798', 'LastActivityDate': '2013-06-24T07:28:52.660', 'LastEditDate': '2013-06-24T07:28:52.660', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8798', 'Tags': '<decision-problem><game-theory><online-algorithms>', 'CreationDate': '2013-06-21T09:52:04.120', 'FavoriteCount': '2', 'Id': '12810''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u'<p>I\'m trying to find an algorithm for a motion planning problem. I have $N$ points, $P_1$ to $P_N$, in $k$-dimensional cartesian space, defining $N-1$ segments. The problem is about constructing the fastest motion plan, that is, a function $p(t)$, <em>approximating</em> the path along the segments, bound by some constraints:</p>\n\n<ul>\n<li><p>For each segment defined by the points $P_i$ and $P_{i+1}$, let $M_i$ be some point on this segment ($M_i$ is part of the solution, not the input). For now, let\'s assume it\'s strictly within the segment. Now, the constraint is that our sought plan $p(t)$ starts with an initial segment from $P_1$ to $M_1$, is followed by $N-2$ second-order B\xe9zier curves, each defined by the control points $(M_i, P_{i+1}, M_{i+1})$, and finally followed by a segment from $M_{n-1}$ to $P_n$.</p></li>\n<li><p>Velocity is preserved on boundaries between the curves and the start/end segments. Note that the <em>direction</em> of velocity is implicitly preserved by the above constraint. (because the vector from $P_i$ to $M_i$ is parallel to the one from $M_i$ to $P_{i+1}$)</p></li>\n<li><p>Along each of the B\xe9zier curves, as well as on the initial and final segment, the acceleration of the plan $p(t)$ is constant. This means that, if the plan specifies that we arrive to $M_i$ at time $T_i$, and it takes $t_i$ time to traverse the curve that begins there, this part of the motion plan is equal to $p(t)=B_i((t-T_i)/t_i)$, where $B_i$ is standard B\xe9zier formula for this curve. Informally, we cannot manually accelerate along the B\xe9zier curves, all we can do is scale the speed/acceleration across an entire curve.</p></li>\n<li><p>The absolute value of acceleration along each dimension $d$ must be no more than $A_d$. The maximum velocity limit may also be defined for each dimension, and I\'m not sure whether or not that would make the problem significantly harder.</p></li>\n<li><p>The initial and final velocity is zero (or possibly a constant).</p></li>\n</ul>\n\n<p>Here\'s a picture of such a path composed of B\xe9zier curves.<img src="http://i.stack.imgur.com/uSjZr.jpg" alt="enter image description here"></p>\n\n<p>Notice that the shape of the path is defined by $N-1$ real numbers $m_i \\in(0, 1)$, which define the position of the points $M_i$ as a convex combination of $P_i$ and $P_{i+1}$. The difficulty of this problem is in determining these numbers. The constraints imply that, given $m_i$, the velocities on every point of the plan are determined up to a common factor. Therefore, knowing $m_i$ of the optimal solution, it is not hard to finish the plan by finding the smallest total plan time which does not violate the acceleration constraints on any of the individual components of the plan.</p>\n\n<p>Ideally, the algorithm would work incrementally - given an optimal solution for the first $n$ points, and the next point, it would fix this solution into an optimal plan for the first $n+1$ points.</p>\n\n<p><strong>Some initial work</strong></p>\n\n<p>Let\'s define $D_i=P_{i+1}-P_i$. Also define $V_i$ to be the velocity of the plan at point $M_i$. But since $V_i$ is parallel to $D_i$, we write $V_i=v_i D_i$, for some $v_i \\in \\mathbb{R}$. Let\'s call $v_i$ the <em>relative speeds</em>.</p>\n\n<p>We will now use some knowledge about B\xe9zier curves to express a relationship between the relative velocities on the ends of a single curve, resulting in an equation involving $v_i$ and $v_{i+1}$. Let\'s forget about our points for a moment and assume we have a quadratic B\xe9zier curve with the control points $(A, B, C)$. If we start with the standard formula for B\xe9zier curves, and factor by $t$, we arrive at:</p>\n\n<p>$$ B(t) = A + 2(B-A)t + (A-2B+C)t^2 $$</p>\n\n<p>The parameter in this curve is $t \\in [0, 1]$, and it is easy to see that $B(0)=A$ and $B(1)=C$. We can also take the derivative of this function and compute it at the ends of the curve:</p>\n\n<p>$$ B\'(0) = 2(B-A) $$\n$$ B\'(1) = 2(C-B) $$</p>\n\n<p>Now return to the problem of finding a relationship between $v_i$ and $v_{i+1}$. The above formula tells us how to compute the velocities at the start and end of a quadratic B\xe9zier curve, however we have to take into account that the B\xe9zier curves in our plan are scaled proportionally in time. So, assume the plan takes $t_i$ time to traverse the i-th B\xe9zier curve. Then, the initial and final velocities along this curve are given by:</p>\n\n<p>$$ V_i = \\frac{2(1-m_i)D_i}{t_i} $$\n$$ V_{i+1} = \\frac{2m_{i+1}D_{i+1}}{t_i} $$</p>\n\n<p>since $(1-m_i)D_i$ corresponds to $B-A$ above, and $m_{i+1}D_{i+1}$ corresponds to $C-B$. Then we substitute $V_i=v_i D_i$ and $V_{i+1}=v_{i+1} D_{i+1}$, which turns the vector equations into real equations. Eradicating $t_i$ gives the following:</p>\n\n<p>$$ v_{i+1} = \\frac{m_{i+1}}{1-m_i}v_i $$</p>\n\n<p>This equation captures many of the constraints of the problem, in terms of real numbers $m_i$ (the relative positions of the splice points) and $v_i$ (the relative velocities at the splice points).\nIn fact, given all $m_i$, this effectively defines the ratios between all $v_i$. Therefore, if after choosing $m_i$ we also choose a value for $v_1$, the plan is completely defined.</p>\n\n<p>Though I don\'t know yet how this helps with finding the optimal $m_i$, taking into account the other constraints (maximum acceleration, starting and ending velocity). While the last equation looks nice, its non-linearity in terms of $m_i$ is not encouraging.</p>\n', 'ViewCount': '156', 'Title': u'Motion planning using second order B\xe9zier curves', 'LastEditorUserId': '4213', 'LastActivityDate': '2013-08-08T01:04:59.303', 'LastEditDate': '2013-08-08T01:04:59.303', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4213', 'Tags': '<optimization><computational-geometry><online-algorithms>', 'CreationDate': '2013-08-07T19:41:56.430', 'Id': '13667''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<hr>\n\n<p>Is there an incremental directed graph data structure that has the following properties:</p>\n\n<ul>\n<li>Keeps an internal graph structure as a DAG, and the graph is accessible (notwithstanding other helper data-structures)</li>\n<li>The accessible DAG is kept as a transitive reduction (notwithstanding other helper data-structures)</li>\n<li>It should be optimized for a sparse graph (adjacency lists)</li>\n<li>It should condense cycles as they are introduced, keeps a mapping between equivalent vertices that are all replaced with one "representative" vertex</li>\n<li>Ability to quickly answer quickly ancestor/descendant/transitive/relationship queries (in $\\mathcal{O}(1)$ or $\\sim\\mathcal{O}\\left(\\log \\left|V\\right|\\right)$ time)</li>\n<li>Should support vertex, edge insertion, deletion would be nice too</li>\n<li>Mutable operations  (such as insertion) should be as output-sensitive as possible; in other words, the complexity should depend as much as possible on how much the operation must change the graph</li>\n<li>Ability to record changes over an operation, if requested. Obviously this might necessarily increase the complexity, but the increase should be output-sensitive. Examples:\n<ul>\n<li>set of deleted vertices (due to condensation)</li>\n<li>set of deleted edges (due to reduction)</li>\n<li>set of new decendent relationships from $u$ ( example: $insert(G,u,v) \\rightarrow \\left\\{t ~|~ path(u,t)\\in G\'\\wedge path(u,t)\\not\\in G\\right\\}$ )</li>\n<li>set of new ancestor relationships from $v$ ( example: $insert(G,u,v) \\rightarrow \\left\\{t ~|~ path(t,v)\\in G\'\\wedge path(t,v)\\not\\in G\\right\\}$ )</li>\n</ul></li>\n</ul>\n\n<p>The closest I can find is <a href="http://code-o-matic.blogspot.com/2010/07/graph-reachability-transitive-closures.html" rel="nofollow">here</a>, <a href="http://code.google.com/p/transitivity-utils" rel="nofollow">implementation</a>. I think you can build on this to do have most of the properties I list, but I am wondering if there is anything better/well known, or perhaps if there is a name for this problem.</p>\n\n<hr>\n\n<p><strong>EDIT:</strong></p>\n\n<h3>Related:</h3>\n\n<ul>\n<li><a href="http://cstheory.stackexchange.com/q/14343/3377">What is the fastest deterministic algorithm for dynamic digraph reachability with no edge deletion?</a></li>\n<li><a href="http://cstheory.stackexchange.com/q/18787/3377">What is the fastest deterministic algorithm for incremental DAG reachability?</a></li>\n<li><a href="http://cstheory.stackexchange.com/q/5176/3377">Does an algorithm exist to efficiently maintain connectedness information for a DAG in presence of inserts/deletes?</a></li>\n<li><a href="http://cstheory.stackexchange.com/q/2548/3377">Is there an online-algorithm to keep track of components in a changing undirected graph?</a></li>\n<li><a href="http://cstheory.stackexchange.com/q/17135/3377">Dynamic shortest path data structure for DAG</a></li>\n</ul>\n', 'ViewCount': '150', 'Title': 'An incrementally-condensed transitive-reduction of a DAG, with efficient reachability queries', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-10-04T05:16:35.877', 'LastEditDate': '2013-10-04T04:51:04.030', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2755', 'Tags': '<algorithms><data-structures><graphs><shortest-path><online-algorithms>', 'CreationDate': '2013-10-03T21:12:35.287', 'FavoriteCount': '1', 'Id': '14798''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}