{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '90', 'Title': 'Hardness of Approximating 0-1 Integer Programs', 'LastEditDate': '2013-02-18T05:51:25.817', 'AnswerCount': '1', 'Score': '8', 'OwnerDisplayName': 'Jonas Anderson', 'PostTypeId': '1', 'OwnerUserId': '1439', 'Body': '<p>Given a $0,1$ (binary) integer program of the form:\n$$\n\\begin{array}{lll}\n\\text{min} &amp; f(x) &amp; \\\\\n\\text{s.t.} &amp;A\\vec{x} = \\vec{b} &amp; \\quad \\forall i\\\\\n &amp;x_i\\ge 0 &amp; \\quad \\forall i\\\\\n&amp;x_i \\in \\{0,1\\} &amp; \\quad \\forall i\n\\end{array}\n$$</p>\n\n<p>Note: the size of $A$ is not fixed in either dimension.</p>\n\n<p>I believe this problem has been shown to be hard to approximate (strongly ${\\sf NP}$-Complete) <a href="http://dl.acm.org/citation.cfm?id=322090">Garey &amp; Johnson</a>. </p>\n\n<p>If so, is this still the case when $A$, $\\vec{b}$ have binary entries and $f(x)$ is a linear function ( $f(x) = \\sum_i c_i x_i$ )?</p>\n', 'Tags': '<complexity-theory><np-complete><approximation><integer-programming>', 'LastEditorUserId': '683', 'LastActivityDate': '2013-02-18T05:51:25.817', 'CommentCount': '2', 'AcceptedAnswerId': '9887', 'CreationDate': '2013-02-14T01:13:24.667', 'Id': '9810'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '29', 'Title': 'Why are optimization problems always NP-hard and not NP-complete and what does this mean for other levels of the polynomial time hierarchy?', 'LastEditDate': '2013-04-03T20:22:50.270', 'AnswerCount': '0', 'Score': '2', 'OwnerDisplayName': 'user2145167', 'PostTypeId': '1', 'OwnerUserId': '7309', 'Body': '<p>I have read that optimization problems cannot be $\\mathcal{NP}$-complete, but are always classified as $\\mathcal{NP}$-hard. When a problem is NP-complete, I know it is contained in $\\mathcal{NP}$P. This implies in particular that it is not hard for the second level of the polynomial time hierarchy, e.g. for $\\Sigma_2^P$ or $\\Pi_2^P$. But since optimization problems are only NP-hard, I have no such knowledge. Or are optimization problems usually also $\\Sigma_2^P$-hard or $\\Pi_2^P$-hard, or just some of them?</p>\n\n<p>Are there any interesting problems from combinatorial optimization that are harder than $\\mathcal{NP}$-hard, e.g. hard for the second level of the polynomial time hierarchy?</p>\n\n<p>I am in particular interested in problems from combinatorial optimization, e.g. BP (bin packing), TSP and CVRP (capacitated vehicle routing problem). They are all classified as $\\mathcal{NP}$-hard, but CVRP is a generalization of both TSP and BP, so it should be harder? Bin packing should be easier, are there any results showing this?\nDoes anyone know, if there are hardness results for any of these problems that imply more difficult than $\\mathcal{NP}$-hard?</p>\n\n<p>I know there are many versions of CVRP and TSP and unfortunately I know not a lot about them.</p>\n', 'ClosedDate': '2013-04-05T08:15:21.540', 'Tags': '<complexity-theory><terminology><optimization><integer-programming>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-03T20:22:50.270', 'CommentCount': '3', 'CreationDate': '2013-03-21T09:30:40.023', 'Id': '11001'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>As I understand, the <a href="http://en.wikipedia.org/wiki/Assignment_problem" rel="nofollow">assignment problem</a> is in P as the Hungarian algorithm can solve it in polynomial time - O(n<sup>3</sup>). I also understand that the assignment problem is an <a href="http://en.wikipedia.org/wiki/Integer_programming" rel="nofollow">integer linear programming</a> problem, but the Wikipedia page states that this is NP-Hard. To me, this implies the assignment problem is in NP-Hard.</p>\n\n<p>But surely the assignment problem can\'t be in both P and NP-Hard, otherwise P would equal NP? Does the Wikipedia page simply mean that the general algorithm for solving all ILP problems is NP-Hard? A few other sources state that ILP is NP-Hard so this is really confusing my understanding of complexity classes in general.</p>\n', 'ViewCount': '1180', 'Title': 'Are all Integer Linear Programming problems NP-Hard?', 'LastActivityDate': '2013-07-22T11:05:12.550', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '11476', 'Score': '2', 'OwnerDisplayName': 'Matt', 'PostTypeId': '1', 'OwnerUserId': '1554', 'Tags': '<complexity-theory><complexity-classes><linear-programming><integer-programming>', 'CreationDate': '2013-04-21T19:27:20.410', 'Id': '11475'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There are $n$ bins and $m$ type of balls.\nThe $i$th bin has labels $a_{i,j}$ for $1\\leq j\\leq m$, it is the expected number of balls of type $j$.</p>\n\n<p>You start with $b_j$ balls of type $j$. Each ball of type $j$ has weight $w_j$, and want to put the balls into the bins such that bin $i$ has weight $c_i$. A distribution of balls such that previous condition holds is called a feasible solution.</p>\n\n<p>Consider a feasible solution with $x_{i,j}$ balls of type $j$ in bin $i$, then the cost is $\\sum_{i=1}^n \\sum_{j=1}^m |a_{i,j}-x_{i,j}|$. We want to find a minimum cost feasible solution.</p>\n\n<p>This problem is clearly NP-hard if there is no restriction on $\\{w_j\\}$. The subset sum problem reduces to the existence of a feasible solution. </p>\n\n<p>However, if we add the condition that $w_j$ divides $w_{j+1}$ for every $j$, then the subset sum reduction no longer works, so it\'s not clear whether the resulting problem remains NP-hard. Checking for the existence of a feasible solution takes only $O(nm)$ time(attached at the end of the question), but this does not give us the minimum-cost feasible solution. </p>\n\n<p>The problem has a equivalent integer program formulation:\nGiven $a_{i,j},c_i,b_j,w_j$ for $1\\leq i\\leq n,1\\leq j\\leq m$. \n\\begin{align*}\n\\text{Minimize:} &amp; \\sum_{i=1}^n \\sum_{j=1}^m |a_{i,j}-x_{i,j}| \\\\\n\\text{subject to:} &amp; \\sum_{j=1}^m x_{i,j}w_j = c_i \\text{ for all } 1\\leq i\\leq n\\\\\n&amp; \\sum_{i=1}^n x_{i,j} \\leq b_j \\text{ for all } 1\\leq j \\leq m\\\\\n&amp; x_{i,j}\\geq 0 \\text{ for all } 1 \\leq i\\leq n, 1\\leq j \\leq m\\\\\n\\end{align*}</p>\n\n<p>My question is, </p>\n\n<blockquote>\n  <p>Is the above integer program NP-hard when $w_j$ divides $w_{j+1}$ for all\n  $j$?</p>\n</blockquote>\n\n<p>It\'s not obvious how to solve this even when $n=1$ and $w_j=2^j$, namely\n\\begin{align*}\n\\text{Minimize:} &amp; \\sum_{j=1}^m |a_j-x_j| \\\\\n\\text{subject to:} &amp; \\sum_{j=1}^m 2^j x_j = c\\\\\n&amp; 0 \\leq x_j \\leq b_j \\text{ for all } 1\\leq j \\leq m\\\\\n\\end{align*}</p>\n\n<p><strong>An algorithm to decide if there is a feasible solution in $O(nm)$ time</strong>:</p>\n\n<p>Define $w_{m+1}=w_m(\\max_{j} c_j + 1)$ and $d_j = w_{j+1}/w_j$. Let $a\\%b$ be the remained of $a$ divides $b$.</p>\n\n<ol>\n<li>If there exist a $c_i$ that\'s not divisible by $w_1$, return "no feasible solution". (the invariant $c_i$ divides $w_j$ will always be maintained in the following loop)</li>\n<li><p>for $j$ from $1$ to $m$:</p>\n\n<ol>\n<li>$k \\gets \\sum_{i=1}^n (c_i/w_j)\\%d_j$. (the minimum of balls of weight $w_j$ required)</li>\n<li>If $b_j&lt;k$, return "no feasible solution".</li>\n<li>$c_i \\gets c_i - ((c_i/w_j)\\% d_j)$ for all $i$. (remove the minimum number of required balls of weight $w_j$)</li>\n<li>$b_{j+1} \\gets \\lfloor (b_j-k)/d_j \\rfloor$. (group smaller balls into a larger ball)</li>\n</ol></li>\n<li>return "there is a feasible solution".</li>\n</ol>\n', 'ViewCount': '578', 'Title': 'Is it NP-hard to fill up bins with minimum moves?', 'LastEditorUserId': '220', 'LastActivityDate': '2014-04-17T20:15:43.023', 'LastEditDate': '2014-04-17T20:15:43.023', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<complexity-theory><np-hard><integer-programming>', 'CreationDate': '2013-06-03T08:38:00.137', 'FavoriteCount': '3', 'Id': '12441'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>So, as is known, ILP's 0-1 decision problem is NP-complete. Showing it's in NP is easy, and the original reduction was from SAT; since then, many other NP-Complete problems have been shown to have ILP formulations (which function as reductions from those problems to ILP), because ILP is very usefully general.</p>\n\n<p>Reductions <strong>from</strong> ILP seem much harder to either do myself or track down.</p>\n\n<p>Thus, my question is, does anyone know a poly-time reduction from ILP to SAT, that is, demonstrating how to solve any 0-1 ILP decision problem using SAT?</p>\n", 'ViewCount': '278', 'Title': 'Poly-time reduction from ILP to SAT?', 'LastActivityDate': '2013-10-15T04:46:34.827', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '16090', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '10743', 'Tags': '<np-complete><satisfiability><integer-programming>', 'CreationDate': '2013-10-14T21:26:54.377', 'FavoriteCount': '2', 'Id': '16088'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given integers $n,m$, I want to find a $m \\times n$ binary matrix $X$ such that there does not exist any non-zero vector $y \\in \\{-1,0,1\\}^n$ with $Xy=0$ (all operations performed over $\\mathbb{Z}$).  What algorithm could I use for this?</p>\n\n<hr>\n\n<p>In more detail: We are given parameters $n$ and $m$.  The problem is to determine if there exists $x$ such that $x_{i,j} \\in \\{0,1\\}$, and there does not exist $y\\ne (0,0,\\dots,0)$ where $y_j \\in \\{-1,0,1\\}$ for all $j$ and for all $1 \\leq i \\leq m$,</p>\n\n<p>$$\\sum_{1 \\leq j \\leq n} x_{i,j} y_j = 0.$$</p>\n\n<p>(Notice that we require that at least one of the  $y_j \\ne 0$ to avoid the trivial solution.)</p>\n\n<p>For example, consider $m=3,n=4$.  Then, expressing $x_{i,j}$ as a matrix $X$,</p>\n\n<p>$$\nX=\\begin{pmatrix}\n0 &amp; 1 &amp; 1 &amp; 0 \\\\\n1 &amp; 0 &amp; 1 &amp; 1 \\\\\n0 &amp; 1 &amp; 0 &amp; 1 \\\\\n\\end{pmatrix}\n$$</p>\n\n<p>is a valid solution for $m=3$ and $n=4$.</p>\n\n<p>What algorithm can I use to solve this problem?  Can I formulate this as an integer linear programming problem or maybe as a constraint programming problem?</p>\n', 'ViewCount': '205', 'Title': 'Find a binary matrix so that no vector from {-1,0,1}^n is in its kernel', 'LastEditorUserId': '8942', 'LastActivityDate': '2014-01-03T13:18:40.517', 'LastEditDate': '2014-01-03T13:13:21.270', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '8942', 'Tags': '<complexity-theory><linear-programming><linear-algebra><constraint-programming><integer-programming>', 'CreationDate': '2013-12-27T20:07:50.993', 'FavoriteCount': '1', 'Id': '19333'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have the following problem.</p>\n\n<p>maximize $\\sum\\limits_{k=1}^Lx_k$</p>\n\n<p>subject to: $\\mathbf{x}^T\\mathbf{A}~ \\tilde{\\mathbf{x}_i} \\geq 0,~~ \\forall~ i\\in\\{1, 2, \\cdots, L\\}.$</p>\n\n<p>where, $~\\mathbf{x}^T = (x_1, x_2, \\cdots, x_L)\\in \\{0, 1\\}^{1\\times L}$, $\\tilde{\\mathbf{x}_i}=(0, \\cdots, 0, x_i, 0, \\cdots, 0)^T\\in \\{0, 1\\}^{L\\times 1}$, and \n$\\mathbf{A}\\in\\mathbb{R}^{L\\times L}.$</p>\n\n<p>Please tell me how can I specify the kind of this optimization problem?\nIs this an easy integer programming problem?</p>\n', 'ViewCount': '83', 'ClosedDate': '2014-01-15T08:21:38.273', 'Title': 'Is this NP-Hard problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-15T08:20:38.660', 'LastEditDate': '2014-01-15T08:20:38.660', 'AnswerCount': '0', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12683', 'Tags': '<optimization><integer-programming>', 'CreationDate': '2014-01-14T22:06:13.497', 'Id': '19727'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have the following problem.</p>\n\n<blockquote>\n  <p>Maximize $\\sum\\limits_{m=1}^M\\sum\\limits_{n=1}^N x_{mn}$</p>\n  \n  <p>subject to: $\\sum\\limits_{\\substack{m^\\prime=1\\\\ m^\\prime \\neq m}}^M\\sum\\limits_{\\substack{n^\\prime=1\\\\ n^\\prime \\neq n}}^N \\alpha_{mn^\\prime}x_{m^\\prime n^\\prime} \\leq \\alpha_{mn},~~ \\forall~ m\\in\\{1, 2, \\cdots, M\\}, \\forall~ n\\in\\{1, 2, \\cdots, N\\} .$</p>\n  \n  <p>where, $x_{mn} \\in \\{0, 1\\}$, and $\\alpha_{mn} \\in \\mathbb{R} ~\\forall~ m\\in\\{1, 2, \\cdots, M\\}, \\forall~ n\\in\\{1, 2, \\cdots, N\\}$ </p>\n</blockquote>\n\n<p>Please can I say that this is a knapsack problem? \nIs there a way to find a reduction from knapsack problem? In the <a href="http://en.wikipedia.org/wiki/List_of_knapsack_problems" rel="nofollow">most basic form of knapsack problem</a>, if the weights are all equal 1 the optimal solution is easy to solve.</p>\n', 'ViewCount': '61', 'Title': 'Is this problem a knapsack problem?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-22T21:40:49.310', 'LastEditDate': '2014-01-22T21:40:49.310', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12683', 'Tags': '<complexity-theory><optimization><np-hard><knapsack-problems><integer-programming>', 'CreationDate': '2014-01-22T18:58:47.070', 'Id': '19897'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I have an unknown $n$-dimensional vector $x$ whose analytical expression depends on the following sum $x = z + Ba$ where the vector $z$ and the matrix $B\\in \\mathbb{R}^{n\\times s}$ are given. So the $s$-dimensional vector $a$ is to be computed to find $x$.</p>\n\n<p>The only assumption that we have is $x=0$ when we project $x$ onto the space spanned by $s$ different rows (that we don\u2019t know their indices) of the matrix $B$ which has $n$ rows. To do this projection we can use $P_s\\in \\mathbb{R}^{n\\times n}$  which is $1$ on the diagonal entries that correspond to the $s$ selected rows of $B$ and $0$ elsewhere. Hence, $P_s x= P_s z + P_s Ba=0 \\implies a=-(P_sB)^{-1}P_sz$.</p>\n\n<p>The main issue is that we don\u2019t know the positions of these $s$ rows, so the problem is combinatorial and we need to go through all possible $n\\choose s$ projections to find the exact $x$ which corresponds to the least cost $f(x)=\\|y-Ax\\|_2$ where $\\|v\\|_2=\\big(\\sum_iv_i^2\\big)^{1/2}$, $y\\in \\mathbb{R}^{m\\times 1}$ and the matrix $A\\in \\mathbb{R}^{m\\times n}$ are given. </p>\n\n<p>So my question is how I can reformulate my problem as a mixed-integer quadratic programming to go through all possible $n\\choose s$ submatrices of $B$ formed by the $s$ selected rows and finally find the set of rows which corresponds to the least $f(x)$.</p>\n', 'ViewCount': '42', 'Title': 'How to reformulate my problem as a mixed-integer quadratic problem', 'LastEditorUserId': '7487', 'LastActivityDate': '2014-03-06T17:56:47.790', 'LastEditDate': '2014-03-06T16:54:52.230', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '22348', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7487', 'Tags': '<optimization><combinatorics><parallel-computing><integer-programming>', 'CreationDate': '2014-03-06T09:30:18.030', 'Id': '22333'}}