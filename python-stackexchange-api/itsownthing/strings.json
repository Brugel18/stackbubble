{'Body': '<p>I\'m looking for a data structure that stores a set of strings over a character set $\\Sigma$, capable of performing the following operations. We denote $\\mathcal{D}(S)$ as the data structure storing the set of strings $S$.</p>\n\n<ul>\n<li><code>Add-Prefix-Set</code> on $\\mathcal{D}(S)$: given some set $T$ of (possibly empty) strings, whose size is bounded by a constant and whose string lengths are bounded by a constant, return $\\mathcal{D}( \\{ t s\\ |\\ t \\in T, s \\in S\\} )$. Both these bounding constants are global: they are the same for all inputs $T$.</li>\n<li><code>Get-Prefixes</code> on $\\mathcal{D}(S)$: return $\\{ a \\ | \\ as \\in S, a \\in \\Sigma \\}$. Note that I don\'t really mind what structure is used for this set, as long as I can enumerate its contents in $O(|\\Sigma|)$ time.</li>\n<li><code>Remove-Prefixes</code> on $\\mathcal{D}(S)$: return $\\mathcal{D}( \\{ s \\ | \\ as \\in S, a \\in \\Sigma  \\} )$.</li>\n<li><code>Merge</code>: given $\\mathcal{D}(S)$ and $\\mathcal{D}(T)$, return $\\mathcal{D}(S \\cup T)$.</li>\n</ul>\n\n<p>Now, I\'d really like to do all these operations in $O(1)$ time, but I\'m fine with a structure that does all these operations in $o(n)$ time, where $n$ is the length of the longest string in the structure. In the case of the merge, I\'d like a $o(n_1+n_2)$ running time, where $n_1$ is $n$ for the first and $n_2$ the $n$ for the second structure.</p>\n\n<p>An additional requirement is that the structure is immutable, or at least that the above operations return \'new\' structures such that pointers to the old ones still function as before.</p>\n\n<p>A note about amortization: that is fine, but you have to watch out for persistence. As I re-use old structures all the time, I\'ll be in trouble if I hit a worst case with some particular set of operations on the same structure (so ignoring the new structures it creates).</p>\n\n<p>I\'d like to use such a structure in a parsing algorithm I\'m working on; the above structure would hold the lookahead I need for the algorithm.</p>\n\n<p>I\'ve already considered using a <a href="http://en.wikipedia.org/wiki/Trie">trie</a>, but the main problem is that I don\'t know how to merge tries efficiently. If the set of strings for <code>Add-Prefix-Set</code> consists of only single-character strings, then you could store these sets in a stack, which would give you $O(1)$ running times for the first three operations. However, this approach doesn\'t work for merging either.</p>\n\n<p>Finally, note that I\'m not interested in factors $|\\Sigma|$: this is constant for all I care.</p>\n', 'ViewCount': '657', 'Title': "Is there a 'string stack' data structure that supports these string operations?", 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-01T01:47:57.227', 'LastEditDate': '2012-04-01T01:47:57.227', 'AnswerCount': '0', 'CommentCount': '10', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '92', 'Tags': '<data-structures><time-complexity><strings><stack>', 'CreationDate': '2012-03-22T17:49:11.333', 'FavoriteCount': '3', 'Id': '666''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Let $\\Sigma$ be some finite set of characters of fixed size. Let $\\alpha$ be some string over $\\Sigma$. We say that a nonempty substring $\\beta$ of $\\alpha$ is a <em>repeat</em> if $\\beta = \\gamma \\gamma$ for some string $\\gamma$.</p>\n\n<p>Now, my question is whether the following holds:</p>\n\n<blockquote>\n  <p>For every $\\Sigma$, there exists some $n \\in \\mathbb{N}$ such that for every string $\\alpha$ over $\\Sigma$ of length at least $n$, $\\alpha$ contains at least one repeat.</p>\n</blockquote>\n\n<p>I\'ve checked this over the binary alphabet, and this is quite easy for that case, but an alphabet of size 3 is already quite a bit harder to check, amd I\'d like a proof for arbitrarily large grammars.</p>\n\n<p>If the above conjecture is true, then I can (almost) remove the demand for inserting empty strings <a href="http://cs.stackexchange.com/questions/666/is-there-a-string-stack-data-structure-that-supports-these-string-operations">in my other question</a>.</p>\n', 'ViewCount': '336', 'Title': 'Does every large enough string have repeats?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-25T15:29:39.443', 'LastEditDate': '2012-03-25T15:29:39.443', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '758', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '92', 'Tags': '<combinatorics><strings><word-combinatorics>', 'CreationDate': '2012-03-25T14:26:04.570', 'Id': '757''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I want to count the number of strings $s$ over a finite alphabet $A$, that contain no repeats, and by that I mean for any substring $t$ of $s$, $1&lt; |t| &lt; |s|$, there is no disjoint copy of $t$ in $s$.  For exapmle, let $A=\\{a,b\\}$.  Then $aaa$ <em>is</em> one of the strings I want to count, since for the substring $aa$, there are no disjoint copies.  However, $abab$ contains such a repeat.</p>\n\n<p>If someone's already figured out a useful formula, please link.  Otherwise, I will refer back to this post in any article I write, if I use someone's answer.</p>\n\n<p>Here is another example.  Let's try to construct a long string over $\\{a,b\\}$, that contains no repeats:</p>\n\n<p>aaa (can't be a)  <br>\n&nbsp;&nbsp; aaab (a or b)  <br>\n&nbsp;&nbsp;&nbsp;&nbsp; aaabbb (can't be b) <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; aaabbba (can't be b or a) <br>\n&nbsp;&nbsp; aaaba (can't be a or b)  <br></p>\n\n<p>If we built a tree, we could count the number of nodes, but I want a formula.</p>\n\n<p><strong>Edit:</strong>\nWell, it's not as daunting as I first thought if we convert this to a bin-choosing problem.  A set of strings of length k with at least one repeat is equal to the set that is the union of all permutations of the cartesian product:\n$A \\times A \\times \\cdots\\times A \\text{(k-4 times)} \\times R \\times R$ where $R$ is the required repeat.  I don't know if that's helpful, but it sounded pro :)  Anyway, let their be |A| bins, choose any two (even if the same one) to be the repeat, then choose $k-4$ more and multiply (the first 4 are already chosen, see?).  Now I just need to find that formula from discrete math.</p>\n", 'ViewCount': '172', 'Title': 'What is a formula for the number of strings with no repeats?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-19T15:45:22.733', 'LastEditDate': '2012-04-18T05:46:10.587', 'AnswerCount': '1', 'CommentCount': '17', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1118', 'Tags': '<formal-languages><combinatorics><strings><word-combinatorics>', 'CreationDate': '2012-04-17T01:49:50.663', 'Id': '1315''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Why do you think it is that most C++ instructors teaching college level computer sciences discourage or even forbid using strings for text, instead requiring students to use character arrays?</p>\n\n<p>I am assuming this methodology is somehow intended to teach good programming habits, but in my experience I don't see anything wrong with just using strings, and they are significantly easier to use and learn.</p>\n", 'ViewCount': '1582', 'Title': 'C++ Strings vs. Character Arrays', 'LastEditorUserId': '5', 'LastActivityDate': '2012-08-13T00:45:31.913', 'LastEditDate': '2012-04-20T03:26:07.963', 'AnswerCount': '6', 'CommentCount': '5', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1157', 'Tags': '<education><arrays><strings>', 'CreationDate': '2012-04-20T02:11:18.667', 'FavoriteCount': '2', 'Id': '1375''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m trying to write a spell-checker which should work with a pretty large dictionary. I really want an efficient way to index my dictionary data to be used using a <a href="http://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance">Damerau-Levenshtein</a> distance to determine which words are closest to the misspelled word.</p>\n\n<p>I\'m looking for a data structure who would give me the best compromise between space complexity and runtime complexity.</p>\n\n<p>Based on what I found on the internet, I have a few leads regarding what type of data structure to use:</p>\n\n<h2>Trie</h2>\n\n<p><img src="http://i.stack.imgur.com/KhvoF.png" alt="trie-500px"></p>\n\n<p>This is my first thought and looks pretty easy to implement and should provide fast lookup/insertion. Approximate search using Damerau-Levenshtein should be simple to implement here as well. But it doesn\'t look very efficient in terms of space complexity since you most likely have a lot of overhead with pointers storage.</p>\n\n<h2>Patricia Trie</h2>\n\n<p><img src="http://i.stack.imgur.com/EJYB0.png" alt="trie-500px"></p>\n\n<p>This seems to consume less space than a regular Trie since you\'re basically avoiding the cost of storing the pointers, but I\'m a bit worried about data fragmentation in case of very large dictionaries like what I have.</p>\n\n<h2>Suffix Tree</h2>\n\n<p><img src="http://i.stack.imgur.com/uXH1b.png" alt="suffix-500px"></p>\n\n<p>I\'m not sure about this one, it seems like some people do find it useful in text mining, but I\'m not really sure what it would give in terms of performance for a spell checker.</p>\n\n<h2>Ternary Search Tree</h2>\n\n<p><img src="http://i.stack.imgur.com/X8hPY.png" alt="tst"></p>\n\n<p>These look pretty nice and in terms of complexity should be close (better?) to Patricia Tries, but I\'m not sure regarding fragmentation if it would be better of worse than Patricia Tries.</p>\n\n<h2>Burst Tree</h2>\n\n<p><img src="http://i.stack.imgur.com/9jn1m.png" alt="burst"></p>\n\n<p>This seems kind of hybrid and I\'m not sure what advantage it would have over Tries and the like, but I\'ve read several times that it\'s very efficient for text mining.</p>\n\n<hr>\n\n<p>I would like to get some feedback as to which data structure would be best to use in this context and what makes it better than the other ones. If I\'m missing some data structures who would be even more appropriate for a spell-checker, I\'m very interested as well.</p>\n', 'ViewCount': '1908', 'Title': 'Efficient data structures for building a fast spell checker', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-04T14:00:33.120', 'LastEditDate': '2012-05-15T20:22:56.733', 'AnswerCount': '2', 'CommentCount': '8', 'Score': '23', 'PostTypeId': '1', 'OwnerUserId': '1307', 'Tags': '<data-structures><strings><string-metrics>', 'CreationDate': '2012-05-02T03:07:23.057', 'FavoriteCount': '5', 'Id': '1626''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u'<p>Let $A_P = (Q,\\Sigma,\\delta,0,\\{m\\})$ the <em>string matching automaton</em> for pattern $P \\in \\Sigma^m$, that is </p>\n\n<ul>\n<li>$Q = \\{0,1,\\dots,m\\}$</li>\n<li>$\\delta(q,a) = \\sigma_P(P_{0,q}\\cdot a)$ for all $q\\in Q$ and $a\\in \\Sigma$</li>\n</ul>\n\n<p>with $\\sigma_P(w)$ the length of the longest prefix of $P$ that is a Suffix of $w$, that is</p>\n\n<p>$\\qquad \\displaystyle \\sigma_P(w) = \\max \\left\\{k \\in \\mathbb{N}_0 \\mid P_{0,k} \\sqsupset w \\right\\}$.</p>\n\n<p>Now, let $\\pi$ the <em>prefix function</em> from the <a href="https://secure.wikimedia.org/wikipedia/en/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm" rel="nofollow">Knuth-Morris-Pratt algorithm</a>, that is</p>\n\n<p>$\\qquad \\displaystyle \\pi_P(q)= \\max \\{k \\mid k &lt; q \\wedge P_{0,k} \\sqsupset P_{0,q}\\}$.</p>\n\n<p>As it turns out, one can use $\\pi_P$ to compute $\\delta$ quickly; the central observation is:</p>\n\n<blockquote>\n  <p>Assume above notions and $a \\in \\Sigma$. For $q \\in \\{0,\\dots,m\\}$ with $q = m$ or $P_{q+1} \\neq a$, it holds that</p>\n  \n  <p>$\\qquad \\displaystyle \\delta(q,a) = \\delta(\\pi_P(q),a)$</p>\n</blockquote>\n\n<p>But how can I prove this?</p>\n\n<hr>\n\n<p>For reference, this is how you compute $\\pi_P$:</p>\n\n<pre><code>m \u2190 length[P ]\n\u03c0[0] \u2190 0\nk \u2190 0\nfor q \u2190 1 to m \u2212 1 do\n  while k &gt; 0 and P [k + 1] =6 P [q] do\n    k \u2190 \u03c0[k]\n    if P [k + 1] = P [q] then\n       k \u2190 k + 1\n    end if\n    \u03c0[q] \u2190 k\n end while\nend for\n\nreturn \u03c0\n</code></pre>\n', 'ViewCount': '1117', 'Title': 'Connection between KMP prefix function and string matching automaton', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-19T15:53:30.563', 'LastEditDate': '2012-05-17T23:59:30.850', 'AnswerCount': '1', 'CommentCount': '9', 'AcceptedAnswerId': '1900', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1378', 'Tags': '<algorithms><finite-automata><strings><searching>', 'CreationDate': '2012-05-05T09:56:27.257', 'Id': '1669''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '114', 'Title': 'Randomized String Searching', 'LastEditDate': '2012-05-10T14:52:46.263', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1393', 'FavoriteCount': '2', 'Body': "<p>I need to detect whether a binary pattern $P$ of length $m$ occurs in a binary text $T$ of length $n$ where $m &lt; n$.</p>\n\n<p>I want to state an algorithm that runs in time $O(n)$ where we assume that arithmetic operations on $O(\\log_2 n)$ bit numbers can be executed in constant time. The algorithm should accept with probability $1$ whenever $P$ is a substring of $T$ and reject with probability of at least $1 - \\frac{1}{n}$ otherwise.</p>\n\n<p>I think fingerprinting could help here. But I can't get it.</p>\n", 'Tags': '<algorithms><strings><searching><probabilistic-algorithms>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-10T14:52:46.263', 'CommentCount': '3', 'AcceptedAnswerId': '1718', 'CreationDate': '2012-05-07T07:56:27.833', 'Id': '1712''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u'<p>This question has been prompted by <a href="http://cs.stackexchange.com/questions/1626/efficient-data-structures-for-building-a-fast-spell-checker">Efficient data structures for building a fast spell checker</a>.</p>\n\n<p>Given two strings $u,v$, we say they are <em>$k$-close</em> if their <a href="http://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance" rel="nofollow">Damerau\u2013Levenshtein distance</a>\xb9 is small, i.e. $\\operatorname{LD}(u,v) \\geq k$ for a fixed $k \\in \\mathbb{N}$. Informally, $\\operatorname{LD}(u,v)$ is the minimum number of deletion, insertion, substitution and (neighbour) swap operations needed to transform $u$ into $v$. It can be computed in $\\Theta(|u|\\cdot|v|)$ by dynamic programming. Note that $\\operatorname{LD}$ is a <a href="http://en.wikipedia.org/wiki/Metric_%28mathematics%29" rel="nofollow">metric</a>, that is in particular symmetric.</p>\n\n<p>The question of interest is:</p>\n\n<blockquote>\n  <p>Given a set $S$ of $n$ strings over $\\Sigma$ with lengths at most $m$, what is the cardinality of </p>\n  \n  <p>$\\qquad \\displaystyle S_k := \\{ w \\in \\Sigma^* \\mid \\exists v \\in S.\\ \\operatorname{LD}(v,w) \\leq k \\}$?</p>\n</blockquote>\n\n<p>As even two strings of the same length have different numbers of $k$-close strings\xb2 a general formula/approach may be hard (impossible?) to find. Therefore, we might have to compute the number explicitly for every given $S$, leading us to the main question:</p>\n\n<blockquote>\n  <p>What is the (time) complexity of finding the cardinality of the set $\\{w\\}_k$ for (arbitrary) $w \\in \\Sigma^*$?</p>\n</blockquote>\n\n<p>Note that the desired quantity is exponential in $|w|$, so explicit enumeration is not desirable. An efficient algorithm would be great.</p>\n\n<p>If it helps, it can be assumed that we have indeed a (large) set $S$ of strings, that is we solve the first highlighted question.</p>\n\n<hr>\n\n<ol>\n<li>Possible variants include using the <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" rel="nofollow">Levenshtein distance</a> instead.</li>\n<li>Consider $aa$ and $ab$. The sets of $1$-close strings over $\\{a,b\\}$ are $\\{ a, aa,ab,ba,aaa,baa,aba,aab \\}$ (8 words) and $\\{a,b,aa,bb,ab,ba,aab,bab,abb,aba\\}$ (10 words), respectively .</li>\n</ol>\n', 'ViewCount': '268', 'Title': 'How many strings are close to a given set of strings?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-15T20:21:01.853', 'LastEditDate': '2012-05-15T20:21:01.853', 'AnswerCount': '2', 'CommentCount': '6', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<algorithms><time-complexity><strings><word-combinatorics><string-metrics>', 'CreationDate': '2012-05-09T15:48:12.173', 'FavoriteCount': '1', 'Id': '1758''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I want to turn one string into another with only single letter substitions.  What is a good way to do this, passing through only valid words in between (<a href="http://www.wuzzlesandpuzzles.com/wordchange/" rel="nofollow">this</a> website has some examples)?</p>\n\n<p>Valid here means "a word in English" as this is the domain I consider.</p>\n\n<p>My current idea is that I could use a shortest path algorithm with the Hamming distance for edge weights. The problem is that it will take a long time to build the graph, and even then the weight is not so precise in terms of distance (though it will never underestimate it) unless the weight is one, so I would probably have to find a to build a graph that only had weights of one.</p>\n\n<p>What would be the easiest way to build the graph? Am I taking entirely the wrong approach?</p>\n', 'ViewCount': '320', 'Title': 'Turn one string into another with single letter substitions', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-15T20:21:41.307', 'LastEditDate': '2012-05-15T20:21:41.307', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '863', 'Tags': '<algorithms><strings><string-metrics>', 'CreationDate': '2012-05-10T23:30:48.357', 'Id': '1785''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '2080', 'Title': 'dynamic programming exercise on cutting strings', 'LastEditDate': '2012-05-13T18:35:49.400', 'AnswerCount': '2', 'Score': '8', 'OwnerDisplayName': 'Mark', 'PostTypeId': '1', 'OwnerUserId': '1556', 'FavoriteCount': '1', 'Body': '<p>I have been working on the following problem from this <a href="http://www.cs.berkeley.edu/~vazirani/algorithms/chap6.pdf">book</a>.</p>\n\n<blockquote>\n  <p>A certain string-processing language offers a primitive operation which splits a string into two\n  pieces. Since this operation involves copying the original string, it takes n units of time for a\n  string of length n, regardless of the location of the cut. Suppose, now, that you want to break a\n  string into many pieces. The order in which the breaks are made can affect the total running\n  time. For example, if you want to cut a 20-character string at positions $3$ and $10$, then making\n  the first cut at position $3$ incurs a total cost of $20 + 17 = 37$, while doing position 10 first has a\n  better cost of $20 + 10 = 30$.</p>\n</blockquote>\n\n<p>I need a dynamic programming algorithm that given $m$ cuts, finds the minimum cost of cutting a string into $m +1$ pieces.</p>\n', 'Tags': '<algorithms><combinatorics><strings><dynamic-programming>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-08-31T14:56:19.823', 'CommentCount': '0', 'CreationDate': '2012-04-09T03:17:15.270', 'Id': '1822''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am still fighting with hashing and I am ask myself: what is the most efficient way to count the number of different words in a text using a hash table?</p>\n\n<p>My intuition says that applying the hashcode function to every word in the text, as result we will have words with different hash values in different buckets and the same words will have the same bucket and therefore we will have a collision problem which we can resolve using the chaining method.</p>\n\n<p>Does it work like that?</p>\n', 'ViewCount': '773', 'Title': 'Counting different words in text using hashing', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-15T20:29:24.713', 'LastEditDate': '2012-05-14T16:54:51.270', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1011', 'Tags': '<algorithms><strings><hash-tables>', 'CreationDate': '2012-05-14T16:41:35.327', 'Id': '1838''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m looking for a data structure that supports efficient approximate lookups of keys (e.g., Levenshtein distance for strings), returning the closest possible match for the input key. The best suited data structure I\'ve found so far are <a href="http://en.wikipedia.org/wiki/BK-tree">Burkhard-Keller trees</a>, but I was wondering if there are other/better data structures for this purpose.</p>\n\n<p>Edit:\nSome more details of my specific case:</p>\n\n<ul>\n<li>Strings usually have a fairly large Levenshtein difference from each other.</li>\n<li>Strings have a max length of around 20-30 chars, with an average closer to 10-12.</li>\n<li>I\'m more interested in efficient lookup than insertion as I will be building a set of mostly static data that I want to query efficiently.</li>\n</ul>\n', 'ViewCount': '787', 'Title': 'Efficient map data structure supporting approximate lookup', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-27T17:48:11.330', 'LastEditDate': '2012-05-26T14:41:45.563', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '1658', 'Tags': '<data-structures><strings><efficiency>', 'CreationDate': '2012-05-26T13:11:38.040', 'FavoriteCount': '4', 'Id': '2093''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '753', 'Title': 'Finding interesting anagrams', 'LastEditDate': '2012-06-07T22:08:29.743', 'AnswerCount': '4', 'Score': '17', 'PostTypeId': '1', 'OwnerUserId': '1786', 'FavoriteCount': '0', 'Body': "<p>Say that $a_1a_2\\ldots a_n$ and $b_1b_2\\ldots b_n$ are two strings of the same length.  An <strong>anagramming</strong> of two strings is a bijective mapping $p:[1\\ldots n]\\to[1\\ldots n]$ such that $a_i = b_{p(i)}$ for each $i$.</p>\n\n<p>There might be more than one anagramming for the same pair of strings.  For example, If $a=$<code>abcab</code> and $b=$<code>cabab</code> we have $p_1[1,2,3,4,5]\\to[4,5,1,2,3]$ and $p_2[1,2,3,4,5] \\to [2,5,1,4,3]$, among others.</p>\n\n<p>We'll say that the <strong>weight</strong> $w(p)$ of an anagramming $p$ is the number of values of $i\\in[1\\ldots n-1]$ for which $p(i)+1\\ne p(i+1)$. That is, it is the number of points at which $p$ does <em>not</em> increase by exactly 1.For example, $w(p_1) = 1$ and $w(p_2) = 4$.</p>\n\n<p>Suppose there exists an anagramming for two strings $a$ and $b$. Then at least one  anagamming must have least weight. Let's say this this one is <strong>lightest</strong>. (There might be multiple lightest anagrammings; I don't care because I am interested only in the weights.)</p>\n\n<h2>Question</h2>\n\n<p>I want an algorithm which, given two strings for which an anagramming exists, efficiently <strong>yields the exact weight of the lightest anagramming</strong> of the two strings. It is all right if the algorithm yields a lightest anagramming, but it need not.</p>\n\n<p>It is a fairly simple matter to generate all anagrammings and weigh them, but there may be many, so I would prefer a method that finds light anagrammings directly.</p>\n\n<hr>\n\n<h2>Motivation</h2>\n\n<p>The reason this problem is of interest is as follows.  It is very easy to make the computer search the dictionary and find anagrams, pairs of words that contain exactly the same letters.  But many of the anagrams produced are uninteresting.  For instance, the longest examples to be found in Webster's Second International Dictionary are:</p>\n\n<blockquote>\n  <p>cholecystoduodenostomy<br>\n  duodenocholecystostomy</p>\n</blockquote>\n\n<p>The problem should be clear: these are uninteresting because they admit a very light anagramming that simply exchanges the <code>cholecysto</code>, <code>duedeno</code>, and <code>stomy</code> sections, for a weight of 2. On the other hand, this much shorter example is much more surprising and interesting:</p>\n\n<blockquote>\n  <p>coastline<br>\n  sectional</p>\n</blockquote>\n\n<p>Here the lightest anagramming has weight 8.</p>\n\n<p>I have a program that uses this method to locate interesting anagrams, namely those for which all anagrammings are of high weight. But it does this by generating and weighing all possible anagrammings, which is slow.</p>\n", 'Tags': '<algorithms><strings><search-algorithms><natural-lang-processing>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-11-21T14:18:17.910', 'CommentCount': '2', 'AcceptedAnswerId': '2265', 'CreationDate': '2012-06-07T18:31:28.390', 'Id': '2259''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I have one puzzle whose answer I have boiled down to finding the total number and which type of permutation they are.</p>\n\n<p>For example if the string is of length ten as $w = aabbbaabba$, the total number of permutations will be </p>\n\n<p>$\\qquad \\displaystyle \\frac{|w|}{|w|_a! \\cdot |w|_b!} = \\frac{10!}{5!\\cdot 5!}$</p>\n\n<p>Now had the string been of distinct characters, say $w'=abcdefghij$, I would have found the permutations by this algorithm : </p>\n\n<pre><code>for i = 1 to |w|\n  w = rotate(w)\nw = rotate(w)\nreturn w.head + rotate(w.tail)\n</code></pre>\n\n<p>Can some one throw new ideas on this - how to find the number of permutations for a string having repeated characters? Is there any other mathematical/scientific name of for what I am trying to do?</p>\n", 'ViewCount': '1544', 'Title': 'Finding the number of distinct permutations of length N with n different symbols', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-24T11:51:51.870', 'LastEditDate': '2012-06-22T09:14:31.023', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'OwnerDisplayName': 'softy', 'PostTypeId': '1', 'OwnerUserId': '1942', 'Tags': '<algorithms><combinatorics><strings><word-combinatorics>', 'CreationDate': '2012-06-21T16:17:23.717', 'Id': '2443''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>First of all we must read a word, and a desired size.<br>\nThen we need to find the longest palindrome created by characters in this word used in order.<br>\nFor example for size = 7 and word = "abcababac" the answer is 7 ("abababa").   </p>\n\n<p>Postscript: the size of the word is smaller than 3000.</p>\n', 'ViewCount': '3096', 'Title': 'Fastest algorithm for finding the longest palindrome subsequence', 'LastEditorUserId': '39', 'LastActivityDate': '2013-03-22T21:13:31.333', 'LastEditDate': '2012-10-11T21:21:11.817', 'AnswerCount': '3', 'CommentCount': '8', 'Score': '6', 'OwnerDisplayName': 'Lin Yon Xong', 'PostTypeId': '1', 'Tags': '<algorithms><strings><subsequences>', 'CreationDate': '2012-06-18T14:11:18.557', 'FavoriteCount': '1', 'Id': '2466''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Given two strings, $r$ and $s$, where $n = |r|$, $m = |s|$ and $m \\ll n$, find the minimum edit distance between $s$ for each beginning position in $r$ efficiently.</p>\n\n<p>That is, for each suffix of $r$ beginning at position $k$, $r_k$, find the <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" rel="nofollow">Levenshtein distance</a> of $r_k$ and $s$ for each $k \\in [0, |r|-1]$.  In other words, I would like an array of scores, $A$, such that each position, $A[k]$, corresponds to the score of $r_k$ and $s$.</p>\n\n<p>The obvious solution is to use the standard dynamic programming solution for each $r_k$ against $s$ considered separately, but this has the abysmal running time of $O(n m^2)$ (or $O(n d^2)$, where $d$ is the maximum edit distance).  It seems like you should be able to re-use the information that you\'ve computed for $r_0$ against $s$ for the comparison with $s$ and $r_1$.</p>\n\n<p>I\'ve thought of constructing a prefix tree and then trying to do dynamic programming algorithm on $s$ against the trie, but this still has worst case $O(n d^2)$ (where $d$ is the maximum edit distance) as the trie is only optimized for efficient lookup.</p>\n\n<p>Ideally I would like something that has worst case running time of $O(n d)$ though I would settle for good average case running time.  Does anyone have any suggestions?  Is $O(n d^2)$ the best you can do, in general?</p>\n\n<p>Here are some links that might be relevant though I can\'t see how they would apply to the above problem as most of them are optimized for lookup only:</p>\n\n<ul>\n<li><a href="http://stevehanov.ca/blog/index.php?id=114" rel="nofollow">Fast and Easy Levensthein distance using a Trie</a></li>\n<li><a href="http://stackoverflow.com/questions/3183149/most-efficient-way-to-calculate-levenshtein-distance">SO: Most efficient way to calculate Levenshtein distance</a></li>\n<li><a href="http://stackoverflow.com/questions/4057513/levenshtein-distance-algorithm-better-than-onm?rq=1">SO: Levenshtein Distance Algoirthm better than $O(n m)$</a></li>\n<li><a href="http://www.berghel.net/publications/asm/asm.php" rel="nofollow">An extension of Ukkonen\'s enhanced dynamic programming ASM algorithm</a></li>\n<li><a href="http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata" rel="nofollow">Damn Cool Algorithms: Levenshtein Automata</a></li>\n</ul>\n\n<p>I\'ve also heard some talk about using some type of distance metric to optimize search (such as a <a href="http://en.wikipedia.org/wiki/BK-tree" rel="nofollow">BK-tree</a>?) but I know little about this area and how it applies to this problem.</p>\n', 'ViewCount': '836', 'Title': 'Efficiently calculating minimum edit distance of a smaller string at each position in a larger one', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-28T15:40:06.263', 'LastEditDate': '2012-06-28T15:40:06.263', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '2526', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '67', 'Tags': '<algorithms><runtime-analysis><strings><dynamic-programming><string-metrics>', 'CreationDate': '2012-06-27T20:48:29.300', 'Id': '2519''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '139', 'Title': 'Find string that minimizes the sum of the edit distances to all other strings in set', 'LastEditDate': '2012-06-30T10:54:21.683', 'AnswerCount': '1', 'Score': '5', 'OwnerDisplayName': 'jmvidal', 'PostTypeId': '1', 'OwnerUserId': '2015', 'FavoriteCount': '1', 'Body': '<p>I have a set of strings $S$ and I am using the edit-distance (<a href="http://en.wikipedia.org/wiki/Levenshtein_distance" rel="nofollow">Levenshtein</a>) to measure the distance between all pairs.</p>\n\n<p>Is there an algorithm for finding the string $x$ which minimizes the sum of the distances to all strings in $S$, that is</p>\n\n<p>$\\arg_x \\min \\sum_{s \\in S} \\text{edit-distance}(x,s)$</p>\n\n<p>It seems like there should, but I can\'t find the right reference.</p>\n', 'Tags': '<algorithms><reference-request><strings><string-metrics>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-30T10:54:21.683', 'CommentCount': '0', 'AcceptedAnswerId': '2551', 'CreationDate': '2012-06-29T15:25:33.753', 'Id': '2546''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have a very specific question about semantic clustering.</p>\n\n<p>I have a list of words/phrases. I want to run an intelligent semantic clustering algorithm on this list. Please let me know what the available options are. Definitely I am looking for NLP based algorithms.</p>\n\n<p>Simple, open-source, easy-to-use solutions will be highly appreciated. The semantic part is extremely important here.</p>\n', 'ViewCount': '523', 'Title': 'Semantic clustering', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-27T18:49:17.373', 'LastEditDate': '2012-07-27T14:31:08.407', 'AnswerCount': '1', 'CommentCount': '10', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2288', 'Tags': '<algorithms><strings><string-metrics><natural-lang-processing><ontologies>', 'CreationDate': '2012-07-27T10:56:33.110', 'FavoriteCount': '1', 'Id': '2922''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '325', 'Title': 'Compression of domain names', 'LastEditDate': '2012-08-08T06:51:13.347', 'AnswerCount': '1', 'Score': '11', 'OwnerDisplayName': 'eggyal', 'PostTypeId': '1', 'OwnerUserId': '2380', 'FavoriteCount': '1', 'Body': '<p>I am curious as to how one might <em>very compactly</em> compress the domain of an arbitrary <a href="http://en.wikipedia.org/wiki/Internationalized_domain_name">IDN</a> hostname (as defined by <a href="http://tools.ietf.org/html/rfc5890">RFC5890</a>) and suspect this could become an interesting challenge. A Unicode host or domain name (U-label) consists of a string of Unicode characters, typically constrained to one language depending on the top-level domain (e.g. Greek letters under <code>.gr</code>), which is encoded into an ASCII string beginning with <code>xn--</code> (the corresponding A-label).</p>\n\n<p>One can build data models not only from the formal requirements that</p>\n\n<ul>\n<li><p>each non-Unicode label be a string matching <code>^[a-z\\d]([a-z\\d\\-]{0,61}[a-z\\d])?$</code>;</p></li>\n<li><p>each A-label be a string matching <code>^xn--[a-z\\d]([a-z\\d\\-]{0,57}[a-z\\d])?$</code>; and</p></li>\n<li><p>the total length of the entire domain (A-labels and non-IDN labels concatenated with \'.\' delimiters) not exceed 255 characters</p></li>\n</ul>\n\n<p>but also from various heuristics, including:</p>\n\n<ul>\n<li><p>lower-order U-labels are often lexically, syntactically and semantically valid phrases in some natural language including proper nouns and numerals (unpunctuated except hyphen, stripped of whitespace and folded per <a href="http://tools.ietf.org/html/rfc3491">Nameprep</a>), with a preference for shorter phrases; and</p></li>\n<li><p>higher-order labels are drawn from a dictionary of SLDs and TLDs and provide context for predicting which natural language is used in the lower-order labels.</p></li>\n</ul>\n\n<p>I fear that achieving good compression of such short strings will be difficult without considering these specific features of the data and, furthermore, that existing libraries will produce unnecessary overhead in order to accomodate their more general use cases.</p>\n\n<p>Reading Matt Mahoney\'s online book <a href="http://mattmahoney.net/dc/dce.html">Data Compression Explained</a>, it is clear that a number of existing techniques could be employed to take advantage of the above (and/or other) modelling assumptions which ought to result in far superior compression versus less specific tools.</p>\n\n<p>By way of context, this question is an offshoot from a <a href="http://stackoverflow.com/questions/7792624/producing-compact-ciphertext-of-short-strings">previous one on SO</a>.</p>\n\n<hr>\n\n<p><strong>Initial thoughts</strong></p>\n\n<p>It strikes me that this problem is an excellent candidate for offline training and I envisage a compressed data format along the following lines:</p>\n\n<ul>\n<li><p>A Huffman coding of the "<a href="http://publicsuffix.org/">public suffix</a>", with probabilities drawn from some published source of domain registration or traffic volumes;</p></li>\n<li><p>A Huffman coding of which (natural language) model is used for the remaining U-labels, with probabilities drawn from some published source of domain registration or traffic volumes given context of the domain suffix;</p></li>\n<li><p>Apply some dictionary-based transforms from the specified natural language model; and</p></li>\n<li><p>An arithmetic coding of each character in the U-labels, with probabilities drawn from contextually adaptive natural language models derived from offline training (and perhaps online too, although I suspect the data may well be too short to provide any meaningful insight?).</p></li>\n</ul>\n', 'Tags': '<algorithms><strings><natural-lang-processing><data-compression>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-31T13:51:19.050', 'CommentCount': '5', 'CreationDate': '2011-10-18T02:19:42.587', 'Id': '3056''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Say I have an LR grammar <em>G</em> and a string <em>w</em>. I know that I can check if <em>w</em> is in the language of <em>G</em> in linear time. But what if <em>w</em> itself is not in the language of <em>G</em>, but I want to find all substrings of <em>w</em> that are in the language of <em>G</em>? And can I get parse trees for those substrings? What would be the time complexity for these things?</p>\n', 'ViewCount': '91', 'Title': 'Given an LR grammar G and a string w, is it possible to quickly find all substrings in w that are in L(G)?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-11-22T18:34:46.167', 'LastEditDate': '2012-09-12T12:15:54.237', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'OwnerDisplayName': 'oskarkv', 'PostTypeId': '1', 'Tags': '<formal-grammars><parsing><substrings>', 'CreationDate': '2012-08-08T15:52:55.883', 'Id': '3512''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '1105', 'Title': 'Fast k mismatch string matching algorithm', 'LastEditDate': '2012-09-29T20:37:46.053', 'AnswerCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '3011', 'FavoriteCount': '2', 'Body': '<p>I am looking for a fast k-mismatch string matching algorithm. Given a pattern string P of length m, and a text string T of length n, I need a fast (linear time) algorithm to find all positions where P matches a substring of T with at most k mismatches. This is different from the k-differences problem (edit distance). A mismatch implies the substring and the pattern have a different letter in at most k positions. I really only require k=1 (at most 1 mismatch), so a fast algorithm for the specific case of k=1 will also suffice. The alphabet size is 26 (case-insensitive english text), so space requirement should not grow too fast with the size of the alphabet (eg., the FAAST algorithm, I believe, takes space exponential in the size of the alphabet, and so is suitable only for protein and gene sequences).</p>\n\n<p>A dynamic programming based approach will tend to be O(mn) in the worst case, which will be too slow. I believe there are modifications of the Boyer-Moore algorithm for this, but I am not able to get my hands on such papers. I do not have subscription to access academic journals or publications, so any references will have to be in the public domain.</p>\n\n<p>I would greatly appreciate any pointers, or references to freely available documents, or the algorithm itself for this problem. </p>\n', 'Tags': '<algorithms><reference-request><strings><string-metrics><substrings>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-04T09:58:32.560', 'CommentCount': '3', 'AcceptedAnswerId': '4855', 'CreationDate': '2012-09-29T19:47:41.390', 'Id': '4797''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<blockquote>\n  <p><strong>Substring Diff</strong><br>\n  Given two strings of length $n$, $P = p_1\\dots p_n$ and $Q = q_1 \\dots q_n$, we define $M(i, j, L)$ as the number of\n  mismatches between $p_i \\dots p_{i+L-1}$ and $q_j \\dots q_{j+L-1}$. In set\n  notation, $M(i, j, L)$ refers to the size of the set $\\{0 \\leq x &lt; L \\mid p_{i + x} \\neq q_{j + x}\\}$.</p>\n  \n  <p>Given an integer $K$, your task is to find the maximum length $L$ such\n  that there exists pair of indices $(i,j)$ for which we have $M(i, j, L) \\leq K$. Of course, we should also have $i + L - 1 \\leq n$ and $j + L - 1 \\leq n$.</p>\n  \n  <p><strong>Constraints</strong></p>\n  \n  <ul>\n  <li>$0 \\leq K \\leq |P|$</li>\n  <li>Both $P$ &amp; $Q$ would have the same length</li>\n  <li>The size of each of the string would be at the max <strong>1500</strong> </li>\n  <li>All characters in $P$ and $Q$ are lower-case English letters.</li>\n  </ul>\n</blockquote>\n\n<p>The recursive function will have the form:</p>\n\n<pre><code>longest(string1, string2, allowed_mismatches) = \n    {\n        ... (something :P )\n    }\n</code></pre>\n\n<p>The state space then has size $K^3$. With an upper bound on $K$ of 1500, the running time and space usage will be terrible... So direct dynamic programming will not work without some additional property to reduce the state space.</p>\n\n<p>Ideas?</p>\n\n<p><strong>UPDATE</strong></p>\n\n<p>Using the ideas suggested by both Yuval and Vor, I came up with the following solution that works like a charm, running in $O(K^2)$ time and using $K$ space.</p>\n\n<pre><code>def longest_range_min_sum(str1, str2, start1, start2, slice_size, max_sum):\n    longest = 0\n    i = 0\n    running_sum = 0\n    while i + longest &lt; slice_size:\n        if str1[start1 + i + longest] != str2[start2 + i + longest]:\n            running_sum += 1\n        if running_sum &gt; max_sum:\n            if str1[start1 + i] != str2[start2 + i]:\n                running_sum -= 1\n            i += 1\n        else:\n            longest += 1\n    return longest\n\nimport sys\n\ndata = sys.stdin.readlines()\nnum_cases = int(data.pop(0))\nfor ignore in xrange(num_cases):\n    max_mismatches, str1, str2 = data.pop(0).split()\n    max_mismatches = int(max_mismatches)\n    m = n = len(str1)\n    longest = 0\n    for i in xrange(m + n + 1):\n        if i &gt; n:\n            slice_size = m - (i - n)\n        else:\n            slice_size = min(i, m)\n        if slice_size == 0:\n            continue\n        end1 = max(m, m - i)\n        if i &gt; n:\n            end1 = m - (i - n)\n        start1 = end1 - slice_size\n        end2 = min(i, n)\n        start2 = end2 - slice_size\n        #print zeros_and_ones \n        #print str1[start1:end1], ' - ', str2[start2:end2]\n        longest_in_sub = longest_range_min_sum(str1, str2, start1, start2, slice_size, max_mismatches)\n        #print longest_in_sub\n        longest = max(longest, longest_in_sub)\n    print longest\n</code></pre>\n", 'ViewCount': '578', 'Title': 'Dynamic programming table for finding similar substrings is too large', 'LastEditorUserId': '3101', 'LastActivityDate': '2012-10-19T07:02:46.443', 'LastEditDate': '2012-10-19T07:02:46.443', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '5002', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '3101', 'Tags': '<strings><dynamic-programming><substrings>', 'CreationDate': '2012-10-10T10:21:57.203', 'Id': '4994''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '188', 'Title': 'Represent string as concatenations', 'LastEditDate': '2012-10-18T02:50:57.417', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '220', 'FavoriteCount': '1', 'Body': "<p>If $S_1,S_2$ are set of strings, then $S_1S_2 = \\{s_1s_2|s_1\\in S_1, s_2\\in S_2\\}$. $S^0=\\{\\epsilon\\}$, $\\epsilon$ is the empty string. $S^n = S^{n-1}S$. </p>\n\n<p>Two related problems about represent string as concatenation of other strings. </p>\n\n<ol>\n<li><p>Given a finite set $S$ of strings, how to decide if there exist a string can be written as concatenations of elements in $S$ in two different ways?</p></li>\n<li><p>Given a finite set $S$ of strings and $n$, how can one compute the smallest set of strings $T$, such that $S\\subset T^n$?</p></li>\n</ol>\n\n<p>(Bonus: what about infinite $S$, at least when it's regular? For the second problem when $S$ is infinite, we might ask to find a minimal $T$ under set inclusion.)</p>\n", 'Tags': '<algorithms><formal-languages><strings>', 'LastEditorUserId': '220', 'LastActivityDate': '2012-10-20T12:24:21.363', 'CommentCount': '6', 'AcceptedAnswerId': '6190', 'CreationDate': '2012-10-16T22:30:32.147', 'Id': '6114''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>So I have a fun little problem. It will take a minute to explain, but the situation is conceptually very simple. Suppose you have a string of characters, which is interpreted as groups of one or more contiguous characters. This is for run length encoding or something. For example:</p>\n\n<blockquote>\n  <p>zz22344a is two z's, two 2's, one 3, two 4's, and one a.</p>\n</blockquote>\n\n<p>Once you've parsed the original string, you retain only the characters and sizes in an array.</p>\n\n<pre><code>struct Run { char whatChar; int length; }\n\nRun* runArrayVar;\n\nvoid parseIntoArray(char* sourceChars);   // creates runArrayVar\n</code></pre>\n\n<p>I won't put the implementation of parseIntoArray() here because it's trivial to do with a loop, but I'll assume that arrays are null-terminated, although in the problem they don't have to be. Here is the problem part. I want to implement a function like this:</p>\n\n<pre><code>void alterArray(char* newSourceChars, int changedOffset,\n                int changedLength, int changedCharsAdded);\n</code></pre>\n\n<p>This responds to a change in the source text. Included is the new text, the beginning and length of the altered area, and for reference, how many extra characters were added. For example, take the original <code>zz22344a</code>. If the substring <code>223</code> was pasted over with <code>23_44</code>, then the new string would be <code>zz23_4444a</code> and the new array would be two <code>z</code>'s, one <code>2</code>, one <code>3</code>, one <code>_</code>, four <code>4</code>'s, and one <code>a</code>.</p>\n\n<p>I could get the new <code>runArrayVar</code> naively by just calling <code>parseIntoArray</code>, but I want to be less naive: I want to step through and only change the parts of <code>runArrayVar</code> that need to be changed. Finding the first changed element is pretty easy; skip through until you find one that overlaps <code>changedOffset</code> (you need to test one extra char after the element). After that it gets dicey and I can't figure it out. Take the above example:</p>\n\n<p><code>zz</code> needs to be re-checked because the character right after it might have been changed to a <code>z</code>. It wasn't, so it remains <code>zz</code>. Now we're at offset 2.</p>\n\n<p><code>22</code> is rechecked, and it turned into 2. So OK. Now we're at offset 3.</p>\n\n<p><code>3</code> is rechecked, and it's the same. So we're at offset 4.</p>\n\n<p><code>44</code> is rechecked, and apparently turned into an underscore. So we're at offset 5.</p>\n\n<p>At this point we're still looking at characters that have changed, and we're at <code>4444</code>. According to the previous logic, <code>a</code> turned into <code>4444</code>. OK. Now we're past the characters that have changed, and our array still has an element with one a left over. I can keep parsing and terminate the array when I hit the end of the string, but suppose that <code>a</code> was actually a million <code>a</code>s in a row. The algorithm should be able to reason that it doesn't have to do any more work and terminate. If you look at the example, there is nothing you could have changed that particular section into that would influence the <code>a</code>.</p>\n\n<p>This is difficult. I've tried it a lot of different ways and I can't figure out exactly when the algorithm needs to terminate. Please let me know if you have any ideas!</p>\n", 'ViewCount': '81', 'Title': 'Rechecking contiguous characters (as in run length encoding)', 'LastEditorUserId': '5417', 'LastActivityDate': '2013-01-25T16:18:15.193', 'LastEditDate': '2013-01-25T16:18:15.193', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4657', 'Tags': '<strings><substrings>', 'CreationDate': '2012-11-19T17:20:42.823', 'Id': '6770''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm looking for an efficient algorithm to find the longest repeated pattern in a string.</p>\n\n<p>For example, consider the following string of numbers:  </p>\n\n<p><code>5431428571428571428571428571427623874534</code>.</p>\n\n<p>As you can see, <code>142857142857</code> is the longest pattern which is repeated for a couple of times (at least twice) in this string.</p>\n\n<p>The repeated string should not contain any re\nany idea rather than brute-force?  </p>\n", 'ViewCount': '1033', 'Title': 'Find the longest repeated pattern in a string', 'LastEditorUserId': '472', 'LastActivityDate': '2012-11-22T03:33:54.443', 'LastEditDate': '2012-11-22T03:33:54.443', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '5', 'OwnerDisplayName': 'MBZ', 'PostTypeId': '1', 'Tags': '<algorithms><strings><subsequences>', 'CreationDate': '2012-11-08T19:28:56.950', 'FavoriteCount': '1', 'Id': '6776''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>For what size alphabet does it take longer to construct <a href="http://en.wikipedia.org/wiki/Suffix_tree" rel="nofollow">a suffix tree</a> - for a really small alphabet size (because it has to go deep into the tree) or for a large alphabet size? Or is it dependent on the algorithm you use? If it is dependent, how does the alphabet size affect <a href="http://en.wikipedia.org/wiki/Ukkonen%27s_algorithm" rel="nofollow">Ukkonen\'s algorithm</a>?</p>\n', 'ViewCount': '88', 'Title': 'What are the effects of the alphabet size on construct algorithms for suffix trees?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-23T09:43:36.243', 'LastEditDate': '2012-11-23T09:30:49.477', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4696', 'Tags': '<algorithms><data-structures><algorithm-analysis><strings><efficiency>', 'CreationDate': '2012-11-22T22:14:10.630', 'Id': '6842''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Aren't there $n^2$ unique substrings of a string (irrespective of the alphabet size)? Perhaps the number of unique <em>suffix substrings</em> is less than the number of unique <em>substrings</em> of a string.</p>\n", 'ViewCount': '272', 'Title': 'Why does a suffix tree have a linear number of nodes (relative to input string size)?', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-11-29T10:50:42.293', 'LastEditDate': '2012-11-27T07:47:22.710', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '6945', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4748', 'Tags': '<data-structures><strings><trees>', 'CreationDate': '2012-11-27T05:43:15.827', 'Id': '6943''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I want to be able to locate a substring in a string allowing for a specified number of mismatches, insertions and deletions - and at the same time know how many mismatches, insertions and deletions were used for any match.</p>\n\n<p>Using brute force backtrack I can find the matches, but I cannot guarantee that the match was produced using the fewest permutations possible.</p>\n\n<p>Using dynamic programming I can find the matches and guarantee that the match was produced using the fewest permutations possible, but I cannot specify a number of allowed mismatches, insertion and deletions - only a total edit distance.</p>\n', 'ViewCount': '243', 'Title': 'Fuzzy string matching algorithm with allowed events?', 'LastEditorUserId': '19', 'LastActivityDate': '2013-01-27T23:12:52.733', 'LastEditDate': '2012-12-01T05:00:57.040', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4810', 'Tags': '<algorithms><dynamic-programming><strings><substrings>', 'CreationDate': '2012-11-30T10:52:00.527', 'FavoriteCount': '1', 'Id': '7040''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Inspired by this <a href="http://stackoverflow.com/questions/9452701/ukkonens-suffix-tree-algorithm-in-plain-english">question on Suffix Trees</a>, and the fabulous winning answer, I would hereby ask for a similar explanation of Myers\' <a href="http://www.gersteinlab.org/courses/452/09-spring/pdf/Myers.pdf" rel="nofollow">Fast Bit-Vector Algorithm for Approximate String\nMatching Based on Dynamic Programming</a>.</p>\n', 'ViewCount': '106', 'Title': "Myers' Fast bit-vector algorithm in plain English?", 'LastActivityDate': '2012-12-01T11:17:18.233', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4810', 'Tags': '<algorithms><strings>', 'CreationDate': '2012-12-01T11:17:18.233', 'Id': '7078''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<blockquote>\n  <p>We are given two strings $x=x_1,x_2,x_3,\\ldots,x_m$ and $y=y_1,y_2,y_3,\\ldots,y_n$ over some finite alphabet.\n  We consider the problem of converting $x$ to $y$. Using the following operations:</p>\n  \n  <p>1.Substitution: replace one symbol by another one.</p>\n  \n  <p>2.Insertion: inserts one symbol</p>\n  \n  <p>3.Deletion: delete one symbol.</p>\n</blockquote>\n\n<p>For example, if $x$="logarithm" and $y$="algorithm", we convert $x$ to $y$ in the following way:</p>\n\n<ol>\n<li><p>start with "logarithm"</p></li>\n<li><p>inserting "a"at the front gives "alogarithm".</p></li>\n<li><p>deleting "o"gives "algarithm"</p></li>\n<li><p>replacing the second "a"by "o"gives "algorithm".</p></li>\n</ol>\n\n<p>The similarity problem between the string $x$ and $y$ is defined to be the minimum number of operations needed to convert $x$ to $y$.</p>\n\n<p>For example, the similarity between $x$="logarithm" and $y$="algorithm" is 3, because $x$ can be converted to $y$ using three operations. If the string $x$ has length $m$ and the string $y$ is empty, then the similarity between $x$ and $y$ is similar to $m$.</p>\n\n<p>Give a dynamic programming algorithm (in pseudocode) that computes, in $\\mathcal o(mn)$ time, the similarity between the string $x$ and $y$.</p>\n\n<p>It is as the edit distance problem but there is the corresponding minimization problem problem where we measure similarity instead of distance .  </p>\n', 'ViewCount': '400', 'Title': 'String similarity problem', 'LastEditorUserId': '3094', 'LastActivityDate': '2012-12-03T10:17:05.547', 'LastEditDate': '2012-12-02T20:38:06.193', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4828', 'Tags': '<algorithms><reference-request><dynamic-programming><strings>', 'CreationDate': '2012-12-02T19:47:18.867', 'Id': '7109''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have a question that I still struggle with.\nIt would be really appreciated if you guys could give me some hints.</p>\n\n<p>Here is the problem : \nAssume that $a[1\\dots n]$ is an array of $n$ positive real numbers.\nLet $\\alpha &gt;0$ and $\\beta &gt;0$</p>\n\n<ul>\n<li><p>a subarray $a_1$ with $m$ elements of $a[1 \\dots n]$ is called increasing if $\\frac{a_1[i]}{a_1[j]}\\geq \\alpha$, for all $i&gt;j$ and $1 \\leq i, j \\leq m$.</p></li>\n<li><p>a subarray $a_2$ with $k$ elements of $a[1 \\dots n]$ is called decreasing if $\\frac{a_2[i]}{a_2[j]}\\leq \\beta$, for all $i&gt;j$ and $1 \\leq i, j \\leq k$.</p></li>\n</ul>\n\n<p>Question : write a program to find all increasing/decreasing subarrays of $a[1 \\dots n]$ ?\nthanks so much for your help.</p>\n', 'ViewCount': '226', 'Title': 'Find all increasing/decreasing sub array', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-05-01T17:04:54.940', 'LastEditDate': '2013-01-01T14:07:41.843', 'AnswerCount': '2', 'CommentCount': '8', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '5258', 'Tags': '<algorithms><substrings>', 'CreationDate': '2013-01-01T03:12:53.483', 'Id': '7668''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>We commonly create sub-groups of strings in one particular algorithm implementation. I just want to know in CS literature is there any standard name for such kind of grouping. For e.g.</p>\n\n<pre><code>Hello World! This is May from the dairy farm.\n</code></pre>\n\n<p>Strings with sub-groups of two:</p>\n\n<pre><code>Hello World!\nWorld! This\nThis is\nis May\n...\n</code></pre>\n', 'ViewCount': '36', 'Title': 'terminology for grouping words in a string?', 'LastActivityDate': '2013-01-01T13:34:35.417', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7675', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2374', 'Tags': '<terminology><strings><substrings>', 'CreationDate': '2013-01-01T13:08:48.753', 'Id': '7674''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm thinking about the optimal algorithm for the following problem:</p>\n\n<p>Input data:</p>\n\n<ul>\n<li>a <strong>text</strong>, say it's an article about 5-50 pages.</li>\n<li>a set of <strong>ngrams</strong> (ngram strings, n>2), of arbitrary length, could be more than 20k n-grams.</li>\n</ul>\n\n<p>The algorithm should output the following:</p>\n\n<ul>\n<li>a dictionary of all ngrams that were found in the text with the corresponding quantities, it should also take into account that ngrams could partially intersect or consist of each other (like <em>'probability density', 'probability density function', 'probability density distribution'</em>)</li>\n</ul>\n\n<p>So <strong>the question is</strong> what would be the most time-efficient algorithm to compute this?</p>\n\n<p>Both all words in a text and all words in ngrams are reduced to the canonical forms.</p>\n", 'ViewCount': '169', 'Title': 'Optimal algorithm for finding all ngrams from a pre-defined set in a text', 'LastEditorUserId': '98', 'LastActivityDate': '2013-01-27T01:11:03.780', 'LastEditDate': '2013-01-16T21:10:34.413', 'AnswerCount': '4', 'CommentCount': '0', 'AcceptedAnswerId': '8976', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2066', 'Tags': '<algorithms><time-complexity><strings><natural-lang-processing>', 'CreationDate': '2013-01-16T16:38:56.730', 'Id': '8972''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have been experimenting with <a href="https://en.wikipedia.org/wiki/LZ77" rel="nofollow">LZ77</a> (naively $O(n^2)$ runtime, infinite window). Applying it to the 7th Fibonacci word $abaababaabaab$ yields the correct LZ factorization:</p>\n\n<p>$\\qquad a,b,a,aba,baaba,ab$.</p>\n\n<p>My question is about the behavior of LZ77 if we iterate it. My experiments suggest that reapplication of LZ77 to the input will yield no further patterns that were not found the first time. </p>\n\n<p>By reapplication I mean, where in the first instance we treat the factors of the string as the sequence of unit symbols \'a\' and \'b\', in the second application the factors are the LZ factors. I was hoping to discover (over larger various texts, like the Complete Sonnets of Shakespeare) increasing gains, and possibly, "multilevel" patterns found by LZ over the sequence of factors of the previous iterate. But none of this occurred. The sequence of factors after the second iteration is exactly the same as the first.</p>\n\n<p>So where is the bug in my thinking? Is there a simple proof of this given the definition of an LZ factor being the longest prefix from the current position occurring in the concatenation of the preceding LZ factors?</p>\n', 'ViewCount': '111', 'Title': 'Behavior of iterative application of LZ77', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-15T07:17:29.540', 'LastEditDate': '2013-04-15T07:17:29.540', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '5', 'OwnerDisplayName': 'Cris Stringfellow', 'PostTypeId': '1', 'OwnerUserId': '4602', 'Tags': '<strings><data-compression><lempel-ziv>', 'CreationDate': '2013-01-30T14:39:17.333', 'Id': '9311''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '983', 'Title': 'Algorithm for building a suffix array in time $O(n \\log^2 n)$', 'LastEditDate': '2013-02-04T15:51:33.583', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4916', 'FavoriteCount': '1', 'Body': '<p>I\'ve been working with suffix arrays lately, and I can\'t find an efficient algorithm for building a suffix array which is easy to understand.  I have seen in many sites that there is an $O(n \\log^2 n)$ algorithm, but I can\'t understand it, as many important details are omitted.  There\'s an example at <a href="http://apps.topcoder.com/forums/?module=Thread&amp;threadID=627379&amp;start=0&amp;mc=33#1039014" rel="nofollow">Top Coder</a>.</p>\n\n<p>Could someone introduce me an efficient algorithm for suffix array construction, which is easy to comprehend?</p>\n', 'Tags': '<algorithms><data-structures><strings>', 'LastEditorUserId': '4916', 'LastActivityDate': '2013-02-05T22:22:27.363', 'CommentCount': '0', 'AcceptedAnswerId': '9466', 'CreationDate': '2013-02-03T13:11:42.780', 'Id': '9447''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Is there a linear-time algorithm to check that a sequence of characters is a concatenation of palindromes? The only thing that comes to my mind is the naive solution:</p>\n\n<pre><code>1. k = 1\n2. Split string into k substrings (all possibilities) and check\n3. k++\n4. repeat\n</code></pre>\n\n<p>Note: the answer is trivially yes if length 1-strings are defined to be palindromes. Let's assume that this is not the case.</p>\n", 'ViewCount': '1027', 'Title': 'Is there an algorithm for checking if a string is a catenation of palindromes?', 'LastEditorUserId': '2499', 'LastActivityDate': '2013-04-22T17:01:18.820', 'LastEditDate': '2013-04-22T17:01:18.820', 'AnswerCount': '3', 'CommentCount': '9', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2499', 'Tags': '<algorithms><efficiency><strings>', 'CreationDate': '2013-02-06T11:22:25.257', 'FavoriteCount': '2', 'Id': '9540''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>This <a href="http://www.cs.utexas.edu/~moore/best-ideas/string-searching/index.html">page</a> about Knuth-Moriss-Pratt Algorithm compared to Boyer-Moore describes a possible case where the Boyer-Moore algorithm suffers from small skip distance while KMP could perform better.<br>\nI\'m looking for a good example (text,pattern) that can clearly demonstrate this case.</p>\n', 'ViewCount': '504', 'Title': 'An example where Knuth-Morris-Pratt Algorithm is faster than Boyer-Moore?', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-03-20T19:23:37.120', 'LastEditDate': '2013-02-10T14:23:12.430', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '736', 'Tags': '<algorithms><substrings><matching>', 'CreationDate': '2013-02-10T10:41:28.470', 'Id': '9635''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am concerned with the question of <strong>the asymptotic running time of the Ukkonen\'s algorithm</strong>, perhaps the most popular algorithm for constructing <strong>suffix trees</strong> in linear (?) time.</p>\n\n<p>Here is a citation from the book "Algorithms on strings, trees and sequences" by Dan Gusfield (section 6.5.1):</p>\n\n<blockquote>\n  <p>"... the Aho-Corasick, Weiner, <strong>Ukkonen</strong> and McCreight algorithms all either require $\\Theta(m|\\Sigma|)$ space, or the $O(m)$ time bound should be replaced with the minimum of $O(m \\log m)$ and $O(m \\log|\\Sigma|)$".</p>\n  \n  <p><em>[$m$ is the string length and $\\Sigma$ is the size of the alphabet]</em></p>\n</blockquote>\n\n<p>I don\'t understand why that is true.</p>\n\n<ul>\n<li><strong>Space:</strong> well, in case we represent branches out of the nodes using arrays of size $\\Theta(|\\Sigma|)$, then, indeed, we end up with $\\Theta(m|\\Sigma|)$ space usage. However, as far as I can see, it is also possible to store the branches using hash tables (say, dictionaries in Python). We would then have only $\\Theta(m)$ pointers stored in all hash tables altogether (since there are $\\Theta(m)$ edges in the tree), while still being able to access the children nodes in $O(1)$ time, as fast as when using arrays.</li>\n<li><strong>Time</strong>: as mentioned above, using hash tables allows us to access the outgoing branches of any node in $O(1)$ time. Since the Ukkonen\'s algorithm requires $O(m)$ operations (including accessing children nodes), the overall running time then would be also $O(m)$.</li>\n</ul>\n\n<p>I would be very grateful to you for any hints on why I am wrong in my conclusions and why Gusfield is right about the dependence of the Ukkonen\'s algorithm on the alphabet.</p>\n', 'ViewCount': '238', 'Title': "How does the runtime of the Ukkonen's algorithm depend on the alphabet size?", 'LastEditorUserId': '162', 'LastActivityDate': '2013-02-18T14:59:52.107', 'LastEditDate': '2013-02-16T08:05:47.417', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '162', 'Tags': '<algorithms><data-structures><algorithm-analysis><strings>', 'CreationDate': '2013-02-15T22:05:13.680', 'FavoriteCount': '1', 'Id': '9820''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>What is Harrison hashing and what are its applications in web searching? \nCan some one give me some relevant information?    </p>\n\n<p><strong>Update:</strong></p>\n\n<p>I found it <a href="http://www.cs.manchester.ac.uk/ugt/COMP26120/" rel="nofollow">here</a> , and is a part of M.Tech syllabus of a friend of mine. I need to explain him this concept and then see how it can be applied in web applications.\nMany thanks for spending your precious time.    </p>\n', 'ViewCount': '207', 'Title': 'What is Harrison hashing, its applications in web search engines?', 'LastEditorUserId': '6466', 'LastActivityDate': '2013-10-15T01:10:32.837', 'LastEditDate': '2013-02-27T06:34:22.677', 'AnswerCount': '2', 'CommentCount': '4', 'AcceptedAnswerId': '10126', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<algorithms><strings><search-algorithms><hash>', 'CreationDate': '2013-02-26T15:01:05.643', 'Id': '10121''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am reading chapter 32 - String Matching from the book <a href="http://rads.stackoverflow.com/amzn/click/0262033844" rel="nofollow">"Introduction to Algorithms" 3rd edition Cormen et al</a>. The Rabin-Karp Algorithm is not clear to me despite heaving read it several times. Specifically, when the authors start proposing about some modulo operations for solving some problem, I am unable to follow. To be precise, the paragraphs from</p>\n\n<blockquote>\n  <p>We have intentionally overlooked one problem: p and ts may be too\n  large too work with conveniently...</p>\n</blockquote>\n\n<p>on till equation 32.2 (pp 991 in 3rd edition) are <a href="http://i.stack.imgur.com/d5ptz.jpg" rel="nofollow">the paragraphs I am having problems with</a>.</p>\n\n<p>What does "convenient" mean here? Why do they use modulo? I am totally lost.\nIs it possible to explain this in simple english?</p>\n\n<p>I will appreciate if someone can help me in understanding this paragraph. And if there is any other reference (with similar mathematical treatment) where this can be read, please tell me.</p>\n', 'ViewCount': '199', 'Title': "Problem with Cormen's treatment of the Rabin-Karp algorithm", 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-07T12:08:04.267', 'LastEditDate': '2013-04-07T12:08:04.267', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<algorithms><search-algorithms><strings>', 'CreationDate': '2013-03-01T12:51:39.397', 'Id': '10173''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I asked a similar question <a href="http://cs.stackexchange.com/questions/10173/rabin-karp-searching-algorithm">here</a> on Rabin Karp algorithm. My present question is, how do we find the best $q$ (i.e modulus)? What is the criterion? We need to choose a $q$ which will be quick to calculate and also must result in lesser number of spurious hits, right? </p>\n\n<p>Wow do we ensure these things?</p>\n', 'ViewCount': '499', 'Title': 'How do we find the optimal modulus q in Rabin-Karp algorithm?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-07T12:09:29.210', 'LastEditDate': '2013-04-07T12:09:29.210', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<algorithms><search-algorithms><strings>', 'CreationDate': '2013-03-01T14:34:49.860', 'Id': '10174''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I have two datasets that I am trying to match to one another. One dataset's contents is a subset of the other, but contains typographical errors of varying types and magnitude.</p>\n\n<p>I am applying the following logic to the data linkage process:</p>\n\n<p>Apply regular expressions in an iterative manner with increasing flexibility until a match is found (for example, in one iteration, leave vowels as optional). If two matches are found for one record within one iteration, categorize match as tie and leave unmatched. Apply Python's fuzzy regex to handle scenarios which a rule-based regex can't handle, namely character insertions, deletions, and substitutions within an edit distance of one.</p>\n\n<p>I'm having to discuss this process in detail for specs. However, I'm having trouble deciding how to categorize the process. Would this be considered a deterministic process?</p>\n\n<p>Your help would be appreciated. I do not have a CS background, so I apologize if my question is fairly rudimentary.</p>\n", 'ViewCount': '119', 'Title': 'Distinguishing probabilistic, deterministic, and fuzzy matching methods', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-06T06:58:03.727', 'LastEditDate': '2013-03-06T06:58:03.727', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7160', 'Tags': '<regular-expressions><strings><string-metrics>', 'CreationDate': '2013-03-05T19:59:45.920', 'Id': '10301''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am facing problem in understanding the KMP algorithm as given in the book  "Introduction to Algorithm" by Cormen et. al. (Chapter 32): </p>\n\n<p><img src="http://i.stack.imgur.com/5LPPL.jpg" alt="enter image description here"></p>\n\n<p><img src="http://i.stack.imgur.com/MX5hv.jpg" alt="enter image description here"></p>\n\n<p>With respect to the above algorithm, I have following question:</p>\n\n<ol>\n<li><p>In both the algorithms, where exactly (which line number?) while loops, if and for loop ends? It is difficult to visualize the functioning of the algorithm without knowing the \'end\' for each loop and conditional statements.</p></li>\n<li><p>On line number 6 in KMP-MATCHER() and COMPUTE-PREFIX-FUNCTION(), what is the need of checking q>0 and k>0, when we know q and k will always be 0 or positive. Or do the authors want to test q!=0, k!=0? </p></li>\n<li><p>If q=0 and i=1 in KMP-MATCHER(), from 6 to 10 which line will be executed (If I get answer to 1- above then I can find this)       </p></li>\n</ol>\n', 'ViewCount': '164', 'Title': 'Unable to understand control flow in KMP algorithm', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-10-19T19:35:20.363', 'LastEditDate': '2013-04-24T21:15:41.077', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<algorithms><terminology><strings>', 'CreationDate': '2013-03-24T11:49:45.607', 'Id': '10738''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '106', 'Title': 'How to find specificity of a regex match?', 'LastEditDate': '2013-03-26T11:20:44.637', 'AnswerCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7419', 'FavoriteCount': '1', 'Body': "<p>I'm thinking about a routing system. Imagine I have the two following regexes</p>\n\n<ul>\n<li>pathpart1/pathpart2 => specific match that routes to controller1</li>\n<li>.* => catch-all that routes to controller2</li>\n</ul>\n\n<p>And I let them match on a URL, e.g. 'pathpart1/pathpart2'.</p>\n\n<p>They both match, but I would want to give prevalence to the most specific regex, i.e. the regex where <strong>the cardinality of all possible matches of that regex</strong> is the lowest.</p>\n\n<blockquote>\n  <p>Is there a good way to calculate that the first regex has a low cardinality on its match-set (so I want to to go with that match) and the second has a very high cardinality on its match-set (i.e. it is completely not specific, so a match is basically a catch all last resort)...?</p>\n</blockquote>\n\n<p>I do not know upfront which routes are registered with the router, so I can't loop over them in order of cardinality by hand (i.e. low cardinality first, and the catch-all last if all others don't match).</p>\n", 'Tags': '<algorithms><regular-expressions><strings>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-27T10:20:57.763', 'CommentCount': '0', 'AcceptedAnswerId': '10807', 'CreationDate': '2013-03-25T21:22:07.827', 'Id': '10786''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '242', 'Title': "Shortest sub-sequence of one string, that's not a sub-sequence of another string", 'LastEditDate': '2013-05-18T07:32:13.657', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '3083', 'FavoriteCount': '1', 'Body': "<p>Given two strings $x$ and $y$ over the alphabet $\\{A,C,G,T\\}$, I'm trying to determine a shortest string $z$ such that $z$ is a subsequence of $x$ and not a subsequence of $y$.</p>\n\n<blockquote>\n  <p><strong>Example:</strong> a shortest string that is a subsequence of AATGAAC but not a subsequence of ATCGATC is AAG.</p>\n</blockquote>\n", 'Tags': '<algorithms><strings>', 'LastEditorUserId': '755', 'LastActivityDate': '2013-05-18T07:32:13.657', 'CommentCount': '2', 'AcceptedAnswerId': '12038', 'CreationDate': '2013-05-15T11:38:38.767', 'Id': '12037''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Given three strings $x$, $y$, and $z$ over an arbitrary finite alphabet, I need to determine their longest common subsequence (LCS).</p>\n\n<p><strong>Example</strong>: A longest common subsequence of <code>bandana</code>, <code>cabana</code>, and <code>magazine</code> is <code>aan</code>.</p>\n\n<p>I'm trying to find an algorithm which uses $O(|x|\\cdot |y| \\cdot |z|)$ space where $|s|$ denotes the length of the string $s$.</p>\n", 'ViewCount': '163', 'Title': 'Find longest common subsequence in limited space', 'LastEditorUserId': '2205', 'LastActivityDate': '2014-03-25T19:29:35.657', 'LastEditDate': '2013-05-15T18:05:44.963', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '12046', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '3083', 'Tags': '<algorithms><algorithm-analysis><dynamic-programming><strings>', 'CreationDate': '2013-05-15T17:37:25.197', 'Id': '12045''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>If you have a long string of length $n$ and a shorter string of length $m$, what is a suitable recurrence to let you compute all $n-m+1$ <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" rel="nofollow">Levevenshtein distances</a> between the shorter string and all substrings of the longer string of length $m$?</p>\n\n<p>Can it in fact be done in $O(nm)$ time?</p>\n', 'ViewCount': '132', 'Title': 'Semi-local Levenshtein distance', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T09:52:43.530', 'LastEditDate': '2013-09-02T09:52:43.530', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '8938', 'Tags': '<recurrence-relation><dynamic-programming><strings><string-metrics><edit-distance>', 'CreationDate': '2013-06-30T11:00:35.020', 'Id': '12986''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Given s as a string of some alphabet, what is the best known algorithm to compute a corresponding automaton that accepts any string that contains s?</p>\n\n<p>I am mostly intrested of the lowest time complexity so if you tell me what is the best known complexity in O notation to build an automaton for a string that would be just as good.</p>\n', 'ViewCount': '256', 'Title': 'Automaton for substring matching', 'LastEditorUserId': '1033', 'LastActivityDate': '2013-07-02T07:49:31.180', 'LastEditDate': '2013-07-01T12:02:13.157', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1033', 'Tags': '<automata><finite-automata><strings><substrings>', 'CreationDate': '2013-07-01T10:48:25.027', 'Id': '13009''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>From what I have come to understand, the best way to implement it is to use the suffix  array $S$ of the string $w$ and its LCP-array (Longest Common Prefix) $L$.</p>\n\n<p>The answer can be obtained by </p>\n\n<p>$$ \\sum_{i=1}^{|w|} \\left( |S[i]| -L[i-1] \\right).$$</p>\n\n<p>What I don't get is how and why is this working?</p>\n\n<p>I would be very grateful if someone explained this.</p>\n", 'ViewCount': '914', 'Title': 'Number of distinct substrings in a string', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-07-19T07:11:22.433', 'LastEditDate': '2013-07-19T07:11:22.433', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13241', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9073', 'Tags': '<algorithms><data-structures><strings><substrings><suffix-array>', 'CreationDate': '2013-07-07T19:30:34.867', 'Id': '13140''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>We are given an array $a[1 \\ldots n]$ with all $a[i]&gt;0$.</p>\n\n<p>Now we need to find how many distinct sums can be formed from its subarrays (where a subarray is a contiguous range of the array, i.e., $a[j\\ldots k]$ for some $j,k$, the sum is the sum of all of the elements of the subarray). For example, if $a=[1,2,1]$, then the answer is 4: we can form $ 1,2,3,4$.</p>\n\n<p>I know how to count the number of distinct sums in $O(n^2)$ time.</p>\n\n<p>Furthermore, I have come to realise this is similar to the classical problem where we need to find the number of distinct substrings of a string. I was thinking of the possibility of constructing a suffix array and solving it in a similar fashion (in $O(n)$ time). But I have not been able to figure out how to modify that to work here. For example, if we use suffix array for $a=[1,2,1]$ we will get 5 cases instead of the four acceptable ones. Is this possible to do this using suffix arrays or am I thinking in the wrong direction?</p>\n\n<p>Also there is one more direction I have been thinking in. Divide and conquer. Like if I divide the array into two parts every time until it is reduced to a single element. A single element can have one sum. Now if we combine two single elements, It can be done in two ways: if both single ranges have same element then we get 2 different sums, or if both have different elements we get 3 different sums. But I am not being able to generalize this for merging arrays of length greater than 1. Is it possible to merge two m size arrays and get the answer in $O(m)$?</p>\n', 'ViewCount': '262', 'Title': 'Counting number of sums from contiguous subarrays of an array', 'LastEditorUserId': '683', 'LastActivityDate': '2013-07-14T08:29:17.840', 'LastEditDate': '2013-07-14T08:29:17.840', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '8622', 'Tags': '<arrays><substrings><suffix-array>', 'CreationDate': '2013-07-13T20:31:03.527', 'FavoriteCount': '1', 'Id': '13262''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>The <a href="http://rosalind.info/glossary/alignment/" rel="nofollow">global alignment</a> problem can be generalized by setting the cost of some boundary gaps to 0.</p>\n\n<ul>\n<li>Gaps at both end in both strings have 0 cost, then we get the <a href="http://rosalind.info/glossary/semiglobal-alignment/" rel="nofollow">semiglobal alignment</a>.</li>\n<li>Gaps are at the left end of the first string, and right end of second string have 0 cost, then we get <a href="http://rosalind.info/glossary/overlap-alignment/" rel="nofollow">overlap alignment</a>.</li>\n<li>If both boundary gaps for the second string has no cost, we get the <a href="http://rosalind.info/glossary/fitting-alignment/" rel="nofollow">fitting alignment</a>.</li>\n</ul>\n\n<p>But this can\'t capture <a href="http://rosalind.info/glossary/local-alignment/" rel="nofollow">local alignment</a>. Seems strange to let the local alignment to be the odd man out, are there a general (but not too general) framework that captures all the above alignment problems? </p>\n', 'ViewCount': '56', 'Title': 'A framework to capture common variation of sequence alignments', 'LastEditorUserId': '4287', 'LastActivityDate': '2013-07-27T23:29:16.013', 'LastEditDate': '2013-07-27T23:29:16.013', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '220', 'Tags': '<algorithms><strings><bioinformatics>', 'CreationDate': '2013-07-20T07:18:14.790', 'Id': '13354''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am working on multiple patterns search matching algorithms and I found that two algorithms are the strongest candidates, namely <a href="http://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_string_matching_algorithm" rel="nofollow">Aho-Corasick</a> and <a href="http://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm" rel="nofollow">Rabin-Karp</a> in terms of running time. However, there are few things still foggy. I could not find any comprehensive comparison between the two algorithms. Besides, what I need to know is which one of them is more suitable for parallel computing and multiple patterns search. Which one require less hardware resources.  </p>\n\n<p>For AC algorithm searching phase time complexity is O(n+m), while it is O(nm) for RK. However, running time for RK is O(n+m) which make it similar to AC. My conclusion is RK practically better as it does not need memory as AC. I need a confirmation of that.  </p>\n', 'ViewCount': '234', 'Title': 'A comparison between Aho-Corasick algorithm and Rabin-Karp algorithm', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-09T00:14:12.477', 'LastEditDate': '2013-09-16T07:47:49.863', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '9855', 'Tags': '<algorithms><algorithm-analysis><runtime-analysis><strings>', 'CreationDate': '2013-09-14T16:34:08.873', 'Id': '14309''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>One naive approach in solving <em>multiple pattern matching</em> problem is to call <em>single pattern matching</em> procedure on each of the pattern.</p>\n\n<p>There <strong>must</strong> be some drawbacks in this approach, given the variety of multiple pattern matching algorithms such as Aho Cornsick algorithm, which prove to be more efficient.</p>\n\n<p>So what are the drawbacks on this straightforward yet naive approach? In what scenario is this algorithm doing unnecessary works?</p>\n', 'ViewCount': '40', 'Title': 'Drawbacks of repeating a single pattern matching procedure for many patterns', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-03T07:09:50.597', 'LastEditDate': '2013-10-04T06:33:51.647', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4662', 'Tags': '<algorithms><search-algorithms><strings><substrings>', 'CreationDate': '2013-10-01T18:24:30.603', 'Id': '14739''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>There is one point I don\'t understand in the DFA construction for mismatch cases.</p>\n\n<p>Here is the lecture note I watched, which describes how to handle mismatched characters during the DFA construction process.</p>\n\n<p><img src="http://i.stack.imgur.com/r4Q1Z.png" alt="enter image description here"></p>\n\n<p>Some information about the presentation screen shot:</p>\n\n<p><code>pat</code> is the pattern, string index starts at 0, <code>dfa</code> is the state transition table, in which the row is indexed by the character(eg, "A","B" or "C"), column by state(1,2,3,...).</p>\n\n<hr>\n\n<p><strong>My question starts</strong>:</p>\n\n<p>In the place in the presentation, where starts with "<em>To compute dfa[c][j]</em>", it says run the simulation using the last j-1 chars.</p>\n\n<p>I am confused:</p>\n\n<p>Why run the simulation using the last <code>j-1</code> chars, rather the last <code>j</code> chars. </p>\n\n<p>What\'s the intuition of this design?</p>\n', 'ViewCount': '277', 'Title': u'Confusion about finite automata construction in Knuth\u2013Morris\u2013Pratt algorithm', 'LastEditorUserId': '4662', 'LastActivityDate': '2013-12-01T06:48:14.043', 'LastEditDate': '2013-10-18T19:04:46.790', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4662', 'Tags': '<algorithms><finite-automata><strings><matching>', 'CreationDate': '2013-10-18T09:15:06.677', 'FavoriteCount': '1', 'Id': '16195''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Problem Statement:\nSuppose we a thousands of words and we need to maintain these words in a data structure in such a way that we should be able to find all anagrams for a given string.\nI tried to achieve this with O(1) complexity.</p>\n\n<p>I am looking for a algorithm to implement above scenario. I implemented this problem with below algo, but i feel that we can improve its complexity. Any suggestion will be helpful.</p>\n\n<p>Algorithms:</p>\n\n<p>Here is trick to utilize hash code, we can also use character histogram.</p>\n\n<p>Step 1:Create an array of prime numbers.</p>\n\n<pre><code>   int primes[] = {2, 3, 5, 7, ...};\n\n   We are using prime number to avoid false collisions.\n</code></pre>\n\n<p>Step 2:Create a method to calculate hash code of a word\\string.</p>\n\n<pre><code>   int getHashCode(String str){\n     int hash = 31;\n     for(i =0 to length of str){\n        hash = hash*primes['a' - str.charAt[i]];\n     }\n     return hash;\n   }\n</code></pre>\n\n<p>Step 3: Now store all words in a HashMap.</p>\n\n<p>void loadDictionary(String[] words){</p>\n\n<pre><code>  for( word from words for i = 0 to length of words)   {\n     int hash  = getHashCode(word);\n     List&lt;String&gt; anagrams = dictionary.get(hash);\n     if(anagrams ! = null){\n         anagrams.add(word);\n     } else\n        List&lt;String&gt; newAnagrams = new ArrayList&lt;String&gt;();\n        newAnagrams.add(word);\n        dictionary.put(hash, newAnagrams);\n     }\n }\n}\n</code></pre>\n\n<p>Step 4: Now here is the approach to find anagrams:</p>\n\n<pre><code>   int findNumberOfAnagrams(String str){\n\n   List&lt;String&gt; anagrams = dictionary.get(getHashCode(str));\n      return anagrams.size();\n\n   }\n</code></pre>\n", 'ViewCount': '635', 'Title': 'Algorithm to write a dictionary using thousands of words to find all anagrams for a given string with O(1) complexity', 'LastEditorUserId': '6665', 'LastActivityDate': '2013-10-19T14:15:13.607', 'LastEditDate': '2013-10-19T11:43:38.863', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10848', 'Tags': '<algorithms><complexity-theory><time-complexity><strings>', 'CreationDate': '2013-10-19T07:27:25.860', 'FavoriteCount': '1', 'Id': '16221''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>This is the problem, given a string with characters from: <code>a-z</code>, <code>.</code>, <code>*</code>, and another string with characters from <code>a-z</code>. where <code>*</code> can delete the character before it, otherwise <code>*</code> is skipped and <code>.</code> can match any single character. the question is whether the first string can match the second one.</p>\n\n<p><strong>Note:</strong> That is the statement of the problem as I found, but in this case the character <code>*</code> performs the same function that <code>?</code> in a regular expression.</p>\n\n<p>Example:</p>\n\n<pre><code>isMatch("a*", "") = true; //"a*" could be "a" or an empty string ""\nisMatch(".", "") = false; \nisMatch("ab*", "a") = true; \nisMatch("a.", "ab") = true; \nisMatch("a", "a") = true;\n</code></pre>\n\n<p>I\'ve already solved this problem using a slightly modified edit distance, which I only know a 2D dynamic programming approach. I wonder whether exists a linear solution for this problem, maybe it is solvable without a dp approach?</p>\n', 'ViewCount': '75', 'Title': 'exact matching between two strings - linear edit distance?', 'LastActivityDate': '2013-10-21T22:57:59.747', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '16263', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10254', 'Tags': '<algorithms><dynamic-programming><regular-expressions><strings>', 'CreationDate': '2013-10-20T17:52:06.507', 'FavoriteCount': '1', 'Id': '16260''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Given a string $(a_0,a_1,\\ldots a_n)$. I want to find the length of the longest common prefix of the substrings $(a_0,a_1,\\ldots a_{n-1})$ and $(a_1,a_2,\\ldots a_n)$. I know this has atleast $O(n)$ complexity. Lets call this operation as <em>prefix-suffix match</em>.</p>\n\n<p>I want to calculate <em>prefix-suffix match</em> length for all suffixes of a string. Now the naive algorithm which doesn't take into account that all the strings for which I am doing this operation are related has $O(n^2)$ complexity. Now my question is can we do this in better complexity. </p>\n\n<p>Note that what I want is similar to LCP array of a slightly modified suffix array. Where the suffixes are sorted based on length instead of lexicographic ordering. </p>\n", 'ViewCount': '98', 'Title': 'String matching for all suffixes', 'LastActivityDate': '2013-10-24T16:07:22.660', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10915', 'Tags': '<algorithms><strings><suffix-array>', 'CreationDate': '2013-10-22T10:41:46.603', 'Id': '16328''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am trying to create a regular expression that will generate the following language under the {a,b,c} alphabet:\nall words that do not contain the substring "bbc"</p>\n\n<p>I am having a really hard time understanding how to approach this question. I have done several other questions where a certain substring must be excluded, but this one really messes with my logic.</p>\n\n<p>Thanks in advance</p>\n', 'ViewCount': '83', 'ClosedDate': '2013-11-08T23:00:27.200', 'Title': 'A little help with regular expressions', 'LastActivityDate': '2013-12-09T10:40:08.243', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11200', 'Tags': '<formal-languages><regular-expressions><substrings>', 'CreationDate': '2013-11-05T12:22:33.267', 'Id': '16735''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '30', 'Title': 'How can a Turing machine run another machine for an infinite amount of strings?', 'LastEditDate': '2013-12-11T19:01:19.183', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12032', 'FavoriteCount': '0', 'Body': "<p>The proof in my textbook, that $E_{TM}$ can be decided by oracle machine $O^{A_{TM}}$, uses a Turing machine $P$ such that for an input $w$:</p>\n\n<ul>\n<li>$P$ runs the Turing machine $M$ on all strings of $\\Sigma^*$</li>\n<li>If $M$ accepts the string, $P$ accepts</li>\n</ul>\n\n<p>$O^{A_{TM}}$ then asks the oracle if $&lt;P,w&gt; \\in A_{TM}$</p>\n\n<p>I can't seem to understand why $P$ can run $M$ for all strings of $\\Sigma^*$ because this is an infinite amount of strings. I do, however, understand that $P$ actually never has to run and is purely constructed to ask the oracle if it accepts.</p>\n", 'Tags': '<turing-machines><strings>', 'LastEditorUserId': '12032', 'LastActivityDate': '2013-12-11T19:06:05.330', 'CommentCount': '0', 'AcceptedAnswerId': '18888', 'CreationDate': '2013-12-11T18:48:35.790', 'Id': '18887''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Two strings $S$ and $T$ are said to be <em>conjugate</em> if there are two non-empty strings $A$ and $B$ such that $S = A+B$ and $T = B+A$ ($+$ is concatenation). How can I find if two strings are conjugate or not?</p>\n\n<p>Example: if <code>S="tokyo"</code> and <code>T="kyoto"</code>, then the pair $(S,T)$ is conjugate, because we can find <code>A="to"</code> and <code>B="kyo"</code>.</p>\n', 'ViewCount': '64', 'Title': 'Check if there exist A and B such that S=A+B and T=B+A', 'LastEditorUserId': '755', 'LastActivityDate': '2014-01-13T07:38:45.797', 'LastEditDate': '2014-01-13T07:38:45.797', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12759', 'Tags': '<algorithms><strings>', 'CreationDate': '2014-01-11T17:17:17.660', 'Id': '19657''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm a researcher working with a language that has gone through phonological changes through time.  I would like to tag parts of a word (i.e. prefix, stem, suffix) and then apply those phonological changes and then see what is left or different about the stuff that I tagged.</p>\n\n<p>I'm currently using Python with some regex stuff to apply the changes so if I can do this using its NPL toolkit that would be perfect.  I've start to mess around with it but I haven't found anything that will work just yet.  I'm also not sure if this toolkit would be the best for this.</p>\n\n<p>For example, I apply the following transformation to tag <code>re</code>, <code>peat</code> and <code>ed</code> in <code>repeated</code>:\n$$\n\\begin{align}\n  \\mathtt{repeated}\n  &amp; \\xrightarrow{\\mathtt{rep} \\mapsto \\mathtt{rp}} \\mathtt{rpeated} \\\\\n  &amp; \\xrightarrow{\\mathtt{ea} \\mapsto \\mathtt{e}} \\mathtt{rpeted} \\\\\n  &amp; \\xrightarrow{\\mathtt{d}\\$ \\mapsto \\epsilon} \\mathtt{rpete} \\\\\n\\end{align}\n$$</p>\n\n<p>I would like to be able to find out what is left of the stuff I tagged.  So I'd like to see that <code>r</code> is all that is left of the prefix, <code>pe</code> is all that is left of the stem, etc.  Any help or direction is greatly appreciated!</p>\n", 'ViewCount': '25', 'Title': 'Trying to tag parts of a word and keep track of any changes that happen to those parts', 'LastEditorUserId': '39', 'LastActivityDate': '2014-01-29T15:41:39.147', 'LastEditDate': '2014-01-29T15:41:34.770', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12849', 'Tags': '<algorithms><strings><natural-lang-processing><computational-linguistics>', 'CreationDate': '2014-01-14T19:56:01.060', 'Id': '19725''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>So, I've got this problem:</p>\n\n<blockquote>\n  <p>Given a string $\\omega\\in\\{0,\\ldots,9\\}^*$, find the smallest prime number (in base 10) that contains that string, or otherwise returns 0. </p>\n</blockquote>\n\n<p>What I'm asking is a fast algorithm for the problem?</p>\n", 'ViewCount': '107', 'Title': 'Fast ways to compute the smallest prime with a given substring?', 'LastEditorUserId': '31', 'LastActivityDate': '2014-01-23T20:58:12.430', 'LastEditDate': '2014-01-23T15:24:19.347', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11695', 'Tags': '<algorithms><strings><primes>', 'CreationDate': '2014-01-23T12:32:05.913', 'Id': '19910''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>CFG can specify structure of sentences but Regular grammar can only specify strings sequentially. Is it because DFA has only one bit memory?</p>\n', 'ViewCount': '63', 'ClosedDate': '2014-02-05T08:02:49.107', 'Title': 'Why CFG can specify structure of sentence but Regular grammar cannot?', 'LastEditorUserId': '8321', 'LastActivityDate': '2014-03-06T16:05:53.983', 'LastEditDate': '2014-03-06T16:05:53.983', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '947', 'Tags': '<regular-languages><context-free><formal-grammars><strings>', 'CreationDate': '2014-02-05T01:52:36.737', 'Id': '21306''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '178', 'Title': 'Algorithm Request: "Shortest non-existing substring over given alphabet"', 'LastEditDate': '2014-02-21T18:13:37.423', 'AnswerCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '14918', 'FavoriteCount': '1', 'Body': "<p>I'm looking for an (efficient) algorithm to solve the following problem:</p>\n\n<blockquote>\n  <p>Given a string $S$ and a set of characters $M$, find the shortest string composed only of characters in $M$ that is <em>not</em> contained in $S$.</p>\n</blockquote>\n\n<p>Try as I might, I can't seem to map this problem to any of the standard CS string problems.</p>\n", 'Tags': '<algorithms><data-structures><strings><substrings>', 'LastEditorUserId': '14918', 'LastActivityDate': '2014-02-22T09:38:12.063', 'CommentCount': '3', 'AcceptedAnswerId': '21901', 'CreationDate': '2014-02-21T17:58:42.620', 'Id': '21896''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u"<p>consider the pseudo code for calculating failure function:\nI partial understand the algorithm.\nKNUTH-MORRIS-PRATT FAILURE (P)</p>\n\n<p>Input:    Pattern with m characters\nOutput: Failure function f for P[i . . j]</p>\n\n<pre><code>i \u2190 1\nj \u2190 0\nf(0) \u2190 0\nwhile i &lt; m do\n    if P[j] = P[i]\n        f(i) \u2190 j +1\n        i \u2190 i +1\n        j\u2190 j + 1\nelse if j!=0\n     j \u2190 f(j - 1)\nelse\n    f(i) \u2190 0\n    i \u2190 i +1\n</code></pre>\n\n<p>The j in above code signifies the length of longest equal perfect prefix and suffix. So when P[i]==P[j], j is increased by 1, signifying that prefix suffix length has increased by 1(by appending P[i] to suffix and P[j] to prefix).</p>\n\n<p>But when P[i]!=P[j] and j!=0, why does the algo assign f(j-1) to j. What does that signify?</p>\n\n<p>I felt that when P[i]!=P[j], then we can't use the previous j value, so we have to assume lps[i]=0 and compare all possible prefixes to all possible suffixes and then find the longest prefix suffix match. I realise that the algorithm's way of dealing with P[i]!=P[j] is more efficient O(string len), but I just can't understand how it works. </p>\n", 'ViewCount': '38', 'Title': 'O(pattern_length) failure function in kmp algorithm', 'LastActivityDate': '2014-03-02T06:13:21.870', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15186', 'Tags': '<algorithms><algorithm-analysis><strings>', 'CreationDate': '2014-03-02T06:13:21.870', 'FavoriteCount': '1', 'Id': '22182''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>How different are string matching and integer matching in terms of time complexity?</p>\n\n<p>I'm asking this especially in relation to Rabin Karp algorithm. Why is it faster to compute hash code for every substring and check for equality of hashcode with the hashcode of the given string than the naive method of just checking if amy of the substrings match with the given string?</p>\n", 'ViewCount': '45', 'Title': 'string matching vs integer matching', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-03-11T00:18:50.563', 'LastEditDate': '2014-03-10T20:58:37.677', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '22485', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15506', 'Tags': '<algorithms><strings><substrings>', 'CreationDate': '2014-03-10T18:51:36.317', 'Id': '22480''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>(The question is an extension of <a href="http://stackoverflow.com/questions/9404909/algorithms-for-compression-of-set-tries">this</a> unanswered question on stackoverflow)</p>\n\n<p>If we have a set of strings, we can efficiently represent them with <a href="http://en.wikipedia.org/wiki/Trie" rel="nofollow">tries</a>. Common branches can also be merged, resulting in a DAG instead of a tree that is even more compact.</p>\n\n<p>However, if we have a set of sets (i.e. the order does not matter), there are a lot of possible tries that represent the same set of elements.\nAn example can be found in the stackoverflow question I linked above.</p>\n\n<p><strong>Edit:</strong> For example, assume that we are given the following sets of integers.</p>\n\n<pre><code>{1,2,3,4,5}\n{1,2,6,7}\n{1,2,4,7}\n{1,3,5,7}\n</code></pre>\n\n<p>Two possible representations are shown below (trie on the left, DAG on the right)</p>\n\n<p><img src="http://i.stack.imgur.com/fJr2z.png" alt="enter image description here"></p>\n\n<p>My questions are:</p>\n\n<blockquote>\n  <ol>\n  <li>How hard is the problem of finding an optimal (i.e minimal) such trie? </li>\n  <li>Are there any fast algorithms for solving this problem?</li>\n  <li>If not, are there any fast algorithms that find "good" tries?</li>\n  <li>What about the DAG case?</li>\n  </ol>\n</blockquote>\n\n<p>In the scenario I have in mind there is an additional constraint that no set is a subset of another set.</p>\n\n<p>Any link/paper that is even slightly relevant to any of the questions is helpful.</p>\n', 'ViewCount': '75', 'Title': 'Efficiently representing a set of sets', 'LastEditorUserId': '691', 'LastActivityDate': '2014-03-20T05:23:28.300', 'LastEditDate': '2014-03-19T16:06:09.610', 'AnswerCount': '3', 'CommentCount': '8', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '691', 'Tags': '<reference-request><data-structures><strings>', 'CreationDate': '2014-03-19T14:31:35.070', 'FavoriteCount': '1', 'Id': '22807''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I face this problem a lot while searching phone numbers and bank account numbers, when I do remember it partially. </p>\n\n<p>I save a draft in gmail with the content <code>I am mango</code>. Then I search it, by entering just <code>mango</code> and it gets me to the draft. </p>\n\n<p>But when I save a draft with some number such as <code>123987645</code> and try to search by entering <code>12398764</code> i.e just one character missing I fail to find it. Also I failed when I just typed  <code>87645</code>. </p>\n\n<p>Out of curiosity I am asking are the algorithms for finding numbers and text fundamentally different? Or I am missing something?</p>\n', 'ViewCount': '67', 'Title': 'Are algorithms for searching text vs searching numbers fundamentally different?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-23T12:58:54.220', 'LastEditDate': '2014-03-24T12:30:44.410', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<algorithms><search-algorithms><strings><matching>', 'CreationDate': '2014-03-24T12:01:50.507', 'Id': '22997''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p><em>The following may contain errors. It is precisely because I am not\nsure I understand the topic that I am asking questions. I do not have\nbooks about it and could not find an adequate reference on the web.</em></p>\n\n<p>I am discussing a problem regarding an enumeration of strings that\nshould be in <strong>amortized constant delay</strong>. From what I understood (but\nunderstanding that is part of my question), this means that the average\ntime taken for each answer should be independent of the size of the\nanswer, so that the total cost is $O(n)$ where $n$ is the number of\nanswers.</p>\n\n<p>My discussion partner went on to assert (I believe) that amortized\nconstant delay is possible for enumerating the strings accepted by a\ntrie, but not for enumerating the paths of a DAG. And I am at loss to\nsee a significant difference, since proper use of a stack should let\nme explore the DAG as if it had been exploded into a trie (by\nduplicating whatever is below a merge vertex).</p>\n\n<p>The only real difference I can see is that the accepting nodes of a\ntrie can be labeled with a single symbol identifier characterizing the accepted word (turning the trie\ninto a Moore machine) so that the total cost is only a traversal of\nthe trie, with single step output of the symbol label when traversing an\naccepting node.</p>\n\n<p>Such labeling identification is not possible for a DFA structured as a DAG, since an\naccepting node can correspond to different paths. The only way to name\npaths is to describe them in extenso (or nearly so: enough to disambiguate merges), so that the cost\nof the output by itself is already something like $O(n\\times s)$ where\n$s$ is the size of the longest path, thus entailing the same time cost\njust for doing the output.</p>\n\n<p>Where do I err, and what is the accepted wisdom and knowledge on this topic?\nPointers to web references are useful too.</p>\n', 'ViewCount': '31', 'Title': 'What is hiding behind amortized constant delay enumeration?', 'LastActivityDate': '2014-04-02T10:58:09.810', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8321', 'Tags': '<complexity-theory><graphs><strings><amortized-analysis><enumeration>', 'CreationDate': '2014-04-02T10:58:09.810', 'Id': '23337''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Title says it all pretty much. I do realize that often edit distance is defined as the minimum number of operations needed to transform one string to another, but I want something to point to that\'s even more general than that. </p>\n\n<p>I recently saw a brain teaser that claimed that some string was connected in a network to another as "friends" given an edit distance of one. It then went on to claim that friends of friends, friends of friends of friends, etc. (with no given upper bound on the degree of separation), were also in the network of that original string. I can\'t see how this definition of network doesn\'t include every possible string, and so I think the brain teaser is ill-formed. Given sufficient edits, a string can transform to any other string, right? -- but is there a name for that observation? I think this is so fundamental as to be near-impossible to Google, but there is always the distinct possibility of me being an idiot.</p>\n', 'ViewCount': '100', 'Title': 'Is there a basic proof that there exists some edit distance between two strings?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-03T07:54:13.697', 'LastEditDate': '2014-04-03T06:40:20.177', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '23385', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16402', 'Tags': '<strings><string-metrics><edit-distance>', 'CreationDate': '2014-04-03T04:06:27.853', 'Id': '23382''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Is there any specific name for strings of data that have well defined format ? For example URLS, domain names, IP Addresses, Email addresses, File Paths etc. are all having well defined delimiters and data formats. What are these special strings in general called ? </p>\n', 'ViewCount': '80', 'Title': 'What are these special strings called?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-10T17:39:11.273', 'LastEditDate': '2014-04-10T12:44:59.970', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '23635', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4421', 'Tags': '<terminology><strings>', 'CreationDate': '2014-04-10T12:41:52.730', 'Id': '23634''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>How would one search for a string of digits in a large digit sequence? For example, I'd like to search for <code>351814</code> in Euler's number. I'm not too keen on computer science, I'm a pure math major, so I don't really know how to begin. I also wouldn't know how to run said code.   </p>\n\n<p><strong>Any help would be greatly appreciated.</strong></p>\n", 'ViewCount': '85', 'ClosedDate': '2014-04-27T11:41:19.013', 'Title': 'Searching for a string of numbers in a large digit sequence', 'LastEditorUserId': '17106', 'LastActivityDate': '2014-04-27T11:41:04.027', 'LastEditDate': '2014-04-27T05:40:11.397', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16971', 'Tags': '<algorithms><search-algorithms><strings><binary-search>', 'CreationDate': '2014-04-22T00:40:36.540', 'Id': '24009''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>How would I go about making a Turing machine to accept the following language L?</p>\n\n<p>$$L = \\{ www \\mid w = \\{0,1\\}^* \\text{ and } w &gt; 0\\}$$</p>\n\n<p>I was thinking counting the number of symbols in the input string and then dividing by three to find the beginning of each instance of <em>w</em> and then testing if each instance is the same, but this seems a bit roundabout. </p>\n\n<p>I feel like there is a way by marking the first three symbols and then moving the 2nd and 3rd markers until the strings in between them are the same but I'm having a hard time articulating this into an algorithm.</p>\n\n<p>Can anyone point me in the right direction?</p>\n", 'ViewCount': '45', 'Title': 'Turing machine with repeated strings', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T10:19:18.573', 'LastEditDate': '2014-04-29T10:19:18.573', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24214', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14950', 'Tags': '<formal-languages><turing-machines><automata><strings>', 'CreationDate': '2014-04-28T13:35:58.237', 'Id': '24184''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Let\'s say you have the following sentence: "This is my first cs question posted here". How would I go about inserting the sentence into a search tree. Do I assign each word a number value and perform the insertions based on those? </p>\n', 'ViewCount': '15', 'Title': 'Inserting a sentence into search trees', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-29T08:37:33.313', 'LastEditDate': '2014-04-29T08:37:33.313', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '17159', 'Tags': '<data-structures><strings><search-trees>', 'CreationDate': '2014-04-29T01:30:52.450', 'Id': '24204''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}