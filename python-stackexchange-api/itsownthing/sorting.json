{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '45533', 'Title': 'Why is quicksort better than other sorting algorithms in practice?', 'LastEditDate': '2012-03-23T13:15:39.290', 'AnswerCount': '10', 'Score': '90', 'PostTypeId': '1', 'OwnerUserId': '24', 'FavoriteCount': '58', 'Body': '<p>In a standard algorithms course we are taught that <strong>quicksort</strong> is $O(n \\log n)$ on average and $O(n^2)$ in the worst case. At the same time, other sorting algorithms are studied which are $O(n \\log n)$ in the worst case (like <strong>mergesort</strong> and <strong>heapsort</strong>), and even linear time in the best case (like <strong>bubblesort</strong>) but with some additional needs of memory.</p>\n\n<p>After a quick glance at <a href="http://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_of_algorithms">some more running times</a> it is natural to say that quicksort <strong>should not</strong> be as efficient as others.</p>\n\n<p>Also, consider that students learn in basic programming courses that recursion is not really good in general because it could use too much memory, etc. Therefore (and even though this is not a real argument), this gives the idea that quicksort might not be really good because it is a recursive algorithm.</p>\n\n<p><strong>Why, then, does quicksort outperform other sorting algorithms in practice?</strong> Does it have to do with the structure of <em>real-world data</em>? Does it have to do with the way memory works in computers? I know that some memories are way faster than others, but I don\'t know if that\'s the real reason for this counter-intuitive performance (when compared to theoretical estimates).</p>\n\n<hr>\n\n<p><strong>Update 1:</strong> a canonical answer is saying that the constants involved in the $O(n\\log n)$ of the average case are smaller than the constants involved in other $O(n\\log n)$ algorithms. However, I have yet to see a proper justification of this, with precise calculations instead of intuitive ideas only.</p>\n\n<p>In any case, it seems like the real difference occurs, as some answers suggest, at memory level, where implementations take advantage of the internal structure of computers, using, for example, that cache memory is faster than RAM. The discussion is already interesting, but I\'d still like to see more detail with respect to memory-management, since it appears that <em>the</em> answer has to do with it.</p>\n\n<hr>\n\n<p><strong>Update 2:</strong> There are several web pages offering a comparison of sorting algorithms, some fancier than others (most notably <a href="http://www.sorting-algorithms.com/">sorting-algorithms.com</a>). Other than presenting a nice visual aid, this approach does not answer my question.</p>\n', 'Tags': '<algorithms><sorting>', 'LastEditorUserId': '24', 'LastActivityDate': '2014-03-12T10:54:49.140', 'CommentCount': '10', 'AcceptedAnswerId': '90', 'CreationDate': '2012-03-06T19:11:07.127', 'Id': '3'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '6955', 'Title': 'Adding elements to a sorted array', 'LastEditDate': '2012-04-01T07:07:56.053', 'AnswerCount': '5', 'Score': '18', 'PostTypeId': '1', 'OwnerUserId': '863', 'FavoriteCount': '1', 'Body': '<p>What would be the fastest way of doing this (from an algorithmic perspective, as well as a practical matter)?</p>\n\n<p>I was thinking something along the following lines.</p>\n\n<p>I could add to the end of an array and then use bubblesort as it has a best case (totally sorted array at start) that is close to this, and has linear running time (in the best case).</p>\n\n<p>On the other hand, if I know that I start out with a sorted array, I can use a binary search to find out the insertion point for a given element.</p>\n\n<p>My hunch is that the second way is nearly optimal, but curious to see what is out there.</p>\n\n<p>How can this best be done?</p>\n', 'Tags': '<algorithms><efficiency><arrays><sorting>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-06T17:17:29.770', 'CommentCount': '3', 'AcceptedAnswerId': '931', 'CreationDate': '2012-04-01T01:49:35.277', 'Id': '930'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have written a program to sort Linked Lists and I noticed that my insertion sort works much better than my quicksort algorithm. \nDoes anyone have any idea why this is?\nInsertion sort has a complexity of $\\Theta(n^2)$ and quicksort $O(n\\log n)$ so therefore quicksort should be faster. I tried for random input size and it shows me the contrary. Strange...</p>\n\n<p>Here the code in Java:</p>\n\n\n\n<pre><code>public static LinkedList qSort(LinkedList list) {\n\n    LinkedList x, y;\n    Node currentNode;\n    int size = list.getSize();\n\n    //Create new lists x smaller equal and y greater\n    x = new LinkedList();\n    y = new LinkedList();\n\n    if (size &lt;= 1)\n        return list;\n    else {\n\n        Node pivot = getPivot(list);\n        // System.out.println("Pivot: " + pivot.value);     \n        //We start from the head\n        currentNode = list.head;\n\n        for (int i = 0; i &lt;= size - 1; i++) {\n            //Check that the currentNode is not our pivot\n            if (currentNode != pivot) {\n                //Nodes with values smaller equal than the pivot goes in x\n                if (currentNode.value &lt;= pivot.value) {\n                    {\n                        x.addNode(currentNode.value);\n                        // System.out.print("Elements in x:");\n                        // x.printList();\n                    }\n\n                } \n                //Nodes with values greater than the pivot goes in y\n                else if (currentNode.value &gt; pivot.value) {\n                    if (currentNode != pivot) {\n                        y.addNode(currentNode.value);\n                        // System.out.print("Elements in y:");\n                        // y.printList();\n                    }\n                }\n            }\n            //Set the pointer to the next node\n            currentNode = currentNode.next;\n        }\n\n        //Recursive calls and concatenation of the Lists and pivot\n        return concatenateList(qSort(x), pivot, qSort(y));\n\n    }\n}\n</code></pre>\n', 'ViewCount': '3274', 'Title': 'Quicksort vs. insertion sort on linked list: performance', 'LastEditorUserId': '1011', 'LastActivityDate': '2013-02-01T13:07:24.713', 'LastEditDate': '2012-04-20T07:08:17.467', 'AnswerCount': '3', 'CommentCount': '6', 'AcceptedAnswerId': '1386', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1011', 'Tags': '<algorithms><algorithm-analysis><sorting><lists>', 'CreationDate': '2012-04-19T12:05:13.983', 'Id': '1354'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '4509', 'Title': 'Quicksort explained to kids', 'LastEditDate': '2012-04-19T21:11:51.423', 'AnswerCount': '4', 'Score': '10', 'OwnerDisplayName': 'd555', 'PostTypeId': '1', 'OwnerUserId': '1152', 'FavoriteCount': '3', 'Body': u'<p>Last year, I was reading a fantastic <a href="http://arxiv.org/abs/quant-ph/0510032">paper on \u201cQuantum Mechanics for Kindergarden\u201d</a>. It was not easy paper.</p>\n\n<p>Now, I wonder how to explain quicksort in the simplest words possible. How can I prove (or at least handwave) that the average complexity is $O(n \\log n)$, and what the best and the worst cases are, to a kindergarden class? Or at least in primary school?</p>\n', 'Tags': '<algorithms><education><algorithm-analysis><didactics><sorting>', 'LastEditorUserId': '5', 'LastActivityDate': '2012-04-20T14:53:59.763', 'CommentCount': '8', 'AcceptedAnswerId': '1369', 'CreationDate': '2012-04-19T20:23:14.023', 'Id': '1367'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I\'m working on problem H in the <a href="http://neerc.ifmo.ru/past/2004/problems/problems.pdf" rel="nofollow">ACM ICPC 2004\u20132005 Northeastern European contest</a>.</p>\n\n<p>The problem is basically to find the worst case that produces a maximal number of exchanges in the algorithm (sift down) to build the heap.</p>\n\n<ul>\n<li>Input: Input \ufb01le contains $n$ ($1 \\le n \\le 50{,}000$).</li>\n<li>Output:  Output the array containing $n$ different integer numbers from $1$ to $n$, such that it is a heap, and when converting it to a sorted array, the total number of exchanges in sifting operations is maximal possible.</li>\n</ul>\n\n<p>Sample input: <code>6</code><br>\nCorresponding output: <code>6 5 3 2 4 1</code></p>\n\n<p>And the basics outputs:</p>\n\n<pre><code>[2, 1]   \n[3, 2, 1]   \n[4, 3, 1, 2] \n[5, 4, 3, 2, 1] \n[6, 5, 3, 4, 1, 2]\n</code></pre>\n', 'ViewCount': '2275', 'Title': 'Finding a worst case of heap sort', 'LastEditorUserId': '1152', 'LastActivityDate': '2013-10-28T16:39:52.673', 'LastEditDate': '2012-04-28T13:55:03.753', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1152', 'Tags': '<algorithms><data-structures><algorithm-analysis><sorting>', 'CreationDate': '2012-04-27T21:28:44.810', 'FavoriteCount': '1', 'Id': '1540'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '749', 'Title': 'Sorting algorithms which accept a random comparator', 'LastEditDate': '2012-06-12T20:52:01.087', 'AnswerCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1642', 'FavoriteCount': '2', 'Body': u'<p>Generic sorting algorithms generally take a set of data to sort and a comparator function which can compare two individual elements. If the comparator is an order relation\xb9, then the output of the algorithm is a sorted list/array.</p>\n\n<p>I am wondering though which sort algorithms would actually <em>work</em> with a comparator that is not an order relation (in particular one which returns a random result on each comparison). By "work" I mean here that they continue return a permutation of their input and run at their typically quoted time complexity (as opposed to degrading to the worst case scenario always, or going into an infinite loop, or missing elements). The ordering of the results would be undefined however. Even better, the resulting ordering would be a uniform distribution when the comparator is a coin flip.</p>\n\n<p>From my rough mental calculation it appears that a merge sort would be fine with this and maintain the same runtime cost and produce a fair random ordering. I think that something like a quick sort would however degenerate,  possibly not finish, and not be fair.</p>\n\n<p>What other sorting algorithms (other than merge sort) would work as described with a random comparator?</p>\n\n<hr>\n\n<ol>\n<li><p>For reference, a comparator is an order relation if it is a proper function (deterministic) and satisfies the axioms of an order relation:</p>\n\n<ul>\n<li>it is deterministic: <code>compare(a,b)</code> for a particular <code>a</code> and <code>b</code> always returns the same result.</li>\n<li>it is transitive: <code>compare(a,b) and compare(b,c) implies compare( a,c )</code></li>\n<li>it is antisymmetric <code>compare(a,b) and compare(b,a) implies a == b</code></li>\n</ul></li>\n</ol>\n\n<p>(Assume that all input elements are distinct, so reflexivity is not an issue.)</p>\n\n<p>A random comparator violates all of these rules. There are however comparators that are not order relations yet are not random (for example they might violate perhaps only one rule, and only for particular elements in the set).</p>\n', 'Tags': '<algorithms><randomized-algorithms><sorting>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-03-20T18:11:29.530', 'CommentCount': '11', 'AcceptedAnswerId': '2349', 'CreationDate': '2012-06-12T11:39:54.473', 'Id': '2336'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am having trouble finding good resources that give a worst case $O(n \\ln n)$ <a href="http://en.wikipedia.org/wiki/In-place_algorithm">in place</a> <a href="http://www.algorithmist.com/index.php/Stable_Sort">stable</a> sorting algorithm.  Does anyone know of any good resources?</p>\n\n<p>Just a reminder, in place means it uses the array passed in and the sorting algorithm is only allowed to use constant extra space.  Stable means that elements with the same key appear in the same order in the sorted array as they did in the original.</p>\n\n<p>For example, naive merge sort is worst case $O(n \\ln n)$ and stable but uses $O(n)$ extra space.  Standard quicksort can be made stable, is in place but is worst case $O(n^2)$.  Heapsort is in place, worst case $O(n \\ln n)$ but isn\'t stable.  <a href="http://en.wikipedia.org/wiki/Sorting_algorithm">Wikipedia</a> has a nice chart of which sorting algorithms have which drawbacks.  Notice that there is no sorting algorithm that they list that has all three conditions of stability, worst case $O(n \\ln n)$ and being in place.</p>\n\n<p>I have found a paper called <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.22.8523&amp;rep=rep1&amp;type=pdf">"Practical in-place mergesort"</a> by Katajainen, Pasanen and Teuhola, which claims to have a worst case $O(n \\ln n)$ in place stable mergesort variant.  If I understand their results correctly, they use (bottom-up?) mergesort recursively on the first $\\frac{1}{4}$ of the array and the latter $\\frac{1}{2}$ of the array and use the second $\\frac{1}{4}$ as scratch space to do the merge.  I\'m still reading through this so any more information on whether I\'m interpreting their results correctly is appreciated.</p>\n\n<p>I would also be very interested in a worst case $O(n \\ln n)$ in place stable quicksort.  From what I understand, modifying quicksort to be worst case $O(n \\ln n)$ requires <a href="http://en.wikipedia.org/wiki/Selection_algorithm#Linear_general_selection_algorithm_-_Median_of_Medians_algorithm">selecting a proper pivot</a> which would destroy the stability that it would otherwise normally enjoy.</p>\n\n<p>This is purely of theoretical interest and I have no practical application.  I would just like to know the algorithm that has all three of these features.</p>\n', 'ViewCount': '1193', 'Title': 'Worst case $O(n \\ln n)$ in place stable sort?', 'LastActivityDate': '2013-10-27T16:22:39.590', 'AnswerCount': '3', 'CommentCount': '5', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '67', 'Tags': '<algorithms><reference-request><sorting>', 'CreationDate': '2012-07-01T14:50:37.140', 'FavoriteCount': '2', 'Id': '2569'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given an array $A$ of $N$ integers, each element in the array can be increased by a fixed number $b$ with some probability $p[i]$, $0 \\leq i &lt; n$. I have to find the expected number of swaps that will take place to sort the array using <a href="http://en.wikipedia.org/wiki/Bubble_sort" rel="nofollow">bubble sort</a>.</p>\n\n<p>I\'ve tried the following:</p>\n\n<ol>\n<li><p>The probability for an element $A[i] &gt; A[j]$ for $i &lt; j$ can be calculated easily from the given probabilities.</p></li>\n<li><p>Using the above, I have calculated the expected number of swaps as:</p>\n\n<pre><code>double ans = 0.0;\nfor ( int i = 0; i &lt; N-1; i++ ){\n    for ( int j = i+1; j &lt; N; j++ ) {\n        ans += get_prob(A[i], A[j]); // Computes the probability of A[i]&gt;A[j] for i &lt; j.\n</code></pre></li>\n</ol>\n\n<p>Basically I came to this idea because the expected number of swaps can be calculated by the number of inversions of the array. So by making use of given probability I am calculating whether a number $A[i]$ will be swapped with a number $A[j]$.</p>\n\n<p>Note that the initial array elements can be in any order, sorted or unsorted. Then each number can change with some probability. After this I have to calculate the expected number of swaps.</p>\n\n<p>I have posted <a href="http://stackoverflow.com/questions/11331314/number-of-swaps-in-bubble-sort">a similar question</a> before but it did not had all the constraints.</p>\n\n<p>I did not get any good hints on whether I am even on the right track or not, so I listed all the constraints here. Please give me some hints if I am thinking of the problem in an incorrect way.</p>\n', 'ViewCount': '2139', 'Title': 'Expected number of swaps in bubble sort', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-18T01:48:38.960', 'LastEditDate': '2012-07-09T08:40:49.420', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '9', 'OwnerDisplayName': 'TheRock', 'PostTypeId': '1', 'Tags': '<algorithms><algorithm-analysis><sorting><average-case>', 'CreationDate': '2012-07-05T08:44:10.770', 'FavoriteCount': '3', 'Id': '2630'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '202', 'Title': 'Is it possible to always construct a hamiltonian path on a tournament graph by sorting?', 'LastEditDate': '2012-07-09T09:07:50.400', 'AnswerCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2105', 'FavoriteCount': '1', 'Body': '<p>Is it possible to always construct a hamiltonian path on a <a href="http://en.wikipedia.org/wiki/Tournament_%28graph_theory%29#Paths_and_cycles" rel="nofollow">tournament graph</a> $G=(V,E)$ by sorting (using any sorting algorithm) with the following total order:</p>\n\n<p>$\\qquad \\displaystyle a \\leq b \\iff (a,b) \\in E \\lor \\left(\\exists\\, c \\in V. a \\leq c \\land c \\leq b\\right)$</p>\n\n<p>For context, this came from an observation that the inductive construction in the above page seems to be equivalent to insertion sort using the given order. Is it possible to use other sorting algorithms?</p>\n', 'Tags': '<algorithms><graph-theory><sorting>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-21T22:52:26.573', 'CommentCount': '2', 'AcceptedAnswerId': '2652', 'CreationDate': '2012-07-08T04:56:49.143', 'Id': '2646'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I have trouble understanding how to calculate the depth of a sorting network on $n$ inputs.</p>\n\n<p>For example, in case of selection sort, we have:</p>\n\n<p>$\\qquad \\displaystyle D(n)=D(n-1)+2\\\\\\qquad D(2)=1$</p>\n\n<p>which leads to</p>\n\n<p>$\\qquad \\displaystyle D(n)=2n-3=\\Theta(n)$</p>\n\n<p>I have confirmed that the depth of selection sort is equal to $2n-3$ by hand, but I can't understand how the recurrence $D(n)=D(n-1)+2$ is derived.</p>\n", 'ViewCount': '292', 'Title': 'How to calculate the depth of sorting networks?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-03T04:32:08.207', 'LastEditDate': '2012-07-30T07:08:14.057', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'OwnerDisplayName': 'Steven', 'PostTypeId': '1', 'Tags': '<algorithms><algorithm-analysis><recurrence-relation><sorting>', 'CreationDate': '2012-07-29T11:18:33.773', 'FavoriteCount': '1', 'Id': '2950'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>If you have a quick-sort algorithm, and you always select the smallest (or largest) element as your pivot; am I right in assuming that if you provide an already sorted data set, you will always get worst-case performance regardless of whether your 'already sorted' list is in ascending or descending order? </p>\n\n<p>My thinking is that, if you always choose the smallest element for your pivot, then whether your 'already-sorted' input is sorted by ascending or descending doesn't matter because the subset chosen to be sorted relative to your pivot will always be the same size?</p>\n", 'ViewCount': '433', 'Title': 'Does Quicksort always have quadratic runtime if you choose a maximum element as pivot?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-27T12:58:30.307', 'LastEditDate': '2012-08-31T07:28:12.087', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '3379', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2337', 'Tags': '<algorithms><time-complexity><algorithm-analysis><runtime-analysis><sorting>', 'CreationDate': '2012-08-31T04:24:50.107', 'Id': '3377'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '751', 'Title': 'Removing duplicates efficiently and with a low memory overhead', 'LastEditDate': '2012-10-19T08:35:43.330', 'AnswerCount': '1', 'Score': '7', 'OwnerDisplayName': 'doc', 'PostTypeId': '1', 'OwnerUserId': '2729', 'FavoriteCount': '3', 'Body': '<p>I want to filter efficiently a list of integers for duplicates in a way that only the resulting set needs to be stored.</p>\n\n<p>One way this can be seen:</p>\n\n<ul>\n<li>we have a range of integers $S = \\{1, \\dots{}, N\\}$ with $N$ big (say $2^{40}$)</li>\n<li>we have a function $f : S \\to S$ with, supposedly, many collisions (the images are uniformly distributed in $S$)</li>\n<li>we then need to store $f[S]$, that is $\\{f(x) | x \\in S\\}$</li>\n</ul>\n\n<p>I have a quite accurate (probabilistic) estimation of what $|f[S]|$ is, and can therefore allocate data structures in advance (say $|f[S]| \\approx 2^{30}$).</p>\n\n<p>I have had a few ideas, but I am not sure what would be the best approach:</p>\n\n<ul>\n<li>a bitset is out of the question because the input set does not fit into memory.</li>\n<li>a hash table, but (1) it requires some memory overhead, say 150% of $|f[S]|$ and (2) the table has to be explored when built which requires additional time because of the memory overhead.</li>\n<li>an "on the fly" sort, preferably with $O(N)$ complexity (non-comparison sort). Regarding that, I am not sure what is the major difference between <a href="http://en.wikipedia.org/wiki/Bucket_sort" rel="nofollow">bucket sort</a> and <a href="http://en.wikipedia.org/wiki/Flashsort" rel="nofollow">flashsort</a>.</li>\n<li>a simple array with a binary search tree, but this requires $O(N \\log |f[S]|)$ time.</li>\n<li>maybe using <a href="http://en.wikipedia.org/wiki/Bloom_filter" rel="nofollow">Bloom filters</a> or a similar data structure could be useful in a relaxation (with false positives) of the problem.</li>\n</ul>\n\n<p>Some questions on stackoverflow seem to tackle with this sort of things (<a href="http://stackoverflow.com/questions/12240997/sorting-array-in-on-run-time">http://stackoverflow.com/questions/12240997/sorting-array-in-on-run-time</a>, <a href="http://stackoverflow.com/questions/3951547/java-array-finding-duplicates">http://stackoverflow.com/questions/3951547/java-array-finding-duplicates</a>), but none seems to match my requirements.</p>\n', 'Tags': '<algorithms><data-structures><sorting>', 'LastEditorUserId': '2729', 'LastActivityDate': '2012-11-21T23:43:10.673', 'CommentCount': '17', 'CreationDate': '2012-09-03T10:11:36.747', 'Id': '3420'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1040', 'Title': 'Why does heapsort run in $\\Theta(n \\log n)$ instead of $\\Theta(n^2 \\log n)$ time?', 'LastEditDate': '2012-09-16T22:11:13.370', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1758', 'FavoriteCount': '1', 'Body': '<p>I am reading section 6.4 on Heapsort algorithm in CLRS, page 160.</p>\n\n<pre><code>HEAPSORT(A)  \n1 BUILD-MAX-HEAP(A)  \n2 for i to A.length downto 2  \n3   exchange A[i] with A[i]\n4   A.heap-size = A.heap-size-1  \n5   MAX-HEAPIFY(A,1)\n</code></pre>\n\n<p>Why is the running time, according to the book is $\\Theta (n\\lg{n})$ rather than $\\Theta (n^2\\lg{n})$ ? <code>BUILD-MAX-HEAP(A)</code> takes $\\Theta(n)$, <code>MAX-HEAPIFY(A,1)</code> takes $\\Theta(\\lg{n})$ and repeated $n-1$ times (line 3).</p>\n', 'Tags': '<algorithms><algorithm-analysis><landau-notation><sorting>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-09-16T22:11:13.370', 'CommentCount': '0', 'AcceptedAnswerId': '4579', 'CreationDate': '2012-09-16T20:47:58.343', 'Id': '4578'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I recently read an article <a href="http://www.scottaaronson.com/writings/bignumbers.html" rel="nofollow">Scott Aaronson - Big Numbers</a> . That has made me think about the effective upper-bound for sorting.</p>\n\n<p>According to the article, some of the big numbers like the number of particles in the universe and age of universe in milliseconds are less than $10^{100}$.</p>\n\n<p>In any realistic computational device, the data to be sorted will have to be lesser than these numbers. (As otherwise, it would be impossible to store the numbers physically).</p>\n\n<p>$\\log_2(10^{100}) \\approx 333$</p>\n\n<p>Hence, if we take a number $C &gt; 333$, we can show that number of steps required for sorting an input of size $n$ will always be lesser than $Cn$</p>\n\n<p>This makes sorting an $O(n)$ time operation using algorithms like QuickSort or HeapSort.</p>\n\n<p>Is there a point I\'ve wrongly considered while making this assumption? </p>\n\n<p><strong>Should we consider physical constraints while analyzing algorithms? If not, why?</strong></p>\n', 'ViewCount': '65', 'Title': 'Upper-bounding the number of comparisons for Sorting to $\\Theta(n)$ using a physically big number like Number of Particles in the Universe', 'LastActivityDate': '2012-09-24T04:08:05.383', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '4701', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2642', 'Tags': '<algorithm-analysis><sorting>', 'CreationDate': '2012-09-24T03:34:39.680', 'FavoriteCount': '1', 'Id': '4700'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '516', 'Title': 'Sorting as a linear program', 'LastEditDate': '2012-09-30T16:46:29.820', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '71', 'FavoriteCount': '3', 'Body': '<p>A surprising number of problems have fairly natural reductions to linear programming problems. See <a href="http://www.cs.berkeley.edu/~vazirani/algorithms/chap7.pdf">Chapter 7</a> of [1] for examples of network flows, bipartite matching, zero-sum games, shortest paths, a form of linear regression, and even circuit evaluation! </p>\n\n<p>Since circuit evaluation reduces to linear programming, any problem in $P$ must have a linear programming formulation. Therefore, we have a "new" sorting algorithm, via reduction to a linear program. So, my question is,\nwhat is the linear program that will sort an array of $n$ real numbers? What is the running time of the reduce-to-lp-and-solve sorting algorithm?</p>\n\n<hr>\n\n<ol>\n<li><a href="http://www.cs.berkeley.edu/~vazirani/algorithms/">Algorithms</a> by S. Dasgupta, C. Papadimitriou and U. Vazirani (2006)</li>\n</ol>\n', 'Tags': '<algorithms><sorting><linear-programming>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-02T03:55:41.983', 'CommentCount': '6', 'AcceptedAnswerId': '4823', 'CreationDate': '2012-09-30T01:19:11.290', 'Id': '4805'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What is the runtime complexity of the following implementation of Bubblesort (for integers)?</p>\n\n<pre><code>    #define SWAP(a,b)   { int t; t=a; a=b; b=t; }\n\n    void bubble( int a[], int n )\n    /* Pre-condition: a contains n items to be sorted */\n    {\n       int i, j;\n      /* Make n passes through the array */\n      for(i=0;i&lt;n-1;i++)\n      {\n     /* From the first element to the end\n       of the unsorted section */\n        for(j=1;j&lt;(n-i);j++)\n        {\n        /* If adjacent items are out of order, swap them */\n       if( a[j-1]&gt;a[j] ) SWAP(a[j-1],a[j]);\n       }\n    }\n}  \n</code></pre>\n', 'ViewCount': '282', 'Title': 'Complexity of optimized bubblesort', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-07T15:49:43.613', 'LastEditDate': '2012-10-07T15:49:43.613', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '3087', 'Tags': '<algorithms><algorithm-analysis><runtime-analysis><sorting>', 'CreationDate': '2012-10-07T09:52:54.087', 'Id': '4915'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In radix sort we first sort by least significant digit then we sort by second least significant digit and so on and end up with sorted list. </p>\n\n<p>Now if we have list of $n$ numbers we need $\\log n$ bits to distinguish between those number. So number of radix sort passes we make will be $\\log n$. Each pass takes $O(n)$ time and hence running time of radix sort is $O(n \\log n)$ </p>\n\n<p>But it is well known that it is linear time algorithm. Why? </p>\n', 'ViewCount': '3133', 'Title': 'Why is Radix Sort $O(n)$?', 'LastActivityDate': '2012-10-15T00:06:04.160', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '244', 'Tags': '<algorithms><sorting>', 'CreationDate': '2012-10-11T21:25:28.443', 'FavoriteCount': '1', 'Id': '5030'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '494', 'Title': 'Minimum space needed to sort a stream of integers', 'LastEditDate': '2012-10-22T19:53:01.833', 'AnswerCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4315', 'FavoriteCount': '1', 'Body': '<p>This question has gotten a lot of attention on SO:<br>\n<a href="http://stackoverflow.com/questions/12748246/sorting-1-million-8-digit-numbers-in-1mb-of-ram">Sorting 1 million 8-digit numbers in 1MB of RAM</a></p>\n\n<p>The problem is to sort a stream of 1 million 8-digit numbers (integers in the range $[0,\\: 99\\mathord{,}999\\mathord{,}999]$) using only 1 MB of memory ($2^{20}$ bytes = $2^{23}$ bits) and no external storage. The program must read values from an input stream and write the sorted result to an output stream.</p>\n\n<p>Obviously the entire input can\'t fit into memory, but clearly the result can be represented in under 1 MB since $2^{23} \\geq \\log_2 \\binom{10^8}{10^6} \\approx 8079302$ (it\'s a tight fit).</p>\n\n<p>So, what is the minimum amount of space needed to sort n integers with duplicates in this streaming manner, and is there an algorithm to accomplish the specified task?</p>\n', 'Tags': '<algorithms><sorting><space-complexity><data-compression><streaming-algorithm>', 'LastEditorUserId': '4315', 'LastActivityDate': '2012-10-23T10:13:54.180', 'CommentCount': '5', 'AcceptedAnswerId': '6246', 'CreationDate': '2012-10-22T18:13:46.890', 'Id': '6236'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Let's start with the comparison sorting lower bound proof, which I'll summarize as follows:</p>\n\n<ol>\n<li>For $n$ distinct numbers, there are $n!$ possible orderings.</li>\n<li>There is only one correct sorted sequence of the $n$ numbers.</li>\n<li>We are given that comparison ($&lt;$) is the only operation we have that can narrow down the $n!$ possible orderings, and each comparison has only two possible outcomes.</li>\n<li>So $\\log_2(n!)$ comparisons are required.</li>\n</ol>\n\n<p>Now consider the following generalization of the argument above:</p>\n\n<ol>\n<li>Define a space of possibilities and its size (in the case of sorting, $n!$ orderings)</li>\n<li>Define the goal state and its size (in this case, only one correctly sorted answer)</li>\n<li>Define the amount of information that is gained at each step of the computation (in this case, one bit since there are only two possible outcomes per comparison)</li>\n<li>Calculate the information difference between the space of possibilities (step 1) and the goal space (step 2) and divide by the information gain per step (step 3) to yield the lower bound on the number of steps (in this case, $(\\log_2(n!)$ - $\\log_2(1))$ / 1 = $\\log_2(n!)$).</li>\n</ol>\n\n<p>Please answer all the following questions. I'm less concerned with the correctness of the particulars of step 4 than I am with the correctness of steps 1 - 3.</p>\n\n<ol>\n<li>Are there any problems with the generalized argument?</li>\n<li>If the problems can be fixed, what are the fixes?</li>\n<li>If the problems can't be fixed, please point out the fatal ones and provide directions to sources which describe these lower-bounds proofs and their pitfalls.</li>\n</ol>\n", 'ViewCount': '274', 'Title': 'Generalizing the Comparison Sorting Lower Bound Proof', 'LastEditorUserId': '19', 'LastActivityDate': '2012-12-23T05:23:41.497', 'LastEditDate': '2012-11-08T16:36:29.557', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1295', 'Tags': '<proof-techniques><sorting><information-theory><check-my-proof><lower-bounds>', 'CreationDate': '2012-11-08T15:48:38.323', 'FavoriteCount': '1', 'Id': '6562'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>What is it about the structure of <a href="http://en.wikipedia.org/wiki/Counting_sort">counting sort</a> that only makes it work on integers?</p>\n\n<p>Surely strings can be counted?</p>\n\n<pre><code>\'\'\' allocate an array Count[0..k] ; initialize each array cell to zero ; THEN \'\'\'\nfor each input item x:\n    Count[key(x)] = Count[key(x)] + 1\ntotal = 0\nfor i = 0, 1, ... k:\n    c = Count[i]\n    Count[i] = total\n    total = total + c\n\n\'\'\' allocate an output array Output[0..n-1] ; THEN \'\'\'\nfor each input item x:\n    store x in Output[Count[key(x)]]\n    Count[key(x)] = Count[key(x)] + 1\nreturn Output\n</code></pre>\n\n<p>Where above does the linear time break down if you try to use counting sort on strings instead (assuming you have strings of fixed length)? </p>\n', 'ViewCount': '424', 'Title': 'Counting sort on non-integers - why not possible?', 'LastActivityDate': '2012-11-12T22:11:41.517', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '6642', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2826', 'Tags': '<algorithms><sorting>', 'CreationDate': '2012-11-12T21:12:07.090', 'Id': '6641'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm currently learning computer science, and there is a slide of notes brief described the parallel radix sort under data parallelism.</p>\n\n<pre><code>number 101 110 011 001 111 (1st bit)\norder    2   1   3   4   5 (new order)\nnumber 110 101 011 001 111 (2nd bit)\norder    3   1   4   2   5 (new order)\nnumber 101 001 110 011 111 (3rd bit)\norder    3   1   4   2   5 (new order)\nnumber 001 011 101 110 111\n</code></pre>\n\n<p>I roughly know how to sort it from lecturer's explanation, but how is it related to parallel computing to increase the performance?</p>\n", 'ViewCount': '400', 'Title': 'how does the parallel radix sort work?', 'LastActivityDate': '2012-11-24T11:37:28.147', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1895', 'Tags': '<sorting><parallel-computing>', 'CreationDate': '2012-11-24T11:37:28.147', 'Id': '6871'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm trying to understand a proof regarding radix-sort but to no avail.</p>\n\n<p>I'll first write down a brief summary of the proof and then assign some questions which I hope will be clarified enough.</p>\n\n<blockquote>\n  <p>Suppose you have an array of integer numbers in the range $\\{0,1,2,\\ldots n \\log n\\}$.\n  Show and explain an effective algorithm in the worst case which finds out if there are two elements with the same value.\n  note - You can use an extra memory in order of magnitude equals to $O(n)$.</p>\n</blockquote>\n\n<p>I don't really care about how the algorithm will look like. The idea to this proof is using radix-sort in $O(n)$ and then looking for two elements with the same value as the array is sorted.</p>\n\n<p><strong>The proof outline:</strong></p>\n\n<p>Let's suppose we are examining a larger domain which is $\\{0,1,2 ,\\ldots n^2 - 1\\}$.\nNow we'll treat each number according to its binary representation using radix-sort bit by bit.</p>\n\n<p>Right after this, comes the part I can't understand at all....</p>\n\n<p>As we know the order of magnitude of radix-sort is $\\Theta(d(n+k))$ and therefore all we have to decide is which a to choose to have order of magnitude equals to $O(n)$.</p>\n\n<p>using the formula $\\frac{2\\log n}{a}  (n + 2^a)$.</p>\n\n<p>After this step, you just choose $a = \\log n$ and you are done.</p>\n\n<p><strong>My questions are:</strong></p>\n\n<ol>\n<li><p>How did the writer concluded the following formula: \n$\\frac{2\\log n}{a}  (n + 2^a)$?</p></li>\n<li><p>Also, why do the writer prefer to work on the domain of $\\{0,1,2 ,\\ldots n^2 - 1\\}$ instead the one given in the question?</p></li>\n</ol>\n", 'ViewCount': '310', 'Title': 'Radix sort exercise', 'LastEditorUserId': '2205', 'LastActivityDate': '2012-12-02T08:16:39.277', 'LastEditDate': '2012-12-01T09:36:18.030', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '7100', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4514', 'Tags': '<algorithms><algorithm-analysis><sorting>', 'CreationDate': '2012-11-30T18:38:03.813', 'Id': '7051'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>What are the types of things that need to be considered if I need to sort a large random array of 0s and 1s? </p>\n\n<p>You can assume large array is in the order of million or billions.  </p>\n\n<p>I understand there are tons of sorting algorithms out there (quick, merge, radix,.etc.) and there are so many different data structures out there (trees, skip lists, linked lists, etc.) </p>\n\n<p>If somebody asks me to sort this large array, do I simply jump to Quick Sort and say that's the best solution? If not, what am I supposed to be thinking about? </p>\n\n<p>I'm not even sure if I know the right answer to this question, but I would really appreciate it if somebody in the community can give some advise. </p>\n\n<p>Thanks.</p>\n", 'ViewCount': '673', 'Title': 'If I have a large random array of 0s and 1s that I want to sort what kind of an algorithm and data structures should I consider?', 'LastActivityDate': '2012-12-09T19:51:24.157', 'AnswerCount': '4', 'CommentCount': '4', 'AcceptedAnswerId': '7264', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1480', 'Tags': '<sorting><big-data>', 'CreationDate': '2012-12-09T02:44:17.477', 'Id': '7262'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In their book <a href="http://www.amazon.co.uk/Randomized-Algorithms-Cambridge-International-Computation/dp/0521474655/ref=sr_1_1?ie=UTF8&amp;qid=1356380410&amp;sr=8-1"><em>Randomized Algorithms</em>,</a> Motwani and Raghavan open the introduction with a description of their RandQS function -- Randomized quicksort -- where the pivot, used for partitioning the set into two parts, is chosen at random.</p>\n\n<p>I have been racking my (admittedly somewhat underpowered) brains over this for some time, but I haven\'t been able to see what advantage this algorithm has over simply picking, say, the middle element (in index, not size) each time.</p>\n\n<p>I suppose what I can\'t see is this: if the initial set is in a random order, what is the difference between picking an element at a random location in the set and picking an element at a fixed position?</p>\n\n<p>Can someone enlighten me, in fairly simple terms? </p>\n', 'ViewCount': '1069', 'Title': 'What is the advantage of Randomized Quicksort?', 'LastActivityDate': '2014-05-03T22:52:13.613', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '7583', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '5178', 'Tags': '<algorithm-analysis><sorting><randomized-algorithms>', 'CreationDate': '2012-12-24T20:26:07.713', 'FavoriteCount': '1', 'Id': '7582'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Given a tube with numbered balls (random). The tube has holes to remove a ball. Consider the following steps for one operation:</p>\n\n<ol>\n<li>You can pick one or more balls from the holes and remember the order in which you picked the balls.</li>\n<li>You need to tilt the pipe towards left side so that remaining balls in the pipe shifts towards left and occupy the empty space created by removing the balls.</li>\n<li>You are not supposed to change the order in which you picked the numbered balls from the pipe. Now you put them back again in the pipe using the vacant space created by movement of balls.</li>\n</ol>\n\n<p>Steps 1 to 3 is considered as one operation.</p>\n\n<p>Find out the minimum operations required to sort the numbered balls in the ascending order.</p>\n\n<p>For example:\nIf tube contains: $[1\\ 4\\ 2\\ 3\\ 5\\ 6]$</p>\n\n<p>Then we can take out $4$ and $5$ and $6$, and if we tilt pipe to the left, we get $[1\\ 2\\ 3]$, and we insert $(4\\ 5\\ 6)$ in that order to the end of pipe to get $[1\\ 2\\ 3\\ 4\\ 5\\ 6]$.</p>\n\n<p>So minimum number of steps required is 1.  I need to find minimum operations to sort the pipe.</p>\n\n<p>Any ideas or hints on how to solve this problem?</p>\n', 'ViewCount': '363', 'Title': 'Interesting problem on sorting', 'LastEditorUserId': '4249', 'LastActivityDate': '2013-02-05T16:51:10.670', 'LastEditDate': '2013-02-05T11:44:26.733', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '6706', 'Tags': '<sorting><permutations>', 'CreationDate': '2013-02-04T20:01:40.007', 'FavoriteCount': '3', 'Id': '9486'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p><em><strong>Article:</em></strong>  </p>\n\n<h1>CC-Radix: a Cache Conscious Sorting Based on Radix sort</h1>\n\n<p><strong>(IEEE 2003)</strong></p>\n\n<p>I\'m trying to figure out what the author means by this section:</p>\n\n<blockquote>\n  <p>Explanation of CC-Radix For clarity reasons, we explain the recursive\n  version of CC-Radix sort as shown in Figure 3. However, we use the\n  iterative implementation of CC-Radix for the evaluations in this paper\n  because it is more efficient. The parameters of CC-Radix are bucket, which\n  is the data set to be sorted, and b, which is the number of bits of the\n  key that still have to be sorted. Constant b is explained below.</p>\n\n<pre><code>CC-Radix(bucket, b)\n\n\ufffcif fits in cache (bucket) then\n   Radix sort(bucket, b )\n\ufffc\ufffc\ufffc\ufffc\ufffc\ufffcelse\n   sub-buckets = Reverse sorting(bucket, ) \n   for each sub-bucket in sub-buckets\n      CC-Radix(sub-bucket, ) \nendfor\n\ufffc\ufffc\ufffc\ufffc\ufffcendif \nend\n</code></pre>\n  \n  <p>Figure 3. Pseudocode of CC-Radix The algorithm starts by checking\n  whether the data struc- tures to sort bucket fit in cache level Li.\n  Those data struc- tures are vectors S and D and the counter vectors C, one\n  for each of the digits of the key. If so, CC-Radix calls Radix sort.\n  If the data structures do not fit in cache level , the algorithm\n  partitions that bucket into sub-buckets by sorting the bucket by the\n  most significant digit using the counting algorithm (explained above).\n  Here, we call this process of partitioning, Reverse Sorting, and it\n  takes into account the computer architecture of the machine. For each\n  sub-bucket, the CC-Radix sort is called again. Note that the first\n  call to the routine processes the com- plete data set. Further calls\n  to the routine process sub- buckets. Note also that certain subsets of\n  the data may need more Reverse sorting calls than others depending on\n  the data skew.</p>\n  \n  <p>Now, we explain the details of Reverse sorting and the sizing of the\n  parameters of Radix sort. Reverse sorting. After each call of Reverse\n  sorting, the number of digits that remain to be sorted for a specific\n  sub- bucket is decremented by one.</p>\n</blockquote>\n\n<p>I don\'t understand the "Reverse Sorting" part of this - how is that supposed to work?</p>\n\n<p>I know this is a long shot, but I\'m really stuck on what they mean.  Any help is appreciated!</p>\n', 'ViewCount': '130', 'Title': 'Can someone help me understand cache conscience radix sort? (excerpt from journal article attached)', 'LastActivityDate': '2013-02-07T06:59:13.893', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9568', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6733', 'Tags': '<algorithms><sorting>', 'CreationDate': '2013-02-06T15:17:52.903', 'Id': '9547'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In Corman, Introduction To Algorithms, 3rd edition, question 2-4 it asks to count the number of inversions in a list of numbers in $\\theta( n \\lg n )$ time.  He uses a modified Merge Sort to accomplish this.  However, there is something in his algorithm which seems redundant / unnecessary to me:</p>\n\n<pre><code>MERGE-INVERSIONS(A, p, q, r)\nn1 = q - p + 1\nn2 = r - q\nlet L[1 ... n1 + 1] and R[1 ... n2 + 1] be new arrays\nfor i = 1 to n1\n    L[i] = A[p + i - 1]\nfor j = 1 to n2\n    R[j] = A[q + j] \nL[n1 + 1] = infinity\nR[n2 + 1] = infinity\ni = 1\nj = 1\ninversions = 0\ncounted = FALSE\nfor k = p to r\n    if counted == FALSE and R[j]  &lt; L[i]\n        inversions = inversions + n1 - i + 1\n        counted = TRUE\n    if L[i] &lt;= R[j] \n        A[k] = L[i]\n        i++\n    else A[k] = R[j] \n        j++\n        counted = FALSE\nreturn inversions\n</code></pre>\n\n<p>The <code>counted</code> variable seems redundant to me and I would have written the last for loop as follows:</p>\n\n<pre><code>inversions = 0\nfor k = p to r\n    if L[i] &lt;= R[j] \n        A[k] = L[i]\n        i++\n    else A[k] = R[j] \n        inversions = inversions + n1 - i + 1\n        j++\nreturn inversions\n</code></pre>\n\n<p>What am I missing, or is <code>counted</code> really unnecessary?</p>\n', 'ViewCount': '959', 'Title': 'Counting Inversions Using Merge Sort', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-17T11:56:28.703', 'LastEditDate': '2013-02-17T11:38:20.870', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9861', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6728', 'Tags': '<algorithms><algorithm-analysis><sorting><program-correctness>', 'CreationDate': '2013-02-17T10:23:24.240', 'Id': '9858'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1038', 'Title': 'Worst case analysis of bucket sort using insertion sort for the buckets', 'LastEditDate': '2013-02-18T22:03:28.823', 'AnswerCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6815', 'FavoriteCount': '1', 'Body': '<p>Suppose I am using the <a href="http://en.wikipedia.org/wiki/Bucket_sort#Pseudocode" rel="nofollow">Bucket-Sort</a> algorithm, and on each bucket/list I sort with insertion sort (replace nextSort with insertion sort in the wikipedia pseudocode).</p>\n\n<p>In the worst case, this would imply that we would have $O(n^2)$ performance, because if every element was in one bucket, then we would have to use insertion sort on $n$ elements which is $O(n^2)$. </p>\n\n<p>So the first thing that comes to mind to fix the worst case running time is to not use insertion-sort, because it is $O(n^2)$. Instead we could use merge-sort or heap-sort m, because the worst case running time for both of those algorithms is $O(n\\log n)$. However, if we use merge-sort and heap-sort, do they preserve the expected linear running-time of bucket-sort?</p>\n', 'Tags': '<algorithms><algorithm-analysis><runtime-analysis><sorting>', 'LastEditorUserId': '472', 'LastActivityDate': '2013-02-18T22:03:28.823', 'CommentCount': '1', 'AcceptedAnswerId': '9882', 'CreationDate': '2013-02-18T01:16:55.900', 'Id': '9876'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Some sorting algorithms like counting sort/insertion sort can work in $O(n)$ time while other algorithms such as quicksort require $O(n \\log n)$ time.</p>\n\n<p>As I understand it, it's not always possible to use the $O(n)$ sorting algorithms. What are those cases when they can not be used?</p>\n", 'ViewCount': '115', 'Title': 'When can one use a $O(n)$ time sorting algorithm?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-02-20T14:59:51.977', 'LastEditDate': '2013-02-20T14:59:51.977', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '9967', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6821', 'Tags': '<algorithms><sorting>', 'CreationDate': '2013-02-20T12:19:32.960', 'Id': '9965'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a quick question on the bubble sort algorithm. Why does it perform $\\Theta(n^2)$ comparisons on an $n$ element list?</p>\n\n<p>I looked at the Wikipedia page and it does not seem to tell me. I know that because of its magnitude it takes a lot of work with large numbers.</p>\n', 'ViewCount': '541', 'Title': 'Why does bubble sort do $\\Theta(n^2)$ comparisons on an $n$ element list?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-27T12:14:10.343', 'LastEditDate': '2013-02-25T07:26:15.987', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '10061', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '7002', 'Tags': '<algorithms><algorithm-analysis><sorting>', 'CreationDate': '2013-02-24T18:04:04.793', 'Id': '10058'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Inspired by <a href="http://cs.stackexchange.com/q/2336/71">this question</a> in which the asker wants to know if the running time changes when the comparator used in a standard search algorithm is replaced by a fair coin-flip, and also <a href="http://www.robweir.com/blog/2010/02/microsoft-random-browser-ballot.html">Microsoft\'s</a> prominent failure to write a uniform permutation generator, my question is thus:</p>\n\n<p>Is there a comparison based sorting algorithm which will, depending on our implementation of the comparator:</p>\n\n<ol>\n<li>return the elements in sorted order when using a <em>true</em> comparator (that is, the comparison does what we expect in a standard sorting algorithm) </li>\n<li>return a uniformly random permutation of the elements when the comparator is replaced by a fair coin flip (that is, return <code>x &lt; y = true</code> with probability 1/2, regardless of the value of x and y)</li>\n</ol>\n\n<p>The code for the sorting algorithm must be the same. It is only the code inside the comparison "black box" which is allowed to change.</p>\n', 'ViewCount': '296', 'Title': 'Is there a "sorting" algorithm which returns a random permutation when using a coin-flip comparator?', 'LastActivityDate': '2013-03-23T11:27:52.923', 'AnswerCount': '2', 'CommentCount': '6', 'AcceptedAnswerId': '10658', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '71', 'Tags': '<sorting><randomized-algorithms><permutations>', 'CreationDate': '2013-03-20T18:14:44.773', 'Id': '10656'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p><strong>Definition:</strong> A preserved invariant of a state machine is a predicate, $P$, on\nstates, such that whenever $P(q)$ is true of a state, $q$, and $q  \\rightarrow r$ for some state, $r$,\nthen $P(r)$ holds.</p>\n\n<p><strong>Definition:</strong> A line graph is a graph whose edges are all on one path.</p>\n\n<p><strong>Definition:</strong> Formally, a state machine is nothing more than a binary relation on a set, except\nthat the elements of the set are called \u201cstates,\u201d the relation is called the transition\nrelation, and an arrow in the graph of the transition relation is called a transition.\nA transition from state $q$ to state $r$ will be written $q \\rightarrow r$.</p>\n\n<p><strong>DAG</strong>: Directed Acylic Graph</p>\n\n<blockquote>\n  <p>The following procedure can be applied to any directed graph, $G$:</p>\n  \n  <ol>\n  <li>Delete an edge that is in a cycle.</li>\n  <li>Delete edge $&lt;u \\rightarrow v&gt;$ if there is a path from vertex $u$ to vertex $v$ that does not\n  include $&lt;u \\rightarrow v&gt;$.</li>\n  <li>Add edge $&lt;u \\rightarrow v&gt;$ if there is no path in either direction between vertex $u$ and\n  vertex $v$.</li>\n  </ol>\n  \n  <p>Repeat these operations until none of them are applicable.</p>\n</blockquote>\n\n<p>This procedure can be modeled as a state machine. The start state is $G$, and the\nstates are all possible digraphs with the same vertices as $G$.</p>\n\n<p><strong>(b)</strong> Prove that if the procedure terminates with a digraph, $H$, then $H$ is a line\ngraph with the same vertices as $G$.</p>\n\n<p>Hint: Show that if $H$ is not a line graph, then some operation must be applicable.</p>\n\n<p><strong>(c)</strong> Prove that being a DAG is a preserved invariant of the procedure.</p>\n\n<p><strong>(d)</strong> Prove that if $G$ is a DAG and the procedure terminates, then the walk relation\nof the final line graph is a topological sort of $G$.</p>\n\n<p>Hint: Verify that the predicate\n$P(u,v)$:: there is a directed path from $u$ to $v$\nis a preserved invariant of the procedure, for any two vertices $u, \\ v$ of a DAG.</p>\n\n<p><strong>(e)</strong> Prove that if $G$ is finite, then the procedure terminates.</p>\n\n<p>Hint: Let $s$ be the number of cycles, $e$ be the number of edges, and $p$ be the number\nof pairs of vertices with a directed path (in either direction) between them. Note\nthat $p \\leq n^2$ where $n$ is the number of vertices of $G$. Find coefficients $a,b,c$ such\nthat as+bp+e+c is nonnegative integer valued and decreases at each transition.</p>\n\n<blockquote>\n  <p><em><strong>My Problems:</em></strong></p>\n  \n  <p>I got stuck with problems $d$ and $e$ but solutions to other problems are welcome too.</p>\n  \n  <p>At problem  $d$, <strong>I could not understand the hint and why it is given, how it helps</strong>. </p>\n</blockquote>\n\n<p>In my way for proving $d$, I am trying to show that given procedure always preserves the order of vertices, which are associated with edges, on the start graph $G$. So a line graph is automatically a topological sort since the "precedence order" of the vertices are preserved. </p>\n\n<blockquote>\n  <p>But procedure number $3$ is problematic, <strong>how to show it preserves precedence ?</strong></p>\n</blockquote>\n', 'ViewCount': '486', 'Title': 'A procedure for Topological sort, proof for its correctness', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-18T19:45:06.263', 'LastEditDate': '2013-09-20T15:21:45.287', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '7337', 'Tags': '<algorithms><algorithm-analysis><sorting><correctness-proof>', 'CreationDate': '2013-03-23T20:42:41.853', 'Id': '10720'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Given $n$ arrays of size $k$ each, we want to show that at least $\\Omega(nk \\log k)$ comparisons are needed to sort all arrays (indepentent of each other). </p>\n\n<p>My proof is a simple modification of the decision tree argument used to obtain the lower bound for comparison-based sorting of one array. More specifically, I argue that there are in total $k!^n$ possible permutations for the entries in all given arrays, and that a binary tree with that number of leaves is of height $h \\in \\Omega(nk \\log k)$. Is that argument correct? </p>\n\n<p>Furthermore, I was told that merely observing that one needs $\\Omega(k \\log k)$ comparisons for each of the arrays and we need to sort $n$ times in total (for $n$ arrays) is <em>not</em> a sufficient argument. Why is that? My answer would be that this is just <em>one</em> possible approach to this problem, and not a general argument excluding each and every other potential comparison-based algorithm for solving the given task with less than $\\Omega(nk \\log k)$ comparisons. \nHowever, this is not particularly concise and I would consider a rather technical argument (which I don't see) as more appropriate. What would that be?</p>\n", 'ViewCount': '132', 'Title': 'Lower bound for sorting n arrays of size k each', 'LastEditorUserId': '7486', 'LastActivityDate': '2013-03-29T13:24:00.140', 'LastEditDate': '2013-03-29T13:24:00.140', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '10893', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7486', 'Tags': '<algorithms><sorting><arrays><lower-bounds><check-my-proof>', 'CreationDate': '2013-03-29T12:07:19.733', 'Id': '10890'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '409', 'Title': 'Sort array of 5 integers with a max of 7 compares', 'LastEditDate': '2013-04-02T08:10:20.363', 'AnswerCount': '2', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '6728', 'FavoriteCount': '2', 'Body': "<p>How can I sort a list of 5 integers such that in the worst case it takes 7 compares?  I don't care about how many other operations are performed.  I don't know anything particular about the integers.</p>\n\n<p>I've tried a few different divide and conquer approaches which get me down to 8 compares, such as following a mergesort approach, or combining mergesort with using binary search to find the insertion position, but every time I end up with 8 compares worst case.</p>\n\n<p>Right now I'm just looking for a hint, not a solution.</p>\n", 'Tags': '<algorithms><sorting>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-29T17:52:49.513', 'CommentCount': '9', 'AcceptedAnswerId': '10968', 'CreationDate': '2013-04-01T18:18:44.710', 'Id': '10960'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_of_algorithms" rel="nofollow">Wiki</a> has a good cheat sheet, but however it does not involve no. of comparisons or swaps. (though no. of swaps is usually decides its complexity). So I created the following. Is the following info is correct ? Please let me know if there is any error, I will correct it.</p>\n\n<p><strong>Insertion Sort:</strong></p>\n\n<ul>\n<li>Average Case / Worst Case : $\\Theta(n^2)$ ; happens when input is\nalready sorted in descending order</li>\n<li>Best Case : $\\Theta(n)$ ; when input is already sorted</li>\n<li>No. of comparisons : $\\Theta(n^2)$ in worst case &amp; $\\Theta(n)$ in best case</li>\n<li>No. of swaps : $\\Theta(n^2)$ in worst/average case &amp; $0$ in Best case</li>\n</ul>\n\n<p><strong>Selection Sort:</strong></p>\n\n<ul>\n<li>Average Case / Worst Case / Best Case: $\\Theta(n^2)$ </li>\n<li>No. of comparisons : $\\Theta(n^2)$</li>\n<li>No. of swaps : $\\Theta(n^2)$ in worst/average case &amp; $0$ in best case</li>\n</ul>\n\n<p><strong>Merge Sort :</strong></p>\n\n<ul>\n<li>Average Case / Worst Case / Best case : $\\Theta(nlgn)$ ; doesn\'t matter at all whether the input is sorted or not</li>\n<li>No. of comparisons : $\\Theta(n+m)$ in worst case &amp; $\\Theta(n)$ in best case ; assuming we are merging two array of size n &amp; m where $n&lt;m$</li>\n<li>No. of swaps : No swaps ! [but requires extra memory, not in-place sort]</li>\n</ul>\n\n<p><strong>Quick Sort:</strong></p>\n\n<ul>\n<li>Worst Case : $\\Theta(n^2)$ ; happens input is already sorted</li>\n<li>Best Case : $\\Theta(nlogn)$ ; when pivot divides array in exactly half</li>\n<li>No. of comparisons : $\\Theta(n^2)$ in worst case &amp; $\\Theta(nlogn)$ in best case</li>\n<li>No. of swaps : $\\Theta(n^2)$ in worst case &amp; $0$ in best case</li>\n</ul>\n\n<p><strong>Bubble Sort:</strong></p>\n\n<ul>\n<li>Worst Case : $\\Theta(n^2)$</li>\n<li>Best Case : $\\Theta(n)$ ; on already sorted</li>\n<li>No. of comparisons : $\\Theta(n^2)$ in worst case &amp; best case</li>\n<li>No. of swaps : $\\Theta(n^2)$ in worst case &amp; $0$ in best case</li>\n</ul>\n\n<p><strong>Linear Search:</strong></p>\n\n<ul>\n<li>Worst Case : $\\Theta(n)$ ; search key not present or last element</li>\n<li>Best Case : $\\Theta(1)$ ; first element</li>\n<li>No. of comparisons : $\\Theta(n)$ in worst case &amp; $1$ in best case</li>\n</ul>\n\n<p><strong>Binary Search:</strong></p>\n\n<ul>\n<li>Worst case/Average case : $\\Theta(logn)$</li>\n<li>Best Case : $\\Theta(1)$ ; when key is middle element</li>\n<li>No. of comparisons : $\\Theta(logn)$ in worst/average case &amp; $1$ in best case</li>\n</ul>\n\n<hr>\n\n<ol>\n<li>I have considered only basic searching &amp; sorting algorithms. </li>\n<li>It is assumed above that sorting algorithms produce output in ascending order</li>\n<li>Sources : The awesome <a href="http://rads.stackoverflow.com/amzn/click/0262033844" rel="nofollow">CLRS</a> and this <a href="http://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_of_algorithms" rel="nofollow">Wiki</a></li>\n</ol>\n', 'ViewCount': '9952', 'ClosedDate': '2014-02-09T15:34:28.957', 'Title': 'Complexities of basic operations of searching and sorting algorithms', 'LastActivityDate': '2014-02-09T07:07:24.577', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6665', 'Tags': '<algorithm-analysis><asymptotics><runtime-analysis><sorting><searching>', 'CreationDate': '2013-04-03T13:09:39.333', 'FavoriteCount': '1', 'Id': '10991'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '5058', 'Title': 'Quicksort Partitioning: Hoare vs. Lomuto', 'LastEditDate': '2013-04-21T15:09:19.573', 'AnswerCount': '1', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '6728', 'FavoriteCount': '4', 'Body': '<p>There are two quicksort partition methods mentioned in Cormen:</p>\n\n<pre><code>Hoare-Partition(A, p, r)\nx = A[p]\ni = p - 1\nj = r + 1\nwhile true\n    repeat\n        j = j - 1\n    until A[j] &lt;= x\n    repeat\n        i = i + 1\n    until A[i] &gt;= x\n    if i &lt; j\n        swap( A[i], A[j] )\n    else\n        return j\n</code></pre>\n\n<p>and:</p>\n\n<pre><code>Lomuto-Partition(A, p, r)\nx = A[r]\ni = p - 1\nfor j = p to r - 1\n    if A[j] &lt;= x\n        i = i + 1\n        swap( A[i], A[j] )\nswap( A[i +1], A[r] )\nreturn i + 1\n</code></pre>\n\n<p>Disregarding the method of choosing the pivot, in what situations is one preferable to the other?  I know for instance that Lomuto preforms relatively poorly when there is a high percentage of duplicate values ( i.e. where say more than 2/3rds the array is the same value ), where as Hoare performs just fine in that situation.</p>\n\n<p>What other special cases make one partition method significant better than the other?</p>\n', 'Tags': '<algorithms><sorting><quicksort>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-25T07:17:36.723', 'CommentCount': '2', 'AcceptedAnswerId': '11550', 'CreationDate': '2013-04-21T08:02:32.013', 'Id': '11458'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have come across the following problem.</p>\n\n<p>You have $N$ registers, numbered $1,2,\\dots, N$, each of which can hold an integer value. You\nare given the initial values of the registers, which have the property that every number\nfrom $1, \\dots, N$ occurs exactly once among the $N$ registers.</p>\n\n<p>Each register has a "<strong>reset button</strong>": pressing the reset button on register $i$ changes its value to $i$. </p>\n\n<p>In one move you can pick any subset of the registers (say, registers $3, 5, 9$) and simultaneously press all their reset buttons. </p>\n\n<p><strong>However you must ensure that\nevery number from $1,2,\\dots, N$ continues to occur exactly once amongst the $N$ registers</strong>.</p>\n\n<p>The cost of a move that resets $m$ registers simultaneously is $m^2$.</p>\n\n<p>You can perform a\nsequence of such moves one after the other, and the total cost is the sum of the costs\nof the individual moves.</p>\n\n<p>Register $i$ is said to be stable if it contains the value $i$. Given a target $K$, where $K \\le N$,\nthe goal is to perform a sequence of moves at the end of which at least $K$ registers are\nstable. </p>\n\n<p><strong>Find the minimum possible cost for achieving this.</strong></p>\n\n<p>My attempt on problem:</p>\n\n<p>Let $A[1, \\dots, n]$ be given registers with initial values.</p>\n\n<pre><code>1. Divide $A$ into Disjoint Sets \n2. For each disjoint set maintain the number of elements in it. \n3. Find the minimum operations from these subsets(explained below with example)\n</code></pre>\n\n<p>Example:</p>\n\n<pre><code>Register:      1  2  3  4  5  6  7  8  9  10  11\n\nInitial Value: 11 3  6  9  8  4  1  5  10  2  7\n</code></pre>\n\n<p>and $K=7$</p>\n\n<p>Since Every number should be in the register we need to <code>reset</code> set of registers as shown below.</p>\n\n<p>We can Reset $1,11,7$ in a single <code>RESET</code> operation.</p>\n\n<p>Similarly we can reset $2,3,6,4,9,10$ and $5,8$ in a single <code>RESET</code> operation.</p>\n\n<p>So we now have $3$ disjoint subsets of $A$</p>\n\n<p>Let </p>\n\n<p>$S_1=\\{1,11,7\\}$, note that  $|S1|=3$</p>\n\n<p>$S_2=\\{2,3,6,4,9,10\\}$, $|S2|=6$</p>\n\n<p>$S_3=\\{5,8\\}$ and $|S3|=2$</p>\n\n<p>So Minimum number of operations for $K=7$ is $(6^2+2^2)=40$.</p>\n\n<p>Now we need to find minimum number of oprations form these three subset. </p>\n\n<p>more formally Given $S=\\{S_1, S_2, \\dots, S_n\\}$ we need to find Subset $\\{S_{i_1},S{i_2}, \\dots, S_{i_p}\\}$ such that </p>\n\n<p>$\\sum_{j=1}^{p} S_{i_j} \\ge K $ and $\\sum_{j=1}^{p} S_{i_j}^2$ is as minimum as possible.</p>\n\n<p>How to efficiently find the minimum number of operations from these subsets?</p>\n\n<p>Any Alternative solution(s)?</p>\n', 'ViewCount': '145', 'Title': 'Sorting Problem', 'LastEditorUserId': '139', 'LastActivityDate': '2013-05-03T02:14:58.017', 'LastEditDate': '2013-05-02T15:00:47.223', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4752', 'Tags': '<dynamic-programming><sorting><permutations>', 'CreationDate': '2013-05-02T09:08:47.950', 'FavoriteCount': '1', 'Id': '11724'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>The exercises in a textbook I studied asks about the best case for shell sort. I have scribbled a derivation for the same along the margins almost two years ago. Basically I don't know if this was my own derivation or one copied from an authoritative source. </p>\n\n<p>I have elaborated upon the same below. Could you let me know if the reasoning is right here?</p>\n\n<ul>\n<li>The least number of comparisons occur when the data is completely sorted.</li>\n<li>For a particular value of the increment, say, $h_i$, each of the $h_i$ sub-sequences require at most one less comparison than the number of elements in the sub-sequence(as insertion sort is used) which is,${N \\over h_i} - 1$ ,where N is the total number of data items.</li>\n<li>For the given data in this situation $h_i \\times \\left (N \\over h_i - 1 \\right ) = N - h_i$ number of comparisons are needed as there are $h_i$ sub-sequences.</li>\n<li>If the increment sequence selected is has $k$ increments(such that $h_k = 1$), the total number of comparisons required would be $C(N) \\ge (N - h_i) + (N - h_2) + ... + (N - h_k) = kN - \\sum h_i = O(N)$</li>\n</ul>\n", 'ViewCount': '369', 'Title': 'Best case analysis for shell sort', 'LastActivityDate': '2013-05-03T02:56:18.547', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2980', 'Tags': '<algorithms><data-structures><algorithm-analysis><sorting>', 'CreationDate': '2013-05-03T02:56:18.547', 'FavoriteCount': '1', 'Id': '11749'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m wondering if there is a standard way of measuring the "sortedness" of an array?  Would an array which has the median number of possible inversions be considered maximally unsorted?  By that I mean it\'s basically as far as possible from being either sorted or reverse sorted.</p>\n', 'ViewCount': '435', 'Title': 'How to measure "sortedness"', 'LastActivityDate': '2013-05-06T19:27:56.507', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11837', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '6728', 'Tags': '<sorting>', 'CreationDate': '2013-05-06T17:38:13.740', 'FavoriteCount': '4', 'Id': '11836'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m trying to understand why quicksort using Lomuto partition and a fixed pivot is performing erratically, but overall poorly, on randomly generated inputs.  I\'m thinking that even though the inputs are randomly generated, there may be allot of order to the sequences, but I\'m not sure how to measure the level of disorder in the sequences.  I thought about using the number of inversions, but I saw from <a href="http://cs.stackexchange.com/q/11836/6728">this other question I asked</a> that that\'s not really a good measure in this case.</p>\n\n<p>The reason I suspect that my random sequences have allot of "order" to them is that randomizing the pivot fixes the performance problem.  But theoretically there shouldn\'t be an performance problem on these supposedly "random" input sequences.</p>\n', 'ViewCount': '107', 'Title': 'What Measure of Disorder to use when Analysing Quicksort', 'LastEditorUserId': '39', 'LastActivityDate': '2013-05-07T11:07:28.523', 'LastEditDate': '2013-05-07T11:07:28.523', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6728', 'Tags': '<algorithms><sorting>', 'CreationDate': '2013-05-07T06:08:11.727', 'Id': '11846'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've ran some tests and found that Shellsort runs much faster on ordered and reversed lists compared to random lists and almost ordered lists.</p>\n\n<pre><code>Results:\n        Random Reverse Order AlmostOrder\n  time    24      5      4        29\n</code></pre>\n\n<p>The problem that is confusing me is that Shellsort performs insertion sorts on lists separated by gaps, and insertion sort only runs very fast on ordered lists, not reversed lists.</p>\n\n<p>So my question is why does Shellsort work well on ordered and reversed lists when it uses insertion sort and insertion sort doesn't work well on reversed lists?</p>\n", 'ViewCount': '160', 'Title': 'Why does Shellsort work well on Sorted and Reverse ordered lists?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-19T14:52:46.560', 'LastEditDate': '2013-05-19T14:52:46.560', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '2', 'OwnerDisplayName': 'clay', 'PostTypeId': '1', 'Tags': '<algorithms><algorithm-analysis><runtime-analysis><efficiency><sorting>', 'CreationDate': '2013-05-18T02:16:41.193', 'FavoriteCount': '0', 'Id': '12124'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '1018', 'Title': 'Practical Applications of Radix Sort', 'LastEditDate': '2013-05-23T22:58:26.053', 'AnswerCount': '3', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '6728', 'FavoriteCount': '1', 'Body': '<p>Radix sort is theoretically very fast when you know that the keys are in a certain limited range, say $n$ values in the range $[0\\dots n^k -1]$ for example.  If $k&lt;\\lg n$ you just convert the values to base $n$ which takes $\\Theta(n)$ time, do a base $n$ radix sort and then convert back to your original base for an overall $\\Theta(nk)$ algorithm. </p>\n\n<p>However, I\'ve read that <a href="http://www.lamarca.org/anthony/caches.html">in practice radix sort is typically much slower than doing for example a randomized quicksort</a>:</p>\n\n<blockquote>\n  <p>For large arrays, radix sort has the lowest instruction count, but\n  because of its relatively poor cache performance, its overall\n  performance is worse than the memory optimized versions of mergesort\n  and quicksort.</p>\n</blockquote>\n\n<p>Is radix sort just a nice theoretical algorithm, or does it have common practical uses?</p>\n', 'Tags': '<algorithms><sorting><applied-theory><radix-sort>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-15T00:11:26.887', 'CommentCount': '0', 'AcceptedAnswerId': '12228', 'CreationDate': '2013-05-23T07:29:45.403', 'Id': '12223'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I am reading Algorithm design manual by Skiena. It gives proof of Insertion sort by Induction. I am giving the proof described in the below.</p>\n\n<blockquote>\n  <p>Consider the correctness of insertion sort, which we introduced at the beginning of this chapter. The reason it is correct can be shown inductively:</p>\n  \n  <ol>\n  <li>The basis case consists of a single element, and by definition a\n  one-element array is completely sorted.</li>\n  <li>In general, we can assume that the first n \u2212 1 elements of array A\n  are completely sorted after n \u2212 1 iterations of insertion sort.</li>\n  <li>To insert one last element x to A, we find where it goes, namely the\n  unique spot between the biggest element less than or equal to x and\n  the smallest element greater than x. This is done by moving all the\n  greater elements back by one position, creating room for x in the\n  desired location.</li>\n  </ol>\n</blockquote>\n\n<p>I do not understand paragraph #3. Could someone please explain it to me with an example?</p>\n', 'ViewCount': '368', 'Title': 'Insertion sort Proof by Induction', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-02T22:48:42.980', 'LastEditDate': '2013-06-02T22:48:42.980', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8496', 'Tags': '<algorithms><algorithm-analysis><sorting><correctness-proof><induction>', 'CreationDate': '2013-06-02T16:03:58.043', 'Id': '12434'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><img src="http://i.stack.imgur.com/oAsDp.jpg" alt="enter image description here"></p>\n\n<p>I\'m thinking of using something similar to the Merge Sort algorithm. So the recurrence running time of Merge Sort is T(n) = 2T(n/2) + n. What should I do about if n/2 is less than or equal to m, OR if n/2 is greater than or equal to m?</p>\n\n<p>I believe the given function should be location inside the "Merge" function of the Merge Sort.(Since we\'re merging a sorted array) Thank you for your time.</p>\n\n<p>Edited: \nI\'m thinking if n/2 is less than or equal to m, use the "Given" function . Otherwise use the original "Merge" function (The usual Merge for Merge Sort) </p>\n', 'ViewCount': '41', 'Title': 'Constructing a Divide and Conquer Algorithm', 'LastEditorUserId': '4884', 'LastActivityDate': '2013-06-10T03:39:17.973', 'LastEditDate': '2013-06-09T06:05:06.720', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4884', 'Tags': '<sorting><arrays><divide-and-conquer>', 'CreationDate': '2013-06-09T05:57:31.027', 'Id': '12555'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><strong>Some context:</strong> I\'m to write a program that sorts the lines of a file in C for Linux. Since I have to read all lines of the file (<code>fgets()</code> for example) I\'m thinking about inserting them in a tree like structure in a sorted manner using the so called tree sort algorithm.</p>\n\n<p>Looking for a self-balancing tree structure I came across two that may be interesting, the <a href="http://en.wikipedia.org/wiki/Red-black_tree" rel="nofollow">red-black tree</a> and a <a href="http://en.wikipedia.org/wiki/Splay_tree" rel="nofollow">splay tree</a>. According to Wikipedia the red-black tree has an <code>O(log n)</code> worst case and the splay tree has <em>amortized</em> <code>O(log n)</code>.</p>\n\n<p><strong>The actual question:</strong> I know how to roughly compare some complexity levels in O notation but what\'s that amortized time? Given two algorithms one that runs in <code>O(log n)</code> and the other in amortized <code>O(log n)</code> which one would be preferrable?</p>\n', 'ViewCount': '540', 'Title': "What's better for an algorithm complexity, O(log n) or amortized O(log n)?", 'LastActivityDate': '2013-06-17T18:55:45.193', 'AnswerCount': '3', 'CommentCount': '1', 'AcceptedAnswerId': '12715', 'Score': '3', 'OwnerDisplayName': 'James Russell', 'PostTypeId': '1', 'OwnerUserId': '8705', 'Tags': '<time-complexity><sorting>', 'CreationDate': '2013-06-17T09:57:31.023', 'Id': '12714'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I have an issue for which I am looking for an algorithm (if it exists)</p>\n\n<p>What I have:\nAn array of items which have certain properties, e.g. item $A$ has properties $x$ and $y$.</p>\n\n<p>Example: $[ A(x,y), B(x,y), C(x,y), D(x,y), E(x,y) ]$</p>\n\n<p>What I want:\nA result list consisting of elements of the original list, such as $[ A(x,y), C(x,y), E(x,y) ]$, for which the following properties are true:</p>\n\n<ul>\n<li>No reordering of elements, they are in the same order as the original list</li>\n<li>The result has the maximum number of elements, i.e. the longest 'path' possible</li>\n<li>For each pair of consecutive items $(A(x,y), B(x,y))$ in the result, $A.x \\lt B.y$. In other words, an item's $x$ must be less than the next item's $y$.</li>\n</ul>\n\n<p>Complexity: The list in the case I have is about 35 items long, so an algorithm which is $O(n!)$ might not work.</p>\n\n<p>Does such an algorithm exist?</p>\n", 'ViewCount': '102', 'Title': 'Longest subsequence such that A[i].x < A[i+1].y', 'LastEditorUserId': '39', 'LastActivityDate': '2014-02-27T11:03:43.220', 'LastEditDate': '2013-06-20T09:33:57.090', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8755', 'Tags': '<algorithms><sorting><subsequences><lists>', 'CreationDate': '2013-06-19T15:27:23.673', 'FavoriteCount': '1', 'Id': '12764'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>A bit of background, the work that I currently and will be doing involves sorting very large amounts of data (in this case, grayscale pixels in descending order), sometimes up to 4 million.  </p>\n\n<p>Which are the most effective and efficient sorting algorithms that could handle multiple large datasets (such as descried in the 1st paragraph)?  Is there an algorithm that could simultaneously sort through 2 or more sets of pixels?</p>\n', 'ViewCount': '243', 'LastEditorDisplayName': 'user8872', 'Title': 'Which are the most effective sorting algorithms for a large dataset?', 'LastActivityDate': '2013-06-30T23:45:55.733', 'LastEditDate': '2013-06-30T23:45:55.733', 'AnswerCount': '1', 'CommentCount': '7', 'AcceptedAnswerId': '12991', 'Score': '0', 'OwnerDisplayName': 'user8872', 'PostTypeId': '1', 'Tags': '<algorithms><algorithm-analysis><sorting>', 'CreationDate': '2013-06-30T08:50:22.210', 'Id': '12983'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://en.wikipedia.org/wiki/Selection_sort#Comparison_to_other_sorting_algorithms">It is written on Wikipedia</a> that "... selection sort almost always outperforms bubble sort and gnome sort." Can anybody please explain to me why is selection sort considered faster than bubble sort even though both of them have:  </p>\n\n<ol>\n<li><p><strong>Worst case time complexity</strong>: $\\mathcal O(n^2)$  </p></li>\n<li><p><strong>Number of comparisons</strong>:      $\\mathcal O(n^2)$</p></li>\n<li><p><strong>Best case time complexity</strong> :  </p>\n\n<ul>\n<li>Bubble sort: $\\mathcal O(n)$</li>\n<li>Selection sort: $\\mathcal O(n^2)$</li>\n</ul></li>\n<li><p><strong>Average case time complexity</strong> :  </p>\n\n<ul>\n<li>Bubble sort: $\\mathcal O(n^2)$</li>\n<li>Selection sort: $\\mathcal O(n^2)$ </li>\n</ul></li>\n</ol>\n', 'ViewCount': '5657', 'Title': 'Why is selection sort faster than bubble sort?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-07-09T19:48:10.230', 'LastEditDate': '2013-07-06T14:23:05.397', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '8951', 'Tags': '<algorithms><runtime-analysis><efficiency><sorting>', 'CreationDate': '2013-07-06T09:33:35.463', 'Id': '13106'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I recently learned how to implement merge-sort, using a standard recursive algorithm. Can the algorithm be implemented in a way that allows for a tail-recursive implementation? Can it be implemented in an iterative style?</p>\n\n<p>In general how can a recursive algorithm converted into an iterative and tail-recursive algorithm? What are the possible pros and cons of this conversion?</p>\n', 'ViewCount': '889', 'Title': 'Iterative and/or tail-recursive implementations of merge sort?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-07-08T18:34:56.770', 'LastEditDate': '2013-07-08T01:12:53.063', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '13145', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9051', 'Tags': '<algorithms><sorting><recursion>', 'CreationDate': '2013-07-07T17:20:43.893', 'Id': '13139'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '2139', 'Title': 'Recurrence for recursive insertion sort', 'LastEditDate': '2013-07-09T11:26:11.003', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9051', 'FavoriteCount': '0', 'Body': '<p>I tried this problem from CLRS (Page 39, 2.3-4)</p>\n\n<blockquote>\n  <p>We can express insertion sort as a recursive procedure as follows. In order to sort <code>A[1... n]</code>, we recursively sort <code>A[1... n-1]</code> and then insert <code>A[n]</code> into the sorted array <code>A[1... n-1]</code>. Write a recurrence for the running time of this recursive version of insertion sort.</p>\n</blockquote>\n\n<p>The recurrence I formed was</p>\n\n<p>$$\nT(n) = \\begin{cases}\\Theta(1) &amp; \\textrm{if } n = 1,\\\\\n       T(n-1) + \\Theta(n) &amp; \\textrm{if } n &gt; 1.\n\\end{cases}\n$$</p>\n\n<p><strong>My reasoning</strong></p>\n\n<ul>\n<li>the base case of $n = 1$ the list is sorted so there is no work hence constant time.</li>\n<li>For all other cases the time depends on sorting the sequence <code>A[1...n-1]</code> and then insertion into that sequence. Hence it should be their sum, i.e., $T(n-1) + \\Theta(n)$.</li>\n</ul>\n\n<p>I wanted to know whether the recurrence relation is correct. If not what are the mistakes and how to correctly formulate a recurrence relation?</p>\n', 'Tags': '<algorithm-analysis><recurrence-relation><sorting>', 'LastEditorUserId': '2205', 'LastActivityDate': '2013-07-09T14:06:04.290', 'CommentCount': '2', 'AcceptedAnswerId': '13174', 'CreationDate': '2013-07-09T06:51:21.537', 'Id': '13168'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have about 500,000,000 64-bit integers, so these numbers could be very large.\nI want to sort them as quickly as possible. I have a couple of questions:</p>\n\n<ol>\n<li><p>What data structure do you suggest for storing this data?</p></li>\n<li><p>What algorithm do you suggest for sorting these numbers?</p></li>\n</ol>\n\n<p>My main restriction is speed.</p>\n', 'ViewCount': '224', 'Title': 'How should I store and sort a large number of 64-bit integers?', 'LastEditorUserId': '1055', 'LastActivityDate': '2013-07-17T20:07:11.840', 'LastEditDate': '2013-07-17T05:13:23.943', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '13291', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1055', 'Tags': '<algorithms><data-structures><sorting><integers><performance>', 'CreationDate': '2013-07-15T15:49:46.370', 'Id': '13290'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '628', 'Title': 'What is the most power/energy efficient sorting algorithm?', 'LastEditDate': '2013-08-01T12:57:53.000', 'AnswerCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7858', 'FavoriteCount': '1', 'Body': '<p>I am writing a Android phone application that needs to be very power efficient, and I would like to use the most power efficient sorting algorithm. I will implement it in C for extra power efficiency. What algorithm is the most power efficient algorithm for sorting arbitrary text strings?</p>\n', 'Tags': '<algorithms><sorting><efficiency><power-consumption>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-01T13:10:14.323', 'CommentCount': '6', 'AcceptedAnswerId': '13549', 'CreationDate': '2013-07-31T22:27:29.337', 'Id': '13548'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '591', 'Title': 'Rearrange an array using swap with 0', 'LastEditDate': '2013-08-26T11:11:43.570', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4752', 'FavoriteCount': '2', 'Body': u'<p>This is a Google interview question. I got it from a website.</p>\n\n<blockquote>\n  <p>You have two arrays <strong>source</strong> and <strong>target</strong>, containing two permutations of the numbers <code>[0..n-1]</code>. You would like to rearrange source so that it equals to target. The only allowed operations is <strong>\u201cswap a number with 0\u201d</strong>. Find the minimum number of swaps?</p>\n  \n  <p>e.g. {1,0,2,3} -> {1,3,2,0}  swap 0 with 3. one swap is enough.</p>\n</blockquote>\n\n<p>My attempt on problem: If we consider arrays as strings we could use edit distance to convert source to target if other edit distance operations like insert,delete,replace etc are allowed but here only allowed operation is swapping.</p>\n', 'Tags': '<algorithms><sorting><permutations>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-30T07:40:21.463', 'CommentCount': '1', 'AcceptedAnswerId': '13938', 'CreationDate': '2013-08-26T05:21:43.070', 'Id': '13930'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Suppose that there is an algorithm which sorts a sequence of $n$ elements</p>\n\n<p>$$a_1, a_2, ..., a_n$$</p>\n\n<p>Each of the $a_i$ is chosen with probability $1/k$ from a set of $k$ distinct integer numbers. </p>\n\n<p>Is it true, given that $k \\to \\infty$, that:</p>\n\n<ol>\n<li>The probability that any two of incoming sequence elements are equal, tends to $0$?</li>\n<li>The probability that the incoming sequence is already sorted, tends to $\\frac{1}{n!}$?</li>\n</ol>\n\n<p>Why / why not?</p>\n', 'ViewCount': '58', 'Title': 'Sort algorithm input probabilities', 'LastActivityDate': '2013-09-07T20:14:07.100', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '14199', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1198', 'Tags': '<probability-theory><sorting>', 'CreationDate': '2013-09-07T19:28:12.583', 'Id': '14198'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '117', 'Title': 'Probability that a uniformly random sequence is already sorted', 'LastEditDate': '2013-09-09T02:32:58.133', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1198', 'FavoriteCount': '1', 'Body': "<p>Now I tried tackling this question from different perspectives (and already asked a couple of questions here and there), but perhaps only now can I formulate it well and ask you (since I have no good ideas).</p>\n\n<p>Let there be $k, n \\in\\mathbb{Z_+}$. These are fixed.</p>\n\n<p>Consider a set of $k$ integers $S=\\{0, 1, 2, ... k-1\\}$.</p>\n\n<p>We form a sequence  $a_1, a_2, ..., a_n$ by picking numbers from $S$ at random with equal probability $1/k$.</p>\n\n<p>The question is - what is the probability of that sequence to be sorted ascending, i.e. $a_1 \\leq a_2 \\leq ... \\leq a_n$? </p>\n\n<p>Case $k \\to \\infty$:</p>\n\n<p>This allows us to assume (with probability tending to $1$) that all elements $a_1, ..., a_n$ are different. It means that only one ordering out of $n!$ possible is sorted ascending. </p>\n\n<p>And since all orderings are equally likely (not sure why though), the probability of the sequence to be sorted is</p>\n\n<p>$$\\frac{1}{n!}.$$</p>\n\n<p>Case k = 2:</p>\n\n<p>Now we have zeroes and ones which come to the resulting sequence with probability $0.5$ each. So the probability of any particular n-sequence is $\\frac{1}{2^n}$. </p>\n\n<p>Let us count the number of possible sorted sequences:</p>\n\n<p>$$0, 0, 0, \\ldots, 0, 0$$\n$$0, 0, 0, \\ldots, 0, 1$$\n$$0, 0, 0, \\ldots, 1, 1$$\n$$\\ldots$$\n$$0, 0, 1, \\ldots, 1, 1$$\n$$0, 1, 1, \\ldots, 1, 1$$\n$$1, 1, 1, \\ldots, 1, 1$$</p>\n\n<p>These total to $(n+1)$ possible sequences. Now again, any sequence is equally likely, so the probability of the sequence to be sorted is </p>\n\n<p>$$ \\frac{n+1}{2^n}. $$</p>\n\n<p>Question:</p>\n\n<p>I have no idea how to generalize it well for arbitrary $k, n$. Maybe we can tackle it together since my mathematical skills aren't really that high. </p>\n", 'Tags': '<combinatorics><probability-theory><sorting>', 'LastEditorUserId': '755', 'LastActivityDate': '2013-09-09T02:32:58.133', 'CommentCount': '0', 'AcceptedAnswerId': '14211', 'CreationDate': '2013-09-08T07:29:56.110', 'Id': '14209'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>One of my courses introduced the following question:</p>\n\n<blockquote>\n  <p>Given the recurrence relation for mergesort:</p>\n  \n  <p>$T(n) = 2T(n/2) + n$</p>\n  \n  <p>How would the following parameter passing strategies influence the relation and running time of the algorithm:</p>\n  \n  <ol>\n  <li><p>A pointer to the array is passed to the sorting function,</p></li>\n  <li><p>The entire array is copied to a separate location before applying the sorting function,</p></li>\n  <li><p>A subsection of the array is copied to a separate location before applying the sorting function on that subsection.</p></li>\n  </ol>\n</blockquote>\n\n<p>For 1., since this is how mergesort is used most of the time, we can solve it easily using the master theorem.</p>\n\n<p>$f(n) = \\Theta(n^{\\log_b a}) = \\Theta(n) \\implies T(n) = \\Theta(n \\log n)$</p>\n\n<p>For 2. however, I am a bit baffled. Although we do an additional work of $O(n)$, we are only doing so <em>once</em> at the beginning of the sort. Hence, doing one additional instance of $O(n)$ work should not influence the order of the running time (because it already <em>is</em> of a larger order). Hence, for both 2. and 3. the running time would remain at $T(n) = \\Theta(n \\log n)$. </p>\n\n<p>Is this reasoning valid? Something tells me that the $O(n)$ copying should have more of an impact, but I can't seem to give myself a good enough reason that it should be responsible to slow it down enough so that it would worse (i.e. $O(n^2)$). </p>\n\n<p>Any thoughts or hints would be quite appreciated!</p>\n", 'ViewCount': '134', 'Title': 'Do different variants of Mergesort have different runtime?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-16T07:58:23.627', 'LastEditDate': '2013-09-16T06:58:55.213', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '14349', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10093', 'Tags': '<algorithms><algorithm-analysis><runtime-analysis><recurrence-relation><sorting>', 'CreationDate': '2013-09-12T03:25:30.877', 'Id': '14275'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '222', 'Title': 'Which of the common sorting algorithms can be parallelized?', 'LastEditDate': '2013-09-16T07:54:36.567', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10127', 'FavoriteCount': '2', 'Body': "<p>I want to know that whether which of the following algorithm can be parallelized?</p>\n\n<p>Bubble Sort,\nInsertion Sort,\nSelection Sort,\nShell Sort,\nQuick Sort,\nMerge Sort,\nRadix Sort.</p>\n\n<p>Those which can't be, please explain me briefly that how? Or please try to tell me in simple words that what is parallelism in sorting algorithms.</p>\n", 'ClosedDate': '2013-09-16T07:57:07.533', 'Tags': '<algorithms><sorting><parallel-computing>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-16T07:54:36.567', 'CommentCount': '11', 'CreationDate': '2013-09-13T18:08:10.710', 'Id': '14294'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>It is well known now that <a href="http://en.wikipedia.org/wiki/Grover%27s_algorithm" rel="nofollow">Grover\'s quantum algorithm</a> can <strong>SORT</strong> a database of $N$ entries in $O(\\sqrt{N})$ time. How can an algorithm work without reading through the list of entries which needs $O(N)$ operation. How does Grover\'s algorithm avoid reading the list? Is there a special representation that can be used classically as well? I understand any such representation will not help the classical case. However I am curious to understand how Grover avoids reading the list?</p>\n', 'ViewCount': '146', 'Title': "How does Grover's Quantum Sorting avoid reading the list?", 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-22T06:29:18.927', 'LastEditDate': '2013-09-20T16:27:01.477', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '14445', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9753', 'Tags': '<algorithms><sorting><quantum-computing>', 'CreationDate': '2013-09-19T14:55:35.013', 'Id': '14442'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In class we saw the followin problem but i didnt undestand the solution. Do anybody could explain me with more detail the procedure to solve this problem or give me a better solution?:</p>\n\n<blockquote>\n  <p>Assume that $n$ points in the plane are given. Find a polygonal arc with $n-1$ sides whose vertices are given points, and whose sides do not intersect. (Adjacent sides may form a $180$ angle). The number of operations shold be of order $n$ $log$ $n$.</p>\n</blockquote>\n\n<p>The teacher solution was:</p>\n\n<blockquote>\n  <p>Sort all the points with respect to the x-coordinate; when x-coordinates are equal, take the y-coordinate into account, then connect all the vertices by line segments(in that order).</p>\n</blockquote>\n', 'ViewCount': '45', 'ClosedDate': '2013-11-28T21:51:16.080', 'Title': 'Finding a polygonal arc algorithm?', 'LastActivityDate': '2013-10-09T15:57:50.583', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10610', 'Tags': '<algorithms><algorithm-analysis><graphs><sorting>', 'CreationDate': '2013-10-09T15:57:50.583', 'Id': '14955'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There are $n$ pairs of socks, all different. They all went out of the dryer, so there are now $2n$ socks scattered around. Given two socks, the only operation I can do is to decide whether they are identical (- belong to the same pair) or different (- belong to different pairs). What is the best way to sort the socks in matching pairs?</p>\n\n<p>The obvious algorithm is: grab a sock, scan the pile for its matching sock, and put that pair aside. This algorithm requires time $O(n^2)$.</p>\n\n<p>I Found a related question, <a href="http://www.mail-archive.com/kragen-tol@canonical.org/msg00084.html" rel="nofollow">On the complexity of sock-matching</a> from about 10 years ago, which also describes an $O(n^2)$ algorithm.</p>\n\n<p>If each sock has a numeric ID, or another ordinal property, such as: wavelength of color, then the entire set of socks can be sorted by that ordinal property in time $O(n log n)$, and then the pairs can just be collected with an $O(n)$ scan. But, in this question I assume that there is no order on the socks - we can only tell whether two socks are identical or different.</p>\n\n<p>In a similar question in StackOverflow (<a href="http://stackoverflow.com/questions/14415881/how-to-pair-socks-from-a-pile-efficiently">How to pair socks from a pile efficiently?</a>), the accepted answer suggests to use a hash, but again, this assumes that each sock can be represented by a set of properties such as color, pattern, etc., so that each property can be handled separately. In this question I assume that the properties of the socks are only accessible via a function that tells whether two socks are identical or different.</p>\n\n<p>There is a paper named <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.178.4654&amp;rep=rep1&amp;type=pdf" rel="nofollow">Sock sorting</a>, which initially seems related, but actually it deals with another problem, where two socks might seem identical although they are different (this probably makes the problem more difficult).</p>\n\n<p>So, my question is: assuming we only have a binary "identical/different" relation on the socks, can we match the socks faster than $O(n^2)$?</p>\n', 'ViewCount': '140', 'Title': 'sock matching algorithm', 'LastActivityDate': '2013-10-16T13:17:21.433', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '16135', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<algorithms><time-complexity><sorting>', 'CreationDate': '2013-10-16T12:42:54.633', 'FavoriteCount': '1', 'Id': '16133'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was wondering how to remove duplicate values from a linked list in $\\mathcal{O}(n\\lg n)$ time. I have an idea that by using merge sort when we want to compare elements for choosing the small one, if they are equal advance on pointer and just consider one element. Any alternatives?</p>\n', 'ViewCount': '111', 'Title': 'How to purge a linked list in $\\mathcal{O}(n\\log n)$ time?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-10-18T21:13:42.090', 'LastEditDate': '2013-10-18T21:13:42.090', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '16162', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10030', 'Tags': '<sorting><linked-lists>', 'CreationDate': '2013-10-17T14:11:34.833', 'Id': '16160'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been stuck with this problem for 2 weeks. Any idea of how to aproach it?.</p>\n\n<blockquote>\n  <p>Let $L$ be a list of $n$ different integer numbers, assume that the elements of $L$ are in the range $[1,750]$. Design a linear ordering algorithm to order the elements of $L$.</p>\n</blockquote>\n\n<p>I already tried with insertion sort. But I'm not sure if my approach is right:</p>\n\n<ul>\n<li>Construct an array of bits. Initialize them to zero.</li>\n<li>Read the input, for each value you see set the respective bit in the array to 1.</li>\n<li>Scan the array, for each bit set, output the respective value.</li>\n</ul>\n\n<p>Complexity: $O(2n) = O(n)$</p>\n\n<p>I also wanted to use radix sort but I can't understand how to apply it, any idea?</p>\n", 'ViewCount': '146', 'Title': 'Sorting in O(n) time in a finite domain', 'LastEditorUserId': '39', 'LastActivityDate': '2013-10-23T10:11:12.493', 'LastEditDate': '2013-10-23T10:11:12.493', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10610', 'Tags': '<algorithms><algorithm-analysis><time-complexity><sorting><radix-sort>', 'CreationDate': '2013-10-23T06:11:54.673', 'Id': '16350'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I have come across a question that is a bit hard to understand due to its wording, I may havecome up with a possible solution, but I don't know if it's correct. Can you please help me? Thanks in advance!</p>\n\n<p><strong>Question</strong></p>\n\n<p>Suppose we exchange elements $a[i]$ and $a[j]$, where $j &gt; i$, which are originally out of order.</p>\n\n<p>For example, $a = [2,8,3,7,1,5,6]$ and we exchange the second and sixth elements, we have $[2,5,3,7,1,8,6]$. </p>\n\n<p>The array has now fewer inversions. What is the maximum number of inversions that can be removed if we exchange $a[i]$ and $a[j]$?</p>\n\n<p><strong>My proposed answer</strong></p>\n\n<p>Take an array and sort it in reverse order. The first element would have the most inversions. We switch it with the last element and the number of inversions decrease drastically.</p>\n\n<p>The maximum number of inversions would be $j-i+n-2$.</p>\n\n<p><strong>My concern</strong></p>\n\n<p>Since the question doesn't say anything about me being allowed to change the order of the array, I don't know if my proposed answer is the one they were aiming for.</p>\n", 'ViewCount': '185', 'Title': 'Maximum number of inversions that can be removed by swapping two elements?', 'LastEditorUserId': '683', 'LastActivityDate': '2013-10-24T15:54:43.487', 'LastEditDate': '2013-10-24T15:52:29.590', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '16403', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10398', 'Tags': '<sorting><arrays>', 'CreationDate': '2013-10-24T15:06:12.357', 'Id': '16400'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have been looking for a quick and easy explanation on Quick Select and stumbled upon <a href="http://www.youtube.com/watch?v=1vrdZiVmqno" rel="nofollow">this</a>. It\'s quick and easy to follow, but there\'s a part which I am not following quite well:</p>\n\n<p>The uploader is sorting the following array using the 4th smallest element</p>\n\n<p>2 6 5 1 4 9 3, pivot is 2 and last element is 3</p>\n\n<p>We rearrange, the array is now:</p>\n\n<p>2 1 5 6 4 9 3, 5 is greater than 3 so we swap them</p>\n\n<p>2 1 3 6 4 9 5</p>\n\n<p>We go to n/2 and see the right half.</p>\n\n<p>6 4 9 5, pivot is 5</p>\n\n<p>Then the sub-array is rearranged as follows:</p>\n\n<p>4 5 6 9</p>\n\n<p>Shouldn\'t this be 4 5 9 6?</p>\n\n<p>Or is it just putting and shifting?</p>\n', 'ViewCount': '59', 'Title': 'Quick Select explanation', 'LastEditorUserId': '10398', 'LastActivityDate': '2013-10-27T08:38:55.293', 'LastEditDate': '2013-10-27T08:38:55.293', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10398', 'Tags': '<sorting><quicksort>', 'CreationDate': '2013-10-26T20:15:34.240', 'Id': '16453'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Let $S$ be a set of $n$ integers. Consider the following <em>weighted permutations problem</em>.</p>\n\n<blockquote>\n  <p>Let $m&lt;n$ be an integer. What is an efficient algorithm to enumerate all subsets of $m$ integers of $S$ such that they are listed in order of the sum of the integers in each subset?</p>\n</blockquote>\n\n<p>Each subset is a permutation, and each permutation has a total weight that is the sum of the integers in the permutation.</p>\n\n<p>The idea is to come up with an algorithm that is not the trivial algorithm of enumerating all subsets, and then sorting them, i.e. more of a "streaming" type algorithm. That is, efficiency in terms not so much of time but of "small" space.</p>\n\n<p>Maybe this is published somewhere in the literature although I have not seen it.</p>\n', 'ViewCount': '89', 'Title': 'Enumerating weighted permutations in sorted order problem', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-18T21:03:07.127', 'LastEditDate': '2013-11-18T21:03:07.127', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '699', 'Tags': '<algorithms><reference-request><sorting><efficiency><enumeration>', 'CreationDate': '2013-11-05T17:32:02.033', 'FavoriteCount': '1', 'Id': '16744'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For a given acyclic graph $G$, a topological sort is an ordering $v_1, \\dots, v_n$ of the vertices such that the arrows in the graph are all directed forward under that ordering.</p>\n\n<p>Question: can all topological orders of a graph $G$ be obtained from a single ordering by iteratively swapping two vertices that are not connected by an edge?</p>\n\n<p>Motivation. In a certain context I am trying to prove that all topological sorts of an acyclic graph are in fact "equivalent". I want to do this by comparing $v_1, \\dots, v, v\', \\dots v_n$ and $v_1, \\dots, v\', v, \\dots v_n$ where there is no edge between $v,v\'$.</p>\n', 'ViewCount': '104', 'Title': 'topological sort equivalence', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-19T11:41:08.957', 'LastEditDate': '2013-11-09T15:23:59.883', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4287', 'Tags': '<graph-theory><graphs><sorting>', 'CreationDate': '2013-11-09T14:47:39.720', 'FavoriteCount': '1', 'Id': '16848'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'ve got 30 elements which has to be  grouped/sorted into 10 ordered 3-tuple. \nThere are several rules and constraints about grouping/sorting.\nFor example: Element $A$ must not be in the same tuple same unit $B$. \nElement $C$ must not be right in front of element $A$, etc.</p>\n\n<p>I am searching for an approximated algorithm:</p>\n\n<ol>\n<li>We don\'t need to achieve the exact optimum </li>\n<li>It is OK for some rules not to be satisfied, if it helps to fulfill more rules.</li>\n</ol>\n\n<p>Do you know of any algorithm/proceeding that solve this problem or a similar one?\nI fear to solve it in an optimal way, you have to try out every possible solution-> $2 ^ {30}$</p>\n\n<p><strong>EDIT</strong>: Sorry for the bad explanation. I am trying to make it a bit clearer:\nI got 30 elements for example: $\\{1,2,3,\\ldots,30\\}$.\nI need to group them into 3-tuples so that i get something like: $(1,2,3)$, $(4,5,6)$,$\\ldots$,$(28,29,30)$.</p>\n\n<p>There are several constraints. For example: </p>\n\n<ul>\n<li>1 cannot precede 2 in an ordered tuple, so, for instance  $(1,2,3)$ is not a valid tuple.</li>\n<li>5 must be together with 4. </li>\n</ul>\n\n<p>Those constraints can be broken and its possible that there is no solution where all rules can be fulfilled. <br />An solution is considered as good if the amount of rules broken is "low".</p>\n\n<p>Hope that makes it clearer and thanks for the help so far.</p>\n', 'ViewCount': '81', 'Title': 'Algorithm for sorting with constraints', 'LastEditorUserId': '157', 'LastActivityDate': '2013-12-16T01:48:30.027', 'LastEditDate': '2013-12-16T00:37:15.273', 'AnswerCount': '2', 'CommentCount': '5', 'AcceptedAnswerId': '18345', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '11601', 'Tags': '<algorithms><sorting><randomized-algorithms><greedy-algorithms>', 'CreationDate': '2013-11-25T00:14:58.160', 'Id': '18312'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '120', 'Title': 'More efficient algorithm for determining if one list is a sublist of another list', 'LastEditDate': '2013-11-26T01:14:57.783', 'AnswerCount': '2', 'Score': '4', 'OwnerDisplayName': 'Panarit', 'PostTypeId': '1', 'OwnerUserId': '11640', 'FavoriteCount': '1', 'Body': "<p>I'm trying to build an algorithm which takes two lists of natural numbers and finds if every element of the first list is displayed at least once in the second list.</p>\n\n<p>What if the list is sorted? </p>\n\n<p>An algorithm that can do this is by comparing every element of the first list with every element from the second list. I think there is an algorithm with a better complexity. Can anyone give me any idea?</p>\n", 'Tags': '<algorithms><data-structures><sorting><lists><comparison>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-11-26T21:23:38.760', 'CommentCount': '1', 'AcceptedAnswerId': '18350', 'CreationDate': '2013-11-24T14:49:37.500', 'Id': '18346'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>So given an input of lets say 10 strings, what way can we input these so we get the best or worst case for these two given sorts?</p>\n\n<pre><code>Heap sort:\nbest case - nlogn\nworst case - nlogn\n\nQuick sort:\nbest case - nlogn\nworst case - n^2\n</code></pre>\n\n<p>Where I get confused on these two is:</p>\n\n<ul>\n<li><strong>heap</strong>- Since the best and worst case are the same does it not matter\nthe input order? The number of comparisons and assignments will\nalways be the same? I imagine in a heap sort it may be the same since\nthe real work is done in the insertion, but the sorting only uses the\nremoval of the max/min heap? Is that why?</li>\n<li><strong>quick sort</strong>- This one I don't know for sure. I'm not sure what the\nbest case and worst case situations are for this. If its a already\nsorted list of 10 strings for example wouldn't we always have to\nchoose the same amount of pivots to get complete the recursive\nalgorithm? Any help on this explanation would really help.</li>\n</ul>\n", 'ViewCount': '416', 'Title': 'Best and worse case inputs for heap sort and quick sort?', 'LastEditorUserId': '9550', 'LastActivityDate': '2013-11-26T21:03:49.457', 'LastEditDate': '2013-11-26T18:52:40.720', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11638', 'Tags': '<algorithms><complexity-theory><sorting><heaps>', 'CreationDate': '2013-11-26T17:43:11.983', 'Id': '18391'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I have come across many sorting algorithms during my high school studies. However, I never know which is the fastest (for a random array of integers). So my questions are:</p>\n\n<ul>\n<li>Which is the fastest currently known sorting algorithm?</li>\n<li>Theoretically, is it possible that there are even faster ones? So, what's the least complexity for sorting?</li>\n</ul>\n", 'ViewCount': '2193', 'Title': 'What is a the fastest sorting algorithm for an array of integers?', 'LastActivityDate': '2013-12-03T19:50:58.720', 'AnswerCount': '4', 'CommentCount': '6', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '8870', 'Tags': '<algorithms><time-complexity><optimization><sorting>', 'CreationDate': '2013-12-02T16:15:25.337', 'Id': '18536'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '89', 'Title': 'sorting stone Problem', 'LastEditDate': '2013-12-04T10:39:25.287', 'AnswerCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11783', 'FavoriteCount': '2', 'Body': '<p>My friend asked this problem recently &amp; am not sure which sorting to use for this kind of problem:-</p>\n\n<p>There are 20 stones of different heights. Each stone is so heavy, we need to sort the stones such that smallest stones are to left and highest to right. As stones are heavy make algorithm which moves stone least distance possible </p>\n\n<p>Which sorting method suits this kind of problem?</p>\n', 'ClosedDate': '2013-12-26T09:47:10.200', 'Tags': '<sorting>', 'LastEditorUserId': '11783', 'LastActivityDate': '2013-12-06T17:29:50.177', 'CommentCount': '4', 'CreationDate': '2013-12-03T09:52:23.880', 'Id': '18568'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I have been doing a little reading up on bubble sort and have read on wikipedia that it's complexity is measured as $\\Theta(n^2)$</p>\n\n<p>This bubble sort however is slightly more efficient. I thought this would be the best place to ask how I would work out this particular implementations complexity seeing that the number of iterations in the inner loop is reduced with each pass.</p>\n\n<pre><code>for (top = items.Length; top &gt; 0; top--)\n            {\n                for (low = 0, high = 1; high &lt; top; low++, high++)\n                {\n                    if (items[low].CompareTo(items[high]) &gt; 0)\n                    {\n                        tmp = items[high];\n                        items[high] = items[low];\n                        items[low] = tmp;\n                    }\n                }\n            }\n</code></pre>\n", 'ViewCount': '82', 'ClosedDate': '2013-12-05T23:08:19.347', 'Title': 'What is the complexity of this bubble sort algorithm?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-05T23:06:12.697', 'LastEditDate': '2013-12-05T23:06:12.697', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11855', 'Tags': '<algorithm-analysis><runtime-analysis><sorting>', 'CreationDate': '2013-12-05T21:41:38.547', 'Id': '18662'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '75', 'Title': 'Is radix sort a greedy algorithm?', 'LastEditDate': '2014-01-19T02:27:32.353', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8870', 'FavoriteCount': '1', 'Body': '<p>I was thinking of radix sort, and at a sudden thought that it uses de facto the paradigm  of dynamic programming, but I soon changed my mind to greedy algorithm. Is it really a greedy algorithm? </p>\n', 'Tags': '<algorithms><terminology><sorting>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-19T02:27:32.353', 'CommentCount': '3', 'AcceptedAnswerId': '18895', 'CreationDate': '2013-12-11T19:37:58.497', 'Id': '18889'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>So given a input of lets say 10 strings, what way can we input these so we get the best or worst case for these two given sorts?</p>\n\n<pre><code>Heap sort:\nbest case - nlogn\nworst case - nlogn\n\nQuick sort:\nbest case - nlogn\nworst case - n^2\n</code></pre>\n\n<p>Where i get confused on these two is:</p>\n\n<p>heap- Since the best and worst case are the same does it not matter the input order? The number of comparisons and assignments will always be the same? I imagine in a heap sort it may be the same since the real work is done in the insertion, but the sorting only uses the removal of the max/min heap? Is that why?</p>\n\n<p>quick sort- This one I don't know for sure. I'm not sure what the best case and worst case situations are for this. If its a already sorted list of 10 strings for example wouldn't we always have to choose the same amount of pivots to get complete the recursive algorithm? Any help on this explanation would really help.</p>\n\n<p>Thanks</p>\n", 'ViewCount': '2076', 'Title': 'Best and worse case inputs for heap sort and quick sort?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-12-13T07:41:27.657', 'LastEditDate': '2013-12-13T07:41:27.657', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'OwnerDisplayName': 'user3037172', 'PostTypeId': '1', 'Tags': '<algorithm-analysis><runtime-analysis><sorting><quicksort>', 'CreationDate': '2013-11-26T16:04:07.403', 'Id': '18945'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Suppose we want to arrange n numbers stored in an array such that all negative value occur before the positive ones. What will be the minimum number of exchanges in the worst case ? </p>\n', 'ViewCount': '98', 'Title': 'Minimum number of exchanges needed to get all negative values left of all positive ones', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-14T21:01:41.950', 'LastEditDate': '2014-03-14T21:01:41.950', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11984', 'Tags': '<algorithms><algorithm-analysis><sorting>', 'CreationDate': '2013-12-13T13:48:34.530', 'Id': '18952'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is it possible to use a sorting algorithm with a non-transitive comparison, and if yes, why is transitivity listed as a requirement for sorting comparators?</p>\n\n<p>Background:</p>\n\n<ul>\n<li><p><em>A sorting algorithm generally sorts the elements of a\nlist according to a comparator function C(x,y), with</em></p>\n\n<p>\\begin{array}{ll} C(x,y) = \\begin{cases}\n    -1  &amp; {\\text{if}}\\ x\\prec y   \\\\ 0 &amp; {\\text{if}}\\ x\\sim y \\\\ \n    +1 &amp; {\\text{if}}\\ x\\succ y  \\\\ \\end{cases} \\end{array}</p>\n\n<p><em>The requirements for this comparator are, as far as I\nunderstand them:</em></p>\n\n<ul>\n<li><em>reflexive:</em> $\\forall x: C(x,x)=0$ </li>\n<li><em>antisymmetric:</em> $\\forall x,y: C(x,y) = - C(y,x)$ </li>\n<li><em>transitive:</em> $\\forall x,y,z, a: C(x,y)=a \\land C(y,z)=a \\Rightarrow C(x,z)=a$</li>\n<li><em>C(x,y) is defined for all x and y, and the results depend only on x and y</em></li>\n</ul>\n\n<p><em>(These requirements are always listed differently accross different\nimplementations, so I am not sure I got them all right)</em></p></li>\n</ul>\n\n<p>Now I am wondering about a "tolerant" comparator function, that accepts numbers x,y as similar if$ |x - y| \\le 1$:\n\\begin{array}{ll}\nC(x,y) = \\begin{cases}\n-1  &amp; {\\text{if}}\\ x\\lt y-1   \\\\\n0 &amp; {\\text{if}}\\ |x - y| \\le 1 \\\\ \n+1 &amp; {\\text{if}}\\ x\\gt y+1  \\\\\n\\end{cases}\n\\end{array}</p>\n\n<p>Examples: both <code>[ 1, 2, 3, 4, 5]</code> and <code>[1, 4, 3, 2, 5]</code> are correctly sorted  in ascending order according to the tolerant comparator ($C(x,y) \\le 0$ if x comes before y in the list)<br>\nbut <code>[1, 4, 2, 3, 5]</code> is not, since C(4,2)=1</p>\n\n<p>This tolerant comparator is reflexive and antisymmetric, but not transitive.</p>\n\n<p>i.e. C(1,2) = 0 , c(2,3) = 0, but C(1,3) = -1, violating transitivity</p>\n\n<p>Yet I cannot think of any sorting algorithm that would fail to produce a "correctly sorted" output when given this comparator and a random list.</p>\n\n<p>Is transitivity therefore not required in this case? And is there a less strict version of transitivity that <em>is</em> required for the sorting to work?</p>\n\n<p>Related questions:</p>\n\n<ul>\n<li><a href="http://math.stackexchange.com/q/276907/34541">Why is antisymmetry necessary for comparison sort?</a> (about antisymmetry)</li>\n<li><a href="http://cs.stackexchange.com/q/2336/2932">Sorting algorithms which accept a random comparator</a> (about a random C(x,y))</li>\n<li><a href="http://stackoverflow.com/q/20363810/145999">OrderBy with a non-transitive IComparer</a> (about the c# sort algorithm, by me)</li>\n</ul>\n', 'ViewCount': '234', 'Title': 'Is transitivity required for a sorting algorithm', 'LastActivityDate': '2014-02-12T23:38:27.540', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '2932', 'Tags': '<algorithms><sorting><quicksort><transitivity>', 'CreationDate': '2013-12-15T17:19:24.000', 'Id': '19013'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm trying to understand why the sorting algorithm Selection Sort has a time complexity of O(n^2).</p>\n\n<p>Looking at the math, the time complexity is</p>\n\n<p>T(n) = (n-1) + (n-2) + ... + 2 + 1</p>\n\n<p>And this is stated to be equal to</p>\n\n<p>O(n^2)</p>\n\n<p>However I just don't understand the intuition. I have tried several practical experiments for n=10 up to n=5000, and all point to that the time complexity of e.g. 5000 can never be greater T(5000) = 12.497.500 -- not T(5000) = 5000^2 = 25.000.000.</p>\n\n<p>Now, I know that 5000 is not the same as infinity, but I just don't understand the intuition behind</p>\n\n<p>(n-1) + (n-2) + ... + 2 + 1 = O(n^2)</p>\n\n<p>Does someone have a great pedagogical explanation that my dim-witted mind can understand?</p>\n", 'ViewCount': '1122', 'Title': 'Selection Sort Time Complexity using Big O notation', 'LastActivityDate': '2013-12-18T16:54:33.630', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19096', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12219', 'Tags': '<algorithm-analysis><asymptotics><sorting>', 'CreationDate': '2013-12-18T16:43:12.773', 'Id': '19094'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I came across an interesting procedure that ranks (sorts) a set of tuples, <em>not</em> by comparisons between tuples, but by the proximity between <em>next</em> tuple(s) and the set of tuples already ranked.</p>\n\n<p>Specifically, consider the ranking procedure as follows,</p>\n\n<p>Input: $D=\\{p_i\\mid p_i \\in \\mathbb{R}^2, i=1, 2,\\ldots,n\\}$, $i_{start} \\in \\{1, 2,\\ldots, n\\}$, and distance metric $f: 2^D \\times D \\mapsto \\mathbb{R}_{\\ge 0}$<br>\nOutput: $\\Pi = \\left[ i_1, i_2, \\ldots, i_n\\right]$</p>\n\n<ol>\n<li>$\\Pi \\gets \\left[~ \\right]$; // empty sequence</li>\n<li>$A \\gets \\emptyset$;  </li>\n<li>$i_{next} \\gets i_{start}$;  </li>\n<li>while $D \\neq \\emptyset$  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$\\Pi \\gets \\Pi \\oplus i_{next} $ // append $i_{next}$ to sequence</li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$A \\gets A \\bigcup \\left\\{ p_{i_{next}} \\right\\}$; // $p_{i_{next}}$ is a tuple from $D$ identified by subscript ${i_{next}}$  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;$D \\gets D \\setminus \\left\\{p_{i_{next}}\\right\\}$;  // same $p_{i_{next}}$ as in line 6  </li>\n<li>&nbsp;&nbsp;&nbsp;&nbsp;${i_{next}} \\gets \\min \\bigl\\{\\arg_j\\,\\min_{p_j\\in D}\\,f(A, p_j) \\bigr\\}$; // not defined when $D = \\emptyset$   </li>\n</ol>\n\n<p>An example of the distance metric $f(A, p)$ is, say, the distance between 2D point $p$ and the centroid of 2D points in set $A$. As such, the procedure is literally the expansion of a cluster of 2D points, starting from a given point $p_{start}$, until all $n$ points from $D$ have been included. And the sequence $\\Pi$ records the order by which points from $D$ are included in the cluster.</p>\n\n<p>Could anyone shed some light on the literature, background, or well-known examples, of such ranking procedures? In particular, are there any previous results on the complexity bounds of such a procedure perhaps under different types of distance metrics?</p>\n', 'ViewCount': '93', 'Title': 'On ranking (sorting) by a varying distance metric', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-23T13:08:49.810', 'LastEditDate': '2013-12-23T13:08:49.810', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7644', 'Tags': '<algorithms><complexity-theory><reference-request><sorting><ranking>', 'CreationDate': '2013-12-19T18:41:36.297', 'FavoriteCount': '1', 'Id': '19128'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>This is a popular question: </p>\n\n<blockquote>\n  <p>What is the most efficient (in time complexity) way to sort 1 million 32-bit integers? </p>\n</blockquote>\n\n<p>Most answers seem to agree that one of the best ways would be to use radix sort since the number of bits in those numbers is assumed to be constant. This is also a very common thought exercise when CS students are first learning non-comparison based sorts. However, what I haven\'t seen described in detail (or at least clearly) is how to optimally choose the radix (or number of buckets) for the algorithm.</p>\n\n<p><a href="http://www.quora.com/Sorting-Algorithms/What-is-the-most-efficient-way-to-sort-a-million-32-bit-integers" rel="nofollow">In this observed answer</a>, the selection of the radix/number of buckets was done empirically and it turned out to be $2^8$ for 1 million 32-bit integers. I\'m wondering if there is a better way to choose that number? In "Introduction to Algorithms" (p.198-199) it explains Radix\'s run-time should be $\\Theta(d(n+k))$ (d=digits/passes, n=number of items, k=possible values). It then goes further and says that given n b-bit numbers, and any positive integer $r \\leq b$, radix-sort sorts the number in $\\Theta((b/r)(n+2^r))$ time. It then says: </p>\n\n<blockquote>\n  <p>If $b \\geq \\lfloor \\lg(n) \\rfloor$, choosing $r = \\lfloor \\lg(n) \\rfloor$ gives the best time to within a constant factor.</p>\n</blockquote>\n\n<p>But, if we choose $r = \\lg(10^6) =20$, which is not $8$ as the observed answer suggests.</p>\n\n<p>This tells me that I\'m very likely misinterpreting the "choosing of $r$" approach the book is suggesting and missing something (very likely) or the observed answer didn\'t choose the optimal value.</p>\n\n<p>Could anyone clear this up for me?</p>\n', 'ViewCount': '130', 'Title': 'Choosing the optimal radix/number-of-buckets when sorting n-bit integers using radix sort', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-06T16:28:50.420', 'LastEditDate': '2014-02-06T16:28:50.420', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '2', 'OwnerDisplayName': 'sigue', 'PostTypeId': '1', 'Tags': '<algorithms><sorting><efficiency>', 'CreationDate': '2014-01-13T03:18:00.663', 'FavoriteCount': '1', 'Id': '21385'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u"<p>Based on the Wikipedia implementation of insertion sort:</p>\n\n<p>Given an input array $A$:</p>\n\n<pre><code>for i \u2190 1 to length(A)\n    j \u2190 i\n    while j &gt; 0 and A[j-1] &gt; A[j]\n        swap A[j] and A[j-1]\n        j \u2190 j - 1\n</code></pre>\n\n<p>is there a way to quantify how many swaps are needed to sort the input list? It's $O(n^2)$, but I want a more precise bound. A perfectly sorted array clearly needs no swaps (so insertion sort is $\\Omega(n)$), while a completely reversed array requires something on the order of $n^2$ swaps, but how do we quantify the number of swaps?</p>\n", 'ViewCount': '50', 'Title': 'How can I quantify the number of swaps required for insertion sort?', 'LastActivityDate': '2014-02-08T19:17:31.727', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '21456', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2860', 'Tags': '<algorithms><sorting>', 'CreationDate': '2014-02-08T18:42:15.473', 'Id': '21455'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I was <em>convinced</em> that my idea for a solution to sort $k$ sorted lists into one list would work with a 'variation' on MergeSort. I was told this would not work and had to use Heapsort, but didn't get any explanation or intuition behind it. (I believe the assumption is that each of the $k$ lists had size $\\frac{n}{k}$)</p>\n\n<p>Essentially, my intuition behind using Mergesort was that we have $n$ total elements, but all the steps below height $\\log k$ in our recursion tree had already been solved. So at height $\\log k$ each list is of size $\\frac{n}{k}$, so we perform $\\frac{n}{k}$ comparisons and $2\\frac{n}{k}$ inserts (to form a new list from the two $\\frac{n}{k}$ lists) $k$ times in total, which seems to be on the scale of $O(n)$. </p>\n\n<p>We are now one step up on the recursion tree with $\\frac{k}{2}$ lists and we will eventually perform $O(n)$ operations $\\log k$ times.</p>\n\n<p>Can anyone provide insight as to why this intuition is wrong? Or if right, how I should go about formally proving it?</p>\n", 'ViewCount': '97', 'Title': 'Given $k$ sorted lists, $O(n \\log k)$ complexity, Mergesort rather than Heapsort', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-18T21:28:30.520', 'LastEditDate': '2014-02-18T21:28:30.520', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '21788', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '12906', 'Tags': '<algorithms><sorting>', 'CreationDate': '2014-02-18T20:13:25.730', 'Id': '21786'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Say $A'$ is the output of $\\mathrm{Bubblesort}(A)$ on an array of length $N$.\nTo prove that Bubblesort works, we have to prove that it always terminates and that\n$$A'[0]\\leq A'[1] \\leq \\dots \\leq A'[N-1].$$\nIs there anything else that needs to be proven to show that Bubblesort actually sorts?</p>\n\n<p>(I have found this question in a textbook about algorithms.)</p>\n", 'ViewCount': '170', 'Title': 'Proving the Bubblesort actually sorts', 'LastEditorUserId': '683', 'LastActivityDate': '2014-02-21T14:37:04.937', 'LastEditDate': '2014-02-21T14:08:46.187', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14724', 'Tags': '<algorithms><sorting><arrays>', 'CreationDate': '2014-02-21T12:53:59.497', 'Id': '21883'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '248', 'Title': 'QuickSort Dijkstra 3-Way Partitioning: why the extra swapping?', 'LastEditDate': '2014-03-18T10:08:54.497', 'AnswerCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15391', 'FavoriteCount': '1', 'Body': u'<p><img src="http://i.stack.imgur.com/qeA2F.png" alt="Algorithm"></p>\n\n<p>Given the algorithm above (taken from the <a href="https://d396qusza40orc.cloudfront.net/algs4partI/slides/23Quicksort.pdf" rel="nofollow">slides</a> (p. 35) of the <a href="http://coursera.org" rel="nofollow">Coursera</a> course \u201cAlgorithms Part I\u201d by Robert Sedgewick and Kevin Wayne), look at the scenario where i is at "X", the following happens:</p>\n\n<p><strong>Scenario:</strong> i -> "X", "X" > "P"</p>\n\n<pre><code>1. swap("X", "Z"), gt--;   // the value at i is now "Z", which is still &gt; "P"\n2. swap("Z", "Y"), gt--;   // the value at i is now "Y", which is still &gt; "P"\n3. swap("Y", "C"), gt--;    // Now we finally get a value at i "C" which is &lt; "P"\n// Now we can swap values at i and lt, and increrement them\n4. swap("P", "C"), i++, lt++;\n</code></pre>\n\n<p>Why don\'t we just decrement gt until gt points to a value that is &lt; the value at lt ("P" in this case), then we swap this value with the value at i. This will save swapping operations.</p>\n\n<p>So if we do that for the scenario mentioned above, we\'ll do:</p>\n\n<pre><code>1. gt--\n2. gt--\n3. swap("X", "C"), gt--;   \n// Now we can swap values at i and lt, and increrement them\n4. swap("P", "C"), i++, lt++;\n</code></pre>\n\n<p>Is this excessive swapping needed for the algorithm? does it improve performance in some way?\nIf it does improve performance, how? </p>\n\n<p>If it doesn\'t affect performance, please give a proper explanation or a proof as to why this it does not affect performance. </p>\n\n<p>Also, would the second method I mentioned affect performance in any way? please explain why.</p>\n\n<p>P.S. "Affect performance" as used above means either improve/degrade performance.</p>\n', 'Tags': '<algorithms><sorting><quicksort>', 'LastEditorUserId': '133', 'LastActivityDate': '2014-03-24T05:53:55.407', 'CommentCount': '7', 'AcceptedAnswerId': '22395', 'CreationDate': '2014-03-08T05:27:19.077', 'Id': '22389'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '874', 'Title': 'Why is Quicksort described as "in-place" if the sublists take up quite a bit of memory? Surely only something like bubble sort is in-place?', 'LastEditDate': '2014-03-14T09:28:19.193', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '15572', 'FavoriteCount': '2', 'Body': '<p>Quicksort is described as "in-place" but using an implementation such as:</p>\n\n<pre><code>def sort(array):\n    less = []\n    equal = []\n    greater = []\n    if len(array) &gt; 1:\n        pivot = array[0]\n        for x in array:\n            if x &lt; pivot:\n                less.append(x)\n            if x == pivot:\n                equal.append(x)\n            if x &gt; pivot:\n                greater.append(x)\n        return sort(less) + equal + sort(greater)\n    else:\n        return array\n</code></pre>\n\n<p>You have to create a copy of the list for each recursion. By the first return, in memory we have:</p>\n\n<ul>\n<li>array</li>\n<li>greater+equal+less</li>\n</ul>\n\n<p>Then by the second recursion across all sub-lists we have:</p>\n\n<ul>\n<li>array</li>\n<li>greater, equal, less from first recursion</li>\n<li>greater+equal+less from less1, greater+equal+less from greater1</li>\n</ul>\n\n<p>etc...</p>\n\n<p>Is this just badly written code or am I correct in thinking that for a big list, you actually have to have, proportionally, a fair amount of extra space to store thse?</p>\n\n<p>When I think of something that is "in-place", I think of bubble sort, which simply swaps elements in the list like: <a href="http://en.wikipedia.org/wiki/File:Bubble-sort-example-300px.gif">http://en.wikipedia.org/wiki/File:Bubble-sort-example-300px.gif</a></p>\n\n<p>BubbleSort only requires 1 extra variable to store a potentially swapped element.</p>\n', 'Tags': '<algorithms><sorting><quicksort>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-14T11:57:21.597', 'CommentCount': '2', 'AcceptedAnswerId': '22517', 'CreationDate': '2014-03-11T22:51:08.497', 'Id': '22516'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Suppose an algorithm goes through a list of n integers and for every iteration of the loop it is needs to check if the current evaluated element of the list is even. If it is even, return the index of the integer that is evaluated as even.</p>\n\n<p>How come the algorithm would have 2n+1 comparison?</p>\n\n<p>I thought linear search would have n comparision because it is going through n elements. +1 comparison for the if statement. So that would make the algorithm O(n+1) comparison, no?. Where did the extra n come from?</p>\n\n<p>Pseudo-code:</p>\n\n<pre><code>procedure last_even_loc(a1,a2,...,an:integers);\nlocation = 0;\nfor i = 1 to n\n\n    if (a_i = 0) (mod 2) then location = i\n\nreturn location;\n</code></pre>\n', 'ViewCount': '66', 'Title': 'Why is there a 2n+1 comparison for a linear search algorithm?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-23T11:52:41.557', 'LastEditDate': '2014-03-23T11:52:41.557', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '22853', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15555', 'Tags': '<algorithms><algorithm-analysis><runtime-analysis><sorting>', 'CreationDate': '2014-03-20T03:45:36.143', 'Id': '22849'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Help would be much appreciated.  </p>\n\n<p>"Receive a number and reorder it from the largest to the smallest.<br>\nInput: 13252<br>\nOutput: 53221<br>\nCant use arrays...\nOnly while, for, if/else  ...</p>\n\n<p>any idea? i\'m clueless.<br>\nThanks for the help.</p>\n', 'ViewCount': '52', 'ClosedDate': '2014-03-27T08:39:14.710', 'Title': 'A home assignment. C language', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-27T08:39:56.697', 'LastEditDate': '2014-03-27T08:39:56.697', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16170', 'Tags': '<algorithms><sorting>', 'CreationDate': '2014-03-26T22:20:53.537', 'Id': '23102'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>When getting source array length, I want to generate the array of swaps that need to be performed in order to sort the source array. I want to make this array <strong>as small as possible</strong>. Swaps will be performed only if necessary for sorting.</p>\n\n<p>Example </p>\n\n<ul>\n<li>input: <strong>3</strong>; </li>\n<li>Output: <strong>[0,1 , 1,2 , 0,1];</strong></li>\n</ul>\n\n<p>I want to understand how to calculate the number of such swaps and how exactly to generate such array.</p>\n\n<p><strong>Edit:</strong> Some thing like <a href="http://pages.ripco.net/~jgamble/nw.html" rel="nofollow">network sorting</a>.</p>\n', 'ViewCount': '84', 'Title': 'Find the minimum amount of swaps to sort array', 'LastEditorUserId': '10572', 'LastActivityDate': '2014-03-30T15:07:02.737', 'LastEditDate': '2014-03-30T14:30:19.207', 'AnswerCount': '2', 'CommentCount': '6', 'AcceptedAnswerId': '23259', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10572', 'Tags': '<algorithms><sorting>', 'CreationDate': '2014-03-30T10:44:53.997', 'Id': '23251'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '47', 'Title': "Why don't we calculate swaps and other steps except comparison for finding time complexity of a sorting algorithm?", 'LastEditDate': '2014-04-02T15:14:24.200', 'AnswerCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14498', 'Body': '<p>I was learning some basic sorting techniques with their complexity. However I cannot understand why only the number of comparisons are taken into account while calculating time complexity and operations such as swap are ignored. <a href="http://en.wikipedia.org/wiki/Selection_sort#Analysis" rel="nofollow">Link to selection sort analysis</a>. Please help me understand.</p>\n', 'ClosedDate': '2014-04-02T15:14:58.270', 'Tags': '<algorithm-analysis><runtime-analysis><sorting>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-02T15:14:24.200', 'CommentCount': '2', 'AcceptedAnswerId': '23341', 'CreationDate': '2014-04-02T13:06:10.697', 'Id': '23339'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '41', 'Title': 'Dual-pivot Quicksort reference implementation?', 'LastEditDate': '2014-04-25T06:56:55.333', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7533', 'FavoriteCount': '2', 'Body': "<p>Has some sort of canonical - or reference - implementation of Dual-pivot Quicksort been posted anywhere?</p>\n\n<p>I would like to include that algorithm in a comparison among sorting algorithms for a specialized need that I have, but the Java versions I've seen appear to have various kinds of tweaks applied to them, like using Insertion Sort for small (sub-) arrays, which makes it harder to compare the fundamentals.</p>\n", 'Tags': '<algorithms><reference-request><sorting><quicksort>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-25T09:18:42.890', 'CommentCount': '7', 'AcceptedAnswerId': '24099', 'CreationDate': '2014-04-25T00:47:08.157', 'Id': '24092'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking on several algorithm. Usuall O(n log n) algorithms compare numbers as they are, there is not a change to get better than log performance.</p>\n\n<p>Fast nearly O(n) algorithms like Radix sort, Counting sort, Bitonic sort.. are using different approach and therefore can run "faster". The faster is usually joined with bigger memory usage. I have been looking / trying to create some algorithm, that can sort numbers in nearly O(n) but with usage of bit representation of numbers. So something similar to Radix sort, but in binary mode. Is there any algorithm like this, since I have not found any reference ?</p>\n', 'ViewCount': '28', 'ClosedDate': '2014-04-26T12:18:44.577', 'Title': 'Sorting algorithms for integer numbers - "binary mode"', 'LastActivityDate': '2014-04-25T18:25:24.487', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17083', 'Tags': '<algorithms><sorting>', 'CreationDate': '2014-04-25T18:25:24.487', 'Id': '24114'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The 1-D <strong>distinct</strong> closest pair of points problem is as follows: Given a set of n <strong>distinct integer</strong> points on real line, find a pair of points with the smallest distance between them, here the distance between two points p_i and p_j is absolute difference of their values, i.e, |p_i-p_j|. </p>\n\n<p>A naive way to solve this problem is to sort the points and check distance of each consecutive points in sorted order and take the minimum of such distances and this takes O(nlog n) time.</p>\n\n<p>My question is can we do better than that? Can we solve it in o(n log n)(note the little-oh) time? If not, then how to show an omega(nlog n) time bound for this problem?</p>\n\n<p>Note that, if the <strong>distinctness</strong> criteria was not there we could have shown a lower bound using Element Distinctness Problem.</p>\n', 'ViewCount': '20', 'Title': 'Linearithmic lower bound for 1-D "distinct" closest pair of points problem', 'LastActivityDate': '2014-04-25T20:06:05.070', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24116', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '15697', 'Tags': '<algorithms><data-structures><sorting><lower-bounds>', 'CreationDate': '2014-04-25T19:47:38.497', 'Id': '24115'}},