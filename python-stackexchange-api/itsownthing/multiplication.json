3740:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '130', 'Title': 'Carry-free multiplication operation', 'LastEditDate': '2013-10-30T17:32:48.187', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2755', 'FavoriteCount': '3', 'Body': '<p>In long-multiplication, you shift and add, once for each $1$ bit in the lower number.</p>\n\n<p>Let $r = p \\otimes q$ be an operation similar to multiplication, but slightly simpler: when expressed via long-multiplication, the addition does not carry. Essentially you bitwise-<strong>xor</strong> the shifted numbers.</p>\n\n<p>Like so:</p>\n\n<p>$$\n  \\left[\\begin{matrix}\n    &amp;&amp;p_n &amp; ... &amp; p_i &amp; ... &amp; p_2 &amp; p_1 \\\\\n    &amp;&amp;q_n &amp; ... &amp; q_i &amp; ... &amp; q_2 &amp; q_1 &amp; \\otimes\\\\\n    \\hline\\\\\n    &amp;&amp;q_1 \\cdot p_n &amp; ... &amp; q_1 \\cdot p_i\n      &amp; ... &amp; q_1 \\cdot p_2 &amp; q_1 \\cdot p_1\\\\\n    &amp;q_2 \\cdot p_n &amp; ... &amp; q_2 \\cdot p_i\n      &amp; ... &amp; q_2 \\cdot p_2 &amp; q_2 \\cdot p_1\\\\\n    &amp;&amp;&amp;&amp;&amp;&amp;&amp;...\\\\\n    q_i \\cdot p_n &amp; ... &amp; q_i \\cdot p_i\n      &amp; ... &amp; q_i \\cdot p_2 &amp; q_i \\cdot p_1 &amp; \\stackrel{i}{\\leftarrow}\n      &amp;&amp;{\\Huge{\\oplus}} \\\\\n    \\hline \\\\\n    \\\\r_{2n}&amp; ... &amp; r_i\n      &amp; ... &amp;r_4&amp; r_3 &amp; r_2 &amp;r_1 &amp; =\n  \\end{matrix}\n  \\right]\n$$</p>\n\n<p>Using the long-multiplication-style formulation, this takes $\\mathcal O\\left(\\max\\left(\\left|p\\right|,\\left|q\\right|\\right)^2\\right)=\\mathcal O\\left(\\left|r\\right|^2\\right)$ time. Can we do better? Perhaps we can reuse some existing multiplication algorithms, or even better.</p>\n\n<hr>\n\n<h2>Followup: <a href="http://cs.stackexchange.com/q/16585/2755">Shift-and-or multiplication operation</a></h2>\n', 'Tags': '<algorithms><integers><number-theory><multiplication>', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-10-30T17:32:48.187', 'CommentCount': '4', 'AcceptedAnswerId': '16581', 'CreationDate': '2013-10-30T16:33:37.543', 'Id': '16578'},3741:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Continuing in the same vein as <a href="http://cs.stackexchange.com/q/16578/2755">Carry-free multiplication operation</a>, a followup question is as follows (differences in bold):</p>\n\n<p>Let $r = p \\oplus q$ be an operation similar to multiplication, but slightly simpler: when expressed via long-multiplication the columns aren\'t summed up, but rather <strong>or</strong>\'d (not <strong>xor</strong>) together. Nothing is carried.</p>\n\n<p>$$\n  \\left[\\begin{matrix}\n    &amp;&amp;p_n &amp; ... &amp; p_i &amp; ... &amp; p_2 &amp; p_1 \\\\\n    &amp;&amp;q_n &amp; ... &amp; q_i &amp; ... &amp; q_2 &amp; q_1 &amp; \\otimes\\\\\n    \\hline\\\\\n    &amp;&amp;q_1 \\cdot p_n &amp; ... &amp; q_1 \\cdot p_i\n      &amp; ... &amp; q_1 \\cdot p_2 &amp; q_1 \\cdot p_1\\\\\n    &amp;q_2 \\cdot p_n &amp; ... &amp; q_2 \\cdot p_i\n      &amp; ... &amp; q_2 \\cdot p_2 &amp; q_2 \\cdot p_1\\\\\n    &amp;&amp;&amp;&amp;&amp;&amp;&amp;...\\\\\n    q_i \\cdot p_n &amp; ... &amp; q_i \\cdot p_i\n      &amp; ... &amp; q_i \\cdot p_2 &amp; q_i \\cdot p_1 &amp; \\stackrel{i}{\\leftarrow}\n      &amp;&amp;{\\bigvee} \\\\\n    \\hline \\\\\n    \\\\r_{2n}&amp; ... &amp; r_i\n      &amp; ... &amp;r_4&amp; r_3 &amp; r_2 &amp;r_1 &amp; =\n  \\end{matrix}\n  \\right]\n$$</p>\n\n<p>Using the long-multiplication-style formulation, this takes $\\mathcal O\\left(\\max\\left(\\left|p\\right|,\\left|q\\right|\\right)^2\\right)=\\mathcal O\\left(\\left|r\\right|^2\\right)$ time. Can we do better? Perhaps we can reuse some existing multiplication algorithms, or even better.</p>\n', 'ViewCount': '446', 'Title': 'Shift-and-or multiplication operation', 'LastActivityDate': '2013-10-30T19:44:37.417', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2755', 'Tags': '<algorithms><integers><number-theory><multiplication>', 'CreationDate': '2013-10-30T17:35:19.933', 'FavoriteCount': '2', 'Id': '16585'},3742:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Two matrices can be stored in either row major or column major order in contiguous memory. Does the time complexity of computing their multiplication vary depending on the storage scheme? That is, I want to know whether it will work faster if stored in row major or column major order.</p>\n', 'ViewCount': '83', 'Title': 'Does the performance of matrix multiplication depend on the storage of the array?', 'LastEditorUserId': '472', 'LastActivityDate': '2013-11-12T03:18:57.387', 'LastEditDate': '2013-11-10T23:05:57.370', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8533', 'Tags': '<algorithms><time-complexity><storage><multiplication>', 'CreationDate': '2013-11-10T04:00:59.373', 'Id': '17865'},3743:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Given the following multiplication table how could one construct an NFA such that it accepts all strings that have a certain product (say a) ? </p>\n\n<p>The string "abcb" would be evaluated as (a(b(cb))) = a</p>\n\n<p>\\begin{array}{c|ccc} \n    \\times &amp; a &amp; b &amp; c \\\\\n    \\hline \n    a &amp; a &amp; a &amp; c \\\\\n    b &amp; c &amp; a &amp; b \\\\\n    c &amp; b &amp; c &amp;a\n   \\end{array}</p>\n\n<p>I tried to take the transpose of the above matrix:</p>\n\n<p>\\begin{array}{c|ccc} \n    \\times &amp; a &amp; b &amp; c \\\\\n    \\hline \n    a &amp; a &amp; c &amp; b \\\\\n    b &amp; a &amp; a &amp; c \\\\\n    c &amp; c &amp; b &amp; a\n   \\end{array}</p>\n\n<p>And build an NFA for that. I then reversed all the transitions, but I don\'t think that works.</p>\n', 'ViewCount': '72', 'Title': 'NFA for right left multiplication', 'LastActivityDate': '2013-12-02T04:34:35.407', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11741', 'Tags': '<regular-languages><finite-automata><nondeterminism><multiplication>', 'CreationDate': '2013-12-01T20:37:27.720', 'Id': '18509'},3744:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m reading <a href="http://download-software.intel.com/sites/default/files/article/165685/clmul-wp-rev-2.01-2012-09-21.pdf">this Intel white paper on carry-less multiplication</a>. It describes multiplication of polynomials in $\\text{GF}(2^n)$. On a high level, this is performed in two steps: (1) multiplication of polynomials over $\\text{GF}(2)$, and (2) reducing the result modulo an irreducible polynomial. We use the "standard" bitstring representation of polynomials, i.e. $x^3+x+1 = [1011]$.</p>\n\n<p>The paper gives an algorithm for calculation of the remainder polynomial on page 16 in Algorithm 3. However, I\'m having trouble understanding the reduction algorithm on pages 16-17 (Algorithm 4). Essentially, I think we need Algorithm 4 for larger fields when our or partial results don\'t fit 128 bits anymore. They give an example for multiplication of two polynomials in $\\text{GF}(2^{128})$.</p>\n\n<blockquote>\n  <p>Where do the "magic constants" 63, 62, and 57 for right shifts, and the "magic constants" 1, 2, and 7 for left shifts come from?</p>\n</blockquote>\n\n<p>For example, how does one generalize the algorithm for smaller fields, say $\\text{GF}(2^{32})$? Would the corresponding shift values then be 15, 14, 9 and 1, 2, 7?</p>\n\n<blockquote>\n  <p>In the final step 4, the algorithm tells you to "XOR $[E_1:E_0]$, $[F_1:F_0]$, and $[G_1:G_0]$ with each other and $[X_3:D]$".</p>\n</blockquote>\n\n<p>Why do we do this? As far as I can see, the result of this XOR operation is neither stored anywhere nor used anywhere. Is it somehow used for computing $[H_1 : H_0]$?</p>\n', 'ViewCount': '79', 'Title': "Understanding Intel's algorithm for reducing a polynomial modulo an irreducible polynomial", 'LastEditorUserId': '16379', 'LastActivityDate': '2014-04-10T16:46:42.737', 'LastEditDate': '2014-04-08T12:51:39.823', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '23574', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '16379', 'Tags': '<algorithms><integers><polynomials><multiplication>', 'CreationDate': '2014-04-08T12:44:30.947', 'Id': '23549'},3745:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Does anyone have (or can easily write) an optimal inline assembly function for the M0+ processor in Thumb mode to multiply two 32-bit numbers and return a 64-bit number?</p>\n\n<p>As the M0+ does not have long multiply, the only way this can be accomplished is through primitive multiplication, for which the compiler calls __aeabi_lmul which performs 64x64=64 multiplication in 34 instructions. I'm hoping a significantly faster algorithm exists, given that the inputs are only 32 bits.</p>\n", 'ViewCount': '4', 'ClosedDate': '2014-04-25T07:00:02.017', 'Title': 'Fastest M0+ Thumb 32x32=64 Function?', 'LastActivityDate': '2014-04-25T03:25:01.580', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17060', 'Tags': '<algorithms><multiplication>', 'CreationDate': '2014-04-25T03:25:01.580', 'Id': '24093'}