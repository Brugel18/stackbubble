180_0:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': u'<p>Specifying any arbitrary 9x9 grid requires giving the position and value of each square. A na\xefve encoding for this might give 81 (x, y, value) triplets, requiring 4 bits for each x, y, and value (1-9 = 9 values = 4 bits) for a total of 81x4x3 = 972 bits. By numbering each square, one can reduce the positional information to 7 bits, dropping a bit for each square and a total of 891 bits. By specifying a predetermined order, one can reduce this more drastically to just the 4 bits for each value for a total of 324 bits. However, a sudoku can have missing numbers. This provides the potential for reducing the number of numbers that have to be specified, but may require additional bits for indicating positions.  Using our 11-bit encoding of (position, value), we can specify a puzzle with $n$ clues with $11n$ bits, e.g. a minimal (17) puzzle requires 187 bits.  The best encoding I\'ve thought of so far is to use one bit for each space to indicate whether it\'s filled and, if so, the following 4 bits encode the number. This requires $81+4n$ bits, 149 for a minimal puzzle ($n=17$). Is there a more efficient encoding, preferably without a database of each valid sudoku setup? (Bonus points for addressing a general $n$ from $N \\times N$ puzzle)</p>\n\n<p>It just occurred to me that many puzzles will be a rotation of another, or have a simple permutation of digits.  Perhaps that could help reduce the bits required.  </p>\n\n<p>According to <a href="http://en.wikipedia.org/wiki/Sudoku#Mathematics_of_Sudoku">Wikipedia</a>, </p>\n\n<blockquote>\n  <p>The number of classic 9\xd79 Sudoku solution grids is 6,670,903,752,021,072,936,960 (sequence A107739 in OEIS), or approximately $6.67&#215;10^{21}$.</p>\n</blockquote>\n\n<p>If I did my math right ($\\frac{ln{(6,670,903,752,021,072,936,960)}}{ln{(2)}}$), that comes out to 73 (72.498) bits of information for a lookup table.</p>\n\n<p>But:</p>\n\n<blockquote>\n  <p>The number of essentially different solutions, when symmetries such as rotation, reflection, permutation and relabelling are taken into account, was shown to be just 5,472,730,538[15] (sequence A109741 in OEIS).</p>\n</blockquote>\n\n<p>That gives 33 (32.35) bits, so it\'s possible that a clever method of indicating which permutation to use could get below the full 73 bits.</p>\n', 'ViewCount': '312', 'Title': 'Efficient encoding of sudoku puzzles', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:36:39.563', 'LastEditDate': '2012-04-22T16:36:39.563', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '12', 'Tags': '<combinatorics><modelling><information-theory><sudoku>', 'CreationDate': '2012-03-09T17:02:17.730', 'FavoriteCount': '0', 'Id': '165'},180_1:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '1098', 'Title': 'How to determine likely connections in a social network?', 'LastEditDate': '2012-04-22T16:33:09.770', 'AnswerCount': '4', 'Score': '20', 'PostTypeId': '1', 'OwnerUserId': '151', 'FavoriteCount': '2', 'Body': '<p>I am curious in determining an approach to tackling a "suggested friends" algorithm.</p>\n\n<p><a href="http://facebook.com">Facebook</a> has a feature in which it will recommended individuals to you which it thinks you may be acquainted with. These users normally (excluding the edge cases in <a href="http://www.facebook.com/help/?faq=154758887925123#How-do-I-suggest-a-friend-to-someone?">which a user specifically recommends a friend</a>) have a highly similar network to oneself. That is, the number of friends in common are high. I assume Twitter follows a similar path for their "Who To Follow" mechanism.</p>\n\n<p><a href="http://stackoverflow.com/a/6851193/321505">Stephen Doyle (Igy)</a>, a Facebook employee suggested that the related newsfeed that uses <a href="http://www.quora.com/How-does-Facebook-calculate-weight-for-edges-in-the-EdgeRank-formula">EdgeRank formula</a> which seems to indicate that more is to valued than friends such as appearance is similar posts. Another user suggested the Google Rank system. </p>\n\n<p>Facebook states their News Feed Optimization as $\\sum u_{e}w_{e}d_{e}$ where</p>\n\n<p>$u_{e}$ = affinity score between viewing user and edge creator<br>\n$w_{e}$ = weight for this edge (create, comment, like, tag, etc)<br>\n$d_{e}$ = time decay factor based on how long ago the edge was created   </p>\n\n<p>Summing these items is supposed to give an object\'s rank which I assume as Igy hinted, means something in a similar format is used for suggested friends.</p>\n\n<p>So I\'m guessing that this is the way in which connections for all types are done in general via a rank system?</p>\n', 'Tags': '<algorithms><machine-learning><modelling><social-networks>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:33:09.770', 'CommentCount': '2', 'AcceptedAnswerId': '314', 'CreationDate': '2012-03-12T23:24:54.360', 'Id': '261'},180_2:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>A drink dispenser requires the user to insert a coin ($\\bar c$), then press one of three buttons: $\\bar d_{\\text{tea}}$ requests a cup of tea $e_{\\text{tea}}$, ditto for coffee, and $\\bar r$ requests a refund (i.e. the machine gives back the coin: $\\bar b$). This dispenser can be modeled by the following <a href="http://en.wikipedia.org/wiki/Calculus_of_communicating_systems" rel="nofollow">CCS</a> process:</p>\n\n<p>$$ M \\stackrel{\\mathrm{def}}= c.(d_{\\text{tea}}.\\bar e_{\\text{tea}}.M + d_{\\text{coffee}}.\\bar e_{\\text{coffee}}.M + r.\\bar b.M)$$</p>\n\n<p>A civil war raises the price of coffee to two coins, while the price of tea remains one coin. We want a modified machine that delivers coffee only after two coins, and acquiesces to a refund after either one or two coins. How can we model the modified machine with a CCS process?</p>\n', 'ViewCount': '151', 'Title': 'CCS process for a drink dispenser with two different prices', 'LastEditorUserId': '39', 'LastActivityDate': '2013-09-17T17:42:36.120', 'LastEditDate': '2013-09-17T17:42:36.120', 'AnswerCount': '2', 'CommentCount': '3', 'AcceptedAnswerId': '446', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '39', 'Tags': '<logic><concurrency><modelling><process-algebras><ccs>', 'CreationDate': '2012-03-17T00:49:38.620', 'Id': '444'},180_3:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>The Eagles are a rock supergroup from the 70s and 80s, responsible for such classics as <em>Hotel California</em>. They have two quite distinctive sounds, one where guitarist Joe Walsh is present (for example, in <em>Life in the Fast Lane</em>) and one where he is absent. The latter songs have a markedly more sombre/boring feel.</p>\n\n<p>I'm curious to understand the degree to which an (unsupervised) learning algorithm would be able to detect the difference between the two sounds. One could imagine that it would be easy to tell the difference between speed metal and classical music, but what about sounds by the same band.</p>\n\n<blockquote>\n  <p>How would I set up such an experiment? Assume that I already have the relevant audio files in some standard format.</p>\n</blockquote>\n\n<p>Note that this should also apply to other rock groups, such as AC/DC who had a change of lead singer in 1980, and possibly even to other genres, possibly even more modern music.</p>\n", 'ViewCount': '315', 'Title': 'Clustering of Songs (The Joe Walsh Problem)', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:24:15.210', 'LastEditDate': '2012-04-22T16:24:15.210', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '19', 'PostTypeId': '1', 'OwnerUserId': '31', 'Tags': '<machine-learning><modelling>', 'CreationDate': '2012-03-19T11:33:08.247', 'FavoriteCount': '1', 'Id': '494'},180_4:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am trying to compare the performance of a classification result with Bayes classifier, K-NN, Piece wise component analysis (PCA). I have doubts regarding the following (please excuse my lack of programming skills since I am a biologist and not a programmer thus finding the Matlab documentation hard to follow).</p>\n\n<p>In the Matlab code </p>\n\n<pre><code>    Class = knnclassify(Sample, Training, Group, k)\n    Group =  [1;2;3]   //where 1,2,3 represents Class A,B,C respectively.\n</code></pre>\n\n<p>What goes in the sample because my data is a 100 row 1 column for each of the classes? So Group 1 contains data like $[0.9;0.1;......n]$ where $n=100$. Would the sample be a vector containing random mixtures of the data points from the three classes? Same question for the <code>Training</code> matrix.</p>\n', 'ViewCount': '110', 'Title': 'Pattern classification: what goes into the sample?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:13:55.830', 'LastEditDate': '2012-04-22T16:13:55.830', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<machine-learning><modelling><pattern-recognition>', 'CreationDate': '2012-04-02T06:06:42.343', 'Id': '983'},180_5:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I was interested on evaluating a catalogue that students would be using to observe how is it being used probabilistically. </p>\n\n<p>The catalogue works by choosing cells in a temporal sequence, so for example:</p>\n\n<ul>\n<li>Student A has: ($t_1$,$Cell_3$),($t_2$,$Cell_4$)</li>\n<li>Student B has: $(t_1,Cell_5),(t_2,Cell_3),(t_3,Cell_7)$. </li>\n</ul>\n\n<p>Assume that the cells of the table are states of a <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model" rel="nofollow">Hidden Markov Model</a>, so the transition between states would map in the real world to a student going from a given cell to another.</p>\n\n<p>Assuming that the catalogue is nothing more than guidance, it is expected to have a certain kind of phenomenon to occur on a given artifact. Consider this artifact to be unique, say, for example a program. </p>\n\n<p>What happens to this program is a finite list of observations, thus, for a given cell we have a finite list of observations for following the suggestion mentioned on that cell. On a HMM this would be then the probability associated to a state to generate a given observation in this artifact. </p>\n\n<p>Finally, consider the catalogue to be structured in a way that initially it is expected that the probability to start in a given cell is equal. The catalogue does not suggest any starting point. </p>\n\n<ul>\n<li><p><strong>Question 1</strong>: Is the mapping between the catalogue and the HMM appropriate?</p></li>\n<li><p><strong>Question 2</strong>: Assuming question 1 holds true. Consider now that we train the HMM using as entries $(t_1,Cell_1), (t_2,Cell_3) , ... (t_n,Cell_n)$ for the students. Would the trained HMM, once asked to generate the transition between states that it is most likely yields as result what is the most used way by the people who used the catalogue for a given experiment $\\epsilon$? </p></li>\n</ul>\n', 'ViewCount': '74', 'Title': 'Is it viable to use an HMM to evaluate how well a catalogue is used?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-19T02:04:32.233', 'LastEditDate': '2012-04-22T16:09:37.950', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '1132', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<probability-theory><empirical-research><modelling><hidden-markov-models>', 'CreationDate': '2012-04-07T23:04:00.013', 'Id': '1122'},180_6:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I once had a veteran in my course that created an algorithm that would suggest cooking recipes. At first, all sort of crazy recipes would come out. Then, she would train the cooking algorithm with real recipes and eventually it would suggest very good ones. </p>\n\n<p>I believe she used something related to Bayes Theorem or Clustering, but she is long gone and so is the algorithm. I have searched the internet but looking for cooking recipes will yield any sort of results but not the one I am looking for. So, my question is:</p>\n\n<blockquote>\n  <p>What techniques can be used to devise an algorithm that (randomly) suggests feasible recipes (without using a database of fixed recipes)?</p>\n</blockquote>\n\n<p>Why would I bother looking for a cooking algorithm? Well, it was a very good example of a real world application of the underlying concepts, and such algorithm could be useful in different settings that are closer to the real world.</p>\n', 'ViewCount': '769', 'Title': 'How to devise an algorithm that suggests feasible cooking recipes?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-03T16:52:16.993', 'LastEditDate': '2012-04-22T16:09:20.370', 'AnswerCount': '4', 'CommentCount': '24', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<machine-learning><artificial-intelligence><modelling><recommendation-systems>', 'CreationDate': '2012-04-08T00:17:14.350', 'FavoriteCount': '1', 'Id': '1124'},180_7:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>This question might seems vague but heres the context:</p>\n\n<p>When we are focusing on HCI we would most likely be interested on knowing first how the user usually deals with a certain object. We then try to see how our system could take away one of the tasks he would do himself and try to do it itself. </p>\n\n<ul>\n<li><p>The object of my interest here is a simple paper catalogue. How would you measure its usability (paper one). </p></li>\n<li><p>Then, how would you map it to a system interface? How would you measure the usability now on the system?</p></li>\n<li><p>How would you compare the two usabilities measures?</p></li>\n</ul>\n\n<p>This question narrows down this approach which is suggested on Stones book - User Interface and Evaluation. </p>\n\n<p>What the catalogue is about is not the point, that why I left it without a description: To avoid suggestions trying to measure what the catalogue is about. My focus here is on the particular mapping of this kind of object on the real world as a simple paper and when it is mapped to a system interface. Assume the catalogue to consist of rows and tables, where each matching row and table gives you a suggestion and you must first reason about each row and each column to see if it suits you (Perhaps you would suggest another template for the catalogue?).</p>\n', 'ViewCount': '50', 'Title': 'How can I measure the usability of a catalogue?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:07:59.883', 'LastEditDate': '2012-04-22T16:07:59.883', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '1173', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '983', 'Tags': '<empirical-research><modelling><hci>', 'CreationDate': '2012-04-09T06:58:17.557', 'Id': '1154'},180_8:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>(this is related to my other question, see <a href="http://cs.stackexchange.com/questions/1217/how-to-devise-an-algorithm-to-arrange-resizable-windows-on-the-screen-to-cover">here</a>)</p>\n\n<p>Imagine a screen, with 3 windows on it:</p>\n\n<p><img src="http://i.stack.imgur.com/vVUl3.jpg" alt="enter image description here"></p>\n\n<p>I\'d like to find an efficient data structure to represent this, while supporting these actions:</p>\n\n<ul>\n<li>return a list of coordinates where a given window can be positioned without overlapping with others\n<ul>\n<li>for the above example, if we want to insert a window of size 2x2, possible positions will be (8, 6), (8, 7), ..</li>\n</ul></li>\n<li>resizing a window on the screen without overlapping other windows while maintaining aspect ratio</li>\n<li>insert window at position x, y (assuming it doesn\'t overlap)</li>\n</ul>\n\n<p>Right now my naive approach is keeping an array of windows and going over all points on the screen, checking for each one if it\'s in any of the windows. This is $O(n\\cdot m\\cdot w)$ where $n, m$ are the width, height of the screen and $w$ is the number of windows in it. Note that in general $w$ will be small (say &lt; 10) where each window is taking a lot of space.</p>\n', 'ViewCount': '93', 'Title': 'Efficient queriable data structure to represent a screen with windows on it', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T11:39:14.260', 'LastEditDate': '2012-04-22T11:39:14.260', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1042', 'Tags': '<algorithms><computational-geometry><user-interface><modelling>', 'CreationDate': '2012-04-14T12:08:18.573', 'Id': '1268'},180_9:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>(this is related to my other question, see <a href="http://cs.stackexchange.com/questions/1217/how-to-devise-an-algorithm-to-arrange-resizable-windows-on-the-screen-to-cover">here</a>)</p>\n\n<p>I would like to write a function that scores a given arrangement of windows on a screen.</p>\n\n<p>The purpose of this function is to determine whether a particular layout is good and by going over other possible layouts, finding the one with the highest score.</p>\n\n<p>Here are some characteristics that I think make a good layout:</p>\n\n<ol>\n<li>maximizing amount of space used by windows (or in other words, the free space on the screen should be minimized)</li>\n<li>windows are (more or less) evenly sized</li>\n</ol>\n\n<p>Bonus: assigning each window a priority and giving a higher score for layouts where windows with a higher priority take more space.</p>\n\n<p>Here\'s an example: Suppose our screen is 11x11 and we want to put two windows on it. Window A\'s initial size is 1x1 and window B is 2x1.</p>\n\n<p>When we resize windows, we preserve their aspect ratio. So here are two possible layout:</p>\n\n<p><img src="http://i.stack.imgur.com/zG3bg.jpg" alt="enter image description here"></p>\n\n<p>The function should give the one on the right a higher score.</p>\n\n<p>Another nice thing to have is the option to \'dock\' a window to one or more sides of the screen. Then suppose we want to dock A to the bottom-left of the screen, the scoring function should prefer this layout than the above one on the right:</p>\n\n<p><img src="http://i.stack.imgur.com/Ol6Vw.jpg" alt="enter image description here"></p>\n', 'ViewCount': '89', 'Title': 'How to score a given arrangement of windows on a screen to produce good layouts', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T15:58:40.977', 'LastEditDate': '2012-04-22T15:58:40.977', 'AnswerCount': '1', 'CommentCount': '7', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1042', 'Tags': '<computational-geometry><user-interface><modelling>', 'CreationDate': '2012-04-14T15:24:22.837', 'Id': '1274'},180_10:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm trying to figure out a way I could represent a Facebook user as a vector. I decided to go with stacking the different attributes/parameters of the user into one big vector (i.e. age is a vector of size 100, where 100 is the maximum age you can have, if you are lets say 50, the first 50 values of the vector would be 1 just like a thermometer).</p>\n\n<p>Now I want to represent the Facebook interests as a vector too, and I just can't figure out a way. They are a collection of words and the space that represents all the words is huge, I can't go for a model like a bag of words or something similar. How should I proceed? I'm still new to this, any reference would be highly appreciated.</p>\n", 'ViewCount': '101', 'Title': 'How to represent the interests of a Facebook user', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-22T16:01:26.117', 'LastEditDate': '2012-04-22T16:01:26.117', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1395', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1173', 'Tags': '<machine-learning><modelling><social-networks><knowledge-representation>', 'CreationDate': '2012-04-20T16:24:33.100', 'Id': '1394'},180_11:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am looking at a modelling tool and are trying to determine all the types of ways that you can model (at a rudimentary level) </p>\n\n<p>I remember seeing a list of ways in which you can connect or categorise information elements. basically the types were as follows:</p>\n\n<ul>\n<li>Lists - constitute a list of information elements</li>\n<li>Hierarchies- visualise information in a parent-child relationship (ie organisational chart)</li>\n<li><p>Flows - connect elements in a logical (lateral) flow (ie process model)</p>\n\n<p>Have you seen any reference to these types, or can you elaborate on the full list of "model types"</p></li>\n</ul>\n', 'ViewCount': '74', 'Title': 'What are the rudimentary types of information connectivity i.e. model types?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-08-14T20:46:24.903', 'LastEditDate': '2012-08-14T20:46:24.903', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2512', 'Tags': '<data-structures><information-theory><modelling><structured-data>', 'CreationDate': '2012-08-14T16:01:08.207', 'FavoriteCount': '1', 'Id': '3182'},180_12:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>There are N players and M objects, each of the objects has a value. Each player has a strategy in choosing an object. Each round a player will choose an object, many players can choose the same object. However the value of each object is divided evenly among every player that has chosen it. There will be 9000 rounds(choices) per game. Our goal is to maximize the values that we accumulate at the end of the game.</p>\n\n<p>Question: how can I build a probability distribution function for each playing assuming that their decisions are random variables?</p>\n\n<p>Current Approach: My current approach is to count the frequency of a player choosing a specific object and dividing by the total number of rounds, that would give a probability a player is likely to choose that specific object.</p>\n\n<p>Problem: With each player playing aggressively trying to be unpredictable as possible(noise), with my current approach the probability distribution functions are not accurate(9000 rounds doesn't seem to be enough data). Is there a better way to build these distribution functions?</p>\n\n<p>Note: I've read somewhere that (Bayes model and HMM) are more superior than frequency counts, but I am not sure how to adapt it to this situation.</p>\n", 'ViewCount': '114', 'Title': 'Building probability distribution functions from observation', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-20T09:28:55.593', 'LastEditDate': '2012-11-20T09:28:55.593', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4365', 'Tags': '<machine-learning><probability-theory><modelling>', 'CreationDate': '2012-11-20T00:58:46.293', 'Id': '6775'},180_13:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have a set of binary vectors where each vector represents one day of occupancy in a house and consists of 48 elements (each element for 30 minutes of the day). Each element can be 1 meaning that house was occupied and 0 for non occupied house.</p>\n\n<p>My task is to predict the next day based on the history of the same days (Monday from history of Mondays etc.). So far I am using hamming distance to find 5 most similar days in the history and from them I calculate the probabilities of the occupancy as a mean of those 5 numbers. When the probability is higher than some X, in my case 0.4, I predict it to be occupied.</p>\n\n<p>But there is definitely some more efficient way to do this, any algorithms that would capture the trend in the history?</p>\n', 'ViewCount': '24', 'Title': 'Predict binary occupancy vector from history of vectors', 'LastActivityDate': '2013-04-30T19:15:59.970', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7982', 'Tags': '<algorithms><modelling>', 'CreationDate': '2013-04-30T19:15:59.970', 'Id': '11681'},180_14:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am not sure if this is an appropriate place to ask, since the question may be related to software engineering.</p>\n\n<p>In embedded control domain, model-driven engineering allows a design model to be simulated before being used for code generation. I am wondering how the consistency is preserved between the simulated objects and the generated code? I know that normally the simulated objects are wrapped for the simulation environment. Is it possible to say exactly "what you simulate is what you get" in certain approaches?</p>\n\n<p>Could you please give me some advices.</p>\n\n<p>-Wei</p>\n', 'ViewCount': '21', 'Title': 'Simulation of a model', 'LastActivityDate': '2013-05-04T05:26:26.307', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8040', 'Tags': '<simulation><modelling>', 'CreationDate': '2013-05-04T05:26:26.307', 'Id': '11771'},180_15:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '724', 'Title': 'What randomness really is', 'LastEditDate': '2013-05-19T17:50:20.767', 'AnswerCount': '8', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '8255', 'FavoriteCount': '4', 'Body': '<p>I\'m a Computer Science student and am currently enrolled in System Simulation &amp; Modelling course. It involves dealing with everyday systems around us and simulating them in different scenarios by generating random numbers in different distributional curves, like IID, Gaussian etc. for instance. I\'ve been working on the boids project and a question just struck me that what exactly "random" really is? I mean, for instance, every random number that we generate, even in our programming languages like via the <code>Math.random()</code> method in Java, essentially is generated following an "algorithm".</p>\n\n<p>How do we really know that a sequence of numbers that we produce is in fact, random and would it help us, to simulate a certain model as accurately as possible?</p>\n', 'Tags': '<simulation><randomness><modelling>', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-06-17T01:36:33.863', 'CommentCount': '2', 'AcceptedAnswerId': '12137', 'CreationDate': '2013-05-19T16:49:58.083', 'Id': '12136'},180_16:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '110', 'Title': 'Peer grading design - choosing a graph, to get accurate rankings/ratings', 'LastEditDate': '2013-12-02T23:49:34.417', 'AnswerCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '11721', 'FavoriteCount': '3', 'Body': "<p><strong>Background.</strong> I am writing some code for semi-automated grading, using peer grading as part of the grading process. Students are given pairs of essays at a time, and the students have a slider to choose which is better and how much better it is.  e.g., the slider might look something like this:</p>\n\n<p><code>A---X-B</code></p>\n\n<p>Based on the results of the peer grading, essays are ranked and the teacher will then grade the top X% and bottom X% and scores for all essays will be automatically calculated based on this.  I have already come up with methods for doing this ranking/scoring process; that part works well.</p>\n\n<p><strong>My question.</strong> How should I select which pairs of essays to give to students?</p>\n\n<p>Simulations suggest we need an essay to be peer-graded at least 3 times, to get an accurate ranking.  Thus, each essay should appear in at least 3 of the pairs that are presented for peer grading.</p>\n\n<p>We can think of this as a graph problem.  Think of the essays as nodes.  Each edge represents a pair of essays that are presented during the peer grading process.  The accuracy results above suggest that the degree of each node (or of most nodes) should be at least 3.  What sort of graph should I use?  How should I generate the graph to be used during peer grading?</p>\n\n<p>One challenge is that if you have clusters in the graph, this will skew the peer-gradings.  For example, we wouldn't want to have high-quality essays peer-graded mostly against high-quality essays, because that would skew the results of the peer grading.</p>\n\n<p>What would you recommend?</p>\n\n<p>I think this problem could be modelled with a undirected graph using something like the following:</p>\n\n<ul>\n<li>Start by taking the node with the least degree and link it with the next least</li>\n<li>Continue until your average degree is at least 3</li>\n<li>Maximise node connectivity</li>\n<li>Minimise number of cliques</li>\n</ul>\n\n<p>Is this a good approach? If not what would you recommend instead?</p>\n", 'Tags': '<algorithms><graphs><modelling>', 'LastEditorUserId': '755', 'LastActivityDate': '2013-12-02T23:49:34.417', 'CommentCount': '5', 'AcceptedAnswerId': '18494', 'CreationDate': '2013-11-30T22:26:52.017', 'Id': '18493'},180_17:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>The classic example of a context-free grammar is $a^nb^n$. That is, $n$ occurrences of $a$ followed by an equal number of occurrences of $b$.</p>\n\n<p>Do such forms occur in the real world? Can you provide an example of a real-world case where there must be $n$ occurrences of something followed an equal number of occurrences of something else?</p>\n\n<p>Let me give an example: if I run an on-line store, then for each purchase made to my store, there must be a corresponding delivery of the purchased item. That might be modeled as $n$ purchases followed by $n$ deliveries:</p>\n\n<blockquote>\n  <p>purchase purchase purchase delivery delivery delivery</p>\n</blockquote>\n\n<p>However, that is not a good data model since each delivery should legitimately be paired to a purchase:</p>\n\n<blockquote>\n  <p>purchase delivery purchase delivery purchase delivery</p>\n</blockquote>\n\n<p>So I am left wondering if there are <em>any</em> real-world examples where data would be (legitimately) modeled as a sequence of $n$ items of one type followed by $n$ items of another type. Can you provide a real-world example please?</p>\n\n<p>Hendrik Jan provided this good example (see it in the comments below): <em>This weekend I visited my mother. Three flights up, and three flights down when I left.</em> </p>\n\n<p>Neat example! Can you think of others?</p>\n\n<p>A colleague just informed me of another example. In the KML specification it says that a &lt;Track> element must contain N &lt;when> elements followed by N &lt;gx:Coord> elements:</p>\n\n<p><a href="https://developers.google.com/kml/documentation/kmlreference#gxtrack" rel="nofollow">https://developers.google.com/kml/documentation/kmlreference#gxtrack</a></p>\n\n<p>Another excellent example. What are other examples?</p>\n\n<p>Another colleague sent me an article about columnar databases. It is often more efficient to store data in columns rather than rows. For example, we may have a column of person\'s ages followed by a column of person\'s heights. Or, a list of N integers (ages) followed by a list of N decimals (heights). This enables efficient calculation of sums or averages. Here\'s the article:</p>\n\n<p><a href="http://www.postgresql.org/message-id/52C59858.9090500@garret.ru" rel="nofollow">http://www.postgresql.org/message-id/52C59858.9090500@garret.ru</a></p>\n\n<p><strong>More examples please! I would like for us to create a nice collection of compelling examples.</strong></p>\n', 'ViewCount': '306', 'Title': 'Is $a^n b^n$ an artificial language or does it occur in the real world?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-06T10:16:16.683', 'LastEditDate': '2014-01-06T10:16:16.683', 'AnswerCount': '2', 'CommentCount': '8', 'OwnerUserId': '9907', 'Score': '4', 'PostTypeId': '1', 'CommunityOwnedDate': '2014-01-06T10:16:16.683', 'Tags': '<formal-languages><context-free><modelling>', 'CreationDate': '2014-01-03T13:12:13.693', 'Id': '19485'},180_18:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I would like to be able to represent circles in x-y coordinates.</p>\n\n<p>Each circle contains an x and y coordinates and radius in double data type.</p>\n\n<p>My goal is to compare circles with each other whether they are partially or completely overlapping.</p>\n\n<p>I am looking for efficient ideas. Honestly the only idea that comes to my mind is draw a line(let's say l1) from x1,y1 to x2,y2 and the length of this line is larger than addition of r1 and r2 then it does not overlap, if r1+r2 =&lt; l1 then it overlaps, but I don't know how to find whether it is completely overlapping or partially. Also this wouldn't work for cases where I am combining more than one circle.</p>\n", 'ViewCount': '74', 'Title': 'How to represent circles in x-y coordinates', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-07T09:54:25.833', 'LastEditDate': '2014-01-07T09:54:25.833', 'AnswerCount': '0', 'CommentCount': '10', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8849', 'Tags': '<algorithms><computational-geometry><modelling>', 'CreationDate': '2014-01-06T03:30:29.157', 'Id': '19525'}