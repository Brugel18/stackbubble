{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>In terms of references and their implementation on the heap and the stack, how is\nequality testing for arrays different from that for integers? </p>\n\n<p>This is to do with Java programming, if you have a stack and a heap, would equality testing for example <code>j == i</code> be the same for arrays and for integers? I understand that arrays, are stored in the heap and the stack, as it holds bulks of data, but integers are only stored in the stack and referenced in the heap.</p>\n\n<p><img src="http://i.stack.imgur.com/xtIHW.png" alt="this is a picture on how integer variables are stored on the heap and referenced on the heap"></p>\n\n<p>I understand for equality testing <code>j==i</code> (variables) the stack pointer will point to the same location.</p>\n\n<p>I\'m confused on how <code>j==i</code> would be different for array and integers.</p>\n\n<p>Could someone explain? </p>\n', 'ViewCount': '214', 'Title': 'Equality testing of arrays and integers in a procedural language', 'LastEditorUserId': '39', 'LastActivityDate': '2012-07-26T10:32:40.923', 'LastEditDate': '2012-05-19T18:11:42.023', 'AnswerCount': '2', 'CommentCount': '5', 'AcceptedAnswerId': '1935', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1376', 'Tags': '<programming-languages><arrays><semantics><equality><memory-management>', 'CreationDate': '2012-05-19T06:38:55.350', 'Id': '1919'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '2016', 'Title': 'Swap space management during pure demand paging', 'LastEditDate': '2012-05-29T08:49:23.003', 'AnswerCount': '1', 'Score': '8', 'OwnerDisplayName': 'shan23', 'PostTypeId': '1', 'OwnerUserId': '476', 'Body': '<p>The following is a doubt that I came across while doing a OS home assignment - however, it seems more concept-based than a straightforward coding question, so IMHO I don\'t think the homework tag is appropriate for this.</p>\n\n<p>In a pure demand paging scheme for multiple processes running at the same time, given a fixed amount of RAM and Swap memory, what happens in the following 2 cases w.r.t the swap space, when</p>\n\n<ol>\n<li><p>A process encounters a page-fault, and there are no free frames available in the RAM, hence requiring one of the pages from the process\' chunk of Kernel Frames to be written out to swap (for simplicity, I\'m not considering the copy-on-write case). Explicitly, where in the Swap space would this frame be written, and what data structures need to be updated for that?</p></li>\n<li><p>When a process needs to page-in a particular page, where does it look in the Swap memory, and how would it know if that particular page be present in Swap at all ?</p></li>\n</ol>\n\n<p>As you can well imagine, I\'m having difficulty understanding in what way to manage the Swap space during pure demand management scheme, and what data structures would be essential. It would be great if you could refer to any links in your answer (I searched in "Operating System Concepts - 8th edition by Silberschatz, I couldn\'t find an explicit answer for my question).</p>\n', 'Tags': '<operating-systems><memory-allocation><virtual-memory><paging><memory-management>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-30T07:49:30.313', 'CommentCount': '1', 'AcceptedAnswerId': '2169', 'CreationDate': '2012-05-22T18:51:13.247', 'Id': '2154'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I have a high interest in priority-queues (E.g., see my answers on: <a href="http://cs.stackexchange.com/q/524">Does there exist a priority queue with $O(1)$ extracts?</a>), and was wondering if there is a priority-queue or similar data-structure where you can sort by multiple values?</p>\n\n<p>For example, if I wanted to sort by <code>numval</code> and sort by <code>strval</code>, and be able to get the highest (G\xf6del numbering for str) in $\\mathcal{O}(1)$.</p>\n\n\n\n<pre><code>struct Node {\n    int numval;\n    std::string strval;\n};\n</code></pre>\n\n<p>Easily I can think to just maintain two priority-queues, but this would require twice the memory.</p>\n\n<p>Is there a better way?</p>\n', 'ViewCount': '214', 'Title': 'Queue that can sort by multiple priorities?', 'LastActivityDate': '2012-07-05T13:37:54.173', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1120', 'Tags': '<data-structures><asymptotics><efficiency><priority-queues><memory-management>', 'CreationDate': '2012-07-05T13:37:54.173', 'FavoriteCount': '2', 'Id': '2629'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Is there any book or tutorial that teaches us how to efficiently apply the common algorithms (sorting, searching, etc.) on large data (i.e. data that cannot be fully loaded into main memory) and how to efficiently apply those algorithms considering the cost of block transfer from external memory ? For example, almost all algorithm textbooks say that B and B+-trees can be used to store data on disk. However, actually how this can be done, especially handling the pointers where the data is present on disk is not explained. Similarly, though many books teach searching techniques, they do not consider data present in secondary memory. </p>\n\n<p>I have checked Knuth's book. Although it discusses these ideas, I still did not understand how to actually apply them in a high-level language. Is there any reference that discusses these details?</p>\n", 'ViewCount': '261', 'Title': 'Applying algorithms on large data', 'LastEditorUserId': '39', 'LastActivityDate': '2012-10-18T21:47:06.810', 'LastEditDate': '2012-10-18T21:21:53.663', 'AnswerCount': '3', 'CommentCount': '10', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '2596', 'Tags': '<algorithms><efficiency><memory-management><big-data>', 'CreationDate': '2012-08-22T11:10:59.273', 'Id': '3287'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Is it possible to design a compiler which optimizes a loop in which arrays are accessed in alternate fashion? For example like this:</p>\n\n<pre><code>// int[] a,b\nint sum = 0;\nfor(int i = 0; i &lt; n; i++)\n{\n  sum += a[i] + b[i];\n}\n</code></pre>\n\n<p>With the usual sequential array storage, <code>a[i]</code> and <code>b[i]</code> may be far away from each other in memory. Therefore, I think a good compiler optimization would detect that <code>a[i]</code> and <code>b[i]</code> are always accesses at the "same" time, and store the arrays interleaved, that is <code>a[0] b[0] a[1] b[1] ...</code> so that one memory access may retrieve both <code>a[i]</code> and <code>b[i]</code>.</p>\n', 'ViewCount': '101', 'Title': 'Are compilers able to detect alternating accesses to arrays and interleave them in memory?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-05T19:48:04.607', 'LastEditDate': '2012-09-05T19:48:04.607', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '3434', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><arrays><program-optimization><memory-management>', 'CreationDate': '2012-09-05T13:27:15.477', 'Id': '3433'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I was studying operating system concepts from <a href="http://rads.stackoverflow.com/amzn/click/0471417432" rel="nofollow">Silberschatz, Galvin and Gagne\'s book</a> (sixth edition) and I have some questions about the flow of execution of a program. A figure explains the processing of the user program:</p>\n\n<p><img src="http://i.stack.imgur.com/we3Si.jpg" alt="program flow diagram"></p>\n\n<p>We get an executable binary file when we reach the <strong>linkage editor</strong> point. As the book says,</p>\n\n<blockquote>\n  <p>The program must be brought into memory and placed within a process for it to be executed.</p>\n</blockquote>\n\n<p>I have several questions about this flow:</p>\n\n<ol>\n<li><p>Before the program is loaded into the memory, the binary executable file generated by the linkage editor is stored in the hard disk. The address where the binary executable file is stored in the hard disk is the logical address as generated by the CPU ? </p></li>\n<li><p>If the previous answer is yes, Why CPU has to generate the logical address ? I mean the executable file is stored somewhere in the hard disk which pertains to an address, why does CPU has to separately do the stuff ? CPU\'s main aim is processing after all! </p></li>\n<li><p>Why does the executable file needs to be in the physical memory i.e ram and can not be executed in the hard disk? Is it due to speed issues ?</p></li>\n</ol>\n', 'ViewCount': '938', 'Title': 'Program compilation and execution flow', 'LastEditorUserId': '39', 'LastActivityDate': '2012-10-20T14:41:54.223', 'LastEditDate': '2012-10-20T14:41:54.223', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6191', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4284', 'Tags': '<compilers><operating-systems><memory-management><virtual-memory>', 'CreationDate': '2012-10-20T07:24:13.227', 'Id': '6187'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>If we let the physical memory size remain constant,</p>\n\n<ul>\n<li>What effect does the size of the page have on the number of frames? </li>\n<li>What effect does the number of frames have on the number of page faults?</li>\n</ul>\n\n<p>Also, please provide reference strings as an example.  </p>\n', 'ViewCount': '1672', 'Title': 'How does increasing the page size affect the number of page faults?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-11-22T14:25:54.897', 'LastEditDate': '2012-11-21T22:09:21.933', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4676', 'Tags': '<operating-systems><memory-management><virtual-memory><paging>', 'CreationDate': '2012-11-21T13:58:21.313', 'FavoriteCount': '1', 'Id': '6813'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>The following problem was on my final and in <code>Gate 2006</code>, but I don't understand how to solve it:</p>\n\n<p>Different methods of memory management have different overheads:</p>\n\n<ul>\n<li>The paging method for memory management uses two-level paging, and its storage overhead is $P$. </li>\n<li>The storage overhead for the segmentation method is $S$.  </li>\n<li>The storage overhead for the segmentation and paging method is $T$.</li>\n</ul>\n\n<blockquote>\n  <p>What is the relation among the overheads in the concurrent execution of the processes below?</p>\n  \n  <p>(a) $P &lt; S &lt; T \\hspace{2em}$<br>\n  (b) $S &lt; P &lt; T\\hspace{2em}$<br>\n  (c) $S &lt; T &lt; P\\hspace{2em}$<br>\n  (d) $T &lt; S &lt; P$</p>\n</blockquote>\n\n<pre><code>Process    Total Size (in KB)    Number of segments  \n P1              195                    4  \n P2              254                    5  \n P3               45                    3  \n P4              364                    8  \n</code></pre>\n\n<ul>\n<li>The page size is 1 KB.  </li>\n<li>The size of an entry in the page table is 4 bytes.  </li>\n<li>The size of an entry in the segment table is 8 bytes.  </li>\n<li>The maximum size of a segment is 256 KB.  </li>\n</ul>\n", 'ViewCount': '160', 'Title': 'Processes and Segmentation', 'LastEditorUserId': '39', 'LastActivityDate': '2012-12-24T15:32:23.540', 'LastEditDate': '2012-11-24T12:57:21.410', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'OwnerDisplayName': 'QueueTank', 'PostTypeId': '1', 'OwnerUserId': '4743', 'Tags': '<operating-systems><memory-management><storage><paging>', 'CreationDate': '2012-11-24T08:51:43.493', 'Id': '6867'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>I stumbled upon the <a href="http://msdn.microsoft.com/en-us/library/bb871031.aspx" rel="nofollow">MSDN Best Practices for Code Review</a>.</p>\n\n<p>Under the section \u201cUntrusted Inputs\u201d, I found following which I didn\'t understand properly. Why is the following considered safe?</p>\n\n<pre><code>printf("%s", buffer);\n</code></pre>\n\n<p>What kinds of guarantees does the C language give regarding the behavior of this snippet? Given that both <code>printf(buffer)</code> and <code>printf("%s", buffer)</code> are accepted by the compiler, why is one considered safer than the other \u2014\xa0shouldn\'t the unsafe version be rejected?</p>\n\n<hr>\n\n<p>Copied following text from the source:</p>\n\n<blockquote>\n  <p>Untrusted Inputs</p>\n  \n  <p>If the input buffer comes from an untrusted source, this can result in a security attack, as the input can contain formatting specifiers that will pull data off the stack. Additionally, it can cause buffer overflows by expanding the resulting string beyond expected limits:</p>\n  \n  <p><code>printf(buffer);</code></p>\n  \n  <p>These should always be converted to the following:</p>\n  \n  <p><code>printf("%s", buffer);</code></p>\n</blockquote>\n', 'ViewCount': '228', 'ClosedDate': '2013-10-04T18:48:55.540', 'Title': 'Handling untrusted string input in printf in C', 'LastEditorUserId': '39', 'LastActivityDate': '2013-10-09T18:42:36.423', 'LastEditDate': '2013-10-09T18:42:36.423', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4981', 'Tags': '<programming-languages><memory-management><security><typing><c>', 'CreationDate': '2012-12-10T05:08:17.723', 'Id': '7287'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am looking to calculate the physical address corresponding to a logical address in a paging memory management scheme. I just want to make sure I am getting the calculation right, as I fear I could be wrong somewhere.</p>\n\n<p>So, the data I have is as follows: </p>\n\n<ul>\n<li><p>The logical address: 717</p></li>\n<li><p>Logical memory size: 1024 bytes (4 pages)</p></li>\n<li><p>Page Table (Page number - Frame number):</p>\n\n<p>(0 - 5), (1 - 2), (2 - 7), (3 - 0)</p></li>\n<li><p>Physical memory: 16 frames</p></li>\n</ul>\n\n<p>So, with 1024 bytes in the logical memory, and 4 pages, then each page is 256 bytes. </p>\n\n<p>Therefore, the size of the physical memory must be 4,096, right? (256*16). </p>\n\n<p>Then, to calculate the logical address offset: </p>\n\n<blockquote>\n  <p>1024 mod 717 = 307</p>\n</blockquote>\n\n<p>Is that how we calculate the offset? </p>\n\n<p>And, we can assume that 717 is in page 2 (1024 / 717 = 2.8)? </p>\n\n<p>So, according to the page table, the corresponding frame number is 3. </p>\n\n<p>And so to get the physical address, we multiply the frame number and page size? </p>\n\n<blockquote>\n  <p>2 * 256 = 768</p>\n</blockquote>\n\n<p>Then, do we add the offset, like so: </p>\n\n<blockquote>\n  <p>768 + 307 = 1,075</p>\n</blockquote>\n\n<p>Thank you for taking the time to read. If I don't quite have this correct, would you be able to advise on the correct protocol to calculating this? </p>\n", 'ViewCount': '4295', 'Title': 'How to work out physical address corresponding to logical address?', 'LastActivityDate': '2013-11-19T09:58:00.347', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '7745', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '2420', 'Tags': '<operating-systems><memory-management><paging>', 'CreationDate': '2013-01-03T23:51:55.903', 'Id': '7743'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>There are three typical ways to allocate memory for programs: static, stack and dynamic heap. However, when I look at the implementation of <a href="http://en.wikipedia.org/wiki/Memory_management" rel="nofollow">dynamic heap memory allocation from wikipedia </a>, what I found is fixed block allocation, etc. So why is dynamic memory allocation called "heap" memory allocation? How does it have something to do with "heap"?</p>\n', 'ViewCount': '58', 'Title': 'How Does Dynamic Heap Storage Have Something to Do with Heap?', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-01-05T10:28:27.700', 'LastEditDate': '2013-01-05T10:13:06.000', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7783', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<programming-languages><compilers><operating-systems><memory-management><memory-allocation>', 'CreationDate': '2013-01-05T07:43:53.093', 'Id': '7776'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="http://en.wikipedia.org/wiki/Page_frame" rel="nofollow">WP</a> has a adequate discussion of <em>paging</em>, which I think I understand.. However I am confused by the articles repeated use of the term <em>Page Frame</em>.</p>\n\n<p>I thought frames and pages were different things.  Could someone please clarify the difference.</p>\n', 'ViewCount': '937', 'Title': "What is the difference between a 'page' or memory and a 'frame' of memory?", 'LastActivityDate': '2013-04-30T07:03:53.967', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11670', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7421', 'Tags': '<memory-management>', 'CreationDate': '2013-04-30T05:21:02.913', 'Id': '11667'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am studying Computer Systems. I have th following question and its answer:</p>\n\n<blockquote>\n  <p>Given the logical address 0xAEF9 (in hexadecimal) with a page size of\n  256 bytes, what is the page number?</p>\n  \n  <p>Answer: <strong>0xAE</strong> (I found this answer in the web, but I want to know how can I\n  figure it out myself?</p>\n</blockquote>\n\n<p>How can I figure out the page number for a given logical address?</p>\n', 'ViewCount': '685', 'Title': 'Given the logical address, how to extract the page number?', 'LastEditorUserId': '7492', 'LastActivityDate': '2013-05-04T16:36:05.083', 'LastEditDate': '2013-05-04T03:36:34.570', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '11721', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4492', 'Tags': '<operating-systems><memory-management><paging><virtual-memory>', 'CreationDate': '2013-05-02T06:12:58.093', 'Id': '11719'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>Given the following exercise from Operating System Concepts Essentials 1st Edition, Chapter 8 Virtual Memory:</p>\n\n<blockquote>\n  <p>An operating system supports a paged virtual memory, using a central\n  processor with a cycle time of 1 microsecond. It costs an additional 1\n  microsecond to access a page other than the current one. Pages have\n  1,000 words, and the paging device is a drum that rotates at 3,000\n  revolutions per minute and transfers 1 million words per second. The\n  following statistical measurements were obtained from the system:</p>\n  \n  <ul>\n  <li>One percent of all instructions executed accessed a page other than\n  the current page.</li>\n  <li>Of the instructions that accessed another page, 80 percent accessed\n  a page already in memory.</li>\n  <li>When a new page was required, the replaced page was modified 50\n  percent of the time.</li>\n  </ul>\n  \n  <p>Calculate the effective instruction time on this system, assuming that\n  the system is running one process only and that the processor is idle\n  during drum transfers.</p>\n</blockquote>\n\n<p>And given the following answer from the textbook-companion website:</p>\n\n<blockquote>\n  <p>effective access time <strong>=</strong> 0.99 \xd7 (1 usec + 0.008 \xd7 (2 usec)</p>\n  \n  <p>+ 0.002 \xd7 (10,000 usec + 1,000 usec)</p>\n  \n  <p>+ 0.001 \xd7 (10,000 usec + 1,000 usec)</p>\n  \n  <p><strong>=</strong> (0.99 + 0.016 + 22.0 + 11.0) usec</p>\n  \n  <p><strong>=</strong> 34.0 usec</p>\n</blockquote>\n\n<p>I have the following formula for computing the effective access time:</p>\n\n<blockquote>\n  <p>effective access time = (1 - p) * memory access time + p * page fault time</p>\n</blockquote>\n\n<p>I am looking for an explanation of how the author came with his solution which is not relative to the formula given in the textbook?</p>\n', 'ViewCount': '2391', 'ClosedDate': '2014-02-28T03:26:21.297', 'Title': 'How to compute the effective access time in Virtual Memory system with demand paging?', 'LastEditorUserId': '4492', 'LastActivityDate': '2014-02-26T23:57:02.913', 'LastEditDate': '2013-05-05T22:38:51.813', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '4492', 'Tags': '<operating-systems><memory-management><virtual-memory>', 'CreationDate': '2013-05-05T22:32:20.517', 'Id': '11813'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Suppose I have a system with 32-bit logical and 16-bit physical address spaces, and the page size is 512 bytes. For simplicity, ignore the valid/invalid bits in the page table.</p>\n\n<p>How many sections will the logical address be divided and how many bits will each section have? The logical address will be divided into three sections, one section for the outer page, one for the inner page, and one for the offset. The outer page section contains 13 bits. The inner page contains 10 bits. The offset section will contain 9 bits. Is this right?</p>\n\n<p>Will the structure of the page table have 2 levels? How would I convert a logical address into a physical address?</p>\n', 'ViewCount': '1019', 'Title': 'Hierarchical Paging', 'LastEditorUserId': '98', 'LastActivityDate': '2013-06-10T09:44:05.930', 'LastEditDate': '2013-06-10T09:44:05.930', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12569', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6723', 'Tags': '<operating-systems><memory-management><paging>', 'CreationDate': '2013-06-09T08:14:15.350', 'Id': '12556'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I know that for executing a program, it should be copied to RAM. But the problem is whole of it may not be copied always. </p>\n\n<p>Since the size of the RAM is limited, there is mechanism called virtual memory. If the addressed thing is not in memory, a page fault occurs and the data is copied to the RAM. My question is who keeps track of which data is in the RAM and not in the RAM?</p>\n', 'ViewCount': '81', 'Title': 'How a program is copied to RAM from harddisk', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-16T10:11:46.007', 'LastEditDate': '2013-07-16T10:11:46.007', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13275', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '947', 'Tags': '<operating-systems><memory-management><virtual-memory><memory-access>', 'CreationDate': '2013-07-15T01:55:36.963', 'Id': '13274'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '436', 'Title': 'Despite it is so important, why don\'t computer science departments offer a class named "memory management"?', 'LastEditDate': '2013-07-16T10:09:37.950', 'AnswerCount': '1', 'Score': '4', 'OwnerDisplayName': 'Kutluhan Metin', 'PostTypeId': '1', 'OwnerUserId': '8744', 'Body': "<p>I don't understand why computer science departments don't offer a class named memory management? I see that most of the problems encountered in computer science are about memory management concepts. As being a computer science student, my department does not offer a class about that. I took a class named file organization which helped me understand harddisk management, I would like to learn memory management very well. If is there anybody who can explain this, it would be very useful.</p>\n", 'ClosedDate': '2014-02-02T11:25:24.150', 'Tags': '<computer-architecture><education><memory-management>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-30T17:48:20.853', 'CommentCount': '0', 'CreationDate': '2013-07-15T06:23:02.950', 'Id': '13278'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>In order to use large size page table hierarchical paging is done .\nIn case of two level page table scheme . for :\nlogical address space - 32bit - $2^32$ \npage size - 4kb i.e $2^12$</p>\n\n<p>It is mentioned that page number is divided evenly :</p>\n\n<pre><code>i.e page number p1 - 10 bits\n    page number p2 - 10 bits\n    page offset d - 12bits.\n</code></pre>\n\n<p>I got this...... but my question is different. I didn't get the concept behind it.<br>\nWhat I thought for that I will take 1 example.  </p>\n\n<p>Take the address <code>0x00FF1234</code>. The binary representation of this address is <code>00000000111111110001001000110100</code>. By splitting this up, we get <code>0000000011 1111110001 001000110100</code>, or <code>0x3 0x3F1 0x234</code>.  </p>\n\n<p><code>0000000011</code> this number  is pointing to 4th entry in the 1st level table. Means there are<br>\n <code>0000000000</code> to <code>1111111111</code> unique numbers ( entries ) in the 1st level table. These gives the address of the 2nd level table.<br>\n In this we are referring <code>0000000011</code> entry. Now does this entry contain some address which points to the base of the 2nd level table ? Now we are being pointed to 1111110001 address means <code>0000000011</code> containing <code>1111110001</code>  address ( I am thinking ) if yes then why only that address ? why not other address ?<br>\nMeans here I want to ask what exactly happens behind this jumping. And how ? I read somewhere here about <code>CR3</code> register and all that but didn't get anything. I don't want that much deep. I just want to solve basic example of paging , TLB , virtual memory for GATE exam.<br>\nAnd what is this page size ( I always consider it as d as offset and solving problem )<br>\nFor example : Page size is 1024 byte ... means d = 10 bytes. Does it mean , it ranges between 000....( 10 times) to 111....( 10 times) ? Not getting this concept properly. </p>\n", 'ViewCount': '470', 'LastEditorDisplayName': 'user742', 'Title': 'want to know concept behing Multilevel paging', 'LastActivityDate': '2013-09-06T23:05:04.197', 'LastEditDate': '2013-09-06T23:05:04.197', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9343', 'Tags': '<operating-systems><memory-management><paging>', 'CreationDate': '2013-09-06T20:03:09.237', 'FavoriteCount': '1', 'Id': '14178'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have come across a question that I am having quite a hard time with. I am to draw a design of an SRAM chip with an organization of 2M*128 SRAM that uses 1K*1K arrays of D latches. And then the questions ends with saying, "if this design is not possible then explain why." I have looked at other SRAM designs and have noticed that the multiplication of their d latch arrays, the resulting number is large enough to cover the first number of the SRAM, in this case 2M.</p>\n\n<p>The other example I was looking at had a 32K*8 SRAM chip with 512*64 arrays of d latches. Assuming the array size is also in K, I multiplied 512 by 64 and came up with 32768. This covers the 32K of the SRAM chip. With my first example above, I multiplied 1K by 1K or 1000 * 1000 = 1000000. This does not cover the 2M of the SRAM chip. So am I to believe that it\'s not possible to design this chip? Also I could be totally wrong. I do not have that much experience in electrical engineering so forgive me.</p>\n\n<p>Any help at all would be greatly appreciated in helping me!</p>\n\n<p>Thank you.</p>\n', 'ViewCount': '53', 'Title': 'Drawing the Design of an SRAM chip', 'LastActivityDate': '2013-09-28T19:38:49.713', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4336', 'Tags': '<memory-management><memory-hardware>', 'CreationDate': '2013-09-28T19:38:49.713', 'Id': '14659'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I often see people assert that reference counting techniques such as <code>shared_ptr</code> in C++ provide prompt collection (e.g. <a href="http://users.cecs.anu.edu.au/~steveb/downloads/pdf/rc-ismm-2012.pdf" rel="nofollow">here</a> and <a href="https://twitter.com/herbsutter/status/389144549517320192" rel="nofollow">here</a>) but I am not sure what exactly is meant by this. Some people tell me that they mean "collects at the earliest possible point" but I think that is not true of scope-based reference counting because it defers collection to the end of scope even if a variable is dead. Therefore, I\'m wondering if other people have a different interpretation that may be correct.</p>\n\n<p>Do computer scientists use the term "prompt" in this context and, if so, what do they mean by it?</p>\n\n<p>More concretely, I once studied the behaviour of various OCaml and F# programs and found that they often collect values before they fall out of scope and, therefore, more "promptly" than scope-based reference counting. For example, the following function runs in bounded memory:</p>\n\n<pre><code>let rec loop tmp i =\n  if i&lt;=0 then tmp else\n    loop (Array.copy (loop (Array.copy tmp) (i-1))) (i-100)\n</code></pre>\n\n<p>Even though the argument <code>tmp</code> is in scope for the entire body of the function it is collected before even the first recursive call to <code>loop</code>.</p>\n\n<p><strong>EDIT</strong> Here is a simpler F# example with a single recursive call and some post-processing to ensure that the call is not in tail position so it cannot be eliminated:</p>\n\n<pre><code>let rec loop tmp i =\n  if i&lt;=0 then tmp else\n    let tmp = loop (Array.copy tmp) (i-1)\n    tmp.[0] &lt;- tmp.[0] + 1\n    tmp\n</code></pre>\n\n<p>Between the copying of the array and the call to <code>loop</code> the argument <code>tmp</code> dies and, indeed, I find that it is garbage collected so this program requires only O(1) space.</p>\n\n<p>Here is the equivalent reference counted C++:</p>\n\n<pre><code>shared_ptr&lt;vector&lt;double&gt; &gt; loop(shared_ptr&lt;vector&lt;double&gt; &gt; tmp, int i) {\n    if (i&lt;=0) {\n        return tmp;\n    } else {\n        shared_ptr&lt;vector&lt;double&gt; &gt; tmp1(new vector&lt;double&gt;(*tmp));\n        shared_ptr&lt;vector&lt;double&gt; &gt; tmp2 = loop(tmp1, i-1);\n        ++(*tmp2)[0];\n        return tmp2;\n    }\n}\n</code></pre>\n\n<p>Although <code>tmp</code> dies between the creation of <code>tmp1</code> and the call to <code>loop</code>, scope-based reference counting keeps it allocated until the end of scope. So <code>n</code> recursive calls require O(n) space.</p>\n', 'ViewCount': '52', 'Title': 'What does "prompt collection" mean in the context of memory management?', 'LastEditorUserId': '10707', 'LastActivityDate': '2013-10-13T23:18:16.920', 'LastEditDate': '2013-10-13T23:18:16.920', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10707', 'Tags': '<memory-management>', 'CreationDate': '2013-10-13T14:26:36.753', 'Id': '16039'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>At the time of writing, Wikipedia describes determinism as:</p>\n\n<p><em>"a deterministic algorithm is an algorithm which, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states"</em></p>\n\n<p>That aligns with my interpretation of determinism as a natural scientist.</p>\n\n<p>If a program contains a benign race condition and its control flow varies depending upon the outcome of the race, is it deterministic? I would say not. However, many people describe thread-safe reference counting, such as <code>shared_ptr</code> in C++, as deterministic even though threads race to decrement the reference count to zero and the winner is responsible for executing the destructor.</p>\n\n<p>The <a href="http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29#Reference_counting" rel="nofollow">Wikipedia page about garbage collection</a> lists determinism as an advantage of reference counting compared to tracing collection and determinism is also referred to <a href="https://twitter.com/herbsutter/status/389144549517320192" rel="nofollow">here</a>. On the other hand, people have <a href="http://nerds-central.blogspot.co.uk/2011/11/reference-counting-if-not-deterministic.html" rel="nofollow">blogged rants</a> explaining why this is wrong.</p>\n\n<p>So what does "reference counting is deterministic" mean, if anything?</p>\n', 'ViewCount': '179', 'Title': 'What does "deterministic" mean in the context of memory management?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-02T17:34:35.060', 'LastEditDate': '2014-02-02T17:34:35.060', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10707', 'Tags': '<nondeterminism><memory-management>', 'CreationDate': '2013-10-15T10:18:08.177', 'Id': '16100'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '578', 'Title': 'Understanding the basic concepts in memory organisation', 'LastEditDate': '2013-11-02T10:30:47.990', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11125', 'FavoriteCount': '1', 'Body': '<p>(Before actually proceeding to the question, I want to confess that this is a homework question, please do consider it and help me in improving my understanding a bit more.)</p>\n\n<p>I have recently started learning computer organisation and architecture. I have gained fair understanding for how caches are organised, how mapping between cache and main memory takes place (direct , fully and set-associative mapping), what is a page table(what are pages, blocks etc.), i can that say I have basic knowledge of segmentation , paging, virtual address and physical addresses.( at the basic level ofcourse).</p>\n\n<p>Well I have come across this question:</p>\n\n<blockquote>\n  <p>A computer has 46-bit virtual address ,32- bit physical address, and a three \n     level page table organisation. The page table base-register stores the\n     base address of the first level table(t1), which occupies exactly one\n     page.Each entry of t1 stores the base address of the page of second level\n     table t2. Each entry of t2 stores the base address of the page of the third\n     level table t3. Each entry of t3 stores a page table entry (PTE). \n     The PTE is 32 bit in size. The processor used in the computer has a 1MB\n     16-way set associative virtually indexed physically tagged cache. The cache\n     block size is 64 Bytes.</p>\n</blockquote>\n\n<p>First of all I am facing difficulty in just imagining such type of a virtual computer. can any one help me by giving a simple steps on How to realize such a virtual computer on paper, or just how to understand what is given in the question. What is really asked? How would one represent a computer having a 46-bit virtual address and having three level page table?</p>\n\n<blockquote>\n  <p>What is virtually indexed and physically tagged cache?</p>\n</blockquote>\n\n<p>After reading what is given above, I feel that I just know the terms but I am unable to relate them together to solve problems. I will be glad If someone tries to explain how my thought process should be understand and apply these concepts practically to solve such types of problems.</p>\n\n<p>Some questions based on the above paragraph:</p>\n\n<ol>\n<li><p>What is the size of a page in KB in this computer?</p></li>\n<li><p>What is the minimum number of page colours needed to guarantee that no<br>\ntwo synonyms map to different sets in the processor cache of this computer?</p></li>\n</ol>\n\n<p>A good resource where such problems are actually taught to solve will a appreciated. Good articles and views are most welcome.</p>\n', 'Tags': '<memory-management><cpu-cache><virtual-memory>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-02T17:05:17.743', 'CommentCount': '2', 'AcceptedAnswerId': '16655', 'CreationDate': '2013-11-01T20:43:32.837', 'Id': '16630'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>An OS contains 10 identical processes that were initiated at the same time.Each process contains 15 identical requests. Each request consume 20 msec of CPU time.A request is followed by an I/O operation which consumes 10 msec.The CPU scheduling overhead is 2 msec. The system uses Round Robin scheduling with the time quantum of 10 msec.</p>\n\n<p>Q1) What is the response time of 1st request of last process ? \n  A) 210 msec  B) 140 msec  c) 230 msec  D) 240 msec</p>\n\n<p>Q2) The subsequent request of the processes receives a response times of \n A) 110 msec  B) 220 msec  C) 230 msec  D) 240 msec</p>\n\n<p>Ans: Q1) D</p>\n\n<pre><code> Q2) C\n</code></pre>\n\n<p>What I thought : </p>\n\n<p>For 1 process, there are 15 request so \n15 * ( 20 + 10) = 450 msec  But all answers are so small than this approach. So no need to think about further i.e. CPU overhead then 2nd...3rd...processes. </p>\n\n<p>Here my problem is I didn't get the concept behind this question properly. CPU overhead ( i.e context switching ) will take place between 10 processes or each process's 15 request.\nSo please tell how this scenario will work. </p>\n\n<p>I didn't get the meaning of 2nd question. </p>\n", 'ViewCount': '60', 'Title': 'processes response time confusion', 'LastEditorUserId': '9343', 'LastActivityDate': '2013-11-12T08:21:02.980', 'LastEditDate': '2013-11-12T05:00:57.927', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9343', 'Tags': '<operating-systems><memory-management><process-scheduling><threads>', 'CreationDate': '2013-11-11T18:54:01.780', 'Id': '17919'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I came to know that the graphic processing unit have something called memory coalescing. On reading on it I was not clear on the topic. Is this any way related to Memory Level Parallelism.</p>\n\n<p>I have searched in Google but was not able to obtain a satisfactory answer. </p>\n\n<p>It would be helpful if someone gives a more comprehensive, easy-to-understand explanation.</p>\n', 'ViewCount': '216', 'Title': 'What is "memory coalescing"?', 'LastEditorUserId': '11539', 'LastActivityDate': '2013-11-22T06:01:41.810', 'LastEditDate': '2013-11-22T06:01:41.810', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '18243', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '11539', 'Tags': '<terminology><reference-request><computer-architecture><memory-management>', 'CreationDate': '2013-11-21T17:58:55.743', 'Id': '18229'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I was taught that when a reference is mapped to a cache block, X, for the first time, the word is stored in the cache block, bearing a tag and index that helps identify it for future reads.  Then, when a later reference is deemed to have the same tag and index for cache block X, the value inside the cache block is returned as the read value. Is it the same process for multi-word caches?</p>\n\n<p>I was given a direct-mapped cache: Four 4-word blocks, 32 bits per word, and these word address references...</p>\n\n<pre><code>Ref   Tag   Index   Hit/Miss\n134   8     1       Miss\n212   13    1       Miss\n135   8     1       Hit\n213   13    1       Hit\n</code></pre>\n\n<p>...were what I determine to be the hit/miss for the references because the tags and the index match, even if the value is wrong.  But the answer key tells me the hit/miss for the references are:</p>\n\n<pre><code>Ref   Tag   Index   Hit/Miss\n134   8     1       Miss\n212   13    1       Miss\n135   8     1       Miss\n213   13    1       Miss\n</code></pre>\n\n<p>...so there's more involved when it comes to multi-word caches?  ...or the answer key is wrong.  Can anyone clarify?</p>\n", 'ViewCount': '103', 'Title': 'What determines a hit/miss with cache memory?', 'LastEditorUserId': '13093', 'LastActivityDate': '2014-01-24T14:28:38.767', 'LastEditDate': '2014-01-24T14:28:38.767', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11887', 'Tags': '<memory-management><cpu-cache>', 'CreationDate': '2013-12-06T22:00:59.117', 'Id': '18696'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Suppose that a processor can address directly up to 4 Gigabyte main memory and can operate words with size 32 bit. Find how big should be the size of the "<a href="http://en.wikipedia.org/wiki/Memory_address_register" rel="nofollow">MAR</a>" (memory address registers), "<a href="http://en.wikipedia.org/wiki/Memory_data_register" rel="nofollow">MDR</a>" (memory data registers) and accumulator registers in this computer?</p>\n\n<p>My answer: MDR is 32 bit wide since it exchanges data not only via the data bus but with the CPU data registers. How about MAR and accumulator? how are they related to the 4 gigabyte main memory?</p>\n', 'ViewCount': '143', 'Title': 'Size of address registers and data registers in relation with memory size', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-02-25T14:45:33.897', 'LastEditDate': '2013-12-27T11:14:59.383', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11906', 'Tags': '<computer-architecture><memory-management>', 'CreationDate': '2013-12-07T18:20:34.063', 'Id': '18724'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I came accross the question regarding program overlays, \n<br><br>\n<code>Program1 is of 100kB and program2 is of 90kB and common code is 10kB and overlay driver is 20kB and error handling routine is 50kB, min memory required when there is no error?</code></p>\n\n<p>according to me it should be 100 + 20 + 10 = 130; as there is no error.. \n<br>but ans is 180; they are considering error handling routine also in account..</p>\n\n<p>I am not getting why error handling routine, if there is no error? </p>\n', 'ViewCount': '46', 'Title': 'In case of program overlays; is it necessary to have error handling routine in memory, regardless of error?', 'LastActivityDate': '2013-12-24T15:23:20.667', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19249', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12221', 'Tags': '<operating-systems><memory-management><virtual-memory><memory-allocation>', 'CreationDate': '2013-12-24T09:10:47.167', 'Id': '19235'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have several confusion like : </p>\n\n<ol>\n<li><p>Does virtual address space resides in virtual memory ?</p></li>\n<li><p>Does each process has its own virtual address space like each process has its own virtual memory and own page table ?</p></li>\n<li><p>Mapping to physical address takes place from virtual memory or virtual address space if they are different thing ?</p></li>\n</ol>\n', 'ViewCount': '73', 'Title': 'Does virtual address space resides in virtual memory?', 'LastActivityDate': '2013-12-31T16:32:20.743', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12467', 'Tags': '<operating-systems><memory-management><paging><virtual-memory>', 'CreationDate': '2013-12-30T19:08:39.193', 'Id': '19383'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Seemingly, a byte has established itself to be 8bit (is that correct?). RAM and NOR-flash can be normally accessed on a quite granular level, but it is up to the system architecture to determine if the smallest addressable unit is 8bit, 16bit or any other power of two bit number. Would the correct terminology be to call this word-addressable? Or asked differently, is a word the size of smallest addressable unit? Or is there some other term to describe this? </p>\n\n<p>Are mabye nibble, byte, word, double word all variable in bit-length and only defined by the architecture? And it is therefore only coincidence that a byte is always 8 bit? E.g. someone could design some new CPU and memory type and define her byte to be 16bit?</p>\n\n<p><strong>Main question:</strong> What is the precise term for the smallest addressable memory block?</p>\n\n<p><strong>Side question:</strong> What is the antonym to this word I'm looking for (e.g. used in NAND-flash)? Page-addressable, block-addressable? Are both correct or is one inprecise?</p>\n", 'ViewCount': '323', 'Title': 'Word- or byte-addressable? Correct terminology', 'LastEditorUserId': '10634', 'LastActivityDate': '2014-01-20T16:42:35.543', 'LastEditDate': '2014-01-20T16:42:35.543', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10634', 'Tags': '<terminology><computer-architecture><memory-management><memory-access>', 'CreationDate': '2014-01-20T12:16:10.260', 'Id': '19848'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Yes, this is a homework question, I've tried working it out and was hoping I could get pointed in the right direction.</p>\n\n<p>Here's the question: </p>\n\n<p>You are designing the instruction set for a new type of computer. The \ncomputer has 64 instructions, 16 general-purpose registers. It supports a \nbyte-addressable memory of up-to 32MB. Answer the following questions. \na. For a 3-operand ADD instruction that only uses register addressing \nmode, how long (number of bits) should the instruction be? \nb. For a 2-operand ADD instruction, in which one of the operands is a \nmemory location with direct addressing mode, how long (number of \nbits) should the instruction be? </p>\n\n<p>I know the question's been asked recently but both questions and answers weren't helpful.</p>\n\n<p>I know that with 64 instructions and 16 registers, there must be 4 bits per register.  I don't exactly know the usage for the 32MB memory right now.</p>\n\n<p>A similar example of part (a) exists on wikipedia, where it states 4 instructions are needed for a 3-operand register addressing mode (load reg1 into a, load reg2 into b, add reg1 and reg2 to reg3, store reg3 in c).  Because it mentions 4 instructions, I thought that would be 1 bit, but that's a really small amount.  There are 3 registers used in the instruction, which would be 12 bits.</p>\n\n<p>For part (b), I believe one is a memory location with direct addressing mode (as stated) and the other is like part (a), using register addressing mode.  There are only two operands, but only one is using register addressing mode, meaning only one register is used?  In that case, the length of the instruction should be 4 bits.</p>\n\n<p>I would appreciate any help! If I'm misunderstanding some of the terms please let me know! Thanks!</p>\n", 'ViewCount': '171', 'Title': 'Information Set Architecture Question', 'LastActivityDate': '2014-01-28T20:02:22.443', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '13151', 'Tags': '<computer-architecture><memory-management>', 'CreationDate': '2014-01-27T01:31:30.527', 'Id': '20003'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>So this is a homework question but I have some solution and I am just confused, so a detailed example or help would be nice.</p>\n\n<p>You are designing the instruction set for a new type of computer. The computer has 64 instructions, 16 general-purpose registers. It supports a byte-addressable memory of up-to 32MB. Answer the following questions. a. For a 3-operand ADD instruction that only uses register addressing mode, how long (number of bits) should the instruction be? b. For a 2-operand ADD instruction, in which one of the operands is a memory location with direct addressing mode, how long (number of bits) should the instruction be?</p>\n\n<p>The question has been asked a couple times, and they are denied because they are homework question, but i just want some insight and help maybe example.</p>\n\n<p>here is my solution for problem a, would that be like: 3(cuz 3 add operand)(log2(64) + log2(16) +25(32MB to bites)) = 105? is that right or am i missing something wrong?</p>\n', 'ViewCount': '12', 'ClosedDate': '2014-01-28T22:34:46.180', 'Title': 'Instruction Set Architecture- Question', 'LastActivityDate': '2014-01-28T21:02:52.607', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '13197', 'Tags': '<computer-architecture><memory-management>', 'CreationDate': '2014-01-28T21:02:52.607', 'Id': '20046'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>When we declare a variable there will be a random part of memory will be allocated in RAM. Which component will allocate the memory? Is the processor or any other specific hardware doing the allocation?</p>\n', 'ViewCount': '59', 'Title': 'Which part of the computer allocates memory in RAM?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-08T01:01:08.070', 'LastEditDate': '2014-02-06T15:07:53.740', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14440', 'Tags': '<operating-systems><memory-management><memory-access><memory-hardware>', 'CreationDate': '2014-02-06T14:29:33.133', 'Id': '21378'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I read in <a href="http://www.cs.virginia.edu/~robins/The_Limits_of_Quantum_Computers.pdf" rel="nofollow">this article</a> that the amount of bits that can be emulated by a certain number of qubits is 2^(number of qubits). This is because each qubit can be in one of 2 states after it collapses, and so before all the quantum... whatevers collapse, that is the function that gets that result. At least, that was generally what it was saying, but I probably mangled the explanation myself; sorry.</p>\n\n<p>Anyway, this relation (2^n) happens to be the same as the relation between memory registers and RAM in classical computers (i.e. if the computer has n bits in the register, it can have up to 2^n bytes in RAM). Is this important? Does it mean qubits will become like the memory registers and their states like the RAM when we switch to quantum computers? Or is it just something that seems important but is actually meaningless in practice?</p>\n\n<p>By the way, there don\'t seem to be any tags for some things I referenced, like RAM &amp; memory registers. Is that because the site is so new, or am I just not looking hard enough?</p>\n', 'ViewCount': '35', 'Title': 'Qubits Related to RAM?', 'LastEditorUserId': '14777', 'LastActivityDate': '2014-02-18T00:15:53.710', 'LastEditDate': '2014-02-17T23:37:17.640', 'AnswerCount': '1', 'CommentCount': '5', 'AcceptedAnswerId': '21745', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14777', 'Tags': '<memory-management><quantum-computing>', 'CreationDate': '2014-02-17T22:52:31.283', 'Id': '21744'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>While reading Stallings OS Internals and Design, I run into problem. Here is example from the book. </p>\n\n<blockquote>\n  <p>For example, consider a simplified computer in which each instruction occupies one 16-bit word of memory. Assume that the PC is set to the location 300. On succeeding instruction cycles, it will fetch instructions from locations 301, 302, ... </p>\n</blockquote>\n\n<p>My question is: If the length of instructions is 16bits, and the smallest addressable unit of the memory is 1B, why on succeeding instruction cycles it will fetch instructions from locations 301 and 302, and not multiples of two, 302 and 304? </p>\n\n<p>Is the memory then organised as a sequence of 16bit long memory words? </p>\n', 'ViewCount': '18', 'Title': 'What memory locations will the CPU fetch instructions from with instruction length of 16bits', 'LastEditorUserId': '9219', 'LastActivityDate': '2014-03-01T18:12:22.970', 'LastEditDate': '2014-03-01T16:12:56.497', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '22163', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9219', 'Tags': '<operating-systems><memory-management>', 'CreationDate': '2014-03-01T16:04:28.047', 'Id': '22161'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>Garbage collections have to visit all objects that are alive, so as to find the memory that can be reclaimed.  (Having many generations\u2019 just delays this a bit)  </p>\n\n<p>All things being equal, it is clearly better to first visit the object that are already paged into RAM, before paging other block in and therefore paging out some object.</p>\n\n<p>Anther possibility is that when the OS wishes to take a page of ram away from the process, the GC is first asked if it has a page that can be given up without needing to be paged out.   The GC may  be mostly done with moving objects from a page, so can clear that page within the time limit the OS has for needing a page.</p>\n\n<p>Yet, I cannot recall any garbage collector that integrates with the OS paging system that drive the order the GC works in. </p>\n\n<p>(Please can someone with enough rep create an garbagecollector tag)</p>\n', 'ViewCount': '82', 'Title': 'Are there any garbage collectors that take into account paging?', 'LastEditorUserId': '15725', 'LastActivityDate': '2014-03-15T17:37:58.513', 'LastEditDate': '2014-03-15T15:48:59.967', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '15725', 'Tags': '<memory-management><paging>', 'CreationDate': '2014-03-15T14:57:46.177', 'FavoriteCount': '1', 'Id': '22649'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have the memory reference string for a multithreaded application and want to run this through a simulator which implements/approximates Belady\'s OPT page replacement algorithm.</p>\n\n<p>But what is the best way to do this?</p>\n\n<p>There is no problem with a single threaded approach - just look for the page in memory with longest reuse distance and get rid of it. But with multithreaded this becomes much more complex - we know what the reuse distances for each thread is, but we don\'t know the "combined" reuse distance.</p>\n\n<p>Practically, it\'s easy to get into the position where a page for one thread has a very long reuse distance and so gets chucked out when memory space is needed, only for it to be quickly faulted back in by another thread.</p>\n\n<p>I cannot find any scientific literature on this - but cannot believe it hasn\'t been studied before: does anyone know of any papers that consider this issue?</p>\n', 'ViewCount': '25', 'Title': "Implementing/approximating Belady's OPT for multithreaded environments (papers?)", 'LastActivityDate': '2014-03-16T22:39:32.250', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6712', 'Tags': '<memory-management><paging><program-optimization><threads>', 'CreationDate': '2014-03-16T22:39:32.250', 'Id': '22687'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '39', 'Title': 'Does exploiting a spatial Locality in Cache always leads to a lower miss rate?', 'LastEditDate': '2014-03-26T10:00:52.293', 'AnswerCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14769', 'FavoriteCount': '1', 'Body': "<p>I've read that, incorporating many words(spatial locality) per cache blocks leads to lower miss rate. Is it the case always? \nOne possibility of such approach is to make a single cache block of size equal to the size of the cache, but that would be meaningless as far as benefits of memory hierarchy are concerned. Isn't it so?</p>\n", 'Tags': '<computer-architecture><memory-management><cpu-cache>', 'LastEditorUserId': '14769', 'LastActivityDate': '2014-03-26T10:00:52.293', 'CommentCount': '0', 'AcceptedAnswerId': '22974', 'CreationDate': '2014-03-23T05:56:25.657', 'Id': '22960'}}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm new here, a brief intro, I'm a student majoring in comp-sci. Right now I'm having a bit confusion to answer one of my assignment, it is about system paging.</p>\n\n<p>I want to know how do I able to know what is the size of the memory of the following question.</p>\n\n<blockquote>\n  <p>there is a 64-bit computer system that uses pure paging with 16KB page size, if each page table entry is 4 bytes long...</p>\n</blockquote>\n\n<p>out of that question, I was asked to give:</p>\n\n<blockquote>\n  <p>(i) what is the maximum size of a page table?\n  (ii) Maximum size of user space main memory that can be supported and If hierarchical paging is used then what is the total level of hierarchies required? Assume that 2-level of hierarchy corresponds to an outer page table and an inner page table.</p>\n</blockquote>\n\n<p>I've read the materials regarding that question and I have a solution as follows:</p>\n\n<blockquote>\n  <p>64-bit computer system. \n      16KB page size = 16*1024 bytes = 16,384 bytes = $2^{14}$, \n      each page table entry is 4 bytes long</p>\n  \n  <p>i. Maximum size of a page table:\n  Size of page table = number of entries * size of entry\n      = $2^{50} \\times 2^5$\n      = $2^{55}$\n      = + 32768 terabytes \n  Number of entries = size of memory / page size.\n      = $2^{64} / 2^{14}$\n      = $2^{50}$</p>\n  \n  <p>ii. Total level of hierarchies required:\n      = number of bits available / number of entries\n      = 55/50\n      = 1 (rounded down)</p>\n</blockquote>\n\n<p>the one that struck me bewildered, because total level of hierarchies that I got is 1.  1 actually... Am I using a correct formula to count them?</p>\n\n<p>thank you for your time</p>\n", 'ViewCount': '136', 'Title': 'size of memory in 64-bit computer system', 'LastEditorUserId': '16325', 'LastActivityDate': '2014-04-01T23:00:22.560', 'LastEditDate': '2014-04-01T23:00:22.560', 'AnswerCount': '0', 'CommentCount': '11', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16325', 'Tags': '<operating-systems><memory-management><paging>', 'CreationDate': '2014-03-31T18:14:11.020', 'Id': '23298'}}