{'Body': '<p>I have observed that there are two different types of states in branch prediction.</p>\n\n<ol>\n<li><p>In superscalar execution, where the branch prediction is very important, and it is mainly in execution delay rather than fetch delay.</p></li>\n<li><p>In the instruction pipeline, where the fetching is more problem since the instructions do not actually get executed till later.</p></li>\n</ol>\n\n<p>Which of these is very important (as in which of these really matters in the CPU now-a-days)? If both are equally important or in case the second one is more important then Why do we not have two instruction pipeline (probably of half the length ) and then depending on the branches, just choose one of them and then again start the population from the beginning?</p>\n', 'ViewCount': '217', 'Title': 'Which kind of branch prediction is more important?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-11-14T00:40:54.050', 'LastEditDate': '2012-03-07T05:32:20.863', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '76', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '123', 'Tags': '<cpu-pipelines><computer-architecture>', 'CreationDate': '2012-03-07T05:11:43.907', 'Id': '73''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m looking for some relatively simple examples of when <a href="http://en.wikipedia.org/wiki/Hazard_%28computer_architecture%29#Structural_hazards">structural hazards</a> occur in a pipelined architecture.</p>\n\n<p>The only scenario I can think of is when memory needs to be accessed during different stages of the pipeline (ie, the initial instruction fetch stage and the later memory read/write stage).</p>\n\n<p>I\'m thinking that there are many more structural hazards in more complex architectures, such as superscalar. Does it class as a structural hazard when an instruction is dispatched to an execution unit but is queued because the unit is in use?</p>\n\n<p>If this is highly architecture-specific, then just assume MIPS or something similar.</p>\n', 'ViewCount': '531', 'Title': 'When do structural hazards occur in pipelined architectures?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-11-13T14:32:05.693', 'LastEditDate': '2012-05-19T21:12:39.830', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6646', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '1554', 'Tags': '<computer-architecture><cpu-pipelines>', 'CreationDate': '2012-05-19T20:49:42.443', 'Id': '1936''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm a little confused about the difference of the memory access and the write-back stage in a <code>RISC pipeline</code>.</p>\n\n<p>We learned in class these following assumptions:</p>\n\n<pre><code>arithmetic &amp; logic: IF, OF, EX, WB\nload: IF, OF, EX, MA, WB\nstore: IF, OF, EX, MA\nbranch: IF, OF, EX\n\nIF=Instruction Fetch, OF=Operand Fetch, EX=Execution, MA=Memory Access, WB=Write-Back\n</code></pre>\n\n<p>Lets say we have the following code now:<br><br>\n    <code>I1: LD R1, 0(R2) ; load R1 from address 0 + R2</code><br>\n    <code>I2: ADD R1, R1, #1 ; R1 = R1 + 1</code><br>\n    <code>I3: ST 0(R2), R1 ; Store R1 at address 0 + R2</code><br></p>\n\n<p>According to what I've learned <code>I1</code> will pass all five stages, <code>I2</code> won't have to access the memory, and <code>I3</code> won't have a write-back.</p>\n\n<p>But then I wonder, how and where does <code>I3</code> store the value then? Just in the memory? And <code>I2</code> fetches the value from memory, but needs to write-back to some place other than the memory? So does that mean that write-back is always to the HDD?</p>\n\n<p>I think I'm missing some core concepts here, as to where the operand is fetched from and where it gets stored to.</p>\n", 'ViewCount': '148', 'Title': 'Difference between memory access and write-back in RISC pipeline', 'LastEditorUserId': '12340', 'LastActivityDate': '2014-01-13T07:08:01.177', 'LastEditDate': '2014-01-13T07:08:01.177', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '19681', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12774', 'Tags': '<computer-architecture><cpu-pipelines>', 'CreationDate': '2014-01-12T14:04:36.507', 'Id': '19668''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p><strong>NOTE</strong>: Let me point out that I did try extensively to solve this on my own. The problem is that, based on that circuit, it would appear that this processor cannot jump. At best the jump instruction will propagate through the pipeline with no effect. There is no data path defined for a jump that tells the processor to change the PC. The only thing that changes the PC (aside from the normal PC+4) is a <strong>beq</strong>.</p>\n\n<hr>\n\n<p>I\'m learning about MIPS pipelining and stages, but what is excruciatingly unclear is how a jump instruction is executed. On an assignment question, I\'m asked to trace the pipeline with the command <strong>"j 16"</strong>, but there does not appear to be any details about how the logic is handled. The closest thing I can find of any relevance is to do with <strong>beq</strong>, but the opcodes are different... <strong>beq</strong> is <strong>000100</strong> and <strong>j</strong> is <strong>000010</strong>. The following table outlines how the control codes work for four classes of opcodes, but it doesn\'t explain what happens for jump, and subsequently, how the machine knows to jump and what it does with the command...</p>\n\n<p><img src="http://i.stack.imgur.com/Pc9Vh.png" alt="Datapath diagram with control registers">\n<img src="http://i.stack.imgur.com/9QPlv.png" alt="Opcode-Control Codes"></p>\n\n<p>So, if I have the instruction <strong>000010 00000000000000000000000100</strong>, how does this get handled by the data path?</p>\n', 'ViewCount': '64', 'Title': 'How are the control signals derived in the MIPS pipeline?', 'LastEditorUserId': '6569', 'LastActivityDate': '2014-01-30T14:48:47.240', 'LastEditDate': '2014-01-30T14:48:47.240', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '6569', 'Tags': '<computer-architecture><cpu-pipelines>', 'CreationDate': '2014-01-30T03:29:24.877', 'Id': '20093''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I was trying to solve a question dealing with n instructions in an uneven pipeline with k stages. I came across a generic formula for even pipelines i.e. (k + n - 1) * clock cycle. But I feel this should not work for uneven pipelines as the above formula is based on fact that the 1st instruction takes time = sum(time of k stages) and the 2nd instruction onwards takes time = maximum of stage delays. </p>\n\n<p>A example: A pipeline is designed with 5 stages having execution times respectively as 3ns, 4ns, 2ns and 4ns. How much time will it take to execute 1000 instructions?</p>\n', 'ViewCount': '140', 'Title': 'Execution time of an uneven pipeline', 'LastEditorUserId': '16189', 'LastActivityDate': '2014-03-27T18:36:40.790', 'LastEditDate': '2014-03-27T18:36:40.790', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '-2', 'PostTypeId': '1', 'OwnerUserId': '14939', 'Tags': '<computer-architecture><cpu-pipelines>', 'CreationDate': '2014-02-22T16:04:48.137', 'Id': '21924''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '69', 'Title': 'Why Instruction Decode and Register Read are in the same stage of MIPS pipeline', 'LastEditDate': '2014-02-25T21:03:57.187', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14769', 'FavoriteCount': '0', 'Body': '<p>Why are instruction decoding and register read are combined in single stage of a 5-stage MIPS-pipeline, even though they serve two different operation?</p>\n', 'Tags': '<computer-architecture><cpu-pipelines>', 'LastEditorUserId': '39', 'LastActivityDate': '2014-02-25T21:04:13.483', 'CommentCount': '3', 'AcceptedAnswerId': '21939', 'CreationDate': '2014-02-23T04:34:32.810', 'Id': '21937''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Given below are 3 different pipelined processors:</p>\n\n<p>$P_1:\\ 4\\ stages\\ with\\ delays\\ \\ \\ \\ 0.6_{ms}\\ \\ 0.8_{ms}\\ \\ 0.6_{ms}\\ \\ 1.1_{ms}\\\\\nP_2:\\ 4\\ stages\\ with\\ delays\\ \\ \\ \\ 2.0_{ms}\\ \\ 1.8_{ms}\\ \\ 2.0_{ms}\\ \\ 1.0_{ms}\\\\\nP_3:\\ 5\\ stages\\ with\\ delays\\ \\ \\ \\ 1.0_{ms}\\ \\ 0.8_{ms}\\ \\ 1.0_{ms}\\ \\ 1.5_{ms}\\ \\ 1.5_{ms}$</p>\n\n<p>One has to find the <strong>Peak Clock Frequencies</strong> of each $\\mathbf{P_i}$. Pipeline buffer register latency is Zero.</p>\n\n<p>I don't know how to solve this, but I've come up with an intuitive formula for calculating peak frequency of clock for processor $P_i$ as $$\\mathcal{C_{p.f}}=\\frac{1}{max(d_i)}$$ where $d_i$ is individual stage delay for processor $P_i$. For example for $P_2$ it's $\\frac{1}{2}KHz = 0.5 KHz$.</p>\n\n<pre><code>Now I don't know whether it's the correct way to calculate peak frequency.\nIf it's not, can anyone tell me what is it?\n\nP.S: I also don't know whether this is the right place to ask this question.\nBut I didn't have any idea about where to post it otherwise.\n</code></pre>\n", 'ViewCount': '45', 'Title': 'A question from Computer Organization on Peak Clock Frequency', 'LastActivityDate': '2014-03-02T16:13:09.683', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11949', 'Tags': '<computer-architecture><cpu-pipelines>', 'CreationDate': '2014-03-02T15:49:40.287', 'Id': '22196''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Basically, I using an algorithm called 'miranda' to look at miRNA targets and it only runs on a single thread. It compares everything in one file against everything in another file, produces a file as an output and runs off of the command line in terminal. The process took roughly 20 hours to create the output file.</p>\n\n<p>I was advised by my supervisor that if i split one of the files up into say 4 equally sized parts, and ran them in four separate terminal windows this would decrease the overall time it took for the process to be completed.</p>\n\n<p>I found that when I was using a single terminal window, the process would take up about 100-120% of the CPU. However, when running four terminal windows, each individual process only takes between 30-40% of the CPU.</p>\n\n<p>How much effect does splitting the file up like this have in the overall time it takes to run the process? Although I split it across four threads, will the effect only be an increase in speed of about 1.5 times?</p>\n", 'ViewCount': '44', 'Title': 'Does splitting a process across 4 terminal windows decrease the time it takes?', 'LastActivityDate': '2014-03-05T18:02:23.337', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9799', 'Tags': '<algorithms><cpu-pipelines><threads>', 'CreationDate': '2014-03-04T17:57:45.533', 'Id': '22277''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>If I have 2 CPU's of the same manufacturer... say AMD</p>\n\n<p>Both are Quad-Core, Both are rated at 3.6Ghz</p>\n\n<p>1 is 100W, the other is 65W</p>\n\n<p>Will the one with the higher wattage out-perform the lower one and why?</p>\n", 'ViewCount': '17', 'ClosedDate': '2014-04-16T17:15:44.867', 'Title': 'Difference in CPU Wattage Question', 'LastActivityDate': '2014-04-15T21:18:42.400', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '16806', 'Tags': '<cpu-cache><cpu-pipelines>', 'CreationDate': '2014-04-15T20:56:43.810', 'Id': '23828''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}