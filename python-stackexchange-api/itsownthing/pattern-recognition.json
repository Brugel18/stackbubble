132_0:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have designed a classifier M which recognizes gestures and classifies it under any category always. A gesture is classified based on the hamming distance between the sample time series y and the training time series x. The result of the classifier are probabilistic values. There are 3 classes/categories with labels A,B,C which classifies hand gestures where there are 100 samples for each class which are to be classified (single feature and data length=100). The data are different time series (x coordinate vs time). The training set is used to assign probabilities indicating which gesture has occured how many times. So,out of 10 training samples if gesture A appeared 6 times then probability that a gesture falls under category A is  </p>\n\n<blockquote>\n  <p>P(A)=0.6\n   similarly \n  P(B)=0.3</p>\n</blockquote>\n\n<p>and</p>\n\n<blockquote>\n  <p>P(C)=0.1</p>\n</blockquote>\n\n<p>Now, I am trying to compare the performance of this classifier with Bayes classifier, K-NN, Principal component analysis (PCA) and Neural Network. </p>\n\n<ol>\n<li>On what basis,parameter and method should I do it if I consider ROC or cross validate since the features for my classifier are the probabilistic values for the ROC plot hence what shall be the features for k-nn,bayes classification and PCA?</li>\n<li>Is there a code for it which will be useful.</li>\n<li>What should be the value of k is there are 3 classes of gestures?</li>\n</ol>\n\n<p>Please help. I am in a fix. </p>\n', 'ViewCount': '137', 'Title': 'Issue in comparing classifiers for pattern recognition', 'LastActivityDate': '2012-03-29T23:11:53.287', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '883', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<machine-learning><pattern-recognition>', 'CreationDate': '2012-03-29T20:22:01.553', 'FavoriteCount': '0', 'Id': '878'},132_1:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am trying to compare the performance of a classification result with Bayes classifier, K-NN, Piece wise component analysis (PCA). I have doubts regarding the following (please excuse my lack of programming skills since I am a biologist and not a programmer thus finding the Matlab documentation hard to follow).</p>\n\n<p>In the Matlab code </p>\n\n<pre><code>    Class = knnclassify(Sample, Training, Group, k)\n    Group =  [1;2;3]   //where 1,2,3 represents Class A,B,C respectively.\n</code></pre>\n\n<p>What goes in the sample because my data is a 100 row 1 column for each of the classes? So Group 1 contains data like $[0.9;0.1;......n]$ where $n=100$. Would the sample be a vector containing random mixtures of the data points from the three classes? Same question for the <code>Training</code> matrix.</p>\n', 'ViewCount': '110', 'Title': 'Pattern classification: what goes into the sample?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-22T16:13:55.830', 'LastEditDate': '2012-04-22T16:13:55.830', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '783', 'Tags': '<machine-learning><modelling><pattern-recognition>', 'CreationDate': '2012-04-02T06:06:42.343', 'Id': '983'},132_2:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I want to determine which parts of an audio file contain speech respectively music.</p>\n\n<p>I hope someone has a made something like this or can tell me where to start. Can you please suggest some method or tutorial for doing the same?</p>\n', 'ViewCount': '107', 'Title': 'Speech vs Music classification', 'LastEditorUserId': '98', 'LastActivityDate': '2013-02-04T05:27:55.623', 'LastEditDate': '2012-06-12T22:14:41.623', 'AnswerCount': '2', 'CommentCount': '7', 'Score': '2', 'OwnerDisplayName': 'Praveen', 'PostTypeId': '1', 'Tags': '<reference-request><pattern-recognition>', 'CreationDate': '2012-06-07T06:40:44.960', 'Id': '2351'},132_3:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I was trying to come up with a system that would evaluate bylaws for an organization as to determine their underlying logic.</p>\n\n<p>I think a first-order predicate system would work for representing the rules, which could be translated from the text via part-of-speech tagging and other NLP techniques.  </p>\n\n<p>Is there a systematic way to interpret the first-order logic rules as a whole, or some type of ML architecture that would work as a second layer to find similarities between the elements.</p>\n\n<p>For example,</p>\n\n<blockquote>\n  <p>List of fun activities:</p>\n  \n  <ul>\n  <li>golf</li>\n  <li>coffee break</li>\n  <li>pizza</li>\n  </ul>\n  \n  <p>Bylaws:</p>\n  \n  <ol>\n  <li><p>On Friday, we play golf</p></li>\n  <li><p>On Friday or Saturday, we take a quick coffee break, and if it's Saturday, we get pizza</p></li>\n  </ol>\n</blockquote>\n\n<p>Conclusion: our group has fun on weekends</p>\n\n<p>It sounds far fetched, but I'm curious if it's possible.  I also realize that perhaps more first-order logic would be a better fit for driving the conclusions of the second layer.  </p>\n", 'ViewCount': '80', 'Title': 'Methods to evaluate a system of written rules', 'LastActivityDate': '2012-08-13T22:49:33.717', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '3160', 'Score': '10', 'OwnerDisplayName': 'jonsca', 'PostTypeId': '1', 'OwnerUserId': '88', 'Tags': '<machine-learning><algorithms><pattern-recognition><logic>', 'CreationDate': '2012-02-16T07:32:59.457', 'Id': '2382'},132_4:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am doing a project on face detection in C#. I want to find the skin area by using skin color segmentation. For that purpose, I have to extract the skin area.</p>\n\n<p>I know I can use <a href="http://en.wikipedia.org/wiki/HSI_color_space" rel="nofollow">HSI</a> or <a href="http://en.wikipedia.org/wiki/YCbCr" rel="nofollow">YCbCr</a>, but what is the exact difference between these?</p>\n', 'ViewCount': '276', 'Title': 'Difference between HSI and YCbCr for pattern recognition by color', 'LastEditorUserId': '39', 'LastActivityDate': '2012-10-31T04:32:18.547', 'LastEditDate': '2012-09-22T20:51:08.260', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '2893', 'Tags': '<pattern-recognition><image-processing>', 'CreationDate': '2012-09-22T19:49:55.650', 'Id': '4673'},132_5:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Shannon's entropy [plog(1/p)] for an image is a probabilistic method for comparing two pixels or a group of pixels.Suppose an image with a  matrix of 3x3 has pixel intensity values</p>\n\n<pre><code>1 1 2\n2 3 3\n4 4 5\n</code></pre>\n\n<p>and another image with 3x3 matrix has group of pixels having intensity values</p>\n\n<pre><code>5 5 6\n6 7 7\n8 8 9\n</code></pre>\n\n<p>Then shannon's entropy for the images would be the same.So in this case the entropy values would point out that the images are same though in actual they are different.So image matching using this technique doesn't help.On basis of supervised classification where I classify an image based on trained databases of shannon's entropy ,we use the concept of entropy to find similarity between two images.Is there any method or research paper where this entropy can be used or modified for image matching for the above case..?</p>\n", 'ViewCount': '2300', 'Title': "Shannon's entropy for an image", 'LastEditorUserId': '157', 'LastActivityDate': '2013-10-11T21:42:02.737', 'LastEditDate': '2012-10-23T02:37:47.963', 'AnswerCount': '3', 'CommentCount': '7', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '3093', 'Tags': '<pattern-recognition><image-processing><entropy><computer-vision>', 'CreationDate': '2012-10-07T20:51:48.457', 'Id': '4935'},132_6:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Having a unsupervised algorithm done on a dataset (e.g. K-means), how can I determine which cluster is normal and which is anomalous (for 30 clusters, for example)? </p>\n\n<p>If the dataset contains normal traffic much more than anomalies (99%), then the radius of clusters associate to normal traffic is bigger. Is this true? Why? </p>\n\n<p>If so, then we set the clusters with greater radius to normal according to a threshold. The smaller the threshold, the more the detection rate and the more the false alarm rate. Is this true?</p>\n\n<p>Could a labeled dataset help determine the normal clusters? For example, finding the closest point to the centroid of a given cluster and checking whether it is labeled anomaly or not?</p>\n\n<p>[1] uses Cluto software and its mountain visualization graph that I can't understand why its 3D, having feature space of dimension 41.</p>\n\n<p>Reference: \n[1] Jose F. Nieves, Data Clustering for Anomaly Detection in Network Intrusion Detection</p>\n", 'ViewCount': '116', 'Title': 'Unsupervised anomaly detection: assigning the clusters to normal and anomaly', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-08-28T05:17:58.957', 'LastEditDate': '2013-06-18T15:43:13.387', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'OwnerDisplayName': 'Yasser MZadeh', 'PostTypeId': '1', 'OwnerUserId': '4654', 'Tags': '<machine-learning><pattern-recognition>', 'CreationDate': '2012-11-19T06:43:36.200', 'Id': '6766'},132_7:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm looking for an OCR technique (PCA or SVM or anything else) in a peculiar setting. I want to detect the motion of the finger so that if someone writes something in front of the camera in the air, I want to recognize the characters online (meaning as soon as they are written).</p>\n", 'ViewCount': '166', 'Title': 'Handwritten character recognition as characters are being traced', 'LastEditorUserId': '39', 'LastActivityDate': '2013-05-02T09:11:28.823', 'LastEditDate': '2013-01-30T21:31:31.013', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6621', 'Tags': '<machine-learning><computer-vision><pattern-recognition><ocr>', 'CreationDate': '2013-01-30T09:16:29.270', 'FavoriteCount': '1', 'Id': '9302'},132_8:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I got a very hard automatically clustering problem with some training data (500 samples, each with roughly 5-50 classes and 10000-20000 data points in total). What I need to do is to cluster an input into multiple classes (the number of classes is unknown). </p>\n\n<p>So far I had some several clustering algorithms, each gives me an output. I noticed that none of them works sufficient robust over the entire training set, but some works better than others on data with a small number classes, some works better on data with a large number of classes. Meanwhile, some gives me very good cluster results on part of a sample, while performs bad on the other half. Visually speaking, I feel that human should be able to generate a better clustering output by combining all initial outputs of using existing methods. However, it seems that it is hard to translate my human selection logic into codes. Because I know that a good cluster result in my data should be of a shape like a long eclipse, if I see a class in one of my output is very dislike this shape, I know there is something wrong, and if I look up the results of this area in other outputs, I can easily pick those close to my expectations. The actual case is even more complicated, my human decision on choose which class in which output for which region in my data sample uses both relative information among different outputs and prior knowledge on the distribution of tested data points. Please help me, I even donot know where to start. </p>\n\n<p>Any comments and hints are welcome. </p>\n\n<p>Thank you.</p>\n\n<hr>\n\n<p>Thank you for your comments. I see what you said, but it turns out that my ultimate goal is different from what you suggested. I am not interested in finding which clustering output is better than others, but trying to generate a new output based on existing clustering output. </p>\n\n<p>At the first glance, these two goals look compatible: if I can choose one best clustering output for a given set of data points, then I shall be able to repeat this process and apply it iterative to cover the entire dataset, and in this way we can generate a new output, whose solution is composed of different clustering outputs at different regions. However, in my problem this is really not a feasible approach, because I really donot know how to separate an entire dataset into reasonable subsets. </p>\n\n<p>If we know how to do this job properly, the clustering problem can be largely simplified. We can first separate the entire set into nonoverlapping subset, then use an appropriate clustering method for each individual subset, and finally collect all subset clustering outputs as a new output. Meanwhile, it seems that this way of sequential process might be harmful if we make mistakes in the early stage of dividing subsets. </p>\n', 'ViewCount': '52', 'Title': 'How to train a clustering system based on multiple initial clustering results', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-25T19:23:51.500', 'LastEditDate': '2013-07-28T11:29:29.213', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9331', 'Tags': '<machine-learning><pattern-recognition>', 'CreationDate': '2013-07-25T01:05:34.993', 'Id': '13424'},132_9:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Is developing an optical character recognition system for an alphabet which has no previous ocr considered a reputable conference or journal worthy research project, given the fact that there are so many commercial ocr system? Though, lots of conference proceeding and journal entries shows up when googled, but most of them are old and are about performance of a specific algorithm. There are also research on ocr for cursive alphabets which are hard to segment, like Arabic. The alphabet I am developing ocr for is of Indic origin and cursive as my final year undergraduate thesis. So, I'm wondering if it's a good research project.</p>\n", 'ViewCount': '74', 'ClosedDate': '2013-07-30T19:31:03.937', 'Title': 'Is developing an OCR considered a research project?', 'LastActivityDate': '2013-07-30T14:03:58.407', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '13519', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9421', 'Tags': '<computer-vision><pattern-recognition>', 'CreationDate': '2013-07-30T09:15:38.420', 'Id': '13512'},132_10:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm interested in learning about how facial recognition works.  I'm especially interested in the algorithms or approach that is used.  What are the leading methods for facial recognition?  Is there a good overview or source to learn about a few of the most widely used algorithms for facial recognition?  What would be the best handful of research papers to read first?</p>\n", 'ViewCount': '90', 'Title': 'How does facial recognition work?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T10:59:55.660', 'LastEditDate': '2013-09-02T10:33:34.133', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<reference-request><computer-vision><pattern-recognition><facial-recognition>', 'CreationDate': '2013-09-02T04:54:02.340', 'Id': '14075'},132_11:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Some humans can lip-read fairly well: by watching someone who is speaking, they can tell what the speaker is saying (even without hearing the speech).</p>\n\n<p>Has there been any work on building computer software to lip-read?  In other words, given a video of someone speaking, is it possible to build software to infer what the person is saying (with access only to the video stream, without audio)?  Has there been any research on this problem, or even deployed systems?</p>\n\n<p>Background and motivation: In the US, certain laws may forbid recording audio without consent.  However, there is generally no prohibition on recording video without consent of the people being recorded.  (That's why you see surveillance cameras all over the place, and why they record only video but never audio.)  I am curious whether technology has advanced enough that, solely from video, it might be possible for automated methods to tell what people are saying -- or whether that might become feasible in the near-future.  And, apart from the privacy implications, such a technology might be pretty useful.</p>\n", 'ViewCount': '117', 'Title': 'Automated lip-reading: inferring what someone is saying, based upon video of them speaking', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T10:57:04.990', 'LastEditDate': '2013-09-02T10:34:40.780', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<reference-request><computer-vision><pattern-recognition><facial-recognition>', 'CreationDate': '2013-09-02T05:05:58.230', 'Id': '14076'},132_12:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<blockquote>\n  <p>Let $\\Sigma  = {1,2,3,4}$  . We say that symbol $\\sigma $ bonds with\n  symbol $\\tau$  if $\\sigma = \\tau$ of $\\sigma = \\tau +1$ for even\n  $\\sigma$ and $\\sigma = \\tau -1$ for odd $\\sigma$ . In other words  , 1\n  and 2 bond  , and 3 and 4 bond (in addition to every number bonding\n  with itself ) . </p>\n  \n  <p>The  Pattern bonding problem is defined as follows:</p>\n  \n  <p>INPUT :  Text $ T = t_{1}  , ..., t_{n}$  and pattern $ P = p_{1}  ,\n ..., p_{m}$ over alphabet  $\\Sigma  $ . </p>\n  \n  <p>OUTPUT :  All locations $i$ in the text that bond with the pattern , \n  i.e  , where $t_{i+j-1}$ bonds with $p_{j}$ $j=1,...,m$ .</p>\n</blockquote>\n\n<p>Can someone supply an algorithm for the pattern bonding problem (the faster the better   complexity can)  ?  , I thought about "Less then matching" .  </p>\n\n<p><strong>Edit: (Answer)</strong></p>\n\n<p>Map $ (1,2) \\rightarrow \\alpha , (3,4)\\rightarrow  \\beta$ then the text and the pattern is on $\\Sigma = {\\alpha , \\beta}$ and then we know to solve it in $O(n)$ using witness or KMP . </p>\n', 'ViewCount': '35', 'Title': 'Pattern bonding problem', 'LastEditorUserId': '4409', 'LastActivityDate': '2013-09-09T15:58:39.527', 'LastEditDate': '2013-09-09T15:58:39.527', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '14235', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4409', 'Tags': '<algorithms><pattern-recognition>', 'CreationDate': '2013-09-09T14:23:55.640', 'Id': '14234'},132_13:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I have in mind a particular 3D object.  Given an image taken by a camera, I want to check whether that image contains an instance of my object.</p>\n\n<p>For instance, let's say that the object is a bathroom sink.  There are many kinds of bathroom sinks, but they tend to share some common elements (e.g., shape, size, color, function).  There can also be significant variation in lighting and pose.  Given an image, I want to know whether the image contains a bathroom sink.</p>\n\n<p>How do I do that?  What technique/algorithm would be appropriate?  Is there research on this topic?</p>\n\n<p>Of course, it is easy to use Google Images to obtain many example images that are known to contain a bathroom sink (or whatever the object I'm looking for might be), which could be used for training some sort of machine learning algorithm.  This suggests to me that maybe some combination of computer vision plus machine learning might be a promising approach, but I'm not sure exactly what the specifics might look like.</p>\n", 'ViewCount': '100', 'Title': 'Object recognition - given an image, does it contain a particular 3D object of interest?', 'LastActivityDate': '2013-10-29T18:12:04.513', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '14719', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '755', 'Tags': '<machine-learning><image-processing><computer-vision><pattern-recognition>', 'CreationDate': '2013-09-30T23:58:18.703', 'Id': '14717'},132_14:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>On <a href="http://en.wikipedia.org/wiki/Pizza_%28programming_language%29" rel="nofollow">this page describing the precursor to the Scala language</a> - the pizza language - they refer to it having both case classes and <a href="http://en.wikipedia.org/wiki/Pattern_matching" rel="nofollow">pattern matching</a> - and then imply that these taken together provide <a href="http://en.wikipedia.org/wiki/Algebraic_data_type" rel="nofollow">algebraic types</a>. </p>\n\n<p>Is this the case? To provide algebraic types - do you combine <a href="http://en.wikipedia.org/wiki/Scala_%28programming_language%29#Case_classes_and_pattern_matching" rel="nofollow">case classes and pattern matching</a>?</p>\n', 'ViewCount': '33', 'Title': 'Are Algebraic types just the combination of case classes and pattern matching?', 'LastActivityDate': '2013-12-07T10:26:16.887', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18712', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1709', 'Tags': '<type-theory><pattern-recognition><abstract-data-types>', 'CreationDate': '2013-12-07T10:12:33.263', 'Id': '18711'},132_15:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Let\'s suppose I have an image of a person and its corresponding background. Using OpenCV I can relatively easily get a silhouette of the person from the image. </p>\n\n<p>I am doing a project on human recognition using silhouettes and the only things I came up with for feature extraction are so called Granlund coefficients derived from Fourier coefficients and <a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#humoments" rel="nofollow">Hu moments</a> which provide me with features I can send to various classifiers I have. </p>\n\n<p>What I am further curious about is what other methods are there, if any, for feature extraction from silhouettes? </p>\n\n<p>EDIT: In accordance with the first commentator, I will expand my question. As I said, I have tried with Granlund coefficients and Hu moments, both of them are well documented standard techniques which you can find in OpenCV documentation and IEEE Xplore digital library (Granlund coefficients). </p>\n\n<p>Also, I didn\'t say anything specific about the features, I just want to know about various methods for silhouette feature extraction, other than the two mentioned above.</p>\n', 'ViewCount': '48', 'Title': 'Methods for silhouette feature extraction', 'LastEditorUserId': '9250', 'LastActivityDate': '2014-01-20T20:33:41.613', 'LastEditDate': '2014-01-20T20:33:41.613', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9250', 'Tags': '<reference-request><pattern-recognition>', 'CreationDate': '2014-01-14T22:21:28.913', 'Id': '19728'},132_16:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'ViewCount': '21', 'Title': 'How do I apply patch sized features to larger images?', 'LastEditDate': '2014-01-24T17:23:21.613', 'AnswerCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13101', 'FavoriteCount': '0', 'Body': "<p>I've been trying to teach myself some machine learning, and I wanted to ask what seems a simple question, but I've not been able to find any resources that explain the next step.</p>\n\n<p>Let's say I am doing semi-supervised learning, and have a few hundred sparsely distributed feature extractors, trained on random 32x32 regions (the unsupervised part of the process). </p>\n\n<p>I now want to take the larger images in my training set, and do some supervised learning based on the feature extractors I now have. In this case, multi-label classification.</p>\n\n<p>The bit I'm not clear on is what I do with the full sized image from my training set:</p>\n\n<ul>\n<li>Take random samples from it? -- seems like it would be pot luck if it picks an area needed to identify appropriate labels</li>\n<li>Take overlapping tiles with a sliding window? -- seems like I'd end up with absurd dimensionality, since for each tile, I get a whole vector of features</li>\n<li>Take adjacent tiles? -- dimensionality still nonsensical, and probably translation sensitive as well</li>\n</ul>\n\n<p>It's a hypothetical example, but let's say my inputs are 800x600 photographs, i.e. the input is about 100-1000 times bigger than the samples I used in the unsupervised learning stage.</p>\n", 'Tags': '<machine-learning><image-processing><pattern-recognition>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-25T12:26:53.737', 'CommentCount': '0', 'AcceptedAnswerId': '19962', 'CreationDate': '2014-01-24T15:46:33.130', 'Id': '19944'},132_17:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Phase space learning <a href="http://cseweb.ucsd.edu/users/gary/pubs/nips94.pdf" rel="nofollow">Paper1</a> and <a href="http://gliamac.mit.edu/people/seung/papers/continuous.pdf" rel="nofollow">Paper2</a> in neural network represents the input  in higher dimension in auto associative learning. So, the network functions as an auto-associative memory where dynamical attractors are fixed points, each corresponding to one of the patterns that we want to store in the network. If the network has 3 input nodes, the the number of outputs will also be 3. Thus, for a time instant, $t$ Input is a vector. </p>\n\n<p>The Authors mention that a trajectory is traced out. In my case, for every time instant I have a feature vector of dimension 3 i.e there are three features. In my opinion, for every time step, t a learning algorithm is used to update the weights. Also. the Authors mention delay embedding for time series reconstruction which is an essential point in any phase space representation. Based on these, the following concepts are unclear and I will be thankful for an intuitive explanation. </p>\n\n<p>Q1. How come a feature vector is delay embedded and a trajectory is formed since we have only one example at every time instant? </p>\n\n<p>Q2. I will appreciate ideas in how to apply phase space learning with particle Swarm optimization and the objective function is the mean square error between the actual output of the network and the target. In my application, I only have the final target vector not a target vector for every time step. </p>\n', 'ViewCount': '14', 'Title': 'Supervised learning based on phase space representation', 'LastEditorUserId': '10583', 'LastActivityDate': '2014-03-11T03:06:09.200', 'LastEditDate': '2014-03-11T03:06:09.200', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10583', 'Tags': '<machine-learning><neural-networks><pattern-recognition><research>', 'CreationDate': '2014-03-11T02:56:38.210', 'Id': '22489'},132_18:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I want to learn maths for artificial intelligence. I heard that main areas of mathematics for AI are Multivariable Calculus, Linear Algebra, Probability and Statistics and Discrete Mathematics. But what level of these subjects do I need? For example the easy level is like Calculus of Gilbert Strang and 18.01 Calculus from MIT Open Course Ware. The hard level is Apostol's or Spivak's Calculus. Do I need easy level of maths or hard level to be good at artificial intelligence and its areas (machine learning, pattern recognition).</p>\n", 'ViewCount': '41', 'ClosedDate': '2014-03-24T10:42:23.590', 'Title': 'What level of maths do I need for artificial intelligence?', 'LastEditorUserId': '13022', 'LastActivityDate': '2014-03-24T10:38:00.990', 'LastEditDate': '2014-03-24T10:38:00.990', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16051', 'Tags': '<machine-learning><artificial-intelligence><pattern-recognition><mathematical-foundations>', 'CreationDate': '2014-03-24T05:50:54.990', 'Id': '22988'},132_19:{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>My research is in the area of Document Image Analysis. To be specific, the topic of my thesis is to automatically recognize and index characters in a set of hand-drawn objects, e.g. given a volume of comics --> how to localize, recognize then index the characters in it (e.g. return "Lucky Luke" position in some random volume).</p>\n\n<p>First thing first, before I can work on the indexing part, I must have some reliable system to recognize the interested characters. After some months working on it, I find the recognition is extremely hard, because the drawings are some time very "abstract".</p>\n\n<p>For normal face recognition, there are a lot of researches on it, thus we have Haar-like features, biometrics features, etc. For normal photograph objects, we may use e.g. SIFT/SURF, or other strong features for the purpose of object recognition.</p>\n\n<p>But in cartoons or comics, we may extract so few or zero feature(s) following the traditional approaches. Human visual interpretation system is amazingly effective in recognize such abstract objects (e.g. only with 4 lines and 2 curves, we still recognize the familiar character).</p>\n\n<p>So I think the solution must be somewhere in the understanding how human can interpret such a set of line strokes as a meaningful object. Once we understand it we can try to "teach" the computer the same way.</p>\n\n<p>Thus are there some good approaches in the terms of recognition of abstract objects such as drawn comic objects? (I searched for some but they\'re not so relevant). Thanks.</p>\n', 'ViewCount': '81', 'Title': 'Method to recognize abstract objects such as hand-drawn objects?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T05:03:02.323', 'LastEditDate': '2014-04-10T22:29:54.210', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'OwnerDisplayName': 'Jim Raynor', 'PostTypeId': '1', 'OwnerUserId': '16662', 'Tags': '<machine-learning><image-processing><pattern-recognition>', 'CreationDate': '2014-04-09T21:53:22.637', 'Id': '23657'}