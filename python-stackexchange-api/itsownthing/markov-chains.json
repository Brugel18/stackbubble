{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '292', 'Title': 'What are the uses of Markov Chains in CS?', 'LastEditDate': '2012-05-16T23:21:38.910', 'AnswerCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '147', 'FavoriteCount': '2', 'Body': "<p>We all know that Markov Chains can be used for generating real-looking text (or real-sounding music). I've also heard that Markov Chains has some applications in the image processing, is that true? What are some other uses of MCs in CS?</p>\n", 'ClosedDate': '2014-02-02T01:34:04.247', 'Tags': '<probability-theory><markov-chains>', 'LastEditorUserId': '39', 'LastActivityDate': '2014-01-25T16:51:31.947', 'CommentCount': '13', 'CreationDate': '2012-03-22T16:36:41.237', 'Id': '663'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Apologies for another Markov Chain question but this one is best given its own question to avoid confusion. I am using a Markov Chain to get the 10 best search results from the union of 3 different search engines. The top 10 results are taken from each engine to form a set of 30 results.</p>\n\n<p>The chain starts at State x, a uniform distribution of set S = {1,2,3,...30}. If the current state is page P, select page Q uniformly from the union of the results from each search engine. If the rank of Q &lt; rank of P in 2 of the 3 engines that rank both P and Q, move to Q. Else, remain at P. </p>\n\n<p>This results in a number of pairwise comparisons being carried out. result2 is compared with result1 and a count is made of each time result2 ranks better than 1. The results are sorted by the results of the pairwise comparisons, with the lowest score ranked first. e.g.</p>\n\n<pre>\nEngine Rankings:                       Pairwise Comparison:\n         eng1   eng2   eng3                    result1  result2  result3  result4  result5\nresult1   1      2      2              result1    0        1        0        0        1\nresult2   4      3      1              result2    2        0        1        2        2\nresult3   2      4      5              result3    3        2        0        1        2\nresult4   5      5      3              result4    3        1        2        0        1\nresult5   3      1      4              result5    2        1        1        2        0\n\n</pre>\n\n<p>The problem with this example is, if we add the total of each row in the pairwise comparison, we get {2,7,8,7,7}, leaving 3 different results with the same score. I'm wondering if there is a method to further sort these results in order to refine the results so that I'm not left with a number of results that have the same score? I've seen Keminization but I can't see how this would apply? Can someone please give me some guidance?</p>\n", 'ViewCount': '107', 'Title': 'Improve Markov Chain results', 'LastActivityDate': '2012-06-23T06:01:57.383', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1916', 'Tags': '<algorithms><machine-learning><markov-chains>', 'CreationDate': '2012-06-22T19:37:01.610', 'Id': '2457'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>There is a markov chain on the states $\\Phi = \\{0,1,2\\dots n\\}$. I am also given the probabilities. E.g., the probability of going from i to i+1 is 1/2, going from i to state 0 = 1/2, and finally going from n to n is 1/2 and n to 0 is 1/2. </p>\n\n<p>I want to find the stationary distribution. And the chain is not reversible. </p>\n\n<p>So I'm not sure how to proceed. My first instinct was to try and use linear algebra but I'm not sure how to do that since I only know that there are $n$ states. Is there a way to solve this analytically, using paper and pencil?</p>\n", 'ViewCount': '47', 'Title': 'Find stationary distribution of markov chain', 'LastEditorUserId': '9819', 'LastActivityDate': '2013-10-05T02:25:57.483', 'LastEditDate': '2013-10-05T02:25:57.483', 'AnswerCount': '0', 'CommentCount': '6', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '9819', 'Tags': '<sampling><markov-chains>', 'CreationDate': '2013-10-05T00:52:38.613', 'Id': '14821'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am having an AI exam in two weeks, and I am still figuring out certain concepts and ideas, related to Bayesian Nets, Hidden Markov Chains, Conditional Random Fields and Neural Nets (yes it is all going to be tested and yes we have a text (AI - A Modern Approach), but no, we did not cover everything in class).</p>\n\n<p>I "know" a few things about the mathematical descriptions of all of those, but I know pretty much nothing about their usage or practical applications.</p>\n\n<p>Here are my questions (and I apologize for my naivety):</p>\n\n<ol>\n<li>What kind of machine learning algorithm classes do they belong to? Since they all need training, does it mean that they are all supervised learning algorithms?</li>\n<li>They all have an underlying structure that allows a graph to represent them, where directed edges denote dependencies between states. The probability of being in a state is computed as a conditional probability from ancestors of the state. Does that sound about right?</li>\n<li>In what kind of situation do you want to use which of the algorithms? Is it possible to some it up, or does it require subtle differentiation and expert-level knowledge?</li>\n<li>Why do Neural Nets get special treatment? I heard of many classes teaching Neural Nets, but I have heard of no such thing for the other guys.</li>\n</ol>\n', 'ViewCount': '52', 'Title': 'How are Bayesian Nets, Hidden Markov Chains, Conditional Random Fields and Neural Nets related?', 'LastActivityDate': '2014-02-28T16:11:53.907', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15080', 'Tags': '<machine-learning><artificial-intelligence><neural-networks><probabilistic-algorithms><markov-chains>', 'CreationDate': '2014-02-26T20:00:12.453', 'Id': '22062'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For probabilistic algorithms such as <a href="http://en.wikipedia.org/wiki/PageRank" rel="nofollow">PageRank</a> and <a href="http://kamvar.org/assets/papers/eigentrust.pdf" rel="nofollow">EigenTrust</a>, the stopping case is given as $|R_{t+1} - R_{t}| &lt; \\epsilon$ (i.e. convergence is assumed). Neither the papers on EigenTrust or PageRank, or the PageRank wiki page, give any <em>clear</em> indication of what $\\epsilon$ should be. </p>\n\n<p>I believe it might be something to do with the damping factor $d = 0.85$; specifically $\\epsilon = 1 - d = 0.15$, but  I can\'t be sure. </p>\n\n<p>How is $\\epsilon$ determined, and if it\'s nothing more than an abitrary value $0 \\leq \\epsilon \\leq 1$, how would you choose a sensible value?</p>\n', 'ViewCount': '41', 'Title': 'PageRank and EigenTrust: How small should epsilon be?', 'LastEditorUserId': '755', 'LastActivityDate': '2014-03-11T02:45:24.150', 'LastEditDate': '2014-03-11T02:45:24.150', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10926', 'Tags': '<probabilistic-algorithms><markov-chains>', 'CreationDate': '2014-03-10T11:57:49.503', 'Id': '22467'}},