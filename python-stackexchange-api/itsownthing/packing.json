{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I would like to write a simple program that accepts a set of windows (width+height) and the screen resolution and outputs an arrangement of those windows on the screen such that the windows take the most space. Therefore it is possible to resize a window, while maintaining  <code>output size &gt;= initial size</code> and the aspect ratio. So for window $i$, I'd like the algorithm to return a tuple $(x, y, width, height)$.</p>\n\n<p>I believe this is might be a variation of 2D Knapsack. I've tried going over results around the web but they mostly had a lot of background (and no implementation) that made it hard for me to follow.</p>\n\n<p>I'm less interested in the fastest possible algorithm, but more in something that is practical for my specific need.</p>\n", 'ViewCount': '458', 'Title': 'How to devise an algorithm to arrange (resizable) windows on the screen to cover as much space as possible?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-04-14T12:28:42.977', 'LastEditDate': '2012-04-11T21:05:32.490', 'AnswerCount': '2', 'CommentCount': '12', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '1042', 'Tags': '<algorithms><computational-geometry><packing><user-interface>', 'CreationDate': '2012-04-10T21:20:21.423', 'Id': '1217'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I wonder what relations are between <a href="http://en.wikipedia.org/wiki/Knapsack_problem" rel="nofollow">the knapsack problem</a>, <a href="http://en.wikipedia.org/wiki/Bin_packing_problem" rel="nofollow">the bin packing problem</a> and <a href="http://en.wikipedia.org/wiki/Set_packing" rel="nofollow">the set packing problem</a>?</p>\n\n<p>From their mathematical formulations, I don\'t see the first two belong to the third one i.e. the set packing problem, although I feel the third one sounds more general than the other two.</p>\n\n<p>Or under what conditions there are some conversions between each other?</p>\n\n<p>Thanks!</p>\n', 'ViewCount': '279', 'Title': 'Relations between the knapsack problem, the bin packing problem, and the set packing problem?', 'LastActivityDate': '2012-10-30T14:57:19.273', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<knapsack-problems><packing>', 'CreationDate': '2012-10-30T14:57:19.273', 'FavoriteCount': '2', 'Id': '6389'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have ordered a few leather sheets from which I would like to build juggling balls by sewing edges together. I\'m using the Platonic solids for the shape of the balls.</p>\n\n<p>I can scan the leather sheets and generate a polygon that approximates the shape of the leather sheet (as you know, it\'s animal skin, and it doesn\'t come in rectangles).</p>\n\n<p>So now, I would like to maximize the size of my juggling ball.</p>\n\n<p>In my example, the polygons are regular ones, but I\'m looking for a solution with simple polygons.</p>\n\n<p>What is the largest scale factor that I can apply to my polygons so that they all fit inside the sheet ?</p>\n\n<p>I am trying to minimize the waste by using as much as material as possible.</p>\n\n<p>Obviously, cutting the polyhedron net into individual polygon will increase the space of possible combination, but also decrease the quality of the final geometry, because there is more sewing involved and accumulated errors. But this question is not about enumerating the different ways of unfolding a polyhedron. They can be considered independently. So the polygons are simple polygons.</p>\n\n<p><em>Formally:</em></p>\n\n<p>Input:</p>\n\n<ul>\n<li>$P$ : a simple polygon (the target)</li>\n<li>$S$ : the set of polygons I want to place</li>\n<li>$G$ : a graph of $n$ simple polygons - each node represents a simple polygon in $S$, and there is one edge edge between each pair of polygons that share a common edge   </li>\n<li>$\\alpha &gt;= 0, \\beta &gt;= 0$ (usage of material and connectivity)</li>\n</ul>\n\n<p>Output:</p>\n\n<ul>\n<li>a scale factor $f$</li>\n<li>$H$, a subgraph of $G$ </li>\n<li>$Loc$: a location and an angle for each polygon in $V(G)$</li>\n<li>a measure of the quality $m$ of the solution: $ m = \\alpha.f + \\beta. {|E(H)|\\over|E(G)|} $</li>\n</ul>\n\n<p>Maximize $m$ subject to these conditions:</p>\n\n<ul>\n<li>$ | V(H) | =  |V(G)| $  (1)</li>\n<li>$ | E(H) | &lt;= |E(G)| $  (2)</li>\n<li>for every polygon $S_i$ in $S$, $S_i$ scaled by a factor $f$ at location $Loc(S_i)$ is inside $P$ (3)</li>\n<li>polygons in $V(H)$ don\'t overlap (4)</li>\n</ul>\n\n<p>( V(G) are the vertices in the graph, and S is the set of polygons, but they describe the same set of objects. Maybe there is a more compact way to do this.) </p>\n\n<p>Explanation of the conditions:</p>\n\n<ul>\n<li>(1) I want all the polygons to be in the final layout</li>\n<li>(2) Some connections may be broken if necessary</li>\n<li>(3) (4) the ball is made of leather</li>\n</ul>\n\n<p>Here is the target polygon\n<img src="http://i.stack.imgur.com/mopxJ.jpg" alt="Leather sheet"></p>\n\n<p>Here is the set of polygons I want to pack:\n<img src="http://i.stack.imgur.com/H4LEi.png" alt="Polyhedron net"></p>\n', 'ViewCount': '337', 'Title': 'How to pack polygons inside another polygon?', 'LastEditorUserId': '2151', 'LastActivityDate': '2012-11-22T11:14:54.447', 'LastEditDate': '2012-11-22T11:14:54.447', 'AnswerCount': '0', 'CommentCount': '9', 'Score': '15', 'PostTypeId': '1', 'OwnerUserId': '2151', 'Tags': '<optimization><computational-geometry><packing>', 'CreationDate': '2012-11-21T06:14:34.403', 'FavoriteCount': '1', 'Id': '6800'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>The problem I have is like this bin packing problem, but instead I have $n$ bins and a collection of items with discrete masses. I need to put at least $m$ kg of stuff in each bin.</p>\n\n<p>Is there an efficient way of doing this? Is there a way that will assure there is approximately the same amount in each bin? Does having a good guess at the probability distribution of the masses help?</p>\n\n<p><strong>More explicitly:</strong></p>\n\n<p>I have $q$ objects $\\{o_1...o_q\\}$, each has a size $w(o_i) \\in \\mathbb{N}$.</p>\n\n<p>I need to find a collection of $n$ disjoint bins $B = \\{b_1...b_n\\}$ containing the objects such that</p>\n\n<p>$$\\forall b_i \\in B: \\sum_{o \\in b_i}w(o) &gt; m$$</p>\n\n<p>for some $m$. When it is possible that is.</p>\n', 'ViewCount': '53', 'Title': 'Relaxed Bin Packing Problem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-08T14:55:04.787', 'LastEditDate': '2013-04-08T14:55:04.787', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '7641', 'Tags': '<algorithms><efficiency><packing>', 'CreationDate': '2013-04-08T11:11:38.520', 'Id': '11139'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a problem which I suspect is NP-complete. It is easy to prove that it is NP. My current train of thought revolves around using a reduction from knapsack but it would result in instances of 0-1-Knapsack with the value of every item being equal to its weight.</p>\n\n<p>Is this still NP-complete? Or am I missing something?</p>\n', 'ViewCount': '367', 'Title': 'Is the 0-1 Knapsack problem where value equals weight NP-complete?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-14T10:40:18.413', 'LastEditDate': '2013-04-14T10:40:18.413', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11245', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7139', 'Tags': '<complexity-theory><np-complete><decision-problem><packing>', 'CreationDate': '2013-04-11T22:41:16.210', 'Id': '11243'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Cutting problems are problems where a certain large object should be cut to several small objects. For example, imagine you have a factory that works with large boards of raw glass, of width W and length L. There are several buyers, each of which wants an unbounded number of small glass boards. Buyer $i$ wants boards of length $l_i$ and width $w_i$. Your goal is to cut small boards from the large board, such that the total used is maximized and the waste is minimized (There are also <a href="http://www.citeulike.org/user/erelsegal-halevi/article/1695945">other types of cutting and packing problems</a>).</p>\n\n<p>One common restriction in cutting problems is, that the cuts must be <strong>guillotine cuts</strong>, i.e., each existing rectangle can be cut only to two smaller rectangles; it is impossible to make L-shapes etc. Obviously, the maximum used area with guillotine cuts might be smaller than the maximum used area without restriction.</p>\n\n<p>My question is: <strong>Are there upper and lower bounds on the ratio between the optimal guillotine cut and the optimal general cut?</strong></p>\n\n<p>Related work: <a href="http://www.citeulike.org/user/erelsegal-halevi/article/7153709">Song et al. (2009)</a> describe an algorithm that uses a restricted type of guillotine cuts - <em>twice-guillotine cuts</em>. They prove, using geometric constraints, that the ratio between the maximum twice-guillotine cut to the maximum guillotine cut is bounded by <strong>$\\frac{6}{7}$</strong>. I am looking for a comparable result about the ratio between the maximum guillotine cut to the maximum general cut.</p>\n', 'ViewCount': '61', 'Title': 'guillotine cuts versus general cuts', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-10-29T07:48:31.090', 'LastEditDate': '2013-10-29T07:48:31.090', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><computational-geometry><lower-bounds><packing>', 'CreationDate': '2013-10-29T07:40:13.090', 'Id': '16533'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>According to Wikipedia, the <a href="http://en.wikipedia.org/wiki/Independent_set_%28graph_theory%29" rel="nofollow">Independent Set</a> problem is a special case of the <a href="http://en.wikipedia.org/wiki/Set_packing" rel="nofollow">Set Packing</a> problem. But, it seems to me that these problems are equivalent.</p>\n\n<p>The <a href="http://en.wikipedia.org/wiki/Independent_set_%28graph_theory%29" rel="nofollow">Independent Set</a> search problem is: given a graph $G(V,E)$ and an integer $n$, find $n$ vertices no two of which are adjacent.</p>\n\n<p>The <a href="http://en.wikipedia.org/wiki/Set_packing" rel="nofollow">Set Packing</a> search problem is: given a finite collection $C$ of finite sets and an integer $n$, find $n$ sets that are pairwise disjoint.</p>\n\n<p>I think they are equivalent based on the following bidirectional reduction:</p>\n\n<p>&rarr;: Given an independent set problem on a graph $G(V,E)$, create a collection of $C$ of sets, where for each vertex $v \\in V$ there is a set $S_v \\in C$ containing all edges adjacent to $v$. Now, every set packing in $C$ corresponds to a set of vertices no two of which have an edge in common, i.e., this is an independent set in $G$ of the same size.</p>\n\n<p>&larr;: Given a set packing problem on a collection $C$, create a graph $G(V,E)$ where for every set $S \\in C$ there is a vertex $v_S \\in V$, and there is an edge between $v_{S_1}$ and $v_{S_2}$ iff the sets $S_1$ and $S_2$ intersect. Now, every independent vertex set in $G$ corresponds to a set of sets from $C$ no two of which intersect, i.e., this is a set packing in $C$ of the same size.</p>\n\n<p>My question is: is my reduction correct? If so, are these problem equivalent? Is it possible to use approximation algorithms for one problem on the other problem?</p>\n', 'ViewCount': '145', 'Title': 'Equivalence of independent set and set packing', 'LastActivityDate': '2013-12-08T11:18:43.767', 'AnswerCount': '2', 'CommentCount': '0', 'AcceptedAnswerId': '18741', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<algorithms><graphs><sets><packing>', 'CreationDate': '2013-12-08T08:50:02.567', 'FavoriteCount': '1', 'Id': '18736'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<pre><code>There are n collections of M sets.\nPick a single set from each collection,\nsuch that all n picked sets are pairwise disjoint.\n</code></pre>\n\n<p>This problem can be converted to the standard <a href="http://en.wikipedia.org/wiki/Set_packing" rel="nofollow">Set Packing</a> problem in the following way: add a unique element $e_i$ to all $M$ sets in each collection $C_i$. Then find a set packing of size $n$ in the resulting collection. Each set in the returned set packing must belong to a different collection.</p>\n\n<p>So, the variant is not more difficult than the original set packing problem.</p>\n\n<p>MY QUESTION IS: is the variant easier than the original problem? In particular:</p>\n\n<ul>\n<li>Is it possible to solve the variant problem in time polynomial in $n$ (assuming $M$ is constant)?</li>\n<li>Is it possible to approximate the variant problem in a more efficient way than the approximations known for the general set packing problem (i.e. $O(\\sqrt{nM})$)?</li>\n</ul>\n', 'ViewCount': '40', 'Title': 'Set packing variant', 'LastEditorUserId': '1636', 'LastActivityDate': '2013-12-08T11:02:12.180', 'LastEditDate': '2013-12-08T10:39:51.820', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '18740', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<algorithms><np-complete><sets><packing>', 'CreationDate': '2013-12-08T09:03:16.310', 'Id': '18737'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>An adversary gives you a set of items whose total size is $x$ (he gets to choose how $x$ is distributed. e.g. there may be $k-1$ items of size $\\frac{x}{k}$ and 2 items of size $\\frac{x}{2k}$).</p>\n\n<p>The item are now randomly distributed into $2x$ bins (you may assume $2x\\in \\mathbb{N}$).</p>\n\n<p>What\'s the probability (i.e. what can we guarantee to achieve for any adversarial choice)  no bin contains items with total size > 1?</p>\n\n<hr>\n\n<p>For example, if the adversary chose all items (except for the last one) to be of size $\\frac{1}{2} + \\epsilon$ , then we have $2x-1$ items that no two of them can fit in a single bin. The last item can fit everywhere. hence the probability is bounded by (relaxing to $2x-1$ bins):</p>\n\n<p>$\\frac{(2x-1)!}{(2x-1)^{2x-1}} &lt; e^{-(2x-1)}$ .</p>\n\n<p>On the other hand, all I know for a general item set is that a "good" coloring exist (easy to see using the first fit algorithm).</p>\n\n<p>Any ideas?</p>\n', 'ViewCount': '27', 'Title': 'Adversarial bin packing', 'LastEditorUserId': '12486', 'LastActivityDate': '2013-12-31T09:37:08.750', 'LastEditDate': '2013-12-31T09:37:08.750', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12486', 'Tags': '<combinatorics><probability-theory><lower-bounds><knapsack-problems><packing>', 'CreationDate': '2013-12-31T09:24:16.570', 'Id': '19398'}},