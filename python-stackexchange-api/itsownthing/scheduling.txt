{'ViewCount': '635', 'Title': 'Does cooperative scheduling suspend processes when they perform an  I/O operation?', 'LastEditDate': '2012-04-07T13:42:43.093', 'AnswerCount': '4', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '40', 'FavoriteCount': '0', 'Body': '<p>Many operating systems references say that with cooperative (as opposed to preemptive) multitasking, a process keeps the CPU until it explicitly voluntarily suspends itself.  If a running process performs an I/O request that cannot be immediately satisfied (e.g., requests a key stroke that is not yet available), does the scheduler suspend it, or does it really keep the CPU until the request can be serviced?</p>\n\n<p>[Edited to replace "blocks on i/o" with "performs an I/O request that cannot be immediately satisfied."]</p>\n', 'Tags': '<operating-systems><process-scheduling>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-04-09T22:15:05.277', 'CommentCount': '2', 'AcceptedAnswerId': '12', 'CreationDate': '2012-03-06T19:17:48.460', 'Id': '5'}{'Body': '<p>Suppose that a certain parallel application uses a master-slave design to process a large number of workloads. Each workload takes some number of cycles to complete; the number of cycles any given workload will take is given by a known random variable $X$. Assume that there are $n$ such workloads and $m$ equivalent slaves (processing nodes). Naturally, a more general version of this question addresses the case of slaves of differing capabilities, but we ignore this for now.</p>\n\n<p>The master cannot process workloads, but can distribute workloads to slave nodes and monitor progress of slave nodes. Specifically, the master can perform the following actions:</p>\n\n<ol>\n<li>Instantaneously begin processing of any $k$ workloads on any free node.</li>\n<li>Instantaneously receive confirmation of the completion by a node of a previously initiated batch of $k$ workloads.</li>\n<li>At any point in time, and instantaneously, determine the state of all nodes (free or busy) as well as the number of workloads completed and the number of workloads remaining.</li>\n</ol>\n\n<p>For simplicity\'s sake, assume $k$ divides $n$.</p>\n\n<p>There are at least two categories of load balancing strategies for minimizing the total execution time of all workloads using all slaves (to clarify, I\'m talking about the makespan or wall-clock time, not the aggregate process time, which is independent of the load-balancing strategy being used under the simplifying assumptions being made in this question): static and dynamic. In a static scheme, all placement decisions are made at time $t = 0$. In a dynamic scheme, the master can make placement decisions using information about the progress being made by some slaves, and as such, better utilization can be attained (in practice, there are overheads associated with dynamic scheduling as compared to static scheduling, but we ignore these). Now for some questions:</p>\n\n<ol>\n<li>Is there a better way to statically schedule workloads than to divide batches of $k$ workloads among the $m$ slaves as evenly as possible (we can also assume, for simplicity\'s sake, that $m$ divides $n/k$, so batches could be statically scheduled completely evenly)? If so, how?</li>\n<li>Using the best static scheduling policy, what should the mean and standard deviation be for the total execution time, in terms of the mean $\\mu$ and standard deviation $\\sigma$ of $X$? </li>\n</ol>\n\n<p>A simple dynamic load balancer might schedule $i$ batches of $k$ workloads to each slave initially, and then, when nodes complete the initial $i$ batches, schedule an additional batch of $k$ workloads to each slave on a first-come, first-served basis. So if two slave nodes are initially scheduled 2 batches of 2 workloads each, and the first slave finishes its two batches, an additional batch is scheduled to the first slave, while the second slave continues working. If the first slave finishes the new batch before the second batch finishes its initial work, the master will continue scheduling to the first slave. Only when the second slave completes executing its work will it be issued a new batch of workloads. Example:</p>\n\n<pre><code>         DYNAMIC           STATIC\n         POLICY            POLICY\n\n     slave1  slave2    slave1  slave2\n     ------  ------    ------  ------\n\nt&lt;0    --      --        --      --\n\nt&lt;1  batch1  batch3    batch1  batch3\n     batch2  batch4    batch2  batch4\n                       batch5  batch7\n                       batch6  batch8\n\nt=1    --    batch3    batch5  batch3\n             batch4    batch6  batch4\n                               batch7\n                               batch8\n\nt&lt;2  batch5  batch3    batch5  batch3\n             batch4    batch6  batch4\n                               batch7\n                               batch8\n\nt=2    --    batch4    batch6  batch4\n                               batch7\n                               batch8\n\nt&lt;3  batch6  batch4    batch6  batch4\n                               batch7\n                               batch8\n\nt=3    --      --        --    batch7\n                               batch8\n\nt&lt;4  batch7  batch8      --    batch7\n                               batch8\n\nt=4    --      --        --    batch8\n\nt&lt;5      -DONE-          --    batch8\n\nt=5                      --      --\n\nt &lt; 6                      -DONE-\n</code></pre>\n\n<p>For clarification, batches 1 and 2 take 1/2 second each to be processed, batch 3 takes 2 seconds to be processed, and batches 4-8 take 1 second each to be processed. This information is not known a-priori; in the static scheme, all jobs are distributed at t=0, whereas in the dynamic scheme, distribution can take into account what the actual runtimes of the jobs "turned out" to be. We notice that the static scheme takes one second longer than the dynamic scheme, with slave1 working 3 seconds and slave2 working 5 seconds. In the dynamic scheme, both slaves work for the full 4 seconds.</p>\n\n<p>Now for the question that motivated writing this:</p>\n\n<ol>\n<li>Using the dynamic load balancing policy described above, what should the mean and standard deviation be for the total execution time, in terms of the mean $\\mu$ and standard deviation $\\sigma$ of $X$?</li>\n</ol>\n\n<p>Interested readers have my assurances that this isn\'t homework, although it probably isn\'t much harder than what one might expect to get as homework in certain courses. Given that, if anyone objects to this being asked and demands that I show some work, I will be happy to oblige (although I don\'t know when I\'ll have time in the near future). This question is actually based on some work that I never got around to doing a semester or two ago, and empirical results were where we left it. Thanks for help and/or effort, I\'ll be interested to see what you guys put together.</p>\n', 'ViewCount': '198', 'Title': 'Analyzing load balancing schemes to minimize overall execution time', 'LastEditorUserId': '69', 'LastActivityDate': '2012-03-09T17:09:49.673', 'LastEditDate': '2012-03-09T17:09:49.673', 'AnswerCount': '1', 'CommentCount': '9', 'AcceptedAnswerId': '140', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '69', 'Tags': '<scheduling><distributed-systems><parallel-computing>', 'CreationDate': '2012-03-08T16:00:04.720', 'Id': '134'}{'Body': '<p><a href="http://en.wikipedia.org/wiki/Two-level_scheduling" rel="nofollow">Two-level scheduling</a> is useful when a system is running more processes than fit in RAM: a lower-level scheduler switches between resident processes, and a higher-level scheduler swaps groups of processes in and out.</p>\n\n<p>I find no other mention of two-level scheduling in Andrew Tanenbaum\'s <em>Operating Systems: Design and Implementation</em>, 1st ed. Exercise 2.22 asks why two-level scheduling might be used; I don\'t know whether it\'s there as a reading comprehension check or there are other reasons not prominently mentioned in the text.</p>\n\n<p>Is two-level scheduling useful to manage other resource contentions, besides memory?</p>\n', 'ViewCount': '288', 'Title': 'Are two-level schedulers only useful to manage swapping?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-03-20T18:05:44.773', 'LastEditDate': '2012-03-11T21:56:40.317', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '39', 'Tags': '<scheduling><operating-systems>', 'CreationDate': '2012-03-11T21:24:13.807', 'Id': '224'}{'Body': "<p>In a round-robin scheduler, adding a process multiple times to the process list is a cheap way to give it higher priority.</p>\n\n<p>I wonder how practical an approach this might be. What benefit does it have over other techniques such as giving the process a longer time slice (benefit: less switching time) or maintaining a separate list of high-priority processes. In particular, how does listing a process multiple times influence fairness and reactivity?</p>\n\n<p>(From exercise 2.16 in Andrew Tanenbaum's <em>Operating Systems: Design and Implementation</em> 1st ed.)</p>\n", 'ViewCount': '501', 'Title': 'Round-robin scheduling: allow listing a process multiple times?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-26T18:06:08.697', 'LastEditDate': '2012-04-07T13:42:29.833', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '392', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '39', 'Tags': '<operating-systems><process-scheduling>', 'CreationDate': '2012-03-11T21:39:01.683', 'Id': '226'}{'Body': '<p>There are different queues of processes (in an operating system):</p>\n\n<p><em>Job Queue:</em> Each new process goes into the job queue. Processes in the job queue reside on mass storage and await the allocation of main memory.</p>\n\n<p><em>Ready Queue:</em> The set of all processes that are in main memory and are waiting for CPU time is kept in the ready queue.</p>\n\n<p><em>Waiting (Device) Queues:</em> The set of processes waiting for allocation of certain I/O devices is kept in the waiting (device) queue.</p>\n\n<p>The short-term scheduler (also known as CPU scheduling) selects a process from the ready queue and yields control of the CPU to the process.</p>\n\n<p>In my lecture notes the long-term scheduler is partly described as maintaining a queue of new processes waiting to be admitted into the system. </p>\n\n<p>What is the name of the queue the long-term scheduler maintains? When it admits a process to the system is the process placed in the ready queue?    </p>\n', 'ViewCount': '1749', 'Title': 'Which queue does the long-term scheduler maintain?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-04T05:30:51.123', 'LastEditDate': '2012-04-22T16:10:28.683', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '1115', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '935', 'Tags': '<operating-systems><terminology><process-scheduling>', 'CreationDate': '2012-04-07T06:24:48.613', 'Id': '1106'}{'ViewCount': '260', 'Title': 'How does variance in task completion time affect makespan?', 'LastEditDate': '2012-04-13T22:15:45.380', 'AnswerCount': '2', 'Score': '13', 'PostTypeId': '1', 'OwnerUserId': '69', 'FavoriteCount': '0', 'Body': "<p>Let's say that we have a large collection of tasks $\\tau_1, \\tau_2, ..., \\tau_n$ and a collection of identical (in terms of performance) processors $\\rho_1, \\rho_2, ..., \\rho_m$ which operate completely in parallel. For scenarios of interest, we may assume $m \\leq n$. Each $\\tau_i$ takes some amount of time/cycles to complete once it is assigned to a processor $\\rho_j$, and once it is assigned, it cannot be reassigned until completed (processors always eventually complete assigned tasks). Let's assume that each $\\tau_i$ takes an amount of time/cycles $X_i$, not known in advance, taken from some discrete random distribution. For this question, we can even assume a simple distribution: $P(X_i = 1) = P(X_i = 5) = 1/2$, and all $X_i$ are pairwise independent. Therefore $\\mu_i = 3$ and $\\sigma^2 = 4$.</p>\n\n<p>Suppose that, statically, at time/cycle 0, all tasks are assigned as evenly as possible to all processors, uniformly at random; so each processor $\\rho_j$ is assigned $n/m$ tasks (we can just as well assume $m | n$ for the purposes of the question). We call the makespan the time/cycle at which the last processor $\\rho^*$ to finish its assigned work, finishes the work it was assigned. First question:</p>\n\n<blockquote>\n  <p>As a function of $m$, $n$, and the $X_i$'s, what is the makespan $M$? Specifically, what is $E[M]$? $Var[M]$?</p>\n</blockquote>\n\n<p>Second question:</p>\n\n<blockquote>\n  <p>Suppose $P(X_i = 2) = P(X_i = 4) = 1/2$, and all $X_i$ are pairwise independent, so $\\mu_i = 3$ and $\\sigma^2 = 1$. As a function of $m$, $n$, and these new $X_i$'s, what is the makespan? More interestingly, how does it compare to the answer from the first part?</p>\n</blockquote>\n\n<p>Some simple thought experiments demonstrate the answer to the latter is that the makespan is longer. But how can this be quantified? I will be happy to post an example if this is either (a) controversial or (b) unclear. Depending on the success with this one, I will post a follow-up question about a dynamic assignment scheme under these same assumptions. Thanks in advance!</p>\n\n<p><strong>Analysis of an easy case: $m = 1$</strong></p>\n\n<p>If $m = 1$, then all $n$ tasks are scheduled to the same processor. The makespan $M$ is just the time to complete $n$ tasks in a complete sequential fashion. Therefore,\n$$\\begin{align*}\r\n E[M]\r\n &amp;= E[X_1 + X_2 + ... + X_n] \\\\\r\n &amp;= E[X_1] + E[X_2] + ... + E[X_n] \\\\\r\n &amp;= \\mu + \\mu + ... + \\mu \\\\\r\n &amp;= n\\mu\r\n\\end{align*}$$\nand\n$$\\begin{align*}\r\n Var[M]\r\n &amp;= Var[X_1 + X_2 + ... + X_n] \\\\\r\n &amp;= Var[X_1] + Var[X_2] + ... + Var[X_n] \\\\\r\n &amp;= \\sigma^2 + \\sigma^2 + ... + \\sigma^2 \\\\\r\n &amp;= n\\sigma^2 \\\\\r\n\\end{align*}$$</p>\n\n<p>It seems like it might be possible to use this result to answer the question for $m &gt; 1$; we simply need to find an expression (or close approximation) for $\\max(Y_1, Y_2, ..., Y_m)$ where $Y_i = X_{i\\frac{n}{m} + 1} + X_{i\\frac{n}{m} + 2} + ... + X_{i\\frac{n}{m} + \\frac{n}{m}}$, a random variable with $\\mu_Y = \\frac{n}{m}\\mu_X$ and $\\sigma_Y^2 = \\frac{n}{m}\\sigma_X^2$. Is this heading in the right direction?</p>\n", 'Tags': '<probability-theory><scheduling><parallel-computing>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-12-07T11:20:11.647', 'CommentCount': '1', 'AcceptedAnswerId': '1251', 'CreationDate': '2012-04-12T20:03:55.620', 'Id': '1236'}{'ViewCount': '214', 'Title': "Ordering elements so that some elements don't come between others", 'LastEditDate': '2012-05-30T07:24:52.507', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '69', 'FavoriteCount': '5', 'Body': '<p>Given an integer $n$ and set of triplets of distinct integers\n$$S \\subseteq \\{(i, j, k) \\mid 1\\le i,j,k \\le n, i \\neq j, j \\neq k, i \\neq k\\},$$\nfind an algorithm which either finds a permutation $\\pi$ of the set $\\{1, 2, \\dots, n\\}$ such that\n$$(i,j,k) \\in S \\implies (\\pi(j)&lt;\\pi(i)&lt;\\pi(k)) ~\\lor~ (\\pi(i)&lt;\\pi(k)&lt;\\pi(j))$$\nor correctly determines that no such permutation exists.  Less formally, we want to reorder the numbers 1 through $n$; each triple $(i,j,k)$ in $S$ indicates that $i$ must appear before $k$ in the new order, but $j$ must not appear between $i$ and $k$.</p>\n\n<p><strong>Example 1</strong></p>\n\n<p>Suppose $n=5$ and $S = \\{(1,2,3), (2,3,4)\\}$.  Then</p>\n\n<ul>\n<li><p>$\\pi = (5, 4, 3, 2, 1)$ is <em>not</em> a valid permutation, because $(1, 2, 3)\\in S$, but $\\pi(1) &gt; \\pi(3)$.</p></li>\n<li><p>$\\pi = (1, 2, 4, 5, 3)$ is <em>not</em> a valid permutation, because $(1, 2, 3) \\in S$ but $\\pi(1) &lt; \\pi(3) &lt; \\pi(5)$.</p></li>\n<li><p>$(2, 4, 1, 3, 5)$ is a valid permutation.</p></li>\n</ul>\n\n<p><strong>Example 2</strong></p>\n\n<p>If $n=5$ and $S = \\{(1, 2, 3), (2, 1, 3)\\}$, there is no valid permutation.  Similarly, there is no valid permutation if $n=5$ and $S = \\{(1,2,3), (3,4,5), (2,5,3), (2,1,4)\\}$  (I think; may have made a mistake here).</p>\n\n<p><em>Bonus: What properties of $S$ determine whether a feasible solution exists?</em></p>\n', 'Tags': '<algorithms><optimization><scheduling>', 'LastEditorUserId': '72', 'LastActivityDate': '2012-05-30T07:24:52.507', 'CommentCount': '5', 'AcceptedAnswerId': '1275', 'CreationDate': '2012-04-13T19:26:19.010', 'Id': '1255'}{'Body': '<p>For the following jobs: </p>\n\n<p><img src="http://i.stack.imgur.com/rwOBN.png" alt="job table"></p>\n\n<p>The <strong>average wait time</strong> would be using a FCFS algorithm:</p>\n\n<p>(6-6)+(7-2)+(11-5)+(17-5)+(14-1) -> 0+5+6+10+13 -> 34/5 = 7 (6.8)</p>\n\n<p>What would the <strong>average turnaround time</strong> be? </p>\n', 'ViewCount': '8299', 'Title': 'What is the average turnaround time?', 'LastActivityDate': '2014-04-30T15:21:50.527', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '1279', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '935', 'Tags': '<algorithms><operating-systems><process-scheduling><scheduling>', 'CreationDate': '2012-04-14T13:25:49.020', 'Id': '1270'}{'ViewCount': '1291', 'Title': 'What is meant by interrupts in the context of operating systems?', 'LastEditDate': '2012-05-18T07:45:37.680', 'AnswerCount': '4', 'Score': '7', 'OwnerDisplayName': 'user28694', 'PostTypeId': '1', 'OwnerUserId': '3017', 'Body': '<p>I\'ve decided to read <a href="http://rads.stackoverflow.com/amzn/click/0470128720" rel="nofollow">Operating Systems Concepts</a> by Silberschatz, Galvin Gagne (8th edition) over the summer. I\'ve gotten to a topic that\'s confusing me - interrupts and their role as it relates to operating systems. </p>\n\n<p>The text says that an operating system will begin a first process such as "init" and then wait for an "event" to occur and this event is usually signaled by an interrupt. The text also says that the interrupt can come from either the hardware or the software. How does this work, in a little more detail? Is the operating system driven by interrupts? </p>\n\n<p>I am just looking for some big picture understanding. </p>\n', 'Tags': '<operating-systems><computer-architecture><process-scheduling>', 'LastEditorUserId': '1541', 'LastActivityDate': '2012-05-18T07:45:42.593', 'CommentCount': '0', 'AcceptedAnswerId': '1701', 'CreationDate': '2012-05-05T21:03:18.007', 'Id': '1700'}{'Body': u'<p>I was reading <strong>Linux Kernel Development</strong> by Robert Love, where I came across this</p>\n\n<blockquote>\n  <p>Linux takes an interesting approach to thread support: It does not\n  differentiate between threads and normal processes.To the kernel, all\n  processes are the same\u2014 some just happen to share resources.</p>\n</blockquote>\n\n<p>I do not know much about OSs (aspire to know more) and kernels and hence the above quote raised a question about thread implementations in different OSs(at least the popular ones like Windows, Linux and Unix).</p>\n\n<p>Can someone please explain the different techniques for providing thread-support in an OS? ( and optionally contrast them)</p>\n', 'ViewCount': '512', 'Title': 'How are threads implemented in different OSs?', 'LastEditorUserId': '59', 'LastActivityDate': '2012-06-07T23:11:00.057', 'LastEditDate': '2012-06-07T23:11:00.057', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '59', 'Tags': '<operating-systems><process-scheduling><threads>', 'CreationDate': '2012-06-07T07:07:14.337', 'Id': '2248'}{'ViewCount': '383', 'Title': 'Getting parallel items in dependency resolution', 'LastEditDate': '2012-06-28T22:30:03.503', 'AnswerCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1995', 'FavoriteCount': '2', 'Body': '<p>I have implemented a topological sort based on the <a href="http://en.wikipedia.org/wiki/Topological_sort" rel="nofollow">Wikipedia article</a> which I\'m using for dependency resolution, but it returns a linear list. What kind of algorithm can I use to find the independent paths?</p>\n', 'Tags': '<algorithms><graphs><parallel-computing><scheduling>', 'LastEditorUserId': '39', 'LastActivityDate': '2012-06-28T22:30:03.503', 'CommentCount': '1', 'AcceptedAnswerId': '2525', 'CreationDate': '2012-06-28T09:12:35.827', 'Id': '2524'}{'Body': '<p>In "Computers and Intractability A Guide to the Theory of NP-Completeness" textbook pp 236, "Sequencing to minimize tardy tasks" is NP-complete.<br>\nTo be specific the problem is as follows: </p>\n\n<p>For each task $t \\in T$, partial order $&lt;$ on $T$, a length $l(t)$, and a deadline $d(t)$ and a positive integer $K \\leq |T|$. Is there a one-processor schedule $s$ for $T$ that obeys the precedence constraints, that is $s$ is such that $t &lt; t\'$ implies $s(t)+l(t) &lt; s(t\')$, and such that there are at most $K$ tasks for which $s(t) + l(t) &gt; d(t)$? </p>\n\n<p>Now we associate each task with a release time $r(t)$ and $s(t)$ should be $\\geq r(t)$. Does the revised problem stay NP-completeness ?</p>\n', 'ViewCount': '186', 'Title': 'NP-completeness of scheduling to minimise tardy tasks with release times', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-09T08:34:55.763', 'LastEditDate': '2012-07-09T08:31:18.467', 'AnswerCount': '1', 'CommentCount': '6', 'Score': '1', 'OwnerDisplayName': 'user1403806', 'PostTypeId': '1', 'OwnerUserId': '2090', 'Tags': '<complexity-theory><scheduling>', 'CreationDate': '2012-07-06T01:11:14.227', 'Id': '2633'}{'Body': '<p>Given a set of tasks (execution time, deadline=period):</p>\n\n<ul>\n<li>$T_1(20,100)$</li>\n<li>$T_2(30,250)$</li>\n<li>$T_3(100,400) $</li>\n</ul>\n\n<p>Now I want to restrict the deadlines as $D_i = f \\cdot P_i$, where $D_i$ is new deadline for $i$-th task, $P_i$ is the original period for $i$-th task and $f$ is the factor I want to figure out. What is the smallest value of $f$ that the tasks will continue to meet their deadlines?</p>\n', 'ViewCount': '70', 'Title': 'Scheduling: advance deadline for implicit-deadline rate monotonic algorithm', 'LastEditorUserId': '31', 'LastActivityDate': '2012-10-01T18:14:07.263', 'LastEditDate': '2012-09-30T09:42:04.520', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '2998', 'Tags': '<algorithms><scheduling>', 'CreationDate': '2012-09-30T07:04:11.410', 'FavoriteCount': '1', 'Id': '4810'}{'Body': u"<p>This is a homework problem for my introduction to algorithms course.</p>\n\n<blockquote>\n  <p>Recall the scheduling problem from Section 4.2 in which we sought to\n  minimize the maximum lateness. There are $n$ jobs, each with a deadline\n  $d_i$ and a required processing time $t_i$, and all jobs are available to be\n  scheduled starting at time $s$. For a job $i$ to be done, it needs to be assigned\n  a period from $s_i \\geq s$ to $f_i$ = $s_i + t_i$, and different jobs should be assigned\n  nonoverlapping intervals. As usual, such an assignment of times will be\n  called a schedule.</p>\n  \n  <p>In this problem, we consider the same setup, but want to optimize a\n  different objective. In particular, we consider the case in which each job\n  must either be done by its deadline or not at all. We\u2019ll say that a subset $J$ of\n  the jobs is schedulable if there is a schedule for the jobs in $J$ so that each\n  of them finishes by its deadline. Your problem is to select a schedulable\n  subset of maximum possible size and give a schedule for this subset that\n  allows each job to finish by its deadline.</p>\n  \n  <p>(a) Prove that there is an optimal solution $J$ (i.e., a schedulable set of\n  maximum size) in which the jobs in $J$ are scheduled in increasing\n  order of their deadlines.</p>\n  \n  <p>(b) Assume that all deadlines $d_i$ and required times $t_i$ are integers. Give\n  an algorithm to find an optimal solution. Your algorithm should\n  run in time polynomial in the number of jobs $n$, and the maximum\n  deadline $D = \\max_i d_i$.</p>\n</blockquote>\n\n<p>I've solved the problem as worded with the recurrence </p>\n\n<p>$Opt(i, d) = \\max\\left \\{ \n\\begin{array}\n \\\\ Opt(i-1, d-t_i) + 1 \\hspace{20 mm} d\\leq d_i\n \\\\ Opt(i-1, d) \n\\end{array}\n\\right \\}$</p>\n\n<p>but our instructor added a new requirement that our algorithm must not be dependent on D. This recurrence seems like it would produce an $O(nD)$ running time if implemented with dynamic programming.</p>\n\n<p>I can't figure out how to reduce its running time from $O(nD)$ to $O(n^k)$. To me it seems like it's a variation on the knapsack problem with all values equal to 1. In which case it seems like this is the best that can be done.</p>\n\n<p>If I'm doing something wrong could someone point me in the right direction, or if I've done everything right so far, could someone at least give me a hint as to how I can make an $O(n^k)$ recurrence or algorithm.</p>\n", 'ViewCount': '560', 'Title': 'Maximum Schedulable Set Zero-Lateness Deadline Scheduling', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-30T18:55:05.237', 'LastEditDate': '2012-10-31T09:59:21.227', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4294', 'Tags': '<algorithms><time-complexity><dynamic-programming><efficiency><scheduling>', 'CreationDate': '2012-10-20T23:13:27.230', 'FavoriteCount': '2', 'Id': '6202'}{'Body': '<p>There are three processes in line, $P_0$, $P_1$ and $P_2$.</p>\n\n<ol>\n<li><p>$P_0$ registered and executes</p></li>\n<li><p>$P_0$ I/O blocked</p></li>\n<li><p>so $P_1$ executes</p></li>\n<li><p>$P_1$ I/O blocked</p></li>\n<li><p>$P_0$ executes. ??</p></li>\n</ol>\n\n<p>After $P_1$ must come $P_2$ that is what FCFS (First-Come-First-Serve) is about.</p>\n\n<p>So anyone please explain why is $P_0$ coming again? $P_0$ should be in the tail of ready queue after servicing I/O.</p>\n\n<hr>\n\n<blockquote>\n  <p>Or does the process completing an I/O return to the TOP of the Ready\n  Queue instead of the bottom in FCFS?</p>\n</blockquote>\n\n<hr>\n\n<h2><a href="http://www.ontko.com/moss/sched/user_guide.html" rel="nofollow">The link</a></h2>\n\n<p><em><strong>The scheduling.conf</em></strong></p>\n\n<pre><code>// # of Process \nnumprocess 4\n\n// mean deivation\nmeandev 2000\n\n// standard deviation\nstanddev 0\n\n// process    # I/O blocking\nprocess 500\nprocess 500\nprocess 500\nprocess 500\n\n// duration of the simulation in milliseconds\nruntime 10000\n</code></pre>\n\n<p><em><strong>The Summary-Processes</em></strong></p>\n\n<pre><code>Process: 0 registered... (2000 500 0 0)\nProcess: 0 I/O blocked... (2000 500 500 500)\nProcess: 1 registered... (2000 500 0 0)\nProcess: 1 I/O blocked... (2000 500 500 500)\nProcess: 0 registered... (2000 500 500 500)  --&gt; why p0 it should be p2 w.r.t FCFS\nProcess: 0 I/O blocked... (2000 500 1000 1000)\nProcess: 1 registered... (2000 500 500 500)\nProcess: 1 I/O blocked... (2000 500 1000 1000)\nProcess: 0 registered... (2000 500 1000 1000)\nProcess: 0 I/O blocked... (2000 500 1500 1500)\nProcess: 1 registered... (2000 500 1000 1000)\nProcess: 1 I/O blocked... (2000 500 1500 1500)\nProcess: 0 registered... (2000 500 1500 1500)\nProcess: 0 completed... (2000 500 2000 2000)\nProcess: 1 registered... (2000 500 1500 1500)\nProcess: 1 completed... (2000 500 2000 2000)\nProcess: 2 registered... (2000 500 0 0)\nProcess: 2 I/O blocked... (2000 500 500 500)\nProcess: 3 registered... (2000 500 0 0)\nProcess: 3 I/O blocked... (2000 500 500 500)\nProcess: 2 registered... (2000 500 500 500)\nProcess: 2 I/O blocked... (2000 500 1000 1000)\nProcess: 3 registered... (2000 500 500 500)\nProcess: 3 I/O blocked... (2000 500 1000 1000)\nProcess: 2 registered... (2000 500 1000 1000)\nProcess: 2 I/O blocked... (2000 500 1500 1500)\nProcess: 3 registered... (2000 500 1000 1000)\nProcess: 3 I/O blocked... (2000 500 1500 1500)\nProcess: 2 registered... (2000 500 1500 1500)\nProcess: 2 completed... (2000 500 2000 2000)\nProcess: 3 registered... (2000 500 1500 1500)\nProcess: 3 completed... (2000 500 2000 2000)\n</code></pre>\n\n<p><em><strong>The Summary-Results</em></strong></p>\n\n<pre><code>Scheduling Type: Batch (Nonpreemptive)\nScheduling Name: First-Come First-Served\nSimulation Run Time: 8000\nMean: 2000\nStandard Deviation: 0\nProcess #   CPU Time        IO Blocking     CPU Completed   CPU Blocked\n0           2000 (ms)       500 (ms)        2000 (ms)       3 times\n1           2000 (ms)       500 (ms)        2000 (ms)       3 times\n2           2000 (ms)       500 (ms)        2000 (ms)       3 times\n3           2000 (ms)       500 (ms)        2000 (ms)       3 times\n</code></pre>\n', 'ViewCount': '689', 'ClosedDate': '2013-11-09T13:12:49.210', 'Title': 'First-Come-First-Serve scheduling algorithm - what happens to process after returning from I/O? where does it go in the queue', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-02T00:09:47.220', 'LastEditDate': '2013-07-04T22:09:09.530', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'OwnerDisplayName': 'Doopy Doo', 'PostTypeId': '1', 'Tags': '<operating-systems><process-scheduling>', 'CreationDate': '2012-10-19T14:01:19.533', 'Id': '6209'}{'Body': '<p>I would like to know what impacts does a scheduling algorithm say Round Robin of FIFO have on a Operating system. I understand the a scheduling algorithm has the processes run in burst then switch between one another. But what does this mean for an OS. All i can figure out is that the OS has to keep track of which process is running, see if its done/completed its operation, chose/switch to another process and run it for a given time. Am I missing the obvious here? It does not really seam to me that a scheduling algorithm really affect the OS per say but the CPU hardware.</p>\n', 'ViewCount': '386', 'Title': 'Scheduling algorithms and quantum time', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-02T18:43:37.563', 'LastEditDate': '2012-11-01T22:37:29.953', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'OwnerDisplayName': 'MNM', 'PostTypeId': '1', 'Tags': '<operating-systems><process-scheduling>', 'CreationDate': '2012-11-01T13:05:31.500', 'Id': '6432'}{'Body': '<p>As the net-evergreen <a href="http://www.snopes.com/holidays/christmas/santa/physics.asp">The Physics of Santa</a> establishes, it is physically impossible for Santa to get a gift to every kid on the planet. Route planning won\'t help much there, but can a good planning algorithm at least make sure that every kid gets a gift once in a while while Santa <em>also</em> serves as many kids as possible each year?</p>\n\n<hr>\n\n<p>Consider a complete graph with real, positive weights and a constant $k$. We want to solve a variant of the Travelling Sales Person problem:</p>\n\n<blockquote>\n  <p>Is there a circular route of length at most $k$ that serves more than $m$ nodes?</p>\n</blockquote>\n\n<p>The optimisation version would be:</p>\n\n<blockquote>\n  <p>Maximise the number of nodes that can be served with a circular route of length at most $k$.</p>\n</blockquote>\n\n<p>This is motivated by real-world limitations on routes: Santa has one night to deliver as many gifts as possible, a sales person has eight hours for one day\'s route, and so on.</p>\n\n<p>The first, but not final question is: how hard is this problem? Let\'s assume we can start at any node, but that should not make too much of a difference.</p>\n\n<p>Now, in order to model fairness, let\'s assume there are $N$ nodes and we can visit at most $M$ with every tour. Ideally, we would want that every node is visited $t\\cdot\\frac{M}{N}$ times across $t$ efficient tours. Since there may be bottleneck nodes that have to be visited more often in order to ensure routes visit many nodes, some will inevitably have to be visited less often. That also excludes the trivial approximation of removing once visited nodes until all have been visited.</p>\n\n<p>So, here is the final question. Let $T$ be the number of tours needed until all nodes have been visited by <em>efficient</em> $k$-tours. How can we algorithmically determine the minimal value of $T$ (and all the necessary routes)? How complex is this problem?</p>\n\n<p>I guess this is really a multi-criterial problem: each tour should visit as many nodes as possible while we want to keep tours as disjoint as possible.</p>\n', 'ViewCount': '179', 'Title': 'Can Santa be both fair and efficient?', 'LastActivityDate': '2012-11-09T03:48:37.460', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '98', 'Tags': '<complexity-theory><graphs><scheduling>', 'CreationDate': '2012-11-07T11:10:15.287', 'FavoriteCount': '2', 'Id': '6531'}{'Body': '<p>What would be the process state in a multi threaded process, in which threads are in different states (running, waiting, blocked etc)</p>\n', 'ViewCount': '101', 'Title': 'Process state in multi threaded process', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-09T07:57:00.760', 'LastEditDate': '2012-11-09T07:57:00.760', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4508', 'Tags': '<terminology><operating-systems><process-scheduling><threads>', 'CreationDate': '2012-11-08T10:47:53.373', 'Id': '6558'}{'Body': '<p>Given $n$ jobs, schedule them such that the weighted sum is minimum.</p>\n\n<p>weighted minimum sum S  for the schedule $\\sigma = \\{ J_1, J_2, ... J_n \\}$ is given by :</p>\n\n<p>$S = \\sum_{1\\leqq i \\leqq n} w_i C_i$ where $C_i\\ = \\sum_{1\\leqq j \\leqq i} t_j$ and $w_i$ is the weight of job $J_i$,  $t_i$ is the time $J_i$ takes to complete.</p>\n\n<p>I think the solution is to schedule the jobs in shortest weighted processing time i.e. to arrange them in the increasing order of  $ t_i/w_i $.</p>\n\n<p>But how to prove this.</p>\n', 'ViewCount': '85', 'Title': 'Single machine job scheduling', 'LastEditorUserId': '41', 'LastActivityDate': '2012-12-23T09:25:30.377', 'LastEditDate': '2012-12-23T09:25:30.377', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4980', 'Tags': '<algorithms><scheduling>', 'CreationDate': '2012-12-20T07:28:33.517', 'Id': '7521'}{'ViewCount': '632', 'Title': 'Scheduling algorithm to minimize maximum deadline overshoot in pre-emptive scheduler', 'LastEditDate': '2013-01-12T18:59:53.610', 'AnswerCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '4751', 'FavoriteCount': '1', 'Body': '<p>Suppose there are $n$ tasks, which need to be scheduled by a <em>pre-emptive</em> scheduler. Each task $T_i$ has a deadline $d_i$ and a total processing time $t_i$ associated with it. Now, all $n$ tasks are given a priory to the scheduler. The scheduler can run a task for 1 unit of time in one go. After each unit of time, it can schedule any process (including the current one) for the next 1 unit of time.</p>\n\n<p>The goal of the scheduler is to <em>minimize</em> the <em>maximum</em> overshoot of its deadline by any process. For example, for tasks $T_1: (2, 2)$, $T_2: (1, 1)$ and $T_3: (4, 3)$ are the 3 tasks with their respective $(d_i, t_i)$, then a schedule of $T_2, T_1, T_3, T_1, T_3, T_3$ gives a maximum overshoot of 2. No other schedule can reduce the maximum overshoot.</p>\n\n<p>My solution is to use "Earliest Deadline First Scheduling", with tie-breaks based on most time/work remaining. Further ties are broken arbitrarily. Basically, after each unit of time, the task with the earliest deadline is scheduled first. Any ties are decided on which task has the most work remaining. Further ties are broken arbitrarily. This seems to work on a few small hand-constructed cases. But I could not prove or disprove it.</p>\n\n<p>To make the question more than a yes/no question, I would really appreciate it if someone could prove if this is correct, or provide a correct and efficient (sub-quadratic time) algorithm for this. This is not homework. It was presented to me by someone, and I suspect it might be a popular interview question or a question on a programming forum.</p>\n', 'Tags': '<algorithms><optimization><scheduling>', 'LastEditorUserId': '2100', 'LastActivityDate': '2013-08-14T07:27:28.117', 'CommentCount': '0', 'AcceptedAnswerId': '7906', 'CreationDate': '2013-01-12T06:01:51.120', 'Id': '7900'}{'ViewCount': '73', 'Title': 'What mechanisms prevent a process from taking over the processor forever?', 'LastEditDate': '2013-01-31T19:25:51.833', 'AnswerCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6598', 'FavoriteCount': '0', 'Body': '<p>Suppose a process keeps running code (e.g. an infinite loop). How can other programs take over? What prevents the process from remaining active forever?</p>\n', 'Tags': '<operating-systems><process-scheduling>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-02-01T00:39:25.167', 'CommentCount': '2', 'AcceptedAnswerId': '9374', 'CreationDate': '2013-01-31T13:24:04.120', 'Id': '9354'}{'Body': '<p>I\'ve got a confusion in the following section of a book. Here we taking about FCFS Scheduling. I feel that calculation table is incorrect in the book. Because P3 got completed at time 7, it\'s turnaround time should be 7-3 because third process arrival time is 3 so why they take 1? Remember turn around time = t(process completed)-t(process submitted)</p>\n\n<p>For P4 it\'s 11-4 which I feel wrong again. Further for P5. So I want to know whether I\'m wrong in understanding this all or the following is really a wrong calculation. Can someone please explain. Thanks!\nCheck the fallowing links for book scan:\n<a href="http://i.stack.imgur.com/oGtva.jpg" rel="nofollow">http://i.stack.imgur.com/oGtva.jpg</a>\n<a href="http://i.stack.imgur.com/mVP03.jpg" rel="nofollow">http://i.stack.imgur.com/mVP03.jpg</a></p>\n', 'ViewCount': '30', 'Title': 'Process scheduling confusion', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-02-10T12:38:57.680', 'LastEditDate': '2013-02-10T12:38:57.680', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'OwnerDisplayName': 'user1938918', 'PostTypeId': '1', 'OwnerUserId': '8231', 'Tags': '<scheduling>', 'CreationDate': '2013-02-09T10:14:54.163', 'Id': '9631'}{'Body': '<p>I\'m developing software to run variations on a base process flow (see #1, below). A user specifies in a text file what steps in the process to modify. Because each step takes a long time to run, I\'d like to minimize the amount of duplicate processing required. For example, if variations occur at step B, I could run step A one for all results before "branching" at step B (see #2 below). Similarly, I could branch again at step D if additional variations on step D are indicated (see #3 below).</p>\n\n<p><strong>1) Base Process:</strong></p>\n\n<pre><code>input --&gt; A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; result\n</code></pre>\n\n<p><strong>2) Modification of Step B:</strong></p>\n\n<pre><code>input --&gt; A --&gt; B1 --&gt; C --&gt; D --&gt; E --&gt; result1\n                B2 --&gt; C --&gt; D --&gt; E --&gt; result2\n</code></pre>\n\n<p><strong>3) Modification of Steps B and D:</strong></p>\n\n<pre><code>input --&gt; A --&gt; B1 --&gt; C --&gt; D1 --&gt; E --&gt; result1\n                             D2 --&gt; E --&gt; result2\n                B2 --&gt; C --&gt; D1 --&gt; E --&gt; result3\n                             D2 --&gt; E --&gt; result4\n</code></pre>\n\n<p>Is there a simple algorithm to determine the the common process steps and the branch points as in #3 given a base flow as in #1 and a list of steps to change, e.g.</p>\n\n<pre><code>Variation  StepB  StepD\n   1         1      1\n   2         1      2\n   3         2      1\n   4         2      2\n</code></pre>\n\n<p>The above example is simple but there could be hundreds of variations modifying dozens of different steps in actual usage. </p>\n', 'ViewCount': '56', 'Title': 'Algorithm for finding optimal branch points', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-21T14:08:38.050', 'LastEditDate': '2013-04-21T14:08:38.050', 'AnswerCount': '1', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6936', 'Tags': '<algorithms><optimization><scheduling>', 'CreationDate': '2013-02-18T19:13:35.097', 'Id': '9901'}{'Body': '<p>Consider the <a href="http://en.wikipedia.org/wiki/Interval_scheduling" rel="nofollow">interval scheduling problem</a>, see also <a href="http://www.phailed.me/2012/08/interval-scheduling-problem/" rel="nofollow">here</a>. </p>\n\n<p>In order to schedule the $n$ job requests over one resource, you sort the requests in order of finish time, choose the request with earliest finish time, choose the next compatible one, and so on. </p>\n\n<p>Now, let us say we have two resources instead of one. How do I schedule my jobs now? As my idea goes, again you start by sorting the requests in order of finish time. My problem is, how do I proceed after that? Do I choose the resources in sequential or in an alternate fashion?</p>\n\n<p>If I go for sequential manner, I schedule all the possible jobs in the first resource and then do the same for second resource with the jobs yet to be scheduled. </p>\n\n<p>If I go for alternate fashion, I choose the first possible job in the first resource, then second possible job in the second resource and so on.</p>\n\n<p>In each case we will have take in to account the chosen jobs being compatible, needless to say.</p>\n\n<p>I can not decide which of these is going to be optimal.</p>\n\n<p>Any input will be appreciated.</p>\n', 'ViewCount': '168', 'Title': 'Interval Scheduling Problem with more than One Resource', 'LastEditorUserId': '7200', 'LastActivityDate': '2013-03-18T00:07:18.963', 'LastEditDate': '2013-03-18T00:07:18.963', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7200', 'Tags': '<algorithms><optimization><scheduling>', 'CreationDate': '2013-03-12T00:49:56.563', 'Id': '10460'}{'Body': "<p>There are 3 processors: $P_1$, $P_2$, $P_3$. $P_1$ can execute only one job while the other two can execute any number of jobs in parallel.</p>\n\n<p>Each job consists of 3 parts, and each part is processed by their respective processor (eg. part 1 by $P_1$). Furthermore part 2 can be executed only after $P_1$ finishes executing part 1, and part 3 can be executed only after $P_2$ finishes executing part 2.</p>\n\n<p>Suppose there are $n$ jobs, and again each job has 3 parts. The processor $P_k$ takes time $T_{i\\,k}$ to complete part $k$ of job $i$.\nCan anyone suggest an algorithm that takes set of $n$ jobs and determines the the jobs should be processed  so that the total time is minimized?</p>\n\n<p>This is a homework problem and I don't know where ti start</p>\n", 'ViewCount': '102', 'Title': 'Minimize the total execution time of jobs executed by 3 processors in sequence', 'LastEditorUserId': '5020', 'LastActivityDate': '2013-03-26T02:22:27.973', 'LastEditDate': '2013-03-24T19:24:09.633', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '10793', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7391', 'Tags': '<algorithms><scheduling>', 'CreationDate': '2013-03-24T05:04:14.490', 'Id': '10736'}{'Body': '<p>I am finding it difficult to clearly differentiate between Multiprogramming and Multitasking.</p>\n\n<p>My primary source has been <a href="http://en.wikipedia.org/wiki/Computer_multitasking" rel="nofollow">Wikipedia</a>, but the WP article seems to be a little at odds with some less reputable sources (like my college professor).</p>\n\n<p>As I read WP, <em>multiprogramming</em> is a rudimentary way of increasing CPU throughput, by context-switching when a process waits for I/O.</p>\n\n<blockquote>\n  <p>Multiprogramming doesn\'t give any guarantee that a program will run in a timely manner. Indeed, the very first program may very well run for hours without needing access to a peripheral. </p>\n</blockquote>\n\n<p><em>Cooperative Time-sharing</em>, synonymous with <em>Cooperative Multitasking</em>, is an improvement on multiprogramming (with which it is not synonymous). The CPU context-switches regularly to give the impression of simultaneous execution, but processes are still required to yield - and poorly designed programs can starve the rest of the system.</p>\n\n<p><em>Preemptive Multitasking</em> takes more aggressive control of scheduling, giving priority to some processes over others, etc.</p>\n\n<ol>\n<li>Is this overview correct? If not is that because WP is incorrect or because I read WP wrong?</li>\n<li>Why do some sources seem to conflate multiprogramming and multitasking? </li>\n</ol>\n', 'ViewCount': '7123', 'Title': 'What is the difference between Multiprogramming and Multitasking', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-17T20:59:46.423', 'LastEditDate': '2013-03-26T11:56:51.257', 'AnswerCount': '3', 'CommentCount': '6', 'AcceptedAnswerId': '10811', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '7421', 'Tags': '<terminology><process-scheduling>', 'CreationDate': '2013-03-26T11:49:56.370', 'Id': '10801'}{'ViewCount': '192', 'Title': 'Job scheduling with a bottleneck problem', 'LastEditDate': '2013-03-29T08:50:28.533', 'AnswerCount': '2', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '140', 'FavoriteCount': '3', 'Body': '<p>Given $n$ jobs $J_1,J_2,...,J_n$, each job requires $T_i &gt; 0, T_i \\in N$ time to complete.</p>\n\n<p>Each job must be pre-processed and post-processed by a single machine M that can handle only <em>1 job at a time</em> and both phases require 1 unit of time. After being pre-processed, job $J_i$ is sent to a machine with unlimited power (that can handle in parallel an unlimited number of jobs) and it will be ready in time $T_i$, then it must be sent (<strong>immediately</strong>) to machine M again for post-processing. </p>\n\n<p><img src="http://i.stack.imgur.com/Y3BVv.png" alt="enter image description here"></p>\n\n<p>The associated decision problem is:</p>\n\n<p><em>Input:</em> the processing times $T_i &gt;0, T_i \\in \\mathbb{N}$ of $N$ jobs, an integer $K\\geq 2N$<br>\n<em>Question:</em> can we process all the jobs in time $\\leq K$ using the above "bottleneck" model ?</p>\n\n<blockquote>\nHas this problem a name?<br>\nWhat is its complexity? (is it in $\\sf{P}$ or is it $\\sf{NP}$-complete?)\n</blockquote>\n\n<p><strong>UPDATE 29 March:</strong><br>\nAs correctly noticed by M.Cafaro in his answer, the problem is similar to the \n<em>Unconstrained Minimum Finish Time Problem (UMFT)</em> (see Chapter 17 of \n<a href="http://books.google.it/books?id=MAY1ZstmGPkC">Handbook of Scheduling Algorithms</a>) which is $\\sf{NP}$-hard (proved in\n W. Kern and W. Nawijn, "Scheduling multi-operation jobs with time lags on a single machine", University of Twente, 1993). As I can see, there are some differences because in my model:</p>\n\n<ul>\n<li>the pre/post processing time is constant (1 unit of time)</li>\n<li>as soon as the job is completed it must immediately be post-processed (the UMFT model allows delays)</li>\n</ul>\n\n<p>I didn\'t found the Kern &amp; Nawijn proof online, so I still don\'t know if the above restrictions change the difficulty of the problem.</p>\n\n<p>Finally you can think the whole process like a single <em>cook robot</em> with a big oven; the robot can prepare different types of foods one at a time (all require the same time of preparation), put them in the oven, and as soon as they are cooked it must remove them from the oven and add some cold ingredients ... the "<em>cook robot problem</em>" :-)</p>\n', 'Tags': '<complexity-theory><reference-request><scheduling>', 'LastEditorUserId': '140', 'LastActivityDate': '2013-06-21T18:54:32.070', 'CommentCount': '11', 'AcceptedAnswerId': '12822', 'CreationDate': '2013-03-28T11:49:30.607', 'Id': '10869'}{'Body': '<p>I have a problem similar to the interval scheduling algorithm. The differences are:</p>\n\n<ul>\n<li>The jobs have the same length.</li>\n<li>There are several categories of jobs and only one job from each category can be chosen.</li>\n<li>There can be no overlap in time between different categories.</li>\n</ul>\n\n<p>I have illustrated the problem with a picture:</p>\n\n<p>Each line is a job. Different color means that they belong to a different category. So I need to choose one of each colored line to try to cover as large an area as possible without any lines overlapping. Remember that lines with the same color should not be chosen twice. And yes, for the illustration the problem is trivial.</p>\n\n<p><img src="http://i.stack.imgur.com/fLk1Z.png" alt="enter image description here"></p>\n\n<p>Does my problem have a name? Does it require a DP algorithm?</p>\n', 'ViewCount': '98', 'Title': 'Variation of interval scheduling algorithm with several job categories, only one from each can be used', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-02T15:13:15.947', 'LastEditDate': '2013-04-02T15:13:15.947', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2826', 'Tags': '<algorithms><optimization><scheduling>', 'CreationDate': '2013-04-02T13:16:11.903', 'FavoriteCount': '2', 'Id': '10970'}{'Body': "<blockquote>\n  <p>Given a set of n jobs with [start time, end time, cost] find a subset so that no 2 jobs overlap and the cost is maximum.</p>\n</blockquote>\n\n<p>Now I'm not sure if a greedy algorithm will do the trick. That is, sort by cost and always take the next job that doesn't intersect and with max cost between the two.</p>\n\n<p>Is this equivalent to a knapsack problem? How could I approach it?</p>\n", 'ViewCount': '407', 'Title': 'Find non-overlapping scheduled jobs with maximum cost', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-16T17:54:04.300', 'LastEditDate': '2013-11-09T15:21:08.183', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7705', 'Tags': '<algorithms><scheduling><greedy-algorithms><knapsack-problems>', 'CreationDate': '2013-04-12T15:24:23.293', 'Id': '11265'}{'Body': '<p>As I understand the <em>convoy effect</em>, in the context of vehicular traffic in a road system. A slow moving group of vehicles passes through the system, slowing traffic even in areas which were not directly affected by the convoy.</p>\n\n<p>How does this apply in the context of CPU scheduling? It does not seem to be an analogous situation.</p>\n', 'ViewCount': '3155', 'Title': 'The convoy effect in process scheduling', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-16T09:18:33.377', 'LastEditDate': '2013-04-15T07:22:01.517', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7421', 'Tags': '<operating-systems><process-scheduling>', 'CreationDate': '2013-04-15T04:39:00.593', 'Id': '11325'}{'Body': '<p>Whats the diffrence between Disk scheduling and process scheduling? I mean i know the roles of disks and processes, but it seems to me they both have the same aim. to reduce monopolies, they even both share similar algorithms like first come first serve. Am i right?</p>\n', 'ViewCount': '814', 'Title': 'Disk scheduling and process scheduling', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-05-06T13:25:25.903', 'LastEditDate': '2013-05-06T11:59:45.810', 'AnswerCount': '2', 'CommentCount': '5', 'AcceptedAnswerId': '11827', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8054', 'Tags': '<operating-systems><process-scheduling>', 'CreationDate': '2013-05-06T06:38:57.250', 'Id': '11820'}{'Body': u'<p>We wish to manufacture n distinct hardware items. Each item needs to go through 3 stages of processing. The first stage called design can only be performed by our master designer who works by starting work on an item, designing it through to the end, and only then starting on another item. The remaining two phases, called assembly and testing, are outsourced and for each of them there is an infinite supply of people who can perform the corresponding task as soon as it is assigned to them. Naturally, each item first needs to be designed, then assembled, and then tested.</p>\n\n<p>Each item a requires d\u2090 hours of design, a\u2090 hours of assembly, and t\u2090 hours of testing. We are interested in determining the order in which we should design the items so that we minimize the time by which all items will be ready. For example, if we only had two pieces and we first designed item 1 and then designed item 2, the time by which both items would be finished is</p>\n\n<p>max{d\u2081 + a\u2081 + t\u2081, d\u2081 + d\u2082 + a\u2082 + t\u2082}.</p>\n\n<p>If, alternatively, we first design item 2 and then item 1, the time by which both items would</p>\n\n<p>be finished is</p>\n\n<p>max{d\u2082 + a\u2082 + t\u2082, d\u2082 + d\u2081 + a\u2081 + t\u2081}.</p>\n\n<p>Give a O(n log n) algorithm which takes as input n triples (d, a, t) and determines the optimal design order.</p>\n\n<p>Thanks for your help guys!</p>\n', 'ViewCount': '80', 'Title': 'Interval Scheduling Optimization type of Problem, optimal order of manufacture', 'LastActivityDate': '2013-05-07T06:43:02.403', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8075', 'Tags': '<algorithms><asymptotics><optimization><scheduling>', 'CreationDate': '2013-05-07T06:43:02.403', 'Id': '11847'}{'Body': '<p>I am trying to solve a problem of finding incompatible jobs set using greedy algorithm. However, I am not sure if greedy algorithm can solve this problem or I need to perform another approach.</p>\n\n<p>I have a set of jobs with start and finish time and I want to find the smallest subset of this jobs such that all the jobs are incompatible with at least one job of this subset.</p>\n\n<p>Suppose</p>\n\n<pre><code>job  start   end\n1    1       3\n2    2       11\n3    4       6\n4    7       8\n</code></pre>\n\n<p>My required job set J is {2} since  all the jobs are incompatible with at least one job of the job set J. I tried to use greedy algorithm like sorting jobs by start time, end time ( adding one  and removing all the ones incompatible and so on) But it is not optimal. As you can see in this example. If I add job 1 and then remove all the job incompatible with it, I will remove job 2, Then I will have to add 3 and 4 in the jobset J.</p>\n\n<p>Am I going the right way?</p>\n', 'ViewCount': '200', 'Title': 'Issues with using greedy algorithm (Interval scheduling variant)', 'LastEditorUserId': '8153', 'LastActivityDate': '2013-05-14T22:45:50.280', 'LastEditDate': '2013-05-14T14:31:20.733', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8153', 'Tags': '<algorithms><combinatorics><dynamic-programming><scheduling><greedy-algorithms>', 'CreationDate': '2013-05-14T04:16:16.893', 'Id': '12001'}{'Body': '<p>Can someone suggest an algorithm to solve job assignment problem with condition?</p>\n\n<p>With condition means that some jobs cannot be done by some workers. For example table as shown below:</p>\n\n<p><img src="http://i.stack.imgur.com/48Tqv.png" alt="enter image description here"></p>\n\n<p>In this table x - means that it is impossible to do. For example, worker 1 cannot do jobs 1,3 and 5.</p>\n\n<p>I encountered such situation and there may be cases as shown above when usual Hungarian algorithm seems cannot solve such task because there is no way to complete all tasks by distributing one task per worker. </p>\n\n<p>However, my main case it is allowed that one worker wil do several tasks (tasks, which worker can do). Main task is to complete all jobs using existing workers, but it is desirable that, all workers do roughly same number of tasks.</p>\n\n<p>So is there some solution of such problem? May be any algorithms do exist?</p>\n', 'ViewCount': '137', 'Title': 'Algorithm to solve job assignment problem', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-19T14:51:50.040', 'LastEditDate': '2013-05-19T14:51:50.040', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '5207', 'Tags': '<algorithms><optimization><linear-programming><scheduling><assignment-problem>', 'CreationDate': '2013-05-18T19:39:04.773', 'Id': '12122'}{'Body': "<p>The problem is a scheduling problem with n jobs and k machines. Each job i can be started at any time, but its duration is not exactly known except a time span interval. For example, a job may take anything from 5 mins to 10 mins. The list of jobs and their duration interval is given to the scheduler and the aim is to minimize the time all jobs would be finished. \nIn interval scheduling, the job start and end time is given and the length is fixed. Here, the job can start and end anytime (should be done in whole though) but its duration (length) is not exactly known.</p>\n\n<p>I searched the literature for this problem but couldn't find it. Is there any keywords I can use or any reference for this problem? Is it well-defined?</p>\n", 'ViewCount': '159', 'Title': 'A variant of job assignment (scheduling) problem with variable time span', 'LastActivityDate': '2013-08-02T19:50:55.893', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '8995', 'Tags': '<optimization><scheduling><process-scheduling><assignment-problem>', 'CreationDate': '2013-07-03T18:47:45.597', 'Id': '13066'}{'Body': "<p>I'm writing a program (using genetic algorithms) that finds sort-of-optimal scheduling plan for a factory.</p>\n\n<ul>\n<li>The factory has several types of machines (say, <code>locksmith, miller, welding</code>)</li>\n<li>There are few machines of each type. (say, <code>3 locksmiths, 2 millers, 3 welders</code>)</li>\n<li>There are several types of operations (some machines do more than one operation on the job, say, <code>locksmith does soldering and assembling</code>).</li>\n<li>The jobs on the machines have different times, all known beforehand.</li>\n<li>The jobs have dependencies on jobs done before (say, <code>a product's made of 10 screws and 4 subparts, each of which needs 4 screws</code>).</li>\n</ul>\n\n<p>From what I searched, this looks sort of like a Flow Shop problem. The difference is in the dependencies and in the same machine doing different operations with different times on a job.</p>\n\n<hr>\n\n<h2>My main question is:</h2>\n\n<p><strong>Is there some kind of a classification of these problems?</strong> A summary telling the differences?</p>\n\n<p>For example, I don't understand much of how do these differ: Open Shop, Job Shop, Flow Shop, Permutation Flow Shop. And whether or not I missed something similar that could fit better to my problem.</p>\n\n<hr>\n\n<p>As a side question, what approach do you think could help me best with the unusual requirements I've posted above? I'm writing my current approach below.</p>\n\n<p>So far I've been able to work with the tree of dependencies without regard to the makespan times: just making a plan - a list of IDs, really - of what comes after what, from looking at the tree of what's been done so far and what are the leaves (nodes having done all their dependencies).</p>\n\n<p>This allows for fast creation of meaningful individuals in the Genetic Algorithm population, but there seems to be no computationally cheap way to learn the individual's makespan time (which I have as the fitness function).</p>\n\n<p>For that I have to create a calendar, or Gantt chart, if you will, to which I put the operations on the jobs in the earliest place possible, in the machine queue that's free at that moment, etc. The whole plan has to materialize and that seems the most costly computation of the whole problem.</p>\n", 'ViewCount': '234', 'Title': 'Classification of job shop scheduling problems', 'LastActivityDate': '2013-07-23T01:50:49.417', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '13366', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '9122', 'Tags': '<optimization><scheduling><heuristics><genetic-algorithms>', 'CreationDate': '2013-07-11T03:03:06.187', 'Id': '13219'}{'Body': '<p>A team has decided that every morning someone should bring croissants for everybody. It shouldn\'t be the same person every time, so there should be a system to determine whose turn it is next. The purpose of this question is to determine an algorithm for deciding whose turn it will be to bring croissants tomorrow.</p>\n\n<p>Constraints, assumptions and objectives:</p>\n\n<ul>\n<li>Whose turn it is to bring croissants will be determined the previous afternoon.</li>\n<li>On any given day, some people are absent. The algorithm must pick someone who will be present on that day. Assume that all absences are known a day in advance, so the croissant buyer can be determined on the previous afternoon.</li>\n<li>Overall, most people are present on most days.</li>\n<li>In the interest of fairness, everyone should buy croissants as many times as the others. (Basically, assume that every team member has the same amount of money to spend on croissants.)</li>\n<li>It would be nice to have some element of randomness, or at least perceived randomness, in order to alleviate the boredom of a roster. This is not a hard constraint: it is more of an aesthetic judgement. However, the same person should not be picked twice in a row.</li>\n<li>The person who brings the croissants should know in advance. So if person P is to bring croissants on day D, then this fact should be determined on some previous day where person P is present. For example, if the croissant bringer is always determined the day before, then it should be one of the persons who are present the day before.</li>\n<li>The number of team members is small enough that storage and computing resources are effectively unlimited. For example the algorithm can rely on a complete history of who brought croissants when in the past. Up to a few minutes of computation on a fast PC every day would be ok.</li>\n</ul>\n\n<p>This is a model of a real world problem, so you are free to challenge or refine the assumptions if you think that they model the scenario better.</p>\n\n<p>Origin: <a href="http://stackoverflow.com/questions/17807531/find-out-whos-going-to-buy-the-croissants">Find out who\'s going to buy the croissants</a> by <a href="http://stackoverflow.com/users/851498/florian-margaine">Florian Margaine</a>. My reformulation here has slightly different requirements.</p>\n', 'ViewCount': '425', 'Title': 'Find out whose turn it is to buy the croissants', 'LastActivityDate': '2013-07-25T18:05:50.707', 'AnswerCount': '3', 'CommentCount': '4', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '39', 'Tags': '<algorithms><scheduling>', 'CreationDate': '2013-07-24T20:23:27.230', 'FavoriteCount': '1', 'Id': '13420'}{'Body': "<p>Here is a variation of a job-scheduling Problem.\nLet $J = \\{j_1,...j_n\\}$ be a set of Jobs for $1 \\leq i \\leq n$. Given Job length $|j_i|\\in \\mathbb{N}$, deadline $f_i \\in \\mathbb{N}$, profit $p_i \\ge 0$ and starting-time $s_i  \\in \\mathbb{N}$. I am looking for a greedy approximation factor given that the Job length may only be distinguished by factor k. </p>\n\n<p>$$max_i|j_i| \\leq k \\cdot min_i|j_i|$$</p>\n\n<p>The Greedy algorithm of this Problem is fairly stupid. Greedy takes a job with the biggest profit.  I created an example (3-Job-Scheduling):</p>\n\n<p>Let $J = \\{j_1,j_2,j_3\\}$ with $|j_1| = 2, j_2 = j_3 = 1$ and </p>\n\n<p>$s_1 = 0; s_2 = 0; s_3 = 1$,</p>\n\n<p>$f_1 = 2;f_2 = 1; f_3 = 2$</p>\n\n<p>$p_1 = w; p_2 = p_3 = (w-1)$</p>\n\n<p>What I want to show is that Greedy gives us w while 2(w-1) is the optimal solution. </p>\n\n<p>My question: Is this valid for n-Job-Scheduling (the general case). Is this the worst-case? </p>\n\n<p>I can't think of anything worse. So I figured since the problem is a k-Matroid (is this a common term?) there will be a an approximation factor $\\frac{1}{k-\\epsilon}$ for  any $\\epsilon &gt; 0.$ I know this is not exactly a proof yet, but am I on the right way?</p>\n\n<p>Thanks for your help!</p>\n", 'ViewCount': '118', 'Title': 'Single machine job scheduling (Greedy heuristic)', 'LastActivityDate': '2013-11-08T13:06:23.300', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10940', 'Tags': '<approximation><scheduling><greedy-algorithms><check-my-proof>', 'CreationDate': '2013-11-08T13:06:23.300', 'Id': '16821'}{'Body': "<p>An OS contains 10 identical processes that were initiated at the same time.Each process contains 15 identical requests. Each request consume 20 msec of CPU time.A request is followed by an I/O operation which consumes 10 msec.The CPU scheduling overhead is 2 msec. The system uses Round Robin scheduling with the time quantum of 10 msec.</p>\n\n<p>Q1) What is the response time of 1st request of last process ? \n  A) 210 msec  B) 140 msec  c) 230 msec  D) 240 msec</p>\n\n<p>Q2) The subsequent request of the processes receives a response times of \n A) 110 msec  B) 220 msec  C) 230 msec  D) 240 msec</p>\n\n<p>Ans: Q1) D</p>\n\n<pre><code> Q2) C\n</code></pre>\n\n<p>What I thought : </p>\n\n<p>For 1 process, there are 15 request so \n15 * ( 20 + 10) = 450 msec  But all answers are so small than this approach. So no need to think about further i.e. CPU overhead then 2nd...3rd...processes. </p>\n\n<p>Here my problem is I didn't get the concept behind this question properly. CPU overhead ( i.e context switching ) will take place between 10 processes or each process's 15 request.\nSo please tell how this scenario will work. </p>\n\n<p>I didn't get the meaning of 2nd question. </p>\n", 'ViewCount': '60', 'Title': 'processes response time confusion', 'LastEditorUserId': '9343', 'LastActivityDate': '2013-11-12T08:21:02.980', 'LastEditDate': '2013-11-12T05:00:57.927', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '9343', 'Tags': '<operating-systems><memory-management><process-scheduling><threads>', 'CreationDate': '2013-11-11T18:54:01.780', 'Id': '17919'}{'Body': "<p>I've been told it is possible to find a solution to this optimization problem in $\\Theta(n)$ but I still don't know how I could do it. I did find easily a solution in $n\\lg (n)$ though. I only need to have a VALID solution, not the optimal.</p>\n\n<p>This is the problem :</p>\n\n<p>Let say you have n tasks that have a start time and a max time. Each task takes 1 unit of time to complete. </p>\n\n<p>So for example :</p>\n\n<pre><code>T1 = 2,3\nT2 = 1,4\nT3 = 4,5\nT4 = 1,5\nT5 = 3,4\n</code></pre>\n\n<p>This means that T1 CAN be started at time 2 and must be done by time 3. So a correct solution could be : </p>\n\n<blockquote>\n  <p>T2, T1, T5, T3, T4</p>\n</blockquote>\n\n<p>Any idea on how I could create an algorithm in $\\Theta(n)$? For now I thought of using a sorting algorithm that does not use comparison but it only works with integer so I can't really get a reference to an object or something.</p>\n", 'ViewCount': '71', 'Title': 'Scheduling optimization problem in theta(n)', 'LastEditorUserId': '1636', 'LastActivityDate': '2013-11-22T20:47:50.657', 'LastEditDate': '2013-11-22T08:44:07.007', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11536', 'Tags': '<optimization><scheduling>', 'CreationDate': '2013-11-21T19:01:37.490', 'Id': '18233'}{'Body': '<p>What bad things can occur when the lengths of the time slices in a multitasking system are too small? What can happen when they are too big?  How should the length of the time slice be chosen?</p>\n', 'ViewCount': '114', 'Title': 'What happens when time slices are too short or too long?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-12-04T01:48:02.900', 'LastEditDate': '2013-12-04T01:48:02.900', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18576', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11723', 'Tags': '<operating-systems><process-scheduling>', 'CreationDate': '2013-12-01T01:14:30.103', 'Id': '18496'}{'ViewCount': '145', 'Title': 'Exponential averaging for SJF CPU scheduling', 'LastEditDate': '2014-01-24T18:48:46.530', 'AnswerCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '13062', 'FavoriteCount': '1', 'Body': '<blockquote>\n  <p>Calculate the exponential averaging with $T_1 = 10$, $\\alpha=0.5$ and the algorithm is SJF with previous runs as $8,7,4,16$.</p>\n  \n  <ol>\n  <li>9 </li>\n  <li>8 </li>\n  <li>7.5 </li>\n  <li>None</li>\n  </ol>\n</blockquote>\n\n<p>I am getting 4. None as the answer. </p>\n\n<p>But it is given that 3. 7.5 is the correct answer.\nI think I am missing something here.</p>\n\n<p>Because I only used the formula, $S_{n + 1}{}{}{}{} = a(T_n) + (1-a)*S_n$.</p>\n', 'Tags': '<operating-systems><process-scheduling>', 'LastEditorUserId': '13107', 'LastActivityDate': '2014-03-13T10:56:43.757', 'CommentCount': '5', 'AcceptedAnswerId': '19949', 'CreationDate': '2014-01-23T13:14:11.970', 'Id': '19911'}{'Body': '<p>I have been faced with a problem where three concurrent processes <strong>X</strong>, <strong>Y</strong> ,<strong>Z</strong> execute three different code segments that access and update certain shared variables. Before entering the respective code segments :</p>\n\n<ul>\n<li><p>Process X executes the P operation on semaphores a,b and c;</p></li>\n<li><p>Process Y executes the P operation on semaphores b,c and d;</p></li>\n<li><p>Process Z executes the P operation on semaphores c,d and a.</p></li>\n</ul>\n\n<p>After completing the execution of its code segment, each process invokes the V operation (i.e, signal) on its three semaphores. All semaphores are binary semaphores initialized to one. </p>\n\n<p>How do I recognise a deadlock-free order of invoking the P operations by the processes ? For illustration, the given examples are the following</p>\n\n<ol>\n<li>X: P(a)P(b)P(c) Y:P(b)P(c)P(d) Z:P(c)P(d)P(a)</li>\n<li>X: P(b)P(a)P(c) Y:P(b)P(c)P(d) Z:P(a)P(c)P(d)</li>\n<li>X: P(b)P(a)P(c) Y:P(c)P(b)P(d) Z:P(a)P(c)P(d)</li>\n<li>X: P(a)P(b)P(c) Y:P(c)P(b)P(d) Z:P(c)P(d)P(a)</li>\n</ol>\n', 'ViewCount': '45', 'Title': 'How to build/recognise a deadlock-free order of resources', 'LastEditorUserId': '13107', 'LastActivityDate': '2014-02-16T12:38:56.143', 'LastEditDate': '2014-02-15T16:47:27.490', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '21666', 'Score': '0', 'OwnerDisplayName': u'\u0110\u0113\u0113pak Sh\xe3rm\xe3', 'PostTypeId': '1', 'Tags': '<process-scheduling><deadlocks>', 'CreationDate': '2014-02-15T06:46:20.643', 'Id': '21665'}{'Body': "<p>I'm wondering which is a better scheduling algorithm to use. The only real difference I can see is that in FSCAN there are two queues, and when a scan begins all requests are put in one queue and the other left empty. Then during the scan the other queue is used to store new requests and deferred until all the old requests have been processed. </p>\n", 'ViewCount': '36', 'Title': 'Hard disk scheduling - N-set-SCAN vs FSCAN', 'LastActivityDate': '2014-03-10T18:16:46.670', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15503', 'Tags': '<scheduling>', 'CreationDate': '2014-03-10T17:04:25.327', 'Id': '22477'}{'Body': "<p>I'm reading up on network scheduling algorithms such as RED, ARED and WRED but I'm still not completely sure why networks need scheduling and these algorithms are necessary. </p>\n\n<p>Thanks!</p>\n", 'ViewCount': '49', 'Title': 'Why do networks need scheduling?', 'LastEditorUserId': '15503', 'LastActivityDate': '2014-03-12T12:39:32.913', 'LastEditDate': '2014-03-12T12:39:32.913', 'AnswerCount': '0', 'CommentCount': '3', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '15503', 'Tags': '<computer-networks><scheduling>', 'CreationDate': '2014-03-12T10:35:07.107', 'FavoriteCount': '1', 'Id': '22537'}