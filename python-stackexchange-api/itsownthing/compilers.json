{'ViewCount': '188', 'Title': 'Parsing arbitrary context-free grammars, mostly short snippets', 'LastEditDate': '2012-03-12T17:43:05.270', 'AnswerCount': '1', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '39', 'FavoriteCount': '2', 'Body': "<p>I want to parse user-defined domain specific languages. These languages are typically close to mathematical notations (I am not parsing a natural language). Users define their DSL in a BNF notation, like this:</p>\n\n<pre><code>expr ::= LiteralInteger\n       | ( expr )\n       | expr + expr\n       | expr * expr\n</code></pre>\n\n<p>Input like <code>1 + ( 2 * 3 )</code> must be accepted, while input like <code>1 +</code> must be rejected as incorrect, and input like <code>1 + 2 * 3</code> must be rejected as ambiguous.</p>\n\n<p>My parser must work on any context-free grammar, even ambiguous ones, and must accept all unambiguous input. I need the parse tree for all accepted input. For invalid or ambiguous input, I ideally want good error messages, but to start with I'll take what I can get.</p>\n\n<p>I will typically invoke the parser on relatively short inputs, with the occasional longer input. So the asymptotically faster algorithm may not be the best choice. I would like to optimize for a distribution of around 80% inputs less than 20 symbols long, 19% between 20 and 50 symbols, and 1% rare longer inputs. Speed for invalid inputs is not a major concern. Furthermore, I expect a modification of the DSL around every 1000 to 100000 inputs; I can spend a couple of seconds preprocessing my grammar, not a couple of minutes.</p>\n\n<p>What parsing algorithm(s) should I investigate, given my typical input sizes? Should error reporting be a factor in my selection, or should I concentrate on parsing unambiguous inputs and possibly run a completely separate, slower parser to provide error feedback?</p>\n", 'Tags': '<formal-languages><parsers><compilers>', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-24T01:22:22.403', 'CommentCount': '9', 'AcceptedAnswerId': '237', 'CreationDate': '2012-03-12T11:27:50.537', 'Id': '234''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>There's been a lot of hype about JIT compilers for languages like Java, Ruby, and Python. How are JIT compilers different from C/C++ compilers, and why are the compilers written for Java, Ruby or Python called JIT compilers, while C/C++ compilers are just called compilers?</p>\n", 'ViewCount': '703', 'Title': 'How is a JIT compiler different from an ordinary compiler?', 'LastActivityDate': '2013-03-21T22:33:35.770', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '262', 'Score': '14', 'PostTypeId': '1', 'OwnerUserId': '5', 'Tags': '<compilers>', 'CreationDate': '2012-03-12T22:44:53.997', 'FavoriteCount': '4', 'Id': '257''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p><em>Originally <a href="http://math.stackexchange.com/questions/22614/help-understand-texthandle-in-parsing-problem">http://math.stackexchange.com/questions/22614/help-understand-texthandle-in-parsing-problem</a> but unaswered there</em></p>\n\n<p>The BNF is defined as followed:</p>\n\n<pre><code>S -&gt; aAb | bBA \nA -&gt; ab | aAB\nB -&gt; bB | b\n</code></pre>\n\n<p>The sentence is:</p>\n\n<pre><code>aaAbBb\n</code></pre>\n\n<p>And this is the parse tree:\n<img src="http://i.stack.imgur.com/gpdeo.png" alt="enter image description here"></p>\n\n<p><strong>Phrases:</strong> aaAbBb, aAbB, bB<br>\n<strong>Simple Phrases:</strong> bB<br>\n<strong>Handle:</strong> ?    </p>\n\n<p>From the book, <code>handle</code> is defined as followed:\n<code>B</code> is the handle of the right sentential from $y = aBw$ if and only if:<br>\n$S \\to_{rm} \\cdot aAw \\to_{rm} aBw$</p>\n\n<p>So in my case, what\'s the handle? Any idea?  </p>\n', 'ViewCount': '213', 'Title': 'Understanding $\\text{handle}$ in parsing problem', 'LastEditorUserId': '98', 'LastActivityDate': '2012-06-29T12:53:46.907', 'LastEditDate': '2012-06-29T12:53:46.907', 'AnswerCount': '3', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '5', 'Tags': '<formal-languages><compilers><parsers>', 'CreationDate': '2012-03-13T06:36:58.727', 'Id': '290''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm working on a parser for a C-style language, and for that parser I need the regular expression that matches C-style /**/ comments. Now, I've found this expression on the web:</p>\n\n<pre><code>/\\*([^\\*]*\\*+[^\\*/])*([^\\*]*\\*+|[^\\*]*\\*/\n</code></pre>\n\n<p>However, as you can see, this is a rather messy expression, and I have no idea whether it actually matches exactly what I want it to match.</p>\n\n<p>Is there a different way of (rigorously) defining regular expressions that are easy to check by hand that they are really correct, and are then convertible ('compilable') to the above regular expression?</p>\n", 'ViewCount': '845', 'Title': 'Deriving the regular expression for C-style /**/ comments', 'LastEditorUserId': '95', 'LastActivityDate': '2013-03-20T16:37:17.823', 'LastEditDate': '2012-03-13T21:36:26.030', 'AnswerCount': '3', 'CommentCount': '5', 'AcceptedAnswerId': '312', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '92', 'Tags': '<compilers><parsers><regular-languages>', 'CreationDate': '2012-03-13T14:00:00.143', 'Id': '311''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>The following DFA is a lexical analyzer which is supposed to recognize comments. The lexical analyzer will ignore the comment and goes back to the state one. I\'m told that there\'s something wrong with it but I can\'t figure it out. What\'s the problem?</p>\n\n<p><img src="http://i.stack.imgur.com/EeIdO.png" alt="enter image description here"></p>\n\n<p>FWIW, those tiny signs are stars which are necessary for C-style comment: "/* comment */"<br>\n  The loop in the state three is "except *"</p>\n', 'ViewCount': '489', 'Title': 'A DFA for recognizing comments', 'LastEditorUserId': '41', 'LastActivityDate': '2014-01-21T22:54:19.720', 'LastEditDate': '2012-03-25T15:53:37.777', 'AnswerCount': '3', 'CommentCount': '2', 'AcceptedAnswerId': '398', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '51', 'Tags': '<formal-languages><automata><finite-automata><compilers>', 'CreationDate': '2012-03-14T22:46:16.420', 'Id': '396''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Let $\\Sigma$ be the set of terminal and $N$ the set of non-terminal symbols of some context-free grammar $G$.</p>\n\n<p>Say I have a string $a \\in (\\Sigma \\cup N)^+$ such that $x a y \\in \\mathcal{S}(G)$ where $x,y\\in (\\Sigma \\cup N)^*$ and $\\mathcal{S}(G)$ are the sentential forms of $G$.</p>\n\n<p>Given $G$, I'd like to determine a set $C = \\{ b \\mid wabz \\in \\mathcal{S}(G), b \\in \\Sigma \\cup N \\}$. </p>\n\n<p>To clarify, in this case, $w, x, y, z, a, b$ are strings of terminals and non-terminals and $b$ is of length one.</p>\n\n<p>I can see how to do this if $a$ is also of length one; each $b$ is a member of the follow set of $a$ (including non-terminals).</p>\n\n<p>However, I am curious if it's possible for a sequence of characters. For my application, the string $a$ is not much longer than the right hand side of the productions in $G$.</p>\n\n<p>The distinction between terminals and non-terminals is somewhat mute in my application because I am using a generative grammar; and I believe that this won't lead to much trouble since $b$ is of length one.</p>\n", 'ViewCount': '285', 'Title': 'Given a string and a CFG, what characters can follow the string (in the sentential forms of the CFG)?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-27T03:04:17.907', 'LastEditDate': '2012-03-27T03:04:17.907', 'AnswerCount': '1', 'CommentCount': '12', 'AcceptedAnswerId': '556', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '237', 'Tags': '<algorithms><context-free><formal-grammars><compilers>', 'CreationDate': '2012-03-20T22:55:17.150', 'Id': '555''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u"<p>I wonder if it is possible to build compilers for dynamic languages like Ruby to have similar and comparable performance to C/C++? From what I understand about compilers, take Ruby for instance, compiling Ruby code can't ever be efficient because the way Ruby handles reflection, features such as automatic type conversion from integer to big integer, and lack of static typing makes building an efficient compiler for Ruby extremely difficult.</p>\n\n<p>Is it possible to build a compiler that can compile Ruby or any other dynamic languages to a binary that performs very closely to C/C++? Is there a fundamental reason why JIT compilers, such as PyPy/Rubinius will eventually or will never match C/C++ in performance?</p>\n\n<p>Note: I do understand that \u201cperformance\u201d can be vague, so to clear that up, I meant, if you can do X in C/C++ with performance Y, can you do X in Ruby/Python with performance close to Y? Where X is everything from device drivers and OS code, to web applications.</p>\n", 'ViewCount': '3475', 'Title': 'Can a dynamic language like Ruby/Python reach C/C++ like performance?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-05-25T11:53:21.720', 'LastEditDate': '2012-03-29T00:16:48.180', 'AnswerCount': '9', 'CommentCount': '4', 'Score': '36', 'PostTypeId': '1', 'OwnerUserId': '124', 'Tags': '<programming-languages><compilers>', 'CreationDate': '2012-03-28T01:27:42.453', 'FavoriteCount': '15', 'Id': '842''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '730', 'Title': 'Why is using a lexer/parser on binary data so wrong?', 'LastEditDate': '2012-03-30T17:39:36.810', 'AnswerCount': '3', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '268', 'FavoriteCount': '0', 'Body': '<p>I often work with <a href="http://en.wikipedia.org/wiki/Lexical_analysis" rel="nofollow">lexer</a>/<a href="http://en.wikipedia.org/wiki/Parsing" rel="nofollow">parsers</a>, as opposed to a parser combinator and see people who never took a class in parsing, ask about parsing binary data. Typically the data is not only binary but also context sensitive. This basically leads to having only one type of token, a token for byte.  </p>\n\n<p>Can someone explain why parsing binary data with a lexer/parser is so wrong with enough clarity for a CS student who hasn\'t taken a parsing class, but with a footing on theory?</p>\n', 'Tags': '<programming-languages><compilers><parsers>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-04T18:24:18.923', 'CommentCount': '18', 'AcceptedAnswerId': '901', 'CreationDate': '2012-03-30T11:37:54.867', 'Id': '899''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '271', 'Title': 'From the LR(1) parsing table, can we deduce that it is also an LALR and SLR table?', 'LastEditDate': '2012-04-02T04:47:34.390', 'AnswerCount': '1', 'Score': '4', 'OwnerDisplayName': 'Jatin', 'PostTypeId': '1', 'OwnerUserId': '949', 'Body': '<p>There is this question I read somewhere but could not answer myself.</p>\n\n<p>Assume I have an LR(1) Parsing table. Is there any way that just by looking at it and its items, can I deduce that it is also a table for LALR and SLR?</p>\n', 'Tags': '<compilers><parsers>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-04-02T04:47:34.390', 'CommentCount': '2', 'AcceptedAnswerId': '940', 'CreationDate': '2012-04-01T05:39:31.193', 'Id': '938''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m studying Bootstrapping from Red Dragon Book Compilers and found the T diagram for cross compiler pretty confusing. I can\'t understand what is meant by "Run compiler1 through compiler2". Can anyone provide some better explanation, analogy or an example to relate with some real world compiler?</p>\n\n<p>Some notation first. By\n$LSN=$ <img src="http://i.stack.imgur.com/7G7ga.png" alt="enter image description here">\n I mean a compiler for language $L$\nwritten in language $S$ that produces output language/machine code $N$. \nThis is a <a href="http://en.wikipedia.org/wiki/Tombstone_diagram" rel="nofollow"><em>tombstone</em> or <em>T-diagrams</em></a>.</p>\n\n<blockquote>\n  <p><strong>Compiling a Compiler</strong></p>\n  \n  <ol>\n  <li><p>Suppose we have cross-compiler for a new language L \n     in implementation language S generating code for machine N.</p>\n  \n  <p>$LSN=$<br>\n  <img src="http://i.stack.imgur.com/xsc0T.png" alt="T-diagram for LSN"></p></li>\n  <li><p>Suppose we also have an existing S compiler running on machine M \n     implementing code for machine M:</p>\n  \n  <p>$SMM=$<br>\n  <img src="http://i.stack.imgur.com/UBlkh.png" alt="T-diagram for SMM"></p></li>\n  <li><p>Run LSN through SMM to produce LMN</p></li>\n  </ol>\n  \n  <p><strong>Compiler Construction</strong></p>\n  \n  <p>$LMN = LSN + SMM$<br>\n   <img src="http://i.stack.imgur.com/yFrsZ.png" alt="T-diagram for LMN = LSN + SMM"></p>\n</blockquote>\n', 'ViewCount': '1237', 'Title': "Cross Compiler's T diagram", 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-20T20:26:12.713', 'LastEditDate': '2012-04-22T15:57:57.733', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '8', 'OwnerDisplayName': 'Saurabh', 'PostTypeId': '1', 'Tags': '<compilers><terminology>', 'CreationDate': '2012-04-15T05:55:40.287', 'FavoriteCount': '1', 'Id': '1281''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I am currently learning assembly programming on wombat 4, I am looking at Frame pointers. I understand exactly what a frame pointer is: it is a register and are used to access parameters on a stack. But i'm confused on how they affect the program counter and why they are preferred over normal registers. </p>\n\n<p>Could some one explain, please.  </p>\n", 'ViewCount': '190', 'Title': 'Frame Pointers in Assembler', 'LastEditorUserId': '39', 'LastActivityDate': '2012-05-05T20:27:16.077', 'LastEditDate': '2012-05-05T20:27:16.077', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '1668', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1376', 'Tags': '<computer-architecture><compilers>', 'CreationDate': '2012-05-05T06:55:17.640', 'Id': '1665''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Here I\'m really interested in lowering barriers to mathematical education.</p>\n\n<p>Target:</p>\n\n<p>I\'d like to see created for the JavaScript community, an equivalent of the Python-based/linked <strong>scientific and high-performance computing</strong> libraries (great lists of which are available through <a href="http://sagemath.org/download-packages.html" rel="nofollow">Sage</a> and <a href="http://wiki.python.org/moin/NumericAndScientific" rel="nofollow">otherwise</a>). And I want that, because I\'d like to make it easy for people who learn JavaScript to get into scientific and numerical computing without having to learn Python (&amp; company). (I know it\'s easy to learn Python, as I basically did it at some point, but this suggests that perhaps it\'ll be easy to compile some restricted subset of JavaScript to Python.)</p>\n\n<p>Hypothesised method:</p>\n\n<p>I\'m primarily interested in a new language with minimal difference from JavaScript, because the market ("human compilers") I\'m targeting are programmers who already know JavaScript. What I want to target those people for, is to give them a minimally different language in which to write code that compiles to faster C, in the manner that RPython and Cython do for Python. I\'m willing to throw out a lot of JavaScript features, I just want to be careful to add a minimum number of features back in. I\'ll definitely be looking at Lua, Dart, ECMA Harmony (which has no formal date of release, or am I mistaken?), etc. as these are all close resemblances to contemporary (2012) implementations of JavaScript.</p>\n\n<p>Questionable Motivations:</p>\n\n<p>I\'m personally willing to learn any language/toolset that gets things done faster (I\'m learning Erlang myself, for this), but here, I am specifically interested in lowering the bar (sorry) for other people who may not have such willingness. This is just one of those "want to have my cake, and eat it too, so I am putting some time into researching the problem" situations. I have very limited prior experience in computer language design, but so far from a hacking-the-ecosystem point of view, the problem seems interesting enough to study, so, I hope to be doing more of that soon.</p>\n', 'ViewCount': '1892', 'Title': 'A faster, leaner JavaScript for scientific computing: what features should I keep?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-09-20T22:00:49.383', 'LastEditDate': '2012-09-02T14:22:18.533', 'AnswerCount': '3', 'CommentCount': '6', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1394', 'Tags': '<programming-languages><compilers><performance>', 'CreationDate': '2012-05-06T19:39:35.367', 'FavoriteCount': '2', 'Id': '1693''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Languages like Java, C#, Eiffel, and C++ have subtype hierarchies which are directed acyclic graphs, due to interfaces in Java and C# and multiple inheritance in Eiffel and C++. An obvious way to check whether type $A$ is a subtype of type $B$ is to traverse the graph of the subtype hierarchy starting at $A$ to see whether type $B$ appears 'above' it. This surely is not the most efficient way to implement subtype tests.</p>\n\n<blockquote>\n  <p>What techniques exist to efficiently implement subtype testing for modern OO languages?</p>\n</blockquote>\n\n<p>I'm interested in efficiency both in terms of time and memory and any trade-offs between the two.</p>\n", 'ViewCount': '142', 'Title': 'Efficient subtype testing', 'LastEditorUserId': '31', 'LastActivityDate': '2012-06-03T12:29:13.423', 'LastEditDate': '2012-06-02T14:51:02.927', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '31', 'Tags': '<programming-languages><compilers><typing>', 'CreationDate': '2012-06-02T11:00:24.770', 'FavoriteCount': '2', 'Id': '2198''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u"<p>In the following grammar that is used for math expressions(and other grammars) how do I know where should I place action symbols(@add, @mul, @pushID)? Is there a algorithm for it?</p>\n\n<pre>\nE -> TE`\nE'-> +T @add E'|\u03f5\nT -> FT`\nT'-> xF @mul T'|\u03f5\nF -> (E)|@pushID id\n</pre>\n\n<p>For example why @add is between <code>+T</code> and <code>E'</code> and not after <code>E'</code>?\nI searched for it's algorithm but didn't find anything useful.</p>\n", 'ViewCount': '81', 'Title': 'Where should we place action symbols in a grammar?', 'LastActivityDate': '2014-04-03T19:35:40.680', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1820', 'Tags': '<formal-grammars><compilers>', 'CreationDate': '2012-06-10T19:12:23.783', 'Id': '2321''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u'<p>I\u2019m working on a compiler for a concatenative language and would like to add type inference support. I understand Hindley\u2013Milner, but I\u2019ve been learning the type theory as I go, so I\u2019m unsure of how to adapt it. Is the following system sound and decidably inferable?</p>\n\n<p>A term is a literal, a composition of terms, a quotation of a term, or a primitive.</p>\n\n<p>$$ e ::= x \\:\\big|\\: e\\:e \\:\\big|\\: [e] \\:\\big|\\: \\dots $$</p>\n\n<p>All terms denote functions. For two functions $e_1$ and $e_2$, $e_1\\:e_2 = e_2 \\circ e_1$, that is, juxtaposition denotes reverse composition. Literals denote niladic functions.</p>\n\n<p>The terms other than composition have basic type rules:</p>\n\n<p>$$\n\\dfrac{}{x : \\iota}\\text{[Lit]} \\\\\n\\dfrac{\\Gamma\\vdash e : \\sigma}{\\Gamma\\vdash [e] : \\forall\\alpha.\\:\\alpha\\to\\sigma\\times\\alpha}\\text{[Quot]}, \\alpha \\text{ not free in } \\Gamma\n$$</p>\n\n<p>Notably absent are rules for application, since concatenative languages lack it.</p>\n\n<p>A type is either a literal, a type variable, or a function from stacks to stacks, where a stack is defined as a right-nested tuple. All functions are implicitly polymorphic with respect to the \u201crest of the stack\u201d.</p>\n\n<p>$$\n\\begin{aligned}\n\\tau &amp; ::= \\iota \\:\\big|\\: \\alpha \\:\\big|\\: \\rho\\to\\rho \\\\\n\\rho &amp; ::= () \\:\\big|\\: \\tau\\times\\rho \\\\\n\\sigma &amp; ::= \\tau \\:\\big|\\: \\forall\\alpha.\\:\\sigma\n\\end{aligned}\n$$</p>\n\n<p>This is the first thing that seems suspect, but I don\u2019t know exactly what\u2019s wrong with it.</p>\n\n<p>To help readability and cut down on parentheses, I\u2019ll assume that $a\\:b = b \\times (a)$ in type schemes. I\u2019ll also use a capital letter for a variable denoting a stack, rather than a single value.</p>\n\n<p>There are six primitives. The first five are pretty innocuous. <code>dup</code> takes the topmost value and produces two copies of it. <code>swap</code> changes the order of the top two values. <code>pop</code> discards the top value. <code>quote</code> takes a value and produces a quotation (function) that returns it. <code>apply</code> applies a quotation to the stack.</p>\n\n<p>$$\n\\begin{aligned}\n\\mathtt{dup} &amp; :: \\forall A b.\\: A\\:b \\to A\\:b\\:b \\\\\n\\mathtt{swap} &amp; :: \\forall A b c.\\: A\\:b\\:c \\to A\\:c\\:b \\\\\n\\mathtt{pop} &amp; :: \\forall A b.\\: A\\:b \\to A \\\\\n\\mathtt{quote} &amp; :: \\forall A b.\\: A\\:b \\to A\\:(\\forall C. C \\to C\\:b) \\\\\n\\mathtt{apply} &amp; :: \\forall A B.\\: A\\:(A \\to B) \\to B \\\\\n\\end{aligned}\n$$</p>\n\n<p>The last combinator, <code>compose</code>, ought to take two quotations and return the type of their concatenation, that is, $[e_1]\\:[e_2]\\:\\mathtt{compose} = [e_1\\:e_2]$. In the statically typed concatenative language <a href="http://www.cat-language.com/" rel="nofollow">Cat</a>, the type of <code>compose</code> is very straightforward.</p>\n\n<p>$$\n\\mathtt{compose} :: \\forall A B C D.\\: A\\:(B \\to C)\\:(C \\to D) \\to A\\:(B \\to D)\n$$</p>\n\n<p>However, this type is too restrictive: it requires that the production of the first function <em>exactly match</em> the consumption of the second. In reality, you have to assume distinct types, then unify them. But how would you write that type?</p>\n\n<p>$$ \\mathtt{compose} :: \\forall A B C D E. A\\:(B \\to C)\\:(D \\to E) \\to A \\dots $$</p>\n\n<p>If you let $\\setminus$ denote a <em>difference</em> of two types, then I <em>think</em> you can write the type of <code>compose</code> correctly.</p>\n\n<p>$$\n\\mathtt{compose} :: \\forall A B C D E.\\: A\\:(B \\to C)\\:(D \\to E) \\to A\\:((D \\setminus C)\\:B \\to ((C \\setminus D)\\:E))\n$$</p>\n\n<p>This is still relatively straightforward: <code>compose</code> takes a function $f_1 : B \\to C$ and one $f_2 : D \\to E$. Its result consumes $B$ atop the consumption of $f_2$ not produced by $f_1$, and produces $D$ atop the production of $f_1$ not consumed by $f_2$. This gives the rule for ordinary composition.</p>\n\n<p>$$\n\\dfrac{\\Gamma\\vdash e_1 : \\forall A B.\\: A \\to B \\quad \\Gamma\\vdash e_2 : \\forall C D. C \\to D}{\\Gamma\\vdash e_1 e_2 : ((C \\setminus B)\\:A \\to ((B \\setminus C)\\:D))}\\text{[Comp]}\n$$</p>\n\n<p>However, I don\u2019t know that this hypothetical $\\setminus$ actually corresponds to anything, and I\u2019ve been chasing it around in circles for long enough that I think I took a wrong turn. Could it be a simple difference of tuples?</p>\n\n<p>$$\n\\begin{align}\n\\forall A. () \\setminus A &amp; = () \\\\\n\\forall A. A \\setminus () &amp; = A \\\\\n\\forall A B C D. A B \\setminus C D &amp; = B \\setminus D \\textit{ iff } A = C \\\\\n\\text{otherwise} &amp; = \\textit{undefined}\n\\end{align}\n$$</p>\n\n<p>Is there something horribly broken about this that I\u2019m not seeing, or am I on something like the right track? (I\u2019ve probably quantified some of this stuff wrongly and would appreciate fixes in that area as well.)</p>\n', 'ViewCount': '240', 'Title': 'Type inference with product types', 'LastEditorUserId': '41', 'LastActivityDate': '2012-06-13T19:17:41.510', 'LastEditDate': '2012-06-12T18:08:36.097', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '2346', 'Score': '10', 'PostTypeId': '1', 'OwnerUserId': '1821', 'Tags': '<programming-languages><logic><compilers><type-theory><type-checking>', 'CreationDate': '2012-06-11T04:14:50.140', 'Id': '2326''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Is there any scientific work about deep copying? So far I have only found source codes (Java, Python, ...). However, there are various approaches and nobody seems to evaluate them.</p>\n\n<ul>\n<li>Reflection-based (Python)</li>\n<li>Auto-generated shallow-copy-based (Java)</li>\n<li>Compiler-generated polymorphic deep copy (anybody?)</li>\n</ul>\n\n<p>The last one seems to be the most efficient one, but I do not know if it is implemented anywhere.</p>\n', 'ViewCount': '442', 'Title': 'How to implement deep copy?', 'LastActivityDate': '2012-06-14T11:35:07.010', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '1857', 'Tags': '<programming-languages><compilers>', 'CreationDate': '2012-06-14T10:41:55.900', 'Id': '2370''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I had written a <a href="https://github.com/shabbyX/shCompiler" rel="nofollow">compiler compiler</a> a few years ago and I\'m now cleaning it up, improving it, and turning it into C.</p>\n\n<p>I came across a terminology problem however that I remember in the past I couldn\'t solve it either.</p>\n\n<p>Imagine an LL(k) stack. In this stack, you may have terminals, that are expected to be matched with the next token, or non-terminals that would expand based on the next token. In either case, there is a string in the stack.</p>\n\n<p>The word I am looking for, is a term that means either a terminal or non-terminal. <a href="http://en.wikipedia.org/wiki/Terminal_and_nonterminal_symbols" rel="nofollow">Wikipedia</a> was of no help.</p>\n\n<p>To clarify a bit more, imagine a grammar with $t = \\{a \\mid a \\text{ terminal}\\}$ and $T = \\{A \\mid A \\text{ non-terminal}\\}$. If you have a set $X = \\{x | x \\in t \\vee x \\in T\\}$, how would you refer to an element of $X$? "Grammar symbol"? "Grammar element"? "Terminal or non-terminal symbol"?</p>\n\n<p>I am in particular looking for a name as short and to the point as possible, since this will end up becoming a variable name!</p>\n', 'ViewCount': '153', 'Title': 'How to call something that can be either a terminal or a nonterminal?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-07-23T09:10:30.030', 'LastEditDate': '2012-07-23T09:06:22.513', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '2870', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '944', 'Tags': '<terminology><formal-grammars><compilers>', 'CreationDate': '2012-07-23T08:50:15.063', 'Id': '2868''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Repost from Stack Overflow:</p>\n\n<p>I'm going through past exams and keep coming across questions that I can't find an answer for in textbooks or on google, so any help would be much appreciated.</p>\n\n<p>The question I'm having problems with at the moment is as follows:  </p>\n\n<blockquote>\n  <p>Given a regular expression (a|bb)*, derive an estimate of the cost in time for \n  converting it to a corresponding NFA and a DFA. Your answer should refer to\n  the size of the regular expression.</p>\n</blockquote>\n\n<p>A similar question from another year is:</p>\n\n<blockquote>\n  <p>Given that, for the above example, you know the size of the original regular\n  expression, |r| and the size of the input string |x|, explain how you would calculate the cost in time for constructing and running the NFA versus constructing\n  and running an equivalent DFA.</p>\n</blockquote>\n\n<p>The resulting NFA for (a|bb)* has 9 states, while the DFA has 4. Even knowing this, I have no idea how to approach the question.</p>\n", 'ViewCount': '819', 'Title': 'Cost in time of constructing and running an NFA vs DFA for a given regex', 'LastActivityDate': '2012-08-09T21:15:55.073', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3094', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '2386', 'Tags': '<regular-languages><automata><finite-automata><compilers>', 'CreationDate': '2012-08-07T09:36:46.857', 'Id': '3071''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In Chapter 9 of the Dragon Book, the authors describe the dataflow framework for global analysis (described also in <a href="http://dragonbook.stanford.edu/lecture-notes/Stanford-CS243/l3-handout.pdf">these slides</a>).  In this framework, an analysis is defined by a set of transfer functions, along with a <a href="http://en.wikipedia.org/wiki/Semilattice">meet semilattice</a>.</p>\n\n<p>At each step of the iteration, the algorithm works by maintaining two values for each basic block: an IN set representing information known to be true on input to the basic block, and an OUT set representing information known to be true on output from the basic block.  The algorithm works as follows:</p>\n\n<ol>\n<li>Compute the meet of the OUT sets for all predecessors of the current basic block, and set that value as the IN set to the current basic block.</li>\n<li>Compute $f(IN)$ for the current basic block, where $f$ is a transfer function representing the effects of the basic block.  Then set OUT for this block equal to this value.</li>\n</ol>\n\n<p>I am confused about why this algorithm works by taking the meet of all the input blocks before applying the transfer function.  In some cases (non-distributive analyses), this causes a loss of precision.  Wouldn\'t it make more sense to apply the transfer function to each of the OUT values of the predecessors of the given block, then to meet all of those values together?  Or is this not sound?</p>\n\n<p>Thanks!</p>\n', 'ViewCount': '84', 'Title': 'Dataflow framework for global analysis: Why meet, then apply?', 'LastActivityDate': '2012-08-12T05:26:27.267', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3133', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2131', 'Tags': '<compilers><program-optimization>', 'CreationDate': '2012-08-08T17:40:34.587', 'Id': '3095''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am looking for answers which provide short overview of models and current state of research for <a href="http://en.wikipedia.org/wiki/Automatic_parallelization" rel="nofollow">auto-parallelisation</a> of sequential code.</p>\n', 'ViewCount': '105', 'Title': 'What are current approaches to auto-parallelisation?', 'LastEditorUserId': '472', 'LastActivityDate': '2012-10-18T05:21:42.593', 'LastEditDate': '2012-08-14T12:08:43.540', 'AnswerCount': '1', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '191', 'Tags': '<reference-request><compilers><parallel-computing><code-generation>', 'CreationDate': '2012-08-14T05:31:42.663', 'FavoriteCount': '2', 'Id': '3168''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<h3>Abstract problem description</h3>\n\n<p>The way I see it, unparsing means to create a token stream from an AST, which when parsed again produces an equal AST, i.e. <code>parse(unparse(AST)) = AST</code> should hold.  </p>\n\n<p>This is the equal to finding a valid parse tree which would produce the same AST. </p>\n\n<p>The language is described by a context free S-attributed grammar using a eBNF variant. </p>\n\n<p>So the unparser has to find a valid \'path\' through the traversed nodes in which all grammar constraints hold. This bascially means to find a valid allocation of AST nodes to grammar production rules. This is a constraint satisfaction problem (CSP) in general and could be solved, like parsing, by backtracking in $O(e^n)$. </p>\n\n<p>Fortunately for parsing, this can be done in $O(n^3)$ using GLR (or better restricting the grammar). Because the AST structure is so close to the grammar production rule structure, I was really surprised seeing an implementation where the runtime is worse than parsing: XText uses ANTLR for parsing and backtracking for unparsing. </p>\n\n<h3>Questions</h3>\n\n<ol>\n<li>Is a context free S-attribute grammar everything a parser and unparser need to share or are there further constraints, e.g. on the parsing technique / parser implementation?</li>\n<li>I\'ve got the feeling this problem isn\'t $O(e^n)$ in general -- could some genius help me with this?</li>\n</ol>\n\n<p>I didn\'t receive an answer for this question on <a href="http://stackoverflow.com/questions/11918961/unparse-ast-oexpn">StackOverflow</a>. It was suggested to ask here, but I hate redundancy, so I hope you forgive me for asking you to <a href="http://stackoverflow.com/questions/11918961/unparse-ast-oexpn">answer here</a>. </p>\n', 'ViewCount': '148', 'Title': 'Can abstract syntax trees be unparsed in subexponential time?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-12-24T19:05:30.280', 'LastEditDate': '2012-12-23T05:26:29.457', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '2465', 'Tags': '<algorithms><compilers><parsers>', 'CreationDate': '2012-08-16T21:52:15.340', 'FavoriteCount': '1', 'Id': '3233''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '114', 'Title': 'What is a malformed token?', 'LastEditDate': '2012-08-21T19:21:13.963', 'AnswerCount': '1', 'Score': '2', 'OwnerDisplayName': 'akh2103', 'PostTypeId': '1', 'OwnerUserId': '2605', 'Body': '<p>I am reading Programming Language Pragmatics by Michael Scott. He says that on a first pass, a compiler will break a program into a series of tokens. He says that it will check for malformed tokens, like 123abc or $@foo (in C). </p>\n\n<p>What is a malformed token? A variable that does not meet the rules of variable-naming? An operator that does not exist (ex. "&lt;-")?</p>\n\n<p>Is this analogous to a misspelled word?</p>\n', 'Tags': '<programming-languages><compilers>', 'LastEditorUserId': '472', 'LastActivityDate': '2012-08-21T19:51:02.953', 'CommentCount': '1', 'AcceptedAnswerId': '3279', 'CreationDate': '2012-08-21T15:13:34.463', 'Id': '3278''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u"<p>I got one grammar:</p>\n\n<pre><code>re2: re1 $\n\nre1: expr == expr | expr != expr | expr &lt; expr | expr &lt;= expr | expr &gt;= expr | expr &gt; expr | expr\n\nexpr: expr + term | expr - term | term\n\nterm: term * factor | term / factor | factor\n\nfactor: (expr) | num | id\n\nnum: (0|1|2|3|4|5|6|7|8|9)num | \u03b5\n\nid: (a|b|....|z|A|B|....|Z|)id | \u03b5\n\nHere are the FOLLOW sets:\n\nFOLLOW(r2) = {}\nFOLLOW(r1) = {$}\nFOLLOW(expr) = {=,!,&lt;,&gt;,+,-,)}\nFOLLOW(term) = FOLLOW(factor) = FOLLOW (id) = FOLLOW (num) = {=,!,&lt;,&gt;,+,-,),*,/}\n</code></pre>\n\n<p>Now this grammar clearly got reduce-reduce conflict from\nnum: \u03b5 and id: \u03b5 because FOLLOW(num) \u2229 FOLLOW(id) != empty set</p>\n\n<p>Now let's say I fix the grammar by  doing the following (I assume it is mistake in the grammar because (\u03b5 == \u03b5) makes no sense):</p>\n\n<pre><code>num: (0|1|2|3|4|5|6|7|8|9)num | (0|1|2|3|4|5|6|7|8|9)\nid: (a|b|....|z|A|B|....|Z|)id | (a|b|....|z|A|B|....|Z|) \n</code></pre>\n\n<p>Now my question is, is this grammar SLR i.e can it be parsed by SLR parser? I know by building the parser I can find out but on exam I can not make the whole parser and then determine (I would lose lot of time).</p>\n", 'ViewCount': '344', 'Title': 'Ambiguous grammar? Could the grammar be parsed by SLR parser?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-10-05T22:08:40.713', 'LastEditDate': '2012-08-25T04:03:25.147', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'OwnerDisplayName': 'user1377320', 'PostTypeId': '1', 'OwnerUserId': '2634', 'Tags': '<formal-languages><formal-grammars><compilers><parsing>', 'CreationDate': '2012-08-24T22:55:28.367', 'Id': '3325''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Is it possible to design a compiler which optimizes a loop in which arrays are accessed in alternate fashion? For example like this:</p>\n\n<pre><code>// int[] a,b\nint sum = 0;\nfor(int i = 0; i &lt; n; i++)\n{\n  sum += a[i] + b[i];\n}\n</code></pre>\n\n<p>With the usual sequential array storage, <code>a[i]</code> and <code>b[i]</code> may be far away from each other in memory. Therefore, I think a good compiler optimization would detect that <code>a[i]</code> and <code>b[i]</code> are always accesses at the "same" time, and store the arrays interleaved, that is <code>a[0] b[0] a[1] b[1] ...</code> so that one memory access may retrieve both <code>a[i]</code> and <code>b[i]</code>.</p>\n', 'ViewCount': '101', 'Title': 'Are compilers able to detect alternating accesses to arrays and interleave them in memory?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-05T19:48:04.607', 'LastEditDate': '2012-09-05T19:48:04.607', 'AnswerCount': '1', 'CommentCount': '6', 'AcceptedAnswerId': '3434', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><arrays><program-optimization><memory-management>', 'CreationDate': '2012-09-05T13:27:15.477', 'Id': '3433''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>We collect most of the information about possible compiler optimizations during forward pass. Is it possible to utilize the information collected in forward pass in a backward pass so as to perform better optimizations ?</p>\n\n<p>Note: I have been going through the patent <a href="http://www.google.com/patents/US7765534" rel="nofollow">Compiler with cache utilization optimizations</a> by Roch G. Archambault et al. (2004) and was wondering what kind of information might have been utilized in their backward pass.</p>\n', 'ViewCount': '71', 'Title': 'Benefit of Backward Pass at compile time', 'LastEditorUserId': '2741', 'LastActivityDate': '2012-09-06T23:36:56.983', 'LastEditDate': '2012-09-06T23:36:56.983', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '3452', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><program-optimization>', 'CreationDate': '2012-09-06T13:29:18.803', 'Id': '3449''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>How exactly <a href="http://en.wikipedia.org/wiki/Loop_dependence_analysis" rel="nofollow">Loop Dependence Analysis</a> helps in <a href="http://en.wikipedia.org/wiki/Vectorization_%28parallel_computing%29" rel="nofollow">vectorization</a> ? Are there any standard rules of safety criterias for parallizing such loops ?</p>\n', 'ViewCount': '71', 'Title': 'Using Loop Dependence analysis for vectorization', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-08T09:27:02.593', 'LastEditDate': '2012-09-07T07:27:34.463', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '3465', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '2741', 'Tags': '<compilers><parallel-computing><program-optimization>', 'CreationDate': '2012-09-07T00:25:42.440', 'Id': '3454''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have been reading about PHP and many authors mention semantic and logical errors separately. As an example of a semantic error, they give a function called with incorrect number of parameters: this will not be caught by the parser, but will throw an error when run.</p>\n\n<p>Yet in languages such as C++, this will be caught by the compiler. I would say that it\'s a syntax error then. What is the difference then between a semantic and a logical error?</p>\n\n<p>For example, in <a href="http://www.oopweb.com/Java/Documents/ThinkCSJav/Volume/chap01.htm" rel="nofollow">How to think like a computer scientist</a>, the author uses "logic error" and "semantic error" interchangeably. On the other hand, in the <a href="http://flylib.com/books/en/4.350.1.159/1/" rel="nofollow">Visual Basic .NET. Primer Plus</a>, "logic error" is separated from "semantic error".</p>\n', 'ViewCount': '519', 'Title': 'Can all languages have semantic and logical errors?', 'LastEditorUserId': '98', 'LastActivityDate': '2012-09-13T01:58:13.523', 'LastEditDate': '2012-09-12T22:52:42.637', 'AnswerCount': '3', 'CommentCount': '4', 'Score': '5', 'OwnerDisplayName': 'user970696', 'PostTypeId': '1', 'Tags': '<terminology><programming-languages><compilers><program-correctness>', 'CreationDate': '2012-08-31T09:12:57.057', 'FavoriteCount': '1', 'Id': '3519''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m being asked to create a "top down grammar" for a certain language (I\'m pretty sure there\'s no such thing as a "top down grammar" but I think it means write a grammar that an LL(k) parser can parse).</p>\n\n<p>I\'m pretty sure the language is not LL(1), but I can remove left-recursion and common prefixes from it and still have an unambiguous grammar. But I\'m a little confused about the significance of that. If I successfully removed left-recursion and common prefixes and the grammar is still unambiguous, is the language LL(k)? And does that mean it can be parsed by a top-down parser?</p>\n', 'ViewCount': '205', 'Title': 'Can an LL(k) parser parse any grammar without left recursion or common prefixes?', 'LastEditorUserId': '41', 'LastActivityDate': '2012-10-09T19:24:19.990', 'LastEditDate': '2012-10-09T03:45:47.377', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'OwnerDisplayName': 'Aurast', 'PostTypeId': '1', 'Tags': '<formal-languages><compilers><parsing>', 'CreationDate': '2012-09-18T15:04:43.747', 'Id': '4630''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '923', 'Title': 'Is there any way to distinguish between LL(k) and LR(k) grammar?', 'LastEditDate': '2012-10-05T19:53:15.253', 'AnswerCount': '2', 'Score': '8', 'OwnerDisplayName': 'Deb', 'PostTypeId': '1', 'OwnerUserId': '3075', 'FavoriteCount': '2', 'Body': '<p>I am recently studying about Compilers designing. I came to know about two types of grammar one is LL grammar and other is LR grammar.</p>\n\n<p>We also know the facts that every LL grammar is LR that is LL grammar is a proper subset of LR grammar. First one is used in top-down parsing and the second one is used in bottom-up parsing.  </p>\n\n<p>But is there any way to so that we can say that a given grammar is LL or LR?</p>\n', 'Tags': '<formal-grammars><compilers><parsing>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-10-06T03:43:28.817', 'CommentCount': '3', 'AcceptedAnswerId': '4897', 'CreationDate': '2012-10-05T14:27:41.813', 'Id': '4888''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I was studying operating system concepts from <a href="http://rads.stackoverflow.com/amzn/click/0471417432" rel="nofollow">Silberschatz, Galvin and Gagne\'s book</a> (sixth edition) and I have some questions about the flow of execution of a program. A figure explains the processing of the user program:</p>\n\n<p><img src="http://i.stack.imgur.com/we3Si.jpg" alt="program flow diagram"></p>\n\n<p>We get an executable binary file when we reach the <strong>linkage editor</strong> point. As the book says,</p>\n\n<blockquote>\n  <p>The program must be brought into memory and placed within a process for it to be executed.</p>\n</blockquote>\n\n<p>I have several questions about this flow:</p>\n\n<ol>\n<li><p>Before the program is loaded into the memory, the binary executable file generated by the linkage editor is stored in the hard disk. The address where the binary executable file is stored in the hard disk is the logical address as generated by the CPU ? </p></li>\n<li><p>If the previous answer is yes, Why CPU has to generate the logical address ? I mean the executable file is stored somewhere in the hard disk which pertains to an address, why does CPU has to separately do the stuff ? CPU\'s main aim is processing after all! </p></li>\n<li><p>Why does the executable file needs to be in the physical memory i.e ram and can not be executed in the hard disk? Is it due to speed issues ?</p></li>\n</ol>\n', 'ViewCount': '938', 'Title': 'Program compilation and execution flow', 'LastEditorUserId': '39', 'LastActivityDate': '2012-10-20T14:41:54.223', 'LastEditDate': '2012-10-20T14:41:54.223', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '6191', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4284', 'Tags': '<compilers><operating-systems><memory-management><virtual-memory>', 'CreationDate': '2012-10-20T07:24:13.227', 'Id': '6187''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Imagine two machines of different architecture which produce output of a standard format.</p>\n\n<p>If you have a program for one machine and can observe it's operation and output, what techniques exist to automatically produce an equivalent program for the alternate architecture?</p>\n\n<p>By equivalent I mean produces equal output (by some equality relation) for equivalent input.</p>\n", 'ViewCount': '74', 'Title': 'Instruction Translation', 'LastEditorUserId': '55', 'LastActivityDate': '2012-10-28T00:11:13.583', 'LastEditDate': '2012-10-28T00:11:13.583', 'AnswerCount': '1', 'CommentCount': '3', 'AcceptedAnswerId': '6287', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '4340', 'Tags': '<programming-languages><compilers>', 'CreationDate': '2012-10-24T10:23:49.107', 'Id': '6284''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Take a Turing machine, with a terminating program, convert it to some representation of the machine which captures, in a lossless manner, its state as it performs the computation.</p>\n\n<p>So you have a complete representation of the machine, the program, and its internal organisation as it performs the computation.</p>\n\n<p>I am going to suggest a graphical form, nodes and edges, names for nodes.</p>\n\n<p>Take a second Turing machine with a slightly different program. This program is identical save that it performs a single unit of function from the first program in a non optimal way, say it performs the single unit 3 times, changing some value to the correct output the first time, taking it to some second result the second time and then finally returning again to the correct first result. Like a reflection.</p>\n\n<p>Would it not be possible for some statistical technique to analyse the graph of the two machines including their process and find a compression of the graph of the second machine, which is smaller in terms of the size of the graph of its process and yet consistent with the mode of operation of the machine.</p>\n\n<p>For instance a graph matching algorithm could find that there is a subgraph match between one portion of the the process graph of the first machine and one part of the process graph of the second machine and replace the subgraph of the second machine with the subgraph of the process of the first machine.</p>\n\n<p>How it would then alter the program of the second machine to generate that altered graph I am unsure of.</p>\n\n<p>Do such techniques exist? Where would I find them, or is the analysis flawed or incomplete in some way which prevents its operation? What should I learn to understand its implementation or the truth of its deficiency?</p>\n', 'ViewCount': '104', 'Title': 'Is it possible to analyse computation?', 'LastEditorUserId': '39', 'LastActivityDate': '2012-11-02T21:06:44.393', 'LastEditDate': '2012-11-02T21:06:44.393', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4340', 'Tags': '<graphs><optimization><runtime-analysis><compilers><artificial-intelligence>', 'CreationDate': '2012-11-02T12:58:51.063', 'Id': '6452''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am having difficulty with one of the exercises in the <em>Dragon Book</em>:</p>\n\n<blockquote>\n  <p><strong>Exercise 2.4.1(c):</strong> Construct recursive-descent parsers, starting with\n  the following grammars:</p>\n  \n  <p>$$S \\rightarrow 0S1\\ |\\ 01$$</p>\n</blockquote>\n\n<p>Yet, for constructing a feasible parser, it is required that for two productions $A \\rightarrow \\alpha\\ |\\ \\beta$, their FIRST sets are disjoint. But since:</p>\n\n<blockquote>\n  <p>$$FIRST(0S1) = \\{ 0 \\} \\hspace{2em}\\&amp;\\hspace{2em} FIRST(01) = \\{ 0 \\}$$</p>\n</blockquote>\n\n<p>this is not the case. How does one proceed here? Just state it is not feasible due to the stated conflict or is there alternative approach, like modfying the grammar?</p>\n', 'ViewCount': '523', 'Title': 'Recursive-Descent Predictive Parser for $S \\rightarrow 0S1\\ |\\ 01$', 'LastEditorUserId': '4304', 'LastActivityDate': '2012-11-05T22:00:36.987', 'LastEditDate': '2012-11-05T01:53:06.597', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4459', 'Tags': '<context-free><compilers><parsers>', 'CreationDate': '2012-11-05T01:09:51.563', 'Id': '6479''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Lots of basic questions are there in my mind. I need to clear them.</p>\n\n<p><strong>Statement 1:</strong> A compiler converts a human-readable codes to object codes, and those are converted to a machine code (executable) by linker.</p>\n\n<p>Am I right here?</p>\n\n<p>At <a href="http://en.wikipedia.org/wiki/Object_file" rel="nofollow">wikipedia</a>, it is written that</p>\n\n<pre><code>Object files are produced by an assembler, compiler, or other language\ntranslator, and used as input to the linker.\n</code></pre>\n\n<p><strong>Question 1:</strong> An assembler converts assembly language code (<code>MOV A, B</code> <code>ADD C</code>) to machine code. In case of high-level language like C++, that is generated by linker above. So assembler is not used anywhere. So how can it create an object file as written above? </p>\n\n<p>Intermediate code is generated to make the code run on different architectures.</p>\n\n<p><strong>Question 2:</strong> Are *.class (bytecode) files created by java compiler object files? If yes, then can we say that the JVM that runs them is a type of linker (however its not creating the executable)?</p>\n\n<p><strong>Question 3:</strong> When we compile a C++ program in Turbo C++, we get *.obj files which are the object files. Can we use them to generate the executable in some other architecture?</p>\n', 'ViewCount': '132', 'Title': 'Some questions regarding compilers and assemblers', 'LastEditorUserId': '98', 'LastActivityDate': '2012-11-06T14:50:02.113', 'LastEditDate': '2012-11-06T11:15:57.493', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '6513', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4422', 'Tags': '<terminology><compilers><code-generation>', 'CreationDate': '2012-11-06T09:11:05.570', 'Id': '6506''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Is there any algorithm that tells us how to modify semantic actions associated with a left-recursive grammar? For example, we have the following grammar, and its associated semantic actions:</p>\n\n<p>$ S \\rightarrow id = expr $  { S.s = expr.size }</p>\n\n<p>S $\\rightarrow$ if expr then $S_1$ else $S_2$ { $S_1.t = S.t + 2; $\n$S_2.t = S.t + 2;$ $S.s = expr.size + S_1.size + S_2.size + 2;$ }</p>\n\n<p>S $\\rightarrow$ while expr do $S_1$ { $S_1.t = S.t + 4;$ $S.s = expr.size + S_1.s + 1;$ }</p>\n\n<p>S $\\rightarrow$ $S_1$ ; $S_2$  {$S_1.t = S_2.t = S.t;$ $S.s = S_1.s + S_2.s; $ }</p>\n\n<p>Clearly the non-recursive version of the grammer is:</p>\n\n<p>S $\\rightarrow$ id = expr T </p>\n\n<p>S $\\rightarrow$ if expr then $S_1$ else $S_2$ T</p>\n\n<p>S $\\rightarrow$ while expr do $S_1$ T</p>\n\n<p>T $\\rightarrow$ ; $S_2$ T</p>\n\n<p>T $\\rightarrow$ $\\epsilon$</p>\n\n<p>But we also need to change the semantic actions accordingly. Any ideas how this can be done?</p>\n', 'ViewCount': '78', 'Title': 'How to modify semantic actions when removing left-recursion from a grammer', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-23T17:17:48.393', 'LastEditDate': '2014-01-23T17:17:48.393', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '7739', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '2596', 'Tags': '<formal-grammars><compilers><semantics><left-recursion>', 'CreationDate': '2012-11-10T16:11:44.337', 'Id': '6604''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '1826', 'Title': 'How is this grammar LL(1)?', 'LastEditDate': '2012-11-19T18:22:36.037', 'AnswerCount': '3', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '135', 'FavoriteCount': '1', 'Body': '<p>This is a question from the Dragon Book. This is the grammar:</p>\n\n<blockquote>\n  <p>$S \\to  AaAb \\mid BbBa $<br>\n  $A \\to \\varepsilon$<br>\n  $B \\to \\varepsilon$  </p>\n</blockquote>\n\n<p>The question asks how to show that it is LL(1) but not SLR(1). </p>\n\n<p>To prove that it is LL(1), I tried constructing its parsing table, but I am getting multiple productions in a cell, which is contradiction.</p>\n\n<p>Please tell how is this LL(1), and how to prove it?</p>\n', 'Tags': '<formal-grammars><compilers><parsers>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-12-03T22:23:27.980', 'CommentCount': '2', 'AcceptedAnswerId': '6774', 'CreationDate': '2012-11-19T14:30:09.487', 'Id': '6768''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Many common operations are <a href="http://en.wikipedia.org/wiki/Monoid">monoids</a>. Haskell has leveraged this observation to make many higher-order functions more generic (<code>Foldable</code> being one example).</p>\n\n<p>There is one obvious way in which using monoids can be used to improve performance: the programmers is asserting the operation\'s associativity, and so operations can be parallelized. </p>\n\n<p>I\'m curious if there are any other ways a compiler could optimize the code, knowing that we\'re dealing with a monoid. </p>\n', 'ViewCount': '129', 'Title': 'Are monoids useful in optimization?', 'LastActivityDate': '2012-11-24T08:10:13.990', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '6860', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '1590', 'Tags': '<optimization><compilers><category-theory>', 'CreationDate': '2012-11-23T15:34:10.673', 'FavoriteCount': '2', 'Id': '6858''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm currently learning for an exam about compilers and found the following question:</p>\n\n<blockquote>\n  <p>(3 p.) <strong>Bootstrapping</strong>: Explain the concepts of <em>rehosting</em> and <em>retargeting</em>. Use T-diagrams.</p>\n</blockquote>\n\n<p>As far as I understand, rehosting means to compile a compiler for another platform (host), so it should look like this:</p>\n\n<pre><code>-------------\n| a       b |     --------------\n-----   -----     | a        b |\n    | c |-------------    ------\n    -----| c       x || x |\n         -----   ----------\n             | ? |\n             -----\n</code></pre>\n\n<p>Is this correct? And what does retargeting mean? </p>\n", 'ViewCount': '180', 'Title': 'How to explain rehosting and retargeting with T-diagrams?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-18T00:39:30.573', 'LastEditDate': '2014-01-17T23:01:54.847', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '5103', 'Tags': '<terminology><compilers>', 'CreationDate': '2012-12-17T20:15:02.770', 'Id': '7472''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '599', 'Title': 'What are handles in parsing?', 'LastEditDate': '2012-12-24T23:06:04.487', 'AnswerCount': '1', 'Score': '2', 'OwnerDisplayName': 'eshi14', 'PostTypeId': '1', 'OwnerUserId': '5245', 'Body': '<p>I have read a few algorithms for $LR(k)$ parser, in which there is a frequent mention of selecting a handle from the grammar given.\nFor example, one document said  - <em>"the essence of LR parsing is identifying the handle on top of stack"</em></p>\n\n<p>Please help me understand, what are handles in parsing?</p>\n', 'Tags': '<compilers><parsers>', 'LastEditorUserId': '3011', 'LastActivityDate': '2012-12-25T01:36:13.580', 'CommentCount': '0', 'AcceptedAnswerId': '7592', 'CreationDate': '2012-12-24T03:48:43.007', 'Id': '7587''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>There are three typical ways to allocate memory for programs: static, stack and dynamic heap. However, when I look at the implementation of <a href="http://en.wikipedia.org/wiki/Memory_management" rel="nofollow">dynamic heap memory allocation from wikipedia </a>, what I found is fixed block allocation, etc. So why is dynamic memory allocation called "heap" memory allocation? How does it have something to do with "heap"?</p>\n', 'ViewCount': '58', 'Title': 'How Does Dynamic Heap Storage Have Something to Do with Heap?', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-01-05T10:28:27.700', 'LastEditDate': '2013-01-05T10:13:06.000', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7783', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<programming-languages><compilers><operating-systems><memory-management><memory-allocation>', 'CreationDate': '2013-01-05T07:43:53.093', 'Id': '7776''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Have read in Compiler textbook that type inference is context sensitive. Can anyone explain why is it so? This means that we need context sensitive grammar in semantic analysis phase of a compiler with this feature? How is it done in popular programming languages like C?</p>\n', 'ViewCount': '104', 'Title': 'Type inference in compiler is context sensitive?', 'LastActivityDate': '2013-01-06T09:52:09.023', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '947', 'Tags': '<formal-languages><programming-languages><context-free><compilers><context-sensitive>', 'CreationDate': '2013-01-06T03:14:11.183', 'Id': '7796''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I took a course on compilers in my undergraduate studies in which we wrote a compiler that compiles source programs in a toy Java-like language to a toy assembly language (for which we had an interpreter). In the project we made some assumptions about the target machine closely related to "real" native executables, including:</p>\n\n<ul>\n<li>a run-time stack, tracked by a dedicated stack pointer ("SP") register</li>\n<li>a heap for dynamic object allocation, tracked by a dedicated heap pointer ("HP") register</li>\n<li>a dedicated program counter register ("PC")</li>\n<li>the target machine has 16 registers</li>\n<li>operations on data (as opposed to, e.g., jumps) are register-to-register operations</li>\n</ul>\n\n<p>When we got to the unit on using register allocation as an optimization, it made me wonder: What is the theoretical minimum number of registers for such a machine? You can see by our assumptions that we made use of five registers (SP, HP, PC, plus two for use as storage for binary operations) in our compiler. While optimizations like register allocation certainly can make use of <em>more</em> registers, is there a way to get by with fewer while still retaining structures like the stack and heap? I suppose with register addressing (register-to-register operations) we need <em>at least two</em> registers, but do we need more than two?</p>\n', 'ViewCount': '448', 'Title': 'Theoretical minimum number of registers for a modern computer?', 'LastActivityDate': '2013-12-11T00:06:01.113', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '5291', 'Tags': '<compilers><computer-architecture>', 'CreationDate': '2013-01-15T06:31:34.123', 'FavoriteCount': '1', 'Id': '8941''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '257', 'Title': 'How can SML infer types like this?', 'LastEditDate': '2013-02-02T13:58:58.873', 'AnswerCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '1590', 'FavoriteCount': '0', 'Body': '<p><a href="http://en.wikipedia.org/wiki/Standard_ML" rel="nofollow">Wikipedia says</a>:</p>\n\n<pre><code>fun factorial n = \n    if n = 0 then 1 else n * factorial (n-1) \n</code></pre>\n\n<blockquote>\n  <p>A Standard ML compiler is required to infer the static type int -> int of this function\n  without user-supplied type annotations. I.e., it has to deduce that n\n  is only used with integer expressions, and must therefore itself be an\n  integer, and that all value-producing expressions within the function\n  return integers.</p>\n</blockquote>\n\n<p>I don\'t understand how a compiler could infer this. It sounds like SML is essentially solving the halting problem for the <code>factorial</code> function, and showing that it only halts on positive integer inputs. </p>\n\n<p>Am I missing something?</p>\n', 'Tags': '<compilers><functional-programming><type-theory><type-inference>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-25T06:37:00.357', 'CommentCount': '0', 'AcceptedAnswerId': '9411', 'CreationDate': '2013-02-01T23:24:31.383', 'Id': '9407''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Theoretically speaking, is it possible to have a Lisp/Scheme compiler that can produce code that can compete with compiled C, let\'s say within 15-25% margin?</p>\n\n<p>In my testing, I\'ve found that the current crop of compilers (Bigloo, SBCL, Gambit, Chicken, etc) are <strong>20-50 times slower than equivalent C code</strong>.</p>\n\n<p>The <strong>only outlier is the Stalin compiler</strong>. For simple programs, it produces binaries that are equivalent to C. However, what I find suspicious is that none of the other projects (Bigloo, Chicken, Clozure, etc) have attempted to implement whatever tricks Stalin uses ("whole program optimization", etc).</p>\n\n<p>I\'m a huge fan of LISP since the mid 90s and would love to bring it on board so my team can crank out projects in half the time in normally takes using C/C++/.NET/etc, but...the performance issues are a huge roadblock.</p>\n\n<p>I wonder if the lack of quality LISP compilers are due to the fact that no serious time and money has been invested into the subject OR if this simply isn\'t a feasible task given the current state of compiler technology??</p>\n', 'ViewCount': '259', 'Title': 'Quality LISP/Scheme compilers to compete with C/C++', 'LastActivityDate': '2013-02-04T18:53:37.353', 'AnswerCount': '0', 'CommentCount': '8', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6703', 'Tags': '<optimization><compilers>', 'CreationDate': '2013-02-04T18:53:37.353', 'Id': '9483''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am taking the <a href="https://class.coursera.org/compilers-selfservice/class/index" rel="nofollow">Coursera class</a> on compilers and in the lesson about lexers it is hinted that there is a time-space tradeoff between using non-deterministic finite automaton (NFA) and deterministic finite automaton (DFA) to parse regular expressions. If I understand correctly, the tradeoff is that a NFA is smaller, but is more time consuming to traverse because all possible states have to be regarded at the same time and therefore it is most of the time transformed into a DFA.  Are there any lexers that use NFAs instead of DFAs in "real"-life i.e. some compiler that is used in production and not a just a proof of concept?</p>\n', 'ViewCount': '200', 'Title': 'Are there real lexers that use NFAs directly instead of first transforming them to DFAs?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-05T19:53:06.097', 'LastEditDate': '2013-04-02T07:28:48.933', 'AnswerCount': '4', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6843', 'Tags': '<automata><finite-automata><compilers><efficiency><nondeterminism>', 'CreationDate': '2013-02-12T17:55:33.023', 'Id': '9708''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I read about the time complexity for modular arithmetic in many books. There is one thing that I don't understand. I read in some books the following:</p>\n\n<p>For any $a \\mod N$, $a$ has a multiplicative inverse modulo $N$ if and only if it is relatively prime to $N$. When this inverse exists, it can be found in time $O(n^3)$ (where  $n$ denotes the number of bits in the binary representation of $N$) by running the extended Euclid algorithm. My question revolves around extended Euclid algorithm having $O(n^3)$ complexity.</p>\n\n<p>When I write in Java or C#, a line like this:</p>\n\n<pre><code>A = B.modInverse(N) // Java syntax\n</code></pre>\n\n<p>Can I usually say that this line has time complexity $O(n^3)$?\nOr is it necessary to write the code for the extended Euclid algorithm?</p>\n\n<p>Secondly, does extended Euclid algorithm depend on the compiler or the computer architecture?</p>\n", 'ViewCount': '43', 'Title': 'Time complexity for modular arithmatic', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-02-16T13:26:28.003', 'LastEditDate': '2013-02-16T13:26:28.003', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6898', 'Tags': '<time-complexity><compilers>', 'CreationDate': '2013-02-15T23:57:35.800', 'Id': '9821''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Suppose I have a script (<code>.vbs</code>, for example) that is stored in a file. How does the code in the file get converted into machine instructions?  What is between the vbs file and the processor?</p>\n', 'ViewCount': '313', 'Title': 'How does interpreting a script work?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-02-21T04:23:54.060', 'LastEditDate': '2013-02-20T00:04:22.767', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '9996', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6955', 'Tags': '<programming-languages><compilers><interpreters>', 'CreationDate': '2013-02-19T21:46:24.853', 'Id': '9945''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In compiler design, why should left recursion be eliminated in grammars? I am reading that it is because it can cause an infinite recursion, but is it not true for a right recursive grammar as well?</p>\n', 'ViewCount': '1414', 'Title': 'Why is left recursion bad?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-22T02:23:37.270', 'LastEditDate': '2014-01-23T17:17:55.627', 'AnswerCount': '2', 'CommentCount': '2', 'Score': '9', 'OwnerDisplayName': 'user56833', 'PostTypeId': '1', 'Tags': '<formal-grammars><compilers><left-recursion>', 'CreationDate': '2013-02-20T10:06:01.963', 'Id': '9963''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '227', 'Title': "How does 'deforestation' remove 'trees' from a program?", 'LastEditDate': '2013-02-27T11:38:07.923', 'AnswerCount': '3', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4602', 'FavoriteCount': '1', 'Body': '<p>I think understand how deforestation consumes and produces a list at the same time (from a fold and an unfold function -- <a href="http://codereview.stackexchange.com/questions/23180/how-to-make-this-python-function-and-its-inverse-more-beautiful-and-symmetric">see this good answer on CodeReview here</a>), but when I compared that with the <a href="https://en.wikipedia.org/wiki/Deforestation_%28computer_science%29" rel="nofollow">wikipedia entry on the technique</a> it talked about \'removing trees\' from a program. </p>\n\n<p>I understand how a program can be parsed into a syntactic parse tree (is that right?), but what is the meaning of this use of deforestation for some kind of simplification (is it?) of programs? And how would I do it to my code?</p>\n', 'Tags': '<terminology><compilers><functional-programming>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-01T19:46:29.167', 'CommentCount': '0', 'AcceptedAnswerId': '10154', 'CreationDate': '2013-02-26T22:53:06.540', 'Id': '10129''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In a comment to <a href="http://stackoverflow.com/q/12662896/1243762">Learning F#: What books using other programming languages can be translated to F# to learn functional concepts?</a> <a href="http://stackoverflow.com/users/2121246/makarius">Makarius</a> stated:</p>\n\n<blockquote>\n  <p>Note that the "CPS" approach has done great harm to performance in\n  SML/NJ. Its physical evaluation model violates too many assumptions\n  that are built into the hardware. If you take big symbolic\n  applications of SML like Isabelle/HOL, SML/NJ with CPS comes out\n  approx. 100 times slower than Poly/ML with its conventional stack.</p>\n</blockquote>\n\n<p>Can someone explain the reasons for this? (Preferably with some examples) Is there an impedance mismatch here?</p>\n', 'ViewCount': '159', 'Title': 'The "CPS" approach has done great harm to performance in SML/NJ; reasoning desired', 'LastEditorUserId': '39', 'LastActivityDate': '2013-03-03T20:52:58.603', 'LastEditDate': '2013-03-03T20:52:58.603', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10235', 'Score': '8', 'PostTypeId': '1', 'OwnerUserId': '268', 'Tags': '<compilers><functional-programming><proof-assistants><continuations>', 'CreationDate': '2013-03-03T15:49:23.960', 'Id': '10233''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '169', 'Title': 'Top Turing machine simulators on the web?', 'LastEditDate': '2013-03-09T02:47:07.830', 'AnswerCount': '3', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '699', 'FavoriteCount': '1', 'Body': '<p>There are many Turing machine simulators on the web of varying degrees of sophistication and can be highly useful for pedagogical purposes for students of widely varying ages, and they also have advanced theoretical value. </p>\n\n<p>What is a useful TM simulator available and what are its particular discriminating features that differ from other TM simulators available such that one would choose it and not another?</p>\n', 'ClosedDate': '2013-03-10T17:39:58.637', 'Tags': '<reference-request><turing-machines><compilers><education>', 'LastEditorUserId': '6447', 'LastActivityDate': '2013-03-09T02:47:07.830', 'CommentCount': '7', 'AcceptedAnswerId': '10383', 'CreationDate': '2013-03-08T03:32:19.103', 'Id': '10379''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '150', 'Title': 'Getting started with Program Analysis', 'LastEditDate': '2013-03-23T16:25:07.047', 'AnswerCount': '2', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '758', 'FavoriteCount': '0', 'Body': '<p>I\'m looking for resources on getting started with <a href="http://en.wikipedia.org/wiki/Program_analysis" rel="nofollow">program analysis</a>.</p>\n\n<p>The only book I\'ve found on the topic is the <a href="http://www.amazon.ca/Principles-Program-Analysis-Flemming-Nielson/dp/3540654100" rel="nofollow">Nielson &amp; Nielson</a> book.</p>\n\n<p>Other than that, it seems like there are only "compiler" books where "program analysis" would be a chapter, or something along those lines. </p>\n\n<p>Do people know of any other resources?</p>\n', 'Tags': '<reference-request><compilers><semantics>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-24T21:06:22.787', 'CommentCount': '2', 'AcceptedAnswerId': '10726', 'CreationDate': '2013-03-22T20:09:12.373', 'Id': '10696''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I have a compiler optimization which should be quite common, but I can not find a name for it, nor a reference that describes it. </p>\n\n<p>Given an integer x, not known at optimization time, a known constant c and the following program</p>\n\n<pre><code>x_1 = x * c\nx_2 = x_1 / c\nprint(x_2)\n</code></pre>\n\n<p>It's pretty clear that the code can be optimized to</p>\n\n<pre><code>print(x)\n</code></pre>\n\n<p>What is the name of this optimization? Is there a paper/book describing it?</p>\n\n<p>Thanks!</p>\n", 'ViewCount': '38', 'Title': 'What is the name of the optimization that removes self eliminating multiplication-division statements?', 'LastActivityDate': '2013-04-16T16:19:39.100', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '7752', 'Tags': '<optimization><compilers>', 'CreationDate': '2013-04-16T14:41:40.720', 'Id': '11356''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '312', 'Title': 'Does an abstract syntax tree have to be a tree?', 'LastEditDate': '2013-07-07T17:46:36.707', 'AnswerCount': '5', 'Score': '7', 'PostTypeId': '1', 'OwnerUserId': '9034', 'FavoriteCount': '1', 'Body': '<p>Does the output of a parser have to be a tree or could it also be general graph?</p>\n\n<p>Moreover, is there any existing language or a plausible one that uses general graphs representation instead of trees for their syntax?</p>\n', 'Tags': '<compilers><parsing>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-10T21:03:58.573', 'CommentCount': '1', 'AcceptedAnswerId': '13128', 'CreationDate': '2013-07-07T09:10:38.660', 'Id': '13126''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In Andrew W. Appel\'s book, <em>Modern Compiler Implementation in ML</em>, he says under chapter 17 that <em>Computability theory shows that it will always be possible to invent new optimizing transformations</em> and proceeds to prove that a <em>fully optimizing compiler</em> will solve the halting problem: A program <em>Q</em> that produces no output and never halts can easily be replaced by its optimal representation, <em>Opt(Q)</em>, being "L: goto L". So a fully optimizing compiler can solve the halting problem.</p>\n\n<p>So my question is this: <strong>Does a fully optimizing compiler exist for terminating programs?</strong> My only thoughts are the following: Even though a program is guaranteed to terminate, it can still be arbitrarily complex, and for any concrete optimizing compiler, C, one could perhaps construct a program that takes C as input and somehow produces a worse program as some kind of corner case.</p>\n\n<p>Also, <strong>What are the implications of restricting ourselves to terminating programs?</strong></p>\n', 'ViewCount': '185', 'Title': 'Do fully optimizing compilers for terminating programs exist?', 'LastEditorUserId': '9213', 'LastActivityDate': '2013-07-18T16:25:27.483', 'LastEditDate': '2013-07-18T16:25:27.483', 'AnswerCount': '1', 'CommentCount': '4', 'AcceptedAnswerId': '13315', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '9213', 'Tags': '<computability><compilers><program-optimization>', 'CreationDate': '2013-07-17T12:14:57.423', 'Id': '13313''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Now I am confused about symbolic execution (SE) and reachability analysis (RA). As I know, SE uses symbols to execute some code to reach each branch with branch conditions. And RA can be used to find the reachability of each branch, right? When RA is used, we can extract the branch condition for each branch. If so, what's the difference between them? Can they be swift? Are they all static analysis?</p>\n", 'ViewCount': '54', 'Title': 'Difference between symbolic execution and reachability analysis', 'LastEditorUserId': '98', 'LastActivityDate': '2013-07-30T10:30:32.577', 'LastEditDate': '2013-07-30T10:30:32.577', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '13497', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '9406', 'Tags': '<algorithm-analysis><compilers><program-optimization>', 'CreationDate': '2013-07-29T16:10:30.270', 'Id': '13492''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '128', 'Title': 'Getting started with Compiler Design', 'LastEditDate': '2013-08-07T07:34:30.817', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6466', 'FavoriteCount': '2', 'Body': '<p>This is the first time I will be studying compilers in depth. Can someone point me to best online resources (courses, articles, tutorials, video etc ) and books?   </p>\n\n<p>My main aim will be to do some practicals instead of just reading theory.-something where theory practical goes in parallel. So the reference must fulfill this expectations.</p>\n', 'ClosedDate': '2013-08-15T11:47:12.970', 'Tags': '<reference-request><compilers>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-07T07:34:30.817', 'CommentCount': '3', 'CreationDate': '2013-08-06T11:36:19.090', 'Id': '13630''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In his lecture <a href="http://cm.bell-labs.com/who/ken/trust.html" rel="nofollow"><em>Reflections on Trusting Trust</em></a>, Ken Thompson describes a virus that infects a compiler; the infected compiler installs backdoors into programs, but the key part is that the infected compiler also infects all compilers it compiles.</p>\n\n<p>K. Thompson notes that if this was implemented at the Microcode level, it would be almost impossible to stop.</p>\n\n<p>My question is this; in general terms (i.e. I\'m not going to ask for details on how to create the most insidious trojan that has ever existed) how can you write microcode that would inject Thompson\'s trojan into every program compiled on a computer with that microcode.</p>\n\n<p>As far as I can tell, the core of this question (i.e. the most important part, theoretically speaking) is:</p>\n\n<blockquote>\n  <p>Can the code implementing machine code (such as microcode) detect when the machine code it is implementing is a compiler that is compiling (in order to inject trojans into the compiled program), and if so, how?</p>\n</blockquote>\n', 'ViewCount': '105', 'Title': 'In general terms, how could the Thompson Hack be implemented in Microcode?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-25T12:44:17.090', 'LastEditDate': '2013-08-26T11:15:16.100', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '9797', 'Tags': '<computer-architecture><compilers><security>', 'CreationDate': '2013-08-23T10:26:52.827', 'Id': '13885''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Is there any difference between the two?  As per <a href="http://rads.stackoverflow.com/amzn/click/0321486811" rel="nofollow">Ullman\'s book</a>, compilers  convert one language to another (usually low level) language, and so does an assembler. How are the two different?     </p>\n', 'ViewCount': '945', 'Title': 'Is there any real difference between a compiler and an assembler?', 'LastEditorUserId': '903', 'LastActivityDate': '2013-08-28T18:41:50.163', 'LastEditDate': '2013-08-28T18:41:50.163', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '6', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<terminology><compilers>', 'CreationDate': '2013-08-24T12:43:06.587', 'Id': '13904''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am reading <a href="http://gnuu.org/2009/09/18/writing-your-own-toy-compiler/3/" rel="nofollow">this</a> article about compiler. I am facing some problem in understanding the content of the token file. Specifically, what is the meaning of the following lines: </p>\n\n<pre><code>    [ \\t\\n]                 ;\n    [a-zA-Z_][a-zA-Z0-9_]*  SAVE_TOKEN; return TIDENTIFIER;\n    [0-9]+\\.[0-9]*          SAVE_TOKEN; return TDOUBLE;\n    [0-9]+                  SAVE_TOKEN; return TINTEGER;\n</code></pre>\n\n<p>What is * and + at the end of the expressions ?</p>\n\n<p>Thanks in advance for explaining me.  </p>\n', 'ViewCount': '66', 'Title': 'Trying to understand a token file for lexical analysis', 'LastEditorUserId': '98', 'LastActivityDate': '2013-08-26T08:24:05.363', 'LastEditDate': '2013-08-26T08:06:35.300', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<terminology><formal-grammars><compilers>', 'CreationDate': '2013-08-24T14:25:23.360', 'Id': '13909''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>What exactly is the job of a syntax analyzer? Suppose I have a mathematical expression. Is it true that the order of execution of the operations is found with the help of syntax analyzer? </p>\n\n<p>Any example on exact jobs of Syntax Analyzer?     </p>\n', 'ViewCount': '174', 'Title': 'What is the job of Syntax Analyzer in Compiler?', 'LastActivityDate': '2013-12-20T04:45:32.487', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<compilers>', 'CreationDate': '2013-09-02T13:11:30.417', 'Id': '14083''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am writing a compiler for my programming language (both almost complete), but they are stuck in the, I would call, "String vs List-of-Char dilemma".\nMaybe some more experienced compiler programmer could help.</p>\n\n<p>It is a functional, strongly typed (with inference) and almost pure (immutable vars) language.\nAs I could perceive, using a list of chars is better for simplicity/generality of the language. But it adds complexity to the runtime/stdlib, because the user may require sometimes to print a List-of-Char as a text and sometimes as a list. </p>\n\n<p>Perhaps a built-in function just to print a List-of-Char as text would be a good compromise? I may be missing something here.</p>\n\n<p>In the other hand, defining a "String" type different from "List", requires duplicity of all list functions like "head", "tail", "replace" etc. to preserve the soundness and simplicity of the type system. It also requires duplicity from the user when implementing similar methods. </p>\n\n<p>Perhaps a built-in function just to convert a List-of-Char to String and vice-versa would be a good compromise? I may also be missing something here.</p>\n\n<p>obs.: The code is in github if anyone has interest into delving in the problem.</p>\n', 'ViewCount': '106', 'Title': 'Pros and cons of representing strings as lists of characters', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-17T11:58:29.307', 'LastEditDate': '2013-09-17T07:55:23.633', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8747', 'Tags': '<programming-languages><compilers><functional-programming>', 'CreationDate': '2013-09-16T18:29:52.983', 'FavoriteCount': '1', 'Id': '14360''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Assembly language is converted in to machine language by assembler. Why would a compiler convert high-level language to assembly? Can't it directly convert from the high-level language to machine code?</p>\n", 'ViewCount': '337', 'Title': 'Why do compilers produce assembly code?', 'LastEditorUserId': '39', 'LastActivityDate': '2014-01-30T20:01:50.190', 'LastEditDate': '2013-10-02T10:11:12.227', 'AnswerCount': '3', 'CommentCount': '0', 'AcceptedAnswerId': '14752', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10453', 'Tags': '<compilers><code-generation>', 'CreationDate': '2013-10-02T07:24:14.817', 'Id': '14749''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '88', 'Title': 'How are the web based compilers designed?', 'LastEditDate': '2013-10-14T13:52:24.180', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10700', 'FavoriteCount': '2', 'Body': '<p>Is it possible to design a compiler that can safely compile and run untrusted code?</p>\n\n<p>As a practical example, I want to know how the online compilers are designed/programmed?(Like the one on codepad.org) Are they similar to our traditional day-to-day compiler. How they are hosted on servers?</p>\n', 'ClosedDate': '2013-10-14T07:53:58.367', 'Tags': '<compilers>', 'LastEditorUserId': '2755', 'LastActivityDate': '2013-10-14T13:52:24.180', 'CommentCount': '3', 'AcceptedAnswerId': '16043', 'CreationDate': '2013-10-13T13:52:40.467', 'Id': '16037''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>Is it possible, given a declarative description of an architecture's register layout and instruction semantics and machine code encodings, to autogenerate a compiler back-end?</p>\n\n<p>If so, has anyone ever done this?</p>\n", 'ViewCount': '43', 'Title': 'Compiler backend generated from declarative description of the architecture', 'LastActivityDate': '2013-10-14T14:57:17.137', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10707', 'Tags': '<compilers>', 'CreationDate': '2013-10-13T23:47:18.770', 'FavoriteCount': '1', 'Id': '16058''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm a computer science student. I want to create my own programming language (A basic language with few instructions).</p>\n\n<p>I know how to do a syntactic analyser, I already did it in Perl. In an article, I read something about the compiler, a compiler is done in itself.</p>\n\n<p>For example the C compiler is written in C. How it's possible?\nI can make my own language but I don't know how I could execute it? Any idea?</p>\n\n<p>It's really a good question and I can write a blog the project.</p>\n", 'ViewCount': '269', 'Title': 'Compile a programming language with itself', 'LastEditorUserId': '3094', 'LastActivityDate': '2013-10-22T05:38:32.397', 'LastEditDate': '2013-10-20T08:17:22.657', 'AnswerCount': '3', 'CommentCount': '2', 'AcceptedAnswerId': '16323', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10871', 'Tags': '<programming-languages><compilers>', 'CreationDate': '2013-10-20T07:26:09.480', 'Id': '16248''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I think the Question is self sufficient. Is the syntax of C Language completely defined through Context Free Grammars or do we have Language Constructs which may require non-Context Free definitions in the course of parsing?</p>\n\n<p>An example of non CFL construct i thought was the declaration of variables before their use. But in Compilers(Aho Ullman Sethi), it is stated that the C Language does not distinguish between identifiers on the basis of their names. All the identifiers are tokenized as 'id' by the Lexical Analyzer. If C is not completely defined by CFGs, please can anyone give an example of Non CFL construct in C?</p>\n", 'ViewCount': '98', 'Title': 'Is the Syntax of C Language completely defined by CFGs?', 'LastEditorUserId': '39', 'LastActivityDate': '2014-03-24T14:18:04.997', 'LastEditDate': '2014-03-24T14:18:04.997', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '10717', 'Tags': '<context-free><programming-languages><compilers><parsing><c>', 'CreationDate': '2013-10-25T17:05:06.557', 'Id': '16426''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Say that you have a program with only total functions, or if that is impossible, consider a subset of the program with only total functions. Is it theoretically possible to statically determine the maximum size of the stack frame at runtime? The language may have other characteristics that are relevant/necessary (such as a specific type system).</p>\n', 'ViewCount': '43', 'Title': 'Say that a stack frame only contains total functions: could the maximum stack size be statically determined?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-02T09:40:56.593', 'LastEditDate': '2013-10-30T21:32:01.120', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '16593', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '11089', 'Tags': '<algorithm-analysis><compilers>', 'CreationDate': '2013-10-30T21:00:34.483', 'Id': '16592''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>In the <a href="https://class.coursera.org/compilers/lecture/index" rel="nofollow">compiler course by Alex Aiken on Coursera</a>, more specifically lecture <a href="https://class.coursera.org/compilers/lecture/20" rel="nofollow">05-02 Context Free Grammars</a>,  the professor says that CFGs give answers of the type yes/no, i.e. whether the given string of tokens is valid or not. He adds that it is also desirable to know <em>how</em> a particular string of tokens is in the language; for this purpose he introduces parse trees.</p>\n\n<p>Why is the "how" part important?      </p>\n', 'ViewCount': '328', 'Title': "What information do we get from a compiler's parse tree?", 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-03T09:22:35.317', 'LastEditDate': '2013-11-02T15:49:25.097', 'AnswerCount': '4', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '6466', 'Tags': '<context-free><compilers><parsers>', 'CreationDate': '2013-11-02T10:34:57.683', 'Id': '16647''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': u'<p>I am learning LR(1) parsing from the Dragon Book. I am really confused with this sentence.</p>\n\n<blockquote>\n  <p>Formally we say that a configuration $[A \\to u\u2022v, a]$ is valid for a viable prefix $\u03b1$ if  there is a rightmost derivation $S \\Rightarrow^* \u03b2Aw \\Rightarrow^* \u03b2uvw$ where $\u03b1 = \u03b2u$ and either $a$ is the first symbol of $w$ or $w$ is $\u2202$ and $a$ is $\\$$. </p>\n</blockquote>\n\n<p>I am not able to figure out how validation of a configuration for a viable prefix is <em>useful</em> . What does it speak <em>intutively</em> and why does it matters?</p>\n', 'ViewCount': '47', 'Title': u'what does \u201cConfiguration is valid for a viable prefix \u201d actually means?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-03T15:24:39.277', 'LastEditDate': '2013-11-03T15:24:39.277', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11151', 'Tags': '<terminology><compilers><parsers><parsing>', 'CreationDate': '2013-11-03T14:55:18.830', 'FavoriteCount': '1', 'Id': '16673''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I\'m both asking for me &amp; future readers as to how pictures, sounds, textures, assets, and such are compiled and linked in to one binary/program, and how that process works.</p>\n\n<p>I have seen this in standalone programs I have downloaded on Windows, and I\'m fairly certain any OS can implement this. It appears that, instead of keeping the data stored separately as individual files within the filesystem, all data is converged in to one file. When you run the program, it\'s as if the data could have just, instead of requiring multiple scattered files through the drive, directories, subdirectories, etc., been bound to one program with everything in it; no need for fragmentation, missing files, etc.</p>\n\n<p>So, to sum this question up, let me first illustrate some key points:</p>\n\n<p>I had originally thought that, <strong><em>since all files on the computer are basically high-and-low voltage sources at the lowest level</em></strong>, files can be converged together, being similar to <a href="http://en.wikipedia.org/wiki/Archive_file" rel="nofollow">"zipping/unzipping files."</a> Using this common ground, it\'s easy to see how the data of a file, <strong><em>any file</em></strong>, could be bound/binded together with other data, and act, from the scope of the filesystem and GUI, as "just a file." But many things are actually in it that don\'t have to only represent just a typical idea of a "program" with some people\'s view of it as only instructions like adding, moving data around, etc.</p>\n\n<p>I am not sure of this, but I have a good sense that it\'s similar, so this why I\'m asking for clarification.</p>\n\n<p>When you see a standalone program from one file that contains external assets when you run it (texture files, video data format, image data, sounds, other resources, etc.),  it\'s clear that the single executable file has all the data necessary "packed" in to one somehow, or the such.</p>\n\n<p>How does the compiler/linker do this, how would the program/library/etc. access the data converged in it as opposed to differing from separate "files" independently, and how are compiler\'s/linker\'s settings adjusted to do this in any general sense?</p>\n\n<p>NOTE: Programmers, StackOverflow, Superuser, and few others deny this question, and give no reason why, so I figured this area might see it fit.</p>\n', 'ViewCount': '52', 'Title': 'How are image files, sounds, data, etc. compiled/linked in to a single file?', 'LastEditorUserId': '268', 'LastActivityDate': '2013-12-27T00:44:21.287', 'LastEditDate': '2013-12-27T00:17:49.613', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12391', 'Tags': '<terminology><data-structures><compilers>', 'CreationDate': '2013-12-26T21:57:39.090', 'Id': '19313''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have two questions.  </p>\n\n<ol>\n<li><p>After compilation of any C program result is assembly language code which should depend on processor. So my question is: how do different computers with different processor types, for example Intel i3,i5,i7 etc., are able to run the same software, for example, media-player, browser, etc.?<br>\n(I guess strangely it depends on Operating System) and on that software site they do not ask for processor type.  </p></li>\n<li><p>Do programs interact with any part of operating system for conversion of assembly code to machine code?</p></li>\n</ol>\n', 'ViewCount': '97', 'Title': 'Confusion about compiler and assembler', 'LastEditorUserId': '268', 'LastActivityDate': '2014-01-02T22:38:51.200', 'LastEditDate': '2014-01-02T22:38:51.200', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10380', 'Tags': '<operating-systems><compilers>', 'CreationDate': '2014-01-02T18:37:50.257', 'Id': '19463''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I want know if compiler interacts with operating system during compilation process.And if yes then which part of compiler interacts with which part of operating system</p>\n', 'ViewCount': '50', 'ClosedDate': '2014-01-11T08:21:43.597', 'Title': 'compiler interaction with OS', 'LastActivityDate': '2014-01-03T18:01:11.237', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10380', 'Tags': '<operating-systems><compilers>', 'CreationDate': '2014-01-03T17:42:37.693', 'Id': '19490''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I understand the restrictions, because a regular language is expressive enough to allow all types of tokens. And even if some context is needed in many languages to tokenize properly, they all seem to be "approximately" regular languages.</p>\n\n<p>Yet I would be interested if any attempt in any programming language, possibly esoteric language, has been taken to completely eschew the conventional division between type-3 lexers and type-2 parser.</p>\n', 'ViewCount': '33', 'Title': 'Has there been a lexer that takes in much more than a regular language?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-20T14:35:25.787', 'LastEditDate': '2014-01-20T09:14:37.250', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4289', 'Tags': '<reference-request><regular-languages><compilers>', 'CreationDate': '2014-01-19T23:12:01.723', 'Id': '19837''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm following the algorithm for left recursion elimination from a grammar. It says remove the epsilon production if there is any.</p>\n\n<p>I have the grammar</p>\n\n<p>$\\qquad S \\to Aa \\mid b$<br>\n$\\qquad A \\to Ac \\mid Sd \\mid \\varepsilon$</p>\n\n<p>I can see after removing the epsilon productions the grammer becomes</p>\n\n<p>$\\qquad S \\to Aa \\mid a \\mid b$<br>\n$\\qquad A \\to Ac \\mid Sd \\mid c \\mid d$ </p>\n\n<p>I'm confused where the $a \\mid b$ for $S$ and $c \\mid d$ for $A$ come from.\nCan someone explain this?</p>\n", 'ViewCount': '38', 'Title': 'Eliminating $\\varepsilon$-productions during elimination of left recursion', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-23T20:51:58.290', 'LastEditDate': '2014-01-23T17:14:14.097', 'AnswerCount': '1', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '12993', 'Tags': '<context-free><formal-grammars><compilers><left-recursion>', 'CreationDate': '2014-01-23T15:28:15.480', 'Id': '19913''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '101', 'Title': 'Is this grammar LR(1)', 'LastEditDate': '2014-01-29T17:12:56.117', 'AnswerCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11750', 'FavoriteCount': '1', 'Body': "<p>I am reading parser chapter from dragon book and I found a grammar over there - </p>\n\n<p>$ S \\rightarrow L=R $</p>\n\n<p>$ S \\rightarrow R $</p>\n\n<p>$L \\rightarrow *R $</p>\n\n<p>$L \\rightarrow id $</p>\n\n<p>$R \\rightarrow L $</p>\n\n<p>Now I have created some of its items, not sure if they are correct - </p>\n\n<p>$ I_{0} $</p>\n\n<p>$S' \\rightarrow .S  ; \\$ $</p>\n\n<p>$S \\rightarrow .L=R ; \\$ $</p>\n\n<p>$S \\rightarrow .R ; \\$ $</p>\n\n<p>$ L \\rightarrow .*R; \\$/= $</p>\n\n<p>$ L \\rightarrow .id; \\$/= $</p>\n\n<p>$ R \\rightarrow .L; \\$ $</p>\n\n<p>$ I_{1} $</p>\n\n<p>$ S' \\rightarrow S.; \\$ $</p>\n\n<p>$ I_{2} $</p>\n\n<p>$S \\rightarrow L.=R ; \\$ $</p>\n\n<p>$ R \\rightarrow L.; \\$ $</p>\n\n<p>Now I2 contains Shift reduce conflict but the lookahead symbol that is appearing is creating doubt I mean how $ can be lookahead symbol to shift <code>=</code> sign? </p>\n", 'Tags': '<formal-grammars><compilers><parsers>', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-03T22:55:58.517', 'CommentCount': '0', 'AcceptedAnswerId': '20232', 'CreationDate': '2014-01-29T15:42:30.253', 'Id': '20068''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Im trying to draw an annotated parse tree for <code>3*5+4n</code>, the text book shows the following:</p>\n\n<p><img src="http://i.stack.imgur.com/TilDt.png" alt="enter image description here"><br>\n<sup>[<em>Compilers - Principles, techniques and tools (Dragon Book) by Aho, p308</em>]</sup></p>\n\n<p>I have a few questions regarding this</p>\n\n<ol>\n<li><p>Why is <code>3*5+4</code> considered as a single string? Can\'t I draw a parse tree something like \nfor the same string ie:with operator at the node <img src="http://i.stack.imgur.com/PRd1R.jpg" alt="enter image description here"> </p></li>\n<li><p>What is the need for giving <code>T.VAL=3</code> and then giving another child <code>F.VAL=3</code>. (I understand that the integer attribute for digit needs to be supplied by the lexical analyzer)</p></li>\n</ol>\n', 'ViewCount': '226', 'ClosedDate': '2014-02-03T00:27:50.477', 'Title': 'Drawing Annotated Parse Tree for Syntax Directed Definition', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-30T11:40:12.120', 'LastEditDate': '2014-01-30T11:13:37.357', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12993', 'Tags': '<formal-grammars><compilers><parsing><syntax-trees>', 'CreationDate': '2014-01-30T08:37:50.427', 'Id': '20098''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Considering programming languages with significant whitespace for indentation, such as Python or Haskell. How does this whitespace fit into the grand schemes of programming language grammars.</p>\n\n<p>I can see that a "preprocessor" can convert indent changes into tokens which are then handled in grammars, yet can one also perform the parsing based upon a single grammar without changing the intrinsic complexity of the 2nd grammer?</p>\n', 'ViewCount': '29', 'Title': 'Indentation based Grammars', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-01T15:40:14.350', 'LastEditDate': '2014-02-01T15:34:28.963', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '20188', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8028', 'Tags': '<formal-grammars><compilers><parsers>', 'CreationDate': '2014-02-01T10:34:48.470', 'Id': '20181''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Consider following grammar:</p>\n\n<p>$$X\\to Yc|ZY$$</p>\n\n<p>$$Y\\to ab|cX$$</p>\n\n<p>$$Z\\to d|\\epsilon$$</p>\n\n<p>Can this be converted to LL(1)?</p>\n\n<p>Cleary, its not LL(1) because of First/First conflict at first production. Can anyone suggest something to make it LL1?</p>\n', 'ViewCount': '67', 'Title': 'Is this grammar LL(1)?', 'LastEditorUserId': '14403', 'LastActivityDate': '2014-02-06T08:44:11.353', 'LastEditDate': '2014-02-05T19:50:39.943', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14403', 'Tags': '<formal-languages><formal-grammars><compilers>', 'CreationDate': '2014-02-05T10:30:12.203', 'Id': '21315''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I have dug in simple binaries, such as though like x86 bootloaders, sega video game binaries, etc. I know that these files tend to use assembler macros to define data, etc.\nWhat I am having trouble figuring out is what assemblers tend to translate macros into exactly (are they instructions, custom formatted data entries used statically, addressing mode/special opcodes, etc.).</p>\n\n<p>I do not know if this is the wrong place to ask. If so,  I am saving time by double-posting on reverse engineering 's SE.</p>\n", 'ViewCount': '33', 'ClosedDate': '2014-02-08T09:33:25.150', 'Title': 'What do assemblers translate macros into during assembling?', 'LastEditorUserId': '10867', 'LastActivityDate': '2014-02-06T20:59:06.310', 'LastEditDate': '2014-02-06T03:52:40.697', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14423', 'Tags': '<compilers>', 'CreationDate': '2014-02-06T01:18:00.843', 'Id': '21340''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I am learning Compiler Design. Can somebody explain what type of Grammar this is? The answer given is $LL(1)$ but there exists a left recursion in the grammar so it cannot be $LL(1)$. I derived the parse table it had conflicts. Am I doing some thing wrong or is the answer given wrong? </p>\n\n<p>My texbook defines:</p>\n\n<blockquote>\n  <p>For LL(1) Grammar if there is left recursion or left factoring then that grammar is not LL(1) grammar if this applies to this grammar then it is not a LL(1) grammar</p>\n</blockquote>\n\n<p>$E \\to E+T \\mid E$</p>\n\n<p>$T \\to T$#$F \\mid F$</p>\n\n<p>$F \\to (E) \\mid i$</p>\n\n<p>I also have one more question: "Is there a Grammar which can be LL(1) but not LALR(1)"</p>\n', 'ViewCount': '49', 'Title': 'Which Type of Grammar is this?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-11T22:46:43.857', 'LastEditDate': '2014-02-11T07:24:00.183', 'AnswerCount': '2', 'CommentCount': '1', 'AcceptedAnswerId': '21543', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14497', 'Tags': '<formal-grammars><compilers><parsing>', 'CreationDate': '2014-02-11T05:20:18.990', 'Id': '21520''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I'm reading the Dragon Book. The following is from the start of Section 3.1.3.</p>\n\n<blockquote>\n  <p>When more than one lexeme can match a pattern, the lexical analyzer must provide the subsequent compiler phases additional information about the particular lexeme that matched. For example, the pattern for token <strong>number</strong> matches both 0 and&nbsp;1, but it is extremely important for the code generator to know which lexeme was found in the source program. Thus, in many cases, the lexical analyzer returns to the parser not only a token name, but an attribute value that describes the lexeme represented by the token; the token name influences parsing decisions, while the attribute value influences translation of tokens after the parse.</p>\n</blockquote>\n\n<p>From what I understand the symbol table stores the variable name and the some details like the type, scope etc. So if a character <code>0</code> is found by the lexical analyzer, it matches the pattern for a number so it uses the token name <code>number</code> so the token becomes <code>&lt;number, attrb&gt;</code>.</p>\n\n<p>As per the snippet I have cited above, I don't understand what data is stored in the symbol table for numbers. Is the value of the number stored in the symbol table?</p>\n", 'ViewCount': '82', 'Title': 'What data is stored in the symbol table for a number token?', 'LastEditorUserId': '9550', 'LastActivityDate': '2014-04-01T23:12:43.733', 'LastEditDate': '2014-02-12T13:56:55.503', 'AnswerCount': '3', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12993', 'Tags': '<compilers><parsing>', 'CreationDate': '2014-02-12T06:38:52.730', 'Id': '21560''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>I've noticed that some languages include a logic engine as part of their type system (e.g. Shen, Typed Clojure).</p>\n\n<p>Other languages have a much more direct type checking algorithm (e.g. Haskell / Hindley-Milner).</p>\n\n<p>What specific features of a type system make it necessary to include a logic engine?</p>\n", 'ViewCount': '110', 'Title': 'When do type systems start needing a logic engine?', 'LastActivityDate': '2014-02-21T08:09:15.760', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '6771', 'Tags': '<programming-languages><compilers><type-theory>', 'CreationDate': '2014-02-21T07:23:09.553', 'FavoriteCount': '1', 'Id': '21879''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Can you tell me what mathematical background (concrete themes) should I have for studying and doing some investigations (in future) in programming languages, compilers and formal methods in software engineering? For instance, discrete mathematic course contains combinatorics, numbers theory, graphs and etc. But I think not all themes are needed to me at the first step. Can you highligh concrete themes of mathematics which are needed for programming languages, compilers and formal methods in software engineering? And may recommend some books and articles about this themes.</p>\n', 'ViewCount': '78', 'ClosedDate': '2014-02-24T16:41:24.710', 'Title': 'Mathematical background for programming languages, compilers and formal methods in software engineering', 'LastActivityDate': '2014-02-24T01:40:14.143', 'AnswerCount': '2', 'CommentCount': '2', 'AcceptedAnswerId': '21958', 'Score': '3', 'OwnerDisplayName': 'Igor B', 'PostTypeId': '1', 'OwnerUserId': '15301', 'Tags': '<programming-languages><compilers><formal-methods>', 'CreationDate': '2014-02-22T17:01:20.457', 'Id': '21956''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '2378', 'Title': 'Time complexity of a compiler', 'LastEditDate': '2014-03-10T02:40:09.983', 'AnswerCount': '5', 'Score': '32', 'PostTypeId': '1', 'OwnerUserId': '5373', 'FavoriteCount': '15', 'Body': '<p>I am interested in the time complexity of a compiler. Clearly this is a very complicated question as there are many compilers, compiler options and variables to consider. Specifically, I am interested in LLVM but would be interested in any thoughts people had or places to start research. A quite google seems to bring little to light.</p>\n\n<p>My guess would be that there are some optimisation steps which are exponential, but which have little impact on the actual time. Eg, exponential based on the number are arguments of a function.</p>\n\n<p>From the top of my head, I would say that generating the AST tree would be linear. IR generation would require stepping through the tree while looking up values in ever growing tables, so $O(n^2)$ or $O(n\\log n)$. Code generation and linking would be a similar type of operation. Therefore, my guess would be $O(n^2)$, if we removed exponentials of variables which do not realistically grow.</p>\n\n<p>I could be completely wrong though. Does anyone have any thoughts on it?</p>\n', 'Tags': '<compilers>', 'LastEditorUserId': '683', 'LastActivityDate': '2014-03-11T18:49:24.920', 'CommentCount': '9', 'AcceptedAnswerId': '22439', 'CreationDate': '2014-03-09T17:24:28.810', 'Id': '22435''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'ViewCount': '42', 'Title': 'Does the OS create its own bootstrapped stack frame when running a program?', 'LastEditDate': '2014-03-18T13:01:50.127', 'AnswerCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '13139', 'FavoriteCount': '1', 'Body': '<p>I\'ve been doing nand2tetris exercises and I\'m quite interested in how compilation actually works. In nand2tetris when creating the VM language I had to create a "bootstrap" which called the main method of the program.</p>\n\n<p>In other languages such as C, Java or even interpreted languages like PHP, does the OS/interpreter/VM automatically create its own first frame on the stack, and then invokes the main method of the program as a new second stack frame?</p>\n\n<p>I\'m trying to think about how initial arguments are passed to a program, and how programs are able to return values. Does each OS have a standard way of creating this initial stack frame which all languages adhere to? When I run a program from command prompt and pass it arguments, what is actually creating that initial stack frame that pushes these arguments onto the stack and that invokes my main method?</p>\n', 'Tags': '<operating-systems><compilers><stack>', 'LastEditorUserId': '31', 'LastActivityDate': '2014-03-18T23:08:51.803', 'CommentCount': '1', 'AcceptedAnswerId': '22773', 'CreationDate': '2014-03-18T12:20:06.083', 'Id': '22753''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>Is there a good general paper about the interpretation or compilation\nof REGEXP in programming languages for pattern matching, with or\nwithout variables? I am not looking for a quick explanation about the\nconstruction of DFAs, but for a real paper on how it is actually done\nin programming languages implementation, and what is considered simple\nor difficult. I expect differences between languages may have an\ninpact. A formal paper on how REGEXP implementation should be done is\nuseful too :-)</p>\n', 'ViewCount': '51', 'Title': 'How are REGEXP implemented in programming languages?', 'LastActivityDate': '2014-03-27T00:44:58.427', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '8321', 'Tags': '<programming-languages><compilers><regular-expressions><matching><interpreters>', 'CreationDate': '2014-03-26T17:01:44.683', 'Id': '23089''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': "<p>For example,</p>\n\n<p>Let the Grammar be:</p>\n\n<pre><code>S-&gt;Sa|B\n</code></pre>\n\n<p>Thus, <code>S-&gt;Sa-&gt;Saa-&gt;...-&gt;Saa...aaa-&gt;Baa...aaa</code></p>\n\n<p>What's wrong with this?</p>\n\n<p>Why is right recursion a solution to the problem?</p>\n\n<pre><code>S-&gt;BS'\nS-&gt;aS'|e\n</code></pre>\n", 'ViewCount': '35', 'ClosedDate': '2014-03-29T11:54:23.990', 'Title': 'Why does left recursion have to be eliminated?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-29T11:54:13.160', 'LastEditDate': '2014-03-29T11:54:13.160', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11684', 'Tags': '<context-free><formal-grammars><compilers><parsing><left-recursion>', 'CreationDate': '2014-03-29T05:06:57.450', 'Id': '23210''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I have an idea of how a C program is turned into machine code by the compiler. I also know how the processor processes the instructions (<a href="https://www.youtube.com/watch?v=cNN_tTXABUA" rel="nofollow">https://www.youtube.com/watch?v=cNN_tTXABUA</a> this video has a good introduction). But what I don\'t understand, is how an operating system (most times written in C or some low-level language) can run programs also in C (or other low-level language). I don\'t understand this. Does the OS read the code and then processes it with some internal functions, or does it only open the machine code and send it to the processor, that makes the rest? In case of the second option, how the OS take care of which instructions are allowed to be executed, and which are not? (example: I may write a program that has an instruction that jumps to a forbidden part of the memory RAM, how the OS protect it from happening?)</p>\n\n<p>I don\'t expect to understand it fully in this post\'s answers, but if you guys could give me an idea and then some books or tags to search, I\'d be happy!</p>\n', 'ViewCount': '105', 'Title': 'How does an operating system implement the C library?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-07T13:20:38.400', 'LastEditDate': '2014-04-07T08:55:08.267', 'AnswerCount': '2', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '16485', 'Tags': '<programming-languages><operating-systems><compilers>', 'CreationDate': '2014-04-05T23:59:07.507', 'Id': '23463''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>The algorithm that is used by gcc and llvm is that of <a href="http://www.cs.rice.edu/~keith/EMBED/dom.pdf" rel="nofollow">Keith D. Cooper, Timothy J. Harvey, and Ken Kennedy</a> (page 9).  We start with the <em>immediate dominators</em> of each control-flow graph node <code>B</code> already calculated and stored in <code>idom[B]</code>:</p>\n\n<pre><code>for each B in all basic blocks\n    if size of Predecessors(B) &gt;= 2\n        for each P in Predecessors(B)\n            runner = P\n            while runner != idom[B]    # idom is the immediate dominator\n                DF(runner) += B\n                runner = idom[runner]\n</code></pre>\n\n<p>My question is about the <code>Predecessors</code> set. Do they refer to the direct predecessors ("fathers") of <code>B</code> or to all of them that lead to <code>B</code>?</p>\n', 'ViewCount': '19', 'Title': 'Algorithm to find Dominance Frontiers', 'LastEditorUserId': '7459', 'LastActivityDate': '2014-04-25T17:34:24.953', 'LastEditDate': '2014-04-25T17:34:24.953', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '24113', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16367', 'Tags': '<compilers>', 'CreationDate': '2014-04-25T17:10:09.557', 'Id': '24112''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}{'Body': '<p>I know the definition of Bootstrapping, "developing a compiler in the target language it needs to compile". But what does this question mean? This was a question in my exam.</p>\n', 'ViewCount': '26', 'ClosedDate': '2014-05-01T12:15:39.560', 'Title': 'How Bootstrapping is done on more than one machine?', 'LastEditorUserId': '17240', 'LastActivityDate': '2014-05-02T10:09:10.797', 'LastEditDate': '2014-05-02T10:09:10.797', 'AnswerCount': '0', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17240', 'Tags': '<compilers>', 'CreationDate': '2014-05-01T07:42:26.507', 'Id': '24289''color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2}