{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Consider a fixed point representation which can be regarded as a degenerate case of a floating number. It is entirely possible to use 2's complement for negative numbers. But why is a sign bit necessary for floating point numbers, shouldn't mantissa bits be using 2's complements?</p>\n\n<p>Also why do the exponent bits use a bias instead of a signed-magnitude representation (similar to the mantissa bits) or 2's complement representation?</p>\n\n<p>Update: Sorry if I didn't make it clear. I was looking for the reason of how floating point representation is shaped. If there is no strong implementation trade-off between the alternatives, then could someone explain the historical aspects of the floating point representation?</p>\n", 'ViewCount': '730', 'Title': "Why floating point representation uses a sign bit instead of 2's complement to indicate negative numbers", 'LastEditorUserId': '4183', 'LastActivityDate': '2012-10-16T11:47:32.687', 'LastEditDate': '2012-10-16T10:23:11.770', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '4183', 'Tags': '<computer-architecture><floating-point><number-formats>', 'CreationDate': '2012-10-13T22:11:40.590', 'FavoriteCount': '1', 'Id': '6048'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been looking into the math behind converting from any base to any base. This is more about confirming my results than anything. I found what seems to be my answer on mathforum.org  but I'm still not sure if I have it right. I have the converting from a larger base to a smaller base down okay because it is simply take first digit multiply by base you want add next digit repeat. My problem comes when converting from a smaller base to a larger base. When doing this they talk about how you need to convert the larger base you want into the smaller base you have. An example would be going from base 4 to base 6 you need to convert the number 6 into base 4 getting 12. You then just do the same thing as you did when you were converting from large to small. The difficulty I have with this is it seems you need to know what one number is in the other base. So I would of needed to know what 6 is in base 4. This creates a big problem in my mind because then I would need a table. Does anyone know a way of doing this in a better fashion. </p>\n\n<p>I thought a base conversion would help but I can't find any that work. And from the site I found it seems to allow you to convert from base to base without going through base 10 but you first need to know how to convert the first number from base to base. That makes it kinda pointless.</p>\n\n<p>Commenters are saying I need to be able to convert a letter into a number. If so I already know that. That isn't my problem however.\nMy problem is in order to convert a big base to a small base I need to first convert the base number I have into the base number I want. In doing this I defeat the purpose because if I have the ability to convert these bases to other bases I've already solved my problem.</p>\n\n<p>Edit: I have figured out how to convert from bases less than or equal to 10 into other bases less than or equal to 10. I can also go from a base greater than 10 to any base that is 10 or less. The problem starts when converting from a base greater than 10 to another base greater than 10. Or going from a base smaller than 10 to a base greater than 10. I don't need code I just need the basic math behind it that can be applied to code.</p>\n", 'ViewCount': '3899', 'Title': 'The math behind converting from any base to any base without going through base 10?', 'LastEditorUserId': '6912', 'LastActivityDate': '2013-03-12T23:02:49.237', 'LastEditDate': '2013-03-12T21:18:02.180', 'AnswerCount': '4', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '6912', 'Tags': '<algorithms><arithmetic><number-formats>', 'CreationDate': '2013-03-06T14:17:37.380', 'FavoriteCount': '2', 'Id': '10318'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am asking this to advance the argument that BigDecimal is better than float or double for representing exact amounts of currency.  </p>\n\n<p>Can someone refer me to a proof that between any two integers there are only four values that multiples of .01 and can be exactly represented in base 2?  Or at least confirm I'm correct in my belief that it's true?</p>\n", 'ViewCount': '72', 'Title': 'Show that only a few multiples of .01 decimal are powers of 2', 'LastActivityDate': '2013-06-28T16:00:10.597', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '12954', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '8911', 'Tags': '<number-formats>', 'CreationDate': '2013-06-28T15:20:29.120', 'Id': '12952'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '216', 'Title': 'Confused by Floating Point Spacing', 'LastEditDate': '2013-09-17T12:06:36.347', 'AnswerCount': '1', 'Score': '5', 'OwnerDisplayName': 'Mike N.', 'PostTypeId': '1', 'OwnerUserId': '10176', 'Body': "<p>I'm currently taking a numerical analysis class in college and we're covering floating point systems. For the most part, I have a good grasp on it. However, something I can't seem to visualize, and haven't seen any totally lucid explanations about after searching extensively, is spacing between floating point numbers. Also of note is that I'm talking about IEEE-754 here, but it applies to general systems too.</p>\n\n<h3>The Things I Do Understand:</h3>\n\n<ul>\n<li>The area between $[-1,1]$ is a denormalized area.</li>\n<li>The areas after $1$ and less than $-1$ are where the normalized floating point numbers reside.</li>\n<li>The floating point numbers <em>between</em> perfect powers of the base are uniformly spaced, but the spacing varies from one perfect power of the base to another.</li>\n<li>The spacing between values between two perfect powers is proportional to the power on the left for positive numbers and the power on the right for negative numbers. (i.e. on a number line, the uniformly-spaced values between two low powers are closer together than between a higher power.)</li>\n</ul>\n\n<h3>What I'm Struggling to Understand</h3>\n\n<ul>\n<li><p>From my understanding, the machine epsilon $\\epsilon$ is a fundamental unit of spacing with respect to the floating point number line. That is, between $[1,B]$ where $B$ is the base, all values are $\\epsilon$ apart. Then, you can scale any arbitrary floating point number by that fundamental machine epsilon and that product is the uniform spacing for that floating point number's associated power range. Is this even a correct interpretation? </p>\n\n<p>I also read that $\\epsilon$ is an upper bound for relative error, so I'm not really sure how that fits into my explanation of it being an indivisible spacing unit.</p></li>\n<li><p>One of the questions I haven't been able to answer is what the minimum and maximum spacing between two positive floating point numbers is. I can trick myself into thinking I understand why multiplying the x's associated $B^e \\cdot \\epsilon$, where x is an arbitrary floating point number and $e$ is that number's corresponding exponent, yields the upper bound on error and therefore spacing, so $B^e \\cdot \\epsilon$ would be the maximum spacing. </p>\n\n<p>Minimum spacing truly boggles my mind right now, though. If the machine epsilon is the indivisible unit of spacing, then for example, how could we have more minimal spacing than between $1$ and $1 + \\epsilon$? Wouldn't that just be left to the rounding rule used (if round-to-nearest, it would depend whether the number is closer to $1$ or $1 + \\epsilon$, since it'll be rounded to one of those two).</p></li>\n</ul>\n\n<p>Basically, if you could explain this in plain-english it would really help me get a solid understanding of what's going on at the number line level.</p>\n", 'Tags': '<computer-architecture><floating-point><number-formats>', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-17T12:06:36.347', 'CommentCount': '0', 'AcceptedAnswerId': '14370', 'CreationDate': '2013-09-16T23:24:15.270', 'Id': '14369'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u'<p>From the <a href="http://en.wikipedia.org/wiki/IEEE_floating_point#Formats" rel="nofollow">Wikipedia page</a> on the IEEE Standard for Floating-Point Arithmetic,</p>\n\n<blockquote>\n  <p>The possible finite values that can be represented in a format are determined by the base (b), the number of digits in the significand (precision, p), and the exponent (<code>q</code>) parameter <code>emax</code>:</p>\n  \n  <p>...</p>\n  \n  <p>q must be an integer such that <code>1\u2212emax \u2264 q+p\u22121 \u2264 emax</code> (e.g., if p=7 and emax=96 then q is \u2212101 through 90).</p>\n</blockquote>\n\n<p>I can\'t figure out the reasoning behind the above inequality. I would\'ve thought (in my simplicity) that it would be <code>-emax \u2264 q \u2264 emax</code> or something similar. What am I missing?</p>\n', 'ViewCount': '18', 'Title': u'Floating point format: why must `1\u2212emax \u2264 q+p\u22121 \u2264 emax`?', 'LastActivityDate': '2014-02-22T22:03:28.200', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '14945', 'Tags': '<floating-point><number-formats>', 'CreationDate': '2014-02-22T21:34:16.677', 'Id': '21930'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>When using 2's complement with 4 bits, the largest positive int I can represent is 0111. The smallest negative one is 1000.</p>\n\n<p>The smallest int should intuitively be the negative of 0111 - 1 = 0110 since we can represent one more positive than negative int.</p>\n\n<p>If we invert the bits of 0110 and then add 1, however, we get 1010, which differs from 1000. What am I doing wrong?</p>\n", 'ViewCount': '20', 'Title': "Why do I not get the correct smallest possible value in 2's complement?", 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-15T11:30:43.303', 'LastEditDate': '2014-03-15T11:30:43.303', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '3003', 'Tags': '<encoding-scheme><number-formats>', 'CreationDate': '2014-03-15T08:47:24.770', 'Id': '22645'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>My lecturer told me that when I use an arithmetic I-Type command (ADDI,SUBI etc.) , the IMM field gets sign extended, and when I use a logic I-Type command (ORI,ANDI etc.) , the IMM field is just bits.</p>\n\n<p>He also said that if the IMM field contains a negative number, it is represented in 2's complement.</p>\n\n<p>Let's say I have a command, and two binary numbers X Y, so that X's 2's complement representation looks exactly like Y in regular representation.</p>\n\n<p>Note: X is negative and not the same as Y.</p>\n\n<p>Given a question in which I should say what is the value in the IMM field in an arithmetic I-Type command, how do I know if it's X or Y?</p>\n", 'ViewCount': '36', 'Title': 'MIPS: sign extend in I-Type commands', 'LastEditorUserId': '14724', 'LastActivityDate': '2014-03-17T16:02:14.063', 'LastEditDate': '2014-03-17T15:42:52.267', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '14724', 'Tags': '<computer-architecture><number-formats>', 'CreationDate': '2014-03-17T14:55:12.590', 'Id': '22712'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>It seems like it would be possible to add more precision to the IEEE 32-bit mantissa system if the leading zeroes were also dropped, just like the leading 1 is dropped due to it being implicitly known.</p>\n\n<p>For example, the number 17 would be represented as 0|10000100|00010000000000000000000. The leading 1 of the mantissa is always dropped, since every number in scientific notation starts with a 1. My question is why can't the leading zeroes also be dropped? If we know based on the exponent that the decimal place gets moved 4 spots, shouldn't we also be able to deduce, just like the implied 1, that all other missing bits afterwards would be 0? Granted, in this example it wouldn't make a difference, but for larger numbers, or numbers with a lot of digits past the decimal point, it seems like you would be able to get more precision the more implied bits you drop.</p>\n\n<p>(As I'm typing this, I'm also realizing that you might even be able to drop the next 1 in the mantissa. If the computer knows the number of places to move the exponent, you could have as many zeroes as you want sandwiched between two implied 1's)</p>\n\n<p>Does anyone know if this was ever addressed (or if I completely messed up in my calculations, and it isn't really possible to drop that many bits)?</p>\n", 'ViewCount': '30', 'Title': 'Can we improve the precision of IEEE floats by dropping leading zeros in the mantissa?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-02T21:47:54.493', 'LastEditDate': '2014-04-02T21:47:54.493', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23371', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '16394', 'Tags': '<floating-point><number-formats>', 'CreationDate': '2014-04-02T21:31:11.497', 'Id': '23370'}},