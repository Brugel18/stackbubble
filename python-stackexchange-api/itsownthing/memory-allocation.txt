{'ViewCount': '318', 'Title': 'Clever memory management with constant time operations?', 'LastEditDate': '2012-03-06T22:50:41.743', 'AnswerCount': '3', 'Score': '11', 'PostTypeId': '1', 'OwnerUserId': '68', 'FavoriteCount': '1', 'Body': u"<p>Let's consider a memory segment (whose size can grow or shrink, like a file, when needed) on which you can perform two basic memory allocation operations involving fixed size blocks:</p>\n\n<ul>\n<li>allocation of one block</li>\n<li>freeing a previously  allocated block which is not used anymore.</li>\n</ul>\n\n<p>Also, as a requirement, the memory management system is not allowed to move around currently allocated blocks: their index/address must remain unchanged.</p>\n\n<p>The most naive memory management algorithm would increment a global counter (with initial value 0) and use its new value as an address for the next allocation.\nHowever this will never allow to shorten the segment when only a few allocated blocks remain.</p>\n\n<p>Better approach: Keep the counter, but maintain a list of deallocated blocks (which can be done in constant time) and use it as a source for new allocations as long as it's not empty.</p>\n\n<p>What next? Is there something clever that can be done, still with constraints of constant time allocation and deallocation, that would keep the memory segment as short as possible?</p>\n\n<p>(A goal could be to track the currently non-allocated block with the smallest address, but it doesn't seem to be feasible in constant time\u2026)</p>\n", 'Tags': '<time-complexity><memory-allocation><operating-systems>', 'LastEditorUserId': '41', 'LastActivityDate': '2012-03-07T03:21:22.457', 'CommentCount': '9', 'AcceptedAnswerId': '69', 'CreationDate': '2012-03-06T21:46:27.713', 'Id': '27'}{'ViewCount': '2016', 'Title': 'Swap space management during pure demand paging', 'LastEditDate': '2012-05-29T08:49:23.003', 'AnswerCount': '1', 'Score': '8', 'OwnerDisplayName': 'shan23', 'PostTypeId': '1', 'OwnerUserId': '476', 'Body': '<p>The following is a doubt that I came across while doing a OS home assignment - however, it seems more concept-based than a straightforward coding question, so IMHO I don\'t think the homework tag is appropriate for this.</p>\n\n<p>In a pure demand paging scheme for multiple processes running at the same time, given a fixed amount of RAM and Swap memory, what happens in the following 2 cases w.r.t the swap space, when</p>\n\n<ol>\n<li><p>A process encounters a page-fault, and there are no free frames available in the RAM, hence requiring one of the pages from the process\' chunk of Kernel Frames to be written out to swap (for simplicity, I\'m not considering the copy-on-write case). Explicitly, where in the Swap space would this frame be written, and what data structures need to be updated for that?</p></li>\n<li><p>When a process needs to page-in a particular page, where does it look in the Swap memory, and how would it know if that particular page be present in Swap at all ?</p></li>\n</ol>\n\n<p>As you can well imagine, I\'m having difficulty understanding in what way to manage the Swap space during pure demand management scheme, and what data structures would be essential. It would be great if you could refer to any links in your answer (I searched in "Operating System Concepts - 8th edition by Silberschatz, I couldn\'t find an explicit answer for my question).</p>\n', 'Tags': '<operating-systems><memory-allocation><virtual-memory><paging><memory-management>', 'LastEditorUserId': '98', 'LastActivityDate': '2012-05-30T07:49:30.313', 'CommentCount': '1', 'AcceptedAnswerId': '2169', 'CreationDate': '2012-05-22T18:51:13.247', 'Id': '2154'}{'Body': '<p>So I have a problem understanding how the <a href="http://courses.cs.vt.edu/csonline/OS/Lessons/MemoryAllocation/index.html" rel="nofollow">worst-fit protocol for memory allocation</a> reacts to contiguous blocks of empty memory.  None of the examples I have found address this possibility.</p>\n\n<p>For example, say you have the following blocks (where \'O\' stands for occupied block and \'E\' stands for empty block) and are to allocate 10 MB via the worst-fit algorithm:</p>\n\n<pre><code>------------------------------------------------------------\n|10 MB O | 40 MB E | 10 MB O | 20 MB E | 30 MB E | 10 MB O |\n------------------------------------------------------------\n----0---------1---------2---------3---------4---------5-----\n</code></pre>\n\n<p>My question is does the worst-fit algorithm select block one leaving behind a 30 MB hole in block 1, or does it select block 3 leaving behind a cumulative 40 MB hole between blocks 3 and 4?     </p>\n', 'ViewCount': '1026', 'Title': 'How does worst-fit memory allocation react when encountering contiguous empty memory blocks?', 'LastEditorUserId': '29', 'LastActivityDate': '2014-03-23T07:51:23.327', 'LastEditDate': '2012-06-30T10:17:00.327', 'AnswerCount': '3', 'CommentCount': '2', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '603', 'Tags': '<algorithms><operating-systems><memory-allocation>', 'CreationDate': '2012-06-28T19:47:01.640', 'Id': '2536'}{'Body': '<p>Would someone please  clarify for me the difference between direct and random access?</p>\n\n<p>Specifically, why does this Wikipedia article on <a href="http://en.wikipedia.org/wiki/Direct_access_storage_device" rel="nofollow">Direct Access Storage Devices</a> distinguish between the two:</p>\n\n<blockquote>\n  <p>The direct access capability, occasionally and incorrectly called\n  random access  (although that term survives when referring to memory or RAM), </p>\n</blockquote>\n\n<p>whereas this article on <a href="http://en.wikipedia.org/wiki/Random_access" rel="nofollow">random access</a> doesn\'t:</p>\n\n<blockquote>\n  <p>In computer science, random access (sometimes called direct access) is\n  the ability to access an element at an arbitrary position in a\n  sequence in equal time, independent of sequence size.</p>\n</blockquote>\n', 'ViewCount': '1106', 'Title': 'Direct vs. Random Access', 'LastEditorUserId': '4304', 'LastActivityDate': '2012-11-08T09:20:31.897', 'LastEditDate': '2012-11-07T20:49:27.747', 'AnswerCount': '2', 'CommentCount': '1', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '4492', 'Tags': '<memory-allocation><access-control>', 'CreationDate': '2012-11-07T17:32:26.873', 'FavoriteCount': '1', 'Id': '6540'}{'Body': '<p>There are three typical ways to allocate memory for programs: static, stack and dynamic heap. However, when I look at the implementation of <a href="http://en.wikipedia.org/wiki/Memory_management" rel="nofollow">dynamic heap memory allocation from wikipedia </a>, what I found is fixed block allocation, etc. So why is dynamic memory allocation called "heap" memory allocation? How does it have something to do with "heap"?</p>\n', 'ViewCount': '58', 'Title': 'How Does Dynamic Heap Storage Have Something to Do with Heap?', 'LastEditorUserId': '3011', 'LastActivityDate': '2013-01-05T10:28:27.700', 'LastEditDate': '2013-01-05T10:13:06.000', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '7783', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '848', 'Tags': '<programming-languages><compilers><operating-systems><memory-management><memory-allocation>', 'CreationDate': '2013-01-05T07:43:53.093', 'Id': '7776'}{'Body': '<p>What is the difference between dynamic loading and dynamic linking?</p>\n\n<p>Both systems seem to allow shared libraries, but I am struggling to differentiate between them.</p>\n', 'ViewCount': '1362', 'Title': 'Dynamic loading vs. dynamic linking?', 'LastActivityDate': '2013-04-30T11:50:14.907', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '7421', 'Tags': '<memory-allocation><memory-access>', 'CreationDate': '2013-04-30T05:29:18.877', 'Id': '11668'}{'Body': '<p>I came accross the question regarding program overlays, \n<br><br>\n<code>Program1 is of 100kB and program2 is of 90kB and common code is 10kB and overlay driver is 20kB and error handling routine is 50kB, min memory required when there is no error?</code></p>\n\n<p>according to me it should be 100 + 20 + 10 = 130; as there is no error.. \n<br>but ans is 180; they are considering error handling routine also in account..</p>\n\n<p>I am not getting why error handling routine, if there is no error? </p>\n', 'ViewCount': '46', 'Title': 'In case of program overlays; is it necessary to have error handling routine in memory, regardless of error?', 'LastActivityDate': '2013-12-24T15:23:20.667', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '19249', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '12221', 'Tags': '<operating-systems><memory-management><virtual-memory><memory-allocation>', 'CreationDate': '2013-12-24T09:10:47.167', 'Id': '19235'}{'Body': '<p>How to know the size of page frame used by my OS ?</p>\n\n<p>This could be useful for some optimizations when I code. (Allocate big buffer that fit in a page frame for example).</p>\n\n<p>Page frame is determined by the operating system ? Mine is Windows 7 (but impossible to find information about it on Google. So, may be I wrong...)</p>\n', 'ViewCount': '10', 'ClosedDate': '2014-04-30T11:39:20.670', 'Title': 'How to know the size of page frame used by my OS?', 'LastActivityDate': '2014-04-30T09:04:45.557', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '17208', 'Tags': '<optimization><operating-systems><paging><virtual-memory><memory-allocation>', 'CreationDate': '2014-04-30T09:04:45.557', 'Id': '24253'}