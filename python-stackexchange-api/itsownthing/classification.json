{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am confused about the Vapnik-Chervonenkis dimension of a linear separator in 3 dimensions. </p>\n\n<p>In three dimensions, a linear separator would be a plane, and the classification model would be "everything on one side of a plane." </p>\n\n<p>It\'s apparently proved that the VC dimension of linear separators is d+1, so in 3D, its VC dimension is four. That means it should be able to put any set of 1, 2, 3, or 4 points on one side of a plane. </p>\n\n<p>But, what about this case: four coplanar points on a square with opposite corners same adjacent corners different?</p>\n\n<pre>\n+1    -1\n\n-1    +1\n</pre>\n\n<p>This is the case that a line (2-dimensional linear separator) cannot handle, but the 3-dimensional linear separator is supposed to be able to shatter this. But, I can\'t see how you could put two corners on "one side of a plane" because all four points are coplanar. </p>\n\n<p>Could someone explain how a 3-d linear separator can shatter the four points I just described? </p>\n', 'ViewCount': '90', 'Title': 'VC dimension of linear separator in 3D', 'LastEditorUserId': '98', 'LastActivityDate': '2013-04-25T07:43:51.953', 'LastEditDate': '2013-04-25T07:43:51.953', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '7884', 'Tags': '<statistics><learning-theory><vc-dimension><classification>', 'CreationDate': '2013-04-25T03:25:36.933', 'Id': '11548'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have recently been asked in an interview to devise an algorithm that divides a set of points in a coordinate system so that half of the points lie on one side of the line, and the rest on the other side.</p>\n\n<p>The points are unevenly placed and the line must not pass through any of the points.</p>\n\n<p>Can any one give any approach to solve the problem? Analysis of the algorithm is appreciated.</p>\n\n<p>Hints: Count the points, use medians.</p>\n\n<p>The number of points is assumed to be even.</p>\n', 'ViewCount': '168', 'Title': 'Algorithm to find a line that divides the number of points equally', 'LastEditorUserId': '98', 'LastActivityDate': '2013-05-19T14:54:52.617', 'LastEditDate': '2013-05-19T14:54:52.617', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '12114', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '6699', 'Tags': '<algorithms><machine-learning><computational-geometry><classification>', 'CreationDate': '2013-05-18T13:51:24.557', 'Id': '12111'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Should the independence assumption on which the Naive Bayes (NB) classifier is based, be taken into account when applying Expectation Maximization(EM) to infer missing values?</p>\n\n<p>The Naive Bayes classifier assumes that all attributes are independent given the class variable. \nNormally, the given structure of a Bayesian Network would be exploited by the EM algrithm. However, the NB classifier still performs well enough when the assumption is not met. So it is entirely plausible to have a dataset, in which the assumption does not (entirely) hold and to succesfully train a Naive Bayes classifier.</p>\n\n<p>I am inclined to disregard the independence assumption as it does not (neccesarily) stem from domain-knowledge, but is just a consequence of the simplifying assumptions inherent to Naive Bayes. Am i right in doing so? </p>\n', 'ViewCount': '27', 'Title': "Should Expectation Maximization take into account the Naive Bayes' independence assumption?", 'LastActivityDate': '2013-06-21T12:21:43.560', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '8515', 'Tags': '<probability-theory><classification>', 'CreationDate': '2013-06-21T12:21:43.560', 'Id': '12815'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'ViewCount': '114', 'Title': 'A text-classifier that explains its decisions', 'LastEditDate': '2013-12-15T15:11:45.857', 'AnswerCount': '2', 'Score': '9', 'PostTypeId': '1', 'OwnerUserId': '1342', 'FavoriteCount': '1', 'Body': '<p>I am building a text categorizer for short sentences. In addition to telling the  user "the category of the text you entered is C", I want to be able to explain why I made this decision, in a short and understandable way. For example, I don\'t want to tell the user "I put your sentence into a complex 3-layered neural network and that\'s the answer that scored the best"; I want explanations such as "Your sentence contains the words U, V and W, that are characteristic of this category, because of sentences such as X, Y and Z that appeared in the training data".</p>\n\n<p>My question is: what classification algorithms are best suited for such application?</p>\n\n<p>k-nearest-neighbours seems like a good candidate, because I can tell the user "Your sentence has category C because it is similar to sentences X, Y and Z that have the same category. But its performance on text categorization problems is known to be poor. I am looking for a classifie that balances performance with explanation ability.</p>\n\n<p>EDIT: After spending a lot of time looking for such a classifier, I started to build a machine-learning library called <a href="https://github.com/erelsgl/limdu" rel="nofollow">limdu</a>, that allows the classifiers to explain their decisions. It is still under development, but, it has already helped me explain to myself and my colleagues why our classifiers fail so often...</p>\n', 'Tags': '<machine-learning><classification>', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-12-15T15:11:45.857', 'CommentCount': '2', 'AcceptedAnswerId': '12966', 'CreationDate': '2013-06-28T12:45:51.443', 'Id': '12950'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I am building a classifier for short texts in a chat system. My features are words and pairs of words.</p>\n\n<p>Naturally, the sentences contain spelling mistakes. If a particular wrong spelling of a certain word hasn't appeared in the training corpus, the classifier has no chance to identify it.</p>\n\n<p>I consider taking an existing spelling corrector, and integrate it with my current classifier, but I am not sure how to do it.</p>\n\n<p>Do you know of a paper that integrates an automatic spelling correction tool with a short text classifier? </p>\n", 'ViewCount': '76', 'Title': 'short text categorization with spelling correction', 'LastEditorUserId': '1342', 'LastActivityDate': '2013-08-22T14:34:49.877', 'LastEditDate': '2013-08-22T11:42:58.863', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<reference-request><machine-learning><natural-lang-processing><classification>', 'CreationDate': '2013-08-22T11:20:26.190', 'Id': '13864'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am looking for algorithms to classify words in a paragraph of text. I am particularly interested in a classification to determine if a certain word is noun, verb, etc., but also looking for any kind of word-classification algorithms. I am given a smaller input (e.g. 200 words) so there is no many options for machine learning but I would really appreciate algorithms involving machine learning.</p>\n', 'ViewCount': '90', 'Title': 'Word classification algorithms', 'LastEditorUserId': '98', 'LastActivityDate': '2013-09-02T09:52:19.747', 'LastEditDate': '2013-09-02T09:52:19.747', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '8870', 'Tags': '<machine-learning><classification><computational-linguistics>', 'CreationDate': '2013-08-30T12:42:27.970', 'Id': '14037'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p><a href="https://en.wikipedia.org/wiki/Multi-label_classification" rel="nofollow">Multi-label classification</a> is a machine-learning problem where each sample can have zero or more labels from a closed set of possible labels. This task has applications in several fields. For example, in dialog systems, each sentence that the human says may have several intents, and the classifier should detect all of them. For example, the sentence "I want a cake and a drink" contains the two intents "WANTCAKE" and "WANTDRINK".</p>\n\n<p>Theoretically, I expect a classifier to classify multi-label samples, even if the training data contained only single-label samples. For example, consider the following training set (where each word is considered a feature):</p>\n\n<ul>\n<li>"I want a cake" -> WANTCAKE</li>\n<li>"I want a drink" -> WANTDRINK</li>\n<li>"I want a solution" -> WANTSOLUTION</li>\n</ul>\n\n<p>I would expect a classifier to realize, that the words "I want a" are not relevant for classification, and the words cake/drink/solution are indicative of the classes WANTCAKE/WANTDRINK/WANTSOLUTION respectively, and classify the sentence "I want a cake and a drink" correctly as {WANTCAKE,WANTDRINK}.</p>\n\n<p>This seems trivial to humans. Therefore. I was very surprised to find out, that many state-of-the-art multi-label classifiers fail miserably on this simple task!</p>\n\n<p>For example, consider a multi-label classifier in the "Binary Relevance" method. In this method, there is a single binary classifier for each label. For example, there is a binary classifier for the "WANTCAKE" label, trained with I want a cake" as a positive sample, and the other two sentences as negative samples. When this classifier sees the sentence "I want a cake and a drink and a solution", it sees a <em>single</em> feature "cake" that is a positive signal of WANTCAKE, and <em>two</em> features, "drink" and "solution", that are negative signals of WANTCAKE, because they appeared in the training set with sentences that did not have the WANTCAKE label. Therefore, this classifier returns \'negative\'. The same happens for the other two binary classifiers, and thus the multi-label classifier returns an empty set!</p>\n\n<p>I also tried other approaches to multi-label classification, such as RF-PCT (Random Forest Prediction Clustering Trees), with a slightly larger example (7 labels instead of 3) and got similar results. </p>\n\n<p>I sent this problem to machine learning experts, and they told me that I need more training data. They said that a classifier cannot tag multi-label instances, if the training data contains only single-label instances. In practice, they are right - adding more training data usually improves the accuracy of the classifier. </p>\n\n<p>But I am still bothered with the theoretical issue - how can it be, that there is no state-of-the-art classifier that can solve this trivial, 3-instance problem?</p>\n\n<p>I am looking for a classifier that provably solves such problems. I.e., a classifier for which there is a proof, that if it is given correct single-label samples, it can correctly solve multi-label cases.</p>\n\n<p>Is there such a classifier?</p>\n', 'ViewCount': '89', 'Title': 'Theory of multi-label classification', 'LastActivityDate': '2013-09-08T00:07:55.913', 'AnswerCount': '1', 'CommentCount': '2', 'AcceptedAnswerId': '14205', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1342', 'Tags': '<machine-learning><correctness-proof><classification>', 'CreationDate': '2013-09-03T17:41:10.823', 'Id': '14107'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'m thinking of an application for diabetics, that, given previous values of blood glucose and insulin dosage, predicts the glucose level for the next few hours.</p>\n\n<p>I know a few things about neural networks and perceptrons, but not much. And there are probably whole other worlds of other machine learning methods. So I\'d like to ask about what way should I try to go.</p>\n\n<p>My problem is below:</p>\n\n<hr>\n\n<p>The app would probably have a (very) simplified model over what is the reality (what food, how much of it, did some sport lately?, what kind of insulin, etc.) - and there are also some "expert knowledge" rules that I know but that wouldn\'t get programmed into it (eg. if you have too low glucose level, your body compensates and makes it into a too high glucose level). I want to try how far can I get just with the glucose measurements (when and how much) and insulin dosage (when and how much).</p>\n\n<p>I guess the main question it would be nice if the program solved is <strong>"Given my glucose history, what glucose will I have in a few hours if I take X units of insulin?"</strong> (That could indirectly solve question "How many units of insulin should I take if I want to have a good glucose level in a few hours?" but that\'s more complicated matter.)</p>\n\n<p>The food is an important part of the question, but I think it\'s closely linked to the insulin - the two balance out: if you eat food, you take insulin. You don\'t take insulin without eating (it\'s more complicated than that, but I\'m trying to make it simple), so I guess it could work without putting in the data about food.</p>\n\n<p>Now the data (at least timewise) isn\'t uniformly distributed. Ideally it should be (regular measurements at the morning, noon, evening, etc.) but more often than not the measurements get skipped. So the training dataset would have to deal with having "holes" in it. I guess that\'s ruling out some methods.</p>\n\n<p>What do you recommend to try? (Again, this is not anything medically professional and "to be used in real life" - it\'s just a proof of concept for me and a toy project to try to do some machine learning.)</p>\n', 'ViewCount': '72', 'Title': 'What machine learning method for diabetes prediction SW?', 'LastActivityDate': '2013-09-07T21:06:16.847', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '4', 'PostTypeId': '1', 'OwnerUserId': '9122', 'Tags': '<algorithms><machine-learning><classification>', 'CreationDate': '2013-09-07T21:06:16.847', 'Id': '14201'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I know Gentle Boost, an adaption of the AdaBoost algorithm, can be used for <em>binary</em> classification. However, I need to do $n$-ary classification. How do I modify or extend the GentleBoost algorithm so it can be used for $n$-ary classification?</p>\n', 'ViewCount': '93', 'Title': 'N-ary (NOT binary) Gentle Boost algorithm?', 'LastEditorUserId': '755', 'LastActivityDate': '2013-10-01T19:06:03.560', 'LastEditDate': '2013-10-01T18:47:15.770', 'AnswerCount': '0', 'CommentCount': '4', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<algorithms><machine-learning><classification>', 'CreationDate': '2013-09-30T19:54:09.537', 'Id': '14714'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I recently did work in the area of machine learning for one of my jobs and was able to build a classifier which evaluated to an F score of 85%. I also have access to correctly and incorrectly classified instances. My boss would like to make sure my classifier is good and and test it for statistical significance. I'm not quite sure what he means by this. I have taken a course in statistics quite some time ago where I did hypothesis testing and stuff with confidence intervals. Do you think that's what he means or does he want me to compare it with other algorithms? I don't want to say what kind of data set I am working with but it's comparable to something such as predicting spam or ham for email messages. </p>\n\n<p>Any help or guidance on this question would be greatly appreciated. I am pretty new to the area of computer science research. But am I right in saying that statistics are used quite a lot to evaluate these types of things?</p>\n\n<p>Thank you!</p>\n", 'ViewCount': '29', 'Title': 'Finding Statistical Signifigance for a Classifier', 'LastActivityDate': '2013-10-07T00:11:48.270', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '14870', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '4336', 'Tags': '<machine-learning><statistics><classification>', 'CreationDate': '2013-10-06T23:28:43.117', 'Id': '14866'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a question about preparing the dataset of positive samples for a cascaded classifier that will be used for object detection.</p>\n\n<p>As positive samples, I have been given 3 sets of images:</p>\n\n<ol>\n<li>a set of <strong>colored</strong> images in full size (about 1200x600) with a <strong>white background</strong> and with the object displayed at a different angles in each image</li>\n<li>another set with the same images in grayscale and with a <strong>white background</strong>, scaled down to the detection window size (60x60)</li>\n<li>another set with the same images in grayscale and with a <strong>black background</strong>, scaled down to the detection window size (60x60)</li>\n</ol>\n\n<p>My question is that in Set 1, should the background really be white? Should it not instead be an <strong>environment</strong> that the object is likely to be found in in the testing dataset? Or should I have a fourth set where the images are in their natural environments? How does environment figure into the training samples?</p>\n', 'ViewCount': '36', 'Title': 'Environment requirement in training image dataset for classifier', 'LastEditorUserId': '98', 'LastActivityDate': '2013-11-27T12:25:13.433', 'LastEditDate': '2013-11-12T16:52:26.290', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<machine-learning><image-processing><computer-vision><data-sets><classification>', 'CreationDate': '2013-11-12T09:44:33.823', 'Id': '17949'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>My aim is to classify types of cars (Sedans,SUV,Hatchbacks) and earlier I was using corner features for classification but it didn\'t work out very well so now I am trying Gabor features.<br/></p>\n\n<p><a href="http://www.mathworks.in/matlabcentral/fileexchange/38844-gabor-image-features" rel="nofollow">code from here</a><br/></p>\n\n<p>Now the features are extracted and suppose when I give an image as input then for 5 scales and 8 orientations I get 2 [1x40] matrices.</p>\n\n<p><strong>1. 40 columns of squared Energy.</strong></p>\n\n<p><strong>2. 40 colums of mean Amplitude.</strong></p>\n\n<p>Problem is I want to use these two matrices for classification and I have about 230 images of 3 classes (SUV,sedan,hatchback).</p>\n\n<p>I do not know how to create a [N x 230] matrix which can be taken as vInputs by the neural netowrk in matlab.(where N be the total features of one image).</p>\n\n<p>My question:</p>\n\n<ol>\n<li><p>How to create a one dimensional image vector from the 2 [1x40] matrices for one image.(should I append the mean Amplitude to square energy matrix to get a [1x80] matrix or something else?)</p></li>\n<li><p>Should I be using these gabor features for my purpose of classification in first place? if not then what?</p></li>\n</ol>\n\n<p>Thanks in advance</p>\n', 'ViewCount': '53', 'Title': 'Making feature vector from Gabor filters for classification', 'LastActivityDate': '2013-11-16T13:58:45.183', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '18073', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '11370', 'Tags': '<machine-learning><neural-networks><image-processing><classification>', 'CreationDate': '2013-11-14T06:23:16.160', 'Id': '18009'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm searching for computer vision or machine learning algorithms/methods that are used to classify or differentiate two outdoor environments. Given an image with vehicles, I need to be able to detect whether the vehicles are in a natural open landscape (desert, in particular), or whether they're in the city. </p>\n\n<p>I've searched but can't seem to find relevant work on this. Perhaps because I'm new at computer vision, I'm using the wrong search terms.</p>\n\n<p>Any ideas? Is there any work (or related) available in this direction?</p>\n", 'ViewCount': '70', 'Title': 'Environment detection - How to detect "city" versus "landscape" background environment in computer vision?', 'LastActivityDate': '2013-12-19T18:52:08.227', 'AnswerCount': '4', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<image-processing><computer-vision><classification>', 'CreationDate': '2013-11-28T06:55:27.333', 'Id': '18437'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm having this binary classification model for my Master's thesis. In my tests I get pretty good results (~85%-90% success rate). Though, I would like to have a comparison of other classification problems so I could know if I'm above or below the average success rates.</p>\n\n<p>I know I should do the comparison within my field and I am working on that as well. But it will be nice to have other examples of classification success rates from other fields, for example: medical patients (sick or healthy?), elections of two candidates and etc.</p>\n\n<p>Thanks in advanced,</p>\n\n<p>Cheers!</p>\n", 'ViewCount': '40', 'Title': 'What considered as good results in machine learning binary classification', 'LastActivityDate': '2013-12-02T08:31:10.300', 'AnswerCount': '0', 'CommentCount': '5', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11754', 'Tags': '<machine-learning><classification>', 'CreationDate': '2013-12-02T08:31:10.300', 'Id': '18528'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I'm using machine-learning algorithms to solve binary classification problem (i.e. classification can be 'good' or 'bad'). I'm using <code>SVM</code> based algorithms, <code>LibLinear</code> in particular. When I get a classification result, sometimes, the probability estimations over the result are pretty low. For example, I get a classification 'good' with probability of 52% - those kind of results I rather throw away or maybe classify them as 'unknown'.</p>\n\n<p><strong>EDITED - by D.W.'s suggestion</strong></p>\n\n<p>Just to be more clear about it, my output is not only the classification 'good' or 'bad', I also get the confidence level (in %). For example, If I'm the weather guy, I'm reporting that tomorrow it will be raining, and I'm 52% positive at my forecast. In this case, I'm sure you won't take your umbrella when you leave home tomorrow, right? So in those cases where my model does not have a high confidence level I throw away this prediction and don't count it in my estimations.</p>\n\n<p>Unfortunately, I can't find articles regarding thresholding the probability estimations... </p>\n\n<p>Does anyone have an idea what is a normal threshold that I can set over the probability estimations? or at least can refer me to a few articles about it?</p>\n", 'ViewCount': '69', 'Title': 'What would be a decent threshold for classification problem?', 'LastEditorUserId': '11754', 'LastActivityDate': '2014-04-20T10:08:52.793', 'LastEditDate': '2013-12-21T08:24:16.580', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11754', 'Tags': '<machine-learning><probabilistic-algorithms><statistics><classification>', 'CreationDate': '2013-12-20T07:53:10.210', 'Id': '19146'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>In case of binary classification problem, what are the $y_i$ 's in the training data set $\\{(x_1, y_1), (x_2, y_2), \\dots (x_n, y_n)\\}$?</p>\n\n<p>I guess they are from $\\{1,-1\\}$. Now I see a method for finding a scoring function $f(x) = w^Tx + b$ by minimizing the squared error between the $f(x_i)$'s and $y_i$'s over $w$ and $b$. Now is it correct to minimize the error between $f(x_i)$'s and $y_i$? The latter is a sign while the former is a value? They seem incomparable to me. </p>\n", 'ViewCount': '43', 'Title': 'What values do $y_i$ in training data for binary classification problems attain?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-03-04T15:07:53.207', 'LastEditDate': '2014-02-02T13:53:00.000', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '13091', 'Tags': '<terminology><machine-learning><classification>', 'CreationDate': '2014-02-02T13:01:37.330', 'Id': '20214'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>For many machine learning projects that we do, we start with the k Nearest Neighbour classifier. This is an ideal starting classifier as we usually have sufficient time to calculate all distances and the number of parameters is limited (k, distance metric and weighting)</p>\n\n<p>However, this has often the effect that we stick with the knn classifier as later in the project there is no room for switching to another classifier. What would be good reason to try a new classifier. Obvious ones are memory and time restraints, but are there cases when another classifier can actually improve the accuracy? </p>\n', 'ViewCount': '24', 'Title': 'When should I move beyond k nearest neighbour', 'LastActivityDate': '2014-02-24T18:16:51.620', 'AnswerCount': '3', 'CommentCount': '2', 'AcceptedAnswerId': '21980', 'Score': '8', 'OwnerDisplayName': 'Rhand', 'PostTypeId': '1', 'Tags': '<neural-networks><classification>', 'CreationDate': '2014-02-11T12:18:44.347', 'Id': '21977'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am new to machine learning, so forgive me if I am doing something absolutely absurd.</p>\n\n<p>I have a classification task (~100 classes) and have about 2 million training data points in a 2000-dimensional space. Coordinates of data points are integers (discrete). All points have non-zero coordinates only for &lt; 10 dimensions. That is, each point can be uniquely defined in &lt; 10 dimensional sub-space.</p>\n\n<p>If I use a Gaussian Mixture Model (GMM) for each class, I will end up with ~100 GMMs in a 2000-dimensional space. I feel that given the fact that each point is uniquely definable in less than 10 dimensional space, there can possibly be a better way of doing it.</p>\n\n<p>What am I missing here?</p>\n', 'ViewCount': '40', 'Title': 'Classification algorithm for high dimensional data which is uniquely definable in a very small sub-space', 'LastEditorUserId': '472', 'LastActivityDate': '2014-03-04T09:09:49.450', 'LastEditDate': '2014-03-04T09:09:49.450', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15225', 'Tags': '<machine-learning><classification>', 'CreationDate': '2014-03-03T12:47:29.817', 'FavoriteCount': '1', 'Id': '22217'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I have a data set with two classes: one class has at most 2000 members while the size of the second class is unlimited, though it is typically in the hundreds of thousands.  I have read that it is problematic to use a decision tree to naively classify this data.  My question is, how how I modify the data or the classification scheme to classify such data, using a decision tree at some point?</p>\n', 'ViewCount': '26', 'Title': 'Decision Tree with Unbalanced Data', 'LastActivityDate': '2014-03-29T00:54:58.383', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '15425', 'Tags': '<machine-learning><data-mining><classification>', 'CreationDate': '2014-03-08T17:40:23.287', 'Id': '22406'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Consider the following soft margin loss function: $\\max(0, 1-yf(x))$.  I have the problem of needing to compute the conditional probability $p(y|x)$ corresponding to this function and am having trouble making the connection between conditional probability and this function.  I have come across a few papers (e.g. <a href="http://www.unc.edu/~yfliu/papers/lum.pdf" rel="nofollow">http://www.unc.edu/~yfliu/papers/lum.pdf</a>) that say that "soft classifiers explicitly calculate the class conditional probabilities", but I do not understand how as the output of a classifier is not a probability.  Can someone please explain what I am missing?</p>\n', 'ViewCount': '73', 'Title': 'Soft Margin Loss and Conditional Probabilities', 'LastEditorUserId': '683', 'LastActivityDate': '2014-03-31T12:54:01.220', 'LastEditDate': '2014-03-11T11:50:27.197', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '15425', 'Tags': '<machine-learning><probability-theory><classification>', 'CreationDate': '2014-03-11T08:42:06.473', 'Id': '22494'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>Currently I'm trying to classify spam emails with kNN classification. Dataset is represented in the bag-of-words notation and it contains approx. 10000 observations with approx. 900 features. Matlab is the tool I use to process the data.</p>\n\n<p>Within the last days I played with several machine learning approaches: SVM, Bayes and kNN. In my point of view, kNN's performance beats SVM and Bayes when it comes to minimize the false positive rate. Checking with 10-fold Cross-Validation I obtain a false positive rate of 0.0025 using k=9 and Manhattan-Distance. Hamming distance performs in the same region.</p>\n\n<p>To further improve my FPR I tried to preprocess my data with PCA, but that blow away my FPR as a value of 0.08 is not acceptable.</p>\n\n<p>Do you have any idea how to tune the dataset to get a better FPR?</p>\n\n<p>PS: Yes, this is a task I have to do in order to pass a machine learning course.</p>\n", 'ViewCount': '60', 'Title': 'kNN: how to improve Spam classification?', 'LastActivityDate': '2014-04-26T17:41:22.150', 'AnswerCount': '3', 'CommentCount': '3', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '15994', 'Tags': '<machine-learning><classification>', 'CreationDate': '2014-03-22T11:18:18.067', 'FavoriteCount': '1', 'Id': '22934'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>I've been researching on AdaBoost and GentleBoost classifiers, but can't seem to find a clear answer to the question:</p>\n\n<ul>\n<li>What is Adaboost better at classifying in computer vision?</li>\n<li>What is GentleBoost better at classifying?</li>\n</ul>\n\n<p>I've been told that AdaBoost is good for things with soft edges, like facial recognition, while GentleBoost is good for things with harder and more symmetrical features and edges, like vehicles. Is this true? Is there any proof for this or any evidence to back up this claim?</p>\n", 'ViewCount': '26', 'Title': 'Advantages of adaboost over gentleboost in applications, or vice versa?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-01T13:37:38.917', 'LastEditDate': '2014-04-01T13:37:38.917', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<algorithms><reference-request><machine-learning><classification><computer-vision>', 'CreationDate': '2014-04-01T10:34:09.543', 'FavoriteCount': '1', 'Id': '23316'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I am doing a project to recognize a kind of leaf using ANNs with Emgu CV in C#. My project is to get frames from camera then present them to the ANN and have the ANN tell me if that frame contain a leaf or does not contain a leaf. </p>\n\n<p>I am using 1000 images of leaves that I want to recognize, so if the frame contain a leaf, the ANN will tell me that frame contains one.  I do not know what kind of images I should use for the second class. I want to use images perhaps, for example, like pens, rocks, or telephones all together in the second class.</p>\n', 'ViewCount': '14', 'ClosedDate': '2014-04-10T22:30:27.440', 'Title': 'What types of images should I use for negative examples in a classification problem?', 'LastEditorUserId': '88', 'LastActivityDate': '2014-04-10T19:51:49.737', 'LastEditDate': '2014-04-10T19:51:49.737', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '16457', 'Tags': '<artificial-intelligence><neural-networks><classification>', 'CreationDate': '2014-04-04T20:25:40.320', 'Id': '23434'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>I\'ve been reading up on boosting algorithms.</p>\n\n<p>I understand that the main crux of the algorithm is to build weak classifiers that are slightly better than random guessing, and then to add them up so that we end up with a strong classifier. This is done via "boosting rounds".</p>\n\n<p>With different papers using different variables, like <em>k</em>, <em>n</em>, <em>m</em>, etc, it\'s gotten a bit confusing.</p>\n\n<p>I just want to confirm, if I run a boosting algorithm for, say 150 rounds, is that equivalent to saying that I\'m training 150 <em>weak classifiers</em>? I mean, is a weak classifier the output of one boosting round?</p>\n', 'ViewCount': '25', 'Title': 'Boosting algorithms: Confusion between "weak classifiers" versus "number of boosting rounds"', 'LastActivityDate': '2014-04-09T07:23:23.323', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '23585', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '10418', 'Tags': '<algorithms><classification>', 'CreationDate': '2014-04-08T19:14:37.247', 'Id': '23561'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': u"<p>That's the problem</p>\n\n<p>$$y=(x,w,\\rho) = \\begin{cases}\n 1 &amp; \\sum_{i=1}^3 w_ix_i &gt;\\rho\\\\\n 0 &amp; \\text{otherwise}\n\\end{cases},$$</p>\n\n<p>where $x=\\{x_1,x_2,x_3\\}$ are inputs, $w=\\{w_1,w_2,w_3\\}$ are weights and\n$\\rho$ is the threshold value.</p>\n\n<p>The problem asks to find an opportune set of weights that can \nclassify these inputs.</p>\n\n<p>$$A = \\{(1, 2, 0), (\u22121, 3, 0), (\u22122, \u22123, 0)\\},$$ \n$$B = \\{(0,1,2),(9,0,1),(\u22123,\u22123,3)\\}.$$</p>\n\n<p>The first step is to assign a random weights to all inputs</p>\n\n<p>$w_1= 0.5$, $w_2= 0.7$, $w_3=0.3$.</p>\n\n<p>For the first example\n$(1,2,0)$ that I know is part of the A class</p>\n\n<p>$\\sum_{i=1}^3 w_ix_i=1.9 &lt; \\rho~ \\Rightarrow y=0$ is the result.</p>\n\n<p>I need to update the weights but I can't understand how.</p>\n\n<p>The formula is</p>\n\n<p>$w_i'=w_i*n*x(t-y)$.</p>\n\n<p>Correct?</p>\n", 'ViewCount': '51', 'Title': 'Perceptron learning rule for classification', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-14T08:18:17.777', 'LastEditDate': '2014-04-09T11:47:08.043', 'AnswerCount': '2', 'CommentCount': '3', 'Score': '-3', 'PostTypeId': '1', 'OwnerUserId': '12495', 'Tags': '<artificial-intelligence><probability-theory><neural-networks><classification>', 'CreationDate': '2014-04-09T09:05:18.430', 'Id': '23589'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': '<p>Let $X$ be an $m\\times n$ ($m$: number of records, and $n$: number of attributes) dataset.  When the number of attributes $n$ is large and the dataset $X$ is noisy, classification gets more complicated and the classification accuracy decreases. One way to over come this problem is to use linear transformation, i.e., perform classification on $Y=XR$, where $R$ is an $n\\times p$ matrix, and $p\\leq n$. I was wondering how linear transformation simplifies classification? and why classification accuracy increases if we do classification on the transformed data $Y$ when $X$ is noisy?</p>\n', 'ViewCount': '57', 'Title': 'Why linear transformation can improve classification accuracy when the dimensionality of data is high?', 'LastEditorUserId': '683', 'LastActivityDate': '2014-04-28T22:51:22.710', 'LastEditDate': '2014-04-27T05:08:49.667', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '17110', 'Tags': '<machine-learning><data-mining><linear-algebra><matrices><classification>', 'CreationDate': '2014-04-27T01:46:05.837', 'FavoriteCount': '1', 'Id': '24147'}},{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,{'Body': "<p>One approach for clustering a high dimensional dataset is to use linear transformation, and the most common approaches are PCA and random projection (where random projection arises from the Johnson-Lindenstrauss Lemma). I was wondering why we can't use other random transformation  s like when our transformation matrix $R$ was drawn from a uniform distribution?</p>\n", 'ViewCount': '16', 'Title': 'Subspace clustering with random transformation', 'LastActivityDate': '2014-04-30T04:26:59.197', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '17110', 'Tags': '<data-mining><linear-algebra><classification><cluster>', 'CreationDate': '2014-04-30T03:43:25.603', 'Id': '24249'}},