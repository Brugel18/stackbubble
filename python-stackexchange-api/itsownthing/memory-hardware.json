{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Let r be the number of rows in a DRAM array, and c be the number of columns.</p>\n\n<p>Apparently, DRAM with organization 16x1 requires least pins when r = c = 4 because fewer address bits are required to represent them, and so does DRAM with organization 16x4. Why are these the same? Doesn't the latter have 4 columns instead of 1?</p>\n", 'ViewCount': '44', 'Title': 'Where do these DRAM row/column calculations come from?', 'LastEditorUserId': '39', 'LastActivityDate': '2013-01-24T02:04:22.740', 'LastEditDate': '2013-01-23T19:43:04.990', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '9125', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '2860', 'Tags': '<computer-architecture><memory-hardware>', 'CreationDate': '2013-01-23T15:34:15.350', 'Id': '9111'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>In all computer architecture books we study that Cache memory could be divided into 3 levels (L1,L2 and L3) and its very beneficial to do so. Why don't we use the same approach in case of main memory (RAM). Is there any particular reason that we avoid this?</p>\n", 'ViewCount': '107', 'Title': 'Computer Architecture-3 level RAM hierarchy', 'LastEditorUserId': '98', 'LastActivityDate': '2013-03-20T20:49:01.840', 'LastEditDate': '2013-03-20T20:49:01.840', 'AnswerCount': '1', 'CommentCount': '1', 'AcceptedAnswerId': '10647', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '7347', 'Tags': '<computer-architecture><memory-hardware>', 'CreationDate': '2013-03-20T10:27:37.090', 'Id': '10641'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I am reading Computer Architecture &amp; Organization by William Stallings to understand I/O operations. Stallings pretty well explains why Programmed I/O (CPU keeps checking the I/O module register status) &amp; Interrupt I/O (CPU still has to over look data transfer between I/O module &amp; memory) are not efficient &amp; introduces to DMA, where DMA itself handles everything. </p>\n\n<p>But, however, he also mentions that during a DMA operation, CPU sits idle &amp; has no control over memory bus. If CPU has to sit idle, then how it is better than other two methods ? </p>\n\n<p>Page no. 415, Computer Architecture &amp; Orgazination by Morris Mano:</p>\n\n<blockquote>\n  <p>During the DMA transfer, the CPU is idle and has no control of the memory.</p>\n</blockquote>\n\n<p>Only way it make sense to me is that, CPU can perform any operation which does not involve memory bus during a DMA operation. So, CPU will not be idle. Or am I missing something ?</p>\n\n<p>I think author has formulated in a bad way. It can be phrased like: </p>\n\n<blockquote>\n  <p>During DMA transfer, the CPU has no control of memory buses and thus cannot perform any operations involving memory. However it can perform other operations like arithmetic, logical or can operate on data in cache. </p>\n</blockquote>\n\n<p>Am I right?</p>\n', 'ViewCount': '470', 'Title': 'How DMA improves I/O operation efficiency?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-01-31T20:13:03.183', 'LastEditDate': '2013-04-02T15:15:16.130', 'AnswerCount': '3', 'CommentCount': '3', 'AcceptedAnswerId': '10900', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '6665', 'Tags': '<computer-architecture><memory-hardware><memory-access>', 'CreationDate': '2013-03-29T15:48:19.407', 'Id': '10896'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p><a href="http://www.mikroe.com/img/publication/pic-books/programming-in-c/chapter/03/fig3-3.gif" rel="nofollow">PIC16F887 Block Diagram</a></p>\n\n<p>According to the block diagram above, since we already have Program Memory, which may be used to store our program, why should we still need EEPROM? What is it for?</p>\n', 'ViewCount': '153', 'Title': 'Why we need EEPROM in this micro-controller', 'LastEditorUserId': '6716', 'LastActivityDate': '2013-04-10T19:46:32.367', 'LastEditDate': '2013-04-10T19:46:32.367', 'AnswerCount': '1', 'CommentCount': '0', 'AcceptedAnswerId': '11193', 'Score': '3', 'PostTypeId': '1', 'OwnerUserId': '1374', 'Tags': '<computer-architecture><memory-hardware>', 'CreationDate': '2013-04-10T14:28:37.250', 'Id': '11192'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>Realize I didn't mention x86 or any more details to make this non-specific to any platform, but to just get a general idea of how this is done(this is also a long question with a lot of details).</p>\n\n<p>I know most PC motherboards for desktop (if not all) computers have two sections; north and south bridge, and a chipset connects them together between the CPU's implementation and the buses carrying data around the board.</p>\n\n<p>The x86 CPU has a register, I think, called the accumulator, which has eight bit AL, sixteen bit AX, and thirty-two bit EAX. Data for these registers are typically used for arithmetic operations, general purpose machine instruction, etc.</p>\n\n<p>Also, supposedly for I/O access, such as with Port I/O. There is Port I/O and MMIO (memory-mapped input/output), which are two methods of accessing data outside the CPU.</p>\n\n<p>I have inspected memory maps, but I'm still unclear on whether or not it's part of an instruction fetched from memory (i.e., MOV AL, 0FF) or from some other instruction to actually access hardware. </p>\n\n<p>My basic question is, what specific instructions are used to write and read data from hardware, from a bare machine perspective; no device drivers, no operating system, and no firmware interrupts. This is the very essence of how system software must be made, and there's little complete coverage on how this works from the CPU's register to the hardware itself. I have seen BIOS interrupts, but that abstracts away details. Also, the developer had no idea what happens beyond INT 13. </p>\n\n<p>So, despite my broad question, is there some specific way this is accomplished, either by instruction, correct value set in a register, etc.?</p>\n\n<p>Example: Say I want to make a few beep noises. The sound hardware is responsible for making any noise at all, so I would, from a bare machine perspective, once again, have to directly access the hardware and its components, circuitry, or otherwise internal hardware registers or such to make noise. Is there a complimentary way of doing this that is specifically outlined or guidelined per-platform, or does it vary based on every specific piece of hardware and CPU?</p>\n\n<p>If so, what would help me unravel that mystery to program for it this way? Would the card be, let's say, mapped a special address you write to? Then I would just set a register and the CPU will just send it there with whatever value it contains?</p>\n\n<p>I am confused, and nothing makes clarity of this, because abstractions exist even at the low-level that create a barrier of the unknown.</p>\n", 'ViewCount': '73', 'Title': 'General question about how CPUs send and receive data/bytes to hardware?', 'LastEditorUserId': '2253', 'LastActivityDate': '2013-06-07T22:24:39.173', 'LastEditDate': '2013-06-07T21:13:08.563', 'AnswerCount': '1', 'CommentCount': '0', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '8575', 'Tags': '<operating-systems><memory-hardware>', 'CreationDate': '2013-06-07T19:52:44.357', 'FavoriteCount': '0', 'Id': '12517'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I have come across a question that I am having quite a hard time with. I am to draw a design of an SRAM chip with an organization of 2M*128 SRAM that uses 1K*1K arrays of D latches. And then the questions ends with saying, "if this design is not possible then explain why." I have looked at other SRAM designs and have noticed that the multiplication of their d latch arrays, the resulting number is large enough to cover the first number of the SRAM, in this case 2M.</p>\n\n<p>The other example I was looking at had a 32K*8 SRAM chip with 512*64 arrays of d latches. Assuming the array size is also in K, I multiplied 512 by 64 and came up with 32768. This covers the 32K of the SRAM chip. With my first example above, I multiplied 1K by 1K or 1000 * 1000 = 1000000. This does not cover the 2M of the SRAM chip. So am I to believe that it\'s not possible to design this chip? Also I could be totally wrong. I do not have that much experience in electrical engineering so forgive me.</p>\n\n<p>Any help at all would be greatly appreciated in helping me!</p>\n\n<p>Thank you.</p>\n', 'ViewCount': '53', 'Title': 'Drawing the Design of an SRAM chip', 'LastActivityDate': '2013-09-28T19:38:49.713', 'AnswerCount': '0', 'CommentCount': '1', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '4336', 'Tags': '<memory-management><memory-hardware>', 'CreationDate': '2013-09-28T19:38:49.713', 'Id': '14659'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>This is a kind of follow-up to a question I asked on superuser, where I asked for the definitions of a \'distinghuisable state\' and a \'memory cell\'. My questions where properly answered, but I was still confused about a certain matter.</p>\n\n<p>I\'m reading <a href="http://large.stanford.edu/courses/2012/ph250/kumar1/" rel="nofollow">this little paper</a>, and in particular these sentences:</p>\n\n<blockquote>\n  <p>To perform useful computation, we need to irreversibly change distinguishable states of memory cell(s) .... So the energy required to write information into one binary memory bit is $E_{bit}= k_BT \\ln2$</p>\n</blockquote>\n\n<p>So my interpretation of this is that the author says that to compute, you need to change the state of bits ($ 0 \\rightarrow 1$, $1 \\rightarrow 0$) in order to compute.</p>\n\n<p>But is that actually a reasonable statement? I\'m not really interested in the rest of the paper, only this part. Do computers (I\'m not talking about supercomputers, or future computers which use qubits and whatnot, but just your average computer) compute using bits with 2 dinstinghuisable states?</p>\n\n<p>I actually was able to find this so-called \'SNL-expression\' somewhere else, namely <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-701-introduction-to-nanoelectronics-spring-2010/readings/MIT6_701S10_part7.pdf" rel="nofollow">this</a> pdf, on page 223; it\'s actually a part of MIT\'s ocw.  </p>\n', 'ViewCount': '119', 'Title': 'How do computers compute?', 'LastEditorUserId': '98', 'LastActivityDate': '2013-10-04T06:47:48.613', 'LastEditDate': '2013-10-04T06:47:48.613', 'AnswerCount': '2', 'CommentCount': '4', 'Score': '5', 'PostTypeId': '1', 'OwnerUserId': '10481', 'Tags': '<entropy><memory-hardware>', 'CreationDate': '2013-10-03T14:41:59.803', 'FavoriteCount': '1', 'Id': '14787'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>There is a 64 KB 1-word cache, and a word is 32 bits.  From that I can derive that the length of the tag field is 16 bits, the length of index field is 14 bits, and, as my professor taught me, there is always 2 bits left behind for a byte offset.</p>\n\n<p>Why the offset field is 2 bits, other than it fills in the remaining 2 bits of the word, and what its contents is was never covered in the course.</p>\n\n<p>But when I looked around on Google, I read, and correct me if I am wrong, that the length of the offset field can vary.  Although I have found answers on how to determine the length, I could not find anything about determining its contents when a read hit/miss is performed.  My professor merely said "the byte offset is not used to select the word in the cache".</p>\n\n<p>Just looking for clarification.</p>\n', 'ViewCount': '45', 'Title': 'In cache addressing, what value is placed in the offset field?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-04-19T02:50:30.900', 'LastEditDate': '2014-01-19T02:20:14.857', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '11780', 'Tags': '<cpu-cache><memory-hardware>', 'CreationDate': '2013-12-03T07:40:00.527', 'FavoriteCount': '1', 'Id': '18560'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Consider the following very simple computer program:</p>\n\n<pre><code>for i = 1 to n:\n    y[i] = x[p[i]]\n</code></pre>\n\n<p>Here $x$ and $y$ are $n$-element arrays of bytes, and $p$ is an $n$-element array of words. Here $n$ is large, e.g., $n = 2^{31}$ (so that only a negligible fraction of the data fits in any kind of cache memory).</p>\n\n<p>Assume that $p$ consists of <strong>random numbers</strong>, uniformly distributed between $1$ and $n$.</p>\n\n<p>From the perspective of modern hardware, this should mean the following:</p>\n\n<ul>\n<li>reading $p[i]$ is cheap (sequential read)</li>\n<li>reading $x[p[i]]$ is very expensive (random reads; almost all reads are cache misses; we will have to fetch each individual byte from the main memory)</li>\n<li>writing $y[i]$ is cheap (sequential write).</li>\n</ul>\n\n<p>And this is indeed what I am observing. The program is very slow in comparison with a program that does only sequential reads and writes. Great.</p>\n\n<p>Now comes the question: <strong>how well does this program parallelise</strong> on modern multi-core platforms?</p>\n\n<hr>\n\n<p>My hypothesis was that this program does not parallelise well. After all, the bottleneck is the main memory. A single core is already wasting most of its time just waiting for some data from the main memory.</p>\n\n<p>However, this was <em>not</em> what I observed when I started experimenting with some algorithms where the bottleneck was this kind of operation!</p>\n\n<p>I simply replaced the naive for-loop with an OpenMP parallel for-loop (in essence, it will just split the range $[1,n]$ to smaller parts and run these parts on different CPU cores in parallel).</p>\n\n<p>On low-end computers, speedups were indeed minor. But on higher-end platforms I was surprised that I was getting excellent near-linear speedups. Some concrete examples (the exact timings may be a bit off, there is a lot of random variation; these were just quick experiments):</p>\n\n<ul>\n<li><p>2 x 4-core Xeon (in total 8 cores): factor 5-8 speedups in comparison to single-threaded version.</p></li>\n<li><p>2 x 6-core Xeon (in total 12 cores): factor 8-14 speedups in comparison to single-threaded version.</p></li>\n</ul>\n\n<p>Now this was totally unexpected. Questions:</p>\n\n<ol>\n<li><p>Precisely <strong>why does this kind of program parallelise so well</strong>? What happens in the hardware? (My current guess is something along these lines: the random reads from different thread are "pipelined" and the average rate of getting answers to these is much higher than in the case of a single thread.)</p></li>\n<li><p>Is it <strong>necessary to use multiple threads and multiple cores</strong> to obtain any speedups? If some kind of pipelining indeed takes place in the interface between the main memory and the CPU, couldn\'t a single-threaded application let the main memory know that it will soon need $x[p[i]]$, $x[p[i+1]]$, ... and the computer could start fetching the relevant cache lines from the main memory? If this is possible in principle, how do I achieve it in practice?</p></li>\n<li><p>What is the right <strong>theoretical model</strong> that we could use to analyse this kind of programs (and make <em>correct</em> predictions of the performance)?</p></li>\n</ol>\n\n<hr>\n\n<p><strong>Edit:</strong> There is now some source code and benchmark results available here: <a href="https://github.com/suomela/parallel-random-read" rel="nofollow">https://github.com/suomela/parallel-random-read</a></p>\n\n<p>Some examples of ballpark figures ($n = 2^{32}$):</p>\n\n<ul>\n<li>approx. 42 ns per iteration (random read) with a single thread</li>\n<li>approx. 5 ns per iteration (random read) with 12 cores.</li>\n</ul>\n', 'ViewCount': '358', 'Title': u'Parallelising random reads seems to work well \u2014 why?', 'LastEditorUserId': '232', 'LastActivityDate': '2013-12-14T11:41:53.687', 'LastEditDate': '2013-12-11T21:12:42.423', 'AnswerCount': '3', 'CommentCount': '0', 'Score': '12', 'PostTypeId': '1', 'OwnerUserId': '232', 'Tags': '<parallel-computing><cpu-cache><memory-hardware>', 'CreationDate': '2013-12-10T16:19:59.237', 'FavoriteCount': '2', 'Id': '18834'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>I'm learning for the final exam of Computer System subject, Chapter 5 Large and Fast: Exploiting Memory Hierarchy in the Computer Organization and Design</p>\n\n<p>There are 2 types of subdivision that is confusing me</p>\n\n<blockquote>\n  <ol>\n  <li><p>Address Subdivision Valid bit - Tag bit - Data bit</p></li>\n  <li><p>Block Subdivision Tag bit - Index bit - Offset bit</p></li>\n  </ol>\n</blockquote>\n\n<p>I understand the 2nd type and know how and when to use it.\nBut with the 1st type I don't know when it's used and how to use it</p>\n\n<p>Anyone can help me with this? Thank you!</p>\n", 'ViewCount': '33', 'Title': 'What is the differences between address subdivision and block subdivision', 'LastEditorUserId': '12132', 'LastActivityDate': '2013-12-15T12:51:54.953', 'LastEditDate': '2013-12-15T12:51:54.953', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '0', 'PostTypeId': '1', 'OwnerUserId': '12132', 'Tags': '<memory-hardware>', 'CreationDate': '2013-12-15T09:32:04.640', 'Id': '19006'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>I\'m a newbie in computer science and would to understand how hardware interrupts work at the physical layer. I ask my question considering a specific example. When packet arrives at the network adapter, a hardware interrupt is raised. <a href="http://en.wikipedia.org/wiki/Interrupt" rel="nofollow">Wikipedia</a> says that  </p>\n\n<blockquote>\n  <p>an interrupt is a signal to the processor emitted by hardware or software indicating\n  an event that needs immediate attention.</p>\n</blockquote>\n\n<p>I know that the OS will invoke a corresponding interrupt handler when \nthe interrupt\'s type is detected. But I don\'t understand how the CPU detects and distinguishes incoming interrupts.</p>\n\n<p>First, why CPU does know that the interrupt is coming from the network adapter and not from some other device?</p>\n\n<p>Second, where are interrupt handlers registered in the CPU? Are there specific areas of the CPU that contain addresses for handlers registered by the OS?</p>\n', 'ViewCount': '50', 'Title': 'How does hardware interrupt work on a physical layer', 'LastEditorUserId': '9550', 'LastActivityDate': '2013-12-29T10:23:15.813', 'LastEditDate': '2013-12-29T10:23:15.813', 'AnswerCount': '0', 'CommentCount': '0', 'Score': '2', 'PostTypeId': '1', 'OwnerUserId': '12435', 'Tags': '<memory-hardware>', 'CreationDate': '2013-12-29T04:23:56.807', 'Id': '19354'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>Should the size of its cache line, the width of bus between memory and CPU, and the size of its registers be all equal to the CPU bit?</p>\n\n<p>Is CPU bit determined by the size of its cache line, the width of bus between memory and CPU, or the size of its registers, something else?</p>\n\n<p>Thanks!</p>\n', 'ViewCount': '48', 'Title': 'CPU bit, its cache line, the bus between memory and CPU, and its registers?', 'LastActivityDate': '2014-02-06T02:03:49.730', 'AnswerCount': '1', 'CommentCount': '2', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '336', 'Tags': '<cpu-cache><memory-hardware>', 'CreationDate': '2014-02-05T22:19:43.713', 'Id': '21331'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': '<p>When we declare a variable there will be a random part of memory will be allocated in RAM. Which component will allocate the memory? Is the processor or any other specific hardware doing the allocation?</p>\n', 'ViewCount': '59', 'Title': 'Which part of the computer allocates memory in RAM?', 'LastEditorUserId': '98', 'LastActivityDate': '2014-02-08T01:01:08.070', 'LastEditDate': '2014-02-06T15:07:53.740', 'AnswerCount': '2', 'CommentCount': '0', 'Score': '1', 'PostTypeId': '1', 'OwnerUserId': '14440', 'Tags': '<operating-systems><memory-management><memory-access><memory-hardware>', 'CreationDate': '2014-02-06T14:29:33.133', 'Id': '21378'}{'color':getRandomColor(),'shape':'dot','label':'Strings', 'size': 60, 'isExploded':false, "precedence": 2,'Body': "<p>so I am a bit confused here. I read a memory-map ranging from certain hex values and I'm trying to find out how large RAM is by it. Here's the code:</p>\n\n<pre><code>const char *memorybottom = 0x00000000;\nconst char *memorytop = 0xAA55D0AB;\n</code></pre>\n\n<p>The bottom is 0, and the top is AA55D0AB. I tried to convert that to binary and increased each 2 byte by a power of 2, left to right, but the result is 0.25 kilobytes; 256 bytes, which is 1/4th of a kilobyte. However, someone told me that AA55D0AB is for MB sized RAM.</p>\n\n<p>Can anyone help me translate between hex to determine maximum RAM capacity in MB, GB, KB, etc.? </p>\n\n<p>PS: This is for emulation. I am trying to emulate memory for an Atari 2600 by providing a lowest mem. value pointer to memorybottom, and the opposite with memorytop. However, I am not too familiar with hex but better with binary.</p>\n", 'ViewCount': '28', 'Title': 'How to find out memory size by hex ranges?', 'LastActivityDate': '2014-03-26T20:58:01.117', 'AnswerCount': '1', 'CommentCount': '1', 'Score': '-1', 'PostTypeId': '1', 'OwnerUserId': '16161', 'Tags': '<memory-hardware>', 'CreationDate': '2014-03-26T18:59:52.467', 'Id': '23096'}